<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title><![CDATA[ Building a PC, Part I ]]></title>
<link>https://blog.codinghorror.com/building-a-pc-part-i/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Over the next few days, I'll be <a href="http://www.hanselman.com/blog/TheCodingHorrorUltimateDeveloperRigThrowdownPart2.aspx">building Scott Hanselman's computer</a>. My goal today is more modest: <strong>build a minimal system that boots</strong>.</p>
<p>I'd like to dispel the myth that building computers is risky, or in any way difficult or complicated. <strong>If you can put together a LEGO kit, you can put together a PC from parts.</strong> It's dead easy, like snapping together so many LEGO bricks. Well, mostly. Have you seen how complicated <a href="http://shop.lego.com/Product/?p=10143">some of those LEGO kits</a> are?</p>
<p>Granted, building computers isn't for everybody. There are plenty of other things you might want to do with your time, like, say, spending time with your children, or finding a cure for cancer. That's why people buy pre-assembled computers from Dell. But if you need fine-grained control over <em>exactly</em> what's inside your PC, if you desire a deeper understanding of how the hardware fits together and works, then building a PC is a fun project to take on. You can easily match or beat Dell's prices in most cases, while building a superior rig -- and you can learn something along the way, too.</p>
<p>Here's the complete set of parts we ordered, per <a href="http://www.hanselman.com/blog/CommentView.aspx?guid=6ED8D229-2E2A-4B74-A65A-39EE6F7D4E9D">the component list</a>. The CPU and memory boxes aren't shown, unfortunately, because I had already opened those by the time I took this photo. Whoops!</p>
<p><img alt="image placeholder" >
<p>All you need is a few basic tools to build this PC. I typically use needle-nose pliers, wire cutters, and a small phillips screwdriver.</p>
<p><img alt="image placeholder" >
<p>Before we get started, let me share a few key things I've learned while building PCs:</p>
<p> </p>
<ul>
<li>
<strong>Computer parts are surprisingly durable.</strong> They aren't fragile. You don't have to baby them. So often I see people handle computer parts as if they're sacred, priceless relics. While I don't think you should play "catch" with your new Core 2 Quad processor, it's also not going to explode into flames if you look at it the wrong way. You don't have to tiptoe around the build. Just be responsible and use common sense. I've done some appalling things to computer hardware in my day, truly boneheaded stuff, and I think I've broken all of two or three items in the last 10 years.
<p> </p>
</li>
<li>
<strong>The risk of static discharge is overblown</strong>. I <em>never</em> wear anti-static wristbands, and I've yet to electrocute any components with static electricity. Never. Not once. However, I always touch a metal surface before handing computer components-- and that's a good habit for you to cultivate as well.
<p> </p>
</li>
<li>
<strong>Be patient, and don't force it</strong>. Those rare times I've damaged components, it's because I rushed myself and forced something that I thought should fit-- despite all the warning signs. I've learned through hard experience that "maybe I need to use lots of additional force" is <em>never</em> the right answer when it comes to building PCs. Take a deep breath. Count to ten. Refer to the manual, and double-check your work. </li>
<p> </p>
<p> </p>
</ul>
<p>I always build up the motherboard first. Place the motherboard on top of the anti-static bag it came in so it's easier to work on. Slot in the <strong>CPU</strong> and snap in the <strong>memory sticks</strong>. We're using four sticks here, so every slot is populated. However, if you're only using two sticks of memory, be sure they are in the correct paired slots for dual-channel operation. If you need advice, the motherboard manual is a good reference for basic installation steps.</p>
<p><img alt="image placeholder" >
<p>Continue building up the motherboard by installing the <strong>CPU cooler</strong>. I strongly recommend buying an aftermarket CPU cooler based on a heatpipe tower design, as they <em>wildly</em> outperform the stock Intel coolers. This particular model we chose for Scott's build is <a href="http://www.scythe-usa.com/product/cpu/023/scmn1000_detail.html">the Scythe Mine</a>, but I'm also a fan of the <a href="http://www.scythe-usa.com/product/cpu/024/scinf1000.html">Scythe Infinity</a> and <a href="http://www.scythe.co.jp/en/cooler/SCNJ1000.htm">Scythe Ninja Plus</a>. (You can see the Ninja Plus on <a href="http://www.codinghorror.com/blog/archives/000816.html">my work rig</a>.)</p>
<p>It's important to install the CPU cooler correctly, otherwise you risk frying your CPU. Refer closely to the heatsink instructions. Don't forget to place a bit of the heatsink paste (included with the cooler) on the surface of the CPU before installing. These larger heatsinks can be quite heavy, so be sure you've followed the installation instructions to the letter and secured it firmly to the motherboard. Check the orientation of the heatsink so the fan blows "out" if possible, e.g., towards the back of the motherboard, where the case exhaust fans usually are.</p>
<p><img alt="image placeholder" >
<p>Now let's <strong>build up the case</strong> to accept the motherboard. We chose the <a href="http://www.antec.com/us/productDetails.php?ProdID=81820">Antec P182 case</a> for Scott's build. This case is unique; it's a collaborative venture between the well-known case vendor <a href="http://www.antec.com/">Antec</a> and <a href="http://www.silentpcreview.com/">Silent PC Review</a>, one of my favorite PC enthusiast websites.</p>
<p>This is the second version of the case, which reflects a number of design tweaks over the original P180. It's a little expensive, but the P182 oozes quality and attention to detail. It's probably the single best designed case I've ever worked on. But don't take my word for it; see reviews at <a href="http://www.anandtech.com/printarticle.aspx?i=2966">AnandTech</a> and <a href="http://www.silentpcreview.com/article255-page1.html">SilentPCReview</a>.</p>
<p><img alt="image placeholder" >
<p>Some cases are sold with power supplies, but the higher end cases, such as the P182, typically are not. For Scott's build, we chose the <a href="http://www.corsairmemory.com/products/hx.aspx">Corsair HX series power supply</a>, which is a rebranded and tweaked Seasonic. It's considered one of the best quiet and efficient power supplies on the market, which is why it tops <a href="http://www.silentpcreview.com/article699-page1.html">the list of recommended PSUs</a> at SilentPCReview.</p>
<p>I opened the opposite side of the case to gain access to the PSU cage from both sides, installed the PSU in the cage, and threaded the power cables up through the opening in the middle.</p>
<p><img alt="image placeholder" >
<p>If you have cats, <a href="http://www.codinghorror.com/blog/archives/000831.html">like we do</a>, you have curious cat helpers. Unfortunately, cat helpers aren't all that... <em>helpful</em>.</p>
<p><img alt="image placeholder" >
<p>Now <strong>install the backplate</strong> included with the motherboard. Every backplate is different because every motherboard is different. It's held in by pressure; just snap it in firmly around the edges.</p>
<p><img alt="image placeholder" >
<p>It's finally time to <strong>place the motherboard in the case</strong>. Clear room in the case compartment by moving any errant cables out of the way and stowing them. Make sure the screw holes on the motherboard line up with the pre-installed screw mount standoffs in the case. In our P182, everything matched up perfectly out of the box.</p>
<p>Angle the motherboard down slowly and line up the ports to the backplate, then gently let the motherboard down to rest against the standoffs. Loosely line up the motherboard screw holes to the motherboard standoffs.</p>
<p><img alt="image placeholder" >
<p>Find the packet of screws included with the case, and use the appropriate screws to <strong>secure the motherboard to the case standoffs</strong>.</p>
<p><img alt="image placeholder" >
<p>Now let's <strong>connect the power supply to the motherboard</strong>. There are <em>two</em> power connectors on modern motherboards, so be sure you've connected them both. Don't worry, the connectors are keyed; you can't install them incorrectly and blow up your PC. As you can see here, I threaded the power connectors along the back side of the motherboard platform. That's one of the many nifty little design features of the P182 case.</p>
<p><img alt="image placeholder" >
<p>Before we can boot up, we need to <strong>connect the power and reset switches</strong> so they work. This part is a little fiddly. Find the cable with the labelled power, reset, and LED connectors from the case, then refer to the motherboard manual to see where the appropriate motherboard front panel connector pins are.</p>
<p><img alt="image placeholder" >
<p>Connect each front panel wire to the specific motherboard front panel pins individually. Make sure you connect them to the right location, but orientation of these connectors doesn't matter. This is where the needlenose pliers come in handy unless you have nimble (and tiny) fingers. Why this isn't a universally standard keyed block connector by now is beyond me.</p>
<p><img alt="image placeholder" >
<p>We need some kind of video output to see if our computer can boot, so let's <strong>install a video card</strong>. Scott's not a hardcore gamer, so I went for something midrange, a set of two <a href="http://www.xbitlabs.com/articles/video/display/geforce8600gts.html">NVIDIA 8600GTS</a> cards. They're an excellent blend of performance and the latest DX10 and high-definition features, while using relatively little power.</p>
<p><span style="color: red;">Don't forget to connect the 6-pin video card power connector if your video card requires it!</span> This is a common mistake that I've made more than once. Our power supply has modular connectors, so I snapped in one of the two 6-pin power connectors and threaded it up to the video card.</p>
<p><img alt="image placeholder" >
<p>We're ready for the moment of truth: <strong>does it boot?</strong> I attached a power cord to the power supply, hooked up a utility 15" LCD I keep around for testing, and then pressed the power button.</p>
<p><img alt="image placeholder" >
<p>Success! I know "reboot and select proper boot device" doesn't look like much, but it means everything is working. We've just built a minimal PC that boots up. It's a small step that we'll build on tomorrow.</p>
<p>Getting this system from a pile of parts to bootable state took <strong>about two hours</strong>. Like I promised -- easy! Writing it up is taking almost as long as actually doing it. This was a slow build for me because I was extra cautious with Scott's parts, and I was stopping to take frequent pictures. With some practice, it's possible to build a PC much more quickly-- even in <a href="http://chris.leckness.com/2007/01/10/tiger-direct-pc-building-contest-3-doors-down-etc/">under ten minutes</a>.</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2007-07-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-pc-part-i/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Building a PC, Part II ]]></title>
<link>https://blog.codinghorror.com/building-a-pc-part-ii/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Yesterday, we <a href="http://www.codinghorror.com/blog/archives/000905.html">completed a basic build of Scott Hanselman's computer</a>. We built the system up enough to boot to the BIOS screen successfully. Today, we'll complete the build by installing an operating system and burning it in.</p>
<p>The first thing we'll need is <strong>hard drives</strong>. The <a href="http://www.antec.com/us/productDetails.php?ProdID=81820">Antec P182 case</a> has a well engineered drive mounting system. The bottom cage holds 4 drives, with soft rubber grommets to support each drive, and more importantly, to isolate the case from transmitted, resonant hard drive vibration noise. After all, they are giant hunks of circular metal spinning at 7,200 to 10,000 RPMs.</p>
<p><img alt="image placeholder" >
<p>The boot drive is a 10,000 RPM Raptor, which <a href="http://www.codinghorror.com/blog/archives/000800.html">I can't recommend highly enough</a>. The secondary drive is a run of the mill 500 GB model. I slid them in and secured them using the long screws provided with the case.</p>
<p>I connected two SATA cables and threaded them down to the bottom channel through the center cutout. I snapped a modular SATA power cable into the <a href="http://www.corsairmemory.com/products/hx.aspx">Corsair HX series power supply</a>, and routed that cable around the back, into the hard drive compartment.</p>
<p><img alt="image placeholder" >
<p>Houston, we have storage!</p>
<p>But we can't install an OS without an <strong>optical drive</strong>. Fortunately, DVD drives are dirt cheap; I chose the latest Lite-On DVD drive, in black to match the case. I suppose eventually we'll be buying HD-DVD or Blu-Ray drives, but until the format war is decided, it's DVD all the way for me.</p>
<p>The 5 1/4" drive bays at the top of the P182 require the use of rails, which are provided with the case. I find rail mounting annoying, but since we're only installing a single DVD-R drive, I can deal. It took a bit of trial and error, but I got the rails screwed into each side of the drive and snapped it in to the top bay.</p>
<p><img alt="image placeholder" >
<p>This is not one of those fancy new SATA DVD drives, so we'll need to break out the old-school Parallel ATA cable included with the motherboard. I snapped in another modular power connector to provide the necessary 4-pin power. As usual I routed the power cable along the back of the motherboard tray to preserve the clean interior layout.</p>
<p><img alt="image placeholder" >
<p>We're now ready to boot up the machine. Plug in the power cord, connect a keyboard and mouse, then hit the power switch. During boot, press DELETE to enter the BIOS setup screen. Go into the basic settings and <strong>verify that all the drives we installed are properly detected by the motherboard</strong>.</p>
<p><img alt="image placeholder" >
<p>Looks good-- all three drives are showing up. From here you may want to <strong>adjust a few basic BIOS settings</strong>. For example, I always <a href="http://www.codinghorror.com/blog/archives/000215.html">set the floppy drive to "Disabled"</a>. You'll definitely want to set the boot order to ensure the right drives are booting first-- in our case, it's DVD-R, Raptor, then the second drive. Beyond those basic settings, mucking around in the BIOS isn't required at this point; we want to test the system with stock settings anyway.</p>
<p>However, do I recommend <strong>flashing the motherboard BIOS to the latest version</strong> before you go any further. You'd be surprised how often motherboards ship with out-of-date BIOSes. It isn't <em>required</em>, but your life will be easier if you flash to the latest BIOS now before you complete system setup. A full description of how to flash your motherboard's BIOS is outside the scope of this article, but here's the condensed version:</p>
<p> </p>
<ul>
<li>Check the manufacturer's website for the latest motherboard BIOS. Be absolutely, positively sure you have the BIOS for the correct motherboard model! </li>
<li>Copy the BIOS files to a <a href="http://www.thepcspy.com/articles/hardware/bootable_usb_flash_drive">bootable USB Flash drive</a>. </li>
<li>Boot from the flash drive and follow the instructions. </li>
</ul>
<p>This is a typical BIOS flash scenario. Some vendors do make it easier, though. On my ASUS P5B Deluxe, the flash program is embedded into the BIOS. Others provide programs that allow you to flash the BIOS from within Windows using a friendly GUI.</p>
<p>At any rate, BIOS update or not, we can now <strong>install an operating system</strong>. I placed my OEM copy of Windows Vista into the DVD tray, rebooted, and selected a <a href="http://www.codinghorror.com/blog/archives/000778.html">120-day trial of Windows Vista Ultimate</a>.</p>
<p><img alt="image placeholder" >
<p>Here's one thing I've learned from experience: <span style="color: red;">if your system can't finish a clean install of Windows, it's <strong>not stable</strong></span>. Period. It's tempting to <a href="http://blogs.msdn.com/oldnewthing/archive/2003/10/15/55296.aspx">blame Microsoft</a>, but the only possible culprit if you have problems at this stage is the hardware (or possibly a scratched DVD). Trust me on this one.</p>
<p>Fortunately, our new system completed the Windows install without a hitch. Remember those driver CDs that came with the motherboard? Throw them right in the trash. They're way out of date by the time the motherboard gets from the factory, to the vendor, and then finally to you. The MSI P6N SLI motherboard we chose is based on the well-regarded <strong>NVIDIA 650i SLI chipset</strong>, so we have a one stop shop at the <a href="http://www.nvidia.com/content/drivers/drivers.asp">NVIDIA drivers page</a>. I downloaded the 650i SLI platform drivers for Windows Vista x86, and the latest 8600 GTS graphics driver.</p>
<p>Now that we have Windows installed, and our platform drivers firmly in place, we know our system is <em>reasonably</em> stable. But we want to confirm that our system is <em>totally</em> stable.</p>
<p>To do that, we'll need to download a few <strong>essential burn-in utilities</strong>:</p>
<p> </p>
<ul>
<li>
<a href="http://www.mersenne.org/freesoft.htm">Prime95</a> </li>
<li>
<a href="http://www.futuremark.com/download/3dmark06/">3DMark2006</a> </li>
<li>
<a href="http://www.futuremark.com/download/pcmark05/">PCMark2005</a> </li>
<li>
<a href="http://www.daionet.gr.jp/~masa/rthdribl/">Rthdribl</a> </li>
<li>
<a href="http://www.thecoolest.zerobrains.com/CoreTemp/">CoreTemp</a> </li>
</ul>
<p>I run through basic benchmarks first. If the system can't complete a run of 3DMark or PCMark, it's <em>definitely</em> not stable. The rig we just built generated these scores:</p>
<p> </p>
<table cellspacing="4" cellpadding="4">
<tbody>
<tr>
<td>
<a href="http://www.futuremark.com/download/3dmark06/">3DMark2006</a> (@ 1024x768)</td>
<td>7217</td>
</tr>
<tr>
<td><a href="http://www.futuremark.com/download/pcmark05/">PCMark2005</a></td>
<td>7353</td>
</tr>
</tbody>
</table>
<p> </p>
<p>And of course the <a href="http://www.codinghorror.com/blog/archives/000678.html">obligatory Windows Experience results</a>:</p>
<p><img alt="image placeholder" >
<p>These tests aren't just for stability; they're also reality checks. Make sure these scores are in the ballpark for comparable systems. If not, you got something wrong in the build and somehow crippled your system's performance. Fortunately, these numbers check out (although the memory subscore is suspiciously low), and we didn't have any crashes or reboots during the benchmark runs. So far so good.</p>
<p>Now for the <em>real</em> torture test. We'll use:</p>
<ol>
<li>Four instances of <a href="http://www.mersenne.org/freesoft.htm">Prime95</a> (one per core) to load the CPU </li>
<li>Real-Time HDR IBL (<a href="http://www.daionet.gr.jp/~masa/rthdribl/">RTHDRIBL</a>) to load the GPU </li>
<li>
<a href="http://www.thecoolest.zerobrains.com/CoreTemp/">CoreTemp</a> to monitor temperatures </li>
</ol>
<p>To run four instances of Prime95, create four shortcuts to Prime95.exe using the -A(n) flag, where (n) is the core number. That's documented in <a href="http://www.dfi-street.com/forum/showthread.php?t=16446">this forum thread</a>. Start with "Small FFTs" on the Options | Torture Test dialog in each instance. Then launch RTHDRIBL in a maximized window, and CoreTemp, as pictured here.</p>
<p><img alt="image placeholder" >
<p>Now we need to monitor our patient during the torture test, at least for the first 30 minutes or so.</p>
<p>I use <a href="http://www.codinghorror.com/blog/archives/000353.html">my trusty Kill-a-Watt</a> to <strong>determine how much power the system is consuming</strong>. I saw <span style="color: red;">130 watts</span> at the Windows desktop, and during the extreme CPU and GPU torture test, <span style="color: red;">220 watts</span>.</p>
<p><img alt="image placeholder" >
<p>That gives us a rough idea of how much power dissipation, and therefore heat, we have to worry about. I also use my temperature gun to spot check various heatsinks in the system and make sure they're not getting unusually hot. Here, I'm checking the northbridge heatsink, which gets pretty toasty in modern systems.</p>
<p><img alt="image placeholder" >
<p>Fancy laser temperature guns are fun, but they're not required. I often use my built-in Mark I finger to touch various items in the computer (but not the bare electrical components, obviously) and make sure they're within normal temperature ranges. You might call me "The PC Whisperer"-- I love nothing more than getting in there and physically touching everything that's at risk of temperature damage:</p>
<p> </p>
<ul>
<li>CPU heatsink </li>
<li>Northbridge </li>
<li>Southbridge </li>
<li>Video card heatsink </li>
<li>Hard drives </li>
</ul>
<p>You'll know you're in the danger zone when something is <strong>too hot to leave your finger on for more than a few seconds</strong>. I'm happy to report that all the temperatures on this system check out, both with my temperature gun and my Mk. I finger-- even after hours and hours of torture testing.</p>
<p>Looks like we have a stable, complete system. And when you have a stable, complete system, it's clearly time to <em>overclock it until it breaks</em>. The CPU heatsink remained quite cool throughout the torture test, and CoreTemp confirms relatively low temperatures on each core. This is a very good omen for future overclocking. We'll do that tomorrow.</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2007-07-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-pc-part-ii/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Building a PC, Part III - Overclocking ]]></title>
<link>https://blog.codinghorror.com/building-a-pc-part-iii-overclocking/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Now that we have <a href="http://www.codinghorror.com/blog/archives/000905.html">Scott Hanselman's computer</a> completely built up and stable -- or at least <a href="http://www.codinghorror.com/blog/archives/000907.html">that's what our torture tests told us yesterday</a>-- it's time to see how far we can overclock this system.</p>
<p>Overclocking a computer sounds complicated, but it really isn't. We'll use four tools:</p>
<p> </p>
<ol>
<li>The motherboard's BIOS settings </li>
<li>
<a href="http://www.cpuid.com/cpuz.php">CPU-Z</a> </li>
<li>
<a href="http://www.mersenne.org/freesoft.htm">Prime95</a> </li>
<li>
<a href="http://www.thecoolest.zerobrains.com/CoreTemp/">CoreTemp</a> </li>
</ol>
<p>While overclocking, <strong>CPU-Z will become your new best friend</strong>. It tells us exactly what's happening inside our PC. Let's start with a shot of CPU-Z showing the <strong>stock settings</strong> for this Core 2 Quad 6600.</p>
<p> </p>
<table>
<tbody>
<tr>
<td><img alt="image placeholder" >
<td><img alt="image placeholder" >
</tr>
</tbody>
</table>
<p> </p>
<p>The left side is idle, and the right side is under load. Notice how the system automatically and dynamically adjusts the multiplier and voltage (the areas highlighted in red) to reduce power consumption. On the Intel platform, this technique is known as <a href="http://en.wikipedia.org/wiki/SpeedStep">EIST</a>, Enhanced Intel SpeedStep Technology.</p>
<p>First, a little basic math. This Core 2 Quad is clocked at 2.4 GHz, or 2400 MHz. The CPU speed is a function of the front side bus speed times a multiplier.</p>
<p> </p>
<table cellspacing="4" cellpadding="4">
<tbody>
<tr>
<td>Bus Speed</td>
<td>Front Side Bus Speed</td>
<td>Multiplier</td>
<td> </td>
<td>CPU Speed</td>
</tr>
<tr>
<td>266 MHz</td>
<td>1066 MHz</td>
<td>x9</td>
<td>=</td>
<td>2400 MHz</td>
</tr>
<tr>
<td>266 MHz</td>
<td>1066 MHz</td>
<td>x6</td>
<td>=</td>
<td>1600 MHz</td>
</tr>
<tr>
<td>333 MHz</td>
<td>1333 MHz</td>
<td>x9</td>
<td>=</td>
<td><span style="color: red;">3000 MHz</span></td>
</tr>
</tbody>
</table>
<p> </p>
<p>As you can see, increasing the front side bus speed from 266 MHz to 333 Mhz increases the speed of the CPU. It's also theoretically possible to increase the CPU's speed by changing the multiplier, but Intel locked down multiplier changes years ago at the silicon level. So the only way to increase the CPU's speed is to increase the front side bus speed. (There are exceptions, but they're rare.)</p>
<p>Armed with that knowledge, let's go into the BIOS (by pressing DELETE while the system is booting) and start adjusting the CPU's speed. On the MSI P6N, the CPU speed options are tucked away under a menu titled "Cell Menu". This varies from BIOS to BIOS, but the gist of the settings is the same.</p>
<p><img alt="image placeholder" >
<p>I covered overclocking briefly last year when I <a href="http://www.codinghorror.com/blog/archives/000697.html">built my last home computer</a>. The principles are still the same. To overclock, we simply <strong>bump up the front side bus speed from 1066 MHz to something larger</strong>. To give ourselves additional headroom for overclocking, we also need to bump up the memory and CPU voltages a tad.</p>
<p>Note that this particular motherboard allows me to overclock the CPU front side bus independently of the memory front side bus. The memory bus speed is expressed as a ratio of the FSB, eg, 5:4 or 3:2. Modern motherboards offer a wide range of ratios, so almost any memory bus speed is achievable within a few MHz. I had terrible results overclocking the memory in this system, so the memory is staying locked at its stock 800 MHz speed.</p>
<p>Successful overclocking is a game of inches, not yards. Start small. Increase voltage slightly and the FSB slightly, then reboot. Remember-- we started from a stable system. <strong>If your system shows any sign of instability, no matter how small, you've definitely overclocked too far.</strong></p>
<p>And if your system fails to boot, or if you can't enter the BIOS to set things back, don't fret. This is why vendors include the "reset CMOS" function on the motherboard. On the MSI P6N, it's a small button; on other motherboards it's a jumper. If all else fails, you can also pop out the CMOS battery and let the system sit for a minute or so. That'll definitely clear the BIOS settings. <span style="color: red;">However, make sure you disconnect the power <em>before</em> clearing the CMOS</span>.</p>
<p><img alt="image placeholder" >
<p>If you successfully boot into Windows, that doesn't mean your overclock is stable. You have to run Prime95 torture test for at <em>least</em> an hour to see if things are truly working, and ideally overnight to be completely sure.</p>
<p>Overclocking ability varies widely per sample of CPU and even per motherboard. Some overclock well, some don't. It's largely the luck of the draw, although most Core 2 chips have reputations as solid overclockers for good reason. The Core 2 Quad Q6600 and MSI P6N combo in <em>this</em> system were able to deliver a <strong>successful overclock from 2.4 GHz to 3.0 GHz</strong>, as shown in this CPU-Z screenshot:</p>
<p><img alt="image placeholder" >
<p>But <strong>is it stable?</strong> I ran four instances of Prime95 torture test, alongside CoreTemp to make sure the CPU temperatures stayed under control. CPU temperatures are the enemy of speed-- all other things being equal, the higher the CPU temperature, the less likely it is your system will be stable. (This is also why extreme overclockers use water cooling and liquid nitrogen.) That's one reason why we have a fancy aftermarket CPU cooler.</p>
<p>Once the torture test is running, you can minimize Prime95. The taskbar icon should stay <span style="color: red;">red</span> if things are working properly. If you see a yellow icon, that means Prime95 bombed out and your overclock isn't stable.</p>
<p><img alt="image placeholder" >
<p>After a few hours of heavy Prime95 load on each core, I was satisfied that the system was nominally stable.</p>
<p>Here are the benchmark results reflecting the newly overclocked CPU:</p>
<p><img alt="image placeholder" >
<p> </p>
<table cellspacing="4" cellpadding="4">
<tbody>
<tr>
<td> </td>
<td>Stock</td>
<td>Overclocked</td>
</tr>
<tr>
<td>
<a href="http://www.futuremark.com/download/3dmark06/">3DMark2006</a> (@1024x768)</td>
<td>7217</td>
<td>7398</td>
</tr>
<tr>
<td><a href="http://www.futuremark.com/download/pcmark05/">PCmark2005</a></td>
<td>7353</td>
<td>8432</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Yes, overclocking is a lot of manual effort, a lot of tedious trial and error tweaking. Is the risk of instability and all that effort worth it for a tiny speed bump? Why bother? Well, judge for yourself:</p>
<p> </p>
<table cellspacing="4" cellpadding="4">
<tbody>
<tr>
<td>Core 2 Quad Q6600 (stock)</td>
<td>2.40 GHz</td>
<td align="right">$480</td>
</tr>
<tr>
<td>Core 2 Extreme QX6800</td>
<td>2.93 GHz</td>
<td align="right">$1,345</td>
</tr>
<tr>
<td>Core 2 Quad Q6600 (overclocked)</td>
<td>3.0 GHz</td>
<td align="right">$480</td>
</tr>
</tbody>
</table>
<p> </p>
<p>I'd say <strong>saving nearly a thousand bucks</strong> is a pretty good argument in favor of overclocking.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-pc-part-iii-overclocking/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Steve Mann, Cyborg ]]></title>
<link>https://blog.codinghorror.com/steve-mann-cyborg/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I may have an unusual affinity for hardware, but <a href="http://en.wikipedia.org/wiki/Steve_Mann">Steve Mann</a> is in a class of his own. <a href="http://query.nytimes.com/gst/fullpage.html?sec=technology&amp;res=940CE0D71239F937A25750C0A9649C8B63">He lives the hardware</a>. Steve Mann may be the world's original cyborg.
</p>
<p>
</p>
<blockquote>
<a href="http://en.wikipedia.org/wiki/Steve_Mann">Steve Mann</a>, an engineering professor at the University of Toronto, has lived as a cyborg for more than 20 years, wearing a web of wires, computers and electronic sensors that are designed to augment his memory, enhance his vision and keep tabs on his vital signs.
</blockquote>
<p>
Mr. Mann has been exploring the frontiers of wearable computers since 1980.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Steve is <a href="http://www.wearcam.org/wearhow/node1.html">evidently at version 7</a> of his wearable computer. I'm surprised he hasn't updated the rig since 1999.
</p>
<p>
There was a flurry of interest in his work in 2001, which coincided with a <a href="http://wearcam.org/cyborg.htm">book</a> and a <a href="http://www.imdb.com/title/tt0301145/">movie</a> made about Steve. There's a companion <a href="http://www.linuxdevices.com/articles/AT8144626322.html">article on LinuxDevices</a> describing how to build a similar rig from 2001, but it feels ancient by today's standards.
</p>
<p>
It's hard to tell what's currently happening in the field of wearable computing. <a href="http://wearcam.org/">Steve's personal web page</a> is a shambles; nothing is dated. The <a href="http://www.media.mit.edu/wearables/">MIT wearable computing page</a> hasn't been updated since 2005, and the <a href="http://about.eyetap.org/index.shtml">Wearable Computing home</a> appears to be in a state of limbo. At least <a href="http://www.redwoodhouse.com/wearable/">Andy's wearable computing resource</a> looks like it's being updated on a regular basis.
</p>
<p>
Somehow, I thought the cyborgs would have a more compelling web presence.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/steve-mann-cyborg/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Be a Commodity Blogger ]]></title>
<link>https://blog.codinghorror.com/dont-be-a-commodity-blogger/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Jakob Nielsen's <a href="http://www.useit.com/alertbox/articles-not-blogs.html">"Write Articles, Not Blog Postings"</a> is highly critical of so-called commodity bloggers. As you might imagine, it wasn't received well by the blog community. <a href="http://scobleizer.com/2007/07/09/jacob-nielsen-says-dont-be-like-scoble/">Robert Scoble's stereotypical reaction</a> was perhaps the worst of the bunch. In a legendary display of narcisissm, Robert assumes the article is directed squarely at him, when it clearly wasn't. He then treats it as a personal attack, which it clearly isn't. He piles on with retaliatory personal attacks of his own, which was totally unnecessary.
</p>
<p>
Isn't it ironic how Robert's response <b>reinforces all the negative stereotypes of bloggers that Nielsen addresses in that very article</b>? Maybe it really was about Robert Scoble all along. How embarrassing. For all of us.
</p>
<p>
Can we respond to Nielsen's article without degenerating into knee-jerk narcisissm and <a href="http://weblog.raganwald.com/2007/03/ad-hominem.html">ad-hominem attacks</a>? Sure we can. <a href="http://www.knowing.net/PermaLink,guid,e5aadb98-0a69-44e3-94cb-0afa583b0c0e.aspx">Larry O'Brien's response</a> and <a href="http://www.mikepope.com/blog/AddComment.aspx?blogid=1779">Mike Pope's response</a> are proof of that.
</p>
<p>
It's true that Nielsen's article is richly deserving of criticism. At its core, the blogging advice he offers is awfully simplistic-- I'd summarize it as <b>"don't suck, and if you suck, stop sucking"</b>. Not exactly helpful. And the "mathematical modeling" he so proudly showcases in his article is questionable at best, as <a href="http://stevemcconnell.com/">Steve McConnell</a> pointed out in an email to me.
</p>
<p>
</p>
<blockquote>
Even if you're the world's top expert, your worst posting will be below average, which will negatively impact on your brand equity. If you do start a blog despite my advice, at least screen your postings: wait an hour or two, then reread your comments and avoid uploading any that are average or poor. (Even average content undermines your brand. Don't contribute to information pollution by posting material that isn't above the average of other people's writings. Plus, of course, follow guidelines for blog usability.)
</blockquote>
<p>
The number one writer out of 1000 doesn't have the same standard deviation as the general population. When Tiger Woods has a bad day, he's not worse than average. He might possibly be worse than the average player at a particular professional tournament, but all the players at the tournament are in the top fraction of 1%.  So even when Tiger Woods is at his worst, he's still in the top 1%.
</p>
<p>
</p>
<blockquote>
The fatter the report became, the more it sold. Of course, page count is only a rough indication of the amount of insight, which is what customers are really paying for. The new edition has a large number of eyetracking heatmaps, showing how users read various newsletters, and these many illustrations eat up pages ferociously. Still, there's no doubt that each report edition contains significantly more information than previous editions.
</blockquote>
<p>
I'm reminded of the old statistical fallacy that fire stations must cause fires because there are more fire stations in those areas. If his business is growing overall, it wouldn't matter whether the page count of his report on e-mail newsletter was going up or down-- he's selling more reports because his business is growing. If he provided a correlation analysis newsletter-by-newsletter that showed he got more sales immediately following publication of a longer newsletter, that would be more compelling.
</p>
<p>
Despite the shaky statistical evidence, Nielsen is still an astute observer of human behavior. I loved his previous article on blogging, which cheekily explained why <a href="http://www.codinghorror.com/blog/archives/000421.html">if you're reading this, you are a low value demographic</a>. There's a similar kernel of truth in <a href="http://www.useit.com/alertbox/articles-not-blogs.html">his latest article on blogging</a> that deserves closer examination.
</p>
<p>
</p>
<blockquote>
What matters is that the user experience is that of immersion in comprehensive treatment of a topic, as opposed to a blog-style linear sequence of short, frequent postings commenting on the hot topic of the day. It doesn't matter what software is used to host the content, the distinctions are:
<p>
</p>
<ul>
<li>in-depth vs. superficial
</li>
<li>original/primary vs. derivative/secondary
</li>
<li>driven by the author's expertise vs. being reflectively driven by other sites or outside events
</li>
</ul>
</blockquote>
<p>
Even if you find the rest of the article completely useless, <b>take this advice to heart</b>. I'm no fan of Chris Pirillo, but his <a href="http://chris.pirillo.com/2006/08/18/10-ways-to-eliminate-the-echo-chamber/">10 Ways to Eliminate the Echo Chamber</a> is a more detailed form of the same advice, and should be required reading for every blogger.
</p>
<p>
As with everything else in life, what you get out of blogging is directly proportional to what you put into it. Let us know there's a unique human being in there, not just another mindless, link propagating automaton writing about the same damn current events everyone else is writing about. The world already has enough commodity bloggers. When you post a blog entry, don't forget to add the <i>you</i>.
</p>
<p>
Yes, it takes more effort-- <b>but you're worth it</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-be-a-commodity-blogger/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Non-Maximizing Maximize Button ]]></title>
<link>https://blog.codinghorror.com/the-non-maximizing-maximize-button/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of my great frustrations with the Mac is the way the maximize button on each window <a href="http://www.xvsxp.com/interface/max_vs_zoom.php">fails to maximize the window</a>. In a comment, <a href="http://www.foolsmate.net/blog/index.php">Alex Chamberlain</a> explained why this isn't broken, it's by design:
</p>
<p>
<a href="http://www.foolsmate.net/blog/index.php"></a>
</p>
<blockquote>
This is a textbook example of how Microsoft's programmers got the original Mac GUI wrong when they copied it for Win 3.1, and never bothered to fix it: there's no zoom button on Mac OS windows because it's unnecessary. What you're mistaking for a "maximize" button is actually a "snap window to size of contents" button. Far more useful and elegant. Once again, Microsoft has no taste and no clue when it comes to the GUI. All that money and Gates has never been able to hire a decent human factors person.
</blockquote>
<p>
In other words, pressing the maximize button shouldn't maximize the window to <b>the size of your monitor</b> ...
</p>
<p>
<a href="http://www.suck.com"><img alt="image placeholder" >
</p>
<p>
... according to Apple, pressing the maximize button should maximize the window to <b>the size of the content</b>.
</p>
<p>
<a href="http://www.suck.com"><img alt="image placeholder" >
</p>
<p>
This is oddly reminiscent of the <a href="http://www.codinghorror.com/blog/archives/000885.html">recent font smoothing debate</a>, where Apple sided with the designers, and Microsoft sided with the realities of current hardware. Neither approach is <i>wrong</i>, per se; it depends what you want to emphasize and which tradeoff you think is more important.
</p>
<p>
I think the maximization problem is <b>even more ambiguous than font rendering</b>. With font rendering, the answers are based on objective mathematics: at low DPI you should favor the pixel grid and thus the user; at higher DPI you have enough pixels to favor the designer and render the font more accurately. And it's not an either-or distinction; the operating system could choose the font rendering strategy opportunistically depending on the capabilities of the display.
</p>
<p>
Unfortunately, there is no optimal window maximizing strategy. As you can see in the above screenshot, we end up with a vast expanse of unwanted whitespace when <a href="http://www.suck.com/">suck.com</a> is maximized to a 1600x1200 monitor. <a href="http://www.codinghorror.com/blog/archives/000618.html">Excessively long lines are hard to read</a>, which is why most newspapers are formatted into columns. It's also why websites with any design chops at all <i>never</i> let text extend the full width of the browser.
</p>
<p>
<a href="http://www.nytimes.com/"><img alt="image placeholder" >
</p>
<p>
I agree <i>in principle</i> that windows shouldn't be larger than their maximum usable size. But I also think <b>windows with a fixed layout shouldn't be resizable in the first place</b>. This is the subject of an entire sidebar in Neilsen's latest book, <a href="http://www.amazon.com/exec/obidos/ASIN/0321350316/codihorr-20">Prioritizing Web Usability</a>.
</p>
<p>
</p>
<blockquote>
While the Maximize button tempts many users, they are often poorly served by it. For example, a 1024-pixel-wide window will result in overly long lines for text-heavy applications such as web browsing. The preponderance of maximized windows also makes it difficult for users to understand the multiwindow nature of modern GUIs. In theory people are supposed to work with overlapping windows but in practice they can't when windows take up the entire screen. Maximized windows deceive people into thinking of the computer as a full-screen environment rather than one with multiple, simultaneously active areas.
<p>
Fortunately, maximized windows will gradually vanish as people get bigger monitors. With a 2048-pixel-wide screen, a maximized window is so grotesquely oversized that most users will resize it and work with two or more windows at a time. Tiled windows may also enjoy a renaissance with huge screens, making it easy to deal with two to four windows simultaneously.
</p>
</blockquote>
<p>
Here's where I think this argument starts to break down in a big way. <b>Dealing with multiple windows is far too difficult, even for sophisticated computer users</b>. Adding Z-order in addition to the traditional X and Y positioning is <a href="http://www.codinghorror.com/blog/archives/000548.html">one variable too many</a>. I don't think it's a coincidence that single window interfaces, such as the web browser, or Tivo, dominate the market. Microsoft <a href="http://www.codinghorror.com/blog/archives/000262.html">killed off the multiple document interface in Office</a>-- a form of per-application windowing-- years ago. Can you name one application with a multiple window interface that's even <i>popular?</i>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Manipulating windows is pure excise-- extra work that stands between the user and completing their task. The more windows you have to deal with, the less work you get done, and the more time you spend sizing them, moving them, bringing them to the top, and dragging them around so they aren't overlapping. That's one reason I'm such a fan of <a href="http://www.codinghorror.com/blog/archives/000012.html">double</a> and <a href="http://www.codinghorror.com/blog/archives/000740.html">triple monitor</a> setups; more desktop space equals fewer overlapping windows, and less time spent futzing around with window layout.
</p>
<p>
That's my problem with Apple's non-maximizing maximize button. Allowing users to maximize any window to a monitor has its problems, to be sure. But <b>Apple's method of <i>forcing</i> users to deal with more windows by preventing maximization is not good user interface design</b>. It is fundamentally and deeply flawed. Users don't want to deal with the mental overhead of juggling multiple windows, and I can't blame them: neither do I. Designers should be coming up with alternative user interfaces that <i>minimize</i> windowing, instead of forcing enforcing arbitrary window size limits on the user for their own good.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-non-maximizing-maximize-button/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Principle of Least Power ]]></title>
<link>https://blog.codinghorror.com/the-principle-of-least-power/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Tim Berners-Lee on <a href="http://www.w3.org/DesignIssues/Principles.html">the Principle of Least Power</a>:
</p>
<p>
</p>
<blockquote>
Computer Science spent the last forty years making languages which were as powerful as possible. Nowadays we have to appreciate the reasons for <b>picking not the most powerful solution but the <i>least</i> powerful</b>. The less powerful the language, the more you can do with the data stored in that language. If you write it in a simple declarative from, anyone can write a program to analyze it. If, for example, a web page with weather data has RDF describing that data, a user can retrieve it as a table, perhaps average it, plot it, deduce things from it in combination with other information. At the other end of the scale is the weather information portrayed by the cunning Java applet. While this might allow a very cool user interface, it cannot be analyzed at all. The search engine finding the page will have no idea of what the data is or what it is about. The only way to find out what a Java applet means is to set it running in front of a person.
</blockquote>
<p>
This was later codified in a more formal W3C document, <a href="http://www.w3.org/2001/tag/doc/leastPower.html">The Rule of Least Power</a>. I propose a corollary to this rule, which in the spirit of <a href="http://haacked.com/archive/2007/07/17/the-eponymous-laws-of-software-development.aspx">recent</a> <a href="http://globalnerdy.com/2007/07/18/laws-of-software-development/">memes</a>, I'll call <b>Atwood's Law</b>: any application that <i>can</i> be written in JavaScript, <i>will</i> eventually be written in JavaScript.
</p>
<p>
If you liked that article, I recommend the rest of Berners-Lee's <a href="http://www.w3.org/DesignIssues/">architectural and philosophical points</a> page. Although the content is quite old in internet time-- only two of the articles were written in the last year-- it still contains some timeless nuggets of advice and insight from the guy who <a href="http://en.wikipedia.org/wiki/Tim_Berners-Lee">invented the world wide web</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-principle-of-least-power/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's Wrong With Setup.exe? ]]></title>
<link>https://blog.codinghorror.com/whats-wrong-with-setupexe/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Ned Batchelder shares a <a href="http://www.nedbatchelder.com/blog/200706.html#e20070623T082532">complaint about the Mac application installation process</a>:
</p>
<p>
</p>
<blockquote>
Here's what I did to install the application Foo [on the Mac]:
<p>
</p>
<ol>
<li>Downloaded FooDownload.dmg.zip to the desktop.
</li>
<li>StuffIt Expander launched automatically, and gave me a FooDownload.dmg Folder on the desktop.
</li>
<li>At this point, nothing is happening, so I opened the folder, inside was a FooDownload.dmg icon.
</li>
<li>I opened that, a license agreement appears.
</li>
<li>I agreed to that, and a window appears with an application icon, and instructions to "Drag this icon to your Applications folder".
</li>
<li>I have to find the Applications folder, and drop the icon into it.
</li>
</ol>
<p>
At this point, the application is installed. To clean up, I had to:
</p>
<p>
</p>
<ol>
<li>Close the Applications folder.
</li>
<li>Close the window with the dragging instructions.
</li>
<li>Close the FooDownload.dmg Folder window.
</li>
<li>Get rid of the three (!) things on the desktop: The dmg, the FooDownload.dmg Folder, and the FooDownload.dmg.zip file.
</li>
</ol>
<p>
To me, that seems like a lot of manual steps. In the Windows world, you'll sometimes find shareware where the author gives two options: an installer, or a zip file where you can do everything yourself. The Mac installation process is like the Windows do-it-all-yourself case.
</p>
<p>
Again, I'm not trying to slam the Mac. I genuinely do not understand why on a platform that makes things really simple, where the mantra is that stuff "just works", ordinary users are expected to do all these manual steps.
</p>
</blockquote>
<p>
I've often wondered the same thing-- <b>why does the Mac require the user to jump through a bunch of manual hoops to install an application?</b> Why not use a traditional installer (a.k.a. setup.exe) that automates this manual work for you?
</p>
<p>
To be fair, Windows applications aren't always delivered with installers, either. One of the apps I use is Kenny Kerr's excellent <a href="http://www.windowclippings.com/">Window Clippings</a>. It's delivered as a single executable in a compressed ZIP file. It's a pleasingly simple arrangement, but it's also more work me, the user. Consider how I "install" Windows Clippings:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I have to:
</p>
<p>
</p>
<ol>
<li>Extract the executable from the ZIP file.
</li>
<li>Create a WindowsClippings folder in the C:Program Files folder
</li>
<li>Move the WindowsClippings.exe file to the new folder I just created
</li>
<li>Create a start menu shortcut for WindowsClippings
</li>
</ol>
<p>
That's a lot of tedious, error-prone steps I have to perform before I can run the application. And no two users will have Windows Clippings installed the same way. Some may opt to run it from their desktop, or a temporary folder, or some other inappropriate location. Is this really what we want to subject our users to?
</p>
<p>
Even as a power user, I find this level of control not only unnecessary but onerous. That's why it's so strange to me that the "normal" Mac install parallels the sophisticated "power user" Windows install. A typical user doesn't want this level of control, and they certainly <a href="http://www.codinghorror.com/blog/archives/000461.html">don't want to learn about disks and folders</a>. They just want the application to work. <b>Wouldn't a big giant button that says "Install Me" be a better experience for the user?</b>
</p>
<p>
Traditional Windows installers may be easier than a Mac-style manual install, but they aren't exactly model citizens either. Most installers ask users dozens of questions across multiple wizard pages, along with the <a href="http://www.codinghorror.com/blog/archives/000892.html">inevitable end user license agreement</a> you get strongarmed into accepting.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The WinAmp installer is fairly typical. It's five pages long, and asks me to decide the following:
</p>
<p>
</p>
<ul>
<li>Do you accept our <a href="http://en.wikipedia.org/wiki/EULA">EULA</a>?
</li>
<li>What program options do I want installed? Visualization? Extra Audio Output? User Interface Extensions?
</li>
<li>What icons do I want installed? Start menu? Desktop? Quicklaunch? System Tray?
</li>
<li>Do I want to associate WinAmp with audio files? With CDs? With playlists?
</li>
<li>Where do I want WinAmp installed; at what path?
</li>
<li>Do I want shared settings for all users or individual settings?
</li>
<li>What are my internet connection settings? Do I have a proxy? Do I want to download needed codecs?
</li>
</ul>
<p>
That's <a href="http://www.codinghorror.com/blog/archives/000377.html">a whole lot of thinking</a> necessary to install a tiny little music player. And that's the <i>minimal</i> install-- the lite version that the WinAmp site does its best to <a href="http://www.winamp.com/player/features">hide</a> from me!
</p>
<p>
Perhaps a better approach is the "No-Questions-Asked" installation featured in <a href="http://www.just-great-software.com/">JGSoft applications</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If only more applications-- Mac or Windows-- made it this easy on the user. That's about as close as we can get today to the big giant "Install Me" button I think most users are looking for.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-wrong-with-setupexe/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Futurist Programming.. in 1994 ]]></title>
<link>https://blog.codinghorror.com/futurist-programming-in-1994/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Paul Heberli and Bruce Karsh proposed something they call <a href="http://www.graficaobscura.com/future/">futurist programming</a> in 1994:
</p>
<p>
</p>
<blockquote>
We believe there is a great opportunity for <a href="http://www.graficaobscura.com/future/futman.html">Futurist principles</a> to be applied to the science of computer programming. We react against the heavy <a href="http://www.codinghorror.com/blog/archives/000699.html">religious atmosphere</a> that surrounds every aspect of computer programming. We believe it is time to be free from the constraints of the past, and celebrate a renaissance in the art of computer programming.
<p>
We find that many of today's computer systems are hopelessly wasteful and inefficient. Computer hardware has realized performance increases of a factor of more than 200 in the last 20 years, while in program design very little progress has been made at all since the invention of the subroutine. We would like to see the science of programming advance as quickly as other fields of technology.
</p>
<p>
We believe that undergraduate education spends too much time conveying dogma, instead of teaching a sound theory of program design that helps programmers create good programs. Universities should provide students with less religion, and much more practical experience in making and analyzing small, fast, useful and efficient programs.
</p>
</blockquote>
<p>
<a href="http://en.wikipedia.org/wiki/Futurism_(art)">Futurism</a> was a primarily Italian art movement in the early twentieth century; the most succinct summary I've found is on <a href="http://www.unknown.nu/futurism/">this Futurism resource page</a>:
</p>
<p>
</p>
<blockquote>
Futurism was an international art movement founded in Italy in 1909. It was (and is) a refreshing contrast to the weepy sentimentalism of Romanticism.
<p>
<a href="http://www.mishabittleston.com/artists/giacomo_balla/"><img alt="image placeholder" >
</p>
<p>
The Futurists loved speed, noise, machines, pollution, and cities; they embraced the exciting new world that was then upon them rather than hypocritically enjoying the modern world's comforts while loudly denouncing the forces that made them possible. Fearing and attacking technology has become almost second nature to many people today; the Futurist manifestos show us an alternative philosophy.
</p>
</blockquote>
<p>
The 1994 <a href="http://www.graficaobscura.com/future/futman.html">Manifesto of the Futurist Programmers</a> is wholly based on the 1910 <a href="http://www.unknown.nu/futurism/painters.html">Manifesto of the Futurist Painters</a>. But perhaps the best explanation of what futurist programming <i>actually means</i> is tucked away in the <a href="http://www.graficaobscura.com/future/futnotes.html">Futurist Programming Notes</a>:
</p>
<p>
</p>
<blockquote>
<b>We REJECT</b>
<p>
</p>
<ul>
<li>COPIES of work that has been done before.
</li>
<li>USER CONFIGURABLE software.
</li>
<li>PAPER documentation.
</li>
<li>Any program that WASTES users' precious MEMORY.
</li>
<li>Any program that WASTES users' precious TIME.
</li>
<li>System administration and ADMINISTRATORS.
</li>
<li>Anything that is done for the convenience of the programmer at the expense of the user.
</li>
<li>Extensibility, Modularity, Structured Programming, Reusable code, Top-Down Design, Standards of all kinds, and Object-Oriented "METHODOLOGIES".
</li>
<li>All additional forms of USELESS and IRRESPONSIBLE WASTE.
</li>
</ul>
</blockquote>
<p>
It's an admirable set of goals. Of particular interest is the futurist reverence for programs that dynamically generate code; this presages the current renaissance of <a href="http://en.wikipedia.org/wiki/Dynamic_language">dynamic programming languages</a>, ten years later. Apparently the future is now.
</p>
<p>
The core futurist philosophy that <b>religion and dogma of all kinds should be examined critically</b> is an important one. I've written many times about certain accepted "wisdoms" in software development that are counter-productive if not downright dangerous. I think you should be constantly questioning the status quo, and solidly skeptical of <a href="http://www.codinghorror.com/blog/archives/000557.html">so-called best practices</a>. But this, too, can be taken too far. I intentionally omitted the last sentence of the futurism summary on <a href="http://www.unknown.nu/futurism/">the Futurism resource page</a>:
</p>
<p>
</p>
<blockquote>
Too bad they were all Fascists.
</blockquote>
<p>
You have to be careful that rejecting dogma doesn't itself become a kind of dogma. Sometimes, <a href="http://www.codinghorror.com/blog/archives/000578.html">a bulleted list of best practices can be helpful</a>, too.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/futurist-programming-in-1994/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Will My Software Project Fail? ]]></title>
<link>https://blog.codinghorror.com/will-my-software-project-fail/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.codinghorror.com/blog/archives/000588.html">Most software projects fail</a>. But that doesn't mean yours has to. The first question you should ask is a deceptively simple one: <b>how big is it?</b> Steve McConnell explains in <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art</a>:
</p>
<blockquote>
[For a software project], size is easily the most significant determinant of effort, cost, and schedule. The kind of software you're developing comes in second, and personnel factors are a close third. The programming language and environment you use are not first-tier influences on project outcome, but they are a first-tier influence on the estimate.
</blockquote>
<p>
All other things being equal, large projects tend to fail. That's probably not news to anyone familiar with <a href="http://en.wikipedia.org/wiki/Metcalfe's_law">Metcalfe's Law</a> and <a href="http://www.codinghorror.com/blog/archives/000637.html">Diseconomies of Scale</a>.
</p>
<p>
So if the three most important factors determining the outcome of a software project are...
</p>
<p>
</p>
<ol>
<li>Project size
</li>
<li>Kind of software being developed
</li>
<li>Personnel factors
</li>
</ol>
<p>
... in that order, what else is left? If you can get those three factors under control-- if you're developing a small, simple CRUD database website with a dream team of tightly gelled superstar developers, are you done? Of course there's never <i>any</i> guarantee of project success, but can you at least say you've performed adequate risk management?
</p>
<p>
I'm not so sure. According to Bill de hra, you also have to consider <a href="http://www.dehora.net/journal/2007/01/3_pillars.html">the three pillars</a>:
</p>
<p>
</p>
<blockquote>
The conclusion I draw from this and my own experience having migrating my fair share of source trees is that <b>the version control system is a first order effect on software, along with two others - the build system and the bugtracker.</b>
<p>
<img alt="image placeholder" >
</p>
<p>
Those choices impact absolutely everything else. Things like IDEs, by comparison, don't matter at all. Even choice of methodology might matter less. Although I'm betting there are plenty of software and management teams out there that see version control, build systems and bugtrackers as being incidental to the work, not mission critical tools.
</p>
</blockquote>
<p>
Bill's analysis came as a pleasant surprise to me, because it's exactly the same conclusion I reached while working with <a href="http://msdn.microsoft.com/teamsystem/">Microsoft's Team System</a>. Once you get the three pillars in place...
</p>
<p>
</p>
<ol>
<li>Version control
</li>
<li>Work item tracking
</li>
<li>Build system
</li>
</ol>
<p>
... it's a major improvement in software engineering quality for any software development project. Of course, you don't have to use Team System to get there, but a <i>huge</i> part of the value proposition for Team System is that it's "software engineering in a box". It provides tight integration between these three pre-installed pieces, with no complex configuration required.
</p>
<p>
However you get there, it's just plain good software engineering to have these essentials-- the three pillars-- in place before proceeding too far on a software project.
</p>
<p>
So if we set up our dream team of tightly gelled superstar developers working on our small, simple CRUD database website with an outstanding best-of-breed integrated set of source control, work item tracking, and build tools-- are we done? Have we mitigated all the major project risks and set ourselves up to effortlessly, weightlessly <a href="http://blogs.msdn.com/brada/archive/2003/10/02/50420.aspx">fall into the pit of success</a>?
</p>
<p>
Sadly, no.
</p>
<p>
Bill notes that <a href="http://www.dehora.net/journal/2007/07/earned_value.html">choosing a framework poorly suited to your problem domain</a> can have a crippling effect on your productivity, too.
</p>
<p>
</p>
<blockquote>
The relative verbosity of programming languages isn't the interesting thing; nor is typing doctrine. What's interesting is the culture of frameworks and what different communities deem valuable. My sense of it is that on Java, too many web frameworks - think JSF, or Struts 1.x - consider the Web something you work around using software patterns. The goal is get off the web, and back into middleware. Whereas a framework like Django or Rails is purpose-built for the Web; integrating with the internal enterprise is a non-goal.
<p>
ETag support is just one example; there are so many things frameworks like Rails/Django do ranging from architectural patterns around state management, to URL design, to testing, to template dispatching, to result pagination, right down to table coloring that the cumulative effect on productivity is startling. <b>I suspect designing for the Web instead of around it is at least as important as language choice.</b>
</p>
</blockquote>
<p>
So maybe the real lesson here is that software project success isn't about doing any one particular thing right; it's the much more daunting task of <a href="http://www.codinghorror.com/blog/archives/000889.html">not doing anything wrong</a>. It certainly gives you a new appreciation for those rare successful software projects that somehow managed to snatch victory from the jaws of defeat.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/will-my-software-project-fail/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Building a PC, Part IV: Now It's Your Turn ]]></title>
<link>https://blog.codinghorror.com/building-a-pc-part-iv-now-its-your-turn/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I previously documented the <a href="http://www.hanselman.com/blog/TheCodingHorrorUltimateDeveloperRigThrowdownPart1.aspx">"Ultimate Developer Rig"</a> I'm building for Scott Hanselman:</p>
<p> </p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/archives/000905.html">Building a PC, Part I</a> </li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000907.html">Building a PC, Part II</a> </li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000908.html">Building a PC, Part III</a> </li>
</ul>
<p>I added a little bit of <a href="http://www.codinghorror.com/blog/archives/000665.html">PC quieting magic</a> as a finishing touch. Here's a picture of the final interior, with two types of damping foam -- generic <a href="http://search.ebay.com/search/search.dll?satitle=eggcrate+foam">eggcrate foam</a> and thin <a href="http://www.google.com/products?q=pax.mate">PAX.MATE</a> style foam. Which one I use depends on how much room I have to work with in each area of the case.</p>
<p><img alt="image placeholder" >
<p>The goal is to build a sound dampening chamber around the motherboard, CPU, hard drives (<em>particularly</em> the hard drives), and video cards. Instead of the typical hard, reflective metal inside a case, the sound now bounces off rough, absorbent foam surfaces instead. You can't see it in this shot, but the case cover has a layer of PAX.MATE foam applied as well to complete the "chamber". If you've ever been in a <a href="http://www.acousticalsolutions.com/applications/home_recording_studio.asp">recording studio</a> with foam damping material on the walls, you know how effective it can be at absorbing and diffusing sound. As I discussed in my earlier article on <a href="http://www.codinghorror.com/blog/archives/000665.html">building a quiet PC</a>, the foam damping is a final, finishing step. It won't magically convert a noisy PC into a quiet one, but it <em>can</em> make an already quiet PC that much quieter. The effect is subtle but definitely audible.</p>
<p>At any rate, the rig is now burned in, complete, and ready to ship to Scott. I was surprised to find that the 64-bit version of Vista produced better Windows Experience scores on the exact same hardware: <a href="http://www.hanselman.com/blog/TheCodingHorrorUltimateDeveloperRigThrowdownPart2.aspx">Scott's system</a> now <strong>scores 5.9 across the board, except for memory, which scores 5.8.</strong> Go figure.</p>
<p>I hope you found the series useful and fun. I know I did. We also recorded a <a href="http://www.hanselminutes.com/">Hanselminutes</a> episode where we discussed the philosophy behind the build, and answered a bunch of listener questions; <a href="http://www.hanselman.com/blog/HanselminutesPodcast74JeffAtwoodOverclocksTheUltimatePC.aspx">listen to the show</a> for background.</p>
<p>But in the meantime, if this piqued your interest, <strong>now it's your turn to build a PC</strong>. There was a lot of interest in doing a PC build jamboree at the office, and I invite everyone to participate... at least virtually. I can offer <strong>the following refined build menu</strong> based on my experience with Scott's build-- and <a href="http://www.engadget.com/2007/07/23/intel-cuts-prices-on-quad-core-chips/">recent Intel CPU price cuts</a>.</p>
<p> </p>
<table cellspacing="4" cellpadding="4" width="640">
<tbody>
<tr>
<td valign="top"></td>
<td valign="top"><strong> Basic</strong></td>
<td valign="top"></td>
<td valign="top"><strong> Premium</strong></td>
<td valign="top"></td>
<td valign="top"><strong> Deluxe</strong></td>
<td valign="top"></td>
</tr>
<tr>
<td valign="top">Case</td>
<td valign="top">
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16811129012" target="_top"> Antec NSK 4400</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$80</td>
<td valign="top">
<a href="http://www.kqzyfj.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16811129024%26ATT%3D11-129-024%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Cases%2B%28Computer%2BCases%2B-%2BATX%2BForm%29-_-Antec-_-11129024&amp;cjsku=N82E16811129024" target="_top"> Antec Sonata III</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$150</td>
<td valign="top">
<a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16811129025%26ATT%3D11-129-025%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Cases%2B%28Computer%2BCases%2B-%2BATX%2BForm%29-_-Antec-_-11129025&amp;cjsku=N82E16811129025" target="_top">Antec P182</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$170</td>
</tr>
<tr>
<td valign="top">PSU</td>
<td valign="top">(Included 380w)</td>
<td valign="top"></td>
<td valign="top">(Included 500w)</td>
<td valign="top"></td>
<td valign="top">
<a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16817139001%26ATT%3D17-139-001%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Power%2BSupplies-_-Corsair%2BMemory%2B%2BInc.-_-17139001&amp;cjsku=N82E16817139001" target="_top"> Corsair 520HX</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$130</td>
</tr>
<tr>
<td valign="top">Mobo</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16813188019%26ATT%3D13-188-019%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Motherboards%2B-%2BIntel-_-EVGA-_-13188019&amp;cjsku=N82E16813188019" target="_top">EVGA 680i</a><img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$155</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16813188019%26ATT%3D13-188-019%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Motherboards%2B-%2BIntel-_-EVGA-_-13188019&amp;cjsku=N82E16813188019" target="_top">EVGA 680i</a><img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$155</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16813188019%26ATT%3D13-188-019%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Motherboards%2B-%2BIntel-_-EVGA-_-13188019&amp;cjsku=N82E16813188019" target="_top">EVGA 680i</a><img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$155</td>
</tr>
<tr>
<td valign="top">Memory</td>
<td valign="top">
<a href="http://www.kqzyfj.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16820146677%26ATT%3D20-146-677%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Memory%2B%28Desktop%2BMemory%29-_-Mushkin-_-20146677&amp;cjsku=N82E16820146677" target="_top">Mushkin 2GB DDR2-1066</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$160</td>
<td valign="top">
<a href="http://www.kqzyfj.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16820146677%26ATT%3D20-146-677%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Memory%2B%28Desktop%2BMemory%29-_-Mushkin-_-20146677&amp;cjsku=N82E16820146677" target="_top">Mushkin 2GB DDR2-1066</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$160</td>
<td valign="top">
<a href="http://www.kqzyfj.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16820146677%26ATT%3D20-146-677%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Memory%2B%28Desktop%2BMemory%29-_-Mushkin-_-20146677&amp;cjsku=N82E16820146677" target="_top">Mushkin 2GB DDR2-1066</a>    <strong>x 2</strong>
</td>
<td style="text-align: right;" valign="top">$320</td>
</tr>
<tr>
<td valign="top">CPU</td>
<td valign="top">
<a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16819115005%26ATT%3D19-115-005%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Processors-_-intel-_-19115005&amp;cjsku=N82E16819115005" target="_top"> Intel Core 2 Duo E6300 1.86GHz</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$164</td>
<td valign="top">
<a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16819115003%26ATT%3D19-115-003%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Processors-_-intel-_-19115003&amp;cjsku=N82E16819115003" target="_top"> Intel Core 2 Duo E6600 2.4GHz</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$223</td>
<td valign="top"><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16819115017">Intel Core 2 Quad Q6600 2.4 GHz</a></td>
<td style="text-align: right;" valign="top">$375</td>
</tr>
<tr>
<td valign="top">CPU cooler</td>
<td valign="top"><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16835185044">Scythe SCKTN-2000 "katana"</a></td>
<td style="text-align: right;" valign="top">$30</td>
<td valign="top"><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16835185037">Scythe SCMN-1100 "mine"</a></td>
<td style="text-align: right;" valign="top">$33</td>
<td valign="top"><a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16835185038">Scythe SCNJ-1100P "ninja"</a></td>
<td style="text-align: right;" valign="top">$40</td>
</tr>
<tr>
<td valign="top">Video</td>
<td valign="top">
<a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16814127293%26ATT%3D14-127-293%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Video%2BCards-_-MSI-_-14127293&amp;cjsku=N82E16814127293" target="_top"> MSI 8600GT 256 MB Silent</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$105</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16814130071%26ATT%3D14-130-071%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Video%2BCards-_-EVGA-_-14130071&amp;cjsku=N82E16814130071" target="_top"> EVGA 8800GTS 640 MB</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$350</td>
<td valign="top">
<a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16814130072%26ATT%3D14-130-072%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Video%2BCards-_-EVGA-_-14130072&amp;cjsku=N82E16814130072" target="_top"> EVGA 8800GTX 768 MB</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$487</td>
</tr>
<tr>
<td valign="top">HDD</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16822145137%26ATT%3D22-145-137%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives-_-Hitachi%2BGlobal%2BStorage%2BTechnologies-_-22145137&amp;cjsku=N82E16822145137" target="_top"> Hitachi Deskstar 500GB</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$120</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16822145137%26ATT%3D22-145-137%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives-_-Hitachi%2BGlobal%2BStorage%2BTechnologies-_-22145137&amp;cjsku=N82E16822145137" target="_top"> Hitachi Deskstar 500GB</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$240</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16822136012%26ATT%3D22-136-012%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives-_-Western%2BDigital-_-22136012&amp;cjsku=N82E16822136012" target="_top"> Raptor 150GB</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$165</td>
</tr>
<tr>
<td valign="top"></td>
<td valign="top"></td>
<td valign="top"></td>
<td valign="top"></td>
<td valign="top"></td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16822145137%26ATT%3D22-145-137%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives-_-Hitachi%2BGlobal%2BStorage%2BTechnologies-_-22145137&amp;cjsku=N82E16822145137" target="_top"> Hitachi Deskstar 500GB</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$120</td>
</tr>
<tr>
<td valign="top">DVD</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16827152079%26ATT%3D27-152-079%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-CD%2FDVD%2BBurners%2B%28RW%2BDrives%29-_-Sony%2BNEC%2BOptiarc%2BAmerica%2BInc-_-27152079&amp;cjsku=N82E16827152079" target="_top"> Sony 18X SATA DVDR</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$34</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16827152079%26ATT%3D27-152-079%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-CD%2FDVD%2BBurners%2B%28RW%2BDrives%29-_-Sony%2BNEC%2BOptiarc%2BAmerica%2BInc-_-27152079&amp;cjsku=N82E16827152079" target="_top"> Sony 18X SATA DVDR</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$34</td>
<td valign="top">
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.asp%3FItem%3DN82E16827152079%26ATT%3D27-152-079%26CMP%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-CD%2FDVD%2BBurners%2B%28RW%2BDrives%29-_-Sony%2BNEC%2BOptiarc%2BAmerica%2BInc-_-27152079&amp;cjsku=N82E16827152079" target="_top"> Sony 18X SATA DVDR</a> <img alt="image placeholder" >
</td>
<td style="text-align: right;" valign="top">$34</td>
</tr>
<tr>
<td valign="top"></td>
<td valign="top"></td>
<td valign="top"><span style="color: red;">$848</span></td>
<td valign="top"></td>
<td style="text-align: right;" valign="top"><span style="color: red;">$1345</span></td>
<td valign="top"></td>
<td valign="top"><span style="color: red;">$1996</span></td>
</tr>
</tbody>
</table>
<p>Of course, prices are only valid as of the time I write this post. And feel free to substitute any items between the configurations as you deem necessary. It's your PC; build it the way you want.</p>
<p>A previous comment from <a href="http://blasphemousbits.wordpress.com/">Bob McCormick</a> summarized my build philosophy remarkably well:</p>
<blockquote>Building a PC at least once gives you a deeper understanding of your hardware. It isn't going to fill a specific checklist item in your resume, but the desire to try it at least once is part of the passion that a true craftsman should have for his tools. I think it's similar to how you'll frequently see the celebrity chefs on PBS go visit a winery, an organic farm, a bakery, and so on. They aren't going to learn something there that will make or break their ability to cook a specific dish. But as master craftsman they're passionate about their tools and ingredients. They want to know everything they can about them.</blockquote>
<p>Building (and overclocking) PCs isn't for everyone. But I hope <a href="http://www.google.com/search?q=site%3Acodinghorror.com+intitle%3A%22building+a+pc%22">my series</a> illustrated that it isn't particularly difficult -- and it sure can be rewarding if you have the time and inclination.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-pc-part-iv-now-its-your-turn/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Lessons from Garry's Mod ]]></title>
<link>https://blog.codinghorror.com/lessons-from-garrys-mod/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://gmod.garry.tv/">Garry's Mod</a> is a fascinating study in guerilla programming. It's an <a href="http://en.wikipedia.org/wiki/Garry's_Mod">incredibly successful mod for the game Half-Life 2</a> that essentially <b>converts it into a giant sandbox powered by <a href="http://en.wikipedia.org/wiki/Lua_programming_language">Lua</a></b>.
</p>
<p>
</p>
<blockquote>
There are a large number of Lua scripted 3rd party modifications for Garry's mod. In a server running the Roleplay modification, you have money and tools which enable you to sell items on the map, or to interact with other players. Newer game modes have inventories and highly advanced capabilities including Item Combining and Stock Markets.
<p>
Another example is "Wood Wars", where teams make vehicles or buildings out of wood, and then attack the other team's creations with weapons made up of anything from gas canisters with thrusters on, to shells launched from makeshift cannons.
</p>
<p>
<a href="http://gmod.garry.tv/about/"><img alt="image placeholder" >
</p>
<p>
It has also become a tool for users to create <a href="http://www.youtube.com/watch?v=1u6jy_Qfw9I">music videos</a>, <a href="http://www.hlcomic.com/">comics</a> and other forms of <a href="http://www.youtube.com/watch?v=PROmRl6snG0">Machinima</a>.
</p>
</blockquote>
<p>
If Garry's Mod sounds a lot like a full-blown development environment inside a 3D world governed by physics, that's because it is. But it started out as something much simpler. In this <a href="http://www.shacknews.com/featuredarticle.x?id=471">recent interview</a>, Garry describes the humble beginnings of his eponymous mod:
</p>
<p>
</p>
<blockquote>
<b>Garry Newman</b>: [GMod] was a total experiment. I was really out of my depth in the Source engine at that point. I had no idea how anything worked, but managed to throw version one together by thinking back into Half-Life 2--to work out where I'd seen the feature before. For example, the rope gun. I didn't know how to make rope so I thought back and realized that the Barnacle's tongue was rope. So I just pretty much copied that code into a simple weapon and it worked. Well, kind of worked. This was one of the good things about GMod. I could see the right way to do stuff because a lot of the time Valve had already done it somewhere else in the code. So their code would teach me. I'm not the kind of person that can learn from books, I really need working examples.
<p>
<b>Shack:</b> What would you suggest to mod teams to help them avoid getting held up on the details? Start with a simple idea and build on it?
</p>
<p>
<b>Garry Newman</b>: I would recommend the iterative method to anyone. The main argument against this is that they don't want to release a shit version of their idea and turn everyone off. Fair enough, but it's going to be so much worse if you work your balls off on it for 2 years then release, and your idea is still rubbish. Iterating would have let you know that this idea isn't working out, so you could adjust it. In every update you're picking up more people playing your mod. You build a community.
</p>
</blockquote>
<p>
Garry cites classic <a href="http://en.wikipedia.org/wiki/Sandbox_(video_games)">sandbox games</a> as his inspiration, such as SimCity, The Sims, and Rollercoaster Tycoon. But I'd say the current version of GMod goes far beyond those games and delves deep into software development territory -- he's created <b>a sandbox for creating new sandboxes</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/lessons-from-garrys-mod/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Whatever Happened to Civility on The Internet? ]]></title>
<link>https://blog.codinghorror.com/whatever-happened-to-civility-on-the-internet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In response to Wil Shipley's  <a href="http://wilshipley.com/blog/2007/07/iphones-ajax-sdk-no-thank-you.html">recent post about the lack of an iPhone SDK</a>, a reader left <a href="https://www.blogger.com/comment.g?blogID=11049281&amp;postID=5053147239501487485">this comment</a>:</p>
<blockquote>I often enjoy reading these entries, but you always come across as a little bit of an a**hole. Full of yourself, overly critical and a bit mean. Dismissing and dissing, out of pure ignorance and spite, the work of the people who made Javascript – people who have done more for the world, and written a better language, than you have or likely ever will – is truly a huge a**hole move.</blockquote>
<p>Although I'm <a href="http://www.codinghorror.com/blog/archives/000538.html">a staunch proponent of comments</a> for most blogs, it's comments like this – what Anand Iyer calls <a href="http://blogs.msdn.com/aniyer/archive/2007/07/09/nerd-rage-uncool.aspx">nerd rage</a> – that cause me to question my stance. I don't think it's necessarily wise to dignify these kind of comments with a response, but a few comments later, Wil Shipley responded with <em>exactly</em> what I was thinking:</p>
<blockquote>Miss Manners once said the rudest thing to do is point out someone else's rudeness in public. By extension, what do you suppose the biggest a**hole move is?</blockquote>
<p>Bonus points for invoking Miss Manners; her <a href="http://www.amazon.com/exec/obidos/ASIN/0393058743/codihorr-20">Guide to Excruciatingly Correct Behavior</a> has been a staple of my bookshelf for <em>years</em>. Think what you will about stodgy old <a href="http://en.wikipedia.org/wiki/Judith_Martin">Judith Martin</a>, but she has a razor wit and an enduring, keen eye for human behavior. I learned a lot about life by reading her guide in my early twenties; it's a rich comedy of errors in book form that I earnestly recommend to everyone.</p>
<p><a href="http://www.amazon.com/exec/obidos/ASIN/0393058743/codihorr-20"><img alt="image placeholder" >
<p>I understand <a href="http://www.penny-arcade.com/comic/2004/03/19">the G.I.F.T.</a> is an unfortunate side-effect of anonymity and the faceless interaction mode of the internet. But I think we can do better. As Miss Manners said:</p>
<blockquote>You can deny all you want that there is etiquette, and a lot of people do in everyday life. <strong>But if you behave in a way that offends the people you're trying to deal with, they will stop dealing with you</strong>. There are plenty of people who say, 'We don't care about etiquette, but we can't stand the way so-and-so behaves, and we don't want him around!' Etiquette doesn't have the great sanctions that the law has. But the main sanction we do have is in not dealing with these people and isolating them because their behavior is unbearable.</blockquote>
<p>I don't object to criticism. Criticism is what comments are for. What I object to is criticism that resorts to least-common-denominator attacks. The use of angry invective negates any criticism you were trying to make. Insulting someone might make you feel temporarily vindicated, or give you a brief, cathartic moment of release, but <strong>you aren't convincing anyone of anything</strong>. People will read your angry words and see them – and you – for what you are. It's a completely self-defeating exercise. The minute you call someone an a**hole, they're no longer listening to you.</p>
<p>For an example of <em>effective</em> criticism of the strongest kind, I can think of no better piece than Martin Luther King's <a href="http://www.africa.upenn.edu/Articles_Gen/Letter_Birmingham.html">Letter From Birmingham Jail</a>. I re-read it every year, and each time I'm floored by the passion behind this incredible persuasive essay – and the deep anger and frustration it presents in such rational terms.</p>
<blockquote>While confined here in the Birmingham city jail, I came across your recent statement calling my present activities "unwise and untimely." Seldom do I pause to answer criticism of my work and ideas. If I sought to answer all the criticisms that cross my desk, my secretaries would have little time for anything other than such correspondence in the course of the day, and I would have no time for constructive work. But since I feel that you are men of genuine good will and that your criticisms are sincerely set forth, I want to try to answer your statements in what I hope will be patient and reasonable terms.</blockquote>
<p>This legendary essay demonstrates <strong>the fine art of disagreement: the ability to respect the people you disagree with, and to earn their respect in turn</strong>. The <em>only</em> way to do that is to be civil, reasonable, and rational.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whatever-happened-to-civility-on-the-internet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Google's Number One UI Mistake ]]></title>
<link>https://blog.codinghorror.com/googles-number-one-ui-mistake/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Google's <a href="http://www.codinghorror.com/blog/archives/000529.html">user interface minimalism</a> is admirable. But there's one part of their homepage UI, downloaded millions of times per day, that leaves me scratching my head:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Does anyone actually <i>use</i> the "I'm Feeling Lucky" button?</b> I've been an avid Google user since 2000; I use it somewhere between dozens and hundreds of times per day. But I can count on one hand the number of times I've clicked on the <a href="http://en.wikipedia.org/wiki/I'm_feeling_lucky">"I'm Feeling Lucky" button</a>.
</p>
<p>
I understand this was a clever little joke in the early days of Google-- <i>hey, look at us, we're a search engine that actually works!</i> -- but is it really necessary to carry this clever little joke forward ten years and display it on the monitors of millions of web users every day? We get it already. <b>Google is awesomely effective.</b> That's why I use it so much. That's why Google is <a href="http://www.skrenta.com/2007/01/winnertakeall_google_and_the_t.html">the start page for the internet</a>, loading the Google homepage is virtually <a href="http://colormeimpressed.blogspot.com/2005/05/im-feeling-phthisicky.html">synonymous with internet access</a>, and the verb "to Google" is at risk of becoming a <a href="http://en.wikipedia.org/wiki/Genericized_trademark">genericized trademark</a>. Google has won so decisively, so utterly, and so completely that the power they now wield over the internet actually scares me a little. Okay, it scares me a lot.
</p>
<p>
So can we get rid of the superfluous button now?
</p>
<p>
You might say <a href="http://www.codinghorror.com/blog/archives/000548.html">it's only one more button</a>, so where's the harm. I say <b>giving a feature that's used less than one percent of the time parity with the "Search" button is a needless distraction for users.</b> Furthermore, the "I'm Feeling Lucky" button is only available on the homepage-- it's not a part of any browser toolbar searches, and Google's intermediate search page results don't offer it, either. Why not standardize and stick with the simple, single "Search" button that everyone understands and expects, on every page? Why muddy the waters with a button that's so rarely useful, and on the homepage of all places? The thought necessary to mentally omit this needless button from the page may be miniscule-- but multiply that by the millions upon millions of users who are affected, and all of a sudden it starts to add up to real time. <a href="http://www.codinghorror.com/blog/archives/000377.html">Don't make us think!</a>
</p>
<p>
If you're an advanced computer user, you may be wondering why we bother with Search buttons at all when we have <a href="http://www.shahine.com/omar/GoingToAWebsiteWithControlenter.aspx">a perfectly good ENTER key on our keyboards</a>. As shocking as this may be to us <a href="http://www.codinghorror.com/blog/archives/000091.html">homo logicus</a>, not everyone understands how that works. Sure, we think it's crazy to take our hand <i>off</i> the keyboard, where we were just typing our search query, move it all the way over to the mouse, then carefully move the mouse pointer to a button and left-click it... when we could just take that very same hand, already poised over the keyboard, and lazily tap the ENTER key.
</p>
<p>
But typical users <a href="http://www.codinghorror.com/blog/archives/000754.html">don't really understand basic keyboard shortcuts</a>. They love their mice, and their big, fat, honking "Search" buttons. That's why the current versions of Firefox and IE both have <b>an integrated "go" button directly next to the address bar</b>-- so users have something obvious to click once they've typed the URL into the address bar. Otherwise, I guess, they'd sit there wondering if their computer had frozen.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Personally, I always use the keyboard ENTER key to complete my searches, but I'd be open to a keyboard shortcut such as SHIFT+ENTER that invoked the Lucky function. I still can't imagine using it more than once a week at most-- and that's probably an optimistic estimate.
</p>
<p>
Strunk and White urged us to <a href="http://www.amazon.com/exec/obidos/ASIN/020530902X/codihorr-20">Omit Needless Words</a>:
</p>
<p>
</p>
<blockquote>
Vigorous writing is concise. A sentence should contain no unnecessary words, a paragraph no unnecessary sentences, for the same reason that a drawing should have no unnecessary lines and a machine no unnecessary parts. This requires not that the writer make all his sentences short, or that he avoid all detail and treat his subjects only in outline, but that every word tell.
</blockquote>
<p>
I urge us to <b>Omit Needless Buttons</b>. I hope the "I'm Feeling Lucky" button isn't considered <a href="http://sethgodin.typepad.com/seths_blog/2005/11/classifieds_are.html">a sacred cow</a> at Google. Removing it would be one small step for Google, but a giant collective improvement in the default search user interface for users around the world.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/googles-number-one-ui-mistake/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Coming Software Patent Apocalypse ]]></title>
<link>https://blog.codinghorror.com/the-coming-software-patent-apocalypse/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Every practicing programmer should read <a href="http://en.wikipedia.org/wiki/Software_patent">the Wikipedia article on software patents</a>, if you haven't already.</p>
<blockquote>Many software companies are of the opinion that copyrights and trade secrets provide adequate protection against unauthorized copying of their innovations. Companies such as Oracle Corporation and Red Hat are therefore generally opposed to the patenting of software.
<p>Nonetheless, these companies do file and receive patents. Since their competitors get patents, they must get patents as well for defensive purposes. In the event that they get sued for patent infringement by a competitor they can counter-sue using their own patent portfolio. The net result is that both companies often cross license each others' patents at little or no out-of-pocket expense for either party. However, the cost of developing a suitable portfolio of patents may be out of reach of many small software companies.</p>
</blockquote>
<p>If this sounds like a classic <a href="http://en.wikipedia.org/wiki/Mutual_assured_destruction">Mutually Assured Destruction</a> arms race, that's because it is.</p>
<p><img alt="image placeholder" >
<p>There was a hullabaloo recently about Microsoft <a href="http://haacked.com/archive/2007/05/13/is-fighting-open-source-with-patents-a-smart-move-by.aspx">rattling their software patent sabers</a>. Sadly, there's nothing notable about it; this is simply business as usual for everyone in the software industry. <strong>Software companies are forced to build huge stockpiles of software patents solely to be used as deterrents</strong>.</p>
<p>Many notable computer scientists, including Donald Knuth, believe that <a href="http://lpf.ai.mit.edu/Patents/knuth-to-pto.txt">software is fundamentally unpatentable</a>:</p>
<blockquote>Congress wisely decided long ago that mathematical things cannot be patented.  Surely nobody could apply mathematics if it were necessary to pay a license fee whenever the theorem of Pythagoras is employed.  The basic algorithmic ideas that people are now rushing to patent are so fundamental, the result threatens to be like what would happen if we allowed authors to have patents on individual words and concepts.  Novelists or journalists would be unable to write stories unless their publishers had permission from the owners of the words.  Algorithms are exactly as basic to software as words are to writers, because they are the fundamental building blocks needed to make interesting products.  What would happen if individual lawyers could patent their methods of defense, or if Supreme Court justices could patent their precedents?</blockquote>
<p>I tend to agree with Knuth that software isn't an industry that should be patentable. The fashion industry, for example, has <a href="http://www.techdirt.com/articles/20070405/194853.shtml">no concept of patent protection</a>, and thrives <a href="http://www.csmonitor.com/2003/0909/p09s01-coop.html">regardless</a>:</p>
<blockquote>The fashion world understands that creativity is a collaborative and community affair. It's far too big, robust, and evolving for any one player to "own" as a legal entitlement. Long lineages of couturiers from Balenciaga to Ungaro, Chanel to Lagerfield, and Gucci to Tom Ford have shown that designers necessarily must learn, adopt, and adapt from those who have blazed previous trails. If one were to deconstruct their work, an evolutionary chain of distinct themes, references, design nuances, and outright appropriations could be discerned.
<p>Occasionally someone may protest a "rip-off" and get murmurs of sympathy. And the counterfeiting of brand-name products is rightly condemned as theft. However, in general, creative derivation is an accepted premise of fashion. Indeed, the industry's growth and prosperity have been built upon the famous maxim of Isaac Newton, "If I have seen further, it is by standing on the shoulders of giants."</p>
<p>Is it possible that the fashion industry, long patronized as a realm of the ephemeral and insubstantial, is the real bellwether for future ideas of "ownership" of creative content?</p>
</blockquote>
<p>You <a href="http://www.foodandwine.com/articles/new-era-of-the-recipe-burglar">can't patent recipes</a>, and yet both professional chefs and restaurants are <a href="http://www.marginalrevolution.com/marginalrevolution/2006/10/why_no_patent_o.html">still in business and prospering</a>:</p>
<blockquote>Food relies so much on execution, or at the national chain level on marketing, that the mere circulation of a recipe does not much diminish the competitive advantage of the creative chef.  Try buying a fancy cookbook by a celebrity chef and see how well the food turns out. Most chefs view their cookbooks as augmenting the value of the "restaurant experience" they provide, not diminishing it.  Furthermore, industry norms, and the work of food critics, give innovating chefs the proper reputational credit.  It is not worth the litigation and vagueness of standards that recipe patents would involve.</blockquote>
<p>Of course, the <a href="http://en.wikipedia.org/wiki/Software_patent_debate">software patent debate</a> is neverending. But patents are especially dangerous and deserving of intense debate, because they're so powerful:</p>
<blockquote>Patents give their owners the right to prevent others from using a claimed invention, <strong>even if it was independently developed and there was no copying involved</strong>.</blockquote>
<p>Think about that for a minute. Seriously think about it. Every time you write code – even <em>a brand new algorithm in a clean room environment</em> – you <em>could</em> be infringing a patent, somehow, somewhere. That's why it's so often described as a <a href="http://www.perens.com/Articles/PatentFarming.html">software patent minefield</a>:</p>
<blockquote>Today's computer industry standards increasingly include technology that may be covered by a software patent. The owner of that patent has the right to demand a royalty from all parties that implement the patented principle, or may discriminate regarding who will and will not be allowed to license the patent. It is often the case that there is no way to implement a standard without making use of a particular patented principle. This effectively gives the patent holder absolute control regarding who will implement a standard containing his patented principle.
<p>Such patents arise in two ways: they are knowingly embedded in the standard as it is being created, or they are submarine patents, unknowingly part of the standard until they "surface" after the standard is already in wide use. A pernicious patent holder can engage in patent farming: influencing a standards organization to use a particular principle covered by a patent. In the worst and most deceptive form of patent farming, the patent holder encourages the standards organization to make use of a principle without revealing the existence of a patent covering that principle. Then, later on, the patent holder demands royalties from all implementers of the standard.</p>
</blockquote>
<p>It's probably not fair to say that software patents are 100% evil. But from what I've read, I'd say they're <strong>99 and 44/100ths percent evil</strong>. I'm not sure what any of us can do about this, but it's clear that the current situation is untenable:</p>
<p><img alt="image placeholder" >
<p>Something has to be done, or else we truly are staring down a coming <strong>software patent apocalypse</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-coming-software-patent-apocalypse/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Software Imprinting Dilemma ]]></title>
<link>https://blog.codinghorror.com/the-software-imprinting-dilemma/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Ducklings and goslings <a href="http://www.cerebromente.org.br/n14/experimento/lorenz/index-lorenz.html">imprint on the first creature they see</a> shortly after birth.
</p>
<p>
</p>
<blockquote>
[Austrian naturalist Konrad Lorenz] discovered that if greylag geese were reared by him from hatching, they would treat him like a parental bird. The goslings followed Lorenz about, and when they were adults they courted him in preference to other greylag geese.  He first called the phenomenon "stamping in" in German, which was translated to English as <b>imprinting</b>. Lorenz thought that the sensory object met by the newborn bird was somehow stamped immediately and irreversibly onto its nervous system. In other experiments, he demonstrated that ducklings could be imprinted not only to human beings, but also to inanimate objects such as a white ball. He also discovered that there is a very restricted window of time after hatching that proves effective for imprinting.
</blockquote>
<p>
Imprinting is a powerful biological imperative in certain species, particularly geese and ducks.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But humans also succumb to imprinting, in our own way; in computing this is known as <a href="http://en.wikipedia.org/wiki/Baby_Duck_Syndrome">Baby Duck Syndrome</a>:
</p>
<p>
</p>
<blockquote>
Baby Duck Syndrome is the tendency for computer users to "imprint" on the first system they learn, then judge other systems by their similarity to that first system. The result is that users generally prefer systems similar to those they learned on and dislike unfamiliar systems.
</blockquote>
<p>
I'm as guilty of software imprinting as anyone. I was provided an evaluation copy of <a href="http://www.slickedit.com/">Visual SlickEdit</a>, but I couldn't bring myself to try it out because I have already "imprinted" on the Visual Studio editor. I'm still learning ways to be more effective in my preferred editor; is it really worth my time to divide my effort and attempt to learn a new, unfamiliar editor that I may not even ultimately use? That's <a href="http://www-128.ibm.com/developerworks/web/library/wa-cranky50.html">the software imprinting dilemma</a>:
</p>
<p>
</p>
<blockquote>
Baby duck syndrome affects the way you learn to use computers and software. It can make it hard for you to make the most rational decisions about which software to use or when the learning curve of a given thing is worth the climb. In general, it makes the familiar seem more efficient and the unfamiliar less so. In the short run, this is probably true -- if you're late for a deadline, the best thing to do is not to switch to a new operating system in the hopes that your productivity will increase. In the long run, it's worth trying a few things knowing that they won't all work out, but hoping to find the tools that match your style best.
</blockquote>
<p>
It's impossible to understand the alternatives when you can't muster the energy to get past your own software imprinting. <b>You can't rationally compare alternatives with no <i>experience</i> in the alternatives</b>, and software imprinting <a href="http://www.techiepundit.com/archives/000031.html">robs you of that vital experience</a>.
</p>
<p>
</p>
<blockquote>
There are periodic Usenet group debates about programming editors where various people will proclaim with conviction that their preferred editor is the best. In some of these debates I've asked some of the believers of various editor faiths if they'd ever tried various other alternatives. Well, no. They had never used CodeWright or Visual Slick Edit or Multi-Edit or assorted other editors. Some claimed to have used another editor about 5 or 10 years ago, but not the latest version.
<p>
When I started asking around, I discovered that it's hard to find people who have used recent versions of two major editors, so it's hard to find anyone who can intelligently compare the features of various editors. I use Visual Slick Edit personally. There are things I want it to do that it doesn't do. But I don't know whether any other editor can do all the things I like about Slick plus the things I wish it did.
</p>
</blockquote>
<p>
Maybe it's time to experiment with new operating systems, new applications, and new editors, even if we're happy with our status quo. We should put allegiances and familiarity aside, and <b>push ourselves harder to go beyond our software imprinting</b>-- otherwise, we literally won't know what we're missing.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-software-imprinting-dilemma/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Always. Be. Shipping. ]]></title>
<link>https://blog.codinghorror.com/yes-but-what-have-you-done/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I believe there's a healthy balance all programmers need to establish, somewhere between …</p>
<ul>
<li>Locking yourself away in a private office and having an intimate dialog with a compiler about your program.</li>
<li>Getting out in public and having an open dialog with other human beings about your program. </li>
</ul>
<p>I've talked about this a few <a href="http://blog.codinghorror.com/is-writing-more-important-than-programming/">times</a> <a href="http://blog.codinghorror.com/usability-is-timeless/">already</a>, so I won't belabor the point.</p>
<p>Most programmers are introverts, so they don't usually need any encouragement to run off and <a href="http://blog.codinghorror.com/gee-i-wish-i-had-spent-more-time-alone-with-my-computer/">spend time alone with their computer</a>. They do it naturally. Left to their own devices, that's all they'd ever do. I don't blame them; <a href="http://blog.codinghorror.com/in-programming-one-is-the-loneliest-number/">computers are a lot more rational than people</a>. That's what attracts most of us to the field. But it is possible to go too far in the <em>other</em> direction, too. It's much rarer, because it bucks the natural introversion of most software developers, but it does happen. Take me, for example. <strong>Sometimes I worry that I spend more time talking about programming than actually <em>programming</em>.</strong></p>
<p>At the point when I spend <em>all</em> my time talking about programming, and very little of my time programming, my worst fear has been realized: I've become a pundit. <strong>The last thing the world needs is more pundits.</strong> Pundits only add ephemeral <em>commentary</em> to the world instead of anything concrete and real. They don't build any lasting artifacts; instead, they passively observe other people's work and offer a neverending babbling brook of opinions, criticism, and witty turns of phrase.</p>
<p>Perhaps that's why I find <a href="http://seoblackhat.com/2007/01/29/do-it-fucking-now/">this blog entry</a> from SEO Black Hat so inspiring:</p>
<blockquote>
<p>Do it F***ing Now.</p>
</blockquote>
<blockquote>
<p>Don't wait. Don't procrastinate. The winners in this world are not the ones who find the greatest excuses to put off doing what they know will make them more money. The winners are the ones that prioritize and seize the day.</p>
<p>Create a list of action items to make sure your important tasks get accomplished. Every project you're working on should be in action. If you're not moving, you're standing still. Your next step towards making money must not be "something I'll take care of maybe sometime next week." If it's going to help make you money: Do it F***ing Now.</p>
<p>Some of you may think that you don't need the "f***ing" in "do it f***ing now". You do. You need that impact, that force, that call to action, that kick in the ass to get you moving. Otherwise, you'll end up another loser that had a great idea a long time ago but never did anything about it. Dreamers don't make money. Doers make money. And doers "Do it F***ing Now."</p>
</blockquote>
<p>It's like a stiff jolt of heavily caffeinated coffee. It may be a bit too <a href="http://www.imdb.com/title/tt0104348/">Glengarry Glen Ross</a> for some.</p>
<video poster="/content/images/2015/08/glengarry-speech-poster.jpg" width="100%" height="272" preload="none" controls>
<source src="http://discourse-cdn.codinghorror.com/uploads/default/original/3X/b/2/b20cfd9675d4bcbdda70c9cf8b7a5d740bac1836.mp4">
</source></video>
<p>Specifically <a href="http://yu.ac.kr/~bwlee/esc/baldwin.htm">this speech</a>, and this scene.</p>
<p>Even if it's intentionally over the top, I think this advice applies to programming, too. The best programmers <a href="http://www.codinghorror.com/blog/archives/000135.html">get off their butts</a>. As Cade Roux noted in a comment, the text on the Glengarry Glen Ross blackboard is "Always Be Closing", but we should read it as …</p>
<blockquote>
<h2 id="always">Always</h2>
<h2 id="be">Be</h2>
<h2 id="shipping">Shipping</h2>
</blockquote>
<p>It's helpful to discuss features, but sometimes the value of a feature is inversely proportional to how much it has been discussed. Our job as software developers is to deliver features and solve business problems, not to generate neverending discussion. Ultimately, As Marc Andreessen notes, <a href="http://pmarchive.com/how_to_hire_the_best_people.html">we will be judged by what we – and our code – have done</a>, <em>not</em> the meta-discussion that went on around it.</p>
<blockquote>
<p>For the background part, I like to see what someone has done. <strong>Not been involved in, or been part of, or watched happen, or was hanging around when it happened.</strong></p>
<p>I look for something you've done, either in a job or (often better yet) outside of a job. The business you started and ran in high school. The nonprofit you started and ran in college. If you're a programmer: the open source project to which you've made major contributions. Something.</p>
<p>If you can't find anything – if a candidate has just followed the rules their whole lives, showed up for the right classes and the right tests and the right career opportunities without achieving something distinct and notable, relative to their starting point – then they probably aren't driven. And you're not going to change them.</p>
</blockquote>
<p>Maybe "Do it f***ing now" is too extreme, but at the very least, <strong>make sure you spend at least as much of your time doing as discussing</strong>. Unfortunately, I can't tell you what the right things are to do. If I knew that, I'd probably be a millionaire by now. You'll have to decide what's actually <em>worth</em> doing yourself.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/yes-but-what-have-you-done/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Speeding Up Your PC's Boot Time ]]></title>
<link>https://blog.codinghorror.com/speeding-up-your-pcs-boot-time/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I frequently hear apocryphal stories about Macs booting much faster than Windows boxes. There's <a href="http://www.silvermac.com/2006/macmini-core-duo-start-up-time/">a great set of Mac boot time benchmarks</a> on the Silver Mac site that provide solid empirical data to back up those claims:
</p>
<p>
</p>
<table>
<td></td>
<td style="vertical-align: top; text-align: right; font-weight: bold">Intel iMac</td>
<td style="vertical-align: top; text-align: right; font-weight: bold">G5 iMac</td>
<td style="vertical-align: top; text-align: right; font-weight: bold">G5 iMac</td>
<td style="vertical-align: top; text-align: right"><span style="font-weight: bold">Mac Mini</span></td>
<tr>
<td style="vertical-align: top"></td>
<td style="vertical-align: top; text-align: right;">10.4.4</td>
<td style="vertical-align: top; text-align: right;">10.4.4</td>
<td style="vertical-align: top; text-align: right;">10.4.5</td>
<td style="vertical-align: top; text-align: right;">10.4.5</td>
</tr>
<tr>
<td style="vertical-align: top">Mac sound</td>
<td style="vertical-align: top; text-align: right">4.5</td>
<td style="vertical-align: top; text-align: right">3.5</td>
<td style="vertical-align: top; text-align: right">3.6</td>
<td style="vertical-align: top; text-align: right; color: #3333ff">4.0</td>
</tr>
<tr>
<td style="vertical-align: top">Apple logo</td>
<td style="vertical-align: top; text-align: right">6.7</td>
<td style="vertical-align: top; text-align: right">15.6</td>
<td style="vertical-align: top; text-align: right">15.2</td>
<td style="vertical-align: top; text-align: right; color: #3333ff">10.2</td>
</tr>
<tr>
<td style="vertical-align: top">Mac OS X</td>
<td style="vertical-align: top; text-align: right">31.9</td>
<td style="vertical-align: top; text-align: right">34.4</td>
<td style="vertical-align: top; text-align: right">34.9</td>
<td style="vertical-align: top; text-align: right; color: #3333ff">22.8</td>
</tr>
<tr>
<td style="vertical-align: top">Ready to use</td>
<td style="vertical-align: top; text-align: right">37.9</td>
<td style="vertical-align: top; text-align: right">40.8</td>
<td style="vertical-align: top; text-align: right">41.6</td>
<td style="vertical-align: top; text-align: right; color: #3333ff"><strong>25.8</strong></td>
</tr>
</table>
<p>
To be clear, <b>the standard convention for "boot time" is the time from initial power on to the time we can finally interact with the desktop</b>. The Silver Mac benchmarks are admirably thorough, as they break out important milestones during boot: the first boot sound, the appearance of the Apple logo on the screen, the OS X loading screen, and finally the ability to interact with the desktop. The intermediate milestones help us see where the real bottlenecks are in the boot process.
</p>
<p>
For perspective, <a href="http://hubpages.com/hub/_86_Mac_Plus_Vs_07_AMD_DualCore_You_Wont_Believe_Who_Wins">a 1986 Mac Plus boots to the desktop</a> in <i>eleven seconds</i>. The modern PC it is compared to clocks in at just over a minute of boot time. It's not even remotely a fair comparison for a whole host of reasons, but it's a fun data point nonetheless. How long does it take for your car to boot? Your MP3 player? Your television? Your cell phone?
</p>
<p>
For typical PC boot times, I turn to <a href="http://blogs.zdnet.com/Bott/?p=240">Ed Bott's excellent blog</a>.
</p>
<p>
</p>
<table>
<tr>
<td></td>
<td style="text-align: right;">2006 vintage<br>PC Desktop</td>
<td style="text-align: right;">2005 vintage<br>PC Laptop</td>
<td style="text-align: right;">2004 vintage<br>PC Desktop</td>
</tr>
<tr>
<td>Windows XP</td>
<td style="text-align: right;">1:01</td>
<td style="text-align: right;">1:47</td>
<td style="text-align: right;">0:58</td>
</tr>
<tr>
<td>Windows Vista</td>
<td style="text-align: right;">1:12</td>
<td style="text-align: right;">1:20</td>
<td style="text-align: right;">1:14</td>
</tr>
<tr>
<td>Ubuntu Linux 6.10</td>
<td></td>
<td></td>
<td style="text-align: right;">1:49</td>
</tr>
</table>
<p>
Wow, <b>PC boot times really do suck</b>, right? Well, maybe. It depends on the PC.
</p>
<p>
The <a href="http://www.hanselman.com/blog/GoneQuadDay0WithTheUltimateDeveloperPC.aspx">"Ultimate Developer Rig" I built for Scott Hanselman</a> <font color="red"><b>boots to a clean install of Vista x64 in 22 seconds</b></font>. According to Scott, 10 seconds of that is attributable to the BIOS, and the other 12 is the operating system loading from disk. It's sobering to consider that almost <i>half</i> of the system's total boot time is spent in the third-party motherboard BIOS-- something Microsoft has no control over.
</p>
<p>
Now, these kinds of speedy PC boot times are only attainable if you have a clean install of the operating system. A clean install is <i>de rigueur</i> for Apple, because they're a single-source vendor. They have the luxury of complete control over the way their operating system is shipped-- not to mention the system BIOS itself. Every Apple box should boot consistently quickly as a matter of course. It'd be a crushing disappointment if they didn't.
</p>
<p>
On a Windows box, however, you almost never get a clean install. You typically get Microsoft's operating system plus <b>a bevy of <a href="http://www.codinghorror.com/blog/archives/000554.html">performance-sapping craplets</a> the third-party vendor was paid to install on your system</b>. Your boot times are already compromised the second you break the seal on the box.
</p>
<p>
Tweaking the BIOS to improve boot time is usually out of the question. But it is possible to restore most Windows boxes to near-clean-install boot speeds, at least. The process isn't exactly rocket surgery -- just <b>stop doing so much stuff at startup!</b> The primary tool for turning off unnecessary startup tasks is conveniently built into both XP and Vista: <a href="http://www.netsquirrel.com/msconfig/msconfig_xp.html">MSCONFIG</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In my experience, anything that <i>wants</i> to runs at boot almost never <i>needs</i> to. <b>It's generally safe to turn off almost everything in the <a href="http://www.netsquirrel.com/msconfig/msconfig_xp.html">MSCONFIG</a> startup tab.</b> If you have any applets that you recognize and want to run on boot, leave those; for everything else, when in doubt, turn it off. This not only speeds up your boot time, it also frees up memory on the PC. If you later decide you made a mistake, reverting is easy enough-- just run MSCONFIG again and tick the appropriate checkbox.
</p>
<p>
It's also quite common for your boot time to degrade over time as you install certain kinds of software, as <a href="http://blogs.zdnet.com/hardware/?p=359">noted by Adrian Kingsley-Hughes</a>:
</p>
<p>
</p>
<blockquote>
Sudden changes in boot times are usually quite noticeable, but what usually happens in that boot times grow slowly over time.  You start off with a PC with a fresh install of Windows on it and it feels nice and fast (hopefully - if it doesn't then you're in serious trouble and things are only going to get worse, no matter how much you trash your system trying to speed it up).  You then install security software and performance takes a hit.  Install some big apps like Office and boot times take another nose-dive.  I've seen boot times increase by over 100% over the course of setting up a new PC.  It's actually quite depressing to watch.
</blockquote>
<p>
Indeed, and <b>the vast majority of that boot slowdown is attributable to security and anti-virus software</b>, <a href="http://www.thepcspy.com/articles/other/what_really_slows_windows_down/5">as documented on PC Spy</a>. That's why I urge people to <a href="http://www.codinghorror.com/blog/archives/000803.html">pursue other methods of securing their PCs</a>; if you rely on commercial anti-virus, you are literally <i>crippling</i> your PC's performance. <a href="http://chuvakin.blogspot.com/2007/04/answer-to-my-antivirus-mystery-question.html">Anti-virus software barely works these days anyway</a>, so it's a raw deal no matter how you slice it.
</p>
<p>
Of course, the best boot time of all is <i>no</i> boot time-- as Adrian so aptly <a href="http://blogs.zdnet.com/hardware/?p=359">points out</a>:
</p>
<p>
</p>
<blockquote>
How many times a day do you boot up your PC?  <b>If you [boot] more than two or three times a day on a regular basis then you're not making proper use of the features that your PC offers, such as hibernate or sleep.</b> My systems can go for days, and sometimes weeks, without a reboot, being hibernated/put to sleep at the end of the day or during any big breaks in the work day.  In fact, I like the hibernate feature a lot because it lets me shut my systems down yet leave my work open.  Next time I restart the system, all my apps and documents are open and waiting for me.
<p>
Even if I did need to reboot my system a few times a day, I don't think that I'd be all that worried about boot times unless they were really long (+3 minutes) or my system was really unstable and needed rebooting several times a day.  In either case, there's a problem somewhere that needs to be solved.  If the system only takes a few seconds or a couple of minutes to boot up then I'm really not worried about the effect that the lost time will have on my productivity.
</p>
</blockquote>
<p>
He's right. Maybe boot time is ultimately irrelevant; your best bet is to avoid booting altogether. <b>Make use of those "Sleep" and "Hibernation" options in lieu of powering all the way down</b>. Support is fairly mature for these modes, even in the wild-and-wooly PC ecosystem-- and they're many times faster than cold booting and loading up all your applications again.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/speeding-up-your-pcs-boot-time/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's Worse Than Crashing? ]]></title>
<link>https://blog.codinghorror.com/whats-worse-than-crashing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Here's an interesting thought question from Mike Stall: <a href="http://blogs.msdn.com/jmstall/archive/2007/07/26/there-are-things-worse-than-crashing.aspx">what's worse than crashing?</a>
</p>
<p>
Mike provides the following list of crash scenarios, in order from best to worst:
</p>
<p>
</p>
<ol>
<li>Application works as expected and never crashes.
</li>
<li>Application crashes due to rare bugs that nobody notices or cares about.
</li>
<li>Application crashes due to a commonly encountered bug.
</li>
<li>Application deadlocks and stops responding due to a common bug.
</li>
<li>Application crashes long after the original bug.
</li>
<li>
<b>Application causes data loss and/or corruption.</b>
</li>
</ol>
<p>
Mike points out that there's a natural tension between...
</p>
<p>
</p>
<ul>
<li>failing <i>immediately</i> when your program encounters a problem, eg "fail fast"
</li>
<li>attempting to recover from the failure state and proceed normally
</li>
</ul>
<p>
The philosophy behind "fail fast" is best explained in <a href="http://www.martinfowler.com/ieeeSoftware/failFast.pdf">Jim Shore's article</a> (pdf).
</p>
<p>
</p>
<blockquote>
Some people recommend making your software robust by working around problems automatically. This results in the software "failing slowly." The program continues working right after an error but fails in strange ways later on. A system that fails fast does exactly the opposite: when a problem occurs, it fails immediately and visibly. Failing fast is a nonintuitive technique: "failing immediately and visibly" sounds like it would make your software more
fragile, but it actually makes it more robust. Bugs are easier to find and fix, so fewer go into production.
</blockquote>
<p>
Fail fast is reasonable advice-- if you're a developer. What could possibly be easier than <a href="http://www.codinghorror.com/blog/archives/000676.html">calling everything to a screeching halt</a> the minute you get a byte of data you don't like? Computers are spectacularly unforgiving, so it's only natural for developers to reflect that masochism directly back on users.
</p>
<p>
But from the user's perspective, failing fast isn't helpful. To them, it's just another <a href="http://www.codinghorror.com/blog/archives/000114.html">meaningless error dialog</a> preventing them from getting their work done. The best software never pesters users with meaningless, trivial errors-- it's <a href="http://www.codinghorror.com/blog/archives/000550.html">more considerate than that</a>. Unfortunately, <b>attempting to help the user by fixing the error could make things worse by leading to subtle and catastrophic failures down the road.</b> As you work your way down Mike's list, the pain grows exponentially. For both developers <i>and</i> users. Troubleshooting #5 is a brutal death march, and by the time you get to #6-- you've lost or corrupted user data-- you'll be lucky to have any users <i>left</i> to fix bugs for.
</p>
<p>
What's interesting to me is that despite causing more than my share of software crashes and hardware bluescreens, I've <i>never</i> lost data, or had my data corrupted. You'd figure Murphy's Law would force the worst possible outcome at least once a year, but it's exceedingly rare in my experience. Maybe this is an encouraging sign for the current state of software engineering. Or maybe I've just been lucky.
</p>
<p>
So what can we, as software developers, do about this? If we adopt a "fail as often and as obnoxiously as possible" strategy, we've clearly failed our users. But if we corrupt or lose our users' data through misguided attempts to prevent error messages-- if we fail to treat our users' data as sacrosanct-- we've <i>also</i> failed our users. You have to do both at once:
</p>
<p>
</p>
<ol>
<li>If you <i>can</i> safely fix the problem, you should. Take responsibility for your program. Don't slouch through the easy way out by placing the burden for dealing with every problem squarely on your users.
</li>
<li>If you <i>can't</i> safely fix the problem, always err on the side of protecting the user's data. Protecting the user's data is a sacred trust. If you harm that basic contract of trust between the user and your program, you're hurting not only your credibility-- but the credibility of the entire software industry as a whole. Once they've been burned by data loss or corruption, users don't soon forgive.
</li>
</ol>
<p>
The guiding principle here, as always, should be to <b>respect your users</b>. Do the right thing.
</p>
<p>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-worse-than-crashing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Configuring The Stack ]]></title>
<link>https://blog.codinghorror.com/configuring-the-stack/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A standard part of my development kit is <a href="http://msdn.microsoft.com/vstudio/">Microsoft's Visual Studio</a>. Here's what I have to install to get a current, complete version of Visual Studio 2005 on a new PC:
</p>
<p>
</p>
<ol>
<li>Visual Studio 2005 Team Suite Edition
</li>
<li>Visual Studio Team Explorer (Team Foundation Client)
</li>
<li>Visual Studio 2005 Service Pack 1
</li>
<li>Visual Studio 2005 Service Pack 1 Update for Windows Vista
</li>
<li>SQL Server 2005 Express Service Pack 2
</li>
<li>Visual Studio 2005 Team Edition for Database Professionals
</li>
<li>Visual Studio 2005 Team Edition for Database Professionals Service Pack 1
</li>
</ol>
<p>
Note that this is only a <i>partial</i> list; it doesn't include any of the other Visual Studio add-ons you might need to code against newer Microsoft technologies, such as <a href="http://www.microsoft.com/downloads/details.aspx?familyid=ca9d90fa-e8c9-42e3-aa19-08e2c027f5d6&amp;displaylang=en">ASP.NET AJAX</a>, <a href="http://www.microsoft.com/downloads/details.aspx?FamilyId=5D61409E-1FA3-48CF-8023-E8F38E709BA6&amp;displaylang=en">WF</a>, or <a href="http://www.microsoft.com/downloads/details.aspx?FamilyId=F54F5537-CC86-4BF5-AE44-F5A1E805680D&amp;displaylang=en">.NET 3.0</a>.
</p>
<p>
What's wrong with this picture?
</p>
<p>
I appreciate that some of these products were released out of order, which is partially why the install is so convoluted. But if one of the disadvantages of open-source software is <a href="http://en.wikipedia.org/wiki/Solution_stack">"configuring the stack"</a>, <b>I'm having a hard time seeing how Microsoft's commercial stack is any easier to configure than the alternative open source stacks these days</b>. Either the open source stuff has gotten a lot more streamlined and mature, or the Microsoft stuff is somehow devolving into complexity. I'm not sure which it is, exactly, but the argument that choosing a commercial development stack saves you time rings more and more hollow over time.
</p>
<p>
As the old adage goes, <i>Linux is only free if your time is worthless</i>*. But apparently your time can be worthless even if you've paid for the privilege.
</p>
<p>
* attributed to <a href="http://www.jwz.org/">Jamie Zawinski</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/configuring-the-stack/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Catalogs of Data Visualization ]]></title>
<link>https://blog.codinghorror.com/catalogs-of-data-visualization/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In the spirit of Jennifer Tidwell's <a href="http://www.amazon.com/exec/obidos/ASIN/0596008031/codihorr-20">excellent Designing Interfaces book</a>,  there are a few great catalogs of data visualization emerging online.
</p>
<p>
Start with the oft-cited <b><a href="http://www.visual-literacy.org/periodic_table/periodic_table.html">Periodic Table of Visualization Methods</a></b>.
</p>
<p>
<a href="http://www.visual-literacy.org/periodic_table/periodic_table.html"><img alt="image placeholder" >
</p>
<p>
There's another excellent collection at <b><a href="http://www.smashingmagazine.com/2007/08/02/data-visualization-modern-approaches/">Data Visualization: Modern Approaches</a></b>.
</p>
<p>
<a href="http://www.aharef.info/2006/05/websites_as_graphs.htm"><img alt="image placeholder" >
</p>
<p>
<a href="http://www.munterbund.de/visualisierung_textaehnlichkeiten/essay.html"><img alt="image placeholder" >
</p>
<p>
If you're looking for visualization with a less practical, more web-oriented bent, a colleague recently discovered the <a href="http://www.thefwa.com/">FWA: Favourite Web Awards</a> site. It's a huge catalog of websites that use interesting, unique designs and visualizations. That's where we found <a href="http://www.uniqlo.jp/uniqlock/">the Uniqlock "clock"</a>, and the <a href="http://www.1-click.jp/">giant rickshaw pointer</a>.
</p>
<p>
At any rate, if you're <a href="http://www.codinghorror.com/blog/archives/000739.html">a student of Tufte</a> like I am, you might find it helpful to review a sample of what visualizations and techniques are possible (or even advisable) before plowing ahead on <a href="http://redmonk.com/cote/2007/07/12/update-from-ria-land-air-silverlight-what-is-an-ria-better-guis-the-killer-app/">your next "Rich Internet Application"</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/catalogs-of-data-visualization/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Large Display Paradox ]]></title>
<link>https://blog.codinghorror.com/the-large-display-paradox/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As displays increase in size and prices drop, <b>more and more users will end up with relatively large displays by default</b>. Nobody buys 15 or 17 inch displays any more; soon, it won't make financial sense to buy a display smaller than 20 inches. Eventually, if this trend continues, everyone will have 30-inch displays on their desktops. This is clearly a good thing. You can never have enough display space. But there is one unintended consequence of large displays.
</p>
<p>
One of the <i>advantages</i> of small monitors, ironically, is that <b>because they're small, they nudge users into a simpler, windowless method of working</b>. Instead of wasting time sizing, moving, and z-ordering windows, users only need to deal with one maximized window at a time. They can flip between maximized applications in much the same way they change channels on the television. But once your display gets to 1600 x 1200 or beyond, this easy one-app-per-display model isn't feasible any more. Dan recently ran into this problem <a href="http://www.dansdata.com/3007wfp-hc.htm">when he upgraded to a 30" LCD</a>:
</p>
<p>
</p>
<blockquote>
Users of 30-inch monitors face the terrible, <i>terrible</i> problem of how to effectively use all of that space. You don't often want to maximise a folder or document window on a screen this big; either you'll end up with <a href="http://www.codinghorror.com/blog/archives/000912.html">a lot of white space and important program buttons separated by a vast expanse of nothing</a>, or you'll get lines of text 300 or more characters long, which are <a href="http://www.codinghorror.com/blog/archives/000618.html">difficult to read</a>.
</blockquote>
<p>
That's the <b>large display paradox</b>. Having all that space can make you <i>less</i> productive due to all the window manipulation excise you have to deal with to make effective use of it.
</p>
<p>
Personally, I'm a card-carrying member of <a href="http://www.codinghorror.com/blog/archives/000740.html">the prestigious three monitor club</a>, which means I'm one step ahead of Dan. At least <a href="http://www.time.com/time/photogallery/0,29307,1622338_1363003,00.html">until he doubles or triples down</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Although my displays are only 20 inches in size, <a href="http://www.codinghorror.com/blog/archives/000217.html">I have three of them</a>. Maximizing a window to a 20 inch, 1600 x 1200 display area is a reasonable thing to do most of the time. I also use <a href="http://www.realtimesoft.com/ultramon/">UltraMon</a>, which gives me <b>the indispensible ability to drag maximized windows between monitors</b>. I'm constantly grabbing maximized windows and "throwing" them from monitor to monitor, ala <a href="http://www.imdb.com/title/tt0181689/">Minority Report</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
With my triple monitor setup, I have a very large display surface with a primary area of focus and secondary areas that I can "snap" items to when I want them available for reference, but out of the way. <b>I have a natural snapping grid because I use three physical monitors.</b> It's a side-effect of the hardware, but a crucial one that I've absolutely come to rely on.
</p>
<p>
Dan only has a single large 30 inch monitor, so he has no natural grid to snap windows to. He needs a software solution:
</p>
<p>
</p>
<blockquote>
I've been using <a href="http://reptils.free.fr/">WinSplit Revolution</a> to manage this problem. It's a neat little Windows utility that makes it easy to bounce (most) windows around the screen and quickly resize them to take up the amounts of screen you probably want them to occupy. Two panes, each 1280 by 1600, give you a couple of twenty inch portrait-aspect-ratio "screens" that work great for many tasks.
</blockquote>
<p>
I run into this problem a little bit on my three 20 inch displays, but it's only a minor nuisance. I'm in <i>serious</i> trouble if I ever get a multiple monitor setup with displays larger than 20 inches. (I'd also need a much, much <a href="http://www.codinghorror.com/blog/archives/000551.html">larger desk</a>.) There's no question that <b>maximized windows aren't effective on large displays</b>. For larger displays, I'd need to extend the "snap grid" effect of my three monitors to each individual monitor.
</p>
<p>
That's exactly what the <a href="http://reptils.free.fr/">WinSplit Revolution</a> app does. It's quite intuitive; you use CTRL+ALT+(numpad) to push the currently selected window towards the quadrant of the screen represented by the number. Pressing the key sequence multiple times iterates through the two or three possible sizes at that particular position. This diagram explains it better than I can in text:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As you can see, you end up with a few dozen possible grid arrangements just using the simple numpad direction metaphor. But it's still quite a bit of work; I have to select each window and then use the numeric keypad (or the popup window equivalent) to <a href="http://reptils.free.fr/help.htm">push it over where I want it to go</a>. As of version 1.8, WinSplit Revolution is perfectly multiple monitor aware, and even offers a convenient key combo to move windows from monitor to monitor, too.
</p>
<p>
Fortunately, there's <a href="http://www.donationcoders.com/jgpaiva/gridmove.html">GridMove</a>, which supports multiple monitors. Just use the middle mouse button to drag a window, and you invoke the current grid template, which provides automatic snappable drop targets for that window.
</p>
<p>
<a href="http://www.donationcoders.com/jgpaiva/gridmove.html"><img alt="image placeholder" >
</p>
<p>
In the not-too-distant future, <b>every user will have a monitor so large that maximizing a window no longer makes sense for most applications</b>. It's too bad some kind of automatic snap grid support can't be embedded into the operating system to help users deal with large display areas. Like Dan, we're all going to need it sooner or later. Until then, these applications-- or ones like them-- can fill the gap.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-large-display-paradox/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Dell XPS M1330 Review ]]></title>
<link>https://blog.codinghorror.com/dell-xps-m1330-review/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although I wasn't unhappy with <a href="http://www.codinghorror.com/blog/archives/000624.html">my ASUS W3J laptop</a>, which I've owned for a little over a year now, it was never quite the ultraportable to match <a href="http://www.codinghorror.com/blog/archives/000562.html">my beloved, dearly departed three pound Dell Inspiron 300M</a>. That's why I recently purchased a <a href="http://www.dell.com/content/products/productdetails.aspx/xpsnb_m1330?c=us&amp;cs=19&amp;l=en&amp;s=dhs">Dell XPS M1330 laptop</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I've been eyeing <b>laptops with LED displays and solid-state hard drives</b> for a while now, long before I ever saw the Dell M1330. But the fact that...
</p>
<ul>
<li>it offers the required LED display and SSD drive options
</li>
<li>
<i>and</i> it's a sub-four-pound ultralight
</li>
<li>
<i>and</i> it offers a non-integrated graphics option, which is <i>incredibly</i> rare for an ultralight
</li>
<li>
<i>and</i> it has ridiculously good design for a Dell
</li>
</ul>
<p>
... sort of pushed me over the edge. Plus there are all these rave reviews of the M1330 coming in from <a href="http://www.pcmag.com/article2/0,1895,2150843,00.asp">PC Magazine</a>, <a href="http://www.notebookreview.com/default.asp?newsID=3787">Notebook Review</a>, and <a href="http://reviews.cnet.com/laptops/dell-xps-m1330/4505-3121_7-32465545.html">CNET</a>. And I do mean <i>rave</i> reviews. It's not often you see the jaded PC Magazine reviews dish out this kind of praise:
</p>
<p>
</p>
<blockquote>
It's been a while since Dell delivered a laptop that possessed so many awe-inspiring features. The Dell XPS M1330 is a monumental step in that <b>it takes the best things from other great ultraportables and combines them into a single entity</b>. My only peeve is that the weight can get up there with the nine-cell battery. Otherwise, this ultraportable should easily sit at the top of any laptop shopping list.
</blockquote>
<p>
It's strange, in a way, because the M1330 isn't much of an upgrade from the W3J in terms of absolute hardware specifications. The display sizes are almost the same, both offer 2.0 GHz dual-core CPUs, and the M1330 is even a downgrade in one area: I ordered it with a hard drive that's less than half the size of the W3J. It's more of a sidegrade than a pure upgrade. The resulting <a href="http://www.codinghorror.com/blog/archives/000678.html">Windows Experience benchmark scores</a> are almost the same for both laptops, too.
</p>
<p>
Of course, the first thing I did after getting the machine was <b>format the hard drive</b>. It's a sad fact of life in the PC ecosystem, but <a href="http://www.codinghorror.com/blog/archives/000554.html">if you want a machine clean of bloatware and useless, paid-endorsement installed craplets</a> (including Google Desktop, I might add), you have to raze it to the ground yourself immediately after unboxing it.
</p>
<p>
This is a particularly egregious problem on the 32 GB solid state hard drive, because it had a 10 GB "restore" partition, and a 6 GB "media direct" partition pre-installed from the factory. Nothing like booting up a system with an already-limited 32 GB storage device and finding you only have 16 GB of disk space available. Way to go, Dell.
</p>
<p>
After formatting and beginning a clean install of Vista, I ran into a little problem where the machine would bluescreen immediately on startup after the install. I found that switching the hard drive interface from <a href="http://en.wikipedia.org/wiki/Advanced_Host_Controller_Interface">AHCI</a> back to standard fixed that problem. According to the BIOS warning, this precludes the use of Intel's <a href="http://www.extremetech.com/article2/0,1697,1936630,00.asp">Robson onboard Flash memory cache</a>, but with a solid state hard drive in play I don't think that's much of a loss. <font color="red">UPDATE: it's a better idea to install the proper AHCI driver during the Vista install process, because that's the <i>only</i> time you can make the switch! Copy the "Intel SATA driver" to a USB flash drive, and specify alternate driver during the drive selection phase.</font> The only drivers you'll need for a clean 32-bit Vista install are video, sound, and wired network-- all available from <a href="http://support.dell.com/support/downloads/index.aspx?c=us&amp;cs=19&amp;l=en&amp;s=dhs&amp;SystemID=XPS_M1330">the Dell XPS M1330 driver download page</a>. Everything else is included in the default set of Vista drivers. Beware, though, because 64-bit drivers aren't available for the video card yet.
</p>
<p>
I've only had the machine since Tuesday, so I'm not really in a position to provide a comprehensive review. But after being one of <a href="http://direct2dell.com/one2one/archive/2007/08/03/23340.aspx">the fortunate few to receive their M1330s</a>, I have to agree with the glowing reviews. This is an outstanding machine for people like me who think laptops were meant to be <i>portable</i> first and foremost.
</p>
<p>
Perhaps <b>the most striking thing about the machine is the 32 gigabyte solid-state hard drive</b>. It's blazingly fast and completely silent. I have gotten so used to the low, metronomic rumbling of hard drives when my computers are working that the complete <i>absence</i> of sound in normal operation is rather strange. All you can hear is a bit of very quiet high pitched electronic buzzing, and only if you put your ear very close to the machine.
</p>
<p>
The downside, of course, is that it's <b>only 32 GB in size</b>. It's definitely a little tight. I wasn't too worried, because when I priced this option-- and it's not a cheap option at $500-- I was already using less than 32 GB of disk space on my current ASUS W3J laptop, which has a fairly typical 80 GB laptop hard drive. I tend to run a minimalistic laptop configuration; with Vista Ultimate, Visual Studio 2005, Office 2007, Streets and Trips, Photoshop Elements, and a few other things installed, I have <b>almost 12 GB of disk space free</b> on the 32 GB solid state drive. It's not quite as bad as it sounds; I carry a 100 GB external USB 2.5" hard drive in my bag as a matter of course, for virtual machines and other large items. <a href="http://www.jam-software.com/freeware/">TreeSize</a> was always one of my key utilities; on this machine, it's my new best friend.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
32 GB of space is enough to get by as a primary hard drive, but it definitely makes you realize <b>how spoiled we've all become with our standard ginormous physical hard drives</b>. Hard drive space is one of those things we stopped worrying about years ago; 500 GB desktop drives and 100 GB laptop drives are dirt cheap. But with a smallish SSD drive, you have to start caring about disk space again. On a machine with 2 GB of memory, that mandatory 2 GB hibernate file on disk, plus the 1.5+ GB swap file, start to sting a bit. You can imagine what this would be like on a 64-bit operating system with 4 GB of memory-- you'd be dropping almost a sixth of your disk space on pure overhead!
</p>
<p>
Size (and, well, price) is the only thing keeping solid state hard drives from being a no-brainer on laptops. It'll be a lot easier to stomach the size restriction when <a href="http://news.digitaltrends.com/news/story/12556/samsung_announces_64_gb_solid_state_drive">64 gigabyte solid state hard drives</a> are more widely available. And they're even faster:
</p>
<p>
</p>
<blockquote>
Samsung claims the respective read and write performance on the SSD drive have been increased by 20 and 60 percent: the 64 GB unit can read 64 MB/S, write 45 MB/s, and consumes just half a watt when operating -- and merely one tenth of a watt when idle. In comparison, a mechanical 80 GB 1.8-inch hard drive reads at 15 MB/s, writes at 7 MB/s, and eats 1.5 watts either operating or when idle.
</blockquote>
<p>
After using a machine with a solid-state hard drive for a few days, it's clear to me that <b>solid-state hard drives are absolutely the future for all laptops</b>, and possibly even for desktops in some scenarios. You boot up faster, you shut down faster, and launching applications feels instantaneous. On top of all that, it uses almost no power and produces virtually zero noise or heat. They just need to get the prices down and the sizes up, which will come naturally enough in time. As William Gibson said, <i>the future is already here-- it's just unequally distributed.</i>
</p>
<p>
It's hard to quantify these sorts of things, but <b>I also greatly prefer the aesthetics of the M1330 over my old W3J</b>. For one thing, the wedge shape is much more natural; the keyboard descends to meet your hands and the desktop, and it's always angled up in traditional keyboard form. I'm not sure if it's my imagination or not, but the feel of the keys is better too. One thing I can quantify is that the horrible touchpad arrangement on the W3J, where the sides and bottoms are hard-coded to be scroll areas, thankfully does not exist on the M1330. <a href="http://www.codinghorror.com/blog/archives/000600.html">I love touchpads</a>, and it <i>killed</i> me to have a crappily implemented one. That was my one major beef with the W3J.
</p>
<p>
<b>The XPS M1330 is a proper spiritual successor to my all-time favorite Inspiron 300M</b>. It's not <i>quite</i> the flyweight 3 pound champion the 300M was, but it's far more powerful and much more technologically advanced. It's also prettier, with its <a href="http://www.codinghorror.com/blog/archives/000218.html">remarkably un-Dell-like svelte, sleek design</a>. Be careful, though, because many of the things that make the M1330 so great are, bizarrely, add-on options-- like the solid-state hard drive, the LED display, the discrete NVIDIA 8400M GS graphics, and even the Bluetooth adapter. My only real criticism is the slot-load DVD writer; it's clever, but clever in an unnecessary way. Who still uses ye olde DVDs or CDs in this era of cheap 4 GB flash drives, broadband, and ubiquitous gigabit ethernet? I do wish they had dropped the optical drive to reduce the weight a bit further, but it's a minor complaint. Overall, I love the M1330, and I'd recommend it unconditionally to anyone who shares my preference for an uncompromising, ultralight laptop.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dell-xps-m1330-review/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Trojans, Rootkits, and the Culture of Fear ]]></title>
<link>https://blog.codinghorror.com/trojans-rootkits-and-the-culture-of-fear/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Scott Wasson at The Tech Report notes that <a href="http://techreport.com/ja.zz?comments=13029">two of his family members fell victim to the eCard email exploit</a> that has been making the rounds lately:
</p>
<p>
</p>
<blockquote>
I just dropped off a package containing my dad's laptop at the FedEx depot this afternoon. I spent parts of several days this week recovering his data, wiping the drive, and reinstalling the OS and key apps. My dad's a tech-savvy guy, but in a moment of weakness, he opened <a href="http://www.sophos.com/pressoffice/news/articles/2005/09/va_ecard.html">one of those greeting card spam messages</a> recently and his computer became infected with a trojan. The thing had installed a proxy for IE7 and rerouted all DNS queries to a compromised server, and then covered most if its tracks via a rootkit. I wiped the drive and started over because I didn't think I could be sure otherwise that the trojan was entirely removed from his system.
<p>
I went through the same thing with my wife's PC not long ago. She also knows better than to open attachments, but the greeting card thing caught her off guard somehow. Took her a while to admit that she'd gone through the steps of opening the email, clicking the link, downloading the payload, and running the executable. I lost a day's work, at least, to rebuilding that machine from the ground up.
</p>
<p>
Were it not for tools like <a href="http://www.microsoft.com/technet/sysinternals/Utilities/RootkitRevealer.mspx">Rootkit Revealer</a>, I might not have even been able to detect the trojans. One of them seemed to be attacking our antivirus software and trying to stop the Revealer process, even.
</p>
<p>
I could get mad at my relatives for making a mistake, but it's hard to see the point. The really frustrating thing is that they both had reason to believe a greeting card might be coming their way at the time and reason to be a little frazzled: my dad had brain surgery recently. These email-based attacks prey on those who might not be operating at 100% for whatever reason. That makes me white-hot mad.
</p>
<p>
Which makes me wonder: if it can happen to some fairly tech-savvy folks like these, how widespread is this problem? And what happens when your computer gets infected and you don't have a close relative who's a PC expert? The trojan on my wife's PC wasn't detected by <a href="http://www.microsoft.com/athome/security/spyware/software/default.mspx">Windows Defender</a>, <a href="http://www.avast.com/">Avast! antivirus</a>, or the <a href="http://www.microsoft.com/security/malwareremove/default.mspx">Windows Malicious Software Removal Tool</a>.
</p>
</blockquote>
<p>
I feel his pain. I went through a similar experience on one of my machines recently, which I documented in <a href="http://www.codinghorror.com/blog/archives/000888.html">How to Clean Up a Windows Spyware Infestation</a>. I'm sure I'd be even angrier if this had happened to someone more vulnerable, like my wife, or my father. But there are a few hard lessons to be learned here:
</p>
<p>
</p>
<ol>
<li>
<b>Stop Running As Administrator</b><br>
<p>
To answer the question Scott posed at the bottom of his post, the problem is <i>incredibly</i> widespread; it's a <a href="http://www.codinghorror.com/blog/archives/000891.html">Windows security epidemic</a>. The only real long-term solution for the Windows security epidemic is to <a href="http://www.codinghorror.com/blog/archives/000891.html">stop running as Administrator</a>. Vista's UAC is a marginally effective half-step at best. Why not emulate the UNIX operating sytems, which seem to be immune to most infections to date? When was the last time you heard of a Linux or FreeBSD user running anti-virus software? Or a Mac OS X user? A handful of antivirus programs exist for the Mac, but <a href="http://news.digitaltrends.com/featured_article79.html">they're largely snake oil, as they have little to protect against</a>.
</p>
<p>
If you take the advice to run as a non-administator, you may find that the standard user route is painful, too. I received an email from James Boswell that describes the difficulty:
</p>
<p>
</p>
<blockquote>
You and many others have been advocating the use of admin users and standard users on Windows.  I'm an experienced Windows developer too, and regularly build machines, but I've always had admin access for a single user.  This time, I am putting a Vista Home Premium 64 bit machine together for my son and thought I'd take your advice but I have really struggled with multi users.
<p>
When logged in as the standard user, installations of software are hit and miss.  For example, 3DMark06, Shockwave 10 and Gamespot Download Manager failed to install correctly as standard user (with admin priv. when prompted for password).  All 3 failed installs required me to switch user to the admin and repeat the installs.  Plus many installations require me to enter my password several times, not just during the install, but when the program runs for the first time (usually for firewall access or updates).
</p>
<p>
All of this is very unhelpful, because my son will no doubt want to install software during his use of the computer, and so will come to me saying "Dad, I want to install {Counter Strike | some web plugin | a screensaver} and Vista is bugging me again" so I will look at what he's installing and type my password in to approve access, and then I go back to what I was doing.  But I will now be waiting for the "DAD!!!Ã¢â‚¬Â¦ it doesn't work" follow up because the install failed.
</p>
<p>
I will then have to switch user to admin, repeat my son's actions to access the install program, wait for install to finish, run the app to approve any firewall or other permissions, and then log off.  I'm most definitely for the responsible parental control of PCs, but this is a monumental and entirely unnecessary waste of my time.
</p>
</blockquote>
<p>
This is partially the fault of Windows software developers who fail to test as standard user. It's disappointing, but understandable, since <b>running as Administrator has long been institutionalized in Windows</b>. It's also a particular problem for users who need to install lots of software for whatever reason. In contrast, my wife runs fine as limited user, but she almost never installs software of any kind. I hope more Windows developers are testing their software when running as a standard user, and in time running as a standard user will become as easy(ish) as it is on a Unix based OS.
</p>
<p>
</p>
<p>
</p>
</li>
<li>
<b>Traditional Anti-Virus Doesn't Work Any More</b><br>
<p>
The blacklist approach used by anti-virus vendors simply doesn't scale to today's threat environment. <a href="http://www.codinghorror.com/blog/archives/000715.html">Blacklists are never particularly effective</a>. But it's getting to the point where <a href="http://chuvakin.blogspot.com/2007/04/answer-to-my-antivirus-mystery-question.html">the illusion of protection afforded by a traditional anti-virus solution is <i>worse</i> than no protection at all</a>:
</p>
<p>
</p>
<blockquote>
Let's suppose somebody who is involved with incident response at a typical US public University collected a few recent malware samples from the compromised machines, and then submitted all the samples to VirusTotal for scanning against all current anti-virus and anti-virus-like products. What do you think the average detection rate is?
<p>
Let me give you the answer: it is 33%. In other words, <b>the average detection rate of malware from these "solutions" was 33%</b>, with the maximum at 50% and the minimum at 2%. Keep this number in mind, that shiny anti-virus product you just bought might be protecting you from just 2% of currently active and common malware (not some esoteric and custom uber-haxor stuff)!
</p>
<p>
I have to conclude what many security pundits were blabbing about for years: "mainstream" anti-virus is finally DEAD. It's a weak excuse for defense-in-depth, in about the same sense as wearing an extra shirt provides "another security layer" in a gun fight.
</p>
</blockquote>
<p>
Not only does anti-virus <a href="http://www.codinghorror.com/blog/archives/000803.html">cripple your machine's performance</a>, it doesn't even protect you adequately!  Even if your anti-virus or anti-malware solution is catching an incredibly optimistic 90% of threats, all it takes is <i>one new, undetected threat</i> to get through and your machine is thoroughly <a href="http://www.netscape.com/story/2006/10/05/cory-doctorows-keynote-from-toorcon-8/">0wned</a>.
</p>
<p>
And I do mean 0wned. These aren't your father's <a href="http://www.cert.org/incident_notes/IN-99-02.html">happy99.exe</a> trojans. Today's threats have evolved into very sophisticated beasts. I got a chill when Scott mentioned so casually that <b>the payload of the eCard trojan is a <a href="http://en.wikipedia.org/wiki/Rootkit">rootkit</a> that redirects all DNS queries to a compromised DNS server.</b> That's a worst case scenario which is becoming increasingly common. Good luck detecting a threat which subverts the very kernel of the operating system. Traditional programming techniques don't work; you need to fight fire with fire and hire kernel hackers of your own to pit them against. This leads to a kind of software armageddon that nobody can really "win": you're left with a wake of destroyed operating systems and thoroughly defeated users.
</p>
<p>
</p>
</li>
<li>
<b>The Mainstreaming of Virtual Machine Sandboxes</b><br>
<p>
Running as non-administrator should be absolutely standard, as it is one of the few security techniques which has a proven track record. But, with sufficient desire and initiative, naive or malicious users can still subvert the limited user account. <a href="http://www.codinghorror.com/blog/archives/000347.html">If users want to see the dancing bunnies bad enough</a> -- or, in Scott's case, they want to see the eCard someone "sent" them -- they'll type the administrator password in and escalate. Forget about protecting users from malicious threats. Now you have to deal with a far more difficult problem: <b>how do you protect users from <i>themselves?</i></b> I think <a href="http://www.codinghorror.com/blog/archives/000491.html">virtualization is the only rational way to protect users from themselves</a>-- and that's why virtualization is the next great frontier for computer security.
</p>
<p>
Full-machine virtualization as seen in <a href="http://www.microsoft.com/windows/products/winfamily/virtualpc/default.mspx">Virtual PC 2007</a> and <a href="http://www.vmware.com/">VMWare</a> is one way to achieve this, and it's a completely natural use for the obscene abount of local processing power we have on our desktops. But there's also software virtualization, which isolates all disk access from individual applications. Earlier this year, <a href="http://blogs.zdnet.com/security/?p=241">Google acquired GreenBorder technologies</a>, which used software virtualization to isolate the browser from the disk and completely prevent any malware attacks. Their product is no longer distributed while they do whatever it is they're doing as a part of Google, but for context, you can read <a href="http://www.pcmag.com/article2/0,1759,1980980,00.asp">a review of their original product, GreenBorder Pro, at PC Magazine</a>. Note the "does not need signature updates" notation in the review. With virtualization, you stop caring about blacklists and signature updates; you're protected against any possible threat, now or in the future.
</p>
<p>
Well, except for the <a href="http://www.eweek.com/article2/0,1895,1904647,00.asp">rare</a> <a href="http://www.heise-security.co.uk/articles/92241">threats</a> that target the virtualization layer, but that's a much tougher nut to crack.
</p>
</li>
</ol>
<p>
Most of all, <b>I dislike the culture of fear that permeates Windows security software marketing</b>. I don't think it's ethical to scare users into buying your security software product-- and it also creates a huge conflict of interest between the security software vendors and the virus, malware, and trojan creators. After all, why would we buy anti-virus software if, like Mac OS X users, we had <i>almost no risk</i> of being infected by a virus, malware, or trojan? Windows security software vendors need the threats-- and the more credible and fearsome the threats, the better-- to make money. They have no economic incentive to support an environment where threats are ineffective. <b>The status quo of weak Windows security suits them just fine. It sells their products</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I believe we can solve the Windows security epidemic without using fear as a marketing tactic. We need to <i>stop</i> relying on the illusory, expensive protection of anti-virus blacklists, and <i>start</i> implementing better solutions. We already have the ability to run as a limited user account today. It's too bad the powers that be at Microsoft didn't have the guts to pull the trigger on limited user accounts as a standard setup in Vista. But that shouldn't stop us. We should have the guts to <a href="http://www.codinghorror.com/blog/archives/000891.html">pull the trigger ourselves</a>. And if we add a little virtualization to the mix, I think we can almost completely eliminate most security threats. Windows anti-virus software is considered mandatory today. But I'd love to see a day where, as on OS X and every other Unix operating system variant, anti-virus software is viewed as unnecessary, even superfluous.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/trojans-rootkits-and-the-culture-of-fear/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Measuring Font Legibility ]]></title>
<link>https://blog.codinghorror.com/measuring-font-legibility/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you think of fonts as a bit of design esoterica, consider <a href="http://www.nytimes.com/2007/08/12/magazine/12fonts-t.html">this New York Times article</a> on the new Clearview typeface that will appear on all new highway road signs here in the United States:
</p>
<p>
</p>
<blockquote>
The problem sounded modest enough: Add more information to the state's road signs without adding clutter or increasing the physical size of the sign itself. But with the existing family of federally approved highway fonts -- a chubby, idiosyncratic and ultimately clumsy typeface colloquially known as Highway Gothic -- there was little you could add before the signs became visually bloated and even more unreadable than they already were. "I knew the highway signs were a mess, but I didn't know exactly why," Meeker recalled.
<p>
Around the same time Meeker and his team were thinking about how to solve the problem of information clutter in Oregon, the Federal Highway Administration was concerned with another problem. Issues of readability were becoming increasingly important, especially at night, when the shine of bright headlights on highly reflective material can turn text into a glowing, blurry mess. Highway engineers call this phenomenon halation and elderly drivers, now estimated to represent nearly a fifth of all Americans on the road, are most susceptible to the effect.
</p>
</blockquote>
<p>
I've always considered road signs a rich field for study, as <a href="http://www.codinghorror.com/blog/archives/000438.html">signage design has many parallels to modern GUI design in computer science</a>. The accompanying <a href="http://www.nytimes.com/slideshow/2007/08/12/magazine/20070812_CLEARVIEW_index.html">slideshow for the article</a> provides this image which illustrates the halation problem.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You could improve readability by simply making the font bigger. But this would result in billions of dollars spent on larger signs that increase visual clutter on the roadways. The Clearview font is an attempt to fundamentally improve readability with <i>better design</i> -- a completely redesigned typeface, optimized for highway use.
</p>
<p>
Here's a detailed comparison of the old FHWA typeface, Highway Gothic, and the new Clearview:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This isn't just aesthetics-- it also results in a practical benefit for drivers. That's the best kind of design, and like all the best designs, they provide the data to prove it:
</p>
<p>
</p>
<blockquote>
Intrigued by the early positive results, the researchers took the prototype out onto the test track. Drivers recruited from the nearby town of State College drove around the mock highway. From the back seat, Pietrucha and Garvey recorded at what distance the subjects could read a pair of highway signs, one printed in Highway Gothic and the other in Clearview. Researchers from 3M came up with the text, made-up names like Dorset and Conyer  --  words that were easy to read. <b>In nighttime tests, Clearview showed a 16 percent improvement in recognition over Highway Gothic</b>, meaning drivers traveling at 60 miles per hour would have an extra one to two seconds to make a decision.
</blockquote>
<p>
I've talked before about <a href="http://www.codinghorror.com/blog/archives/000449.html">font legibility experiments</a>, where fonts designed for the web allowed users to read faster. This isn't opinion; it's backed by actual experimental data. There was a <a href="http://psychology.wichita.edu/surl/usabilitynews/81/legibility.htm">more recent experiment from the same source</a> that also found even more benefits from the newest typefaces designed around RGB anti-aliasing. That's why I think <a href="http://www.codinghorror.com/blog/archives/000885.html">Microsoft's font rendering strategy is ultimately smarter than Apple's</a>.
</p>
<p>
So before you write off a design exercise as seemingly trivial as font choice, consider whether that tiny bit of design could improve the user experience, if only a little. And more importantly-- how would you <i>measure</i> the improvement?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/measuring-font-legibility/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Discipline Makes Strong Developers ]]></title>
<link>https://blog.codinghorror.com/discipline-makes-strong-developers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Scott Koon recently wrote about <a href="http://www.lazycoder.com/weblog/2007/08/08/the-number-one-trait-a-successful-developer-needs/">the importance of discipline</a> as a developer trait:</p>
<blockquote>
<p>Every month <a href="http://blog.codinghorror.com/why-do-we-have-so-many-screwdrivers/">a new programming language or methodology appears</a>, followed by devotees singing its praises from every corner of the Internet. All promising increases in productivity and quality. But there is one quality that all successful developers possess. One trait that will make or break every project.</p>
<p><b>Discipline.</b></p>
</blockquote>
<blockquote>
<p>An undisciplined developer will not be able to ship on time and will not write code that is easy to maintain. A disciplined developer will not only enable the success of a project, but will raise the level of productivity in others. Software architects and developers do themselves a disservice when they attribute their success to whatever methodology they have adopted. It really boils down to how disciplined you are.</p>
</blockquote>
<p>It's an interesting coincidence, because I recently gave a presentation to a group of developers on the topic of source control, and I found myself repeating that very same word throughout the presentation: discipline. Discipline. Discipline! I repeat it because <b>the mere <i>presence</i> of a great source control system doesn't obligate anyone to use it in a structured, rational way.</b> No. That takes discipline.</p>
<p>And not many shops, at least in my experience, <i>have</i> the right discipline. All too often, what I see in source control looks more like <a href="http://blog.codinghorror.com/desktopitis/">this Windows desktop</a>:</p>
<p><a href="http://www.codinghorror.com/blog/archives/000612.html"><img alt="image placeholder" >
<p>Instead of a nice, structured set of projects with logical branches and tags, what ends up in source control is a hairy furball of crazily named folders with no logical structure at all. Just like the average user's desktop.</p>
<p>And it doesn't matter what language you use, either. <a href="http://blog.codinghorror.com/you-can-write-fortran-in-any-language/">You can write FORTRAN in any language.</a></p>
<p>So I'm inclined to agree with Scott. <b>Without discipline, things like tools and languages are irrelevant.</b> But repeating the word "discipline" isn't exactly helpful, either. Perhaps what entry-level developers need is a programming mentor who isn't afraid to personally advocate the necessary discipline, someone hard, <a href="http://blog.codinghorror.com/showstopper/">someone like Dave Cutler</a>, or perhaps someone with the right motivational techniques to inspire discipline, like <a href="http://www.imdb.com/title/tt0093058/">Gunnery Sergeant Hartman</a>:</p>
<p><video poster="/content/images/2015/08/meet-gunnery-sergeant-hartman.jpg" width="100%" preload="none" controls><source src="http://discourse-cdn.codinghorror.com/uploads/default/original/3X/d/4/d49a8160af7a5de8d8894ecdc1866f695bf225bc.mp4"></source></video></p>
<blockquote>
<p>If you ladies leave my island, if you survive recruit training, you will be a weapon. You will be a minister of death praying for war. But until that day you are pukes. You are the lowest form of life on Earth. You are not even human f**ing beings. You are nothing but unorganized grabastic pieces of amphibian s**t. Because I am hard you will not like me. But the more you hate me the more you will learn. I am hard but I am fair. There is no racial bigotry here. I do not look down on ni**ers, kikes, wops or greasers. Here you are all equally worthless. And my orders are to weed out all non-hackers who do not pack the gear to serve in my beloved Corps. Do you maggots understand that?</p>
</blockquote>
<p>You can find the same advice stated in more prosaic terms in <a href="http://www.amazon.com/exec/obidos/ASIN/0735619670/codihorr-20">McConnell's Code Complete</a>:</p>
<blockquote>
<p>It's hard to explain to a fresh computer-science graduate why you need conventions and engineering discipline. When I was an undergraduate, the largest program I wrote was about 500 lines of executable code. As a professional, I've written dozens of utilities that have been smaller than 500 lines, but the average main-project size has been 5,000 to 25,000 lines, and I've participated in projects with over 500,000 lines of code. This type of effort requires not the same skills on a larger scale, but a new set of skills altogether.</p>
<p>In a 15-year retrospective on work at NASA's Software Engineering Laboratory, McGarry and Pajerski reported that the methods and tools that emphasize human discipline have been especially effective (1990). Many highly creative people have been extremely disciplined. "Form is liberating", as the saying goes. Great architects work within the constraints of physical materials, time, and cost. Great artists do, too. Anyone who has examined Leonardo's drawings has to admire his disciplined attention to detail. When Michelangelo designed the ceiling of the Sistine Chapel, he divided it into symmetric collections of geometric forms, such as triangles, circles, and squares. He designed it in three zones corresponding to the three Platonic stages. Without this self-imposed structure and discipline, the 300 human figures would have been merely chaotic rather than the coherent elements of an artistic masterpiece.</p>
</blockquote>
<p>Discipline takes many forms and permeates every aspect of software development. Start small. Say your database schema contains three primary key table columns named <code>list_id</code>, <code>ListId</code>, and <code>list_value</code>. There should be a Gunnery Sergeant Hartman on your development team who will.. <i>gently</i>.. remind the team that it might be a good idea to fix problems like this <i>before</i> they become institutionalized in all your future code.</p>
<p>You don't necessarily have to have a strict, rigid military code of conduct. Even though <a href="http://blog.codinghorror.com/fifty-years-of-software-development/">software engineering is a young field</a>, there are a lot of <a href="http://blog.codinghorror.com/what-is-modern-software-development/">accepted conventions that make up modern software development</a>. All it takes to benefit from those conventions is <b>a little old-fashioned discipline.</b> And if it doesn't start with <i>you</i>, then who?</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/discipline-makes-strong-developers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ YSlow: Yahoo's Problems Are Not Your Problems ]]></title>
<link>https://blog.codinghorror.com/yslow-yahoos-problems-are-not-your-problems/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I first saw <a href="http://developer.yahoo.com/performance/rules.html">Yahoo's 13 Simple Rules for Speeding Up Your Web Site</a> referenced in a <a href="http://www.skrenta.com/2007/05/14_rules_for_fast_web_pages_by_1.html">post on Rich Skrenta's blog</a> in May. It looks like there were originally 14 rules; one must have fallen off the list somewhere along the way.
</p>
<p>
</p>
<ol>
<li><a href="http://developer.yahoo.com/performance/rules.html#num_http">Make Fewer HTTP Requests</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#cdn">Use a Content Delivery Network</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#expires">Add an Expires Header</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#gzip">Gzip Components</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#css_top">Put CSS at the Top</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#js_bottom">Move Scripts to the Bottom</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#css_expressions">Avoid CSS Expressions</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#external">Make JavaScript and CSS External</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#dns_lookups">Reduce DNS Lookups</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#minify">Minify JavaScript</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#redirects">Avoid Redirects</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#js_dupes">Remove Duplicate Scripts</a></li>
<li><a href="http://developer.yahoo.com/performance/rules.html#etags">Configure ETags</a></li>
</ol>
<p>
It's solid advice culled from the excellent <a href="http://www.yuiblog.com/">Yahoo
User Interface blog</a>, which will soon be packaged into a <a href="http://www.amazon.com/exec/obidos/ASIN/0596529309/codihorr-20">
similarly excellent book</a>. It's also <a href="http://www.web2expo.com/presentations/webex2007/souders_steve.ppt">
available as a powerpoint presentation</a> delivered at the Web 2.0 conference.</p>
<p>
I've also covered similar ground in my post, <a href="http://www.codinghorror.com/blog/archives/000807.html">
Reducing Your Website's Bandwidth Usage</a>.</p>
<p>
But before you run off and implement all of Yahoo's solid advice, <strong>consider the audience</strong>. These are rules from Yahoo, which <a href="http://www.alexa.com/site/ds/top_500">according to Alexa</a> is one of the <strong>top three web properties in the world</strong>. And Rich's company, <a href="http://topix.net/">Topix</a>, is no slouch either-- they're in the top 2,000. It's only natural that Rich would be keenly interested in Yahoo's advice on how to <b>scale a website to millions of unique users per day.</b></p>
<p>
To help others implement the rules, Yahoo created a <a href="http://addons.mozilla.org/firefox/addon/1843">FireBug</a> plugin, <a href="http://developer.yahoo.com/yslow/">YSlow</a>. This plugin evaluates the current page using the 13 rules and provides specific guidance on how to fix any problems it finds. And best of all, the tool rates the page with a score-- a <i>score!</i> There's nothing we love more than <a href="http://www.codinghorror.com/blog/archives/000717.html">boiling down pages and pages of complicated advice to a simple, numeric score</a>. Here's my <s>report card</s> score for yesterday's post.</p>
<p>
<img alt="image placeholder" >
</p>
<p>
To understand the scoring, you have to dissect the weighting of the individual rules, <a href="http://codeclimber.net.nz/archive/2007/08/15/Dissecting-YSlow.aspx">as Simone Chiaretta did</a>:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="700">
<tr>
<td valign="top"><b><font color="red">Weight 11</font></b></td>
<td valign="top">3. <a href="http://developer.yahoo.com/performance/rules.html#expires">Add an Expires Header</a><br>
4. <a href="http://developer.yahoo.com/performance/rules.html#gzip">GZip Components</a><br>13. <a href="http://developer.yahoo.com/performance/rules.html#etags">Configure ETags</a>
</td>
</tr>
<tr>
<td valign="top"><b><font color="firebrick">Weight 10</font></b></td>
<td valign="top">2. <a href="http://developer.yahoo.com/performance/rules.html#cdn">Use a Content Delivery Network</a><br>
5. <a href="http://developer.yahoo.com/performance/rules.html#css_top">Put CSS at the Top</a><br>
10. <a href="http://developer.yahoo.com/performance/rules.html#minify">Minify JavaScript</a><br>11. <a href="http://developer.yahoo.com/performance/rules.html#redirects">Avoid Redirects</a>
</td>
</tr>
<tr>
<td valign="top"><b>Weight 5</b></td>
<td valign="top">9. <a href="http://developer.yahoo.com/performance/rules.html#dns_lookups">Reduce DNS Lookups</a><br>6. <a href="http://developer.yahoo.com/performance/rules.html#js_bottom">Move Scripts to the Bottom</a><br>12. <a href="http://developer.yahoo.com/performance/rules.html#js_dupes">Remove Duplicate Scripts</a>
</td>
</tr>
<tr>
<td valign="top"><b>Weight 4</b></td>
<td valign="top">1. <a href="http://developer.yahoo.com/performance/rules.html#num_http">Make Fewer Requests</a> (CSS)<br>1. <a href="http://developer.yahoo.com/performance/rules.html#num_http">Make Fewer Requests</a> (JS)</td>
</tr>
<tr>
<td valign="top"><b>Weight 3</b></td>
<td valign="top">1. <a href="http://developer.yahoo.com/performance/rules.html#num_http">Make Fewer Requests</a> (CSS background images)</td>
</tr>
<tr>
<td valign="top"><b>Weight 2</b></td>
<td valign="top">7. <a href="http://developer.yahoo.com/performance/rules.html#css_expressions">Avoid CSS Expressions</a>
</td>
</tr>
</table>
<p>
My YSlow score of 73 is respectable, but I've already made some changes to accommodate
its myriad demands. To get an idea of how some common websites score, <a href="http://codeclimber.net.nz/archive/2007/08/05/How-Slow-is-your-site-How-to-improve-the-performance.aspx">
Simone ran YSlow on
a number of blogs</a> and recorded the results:</p>
<ul>
<li>Google: A (99)
</li>
<li>Yahoo Developer Network blog : D (66)
</li>
<li>Yahoo! User Interface Blog : D (65)
</li>
<li>Scott Watermasysk : D (62)
</li>
<li>Apple : D (61)
</li>
<li>Dave Shea's mezzoblue : D (60)
</li>
<li>A List Apart : F (58)
</li>
<li>Steve Harman : F (54)
</li>
<li>Coding Horror : F (52)
</li>
<li>Haacked by Phil : F (36)
</li>
<li>Scott Hanselman's Computer Zen : F (29)
</li>
</ul>
<p>
YSlow is a convenient tool, but <strong>either the web is full of terribly inefficient
web pages</strong>, or there's something wrong with its scoring. I'll get to
that later.</p>
<p>
The Stats tab contains a summary of the total size
of your downloaded page, along with the footprint with and without browser caching. One of the key findings from Yahoo is that <a href="http://yuiblog.com/blog/2007/01/04/performance-research-part-2/">
40 to 60 percent of daily visitors have an empty cache</a>. So it behooves you
to optimize the size of <em>everything</em> and not rely on client browser caching to save to you
in the common case.</p>
<img alt="image placeholder" >
<p>
YSlow also breaks down the statistics in much more detail via the Components tab.
Here you can see a few key judgment criteria for every resource on your page...</p>
<ul>
<li>Does this resource have an explicit expiration date?</li>
<li>Is this resource compressed?</li>
<li>Does this resource have an ETag?</li>
</ul>
<p>
... along with the absolute sizes.</p>
<img alt="image placeholder" >
<p>
YSlow is a useful tool, but it can be dangerous in the wrong hands.
Software developers love optimization. <a href="http://www.flounder.com/optimization.htm">Sometimes too much</a>.
</p>
<p>
There's some good advice here, but there's also <strong>a lot of advice that only makes
sense if you run a website that gets millions of unique users per day</strong>.
Do you run a website like that? If so, what are you doing reading this instead of
flying your private jet to a Bermuda vacation with your trophy wife? The rest of
us ought to be a little more selective about the advice we follow. Avoid the temptation
to blindly apply these "top (x) ways to (y)" lists that are so popular on Digg and
other social networking sites. Instead, read the advice critically and think about
the consequences of implementing that advice.</p>
<p>
If you fail to read the Yahoo advice critically, you might make your site <em>slower</em>,
as <a href="http://www.haacked.com/archive/2007/08/13/speed-up-your-pages-and-improve-your-yslow-score-with.aspx">
as Phil Haack unfortunately found out</a>. While many of these rules are bread-and-butter
HTTP optimization scenarios, it's unfortunate that a few of the highest-weighted
rules on Yahoo's list are downright dangerous, if not flat-out <i>wrong</i> for smaller web
sites. And when you define "smaller" as "smaller than Yahoo", that's.. well, almost
everybody. So let's take a critical look at the most problematic heavily weighted advice
on Yahoo's list.</p>
<p>
<strong><a href="http://developer.yahoo.com/performance/rules.html#cdn">Use a Content
Delivery Network</a> (Weight: 10)</strong></p>
<p>
If you have to ask how much <a href="http://en.wikipedia.org/wiki/Content_Delivery_Network">
a formal Content Delivery Network</a> will cost, you can't afford it. It's more
effective to think of this as outsourcing the "heavy lifting" on your website--
eg, any large chunks of media or images you serve up -- to external sites that are
much better equipped to deal with it. This is one of the most important bits of
advice I provided in <a href="http://www.codinghorror.com/blog/archives/000807.html">
Reducing Your Website's Bandwidth Usage</a>. And using a CDN, below a reasonably Yahoo-esque traffic volume, can even <a href="http://www.haacked.com/archive/2007/08/13/speed-up-your-pages-and-improve-your-yslow-score-with.aspx">
slow your site down</a>.</p>
<p>
<strong><a href="http://developer.yahoo.com/performance/rules.html#etags">Configure
ETags</a> (Weight: 11)</strong></p>
<p>
ETags are a checksum field served up with each server file so the client can tell if the server resource is different
from the cached version the client holds locally. Yahoo recommends turning ETags
off because they cause problems on server farms due to the way they are generated
with machine-specific markers. So unless you run a server farm, you should ignore
this guidance. It'll only make your site perform worse because the client will have
a more difficult time determining if its cache is stale or fresh. It is possible
for the client to use the existing last-modified date fields to determine whether
the cache is stale, but <a href="http://perl.apache.org/docs/general/correct_headers/correct_headers.html#Last_Modified">
last-modified is a weak validator</a>, whereas <a href="http://perl.apache.org/docs/general/correct_headers/correct_headers.html#Entity_Tags">
Entity Tag (ETag) is a strong validator</a>. Why trade strength for weakness?</p>
<p>
<strong><a href="http://developer.yahoo.com/performance/rules.html#expires">Add an Expires
Header</a> (Weight: 11)</strong></p>
<p>
This isn't bad advice, per se, but it can cause huge problems if you get it wrong.
In Microsoft's IIS, for example, the Expires header is always turned off by default,
probably for that very reason. By setting an Expires header on HTTP resources, you're
telling the client to <em>never check for new versions of that resource</em>-- at
least not until the expiration date on the Expires header. When I say never, I mean
it -- the browser won't even <em>ask</em> for a new version; it'll just assume its
cached version is good to go until the client clears the cache, or the cache reaches
the expiration date. Yahoo notes that they change the filename of these resources
when they need them refreshed.
</p>
<p>
All you're really saving here is the cost of the
client pinging the server for a new version and getting a 304 not modified header
back in the common case that the resource hasn't changed. That's not
much overhead.. unless you're Yahoo. Sure, if you have a set of images or scripts
that almost <em>never</em>
change, definitely exploit client caching and turn on the <a href="http://www.mnot.net/cache_docs/#CACHE-CONTROL">Cache-Control header</a>. Caching is critical to browser performance; every web developer should have <a href="http://www.mnot.net/cache_docs/">a deep understanding of how HTTP caching works</a>.  But only use it in a surgical, limited way for those
specific folders or files that can benefit. For anything else, the risk outweighs the benefit. It's certainly not something you want turned on as a blanket default for your entire website.. unless you like changing filenames every time the content changes.</p>
<p>
I don't mean to take anything away from Yahoo's excellent guidance. <a href="http://developer.yahoo.com/performance/rules.html">
Yahoo's 13 Simple Rules for Speeding Up Your Web Site</a> and the companion
<a href="http://addons.mozilla.org/firefox/addon/1843">FireBug</a> plugin, <a href="http://developer.yahoo.com/yslow/">YSlow</a>, are outstanding
resources for the entire internet. By all means, read it. Benefit from it. Implement it. I've been
<a href="http://www.codinghorror.com/blog/archives/000059.html">banging away on the
benefits of GZip compression for years</a>.</p>
<p>
But also <strong>realize that Yahoo's problems aren't necessarily your problems</strong>. There is no such thing as one-size-fits-all guidance. Strive to <i>understand</i> the advice first, then implement the advice that makes sense for your specific situation. </p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/yslow-yahoos-problems-are-not-your-problems/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Thirteen Blog Cliches ]]></title>
<link>https://blog.codinghorror.com/thirteen-blog-cliches/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I <a href="http://www.codinghorror.com/blog/archives/000004.html">started out</a> in early 2004 as a blog skeptic. But over the last four years, I've become a <a href="http://www.codinghorror.com/blog/archives/000737.html">born-again         believer</a>. In that time, I've written almost a thousand blog entries, and     I've read thousands upon thousands of blog entries. As a result, I've developed     some rather strong opinions about what makes blogs work so well, and what makes     blogs sometimes <em>not</em> work so well.</p>
<p>I'd like to share some of the latter with you today, in a piece I call <strong>Thirteen Blog Cliches</strong>.</p>
<p>Before I start, realize that these are <em>my opinions</em>. That should be a redundant         statement on any blog, much less my own, but I'm putting the disclaimer out there         anyway. Just because I run my blog a certain way doesn't make it the right way – or even a very good way. These are preferences, not beliefs. Please don't be offended if         your blog, or a blog you enjoy, violates one of my so-called cliches. I'm         not trying to single any one person or blog out here. It's your blog,         and you don't have to answer to me. I'm just some guy on the internet. Run your blog as you see fit. These         are nothing more than broad observations formed over a period of four years where         I've been deeply immersed in blog culture.</p>
<p>You may not agree that these are cliches. You might even feel very strongly that         I'm wrong about all of this. That's what comments and trackbacks are for. Use them.</p>
<ol>
<li>
<strong>The Useless Calendar Widget</strong>
<p>This list isn't in any particular order, with one exception. There is nothing I dislike more than the redundant blog calendar widget. It's like a recurring canker sore we can't quite seem to rid ourselves of.</p>
<p><img alt="image placeholder" >
<p>I can't think of a <em>single</em> time I have ever found the blog calendar widget helpful. My computer already has a calendar function, so it's not like I need another calendar displayed in my web browser. Every post carries an obvious datestamp, so I can easily discern when it was published. But knowing whether someone posted an entry on the third tuesday of the month? Utterly useless.</p>
<p>The calendar widget is the vestigial tail of blog engines, evidence of our primordial ancestors. But we've evolved; it's time to lose the tail. Surely there's something more useful we could put in that space.</p>
</li>
<li>
<strong>Random Images Arbitrarily Inserted In Text</strong>
<p>One of the cardinal rules of <a href="http://www.useit.com/papers/webwriting/">web writing</a> is to <strong>avoid large blocks of text</strong>. There are plenty of <a href="http://www.useit.com/alertbox/9703b.html">excellent web writing guides</a> that exhort you to break up your text, using bullets, numbered lists, quotes, paragraph breaks, images – anything, <em>anything</em> to avoid creating an intimidating wall of dense, impenetrable text.</p>
<p>And they're right. That's what you should do. I do it all the time. I'm doing it <em>right now</em>.</p>
<p>But like all good advice, it can be taken too far. For example, when you find yourself inserting random pictures into your writing for the sole purpose of breaking up     the text.</p>
<p><img alt="image placeholder" >
<p>In the above snippet, what does that image have to do with the text? As far as I can tell, absolutely nothing at all. I see this on a disturbing number of blogs and feeds that I regularly read. It's probably due to the influence of <a href="http://philip.greenspun.com/">Philip Greenspun</a> and his seminal book, <a href="http://www.amazon.com/exec/obidos/ASIN/1558605347/codihorr-20"> Philip and Alex's Guide to Web Publishing</a>, where the text is juxtaposed with random photographs     that Philip has taken. It's one of the earliest and best references on web development,     and the fact that it's still relevant today despite its age speaks volumes about     the quality of Mr. Greenspun's writing. But it's the writing that makes the book     a classic, not the amateur photography sprinkled throughout its pages.</p>
<p>As the old adage goes, <em>a picture is worth a thousand words</em>. <strong>But y<strong>ou     should no more insert a random image into your writing than you would insert a thousand     random words into your writing.</strong></strong> I don't care how beautiful your photographs are, it's a terrible, irresponsible practice that distracts and harms readability.</p>
<p>And those of you sitting there smugly, with your stock photo library and your peripherally, tangentially, almost-but-not-quite related images that you use to break up your text, don't think I'm not talking about you, either. Because I am. Think about that the next time you read an article about a "web 2.0 bubble" accompanied by – you guessed it – a stock photo of a child blowing a bubble.</p>
<p>Images are <em>not</em> glorified paragraph breaks. Images should contribute to the content and meaning of the article in a substantive way. And if they don't, they should be cut. Mercilessly.</p>
</li>
<li>
<strong>No Information on the Author </strong>
<p>When I find well-written articles on blogs that I want to cite, I take <a href="http://www.25hoursaday.com/weblog/CommentView.aspx?guid=7a664ec4-f533-4b21-8769-9fbd47179b12">great pains to get the author's name right</a> in my citation. If you've written something worth reading on the internet, you've joined a rare club indeed, and you deserve proper attribution. It's the least I can do.</p>
<p>That's assuming I can <em>find</em> your name.</p>
<p>To be fair, this doesn't happen often. But it shouldn't <em>ever</em> happen. The lack of an "About Me" page – or a simple name to attach to the author's writing – is unforgivable. But it's still a problem today. Every time a reader encounters a blog with no name in the byline, no background on the author, and no simple way to click through to find out <em>anything</em> about the author, it strains credulity to the breaking point. It devalues not only the author's writing, but the credibility of blogging in general.</p>
<p>Maintaining a blog of any kind takes quite a bit of effort. It's irrational to expend that kind of effort without putting your name on it so you can benefit from it. And so we can too. It's a win-win scenario for you, Mr. Anonymous.</p>
</li>
<li>
<strong>Excess Flair</strong>
<p><a href="http://www.imsdb.com/scripts/Office-Space.html"> I'd like to talk to you about your flair</a>.</p>
<p>Blogs work because they're simple. When we <a href="http://www.codinghorror.com/blog/archives/000587.html"> clutter up our blogs</a> with a zillion widgets,         features, and add-ons, we're destroying an essential part of what makes blogs worthwhile.</p>
<p><img alt="image placeholder" >
<p>I've lost track of all the times I've clicked on an image in a blog and been hijacked         by some crazy JavaScript image loading technique, when a simple link to the image         would have sufficed – and probably would have been faster and more convenient. Or when I've moused over an unassuming hyperlink and had an         annoying, superfluous image preview of the link pop up when I didn't want it to.         And do your readers really want to see pictures of the last 10 visitors to your         blog?</p>
<p>Before you add a new "feature" to your blog, consider whether this feature         will be useful enough to your readers to overcome the additional complexity it adds to         the page. Hint: almost none of them are.</p>
</li>
<li>
<strong>The Giant Blogroll</strong>
<p>I'm all for linking generously to outside content. We all <a href="http://en.wikiquote.org/wiki/Isaac_Newton"> stand on the shoulders of giants</a>, after all. Although if you look down in     today's world, you might find that you're standing on lots and lots of midgets.     Large or small, we owe them a debt of gratitude.</p>
<p>Citing your references and influences is a great and necessary thing, but obsessively     listing every single blog you read – the so-called "blogroll" – is just noise.</p>
<p><img alt="image placeholder" >
<p>If you're really reading this many blogs, you should be linking to them organically         in your blog posts, in a sort of natural quid pro quo. Wearing a giant blogroll         on your sleeve is an empty gesture. I'm reminded of the distasteful way that blogs         in giant ad networks (such as Weblogs, Inc) spam every page with a huge list of internal         links to their other blogs. It feels artificial and insincere.</p>
<p>Publish your <a href="http://en.wikipedia.org/wiki/OPML">OPML</a> if you think organic links in your writing aren't telling the whole story, but avoid cluttering up your page with a huge, spammy blogroll.</p>
</li>
<li>
<strong>The Nebulous Tag Cloud</strong>
<p>I'm a big fan of tagging. It's <a href="http://www.codinghorror.com/blog/archives/000246.html"> far superior to the old method of placing everything in hierarchical folders</a>.     Tag categories on blogs are moderately useful, particularly for bloggers who tend     to bounce around among many different topics. What I've <em>never</em> found useful,     however, is the stereotypical tag cloud visualization, where the size of the tag     word varies with its frequency. </p>
<p><img alt="image placeholder" >
<p>The perception is that tag cloud visualizations are cool, like badges of honor for         the tagging club. The reality is that tag cloud visualizations are chaotic, noisy,         and unusable. Keep the tagging, lose the cloud. A simple sorted list of tags, along         with the number of posts associated with each tag, is much more effective.</p>
</li>
<li>
<strong>Excessive Advertisements</strong>
<p>Advertising is a fact of life. People need to feed their starving children. I get it. I've even <a href="http://www.codinghorror.com/blog/archives/000893.html">reluctantly entered the field myself</a>. But is it really necessary to make your blog look like <a href="http://www.flickr.com/photos/stuckincustoms/440698504/">Times Square</a>? Does every square inch of whitespace <em>have</em> to be filled with paid links, Google AdSense, and ad banners?</p>
<p><img alt="image placeholder" >
<p>In the process of researching this article, I found <a href="http://www.sitepronews.com/archives/2007/jan/15.html">a related article on blog usability</a> that's a perfect – even ironic – example of how you can hurt your usability with excessive, obnoxious advertising. It's everywhere.</p>
<p>It is almost <em>never</em> in the reader's interest to see advertisements, so my advice is to tread very lightly, and be respectful of your audience. Bad advertising is so prevalent that if you take the time to advertise responsibly, you may find that readers appreciate you for it.</p>
<p>Well, probably not, but it can't hurt to try.</p>
</li>
<li>
<strong>This Ain't Your Diary</strong>
<p>I don't begrudge anyone their right to post whatever it is they think they need to post on their blog. But let's be perfectly clear: <a href="http://www.codinghorror.com/blog/archives/000536.html">your readers aren't coming to your blog to read about you</a>. They're coming to your blog to find out <a href="http://headrush.typepad.com/creating_passionate_users/2005/01/users_shouldnt_.html">what it can do for them</a>. If you find your blog <a href="http://www.pepysdiary.com/">turning into a diary</a> of your daily activities, you'll have a very limited audience unless you happen to be a real world celebrity. Even my wife isn't particularly interested in the minutiae of what I do every day. Why would I expect my readers to be?</p>
<p><img alt="image placeholder" >
<p>That said, blogs are a place for writers to find an interested audience, and a place for readers to find a helpful peer and a unique voice. It's <a href="http://software.ericsink.com/entries/Goodbye_Sadie.html">OK to be yourself</a>; at some level, it is a cult of personality: people are reading not only because your content     is useful to them, but because they like you. It's normal to inject a regular dose of yourself into the conversation.</p>
<p>But like Tabasco sauce and other powerful seasonings, a little YOU goes a long way. A <em>really</em> long way.  Write accordingly.</p>
</li>
<li>
<strong>Sorry I Haven't Written in a While</strong>
<p>If you haven't posted anything new to your blog in a while, don't waste our time with apologies. Just write! The best apology is new and improved content. Maybe with a wee bit more consistency this time, though.</p>
<p>The most important piece of advice I give anyone who asks me about blogging is this: <strong>pick a schedule you can live with, and stick to it</strong>. That <a href="http://www.codinghorror.com/blog/archives/000910.html">doesn't mean you should post substandard crap</a>, of course, but I find that <a href="http://www.codinghorror.com/blog/archives/000187.html">talent is far less important than enthusiasm</a>. And the best way to demonstrate your enthusiasm – and to improve – is to get out there and <em>write</em>. Regularly.</p>
<p>And if you can't muster the enthusiasm for writing regularly, move on. But don't stop creating.</p>
</li>
<li>
<strong>Blogging About Blogging</strong>
<p>I find meta-blogging – blogging about blogging – <em>incredibly</em> boring. I said as much in <a href="http://www.dailyblogtips.com/interview-with-jeff-atwood-from-coding-horror/">a recent interview</a> on a site that's all about blogging (hence the title, Daily Blog Tips). I wasn't trying to offend or shock; I was just being honest. Sites that contain nothing but tips on how to blog more effectively bore me to tears.</p>
<p>If you accept the premise that most of your readers are <em>not</em> bloggers, then it's highly likely they won't be amused, entertained, or informed by a continual stream of blog entries on the art of blogging. Even if they're filled with extra bloggy goodness.</p>
<p>Meta-blogging is like masturbating. Everyone does it, and there's nothing wrong with it. But writers who regularly get out a little to explore other topics will be healthier, happier, and ultimately more interesting to be around – regardless         of audience.</p>
</li>
<li>
<strong>Mindless Link Propagation</strong>
<p>One of the most pernicious problems in blogging is the <a href="http://chris.pirillo.com/2006/08/18/10-ways-to-eliminate-the-echo-chamber/"> echo chamber effect</a>. Most blog entries merely regurgitate what other people have said or add vapid commentary on top of news articles and press releases. Only the tiniest fraction of blog entries are original content, and only a tiny fraction of         that fraction is worth your time. One of my very favorite articles is <a href="http://chris.pirillo.com/2006/08/18/10-ways-to-eliminate-the-echo-chamber/"> Chris Pirillo's piece on 10 Ways to Eliminate the Echo Chamber</a>. Chris has         been blogging for a very, very long time and he has the battle scars to prove it.         This call to action should be required reading for every blogger. With pop quizzes.</p>
<p>It's always been deeply disappointing to me that <strong>we have the whole of human history         to talk about, and most people can't get past what happened <em>today</em></strong>.         If I wanted news, I'd visit one of the hundreds of news sites that do nothing but         news every day. Putting yourself in the news business is a thankless, unending grind.         Don't do it.</p>
<p><img alt="image placeholder" >
<p>If everyone knows about it, what value does that information have? Three years from         now, will anyone care that Apple released a new iPod on that particular day? My         advice here is almost contrarian: if everyone else is talking about it, that means you should         <em>avoid</em> talking about it. Switch things up. Seek out uncommon sites with         unique information. Dig down to original sources and read the material everyone         is commenting (comments on top of comments on top of comments) endlessly on.</p>
<p>If all you can find to talk about is what's already popular, you're not trying hard enough. Form your own opinion. Do your own research. Go out of your way to blaze a new trail and create something we haven't already seen hundreds of times before.</p>
</li>
<li>
<strong>Top (n) Lists</strong>
<p>Yes, exactly like this one.</p>
<p>The problem with Top (n) Lists is that they become <a href="http://www.codinghorror.com/blog/archives/000578.html"> a substitute for critical thinking</a>,         the classic, laziest possible use of Cliff's Notes that every college professor and high school teacher fears. You're supposed to read the book, then read the Cliff's Notes as a companion to the book – not use the Cliff's notes as a substitute for <em>reading</em> the book.</p>
<p><img alt="image placeholder" >
<p>Lists are a great convention. They make sense, people understand them, and they're         a logical way to structure your writing. But <a href="http://www.codinghorror.com/blog/archives/000932.html"> don't let lists become a crutch</a>. I'm always taken aback when I see the "most         popular" posts on a blog dominated by Top (n) Lists. Shortcuts are only meaningful         if you know what it is, exactly, you're cutting. If all you read is whatever Top         (n) Lists have managed to float to the top of today's Reddit or Digg homepage, then you've cheated yourself out of the deeper experience of reading a complete book.</p>
<p>If you find that the Top (n) List convention is a go-to tool in your writing toolkit,         consider rebalancing your writing portfolio with longer, more in-depth pieces as well.         Not everything should be a sprint; throw a few small marathons in there somewhere         to complement your short distance skills.</p>
</li>
<li>
<strong>No Comments Allowed</strong>
<p><a href="http://www.codinghorror.com/blog/archives/000538.html">A blog without comments is not a blog</a>. Yes, there are exceptions for massively popular blogs where <a href="http://many.corante.com/archives/2007/07/20/spolsky_on_blog_comments_scale_matters.php">comments clearly don't scale</a>. But until that applies, the value of the two-way conversation far outweighs any minor inconvenience on your part. Writing is inconvenient. Get used to it, and get over yourself. The sum total of community contributions is far more useful than any one thing you'll ever write.</p>
<p>Besides, It's an open secret in the blogging community that <strong>the comments are often better than the original blog entry itself</strong>. Would you browse Amazon without the user reviews? No? Then why would you willingly choose to run your blog that way?</p>
<p>Don't be afraid of comments. Embrace them. Moderate them. The community will respect you for it, and your blog will be better for it as well.</p>
</li>
</ol>
<p>This piece ended up being much longer than I originally intended. But I've had a     lot of this stuff on my chest for years, and I wanted to do it justice.     I also needed to explain myself in a constructive way so I don't end up offending     <em>too</em> many people.</p>
<p>I've already broken at least two of my own rules with this very post. How cliche.</p>
<p>Discuss.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/thirteen-blog-cliches/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Leading by Example ]]></title>
<link>https://blog.codinghorror.com/leading-by-example/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It takes discipline for development teams to benefit from <a href="http://www.codinghorror.com/blog/archives/000643.html">modern software engineering conventions</a>. If your team doesn't have the right kind of engineering discipline, the tools and processes you use are almost irrelevant. I advocated as much in <a href="http://www.codinghorror.com/blog/archives/000931.html">Discipline Makes Strong Developers</a>.
</p>
<p>
But some commenters were understandably apprehensive about the idea of having a <a href="http://www.youtube.com/results?search_query=gunnery%20sergeant%20hartman&amp;search=Search">Senior Drill Instructor Gunnery Sergeant Hartman</a> on their team, enforcing engineering discipline.
</p>
<p>
</p>
<blockquote>
<a href="http://www.imdb.com/title/tt0093058/quotes"><img alt="image placeholder" >
<p>
You little scumbag! I've got your name! I've got your ass! You will not laugh. You will not cry. You will learn by the numbers. I will teach you.
</p>
</blockquote>
<p>
Cajoling and berating your coworkers into compliance isn't an effective motivational technique for software developers, at least not in my experience. <b>If you want to pull your team up to a higher level of engineering, you need a leader, not an enforcer.</b> The goal isn't to brainwash everyone you work with, but to negotiate commonly acceptable standards with your peers.
</p>
<p>
I thought Dennis Forbes did an outstanding job of summarizing effective leadership strategies in his post <a href="http://www.yafla.com/dennisforbes/Effectively-Integrating-Into-Software-Development-Teams/Effectively-Integrating-Into-Software-Development-Teams.html">effectively integrating into software development teams</a>. He opens with a hypothetical (and if I know Dennis, probably autobiographical) email that describes <b>the pitfalls of being perceived as an enforcer</b>:
</p>
<p>
</p>
<blockquote>
I was recently brought in to help a software team get a product out the door, with a mandate of helping with some web app code. I've been trying my best to integrate with the team, trying to earn some credibility and respect by making myself useful.
<p>
I've been forwarding various <a href="http://www.joelonsoftware.com/">Joel On Software</a> essays to all, recommending that the office stock up on <a href="http://www.amazon.com/exec/obidos/ASIN/0735619670/codihorr-20">Code Complete</a>, <a href="http://www.amazon.com/exec/obidos/ASIN/0932633439/codihorr-20">Peopleware</a>, and <a href="http://www.amazon.com/exec/obidos/ASIN/0201835959/codihorr-20">The Mythical Man Month</a>, and I make an effort to point out everything I believe could be done better. I regularly browse through the source repository to find ways that other members could be working better.
</p>
<p>
When other developers ask for my help, I try to maximize my input by broadening my assistance to cover the way they're developing, how they could improve their typing form, what naming standard they use, to advocate a better code editing tool, and to give my educated final word regarding the whole stored procedure/dynamic SQL debate.
</p>
<p>
Despite all of this, I keep facing resistance, and I don't think the team likes me very much. Many of my suggestions aren't adopted, and several people have replied with what I suspect is thinly veiled sarcasm.
</p>
<p>
What's going wrong?
</p>
</blockquote>
<p>
I'm sure we've all worked with someone like this. Maybe we were even that person ourselves. Even with the best of intentions, and armed with <a href="http://www.codinghorror.com/blog/archives/000020.html">the top books on the reading list</a>, you'll end up like Gunnery Sergeant Hartman ultimately did: gunned down by your own team.
</p>
<p>
At the end of his post, Dennis provides <a href="http://www.yafla.com/dennisforbes/Effectively-Integrating-Into-Software-Development-Teams/Effectively-Integrating-Into-Software-Development-Teams.html">a thoughtful summary of how to avoid being shot by your own team</a>:
</p>
<p>
</p>
<blockquote>
<b>Be humble.</b> Always first presume that you're wrong. While developers do make mistakes, and as a new hire you should certainly assist others in catching and correcting mistakes, you should try to ensure that you're certain of your observation before proudly declaring your find. It is enormously damaging to your credibility when you cry wolf.
<p>
<b>Be discreet with constructive criticism.</b> A developer is much more likely to be accept casual suggestions and quiet leading questions than they are if the same is emailed to the entire group. Widening the audience is more likely to yield defensiveness and retribution. The team is always considering what your motives are, and you will be called on it and exiled if you degrade the work of others for self-promotion.
</p>
<p>
<b>The best way to earn credibility and respect is through hard work and real results.</b> Cheap, superficial substitutes -- like best practice emails sent to all, or passing comments about how great it would be to implement some silver bullet -- won't yield the same effect, and are more easily neutralized.
</p>
<p>
<b>Actions speak louder than words.</b> Simply talking about implementing a team blog, or a wiki, or a new source control mechanism, or a new technology, is cheap. Everyone knows that you're just trying to claim ownership of the idea when someone eventually actually does the hard work of doing it, and they'll detest you for it. If you want to propose something, put some elbow grease behind it. For instance, demonstrate the foundations of a team blog, including preliminary usage guidelines, and a demonstration of all of the supporting technologies. This doesn't guarantee that the initiative will fly, and the effort might be for naught, but the team will identify that it's actual motiviation and effort behind it, rather than an attempt at some easy points.
</p>
<p>
<b>There is no one-size-fits-all advice.</b> Not every application is a high-volume e-commerce site. Just because that's the most common best-practices subject doesn't mean that it's even remotely the best design philosophies for the group you're joining.
</p>
</blockquote>
<p>
What I like about Dennis' advice is that it focuses squarely on action and results. It correlates very highly with what I've personally observed to work: <b>the most effective kind of technical leadership is leading by example</b>. All too often there are no development leads with the time and authority to enforce, even if they wanted to, so <a href="http://www.codinghorror.com/blog/archives/000689.html">actions become the only currency</a>.
</p>
<p>
But actions alone may not be enough. You can spend a lifetime learning how to lead and still not get it right. Gerald Weinberg's book <a href="http://www.amazon.com/exec/obidos/ASIN/0932633021/codihorr-20">Becoming a Technical Leader: an Organic Problem-Solving Approach</a> provides a much deeper analysis of leadership that's specific to the profession of software engineering.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0932633021/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Within the first few chapters, Weinberg cuts to the very heart of the problem with both Gunnery Sergeant Hartman's and Dennis Forbes' hypothetical motivational techniques:
</p>
<p>
</p>
<blockquote>
How do we want to be helped? I don't want to be helped out of pity. I don't want to be helped out of selfishness. These are situations in which the helper really cares nothing about me as a human being. What I would have others do unto me is to love me-- not romantic love, of course, but true human caring.
<p>
So, if you want to motivate people, either directly or by creating a helping environment, you must first convince them that you care about them, and the only sure way to convince them is by actually caring. People may be fooled about caring, but not for long. That's why the second version of the Golden Rule says, "Love thy neighbor", not "Pretend you love thy neighbor." Don't fool yourself. If you don't really care about the people whom you lead, you'll never succeed as their leader.
</p>
</blockquote>
<p>
Weinberg's <a href="http://www.amazon.com/exec/obidos/ASIN/0932633021/codihorr-20">Becoming a Technical Leader</a> is truly a classic. It is, quite simply, the thinking geek's <a href="http://www.amazon.com/exec/obidos/ASIN/0671723650/codihorr-20">How to Win Friends and Influence People</a>. So much of leadership is learning to give a damn about other people, something that us programmers are notoriously bad at. We may <a href="http://www.codinghorror.com/blog/archives/000761.html">love our machines and our code</a>, but our teammates prove much more complicated.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/leading-by-example/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Not To Write a Technical Book, Epilogue ]]></title>
<link>https://blog.codinghorror.com/how-not-to-write-a-technical-book-epilogue/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I arrived at work today to find this package.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's from one "C. Petzold", <a href="http://www.codinghorror.com/blog/archives/000427.html">whoever the heck that is</a>.
</p>
<p>
Inside was a copy of the book <a href="http://www.amazon.com/exec/obidos/ASIN/0735623945/codihorr-20">3D Programming for Windows: Three-Dimensional Graphics Programming for the Windows Presentation Foundation</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0735623945/codihorr-20"><img alt="image placeholder" >
</p>
<p>
It's even inscribed:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This is, of course, a reference to my post <a href="http://www.codinghorror.com/blog/archives/000846.html">How Not To Write a Technical Book</a>, in which I rather harshly called Petzold's <a href="http://www.amazon.com/exec/obidos/ASIN/0735619573/codihorr-20">previous book</a> "a greyscale sea of endless text and interminable code", and compared it very unfavorably with <a href="http://www.amazon.com/exec/obidos/ASIN/0672328917/codihorr-20">Adam Nathan's book on the same topic</a>.
</p>
<p>
I can't speak for the quality of the book, as I haven't had time to read it yet. But if nothing else, it tells us that Charles Petzold has a good sense of humor. (And, indirectly, it demonstrates <a href="http://www.codinghorror.com/blog/archives/000834.html">the value of an "about me" page on your blog</a> with your contact information.)
</p>
<p>
Thanks, Mr. Petzold.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-not-to-write-a-technical-book-epilogue/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ URL Shortening: Hashes In Practice ]]></title>
<link>https://blog.codinghorror.com/url-shortening-hashes-in-practice/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've become a big fan of <a href="http://twitter.com">Twitter</a>. My philosophy is, <a href="http://www.codinghorror.com/blog/archives/000840.html">when in doubt, make it public</a>, and Twitter is essentially public instant messaging. This suits me fine. Well, when Twitter is actually up and running, at least. Its <a href="http://www.codinghorror.com/blog/archives/000838.html">bouts of frequent downtime are legendary</a>, even today.
</p>
<p>
(I was going to put a screenshot of one of my favorite Twitter messages here, but as I write this Twitter is down. Again. No, I'm not kidding. OK, it's back up.)
</p>
<p>
<a href="http://twitter.com/codinghorror"><img alt="image placeholder" >
</p>
<p>
One of the design constraints of Twitter is that every message is limited to 140 characters. You quickly learn to embrace and live within those constraints, but if you like to post URLs in your Twitter messages like I do, those 140 characters become very dear. That's probably why <b>Twitter automatically converts any URLs over about 30 characters to short URLs using the <a href="http://tinyurl.com/">TinyUrl</a> service</b>.
</p>
<p>
For instance, let's say I wanted to make a shortened URL version of <a href="http://forums.construx.com/blogs/stevemcc/default.aspx">Steve McConnell's blog</a>.
</p>
<p>
<a href="http://forums.construx.com/blogs/stevemcc/default.aspx">http://forums.construx.com/blogs/stevemcc/default.aspx</a>
</p>
<p>
It's not a particularly long URL, but every character matters when it comes to Twitter. I found <a href="http://lists.econsultant.com/top-10-url-redirection-services.html">a list of common URL shortening services</a>, so let's see how they compare:
</p>
<p>
</p>
<ul>
<li>
<a href="http://qurl.net/1YU">http://qurl.net/1YU</a>
</li>
<li>
<a href="http://rurl.org/808">http://rurl.org/808</a>
</li>
<li>
<a href="http://jtty.com/cuy">http://jtty.com/cuy</a>
</li>
<li>
<a href="http://elfurl.com/li4na">http://elfurl.com/li4na</a>
</li>
<li>
<a href="http://shurl.org/pHbnD">http://shurl.org/pHbnD</a>
</li>
<li>
<a href="http://shrinkster.com/s9y">http://shrinkster.com/s9y</a>
</li>
<li>
<a href="http://tinyurl.com/yvvtag">http://tinyurl.com/yvvtag</a>
</li>
<li>
<a href="http://clipurl.com/?PAP269">http://clipurl.com/?PAP269</a>
</li>
<li>
<a href="http://shorl.com/dihyfradiduba">http://shorl.com/dihyfradiduba</a>
</li>
</ul>
<p>
Looks like the best we can do is 3 characters to represent the URL, along with a mandatory 16 characters for the protocol, domain name (everyone drops the leading "www"), and slashes. That's a total of <b>19 characters</b>, a nice improvement over the <b>54 characters</b> that make up the original URL. But using an URL shortening and redirection service isn't without pitfalls of its own.
</p>
<p>
</p>
<ol>
<li>What if the URL redirection service goes belly up, as the <a href="http://www.37signals.com/svn/archives2/tinyurl_vs_url123.php">once-popular url123.com</a> did? All your previous hyperlinks are instantly and forever broken. What if the redirection service is only sporadically available? That's arguably even worse.
</li>
<li>The URL no longer contains any hints whatsoever as to the content of the URL. It's completely opaque. The only way to find out what's behind that hyperlink is to actually click on it. This is not a great user experience for the person doing the clicking.
</li>
<li>URL redirection services are often used by questionable people for nefarious reasons. Another service, <a href="http://lnk.to/">lnk.to</a>, was shut down because of all the spammers abusing their service.
</li>
</ol>
<p>
Despite all the potential problems, URL shortening services are still useful in the right circumstances. For example, sending out very long hyperlinks in email is always risky; you never know when the email clients will insert line breaks in the links and render them unclickable. Not to mention mobile devices, where space is always at a premium.
</p>
<p>
<b>I often wonder why Google doesn't offer an URL redirection service</b>, as they already keep an index of every URL in the world. The idea of Google disappearing tomorrow, or having availability problems, is far less likely than the seemingly random people and companies who operate these URL redirection services-- often for no visible income.
</p>
<p>
But what really struck me about these services is how they're <b>a perfect embodiment of a classical computer science concept-- the <a href="http://en.wikipedia.org/wiki/Hash_table">hash table</a></b>:
</p>
<p>
</p>
<blockquote>
In computer science, a hash table, or a hash map, is a data structure that associates keys with values. The primary operation it supports efficiently is a lookup: given a key (e.g. a person's name), find the corresponding value (e.g. that person's telephone number). It works by transforming the key using a hash function into a hash, a number that is used to index into an array to locate the desired location ("bucket") where the values should be.
</blockquote>
<p>
It doesn't get more fundamental than the keys and values of our beloved hash tables. But some of the services use an absurdly small number of characters as keys-- <b>1YU, 808, cuy</b> -- to <i>represent the entire Steve McConnell blog URL</i>. Thinking about how they did that leads you to some interesting solutions. For instance, let's compare <a href="http://www.fileformat.info/tool/hash.htm?text=http%3A%2F%2Fforums.construx.com%2Fblogs%2Fstevemcc%2Fdefault.aspx%0A">the result of applying traditional hash functions</a> to Steve's blog URL:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="500">
<tr>
<td>Adler32</td>
<td>399014e3</td>
</tr>
<tr>
<td>CRC32</td>
<td>78aa9d1a</td>
</tr>
<tr>
<td>MD2</td>
<td>286c50c2db4fcad77adb4edeb3a937b2</td>
</tr>
<tr>
<td>MD4</td>
<td>387ac3f6aae7956c4fab176271bb4518</td>
</tr>
<tr>
<td>MD5</td>
<td>f061a171dfc30635462850684f98b886</td>
</tr>
<tr>
<td>SHA-1</td>
<td>3c93b6d332091b2970fb660d644d0ba3d756e322</td>
</tr>
</table>
<p>
Even the shortest hash function, the 32-bit CRC, is a bit too long for this usage. That's 4 bytes which will be at least five ASCII characters. To get a shorter URL, you'd have to switch to a 16-bit CRC. If you're <a href="http://www.codinghorror.com/blog/archives/000409.html">clever about how you turn those 16 bits into printable characters</a>, you just might be able to fit those 2 bytes into three ASCII characters.
</p>
<p>
But is a 16 bit hash enough to represent <i>every URL in the universe</i>? Rich Skrenta <a href="http://www.skrenta.com/2007/08/md5_tutorial.html">helps us out with a little hash math</a>:
</p>
<p>
</p>
<blockquote>
Suppose you're using something like <a href="http://en.wikipedia.org/wiki/MD5">MD5</a> (the GOD of HASH). MD5 takes any length string of input bytes and outputs 128 bits. The bits are consistently random, based on the input string. If you send the same string in twice, you'll get the exact same random 16 bytes coming out. But if you make even a tiny change to the input string -- even a single bit change -- you'll get a completely different output hash.
<p>
So when do you need to worry about collisions? The working rule-of-thumb here comes from the <a href="http://en.wikipedia.org/wiki/Birthday_paradox">birthday paradox</a>. Basically <b>you can expect to see the first collision after hashing 2<sup>n/2</sup> items, or 2^64 for MD5</b>.
</p>
<p>
2^64 is a big number. If there are 100 billion urls on the web, and we MD5'd them all, would we see a collision? Well no, since 100,000,000,000 is way less than 2^64:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="300">
<tr>
<td>2<sup>64</sup>
</td>
<td>18,446,744,073,709,551,616</td>
</tr>
<tr>
<td>2<sup>37</sup>
</td>
<td>100,000,000,000</td>
</tr>
</table>
</blockquote>
<p>
For a 16-bit hash, our 2<sup>n/2</sup> is a whopping 256; for a 32-bit hash it'd be 65,536. It's pretty clear that <b>URL shortening services can't rely on traditional hashing techniques</b>, at least not if they want to produce competitively small URLs.
</p>
<p>
<font color="red">My guess is the aggressive URL shortening services are doing a simple iteration across every permutation of the available characters they have as the URLs come in.</font> Each new URL gets a unique three character combination until no more are left. How many URLs would that take? Let's say each character is simple alphanumeric, case sensitive A-Z, a-z, 0-9. You can do somewhat better because more ASCII characters than that are valid in URLs, but let's stick with this for the sake of argument. That's 26 + 26 + 10 or 62 possibilities per character. So with a three character URL, we can represent...
</p>
<p>
62 * 62 * 62 = 238,328
</p>
<p>
... about 250,000 unique three-character short URLs. Beyond that, they'd be forced to move to four character representations. Assuming, of course, that the old URLs never expire.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/url-shortening-hashes-in-practice/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Programming Games, Analyzing Games ]]></title>
<link>https://blog.codinghorror.com/programming-games-analyzing-games/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
For many programmers, <b>our introduction to programming was our dad forcing us to write our own games</b>. Instead of the shiny new Atari 2600 game console I wanted, I got a Texas Instruments TI-99/4a computer instead. That's not exactly what I had in mind at the time, of course, but that fateful decision launched a career that spans thirty years.
</p>
<p>
Evidently, I'm not alone. Mike Lee <a href="http://atomicwang.org/motherfucker/Index/A9267832-5BD9-475F-98E6-A8C269E91C4B.html">had a similar experience</a>:
</p>
<p>
</p>
<blockquote>
I was born in 1976, the same year as Apple, so my dad was just the right age to get into the early results of the home-brew movement. One of my few memories of early childhood is of him coming home with a Sinclair 2000 and a book of games. He sat there for hours typing in the code for Space Invaders, and we played it maybe 30 minutes before turning the machine off and undoing all his work.
</blockquote>
<p>
As <a href="http://a-simian-mind.blogspot.com/2007/05/what-i-learned.html">did Shawn Oster</a>:
</p>
<p>
</p>
<blockquote>
I've been developing software for 25 years, since I was 8, starting with a book called "Your First BASIC Program" that my dad bought me because we had a PC while all my friends were playing StarBlazers on their Apple IIs.  He said if I wanted to play games then I could write one myself.   At the time I was a bit disappointed (OK, crushed) but now... well, Dad, thank you.
</blockquote>
<p>
That's why it's so fascinating to retrace the earliest computer games. The personal computer industry <a href="http://www.codinghorror.com/blog/archives/000718.html">grew up with us</a>. We learned how to program by <a href="http://www.codinghorror.com/blog/archives/000414.html">typing in those simple games from magazines and books</a>. Look closely, and you'll find that those old game programs are the primitive origins of most programmers, the reptile brain stem we all collectively carry around in our heads.
</p>
<p>
Even a humble, simple little pack-in game like Minesweeper has deep <a href="http://www.gamesetwatch.com/2007/02/column_beyond_tetris_minesweep.php">roots going back to the days of punch cards</a>:
</p>
<p>
</p>
<blockquote>
Minesweeper has its origins in the earliest mainframe games of the '60s and '70s. Wikipedia cites the earliest ancestor of Minesweeper as David Ahl's <a href="http://www.atariarchives.org/basicgames/showpage.php?page=53">Cube</a>. But although Cube features "landmines," it's hard to consider this a predecessor of Minesweeper. In Cube, the mines are placed randomly and the only way to discover where they ends the game. You walk over a landmine and you die; you can't avoid the landmines or know where they are before you take a chance.
<p>
<img alt="image placeholder" >
</p>
<p>
However, there are a number of very early "hide and seek" games about locating hidden spots on a grid. For example, in Bob Albrecht's <a href="http://www.atariarchives.org/basicgames/showpage.php?page=94">Hurkle</a>, you have to find a creature hiding on a ten-by-ten grid. After each guess, you're told in what general direction the Hurkle lies. Dana Noftle's <a href="http://www.atariarchives.org/bcc1/showpage.php?page=251">Depth Charge</a> is the same, but in three dimensions. Bud Valenti's <a href="http://www.atariarchives.org/basicgames/showpage.php?page=114">Mugwump</a> has multiple hidden targets, and after each guess, you get the approximate distance to each of them. Unlike Cube, these games match the general pattern of Minesweeper more closely: make a random guess to start, then start using the information provided by that first guess to uncover the hidden items. Of course, unlike Minesweeper (or Cube), the was no danger of "explosion," the only constraint was finding the secret locations in a limited number of guesses.
</p>
<p>
The closest ancestor to Minesweeper is probably Gregory Yob's <a href="http://www.atariarchives.org/bcc1/showpage.php?page=247">Hunt the Wumpus</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Although it used an unorthodox grid (the original game used the vertices of a dodecahedron, and <a href="http://www.atariarchives.org/morebasicgames/showpage.php?page=181">a later version</a> used Mbius strips and other unlikely patterns), the Wumpus evolved from its predecessors in many other ways.
</p>
</blockquote>
<p>
I was intrigued by the newfound connection between Minesweeper and <a href="http://www.codinghorror.com/blog/files/wumpus_origin.htm">Hunt the Wumpus</a>, since <a href="http://www.codinghorror.com/blog/archives/000515.html">the Wumpus is my power animal</a>.
</p>
<p>
Most of the early games weren't even that much <i>fun</i>. Analyzing the game's program was almost as enjoyable as playing it; the very act of typing it in and understanding the program was "game" enough for many of us. But some of these early games evolved and survived until today, as Minesweeper did-- and it has become so ingrained into the public consciousness that it's now the subject of <a href="http://www.collegehumor.com/video:1770138">hilarious parody videos</a>. Despite Minesweeper's simplicity (and popularity), it is also a surprisingly deep game of logic, as documented in the <a href="http://en.wikipedia.org/wiki/Minesweeper_(computer_game)">Wikipedia entry</a>:
</p>
<p>
</p>
<ul>
<li>Analysis: <a href="http://en.wikipedia.org/wiki/Minesweeper_(computer_game)#1._Single_square_analysis">single square</a>, <a href="http://en.wikipedia.org/wiki/Minesweeper_(computer_game)#2._Double_square_analysis:">double square</a>, <a href="http://en.wikipedia.org/wiki/Minesweeper_(computer_game)#3._Shared_mine_analysis">shared mine</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Minesweeper_(computer_game)#NP-completeness">NP-Completeness</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Minesweeper_(computer_game)#Mine_probabilities_must_be_balanced_against_rewards">Mine probabilities</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Minesweeper_(computer_game)#Measuring_board_difficulty">Measuring Board Difficulty</a>
</li>
</ul>
<p>
Minesweeper is still popular with programmers today; <a href="http://students.washington.edu/ahou/automine/index.html">Automine</a>, for example, is a Java program that automatically plays Minesweeper by reading the screen and manipulating the mouse.
</p>
<p>
The Minesweeper article is a part of the amazing <a href="http://www.gamesetwatch.com/column_beyond_tetris/">Beyond Tetris series</a> on GameSetWatch, in which many classic puzzle games are examined from the vantage point of a game designer and game programmer. I recommend it highly. Fair warning, though: don't <a href="http://www.gamesetwatch.com/column_beyond_tetris/">click through</a> unless you have plenty of time on your hands. For a programmer, <b>analyzing games is almost as fun as playing them</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/programming-games-analyzing-games/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Widescreen and FOV ]]></title>
<link>https://blog.codinghorror.com/widescreen-and-fov/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As far as I'm concerned, <a href="http://www.codinghorror.com/blog/archives/000740.html">you can never have enough pixels on your desktop</a>. Until a few years ago, buying a larger display meant buying a larger display in the same, standard 4:3 screen layout-- 640 x 480, 800 x 600, 1024 x 768, 1600 x 1200, and so forth. <b>But widescreen monitors are increasingly popular</b>. It's difficult to buy a larger monitor today without changing your aspect ratio to widescreen.
</p>
<p>
As the new owner of my very first non-4:3 widescreen monitor, I'm learning first hand that widescreen displays can be problematic in certain rendering contexts. The issue of <b>scaling pre-rendered content</b> to a widescreen display is a well-understood problem at this point; <a href="http://www.codinghorror.com/blog/archives/000418.html">non-linear stretching techniques</a> work reasonably well.
</p>
<p>
But when <b>rendering dynamic 3D content</b>, things are a bit more problematic. I just purchased <a href="http://en.wikipedia.org/wiki/Bioshock">the game Bioshock</a>, which "supports" widescreen displays-- but, in fact, it doesn't. Here's a screenshot of the same scene displayed in 1600 x 1200 (4:3), and in widescreen 1920 x 1200 (16:10).
</p>
<p>
<a href="http://farm2.static.flickr.com/1062/1224438792_0416273777_b.jpg"><img alt="image placeholder" >
</p>
<p>
It's wider, technically, but you actually <i>see less</i>. The sides are the same, but the top and bottom of the display is clipped away in widescreen. In effect, the viewport is zoomed in. This is what you <i>have</i> to do to get static, pre-rendered content to fit a widescreen format, because that content is immutable. But this is a terrible solution for dynamically rendered content in a 3D world. Instead, the developers should <b>increase the <a href="http://en.wikipedia.org/wiki/Field_of_view">field of view</a></b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If we <a href="http://www.widescreengamingforum.com/forum/viewtopic.php?p=108502#108502">turn down the FOV in Bioshock</a> to something like 0.84 to accommodate our widescreen 16:10 aspect ratio, we <b>can see more of the world, not less</b>:
</p>
<p>
<a href="http://farm2.static.flickr.com/1376/1224835806_668be694bc_b.jpg"><img alt="image placeholder" >
</p>
<p>
With the adjusted FOV, the wider screen is used to display more of the scene on the left and right edges. Makes sense, doesn't it? But this is not something you get for free-- <a href="http://msdn2.microsoft.com/en-us/library/bb174608.aspx#Aspect_Ratio_and_Widescreen">the rendering engine <i>must</i> be programmed to allow and support changing the FOV</a>.
</p>
<p>
<b>In multiplayer circles, a wider FOV is considered cheating.</b> If you can view more of the world than your opponent, then you might be able to see them coming before they see you. But this is a moot point for Bioshock; it's a single-player game. It's definitely possible to <a href="http://strlen.com/gfxengine/fisheyequake/compare.html">go a little crazy with FOV</a> if you don't have enough physical display size to justify the field of view you've chosen:
</p>
<p>
<a href="http://strlen.com/gfxengine/panquake/"><img alt="image placeholder" >
</p>
<p>
It's a tricky balancing act, and not many rendering engines get it right. That's probably why there's a <a href="http://www.widescreengamingforum.com/wiki/index.php?title=Main_Page">Widescreen Gaming Forum</a> dedicated to dealing with FOV and widescreen issues, along with at least one other website, <a href="http://www.widescreengamer.com/">Widescreen Gamer</a>. As the widescreen display format becomes increasingly popular, you can expect to run into this little rendering quirk eventually.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/widescreen-and-fov/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Computer Workstation Ergonomics ]]></title>
<link>https://blog.codinghorror.com/computer-workstation-ergonomics/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I spend almost every waking moment in front of a computer. I'm what you might call an <em>indoor enthusiast</em>. <strong>I've been lucky not to experience any kind of computer-related injury due to my prolonged use of computers</strong>, but it is a very real professional risk. I get some occasional soreness in my hands or wrists, mostly after marathon binges where I've clearly overdone it – but that's about the extent of it. All too many of my friends have struggled with long-term <a href="http://www.hanselman.com/blog/CommentView.aspx?guid=f54ee04c-7732-454c-be36-c9f764cbe2ab">back pain</a> or <a href="http://haacked.com/archive/2004/06/10/The-Real-Pain-Of-Software-Development-1.aspx">hand</a> <a href="http://www.hanselman.com/blog/TheProgrammersHands.aspx">pain</a>. While you can (and should) <a href="http://www.codinghorror.com/blog/2007/10/geek-diet-and-exercise-programs.html">exercise your body</a> and <a href="http://www.codinghorror.com/blog/2006/06/programming-your-hands.html">exercise your hands</a> to strengthen them, there's one part of this equation I've been ignoring.</p>
<p>I've been on a quest for the <a href="http://www.codinghorror.com/blog/2006/03/the-ideal-computer-desk.html">ultimate computer desk</a> for a few years now, and I've talked at length about the value of <a href="http://www.codinghorror.com/blog/2008/07/investing-in-a-quality-programming-chair.html">investing in a great chair</a>. But I hadn't considered whether my current desk and chair is configured properly to fit my body. What about the <b>ergonomics</b> of my computer workstation?</p>
<p>The OSHA has an <a href="http://www.osha.gov/SLTC/etools/computerworkstations/">official page on computer workstation ergonomics</a>, which is a good starting point. But like all government documents, there's a lot more detail here than most people will ever need. The summary picture does give you an idea of what an ergonomic seating position looks like, though. <b>How close is this to the way you're sitting right now?</b></p>
<p><a href="http://www.osha.gov/SLTC/etools/computerworkstations/"><img alt="image placeholder" >
<p>Microsoft doesn't get enough credit for their often innovative hardware division, which <a href="http://www.e-radiography.net/computing/mouse.htm">first popularized ergonomic computer input devices</a>, starting with the Microsoft Mouse 2.0 in 1993 and following with the Microsoft Natural Keyboard in 1994. With Microsoft's <a href="http://www.microsoft.com/hardware/hcg/hcg_view.mspx">long-standing interest in hardware ergonomics</a>, perhaps it's not too surprising to find that their <a href="http://www.microsoft.com/hardware/hcg/default.html">healthy computing guide</a> is one of the best and most succinct references for ergonomic computing I've found. But you don't have to read it. I'll summarize the key guidelines for computer workstation ergonomics here, distilling the best advice from <em>all</em> the sources I found.</p>
<p>I know I've harped on this, but it bears repeating: <strong>a <a href="http://www.codinghorror.com/blog/2006/03/the-ideal-computer-desk.html">quality desk</a> and <a href="http://www.codinghorror.com/blog/2008/07/investing-in-a-quality-programming-chair.html">quality chair</a> will be some of the best investments you'll <em>ever</em> make as a software developer</strong>. They will last you for 10 years or more, and contribute directly to your work happiness every single day.
</p>
<p>
If you value your physical health, this is not an area you want to economize on. Hopefully you've invested in a decent computer desk and chair that <strong>provide the required adjustability</strong> to achieve an ergonomically correct computer workstation. Beyond the chair, you'll need to potentially adjust the height of your desk and your monitor, too.</p>
<p><img alt="image placeholder" >
<p>
</p>
<p><strong>1. The top of your monitor should be at eye level</strong>, and directly centered in front of you. It should be about an arm's length in front of you.</p>
<p><img alt="image placeholder" >
<p><strong>2. Your desk surface should be at roughly belly button level</strong>. When your arms are placed on the desk, your elbows should be at a ~90 degree angle, just below the desk surface. The armrests of your chair should be at nearly the same level as the desk surface to support your elbows.</p>
<p><img alt="image placeholder" >
<p><strong>3. Your feet should be flat on the floor with your knees at a ~90 degree angle</strong>. Your seat should not be pressing into the back of your knees; if necessary, tilt it slightly forward to alleviate any knee pressure. Sit fully back in your chair, with your back and shoulders straight and supported by the back of the chair.</p>
<p><img alt="image placeholder" >
<p><strong>4. When typing, your wrists should be in line with your forearms and not bent up, down, or to the side.</strong> Your keyboard should be directly centered in front of you. Other frequently used items should be nearby, within arm's reach.</p>
<p><img alt="image placeholder" >
<p>When it comes to computer workstation ergonomics, these are the most basic, most commonly repeated guidelines I saw. Ergonomics is a holistic discipline, not a science, so your results may vary. Still, I'm surprised how many of these very basic guidelines I've been breaking for so many years, without even thinking about it. I'll be adjusting my home desk tomorrow in hopes of more comfortable computing.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/computer-workstation-ergonomics/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Was The Windows Registry a Good Idea? ]]></title>
<link>https://blog.codinghorror.com/was-the-windows-registry-a-good-idea/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>One of the hot new features introduced with Windows 95 was the <a href="http://en.wikipedia.org/wiki/Windows_Registry">Windows Registry</a>. The Windows Registry offered a centralized database-like location to store application and system settings. No more plain text .INI files splattered all over your system. Instead, issue a few easy API calls and your application settings are safely nestled away deep inside the registry hive.</p>
<p>But after living with the Windows Registry for more than a decade, <strong>I'm starting to wonder if we were better off with those .INI files</strong>.</p>
<p><img alt="image placeholder" >
<p>I understand the need to store truly system-wide settings in one place. Let the operating system store settings however it deems fit. The real problem with the registry is that it was exposed to the outside world. Instead of being a secure, central hive for only the most essential and global settings, over time the registry has slowly become <strong>a trash heap of miscellaneous junk settings for every rinky-dink application on the planet</strong>.</p>
<p>Woe to the poor computer user who naively attempts to manipulate the filesystem without first supplicating to the Registry Gods. Manipulating the filesystem is utterly obvious, completely intuitive, and unfortunately also the fastest way to break an application in Windows. You have to reconcile almost everything you do in the filesystem with that opaque, unforgiving binary blob of data known as the Windows Registry.</p>
<p>For instance, when I upgrade and reinstall Windows, most of the games I have installed on my secondary drive are instantly broken because they store cd-key and (redundant) path information in the registry. The game vendors' support teams will tell you to reinstall all your games and patches. Personally, I'd rather search forums and spelunk through the registry to manually recreate the two or three registry keys the game is looking for.</p>
<p>My life would be a heck of a lot easier if per-application settings were stored in a place I could easily see them, manipulate them, and back them up. Like, say... in INI files.</p>
<p>There is an alternative, though. If Windows applications weren't so busy mindlessly piling all their settings on the registry garbage dump with everyone else, they <em>could</em> elect to follow the new, much saner Windows Vista conventions for storing application-specific data:</p>
<pre>/Users/Jeff/AppData/Local
/Users/Jeff/AppData/LocalLow
/Users/Jeff/AppData/Roaming
</pre>
<p><strong>Local</strong> and <strong>LocalLow</strong> are for bits of application data that are truly machine-specific. <strong>Roaming</strong> is for non-machine specific settings that will follow the user. That's where the lion's share of the application settings will be. It's all explained in the <a href="http://download.microsoft.com/download/3/b/a/3ba6d659-6e39-4cd7-b3a2-9c96482f5353/Managing%20Roaming%20User%20Data%20Deployment%20Guide.doc">Roaming User Data Deployment Guide</a> (Word doc). However, these are still user-specific settings, obviously, as they're under the <code>/Users</code> folder. I can't find any new Windows filesystem convention for system level, non-user-specific settings. I suppose that's still Ye Olde Registry by default.</p>
<p>It is possible to write Windows applications that don't use the registry in any way. These are some of my favorite applications. But they're also the most rare and precious of all applications in the Windows software ecosystem.</p>
<p>Over time, it's fair to say that <strong>I've grown to hate the Windows Registry</strong>. How do I hate it? <a href="http://en.wikipedia.org/wiki/Windows_Registry#Disadvantages">Let me count the ways</a>:</p>
<ul>
<li>The registry is a <strong>single point of failure</strong>. That's why every single registry editing tip you'll ever find starts with a <span style="color: red;">big fat screaming disclaimer about how you can break your computer with regedit</span>.
</li>
<li>The registry is <strong>opaque and binary</strong>. As much as I dislike <a href="http://www.codinghorror.com/blog/archives/000647.html">the angle bracket tax</a>, at least XML config files are reasonably human-readable, and they allow as many comments as you see fit.
</li>
<li>The registry has to be <strong>in sync with the filesystem</strong>. Delete an application without "uninstalling" it and you're left with stale registry cruft. Or if an app has a poorly written uninstaller. The filesystem is no longer the statement of record-- it has to be kept in sync with the registry somehow. It's a total violation of <a href="http://www.codinghorror.com/blog/archives/000805.html">the DRY principle</a>.
</li>
<li>The registry is <strong>monolithic</strong>. Let's say you wanted to move an application to a different path on your machine, or even to a different machine altogether. Good luck extracting the relevant settings for that one particular application from the giant registry <a href="http://www.codinghorror.com/blog/archives/000719.html">tarball</a>. A given application typically has dozens of settings strewn all over the registry. </li>
</ul>
<p>What's depressing about all of this is how prescient the UNIX conventions are in retrospect. How many billions of man-hours could we have saved by now if some early Windows NT 3.0 or 3.5 developers had decided to turn off public access to the registry, and transparently redirected the public registry API calls so they followed simpler, UNIX-like filesystem storage conventions instead?</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/was-the-windows-registry-a-good-idea/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Falling Into The Pit of Success ]]></title>
<link>https://blog.codinghorror.com/falling-into-the-pit-of-success/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Eric Lippert notes <a href="http://blogs.msdn.com/ericlippert/archive/2007/08/14/c-and-the-pit-of-despair.aspx">the perils of programming in C++</a>:</p>
<blockquote>
<p>I often think of C++ as my own personal Pit of Despair Programming Language. <b>Unmanaged C++ makes it so easy to fall into traps. Think buffer overruns, memory leaks, double frees, mismatch between allocator and deallocator, using freed memory, umpteen dozen ways to trash the stack or heap  –  and those are just some of the memory issues</b>. There are lots more "gotchas" in C++. C++ often throws you into the Pit of Despair and you have to climb your way up the Hill of Quality. (Not to be confused with scaling the Cliffs of Insanity. That's different.)</p>
</blockquote>
<p>That's <a href="http://www.codinghorror.com/blog/archives/000768.html">the problem with C++</a>. It does a terrible job of protecting you from your own worst enemy –  yourself. When you write code in C++, you're always circling the pit of despair, just one misstep away from plunging to your doom.</p>
<img alt="image placeholder" >
<p>Wouldn't it be nice to use a language designed to keep you from falling into the pit of despair? But avoiding horrific, trainwreck failure modes isn't a particularly laudable goal. Wouldn't it be even <i>better</i> if you used a language that let you effortlessly <a href="http://blogs.msdn.com/brada/archive/2003/10/02/50420.aspx">fall into The Pit of Success</a>?</p>
<blockquote>
<p>The Pit of Success: in stark contrast to a summit, a peak, or a journey across a desert to find victory through many trials and surprises, we want our customers to simply fall into winning practices by using our platform and frameworks.  To the extent that we make it easy to get into trouble we fail.</p>
</blockquote>
<p>Rico Mariani coined this term when talking about language design. You may give up some performance when you choose to code in C#, Python, or Ruby instead of C++. But what you get in return is a much higher likelihood of avoiding the miserable Pit of Despair –  and the opportunity to fall into the far more desirable Pit of Success instead.</p>
<p>As Brad Abrams points out, this concept extends beyond language. A well designed API should <i>also</i> <a href="http://blogs.msdn.com/brada/archive/2003/10/02/50420.aspx">allow developers to fall into the pit of success</a>:</p>
<blockquote>
<p>[Rico] admonished us to think about how we can build platforms that lead developers to write great, high performance code such that developers just fall into doing the "right thing".  That concept really resonated with me. It is the key point of good API design. We should build APIs that steer and point developers in the right direction.</p>
</blockquote>
<p>I think this concept extends even farther, to applications of all kinds: big, small, web, GUIs, console applications, you name it. I've often said that <b>a well-designed system makes it easy to do the right things and annoying (but not impossible) to do the wrong things</b>. If we design our applications properly, our users should be inexorably drawn into the pit of success. Some may take longer than others, but they should all get there eventually.</p>
<p>If users <i>aren't</i> finding success on their own –  or if they're not finding it within a reasonable amount of time –  it's not their fault. It's <i>our</i> fault. <b>We didn't make it easy enough for them to fall into the pit of success.</b> Consider your project a <a href="http://en.wikipedia.org/wiki/Big_Dig_%28Boston%2C_Massachusetts%29">Big Dig</a>: your job is to constantly rearchitect your language, your API, or your application to make that pit of success ever deeper and wider.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-08-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/falling-into-the-pit-of-success/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Choosing Dual or Quad Core ]]></title>
<link>https://blog.codinghorror.com/choosing-dual-or-quad-core/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm a <a href="http://www.codinghorror.com/blog/archives/000285.html">big fan of dual-core systems</a>. I think there's a clear and substantial benefit for all computer users when there are two CPUs waiting to service requests, instead of just one. If nothing else, it lets you gracefully terminate an application that has gone haywire, consuming all available CPU time. It's like having a backup CPU in reserve, waiting to jump in and assist as necessary. But for most software, <b>you hit a point of diminishing returns very rapidly after two cores</b>. In <a href="http://www.codinghorror.com/blog/archives/000655.html">Quad-Core Desktops and Diminishing Returns</a>, I questioned how effectively today's software can really use even <i>four</i> CPU cores, much less the inevitable eight and sixteen CPU cores we'll see a few years from now.
</p>
<p>
To get a sense of what kind of performance improvement we can expect going from 2 to 4 CPU cores, let's focus on the Core 2 Duo E6600 and Core 2 Quad Q6600 processors. These 2.4 GHz CPUs are identical in every respect, except for the number of cores they bring to the table. In a <a href="http://www.techreport.com/articles.x/12737/1">recent review</a>, Scott Wasson at the always-thorough <a href="http://www.techreport.com/">Tech Report</a> presented a slew of benchmarks that included both of these processors. Here's a quick visual summary of <b>how much you can expect performance to improve when upgrading from 2 to 4 CPU cores</b>:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="500">
<tr>
<td>
Task Manager CPU Graph</td>
<td>
</td>
<td align="right">
improvement<br>
2 to 4 cores</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://en.wikipedia.org/wiki/The_Elder_Scrolls_IV:_Oblivion">
The Elder Scrolls IV: Oblivion</a>
</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://en.wikipedia.org/wiki/Tom_Clancy's_Rainbow_Six:_Vegas">
Rainbow 6: Vegas</a>
</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://en.wikipedia.org/wiki/Supreme_Commander">
Supreme Commander</a>
</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.anandtech.com/tradeshows/showdoc.aspx?i=2868&amp;p=9">
Valve Source engine particle simulation</a>
</td>
<td align="right">
1.8 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://en.wikipedia.org/wiki/Valve_Hammer_Editor">
Valve VRAD map compilation</a>
</td>
<td align="right">
1.9 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.futuremark.com/products/3dmark06/">3DMark06</a>: Return to Proxycon</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
3DMark06: Firefly Forest</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
3DMark06: Canyon Flight</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
3DMark06: Deep Freeze</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
3DMark06: CPU test 1</td>
<td align="right">
1.7 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
3DMark06: CPU test 2</td>
<td align="right">
1.6 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.panoramafactory.com/">The Panorama Factory</a>
</td>
<td align="right">
1.6 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.fibus.org/fibusimg.htm">
picCOLOR</a>
</td>
<td align="right">
1.4 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.microsoft.com/windows/windowsmedia/forpros/encoder/default.mspx">
Windows Media Encoder</a> x64</td>
<td align="right">
1.6 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://softlab.technion.ac.il/project/LAME/html/lame.html">
Lame MT</a>
MP3 encoder</td>
<td align="right">
none</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.maxon.net/pages/download/cinebench_e.html">Cinebench</a>
</td>
<td align="right">
1.7 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.povray.org/">POV-Ray</a>
</td>
<td align="right">
2.0 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.mc.vanderbilt.edu/msrc/bioinformatics/Bumber.php">Myrimatch</a>
</td>
<td align="right">
1.8 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.caselab.okstate.edu/research/euler3dbenchmark.html">STARS Euler3D</a>
</td>
<td align="right">
1.5 x</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.sisoftware.net/">SiSoft Sandra</a> Mandelbrot</td>
<td align="right">
2.0 x</td>
</tr>
</table>
<p>
The results seem encouraging, until you take a look at the applications that benefit from quad-core-- the ones that aren't purely synthetic benchmarks are <strong>rendering,
encoding, or scientific applications</strong>
. It's the same old story. Beyond encoding and rendering tasks which are naturally amenable to parallelization, the task manager CPU graphs tell the sad tale of software that simply isn't written to exploit more than two CPUs. </p>
<p>
Unfortunately, CPU parallelism is inevitable. Clock speed can't increase forever; the
physics don't work. Mindlessly ramping clock speed to 10 GHz isn't an option. CPU vendors are forced to deliver more CPU cores running at nearly the same clock speed, or at very small speed bumps. Increasing the number of CPU cores on a die <em>should</em> defeat raw clock speed increases, at least in
theory. <b>In the short term, we have to choose between faster dual-core systems, or
slower quad-core systems. Today, a quad-core 2.4 GHz CPU costs about the same as a dual-core 3.0 GHz CPU.</b> But which one will provide superior performance? A <a href="http://www.xbitlabs.com/articles/cpu/display/core2quad-q6600.html">
recent Xbit Labs review</a> performed exactly this comparison:</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td>
</td>
<td>
<strong>3.0 GHz</strong><br>
Dual Core</td>
<td>
<strong>2.4 GHz</strong><br>
Quad Core</td>
<td align="right">
improvement<br>
2 to 4 cores </td>
</tr>
<tr>
<td>PCMark05
</td>
<td>
 9091</td>
<td>
8853</td>
<td align="right">
<font color="red">-3%</font>
</td>
</tr>
<tr>
<td>
SysMark 2007, E-Learning</td>
<td>
167</td>
<td>
140</td>
<td align="right">
<font color="red">-16%</font>
</td>
</tr>
<tr>
<td>
SysMark 2007, Video Creation</td>
<td>
131</td>
<td>
151</td>
<td align="right">
<font color="green">15%</font>
</td>
</tr>
<tr>
<td>
SysMark 2007, Productivity</td>
<td>
152</td>
<td>
138</td>
<td align="right">
<font color="red">-9%</font>
</td>
</tr>
<tr>
<td>
SysMark 2007, 3D</td>
<td>
160</td>
<td>
148</td>
<td align="right">
<font color="red">-8%</font>
</td>
</tr>
<tr>
<td>
Quake 4</td>
<td>
136</td>
<td>
117</td>
<td align="right">
<font color="red">-15%</font>
</td>
</tr>
<tr>
<td>
F.E.A.R.</td>
<td>
123</td>
<td>
110</td>
<td align="right">
<font color="red">-10%</font>
</td>
</tr>
<tr>
<td>
Company of Heroes</td>
<td>
173</td>
<td>
161</td>
<td align="right">
<font color="red">-7%</font>
</td>
</tr>
<tr>
<td>
Lost Planet</td>
<td>
62</td>
<td>
54</td>
<td align="right">
<font color="red">-12%</font>
</td>
</tr>
<tr>
<td>
Lost Planet "Concurrent Operations"</td>
<td>
62</td>
<td>
81</td>
<td align="right">
<font color="green">30%</font>
</td>
</tr>
<tr>
<td>
DivX 6.6</td>
<td>
65</td>
<td>
64</td>
<td align="right">
0%</td>
</tr>
<tr>
<td>
Xvid 1.2</td>
<td>
43</td>
<td>
45</td>
<td align="right">
<font color="green">5%</font>
</td>
</tr>
<tr>
<td>
H.264 QuickTime Pro 7.2</td>
<td>
189</td>
<td>
188</td>
<td align="right">
0%</td>
</tr>
<tr>
<td>
iTunes 7.3 MP3 encoding</td>
<td>
110</td>
<td>
131</td>
<td align="right">
<font color="red">-16%</font>
</td>
</tr>
<tr>
<td>
3ds Max 9 SP2</td>
<td>
4.95</td>
<td>
6.61</td>
<td align="right">
<font color="green">33%</font>
</td>
</tr>
<tr>
<td>
Cinebench 10</td>
<td>
5861</td>
<td>
8744</td>
<td align="right">
<font color="green">49%</font>
</td>
</tr>
<tr>
<td>
Excel 2007</td>
<td>
39.9</td>
<td>
24.4</td>
<td align="right">
<font color="green">63%</font>
</td>
</tr>
<tr>
<td>
WinRAR 3.7</td>
<td>
188</td>
<td>
180</td>
<td align="right">
<font color="green">5%</font>
</td>
</tr>
<tr>
<td>
Photoshop CS3</td>
<td>
70</td>
<td>
73</td>
<td align="right">
<font color="red">-4%</font>
</td>
</tr>
<tr>
<td>
Microsoft Movie Maker 6.0</td>
<td>
73</td>
<td>
80</td>
<td align="right">
<font color="red">-9%</font>
</td>
</tr>
</table>

<p>
It's mostly what I would expect-- <strong>only rendering and encoding tasks exploit
parallelism enough to overcome the 25% speed deficit between the dual and quad core
CPUs</strong>. Outside of that specific niche, performance will actually <em>suffer</em>
for most general purpose software if you choose a slower quad-core over a faster
dual-core.
</p>
<p>
However, there were some surprises in here, such as Excel 2007, and the Lost Planet
"concurrent operations" setting. It's possible software engineering will eventually
advance to the point that clock speed matters less than parallelism. Or eventually
it might be irrelevant, if we don't get to make the choice between faster clock
speeds and more CPU cores. But in the meantime, <strong>clock speed wins most of the
time</strong>. <strong>More CPU cores isn't automatically better.</strong> Typical
users will be better off with the fastest possible dual-core CPU they can afford.</p>
<p>
</p>
<p>
</p>
<p>    </p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/choosing-dual-or-quad-core/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Keeping The Menu Simple ]]></title>
<link>https://blog.codinghorror.com/keeping-the-menu-simple/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://en.wikipedia.org/wiki/In-N-Out_Burger">In-N-Out Burger</a> is a fast food institution here in California. Part of their appeal, I think, is their radically simplified menu.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Instead of forcing customers to process a complex menu with a hundred choices, In-N-Out <a href="http://gettingreal.37signals.com/">got real</a> and pared it down to what really matters: <b>a burger, fries, and a drink</b>. It's a limited experience, but it's also a tightly focused one. The menu may be small, but you can still customize it -- for advanced In-N-Out customers, there's <a href="http://www.badmouth.net/in-n-outs-secret-menu/">the secret menu</a>.
</p>
<p>
Most software lacks the discipline to present the tightly controlled user experience of the In-N-Out menu. Instead, we befuddle users with the software equivalent of a <a href="http://www.dansdata.com/gz073.htm">fourteen-course restaurant menu</a>. Software developers <a href="http://www.codinghorror.com/blog/archives/000726.html">lapse into complexity by default</a>, because it's the path of least resistance.
</p>
<p>
<a href="http://www.dansdata.com/gz073.htm"><img alt="image placeholder" >
</p>
<p>
Why can't we build software the In-N-Out way, and <b>keep the menu simple</b>? Stop trying to do everything. Don't <a href="http://www.codinghorror.com/blog/archives/000377.html">make users think</a>. Focus on doing a few things exceptionally well, and leave the giant, confusing menu of options for your competitors.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/keeping-the-menu-simple/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Online Newspapers, Offline ]]></title>
<link>https://blog.codinghorror.com/online-newspapers-offline/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the premium features of the <a href="http://www.nytimes.com/">New York Times</a> website is the <a href="http://firstlook.nytimes.com/index.php?cat=4">Windows Reader</a>. It's free if you subscribe to home delivery of the paper, otherwise it's $14.95 per month.
</p>
<p>
<a href="http://www.flickr.com/photo_zoom.gne?id=1331377377&amp;size=o"><img alt="image placeholder" >
</p>
<p>
One of the key attractions of the Times Reader is that it <b>lets you read the newspaper offline</b>. The application runs silently in the background, caching up 7 days worth of news, which you can browse through at your leisure-- with or without an internet connection. And for that, it's great. But given the increasing prevalence of internet connectivity everywhere, through cellular networks as well as WiFi, <a href="http://www.codinghorror.com/blog/archives/000787.html">does offline mode still matter?</a>
</p>
<p>
In many ways, the Times Reader is a superior newspaper reading experience. It supports dynamic, scalable full page layouts, unlike the narrow column of content we're stuck with in the web browser. And the typography features (through <a href="http://en.wikipedia.org/wiki/Windows_Presentation_Foundation#Text">Windows Presentation Foundation</a>) are desktop publishing quality. The "pages" are artfully presented, free of webjunk, and transitions between the articles are all beautifully animated, iPhone style. All of this is nearly impossible to do in a standard web browser.
</p>
<p>
I encourage people to <a href="http://firstlook.nytimes.com/index.php?cat=4">try out the Times Reader</a>. If nothing else, it's a window into some of the missed opportunities of viewing the online world exclusively through the lens of a traditional web browser.
</p>
<p>
But after using the Times Reader for a few days, I can't shake the feeling that <b>the newspaper reading experience it delivers is still inferior to the web browser</b>. Despite the many technical merits (and the offline mode), dividing the browsing experience between two different mediums is not a good idea.
</p>
<p>
<a href="http://img251.imageshack.us/img251/3152/timeswebsitescreenshotljy0.png"><img alt="image placeholder" >
</p>
<p>
The Times Reader version of the paper lacks much of the dynamic content offered on the web page:
</p>
<ul>
<li>opinion column links
</li>
<li>market summary numbers
</li>
<li>articles with embedded flash audio
</li>
<li>articles with embedded flash video
</li>
<li>search function
</li>
<li>personalization
</li>
<li>top (n) most popular / most emailed stories
</li>
</ul>
<p>
I miss this stuff. I always jumped directly to the most popular stories, and I can't do that in the Times Reader. I also find the the constrained view of the reader unnatural. I prefer the large scrolling content area of the web browser. I can use my mouse wheel to scroll to different sections in the reader, but it's alien.
</p>
<p>
The web browser is clearly the design focus for the New York Times. Perhaps that's the way it should be, as that's how most of the world will experience the paper online. In comparison, <b>the Times Reader feels like a B-movie version of the genericized RSS content with better special effects</b>. It just doesn't get the same attention as the home page.
</p>
<p>
Maybe this is a classic case of <a href="http://www.codinghorror.com/blog/archives/000805.html">Don't Repeat Yourself</a>. The Times Reader is a great effort. It's certainly pretty to look at. But I think the Times would be better served by focusing <i>all</i> their effort on delivering an outstanding web experience-- and, if necessary, offering programs that cache sections of the website for offline browsing.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/online-newspapers-offline/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Peanut Butter Theory of User Interface Design ]]></title>
<link>https://blog.codinghorror.com/the-peanut-butter-theory-of-user-interface-design/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://hcibib.org/tcuid/index.html">Task-Centered User Interface Design</a> is a 1993 book delivered in digital shareware form, and also <a href="http://hcibib.org/tcuid/tcuid.pdf">available as a PDF</a>. Although it's almost fifteen years old, it's still highly relevant-- a <b>testament to the timelessness of studying human interface design principles</b>. It was written by Clayton Lewis and John Rieman, who were at the University of Colorado at the time. It looks like <a href="http://books.google.com/books?id=ARTFuerQs6wC&amp;pg=PA229&amp;lpg=PA229&amp;dq=john+rieman+nokia&amp;source=web&amp;ots=rVuL5DNxx5&amp;sig=9Amknm2QNvkvYSTE2D7bBqT0qnY#PPA229,M1">Rieman works on usability for Nokia</a> now, but Lewis is <a href="http://spot.colorado.edu/~clayton/">still teaching HCI</a> in the UC Boulder computer science department.
</p>
<p>
<a href="http://hcibib.org/tcuid/index.html"><img alt="image placeholder" >
</p>
<p>
The book presages so many things we now accept as standard in the usability community: paper drafts, user personas, effort metrics, prototyping, testing, and iteration. It's solid advice written well. And it opens with this crucial warning:
</p>
<p>
</p>
<blockquote>
We've designed this book to be most useful for people who are actually developing user interfaces. That's in contrast to the full-time interface professionals who do research and evaluation in large corporations. We strongly believe that effective interactive systems require a commitment and an understanding throughout the entire development process. <b>It just won't work to build a complete system and then, in the final stages of development, spread the interface over it like peanut butter.</b>
</blockquote>
<p>
Usability is something <i>everybody</i> on your team-- not just the designers-- should be thinking about throughout the lifecyle of your project. If your development team suffers from the delusional peanut butter theory of user interface design, perhaps they should find time to read through <a href="http://hcibib.org/tcuid/index.html">Task-Centered User Interface Design</a>, too.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-peanut-butter-theory-of-user-interface-design/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Problem With Tabbed Interfaces ]]></title>
<link>https://blog.codinghorror.com/the-problem-with-tabbed-interfaces/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Cyrus Najmabadi*  <a href="http://blogs.msdn.com/cyrusn/archive/2005/04/10/406971.aspx">hates tabs in web browsers</a>:</p>
<blockquote>Ok, I seriously don't get tabs on Windows.  Hell, I don't get tabs on OSX either.  In the latter there's a great system called Expos, and in the former the taskbar does the job.  Once I start using tabs, things go all to hell. On OSX, I can't tell which FireFox/Safari window has the tab I want (since it's too small). In Windows I find myself scanning the taskbar for a site I was looking at, but I can't find it because the taskbar only lists the currently active tab.  This makes it so difficult to actually find the site I want and it ends up being far slower than just having a window available for each site.</blockquote>
<p>Initially I disagreed with Cyrus. However broken tabbed browsing may be, it's still a better solution than any of the existing alternatives. For example, Microsoft's own flagship Office suite, even today, suffers from some <a href="http://www.codinghorror.com/blog/archives/000262.html">highly inconsistent, bizarre pseudo-MDI behavior</a> for multiple documents. I'll take simple, reliable tabs over oddball MDI <em>any</em> day. No contest.</p>
<p>Lately I'm starting to come around to Cyrus' way of thinking. I don't hate tabbed interfaces-- yet-- but I definitely see what Cyrus was talking about. Tabs are increasingly the source of two aggravating mistakes for me:</p>
<ol>
<li>
<strong>I inadvertently open multiple copies of a web site</strong>, because I can't see that I already had that web site open in an obscured tab of an existing browser window. </li>
<li>
<strong>I accidentally close a browser window containing information that I needed</strong>, because the information was in an obscured tab of that particular browser window. </li>
</ol>
<p>In a tabbed interface, it's difficult to see anything except the active tab at any given time. <strong>Tabbed interfaces obscure as much as they organize.</strong> Tabs are great in moderation, but once they become a keystone navigational technique of your core applications, something peculiar happens. As Cyrus so aptly said, "once I start using tabs [extensively], things go all to hell."</p>
<p>Allow me to illustrate with an example. Let's say <strong>I want to check my GMail account</strong>, which I do frequently throughout the day. It's likely I already have GMail running, somewhere, so job #1 is to find it.</p>
<p>First, I scan the text in the taskbars. I use <a href="http://www.realtimesoft.com/ultramon/">UltraMon</a>, so each of my three monitors has its own distinct taskbar, summarizing every window on that monitor.</p>
<p><img alt="image placeholder" >
<p>But I don't see the word "GMail" in any of the three taskbars.</p>
<p>Next, I press ALT+TAB-- the poor man's Expos-- and scan through thumbnails of all the windows I have open. Do I see anything that looks like GMail?</p>
<p><a href="http://farm2.static.flickr.com/1030/1341390026_bd0225a693_o.jpg"><img alt="image placeholder" >
<p>No. I don't see the distinctive look of the GMail user interface in any of those thumbnails. I've actually <a href="http://blogs.vertigo.com/personal/jatwood/Blog/Lists/Posts/Post.aspx?ID=31">enlarged the Alt+Tab thumbnail size via registry tweaks</a>, so this is as good as it gets for visibility. Squinting doesn't help.</p>
<p>The Alt+Tab dialog only uses the primary monitor, even though I have a three-monitor configuration. But we can harness the entire screen area of <em>all</em> the monitors if we install <a href="http://insentient.net/">the amazing Switcher</a>. I have Switcher mapped to Windows+Tab, replacing the <em>incredibly</em> lame <a href="http://www.microsoft.com/windows/products/windowsvista/features/details/flip3D.mspx">Flip3D</a>. This is functionally identical to the OSX Expose that Cyrus mentioned. <em>Now</em> can I find GMail?</p>
<p><a href="http://img385.imageshack.us/img385/1773/desktopswitcherlargeiq7.jpg"><img alt="image placeholder" >
<p>No. Even with the additional resolution of Switcher across all three monitors, I don't see GMail in any of the windows. At this point I would usually launch the URL using <a href="http://www.codinghorror.com/blog/archives/000766.html">the keyboard entry area of the Vista Start Menu</a>.  I could use the fancy <a href="http://brandontools.com/content/StartPlusPlus.aspx">Start++ add-in</a> to make this easier, but the vanilla Vista menu works well enough.</p>
<p>But wait! <em>I actually had GMail open already.</em> I've made a mistake.. again. I have <em>two</em> copies of GMail running now. Did you see it? Here, let me show you:</p>
<p><img alt="image placeholder" >
<p>That muddy, tiny little morass of pixels is the <em>only</em> visual indication that I already had GMail running as a tab in an existing browser instance. It's not in the taskbar, it's hardly visible at all in the small Alt+Tab screenshot, and you'd need the Six Million Dollar Man's bionic eye to see that <em>barely</em> visible tab in Expose, I mean, Switcher.</p>
<p>The depressing thing is that it's usually <em>faster</em> to mindlessly launch a new browser than it is to go through this tedious routine of playing <a href="http://en.wikipedia.org/wiki/Where's_Waldo">Where's Waldo</a> with (n) browsers and (n) tabs. And that's what I often do. But it bothers me.</p>
<p>Let me be very clear-- <strong>I like tabs</strong>. I think they're a far better option than the terrible MDI-alike alternatives. But I also think tabbed interfaces present some pretty severe navigational problems of their own. In the above example, if GMail had been in its own browser window, I could have found it instantly by looking in the taskbar, or at worst, by visually selecting it from even a smallish thumbnail image. Because GMail was in a tab, I wasted my time trying to find it, and I wasted even more time needlessly launching another browser. And this isn't an isolated incident. This happens to me <em>every day</em>. More times than I'd care to admit.</p>
<p>So how can we fix this? <strong>How can we integrate tabs with the existing navigational features of the operating system, such as the taskbar, and Expose?</strong> I keep coming back to <a href="http://www.codinghorror.com/blog/archives/000595.html">search as the dominant computing metaphor</a>. The only thing I can think of is a plain-text search facility where I type "Gmail", and the OS would automatically highlight that tab (or window) and bring it to the front. That presupposes a very high level of integration between the application tabs and the operating system, however.</p>
<p>Despite the undeniable convenience of tabs for grouping and organizing related topics together in a single browser instance, I feel like tabs create as many problems for me as they solve. I wish I could "tear off" tabs into standalone windows on demand, too. That might be a reasonable workaround in the meantime.</p>
<p>* whatever happened to Cyrus? The last entry on his blog is two years old, and I can't find hide nor hair of him via internet searches. It's a shame, because I thoroughly enjoyed his blog.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-problem-with-tabbed-interfaces/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Rainbow Hash Cracking ]]></title>
<link>https://blog.codinghorror.com/rainbow-hash-cracking/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The multi-platform password cracker <a href="http://ophcrack.sourceforge.net/">Ophcrack</a> is incredibly fast. How fast? <strong>It can crack the password "Fgpyyih804423" in 160         seconds</strong>. Most people would consider that password fairly secure. The     <a href="https://www.microsoft.com/protect/yourself/password/checker.mspx">Microsoft         password strength checker</a> rates it "strong". The <a href="http://www.geekwisdom.com/dyn/passwdmeter"> Geekwisdom password strength meter</a> rates it "mediocre".</p>
<p>Why is Ophcrack so fast? Because it uses <a href="http://en.wikipedia.org/wiki/Rainbow_table"> Rainbow Tables</a>. No, not the kind of rainbows I have as         my desktop background.</p>
<p><a href="http://www.lexode.com/galerie/galerie/p/t/ptiteclo/113308897248.jpg"><img alt="image placeholder" >
<p>Although those are beautiful, too.</p>
<p>To understand how <a href="http://en.wikipedia.org/wiki/Rainbow_table">rainbow tables</a> work, you first have to understand how passwords         are stored on computers, whether on your own desktop, or on a remote web server         somewhere.</p>
<p><strong>Passwords are <em>never</em> stored in plaintext.</strong> At least they         shouldn't be, unless you're building the world's most insecure system using the world's most naive programmers. Instead,         passwords are stored as <a href="http://www.codinghorror.com/blog/archives/000257.html"> the output of a hash function</a>. Hashes are one-way operations. Even if an         attacker gained access to the hashed version of your password, it's not possible         to reconstitute the password from the hash value alone.</p>
<p>But it is possible to attack the hashed value of your password using <strong>rainbow tables:         enormous, pre-computed hash values for every possible combination of characters</strong>.         An attacking PC could certainly calculate all these hashes on the fly, but taking         advantage of a massive table of pre-computed hash values enables the attack to proceed         several orders of magnitude faster-- assuming the attacking machine has enough RAM to store the entire         table (or at least most of it) in memory. It's a classic <a href="http://lasecwww.epfl.ch/~oechslin/projects/ophcrack/"> time-memory tradeoff</a>, exactly the sort of cheating shortcut you'd expect a black hat attacker         to take.</p>
<p>How enormous are rainbow tables? The installation dialog for <a href="http://ophcrack.sourceforge.net/"> Ophcrack</a> should give you an idea:</p>
<p><img alt="image placeholder" >
<p>It takes a long time to generate these massive rainbow tables, but once they're out there, every         attacking computer can leverage those tables to make their attacks on hashed passwords         that much more potent.</p>
<p>The smallest rainbow table available is the basic alphanumeric one, and         even it is 388 megabytes. That's the default table you get with the Ophcrack bootable         ISO.         Even that small-ish table is remarkably effective. I used it to attack some         passwords I set up in a Windows XP virtual machine with the following results:</p>
<table cellspacing="4" cellpadding="4" width="400">
<tbody>
<tr>
<td></td>
<td>found?</td>
<td>seconds</td>
</tr>
<tr>
<td>Password1!</td>
<td></td>
<td>700</td>
</tr>
<tr>
<td>Fgpyyih804423</td>
<td><strong>yes</strong></td>
<td>159</td>
</tr>
<tr>
<td>Fgpyyih80442%</td>
<td></td>
<td>700</td>
</tr>
<tr>
<td>saMejus9</td>
<td><strong>yes</strong></td>
<td>140</td>
</tr>
<tr>
<td>thequickbrownfoxjumpsoverthelazydog</td>
<td></td>
<td>700</td>
</tr>
</tbody>
</table>
<p>You wouldn't expect this rainbow table to work on the passwords with non-alphanumeric         characters (%&amp;^$# and the like) because the table doesn't contain those characters.         You'll also note that that <a href="http://www.codinghorror.com/blog/archives/000360.html">passphrases, which I am a big fan of</a>, are immune to this technique due to their length.         But then again, <strong>this attack covered 99.9% of all possible 14 character alphanumeric passwords in 11 minutes</strong>, and that was with the         <em>smallest</em> of the available rainbow tables. We could do better by using larger, more         complete rainbow tables. The Ophcrack documentation describes the differences between         the available rainbow tables it uses:</p>
<table cellspacing="4" cellpadding="4">
<tbody>
<tr>
<td valign="top">Alphanumeric 10k</td>
<td width="75" valign="top">388 MB</td>
<td>Contains the LanManager hashes of 99.9%                     of all alphanumerical passwords. These are passwords made of mixed case letters                     and numbers (about 80 billion hashes). Because the LanManager hash cuts passwords                     into two pieces of 7 characters, passwords of length 1 to 14 can be cracked with                     this table set. Since the LanManager hash is also not case sensitive, the 80 billion                     hashes in this table set corresponds to 12 septillion (or 2<sup>83</sup>) passwords.</td>
</tr>
<tr>
<td valign="top">Alphanumeric 5k</td>
<td valign="top">720 MB</td>
<td>Contains the LanManager hashes of 99.9% of all alphanumerical passwords. However,                     because the tables are twice as large, cracking is about                     four times faster if you have at least 1 GB of RAM.</td>
</tr>
<tr>
<td valign="top">Extended</td>
<td valign="top">7.5 GB</td>
<td>Contains the LanManager hashes of 96% of all passwords made of up to 14 mixed                     case letters, numbers and the following 33 special characters: !"#$%&amp;'()*+,-./:;&lt;=&gt;?@[]^_`{|}                     ~. There are about 7 trillion hashes in this table set covering 5 octillion (or 2<sup>92</sup>)                     passwords.</td>
</tr>
<tr>
<td valign="top">NT</td>
<td valign="top">8.5 GB</td>
<td>You can use this table set to crack the NT hashes on machines where the LanManager hash has been disabled. The set contains 99.0% of the hashes of the passwords  made of the following characters:
<ul>
<li>up to 6 mixed case letters, numbers and 33 special characters (same as above) </li>
<li> 7 mixed-case letters and numbers </li>
<li> 8 lower-case letters and numbers </li>
</ul>
<p>There are 7 trillion hashes in this table, corresponding to 7 trillion passwords (the NT hash does not suffer from the weaknesses of the LanManager hash).</p>
</td>
</tr>
</tbody>
</table>
<p>Note that all rainbow tables have specific lengths and character sets they work         in. Passwords that are too long, or contain a character not in the table's character         set, are completely immune to attack from that rainbow table.</p>
<p><strong>Unfortunately, Windows servers are particularly vulnerable to rainbow table attack</strong>,         due to unforgivably weak <a href="http://en.wikipedia.org/wiki/LM_hash">legacy Lan Manager             hashes</a>. I'm stunned that the legacy Lan Manager support "feature" is still         enabled by default in Windows         Server 2003. It's <em>highly</em> advisable that you <a href="http://support.microsoft.com/kb/299656">disable Lan Manager hashes</a>, particularly on Windows servers which happen         to store domain credentials         for every single user. It'd be an awful shame to inconvenience all your Windows         98 users, but I think the increase in security is worth it.</p>
<p>I read that <a href="http://www.microsoft.com/technet/technetmag/issues/2006/08/SecurityWatch/"> Windows Server 2008 will finally kill off LM hashes</a> when it's released next         year. Windows Vista already         removed support for these obsolete hashes on the desktop.         Running OphCrack on my Vista box results in this dialog:</p>
<blockquote>All LM hashes are empty. Please use NT hash tables to crack the remaining hashes.</blockquote>
<p>I'd love to, but I can't find a reliable source for the 8.5 GB rainbow table of     NT hashes that I need to proceed.</p>
<p>The Ophcrack tool isn't very flexible. It doesn't allow you to generate your own rainbow tables. For that,         you'll need to use the <a href="http://www.antsight.com/zsl/rainbowcrack/">Project Rainbow             Crack</a> tools, which can be used to attack almost any character set and any         hashing algorithm. But beware. <strong>There's a reason rainbow table attacks have only             emerged recently, as the price of 2 to 4 gigabytes of memory in a desktop machine             have approached realistic levels</strong>. When I said <em>massive</em>, I meant         it. Here are some generated rainbow table sizes for the more secure NT hash:</p>
<table cellspacing="4" cellpadding="4">
<tbody>
<tr>
<td>Character Set</td>
<td>Length</td>
<td>Table Size</td>
</tr>
<tr>
<td><code>ABCDEFGHIJKLMNOPQRSTUVWXYZ</code></td>
<td align="right">14</td>
<td align="right">0.6 GB</td>
</tr>
<tr>
<td><code>ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789</code></td>
<td align="right">14</td>
<td align="right">3 GB</td>
</tr>
<tr>
<td><code>ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&amp;*()-_+=</code></td>
<td align="right">14</td>
<td align="right">24 GB</td>
</tr>
<tr>
<td><code>ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&amp;*()-_+=~`[]{}|:;"'&lt;&gt;,.?/</code></td>
<td align="right">14</td>
<td align="right">64 GB</td>
</tr>
</tbody>
</table>
<p>A rainbow table attack is usually overkill for a desktop machine. If hackers have physical         access to the machine, security is irrelevant. That's rule number 3 in         the <a href="http://www.microsoft.com/technet/archive/community/columns/security/essays/10imlaws.mspx"> 10 Immutable Laws of Computer Security</a>. There are any number of         tools that can reset passwords given physical access to the machine.</p>
<p>But <strong>when         a remote hacker obtains a large list of hashed passwords from a server or database</strong>, we're in trouble. There's significant         risk from a rainbow table attack. That's why you should never rely on hashes alone-- <a href="http://aspnet.4guysfromrolla.com/articles/112002-1.aspx"> always add some salt to your hash</a> so the resulting hash values are unique.         Salting a hash sounds complicated (and vaguely delicious), but it's quite simple.         You prefix a unique value         to the password before hashing it:</p>
<pre>hash = md5('deliciously-salty-' + password)</pre>
<p>If you've salted your password hashes, an attacker can't use a rainbow table attack         against you-- the hash results from "password" and "deliciously-salty-password"         won't match. Unless your hacker somehow knows that all your hashes are "delicously-salty-"         ones. Even then, he or she would have to generate a custom rainbow table specifically for you.</p>
<p><span style="color: red;">UPDATE: Please read Thomas Ptacek's <a href="http://chargen.matasano.com/chargen/2007/9/7/enough-with-the-rainbow-tables-what-you-need-to-know-about-s.html">excellent and informative response to this post</a>. It goes into much more detal about the nuts and bolts of password hashing. Unlike me, Thomas is a real security expert.</span></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/rainbow-hash-cracking/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Gigabyte: Decimal vs. Binary ]]></title>
<link>https://blog.codinghorror.com/gigabyte-decimal-vs-binary/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Everyone who has ever purchased a hard drive <b>finds out the hard way that there are
two ways to define a gigabyte.</b>
 </p>
<p>
When you buy a "500 Gigabyte" hard drive, the vendor defines it using the <strong>decimal</strong>
<strong>powers of ten definition</strong> of the "Giga" prefix.
</p>
<p></p>
<pre>500 * 10<sup>9</sup> bytes = 500,000,000,000 = 500 Gigabytes
</pre>
<p>
But the operating system determines the size of the drive using the computer's <strong>
binary powers of two definition</strong>
of the "Giga" prefix:
</p>
<p>
</p>
<pre>465 * 2<sup>30</sup> bytes = 499,289,948,160 = 465 Gigabytes
</pre>
<p>
If you're wondering where 35 Gigabytes of your 500 Gigabyte drive just disappeared to, you're not alone. It's <a href="http://dansdata.blogsome.com/2007/01/07/ninety-gigs-down-the-toilet/">an old trick perpetuated by hard drive makers</a>-- they intentionally use <a href="http://en.wikipedia.org/wiki/SI_prefix">the official SI definitions</a> of the Giga prefix so they can inflate the the sizes of their hard drives, at least on paper. This was always an annoyance, but now it's much more difficult to ignore, as it results in large discrepancies with today's enormous hard drives. When is a Terabyte hard drive not a Terabyte? When it's 931 GB.
</p>
<p>
As <a href="http://www.nedbatchelder.com/blog/index.html">Ned Batchelder notes</a>, the hard drive manufacturers are technically conforming to the letter of the <a href="http://en.wikipedia.org/wiki/SI_prefix">
SI prefix definitions</a>. It's us computer science types who are abusing the official prefix
designations:</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="700">
<tr>
<td>
</td>
<td>
</td>
<td align="right" valign="bottom">
Year Approved</td>
<td align="right" valign="bottom">
Official Definition</td>
<td align="right" valign="bottom">
Informal Meaning</td>
<td align="right" valign="bottom">
Difference</td>
<td valign="bottom">
Prefix Derived From
</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Gigabyte">giga</a>
</td>
<td valign="top">
GB</td>
<td align="right" valign="top">
1960</td>
<td align="right" valign="top">10<sup>9</sup>
</td>
<td align="right" valign="top">2<sup>30</sup>
</td>
<td align="right" valign="top">
7%</td>
<td valign="top">Greek root for giant</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Terabyte">tera</a>
</td>
<td valign="top">
TB</td>
<td align="right" valign="top">
1960</td>
<td align="right" valign="top">10<sup>12</sup>
</td>
<td align="right" valign="top">
2<sup>40</sup>
</td>
<td align="right" valign="top">
10%</td>
<td valign="top">Greek root for monster</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Petabyte">peta</a>
</td>
<td valign="top">
PB</td>
<td align="right" valign="top">
1975</td>
<td align="right" valign="top">10<sup>15</sup>
</td>
<td align="right" valign="top">
2<sup>50</sup>
</td>
<td align="right" valign="top">
13%</td>
<td valign="top">Greek root for five, "penta"</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Exabyte">exa</a>
</td>
<td valign="top">
EB</td>
<td align="right" valign="top">
1975</td>
<td align="right" valign="top">10<sup>18</sup>
</td>
<td align="right" valign="top">
2<sup>60</sup>
</td>
<td align="right" valign="top">
15%</td>
<td valign="top">Greek root for six, "hexa"</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Zettabyte">zetta</a>
</td>
<td valign="top">
ZB</td>
<td align="right" valign="top">
1991</td>
<td align="right" valign="top">10<sup>21</sup>
</td>
<td align="right" valign="top">
2<sup>70</sup>
</td>
<td align="right" valign="top">
18%</td>
<td valign="top">Latin root for seven, "septum", p dropped, first letter changed to S to avoid confusion with other SI symbols</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Yottabyte">yotta</a>
</td>
<td valign="top">
YB</td>
<td align="right" valign="top">
1991</td>
<td align="right" valign="top">10<sup>24</sup>
</td>
<td align="right" valign="top">
2<sup>80</sup>
</td>
<td align="right" valign="top">
21%</td>
<td valign="top">Greek root for eight, "octo", c dropped, y added to avoid having symbol of zero-like letter O</td>
</tr>
</table>
<p>
As the size of the prefix grows, so does the gap between the official and informal
meaning of the prefix.
And yes, there are <a href="http://www.lewrockwell.com/orig/kinsella6.html">larger official
SI prefixes</a> beyond these, <a href="http://worsethanfailure.com/Articles/Just_In_Case_It_0x27_s_Needed.aspx">
just in case someone needs more than 1000 yottabytes</a>. Ned noted that
one of the SI proposals is for <a href="http://jimvb.home.mindspring.com/unitsystem.htm">the prefix "luma"</a>, representing 10<sup>63</sup>.
</p>
<p>
Speaking of impossibly large numbers, if you're like most people reading this article, then you probably arrived here through Google. Google is a <a href="http://graphics.stanford.edu/~dk/google_name_origin.html">
tragically but forever
misspelled version of Googol</a>:</p>
<blockquote>
A <a href="http://en.wikipedia.org/wiki/Googol">googol</a> is 10<sup>100</sup>, i.e. a 1 followed by 100 zeros. In official SI prefix terms, a googol is approximately a yotta squared, squared. Even larger is the googolplex, which is equal to 10 to the power of a googol (10<sup>googol</sup>); this number is about the same size as the number of possible games of chess. Even larger numbers have been defined, such as <a href="http://en.wikipedia.org/wiki/Skewes'_number">
Skewes' number</a>, <a href="http://en.wikipedia.org/wiki/Graham's_number">Graham's number</a>, and the <a href="http://en.wikipedia.org/wiki/Steinhaus%E2%80%93Moser_notation">
Moser</a>, which I won't even try to describe.</blockquote>
<p>
But I digress. When we use gigabyte to mean 2<sup>30</sup>, that's an inaccurate and informal
usage. Instead, we're <em>
supposed</em> to be using the more accurate and disambiguated <a href="http://www.iec.ch/">
IEC</a> prefixes. They were introduced in 1998 and formalized with <a href="http://en.wikipedia.org/wiki/IEEE_1541">
IEEE 1541</a> in 2000.</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="250">
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Kibibyte">kibibyte</a>
</td>
<td>
KiB</td>
<td>
2<sup>10</sup>
</td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Mebibyte">mebibyte</a>
</td>
<td>
MiB</td>
<td>
2<sup>20</sup>
</td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Gibibyte">gibibyte</a>
</td>
<td>
GiB</td>
<td>
2<sup>30</sup>
</td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Tebibyte">tebibyte</a>
</td>
<td>
TiB</td>
<td>
2<sup>40</sup>
</td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Pebibyte">pebibyte</a>
</td>
<td>
PiB</td>
<td>
2<sup>50</sup>
</td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Exbibyte">exbibyte</a>
</td>
<td>
EiB</td>
<td>
2<sup>60</sup>
</td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Zebibyte">zebibyte</a>
</td>
<td>
ZiB</td>
<td>
2<sup>70</sup>
</td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Yobibyte">yobibyte</a>
</td>
<td>
YiB</td>
<td>
2<sup>80</sup>
</td>
</tr>
</table>

<p>
You occasionally see these more correct prefixes used in software, but
adoption has been slow at best. There are several problems:</p>
<p>
</p>
<ol>
<li>
<strong>They sound ridiculous</strong>. I hear the metric system used more often in the United
States than I hear the words "kibibyte" or "mebibyte" uttered by anyone with a straight face. Which is to say, never.<p>
</p>
</li>
<li>
<strong>Hard drive manufacturers won't use them.</strong> Drive manufacturers don't
care about being correct. What they do care about is consumers buying their drives
because they have the largest possible number plastered on the front of the box.
If a big lawsuit wasn't enough to get them to mend their ways, I seriously doubt
that the recommendation of an international standards body is going to sway them.<p>
</p>
</li>
<li>
<strong>Tradition rules</strong>. It's hard to give up on the <a href="http://en.wikipedia.org/wiki/Binary_prefix">
rich binary history</a> of kilobytes, megabytes, and gigabytes, particularly when
the alternatives are so questionable.</li>
</ol>
<p>
It's good to keep in mind <b>the discrepancy between the decimal and binary meanings
of the SI prefixes</b>. The difference can bite you if you're not careful. But I think
we're stuck with contextual, dual-use meanings of the SI prefixes for the forseeable
future. Or perhaps we're all overthinking this, as <a href="http://www.bright-green.com/blog">Alan Green</a> notes:</p>
<blockquote>
Whenever I try to discuss [this] with my friends, they say, "Yotta getta life".
</blockquote>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/gigabyte-decimal-vs-binary/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Classic Computer Science Puzzles ]]></title>
<link>https://blog.codinghorror.com/classic-computer-science-puzzles/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Software developers do have a proclivity for puzzles. Perhaps that's why     books like <a href="http://www.amazon.com/exec/obidos/ASIN/0394534913/codihorr-20">
To Mock a Mockingbird</a> exist. It's a collection of logic puzzles which is considered an introduction to <a href="http://users.bigpond.net.au/d.keenan/Lambda/">
lambda calculus</a>, one of the core concepts of <a href="http://en.wikipedia.org/wiki/Lisp_programming_language">
Lisp</a>.
</p>
<p><a href="http://www.amazon.com/exec/obidos/ASIN/0394534913/codihorr-20"><img alt="image placeholder" >
<p>
Such puzzle questions are <a href="http://www.codinghorror.com/blog/archives/000628.html">
<em>de rigueur</em> for many programming interviews</a>, though they're
often abused. There is a downside to thinking of programming languages as solutions
to arbitrarily difficult abstract mathematical puzzles. That's probably why Lisp has <a href="http://damienkatz.net/2007/01/the_volkswagen.html">
a rich reputation for being powerful but simultaneously dense and impenetrable</a>.</p>
<p>
I prefer to think of
programming languages as utilitarian tools for <strong>real world problems</strong>.
They let me accomplish pragmatic (and often
prosaic) goals. PHP is about as unsexy
a language as you'll ever find, but does that matter when it's the technology driving the current Boardwalk
and Park Place of the web world? I'm not a fan of puzzle questions in interviews;
I'd rather have potential developers <a href="http://www.codinghorror.com/blog/archives/000226.html">
give me a presentation</a> or <a href="http://www.codinghorror.com/blog/archives/000781.html">
write a reasonably useful program</a> in the real development environment
they'll be using on the job. Solve all the puzzles you want, but the only one we're
getting <em>paid </em>to solve is the customer's problem.</p>
<p>
That said, <strong>many fundamental computer science concepts can be summarized
well in puzzle form</strong>, which aids tremendously in teaching and learning these key
concepts. Here's a quick list of the <strong>classic computer science puzzles</strong>
that I remember from my university days:</p>
<table cellpadding="12" cellspacing="12" width="100%">
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Dining_philosophers_problem">Dining Philosophers</a><br>
<strong>
Concurrency and Deadlocks</strong><br>
<img alt="image placeholder" >
</td>
<td valign="middle">
Five philosophers sit around a circular table. In front of each philosopher is a
large plate of rice. The philosophers alternate their time between eating and thinking.
There is one chopstick between each philosopher, to their immediate right and left.
In order to eat, a given philosopher needs to use both chopsticks. How can you ensure
all the philosophers can eat reliably without starving to death?</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Travelling_salesman_problem">Travelling Salesman</a><br>
<strong>P=NP</strong><br>
<img alt="image placeholder" >
</td>
<td valign="middle">
A salesperson has a route of cities that make up his or her beat. What's the most efficient
sales route that visits each city exactly once, and then returns to the
home city?</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Eight_queens_puzzle">Eight Queens</a><br>
<strong>
Algorithm Design<br>
</strong>
<img alt="image placeholder" >
</td>
<td valign="middle">
Given eight queens on a standard 8 x 8 chessboard, how many unique positions-- exclusive of rotations and mirror images-- can those eight queens occupy without attacking each other?</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Two_Generals%27_Problem">Two Generals</a><br>
<strong>
Communication Protocols</strong><br>
<img alt="image placeholder" >
</td>
<td valign="middle">
Two armies, each led by a general, are preparing to attack a city. The armies are
encamped outside the city on two mountains separated by a large valley. In order
to capture the city, the generals must attack at exactly the same time. The only
way for the generals to communicate is by sending messengers through the valley.
Unfortunately, the valley is occupied by the city's defenders, so there's a chance
any given messenger will be captured. Each general has no way of knowing if their
messenger arrived. How do the generals coordinate their attack?</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/Tower_of_Hanoi">Towers of Hanoi</a><br>
<strong>
Recursion<br>
</strong>
<img alt="image placeholder" >
</td>
<td valign="middle">
You have a stack of discs, from largest to smallest, that slide on to the first
peg of a three peg board. Your goal is to move the entire stack of discs from the
first peg to the third peg. However, you can only move the topmost disc of any peg,
and smaller discs must always be placed on larger discs. How many moves will it
take? </td>
</tr>
</table>
<p></p>
<p>
I consider this the "greatest hits" of classic computer science puzzles. But I'm
sure I've forgotten a few. Are there any other puzzles I've missed that express fundamental computer
science concepts, the type that would be taught in a typical undergraduate computer
science course?</p>
<p><script type="text/javascript">google_ad_client = &quot;pub-6424649804324178&quot;;google_ad_slot = &quot;8324348970&quot;;google_ad_width = 728;google_ad_height = 90;</script><script src="http://pagead2.googlesyndication.com/pagead/show_ads.js" type="text/javascript"></script>
</p>
<p></p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/classic-computer-science-puzzles/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ You're Probably Storing Passwords Incorrectly ]]></title>
<link>https://blog.codinghorror.com/youre-probably-storing-passwords-incorrectly/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The web is nothing if not a maze of user accounts and logins. Almost everywhere you go on the web requires yet another new set of credentials. Unified login seems to elude us at the moment, so the status quo is <a href="http://www.codinghorror.com/blog/archives/000546.html">an explosion of usernames and passwords for every user</a>. As a consequence of all this siloed user identity data, Facebook and most other web apps encourage us to <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=0ff07054-f6fd-4093-9151-12b9fcbf8938">give out our credentials like Halloween candy</a>, as Dare Obasanjo notes:</p>
<blockquote>On Facebook, there is an option to import contacts from Yahoo! Mail, Hotmail, AOL and Gmail which requires me to enter my username and password from these services into their site. Every time I login to Yahoo! Mail there is a notice that asks me to import my contacts from other email services which requires me to give them my credentials from these services as well.</blockquote>
<p>This is a deplorable state of affairs. <strong>We're teaching users that their credentials are of little value and should be freely handed out to any passing website that catches their fancy</strong>. It's an incredibly dangerous habit to inculcate in users; it makes them <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=59a03a48-3584-465e-8072-a254ec933b32">far more vulnerable to phishing</a>:</p>
<blockquote>If users get comfortable with entering their credentials in all sorts of random places then it makes them more susceptible to phishing attacks. This is one of the reasons services like Meebo are worrying to me.</blockquote>
<p>The <em>last</em> thing we should be doing is coming up with ways to make phishing more powerful. Phishing is a social engineering exploit so timeless, so effective, and so powerful, I call it <a href="http://www.codinghorror.com/blog/archives/000852.html">the forever hack</a>. Rainbow table and brute force attacks can be defeated through judicious use of technology. Phishing can't.</p>
<p><img alt="image placeholder" >
<p>Users collect usernames and passwords like they do Pokemon. It's a sorry state of affairs, but for better or worse, that's the way it is. We, as software developers, are trusted with storing all these usernames and passwords in some sort of database. <strong>The minute we store a user's password, we've taken on the responsibility of securing their password</strong>, too. Let's say a hacker somehow obtains a list of all our usernames and passwords. Either it was an inside job by someone who had access to the database, or the database was accidentally exposed to the public web. Doesn't matter how. It just happened.</p>
<p>Even if hackers have our username and password table, we're covered, right? All they'll see is the hash values. Only the most grossly incompetent of developers would actually <a href="http://blog.moertel.com/articles/2006/12/15/never-store-passwords-in-a-database">store passwords as plaintext in the database</a>, right? Right?</p>
<blockquote>Recently, the folks behind Reddit.com confessed that a backup copy of their database had been stolen. Later, spez, one of the Reddit developers, confirmed that the database contained password information for Reddit's users, and that the information was stored as plain, unprotected text. In other words, once the thief had the database, he had everyone's passwords as well.</blockquote>
<p>Wrong.</p>
<p>I'm only a mouth-breathing Windows developer, not one of the elite <a href="http://www.ycombinator.com/">Y-combinating</a> Lisp, <a href="http://www.codinghorror.com/blog/archives/000839.html">oops, Python</a> developers working on Reddit. And even I know better than that.</p>
<p>You might think it's relatively unimportant if someone's forum password is exposed as plain text. After all, what's an attacker going to do with crappy forum credentials? Post angry messages on the user's behalf? But <strong>most users tend to re-use the same passwords</strong>, probably because they can't remember the two dozen unique usernames and passwords they're forced to have. So if you obtain their forum password, it's likely you also have the password to something a lot more dangerous: their online banking and PayPal.</p>
<p>My point here is not to drag the good names of the developers at Reddit through the mud. <strong>We're all guilty.</strong> I'm sure every developer reading this has stored passwords as plain text at some point in their career. I know I have. Forget the blame. The important thing is to teach our peers that storing plaintext passwords in the database is strictly forbidden-- that there's a better way, starting with basic hashes.</p>
<p>Hashing the passwords prevents plaintext exposure, but it also means you'll be <a href="http://www.codinghorror.com/blog/archives/000949.html">vulnerable to the astonishingly effective rainbow table attack</a> I documented last week. Hashes alone are better than plain text, but <em>barely</em>. It's not enough to thwart a determined attacker. Fortunately, the kryptonite for rainbow table attacks is simple enough-- add a salt value to the hashes to make them unique. I provided an example of a salted hash in my original post:</p>
<pre>hash = md5('deliciously-salty-' + password)
</pre>
<p>But IANAC -- I Am Not A Cryptographer. I meant this only as an <em>example</em>, not as production code that you should copy and paste into that hugely popular enterprise banking solution you're working on. In fact, I ripped it almost directly from Rich Skrenta's excellent post on <a href="http://www.skrenta.com/2007/08/md5_tutorial.html">using MD5 hashes as utility functions</a>.</p>
<p>Thomas Ptacek, on the other hand, <em>is</em> a cryptographer, and <a href="http://www.matasano.com/log/958/enough-with-the-rainbow-tables-what-you-need-to-know-about-secure-password-schemes/">he has a bone to pick with my choice of salting techniques</a>.</p>
<blockquote>What have we learned? We learned that if it's 1975, you can set the ARPANet on fire with rainbow table attacks. If it's 2007, and rainbow table attacks set you on fire, we learned that you should go back to 1975 and wait 30 years before trying to design a password hashing scheme.*
<p>We learned that if we had learned anything from this blog post, we should be consulting our friends and neighbors in the security field for help with our password schemes, because nobody is going to find the game-over bugs in our MD5 schemes until after my Mom's credit card number is being traded out of a curbside stall in Tallinn, Estonia.</p>
<p>We learned that in a password hashing scheme, speed is the enemy. We learned that MD5 was designed for speed. So, we learned that MD5 is the enemy. Also Jeff Atwood and Richard Skrenta.</p>
<p>Finally, we learned that if we want to store passwords securely we have three reasonable options: PHK's MD5 scheme, Provos-Maziere's Bcrypt scheme, and SRP. We learned that the correct choice is Bcrypt.</p>
<p>* editor's note: Not quite true. Most "modern" software does not use a modern password scheme. Windows XP/2000/NT, phpBB, the majority of custom password schemes; all vulnerable to rainbow table precomputation attacks.</p>
</blockquote>
<p>In summary, <strong>if we're storing passwords, we're probably storing those passwords incorrectly</strong>. If it isn't obvious by now, <a href="http://www.codeproject.com/dotnet/SimpleEncryption.asp">cryptography is hard</a>, and the odds of us getting it right on our own are basically nil. That's why we should rely on existing frameworks, and the advice of experts like Thomas. What higher praise is there than that of praise from your sworn enemy?</p>
<p>Let's recap:</p>
<ol>
<li>
<strong>Do not invent your own "clever" password storage scheme</strong>. I know, you're smart, and you grok this crypto stuff. But through this door lies madness-- and <a href="http://en.wikipedia.org/wiki/LM_hash">abominations like LMHash</a> that have ongoing, worldwide security ramifications we're still dealing with today. Take advantage of whatever password storage tools your framework provides, as they're likely to be a heck of a lot better tested and more battle-proven than any crazy scheme you and your team can come up with on your own. Security vulnerabilities, unlike functionality bugs in your application, run deep and silent. They can lay dormant for years.
</li>
<li>
<strong>Never store passwords as plaintext</strong>. This feels like security 101 and is completely obvious in retrospect. But not everyone knows what you know -- just ask Reddit. Store the hashes, never the actual passwords. Educate your fellow developers.
</li>
<li>
<strong>Add a long, unique random salt to each password you store</strong>. The point of a salt (or nonce, if you prefer) is to make each password unique and long enough that <a href="http://www.codinghorror.com/blog/archives/000631.html">brute force attacks are a waste of time</a>. So, the user's password, instead of being stored as the hash of "myspace1", ends up being stored as the hash of 128 characters of random unicode string + "myspace1". You're now completely immune to rainbow table attack.
</li>
<li>
<strong>Use a cryptographically secure hash</strong>. I think Thomas hates MD5 so very much it makes him seem a little crazier than he actually is. But he's right. MD5 is vulnerable. Why pick anything remotely vulnerable, when you don't have to? SHA-2 or Bcrypt would be a better choice. </li>
</ol>
<p>Of course, none of this guarantees you'll be able to prevent someone from deducing that <a href="http://www.wired.com/politics/security/commentary/securitymatters/2006/12/72300">Joe User's Myspace account password is "myspace1"</a>.</p>
<p>But when they do, at least it won't be <em>your</em> fault.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/youre-probably-storing-passwords-incorrectly/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Practicing the Fundamentals: The New Turing Omnibus ]]></title>
<link>https://blog.codinghorror.com/practicing-the-fundamentals-the-new-turing-omnibus/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
While researching <a href="http://www.codinghorror.com/blog/archives/000951.html">Classic Computer Science Puzzles</a>, our CEO Scott Stanfield turned me on to A.K. Dewdney's <a href="http://www.amazon.com/exec/obidos/ASIN/0805071660/codihorr-20">The New Turing Omnibus: 66 Excursions in Computer Science</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0805071660/codihorr-20"><img alt="image placeholder" >
</p>
<p>
This is an incredibly fun little book. Sure, it's got Towers of Hanoi, but it's also got so much more:
</p>
<p>
</p>
<blockquote>
<b>The book is designed to appeal both to the educated layperson and to the student of computer science</b>. But how is that possible? The answer lies in the variety of treatments as well as topics. Some of the topics are inherently easy or I have been lucky enough to stumble upon just the right expository mechanisms. Some of the topics are inherently deep or complicated and there is no way around a certain rigor, including occasional mathematical symbolism.
<p>
For students of computer science, the 66 chapters that follow will give a sneak preview of the major ideas and techniques they will encounter in their undergraduate careers and some they may only encounter as graduate students. For professors of computer science, my colleagues, the 66 chapters will amount to a sneak review. Trying to remember how the Boyer-Moore string-matching algorithm went? It's right there in Chapter 61, Searching Strings. As for your lectures, if you like to deliver your own material this book may be what you've been looking for.
</p>
<p>
At one end of its spectrum of uses, <a href="http://www.amazon.com/exec/obidos/ASIN/0805071660/codihorr-20">The (New) Turing Omnibus</a> may be ideal in bringing students from diverse backgrounds "up to speed." At the other end of the spectrum, you retain creative control but draw a few (or many) of your lectures from this book. Finally, for educated laypersons, the book provides a brief roadmap of computability.
</p>
</blockquote>
<p>
I have no idea why I hadn't heard of this book, originally published in 1988 and updated with a second edition in 1993, until now. <b>The New Turing Omnibus is is probably the single closest published equivalent to what I do on this very blog.</b> It's a grab-bag of computing topics. Each chapter is the equivalent of a short blog post examining a particular topic, peppered with tables, diagrams, and illustrations. And the topics aren't presented in any particular order. Browse and find something you like; discard the rest. Here's a short excerpt from Chapter 33, Shannon's Theory - The Elusive Codes:
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
A <a href="http://www.everything2.com/index.pl?node_id=1387467">complete table of contents</a> for all 66 chapters of The New Turing Omnibus is enumerated at Everything2. I think there's a very high probability that if you enjoy reading this blog on a regular basis, you'll also enjoy this remarkable little book. As promised, it's a great way to <a href="http://headrush.typepad.com/creating_passionate_users/2006/03/dont_forget_squ.html">keep practicing the fundamentals</a> for professionals:
</p>
<p>
</p>
<blockquote>
Bert Bates (my co-author) is a blackbelt level go player, one of the best amateur players in the state. But when a visiting expert-- four belt levels above Bert-- showed up at the local go tournament, Bert was surprised to see the guy reading a book on fundamental go problems that Bert had read much earlier in his learning. The expert said, "I must have read this at least a hundred times. My goal each time is to see how much more quickly I can solve all the problems in the book than I did the last time."
<p>
Some of the best athletes never forget the fundamentals-- whether it's Tiger Woods practicing the basics, or a pro basketball player working on free throws. A good musician might still practice arpeggios. A programmer might... I don't know, actually. <b>What would be the fundamentals that a good programmer might forget?</b> I'll have to think about that one.
</p>
</blockquote>
<p>
But it's not just a book for programmers; it's also got a broad, down-to-earth appeal. It's an intriguing collection of thought puzzles for laypeople with at least a passing interest in the field of computer science.
</p>
<p>
If you'd like to see more, you can <a href="http://www.amazon.com/gp/reader/0805071660/ref=sib_dp_pt/102-9499370-6371302#reader-link">browse through a few pages of the book at Amazon</a>. A few more pages are available <a href="http://books.google.com/books?id=XW7fICYtkg8C&amp;dq=&amp;pg=PP1&amp;ots=fWQL2tqxMH&amp;sig=xYri8q7TNdxEokZE0M5cfhT1TA8">in Google books</a>, but beware the randomly inserted "copyrighted image" placeholder instead of the many illustrations and diagrams throughout the book.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/practicing-the-fundamentals-the-new-turing-omnibus/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Lazyweb Calling ]]></title>
<link>https://blog.codinghorror.com/lazyweb-calling/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>It's hard to pin down the exact etymology of the word <strong>Lazyweb</strong>, but it seems to have <a href="http://www.urbandictionary.com/define.php?term=lazyweb">one primary meaning</a>:</p>
<ol>
<li>Asking a question of an internet audience in the hopes that they will be able to find a solution that you were too lazy or inexperienced to find yourself. </li>
</ol>
<p>The word is attributed to old-school internet ultrageek <a href="http://jwz.livejournal.com/">jwz</a>, which I could totally believe. Or it might have been designer <a href="http://www.blackbeltjones.com/work/?p=334">Matt Jones</a>. It can also have a more specific meaning <a href="http://www.openp2p.com/pub/a/p2p/2003/01/07/lazyweb.html">in the context of writing code</a>, as Clay Shirky notes.</p>
<ol>
<li>Waiting for someone else on the internet to write/build/design what you were thinking of. </li>
<li>Describing something in the hopes that someone else on the internet will write/build/design it. </li>
</ol>
<p>Of course, this kind of feature daydreaming can have <a href="http://conferences.oreillynet.com/cs/et2003/view/e_sess/3750">amusing results</a>.</p>
<p>The common theme of all Lazyweb requests is a tacit acknowledgement that <a href="http://despair.com/meetings.html">none of us is as dumb as all of us</a>.</p>
<p><img alt="image placeholder" >
<p>I don't mind Lazyweb requests, within reason. Contrary to popular belief, <strong>there is such a thing as a stupid question</strong>. It's asked by people who failed to do even the most basic kind of research on their question before they asked. I'm not expecting everyone to <a href="http://www.codinghorror.com/blog/archives/000603.html">read a 32 page document prior to asking any questions</a>, but at least cover the basics before casually deciding to make <em>your</em> problem <em>everyone's</em> problem.</p>
<p>There's nothing wrong with harnessing the collective power of the internet to solve a problem you tried-- and failed-- to solve yourself. Assuming you get an answer, once web crawlers find and index your problem, that question and answer is part of the fabric of the web and can potentially help any future travellers as well. <strong>Done right, Lazyweb is a part of the net public good.</strong></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/lazyweb-calling/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Everything Is Fast For Small n ]]></title>
<link>https://blog.codinghorror.com/everything-is-fast-for-small-n/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Let's say you're about to deploy an application. Said app has been heavily tested by your development team, who have all been infected by unit testing fever. It's also been vetted by your QA group, who spent months spelunking into every crevice of the app. You even had a beta test period with <em>real live users</em>, who dutifully filed bugs and put the application through its paces before finally signing off on the thing.</p>
<p>Your application is useful and popular. Your users love it. Your users love you. But over the next week, something curious happens. As people use the application, it gets progressively slower and slower. Soon, the complaints start filtering in.  Within a few weeks, the app is well-neigh unusable due to all the insufferable delays it subjects users to – and <a href="http://www.codinghorror.com/blog/archives/000882.html">your users turn on you</a>.</p>
<p>Raise your hand if this has ever happened to a project you've worked on. If I had a buck for every time I've personally seen this, I'd have enough for a nice lunch date. Developers test with tiny toy data sets, assume all is well, and then find out the hard way that <strong>everything is fast for small n.</strong></p>
<p>I remember a client-side Javascript sort routine we implemented in a rich intranet web app circa 2002. It worked great on our small test datasets, but when we deployed it to production, we were astonished to find that sorting a measly hundred items could take upwards of <em>5 seconds</em> on a user's desktop machine. <a href="http://www.codinghorror.com/blog/archives/000509.html">JavaScript isn't known for its speed</a>, but what the heck?</p>
<p>Well, guess which <a href="http://en.wikipedia.org/wiki/Sort_algorithm">sort algorithm</a> we used?</p>
<p><a href="http://www.epaperpress.com/sortsearch/"><img alt="image placeholder" >
<p>InsertSort is <strong>n<sup>2</sup></strong> (worst case), ShellSort is <strong>n<sup>3/2</sup></strong>, and QuickSort is <strong>n  log n</strong>. But we <a href="http://en.wikipedia.org/wiki/Sorting_algorithm#List_of_sorting_algorithms">could have done worse</a> – we could have picked Bubble Sort, which is n<sup>2</sup> even in the <em>best</em> case.</p>
<p>Friends, do not do this. <strong>Test your applications with large data sets</strong>, at least large enough to cover your most optimistic usage projections over the next year. Otherwise, you may be sorry. And your users definitely <em>will</em> be sorry.</p>
<p>Big O notation is one of those things that's easier seen than explained. But it's a fundamental building block of computer science.</p>
<blockquote>
<strong><a href="http://www.nist.gov/dads/HTML/bigOnotation.html">Big O notation</a></strong>: A theoretical measure of the execution of an <a href="http://www.nist.gov/dads/HTML/algorithm.html">algorithm</a>, usually the time or memory needed, given the problem size n, which is usually the number of items. Informally, saying some equation f(n) = O(g(n)) means it is less than some constant multiple of g(n). The notation is read, "f of n is big oh of g of n".</blockquote>
<p>Developers rely on data structures and databases that have favorable big O notation performance baked in, without thinking much about it. But if you stray from those well-worn paths, <strong>you can be in a world of performance pain – and much sooner than you could have possibly imagined.</strong> The importance of big O notation is best illustrated in this graph from <a href="http://www.amazon.com/exec/obidos/ASIN/0201657880/codihorr-20">Programming Pearls</a>:</p>
<p><img alt="image placeholder" >
<p>The <a href="http://en.wikipedia.org/wiki/TRS-80">TRS-80</a> algorithm is <strong>48n</strong>, and the <a href="http://en.wikipedia.org/wiki/DEC_Alpha">DEC Alpha</a> algorithm is <strong>n<sup>3</sup></strong>.</p>
<p>When n is 10, they're within a second of each other. But when n grows to 100,000, <strong>the modern DEC Alpha takes a month to do what a prehistoric TRS-80 can accomplish in <em>a few hours</em></strong>. Having a big O notation bottleneck in your app is a one-way ticket in the performance wayback machine to 1997 – or worse. Much worse.</p>
<p>There are friendly names for the common big O notations; saying "n squared" is equivalent to saying "quadratic":</p>
<table cellspacing="0" cellpadding="4" width="450">
<tbody>
<tr>
<td><strong>notation</strong></td>
<td><strong>friendly name</strong></td>
</tr>
<tr>
<td>O(1)</td>
<td><a title="Constant" href="http://en.wikipedia.org/wiki/Constant">constant</a></td>
</tr>
<tr>
<td>O(log <em>n</em>)</td>
<td><a title="Logarithmic" href="http://en.wikipedia.org/wiki/Logarithmic">logarithmic</a></td>
</tr>
<tr>
<td>O([log <em>n</em>]<sup>c</sup>)</td>
<td><a title="Polylogarithmic" href="http://en.wikipedia.org/wiki/Polylogarithmic">polylogarithmic</a></td>
</tr>
<tr>
<td>O(<em>n</em>)</td>
<td><a title="Linear" href="http://en.wikipedia.org/wiki/Linear">linear</a></td>
</tr>
<tr>
<td>O(<em>n</em> log <em>n</em>)</td>
<td>sometimes called "<a title="Linearithmic" href="http://en.wikipedia.org/wiki/Linearithmic">linearithmic</a>" or "supralinear"</td>
</tr>
<tr>
<td>O(<em>n</em><sup>2</sup>)</td>
<td><a title="Quadratic" href="http://en.wikipedia.org/wiki/Quadratic">quadratic</a></td>
</tr>
<tr>
<td>O(<em>n</em><sup><em>c</em></sup>)</td>
<td>
<a title="Polynomial" href="http://en.wikipedia.org/wiki/Polynomial">polynomial</a>, sometimes "<a title="Geometric progression" href="http://en.wikipedia.org/wiki/Geometric_progression">geometric</a>"</td>
</tr>
<tr>
<td>O(<em>c</em><sup><em>n</em></sup>)</td>
<td><a title="Exponential" href="http://en.wikipedia.org/wiki/Exponential">exponential</a></td>
</tr>
<tr>
<td>O(<em>n!</em>)</td>
<td><a title="Factorial" href="http://en.wikipedia.org/wiki/Factorial">factorial</a></td>
</tr>
</tbody>
</table>
<p><a href="http://www.epaperpress.com/sortsearch/tim.html">Tom Niemann</a> has handy charts that compare the growth rates of common algorithms, which I've adapted here:</p>
<table cellspacing="0" cellpadding="3" width="700">
<tbody>
<tr>
<td style="background-color: #efefef;" width="100" align="right"><strong> n</strong></td>
<td width="100" align="right"><strong> lg <em>n</em></strong></td>
<td width="100" align="right"><strong> <em>n</em><sup>7/6</sup></strong></td>
<td style="width: 103px;" align="right"><strong> <em>n</em> lg <em>n</em></strong></td>
<td width="100" align="right"><strong> <em>n</em><sup>2</sup></strong></td>
<td width="100" align="right"><strong>7/6<sup><em>n</em></sup> </strong></td>
<td width="100" align="right"><strong><em>n!</em></strong></td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">1</td>
<td>0</td>
<td>1</td>
<td style="width: 103px;">0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">16</td>
<td>4</td>
<td>25</td>
<td style="width: 103px;">64</td>
<td>256</td>
<td>12</td>
<td>20.9 trillion</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;" height="26">256</td>
<td height="26">8</td>
<td height="26">645</td>
<td style="width: 103px;" height="26">2,048</td>
<td height="26">65,536</td>
<td height="26">137 quadrillion</td>
<td height="26">-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">4,096</td>
<td>12</td>
<td>16,384</td>
<td style="width: 103px;">49,152</td>
<td>16,777,216</td>
<td>-</td>
<td>-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">65,536</td>
<td>16</td>
<td>416,128</td>
<td style="width: 103px;">1,048,565</td>
<td>4,294,967,296</td>
<td>-</td>
<td>-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">1,048,476</td>
<td>20</td>
<td>10,567,808</td>
<td style="width: 103px;">20,969,520</td>
<td>1.09 trillion</td>
<td>-</td>
<td>-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">16,775,616</td>
<td>24</td>
<td>268,405,589</td>
<td style="width: 103px;">402,614,784</td>
<td>281.4 trillion</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>Here are sample execution times, assuming one unit of execution is equal to one millisecond of CPU time. That's probably far too much on today's CPUs, but you get the idea:</p>
<table cellspacing="0" cellpadding="3" width="700">
<tbody>
<tr>
<td style="background-color: #efefef;" width="100" align="right"><strong> n</strong></td>
<td width="100" align="right"><strong> lg <em>n</em></strong></td>
<td width="100" align="right"><strong> <em>n</em><sup>7/6</sup></strong></td>
<td width="100" align="right"><strong> <em>n</em> lg <em>n</em></strong></td>
<td width="100" align="right"><strong> <em>n</em><sup>2</sup></strong></td>
<td width="100" align="right"><strong>7/6<sup><em>n</em></sup> </strong></td>
<td width="100" align="right"><strong><em>n!</em></strong></td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">1</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">16</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td>&lt;1 sec</td>
<td> 663 years</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;" height="26">256</td>
<td height="26">&lt;1 sec</td>
<td height="26">&lt;1 sec</td>
<td height="26">2 sec</td>
<td height="26">65 sec</td>
<td height="26">4.3 mlln yrs</td>
<td height="26">-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">4,096</td>
<td>&lt;1 sec</td>
<td>16 sec</td>
<td>49 sec</td>
<td>4.6 hr</td>
<td>-</td>
<td>-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">65,536</td>
<td>&lt;1 sec</td>
<td>7 min</td>
<td>17 min</td>
<td>50 days</td>
<td>-</td>
<td>-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">1,048,476</td>
<td>&lt;1 sec</td>
<td>3 hr</td>
<td>6 hr</td>
<td>35 years</td>
<td>-</td>
<td>-</td>
</tr>
<tr align="right">
<td style="background-color: #efefef;">16,775,616</td>
<td>&lt;1 sec</td>
<td>3 days</td>
<td>4.6 days</td>
<td>8,923 years</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>Notice how quickly we get into trouble as the number of items (n) increases. Unless you've chosen data structures that offer ideal near-logarithmic performance across the board, by the time you get to 4,096 items you're talking about some <em>serious</em> CPU time. Beyond that, I used <strong>dash as shorthand for "forever"</strong>. That's how bad it can get.</p>
<p>Everything is fast for small n. Don't fall into this trap. It's an easy enough mistake to make. Modern apps are incredibly complex, with dozens of dependencies.  Neglect to index one little field in your database and you're suddenly back in TRS-80 land. The only way to truly know if you've accidentally slipped an algorithmic big O bottleneck into your app somewhere is to <strong>test it with a reasonably large volume of data.</strong></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/everything-is-fast-for-small-n/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ On Expose, Flip3D, and Switcher ]]></title>
<link>https://blog.codinghorror.com/on-expos-flip3d-and-switcher/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I'm one of the rare people who actually likes Windows Vista. Sure, it's far from what was originally promised in terms of features, but it's still a solid quality of life improvement from the crusty old 2001 version of Windows XP. Or at least it will be, once Service Pack 1 is released.</p>
<p>Like anything else, there's plenty to be critical of in Vista. One particular feature of Vista that I find almost unforgivably lame is <a href="http://www.microsoft.com/windows/products/windowsvista/features/details/flip3D.mspx">Flip3D</a>.</p>
<p><a href="http://www.microsoft.com/windows/products/windowsvista/features/details/flip3D.mspx"><img alt="image placeholder" >
<p>It's a third-rate clone of Apple's OSX <a href="http://www.apple.com/macosx/features/expose/">Expose feature</a>, which itself is an exploration of <a href="http://www.codinghorror.com/blog/archives/000858.html">zoomable UI</a>.</p>
<p><a href="http://www.apple.com/macosx/features/expose/"><img alt="image placeholder" >
<p>Vista's Flip3D certainly looks cool enough, and you can use your mouse wheel to spin the windows around, which is entertaining for a few seconds. But it fails miserably in terms of actual usability:</p>
<ul>
<li>It only uses the primary monitor to show the window list, so any additional display space you have is completely wasted. </li>
<li>The windows are stacked on top of each other, partially obscuring every window except the topmost one. This also makes the target area for selecting and clicking on any stacked window very small. </li>
<li>The arbitrary switch from a 2D desktop into a 3D display space is mentally disconcerting. This change also slants and distorts the windows, so readability is lower than it should be. </li>
</ul>
<p>In their effort to distinguish themselves from OSX, Redmond created a complete non-feature. Flip3D is barely better than nothing.</p>
<p>But <strong>we don't have to suffer through Flip3D when we can replace it</strong>. There are several nice alternatives. Personally, I recommend <a href="http://www.howtogeek.com/howto/windows-vista/disable-flip3d-in-windows-vista/">disabling Flip3D</a> and mapping Bao Nguyen's <a href="http://insentient.net/">outstanding Switcher</a> to the Windows+Tab key combination.</p>
<p><a href="http://img141.imageshack.us/img141/3517/switcherscreenshotlargejq3.jpg"> <img alt="image placeholder" >
<p>I just noticed that Bao released <a href="http://baostuff.spaces.live.com/Blog/cns!F1D5A55E2D4C903A!330.entry">a new beta version of Switcher</a>:</p>
<ul>
<li>Middle-click a window to close it. </li>
<li>The first 9 windows can be selected by number; the numeric shortcut is superimposed over the window. </li>
<li>Right-click a window to open it, and minimize all other windows. </li>
<li>Windows now have a large text label superimposed in the corner with the title and icon so you can tell what they are. This is helpful if you have many similar-looking windows, or if they're thumbnailed particularly small. </li>
<li>
<span style="color: red;">You can perform an incremental filtering search on all open windows.</span> </li>
</ul>
<p>These are some killer new features. I've wanted to close windows by middle-clicking on them from the zoomed view forever. But the last item on that list is huge. It's a game changer. Instead of playing <a href="http://en.wikipedia.org/wiki/Where%27s_Waldo%3F">Where's Waldo</a> with my windows, I can press Windows+Tab, then type what I want. It's exactly what I described in <a href="http://www.codinghorror.com/blog/archives/000946.html">The Problem With Tabbed Interfaces</a>:</p>
<blockquote>So how can we fix this? How can we integrate tabs with the existing navigational features of the operating system, such as the taskbar, and Expose? I keep coming back to <a href="http://www.codinghorror.com/blog/archives/000595.html">search as the dominant computing metaphor</a>. The only thing I can think of is a plain-text search facility where I type "Gmail", and the OS would automatically highlight that tab (or window) and bring it to the front. That presupposes a very high level of integration between the application tabs and the operating system, however.</blockquote>
<p>It looks like Bao Nguyen was reading my mind. <strong>Pressing Windows+Tab, then typing "Gmail" is the best thing <em>ever</em> as far as I'm concerned.</strong> No, I can't search tab contents, but I can now match by any window title, which is good enough. The way I can begin typing and watch the windows dynamically fling themselves offscreen as they fall out of my filter <em>in real time</em> is a huge productivity boost. I cannot understate how significant this feature is. It redefines the way I deal with windows; I can type what I want instead of expending the mental effort to visually scan thumbnails of 20 different windows.</p>
<p>Unlike Flip3d, the graphical frills of Switcher are all in service to the functionality. That's the way it should be. I Highly recommend trying out <a href="http://baostuff.spaces.live.com/Blog/cns!F1D5A55E2D4C903A!330.entry">the latest beta of Switcher</a>. But be sure to bring a fast video card to the table for the best experience.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/on-expos-flip3d-and-switcher/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ LCD Monitor Arms ]]></title>
<link>https://blog.codinghorror.com/lcd-monitor-arms/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.steve-olson.com/">Steve Olson</a> contacted me a few weeks ago after he saw <a href="http://www.codinghorror.com/blog/archives/000938.html">my post on ergonomic computing</a>. Steve works for <a href="http://www.ergotron.com/">Ergotron</a>, and offered to comp me some monitor arms.</p>
<p>
Usually when I get offered free items related to my blog, I politely decline. I don't want a conflict of interest, and frankly most of the time what I am offered doesn't appeal to me anyway. But as <a href="http://www.codinghorror.com/blog/archives/000740.html">a long time triple monitor enthusiast</a>, I've been pondering the idea of using LCD monitor arms for a few months now, and Ergotron is a model I've seen recommended a bunch of places. So I accepted Steve's offer. <strong>Take this as a disclaimer; I was provided these monitor arms gratis, so my opinion may be biased.</strong></p>
<p>
Initially I was interested in <a href="http://www.ergotron.com/Products/MultimonitorMounts/tabid/159/ctl/Product/mid/545/PRDID/128/language/en-US/default.aspx">their triple monitor mount</a>, but Steve waved me away from that and recommended three <a href="http://www.ergotron.com/tabid/71/ctl/Product/mid/396/PRDID/1/language/en-US/default.aspx">Ergotron LX Desk Mount LCD Arms</a> instead. I figured he's the expert, so I followed his advice.</p>
<p>I got the LX monitor arms installed earlier this week, after a few trials and tribulations, and here's the end result. What you're seeing is a triple monitor configuration, two 24" widescreen SyncMaster 245BW monitors (1920 x 1200), with a single 21.3" SyncMaster 213T in the middle (1600 x 1200).</p>
<p>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=ergotron%20lx&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325"><img alt="image placeholder" >
</p>
<p>The arms free up a ton of space under the monitors. With the large base of the 245BW, I couldn't put my mouse where I wanted to. Now I can.</p>
<p>All LCDs have a standard VESA mounting plate in the rear, which the arms are designed to slot into like lego bricks. Installing the arms is a simple matter of unbolting the default base from your LCD monitor, and bolting the monitor to the arm. However, be careful – there is more than one <a href="http://www.ergotron.com/tabid/300/language/en-US/default.aspx">VESA mounting plate standard</a>, and larger monitors require larger plates. Ergotron provides a <a href="http://www.ergotron.com/tabid/354/language/en-US/default.aspx">display compatibility page</a> where you can check to see what you'll need. The <strong>100 x 100 mm VESA mounting panel is very common</strong>, but if your monitor is 22" or larger you might have something bigger, as I did on my 24"s.</p>
<p>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=ergotron%20lx&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325"><img alt="image placeholder" >
<p>
Before I set the monitor arms up, I had them sitting on my desk for test purposes, and they were quite the conversation pieces. People kept stopping by my office to check them out and ask what they were, and how they worked.</p>
<p>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=ergotron%20lx&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325"><img alt="image placeholder" >
</p>
<p>
As you can see, I have a 2x1 and 1x1 configuration, two bases with three arms. The base clamps against the bottom of the desk, so you'll need an unobstructed edge to attach them to. We found the best results came from clamping both bases through the holes cut in the desk for cable routing. These holes were never obstructed and offered the best positioning options. There's a clever little integrated cable conduit built into the underside of the larger part of the arm, so the cables don't droop behind the monitor.</p>
<p>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=ergotron%20lx&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325"><img alt="image placeholder" >
</p>
<p>The Ergotron LX monitor arms have exceeded my expectations. They …</p>
<ul>
<li>give your monitors a sleek "floating" look </li>
<li>free up a substantial amount of space on your desk </li>
<li>allow you to reposition the monitors at will </li>
</ul>
<p>The arms are counterweighted and spring tensioned; once you adjust the tension screws for the monitor, you can (almost) effortlessly rotate, angle, and move the LCDs horizontally or vertically within the range of the arm. Turning a monitor to demo something, and then slotting it back into place when I'm done, is no problem.</p>
<p>When I initially considered monitor arms, I decided it was a better investment to upgrade one of my monitors than it was to buy three monitor arms that I may or may not like. Now that I've used these arms for a few days, <strong>I like them so much I'm considering buying a set for myself to use at home.</strong> Yes, with my own money. <a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=ergotron%20lx&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">Amazon carries the Ergotron LX</a> in black and silver for about $115. You can even use these arms to hold your laptop.</p>
<p>Fancy monitor arms are by no means required. The stock LCD monitor bases included by the manufacturers work just fine. But if you're willing to invest a bit and customize your setup, I think the payoff – in terms of flexibility, looks, and convenience – is well worth it.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/lcd-monitor-arms/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Steve McConnell in the Doghouse ]]></title>
<link>https://blog.codinghorror.com/steve-mcconnell-in-the-doghouse/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I often trot out <a href="http://stevemcconnell.com/articles/art03.htm">Steve McConnell's doghouse analogy</a> to illustrate how small projects aren't necessarily representative of <a href="http://blog.codinghorror.com/the-long-dismal-history-of-software-project-failure/">the problems</a> you'll encounter on larger projects.</p>
<blockquote>
People who have written a few small programs in college sometimes think that writing large, professional programs is the same kind of work -- only on a larger scale. It is not the same kind of work. <b>I can build a beautiful doghouse in my backyard in a few hours.</b> It might even take first prize at the county fair's doghouse competition. But that does not imply that I have the expertise to build a skyscraper. The skyscraper project requires an entirely more sophisticated kind of expertise.
</blockquote>
<p>There's a similar passage in <a href="http://www.amazon.com/exec/obidos/ASIN/1556159005/codihorr-20">Rapid Development</a>, which I cited in <a href="http://blog.codinghorror.com/following-the-instructions-on-the-paint-can/">Following the Instructions on the Paint Can</a>.</p>
<blockquote>
<p>What happens if you don't follow the instructions? If you're painting a doghouse on a hot Tuesday night after work, you might only have 2 hours to do the job, and Fido needs a place to sleep that night. You don't have time to follow the instructions. You might decide that you can skip steps 1 through 3 and apply a thick coat rather than a thin one in step 4. If the weather's right and Fido's house is made of wood and isn't too dirty, your approach will probably work fine.</p>
<img alt="image placeholder" >
<p>Over the next few months the paint might crack from being too thick or it might flake off from the metal surfaces of the nails where you didn't prime them, and you might have to repaint it again next year, but it really doesn't matter.</p>
<p>What if, instead of a doghouse, you're painting a Boeing 747? In that case, you had better follow the instructions to the letter. If you don't strip off the previous coat, you'll incur significant fuel efficiency and safety penalties: a coat of paint on a 747 weighs 400 to 800 pounds. If you don't prepare the surface adequately, wind and rain attacking the paint at 600 miles per hour will take their toll much quicker than a gentle wind and rain will on Fido's doghouse.</p>
</blockquote>
<p>The underlying lesson is the same: what works for small projects may be a total disaster on a larger scale. <b>Being a competent software engineer means choosing appropriate strategies for the size of the project you're working on</b>. Are you working on a doghouse, a skyscraper, a jet airliner, or <a href="http://blog.codinghorror.com/were-building-the-space-shuttle/">the space shuttle</a>?</p>
<p>Perhaps that's why I was so entertained by <a href="http://web.archive.org/web/20070623170339/http://blogs.construx.com/blogs/stevemcc/archive/2007/09/23/building-a-fort-lessons-in-software-estimation.aspx">Steve's most recent blog post</a>. He documents building a fort for his kids. It's not <i>exactly</i> a doghouse, but it's close. Along the way, Steve applies his considerable software estimation and project planning skills to the project. (Remember, this is the guy who <a href="http://blog.codinghorror.com/recommended-reading-for-developers/">quite literally wrote the books</a> on these subjects.) It's a small project, too, so our odds of success are <a href="http://blog.codinghorror.com/diseconomies-of-scale-and-lines-of-code/">about as good as they're going to get</a>.</p>
<blockquote>
<p>Whenever I do a physical construction project like this I try to pay attention to which attributes of the project are similar to software projects and which are different. The comparisons are made more challenging by the fact that my construction projects are recreational, whereas I'm trying to draw comparisons to commercial software projects. For the first half of the project, no good similarities jumped at out me. But as the project started to take much longer than I expected, <b>I began to see more and more similarities between my estimates on the fort and problems people run into with software estimates.</b></p>
</blockquote>
<p>How did it go?</p>
<blockquote>
<p>Days 3-6 went about like Days 1 &amp; 2 had gone, which is to say there were lots of little tasks that turned out to be medium-sized tasks, there were little tasks that I just hadn't anticipated, and most things took longer than I had planned. By the end of Day 7 (my buffer day), I was done with the tasks I had planned for Day 3 and had a tiny start on Day 4, which is to say that I'd completed the decking, hadn't started on the railings or framing, and had one wall of the fort framed, but that was all.</p>
<p>My original plan had called for about a week full time and then another couple of weeks of finishing up loose ends like painting, installing trim, and so on. I finished the fort about 6 weeks after I started it, so I was about 100% over my planned schedule, and I ended up at 2-3x my originally planned effort.</p>
</blockquote>
<p>Steve got subsumed in the unpredictable details. This completely mirrors my software project experience. <b>Often, you can't even begin to accurately estimate how long something will take until you start doing it.</b> At least some of it. That's why so many teams turn to <a href="http://blog.codinghorror.com/anything-but-waterfall/">agile, iterative development techniques</a>; part of each iteration involves exploring all those unknowns and turning them into slightly-less-unknowns for the next iteration. <a href="http://blog.codinghorror.com/boyds-law-of-iteration/">The faster we iterate</a>, the closer we get to an accurate estimate, and the more work we get done along the way. We plan by doing.</p>
<p>This is easily my favorite post in <a href="http://web.archive.org/web/20070623170339/http://blogs.construx.com/blogs/stevemcc/default.aspx">Steve's blog</a> to date. Do <a href="http://web.archive.org/web/20070623170339/http://blogs.construx.com/blogs/stevemcc/archive/2007/09/23/building-a-fort-lessons-in-software-estimation.aspx">read the entire post</a> for all the gory details of how things went awry. It's a storybook example of how an <a href="http://blog.codinghorror.com/escaping-from-gilligans-island/">avalanche of little problems</a> can snowball into one huge project delay – even if you're Steve McConnell. And even if you're only building a <s>doghouse</s> fort.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/steve-mcconnell-in-the-doghouse/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Slaying Mighty Dragons: Competitive Ranking and Matching Systems ]]></title>
<link>https://blog.codinghorror.com/slaying-mighty-dragons-competitive-ranking-and-matching-systems/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Attending yesterday's <a href="http://www.halo3.com/">Halo 3</a> launch event at the Silicon Valley Microsoft campus -- and the large Halo3 tournament we helped moderate -- got me thinking about player ranking and matching systems. Without a well-designed ranking and matching system in place, you'll get horribly mismatched games, where one team demolishes the other by a margin of 3x or more. This is counterproductive for both teams:
</p>
<p>
</p>
<ul>
<li>
<b>The higher skilled team</b> learns absolutely nothing by defeating their underskilled opponent. They're coasting by without a challenge. I suppose it's fun, in a way, to win every match and crush your opponents. But it's ultimately an empty and meaningless style of play.
<p>
</p>
</li>
<li>
<b>The lower skilled team</b> is demoralized by a total, crushing defeat at the hands of the higher skilled team. There's no incentive to continue. And when you're consistently matched against opponents that you have no chance of winning against, <a href="http://www.penny-arcade.com/comic/2002/07/26">why play at all?</a>
</li>
</ul>
<p>
An ideal system would always match players of <i>approximately equal skill</i> against each other. How do you know when you've achieved that goal? You look at the data. The record of wins, losses, and ties for each player provides the answer: if the matching and ranking system is working properly, every player or team will eventually plateau at a skill level where they are <b>winning about 50% of the time.</b>
</p>
<p>
There are dozens of possible ranking and rating systems we could use. Christopher Allen and Shannon Appelcline's post <a href="http://www.lifewithalacrity.com/2006/01/ranking_systems.html">Collective Choice: Competitive Ranking Systems</a> explores many of them. But perhaps the most famous ranking system is the <a href="http://en.wikipedia.org/wiki/ELO_rating_system">Elo rating system</a>, which originated in the chess world. It's a simple statistical model used to <a href="http://jobemakar.blogspot.com/2007/05/why-elo-rating-system-rocks.html">objectively rate player skill levels</a>:
</p>
<p>
</p>
<blockquote>
Here's how Elo works:
<p>
</p>
<ul>
<li>A new player is assigned a default rating, say 1200.
</li>
<li>Two players compete, with one of three results: win, loss, tie.
</li>
<li>The two player's ratings are fed into an algorithm along with the end state of the game. A new rating for each player is returned.
</li>
</ul>
<p>
Let's say two players, both rated 1200, play a game. Player 1 wins. Player 1 will now be rated 1205 and player 2 will be rated 1195.
</p>
<p>
Players that win a lot will achieve higher ratings. But the higher rated player also starts to see diminishing returns for defeating low ranked players. In order to increase his rank, he must defeat other higher ranked players. If a high ranked player loses to a low ranked player, he loses much more of his rating then he'd gain if he won the match.
</p>
<p>
Over time the game players will end up being rated based on their Elo skill level rather than other factors.
</p>
</blockquote>
<p>
It's simpler than it seems. Let me put this in language us geeks can understand: <b>you gain more XP from slaying a massive, mighty dragon than you do from beating up on a common wharf rat.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As you level up, it's entirely possible that you may become so very powerful that you'll have to move on from those massive dragons to even more intimidating opponents. Seems obvious enough to those of us who understand the statistical conventions of Dungeons and Dragons.
</p>
<p>
The Elo system, like the Dungeons and Dragons system, is proven to work. Although it was originally designed to rank chess players, it's used <a href="http://en.wikipedia.org/wiki/ELO_rating_system#Elo_ratings_in_other_competitions">throughout the online and offline gaming worlds</a> to rank and match players, in everything from Pokemon to Scrabble to World of Warcraft.
</p>
<p>
When it comes to matching players online, <a href="http://www.blizzard.com/">Blizzard Entertainment</a> is arguably one of the most experienced companies on the planet. They pioneered online ranking systems back in 1996 with Diablo and <a href="http://en.wikipedia.org/wiki/Battle.net">battle.net</a>, and extended that lead through Starcraft, Diablo II, Warcraft III, and the juggernaut that is World of Warcraft. Blizzard has collectively matched and ranked millions of players-- if anyone knows how to get this right, it's Blizzard.
</p>
<p>
Warcraft III is an excellent case study in player ranking and matching. Despite Blizzard's prior experience, and even though it uses the proven Elo ranking system, Warcraft III had <a href="http://www.penny-arcade.com/comic/2002/07/26">a lot of problems matching players</a> -- problems that took years for Blizzard to work out. I myself was an avid Warcraft III ranked player for about a year, so I've experienced this first hand. <a href="http://www.battle.net/war3/files/amm.shtml">Warcraft III's automatic matching system was radically overhauled with Patch 1.15</a> in 2004, a full two years after the game was released. If you scrutinize the Blizzard support FAQs, you can read between the lines to see where the exploits and pathologies are:
</p>
<p>
1. <b>Until a player has played a certain number of games, their performance will be highly variable, and accurately matching them is difficult.</b>
</p>
<p>
</p>
<blockquote>
<a href="http://www.battle.net/war3/ladder/w3xp-ladder-info-ladderfaq.aspx?Gateway=Lordaeron">The skill of players with low-level accounts can vary radically</a>, from a player who has just begun playing multiplayer games of Warcraft III to a highly experienced player who has played hundreds of games but has just created a new account. Novice players would all too often find themselves in unfair matches against very skilled opponents. In an attempt to better match players of similar skill together into games, Battle.net's matchmaking system no longer uses a player's level as the only determining factor when creating games.
</blockquote>
<p>
2. <b>Unless players are consistently playing games, their rating should decay over time.</b>
</p>
<p>
</p>
<blockquote>
<a href="http://www.battle.net/war3/ladder/w3xp-ladder-info-ladderrules.aspx?Gateway=Lordaeron">Players may lose XP if they do not play a minimum number of games per week</a>, as listed on <a href="http://www.battle.net/war3/ladder/war3-ladder-info-charts.aspx?Gateway=Lordaeron#chart1">Chart 1</a>. Failure to play the minimum game requirement during a week results in an XP penalty. For each game you don't play below the amount required for your level, you incur one loss [to an opponent of the same skill level].
</blockquote>
<p>
3. <b>Players cannot cherry-pick opponents or environments to improve their ranking. They must play randomly chosen opponents on neutral ground.</b>
</p>
<p>
</p>
<blockquote>
<a href="http://www.blizzard.com/war3/features/battlenet.shtml">Battle.net's ladder system has been revamped for Warcraft III.</a> This new system promotes active competition and maintains the ladder's integrity. The anonymous matchmaking system (AMM) prevents win trading and ensures that high-level players face opponents of similar skill. The AMM anonymously matches players based on skill level, and randomly selects maps based on the players' preferences. Players can choose their race, but most other game options are preset by the designers, resulting in a higher level of play.
</blockquote>
<p>
If you're not into anonymous play, arranged team games are possible, but they are isolated on a special ladder of their own. This is done to prevent any kind of player collusion from tainting the main ladder results.
</p>
<p>
You can find many of the very same dangers echoed in <a href="http://en.wikipedia.org/wiki/ELO_rating_system#Practical_issues">the "practical issues" section</a> of the Elo rating Wikipedia entry. Chess games and real-time strategy games are completely different things, but they have strikingly similar ranking and matching pathologies.
</p>
<p>
One particular weakness of the Elo system is <b>the overly simplified assumption that the performance of every player will follow a normal distribution</b>. This is a more severe problem than you might think, as it disproportionately affects new and beginning players. As Blizzard noted above, "Novice players would all too often find themselves in unfair matches against very skilled opponents." For many games, a large proportion of your audience will be novices. If these novice players experience several bad mismatches, they may never come back, and pretty soon you won't have a community of gamers to match anyone against.
</p>
<p>
Most modern implementations of the Elo system make adjustments to rectify this glaring flaw:
</p>
<p>
</p>
<blockquote>
Subsequent statistical tests have shown that <b>chess performance is almost certainly not normally distributed</b>. Weaker players have significantly greater winning chances than Elo's model predicts. Therefore, both the USCF and FIDE have switched to formulas based on the logistic distribution. However, in deference to Elo's contribution, both organizations are still commonly said to use "the Elo system".
</blockquote>
<p>
Perhaps the most modern variant of Elo is <a href="http://research.microsoft.com/mlp/apg/Details.aspx">Microsoft's TrueSkill ranking system</a> used on its Xbox Live online gaming network. The TrueSkill system has better provisions for scoring team games, whereas Elo is based on the single player per game model. But TrueSkill's main innovation is incorporating the uncertainty of a player's rating deeply into the mathematical model.
</p>
<p>
</p>
<blockquote>
Rather than assuming a single fixed skill for each player, the system characterises its belief using a bell-curve belief distribution (also referred to as Gaussian) which is uniquely described by its mean <font color="red">ÃŽÂ¼</font> (mu) ("peak point") and standard deviation <font color="blue">ÃÆ’</font> (sigma) ("spread"). An exemplary belief is shown in the figure.
<p>
<img alt="image placeholder" >
</p>
<p>
Note that the area under the skill belief distribution curve within a certain range corresponds to the belief that the player's skill will lie in that range. For example, the green area in the figure on the right is the belief that the player's skill is within level 15 and 20. As the system learns more about a player's skill, <font color="blue">ÃÆ’</font> has the tendency to become smaller, more tightly bracketing that player's skill. Another way of thinking about the <font color="red">ÃŽÂ¼</font> and <font color="blue">ÃÆ’</font> values is to consider them as the "average player skill belief" and the "uncertainty" associated with that assessment of their skill.
</p>
</blockquote>
<p>
It's more complex math than the relatively simple classic Elo ranking system, but TrueSkill should result in more accurate ranking and matching. Remember, that's why we're doing this: <b>to achieve the best possible gameplay experience for <i>all</i> players</b>, not just the elite players who have hundreds of games under their belt.
</p>
<p>
Our goal is to match players of all skill levels to their counterparts, and to let players reliably rise in rank until they reach a natural plateau of 50% win/loss ratio. We don't want blowouts. We want nail-biting, edge-of-your-seat cliffhangers every time, games that go down to the wire. We will know we've succeeded when <b>each player feels like every game was the equivalent of slaying a massive, mighty dragon-- and not beating up on some puny wharf rats.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/slaying-mighty-dragons-competitive-ranking-and-matching-systems/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Can Your Team Pass The Elevator Test? ]]></title>
<link>https://blog.codinghorror.com/can-your-team-pass-the-elevator-test/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Software developers do <a href="http://blog.codinghorror.com/the-best-code-is-no-code-at-all/">love to code</a>. But very few of them, in my experience, can explain <i>why</i> they're coding.  Try this exercise on one of your teammates if you don't believe me. Ask them what they're doing. Then ask them why they're doing it, and <i>keep</i> asking until you get to a reason your customers would understand.</p>
<blockquote>
<p>What are you working on?<br><br>
<i>I'm fixing the sort order on this datagrid.</i><br></p>
<p>Why are you working on that?<br><br>
<i>Because it's on the bug list.</i><br></p>
<p>Why is it on the bug list?<br><br>
<i>Because one of the testers reported it as a bug.</i><br></p>
<p>Why was it reported as a bug?<br><br>
<i>The tester thinks this field should sort in numeric order instead of alphanumeric order.</i><br></p>
<p>Why does the tester think that?<br><br>
<i>Evidently the users are having trouble finding things when item 2 is sorted under item 19.</i><br></p>
</blockquote>
<p>If this conversation seems strange to you, you probably haven't worked with many software developers. Like <a href="http://www.youtube.com/results?search_query=tootsie+pop+owl">the number of licks it takes to get to the center of a tootsie pop</a>, it might surprise you just how many times you have to ask "why" until you get to something – <i>anything</i> – your customers would actually care about.</p>
<p>It's a big disconnect.</p>
<p><b>Software developers think their job is writing code. But it's not.</b>* Their job is to solve the customer's problem. Sure, our preferred medium for solving problems is software, and that does involve writing code. But let's keep this squarely in context: writing code is something you <i>have</i> to do to deliver a solution. It is not an end in and of itself.</p>
<p>As software developers, we spend so much time mired in endless, fractal levels of detail that it's all too easy for us to fall into the trap of coding for the sake of coding. Without a clear focus and something to rally around, we lose the context around our code. That's why <a href="http://blog.codinghorror.com/vision-quest/">it's so important to have a clear project vision statement</a> that everyone can use as a touchstone on the project. If you've got the vision statement down, <b>every person on your team should be able to pass the "elevator test" with a stranger – to clearly explain what they're working on, and why anyone would care, within 60 seconds</b>.</p>
<p>If your team can't explain their work to a layperson in a meaningful way, you're in trouble, whether you realize it or not. But you are in good company. Jim Highsmith is here to help. He explains <a href="http://www.joelonsoftware.com/articles/JimHighsmithonProductVisi.html">a quick formula for building a project vision model</a>:</p>
<blockquote>
<p>A product vision model helps team members pass <b>the elevator test</b> – the ability to explain the project to someone within two minutes. It comes from Geoffrey Moore's book <a href="http://www.amazon.com/exec/obidos/ASIN/0066620023/codihorr-20">Crossing the Chasm</a>. It follows the form:</p>
</blockquote>
<blockquote>
<ul>
<li>for <i>(target customer)</i><br>
</li>
<li>who <i>(statement of need or opportunity)</i><br>
</li>
<li>the <i>(product name)</i> is a <i>(product category)</i><br>
</li>
<li>that <i>(key benefit, compelling reason to buy)</i><br>
</li>
<li>unlike <i>(primary competitive alternative)</i><br>
</li>
<li>our product <i>(statement of primary differentiation)</i><br>
</li>
</ul>
<p>Creating a product vision statement helps teams remain focused on the critical aspects of the product, even when details are changing rapidly. It is very easy to get focused on the short-term issues associated with a 2-4 week development iteration and lose track of the overall product vision.</p>
</blockquote>
<p>I'm not a big fan of formulas, because they're so, well, <i>formulaic</i>. But it's a reasonable starting point. Play <a href="http://en.wikipedia.org/wiki/Mad_Libs">Mad Libs</a> and see what you come up with. It's worlds better than no vision statement, or an uninspiring, rambling, ad-hoc mess masquerading as a vision statement. However, I think Jim's second suggestion for developing a vision statement holds much more promise.</p>
<blockquote>
<p>Even within an IT organization, I think every project should be considered to produce a "product." Whether the project results involve enhancements to an internal accounting system or a new e-commerce site, product-oriented thinking pays back benefits.</p>
<p>One practice that I've found effective in getting teams to think about a product vision is the Design-the-Box exercise. This exercise is great to open up a session to initiate a project. <b>The team makes the assumption that the product will be sold in a shrink-wrapped box, and their task is to design the product box front and back.</b> This involves coming up with a product name, a graphic, three to four key bullet points on the front to "sell" the product, a detailed feature description on the back, and operating requirements.</p>
<p>Coming up with 15 or 20 product features proves to be easy. It's figuring out which 3 or 4 would cause someone to buy the product that is difficult. One thing that usually happens is an intense discussion about who the customers really are.</p>
</blockquote>
<p>Design-the-Box is a fantastic way to formulate a vision statement. It's based on a concrete, real world concept that most people can easily wrap their heads around. Forget those pie-in-the-sky vision quests: <b>what would our (hypothetical) product box look like?</b></p>
<p>We're all consumers; the design goals for a product box are obvious and universal. What is a product box if not the ultimate elevator pitch? It should...</p>
<ul>
<li>Explain what our product is in the simplest possible way.</li>
<li>Make it crystal clear why a potential customer would want to buy this product.</li>
<li>Be uniquely identifiable amongst all the other boxes on the shelf.</li>
</ul>
<p>Consider the box for the <a href="http://www.microsoft-watch.com/content/operating_systems/bill_gates_legacy_microsofts_top_10_flops.html">ill-fated</a> <a href="http://en.wikipedia.org/wiki/Microsoft_Bob">Microsoft Bob</a> product as an example. How do you explain why customers should want Microsoft Bob? How would you even explain what the heck Microsoft Bob <i>is</i>?</p>
<p><a href="http://img237.imageshack.us/img237/9201/bobfrontlargero7.jpg"><img alt="image placeholder" >
<a href="http://img241.imageshack.us/img241/9260/bobbacklargehs7.jpg"><img alt="image placeholder" >
<p>It's instructive to look at existing product boxes you find effective, and those you find ineffective. We definitely know <a href="http://www.youtube.com/results?search_query=microsoft+ipod">what our product box <i>shouldn't</i> look like</a>.</p>
<iframe width="480" height="360" src="//www.youtube.com/embed/G9HfdSp2E2A" frameborder="0" allowfullscreen></iframe>
<p>Have a <a href="http://blog.codinghorror.com/vision-quest/">rock solid vision statement for your project from day one</a>. If you don't, use one of Jim's excellent suggestions to build one up immediately. <b>Without a coherent vision statement, it's appalling how many teams can't pass the elevator test– they can't explain what it is they're working on, or why it matters.</b> Don't make that same mistake. Get a kick-ass vision statement that your teammates can relate their work to. Make sure <i>your</i> team can pass the elevator test.</p>
<p>* Completely stolen from Billy Hollis' great <a href="https://www.youtube.com/watch?v=LiGsw_k8JhY">15-minute software addicts talk</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/can-your-team-pass-the-elevator-test/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Are Web Uploads So Painful? ]]></title>
<link>https://blog.codinghorror.com/why-are-web-uploads-so-painful/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As video on the web becomes increasingly mainstream, I've been dabbling a bit with video sharing myself. But <b>I've found that publishing video content on the web is extraordinarily painful</b>, bordering on cruel and unusual punishment. The web upload process is a serious barrier to online video sharing, and here's why:
</p>
<p>
</p>
<ol>
<li>
<b>Video files are huge</b>
<p>
Video files are easily the largest files most users will ever create. Even at very modest resolutions and bitrates, the filesize will be more than 10 megabytes for anything except the shortest of video clips. And high definition? Forget about it. That's hundreds of megabytes.
</p>
<p>
</p>
</li>
<li>
<b>Limited upstream bandwidth</b>
<p>
Most people have highly asymmetric internet connections: massive download bandwidth, but the tiniest trickle of upload bandwidth. This trickle of upload has to be shared among all the applications competing for bandwidth. Uploading giant video files is challenging under the best of conditions, and most people's internet connections are more like worst case scenarios for uploading.
</p>
<p>
</p>
</li>
<li>
<b>Uploads are precious</b>
<p>
Downloads are a dime a dozen. If a download fails, who cares? There are a hundred different sources to get any particular download from. Re-downloading is fast and easy. But uploads are different. If you're uploading a video, it's likely something you have somehow edited and invested time in. Maybe it's a video you created yourself. You're uploading it with the intent of sharing. If the upload fails, you won't be able to share what you've created with anyone-- so you care intensely about that upload. Uploads are far more precious than downloads, and should be treated with appropriate respect by the browser and the server.
</p>
</li>
</ol>
<p>
Worst of all, <b>our existing browser and HTTP infrastructure is absolutely horrible at handling large file uploads</b>. I mean profoundly, abysmally bad.
</p>
<p>
Consider the <a href="http://video.google.com/videouploadform">upload form for Google Video</a>. It does as little as it possibly can without actually being a vanilla HTML 4.01 form. Once I start an upload of my many-megabyte video file, there's no feedback whatsoever about what's happening. There's only a generic animated GIF and an admonishment not to close the browser window. When will my upload be done? Could be 10 minutes; could be 10 hours. Who knows?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The <a href="http://www.youtube.com/my_videos_upload">YouTube video upload page</a> is slightly better; it uses a flash-based element to provide basic percentage-done feedback on the upload.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Despite the spartan progress feedback, the YouTube upload page is hardly any better than the Google Video upload page. If I accidentally navigate away from the upload page-- or much to my chagrin, if I click on that "having trouble" link-- my upload is arbitrarily cancelled with no warning whatsoever. There's no hope of resuming where I left off. I have to start over from scratch, which is <i>punishing</i> when you're dealing with a large video file and a typical trickle-upload internet connection.
</p>
<p>
If Google Video and YouTube represent the state of the art for web-based video uploads, that's an embarrassment.
</p>
<p>
I can't find <i>any</i> video sharing sites that do uploads well. <b>Large file upload seems to be a textbook case for the advantages of desktop applications over even the most modern of web applications.</b> The Google Video page actually recommends using <a href="https://www.google.com/video/upload/UploadInfo?hl=en">their desktop uploader</a> for video files over 100 megabytes in size. Based on my abysmal user experience to date, I'm inclined to use a desktop uploader for any video file over <i>10</i> megabytes.
</p>
<p>
Large file uploads are an inhospitable wasteland on today's web. But what really drives me crazy is that <i>it doesn't have to be this bad</i>. Our web browsers are failing us. <b>Current web browsers treat downloads as first-class citizens, but uploads don't even rate third-class treatment.</b> Internet Explorer provides a nice enough download user interface:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Like so much about IE, this download dialog has barely changed since 1999. Firefox has an improved download dialog that handles multiple simultaneous downloads.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Why can't browsers, at the very least, provide the same level of feedback about uploads as they do about downloads?</b> The browser surely knows the size of the file I just told it to upload, and it's responsible for streaming those bytes to the server, so it should also be able to tell me when the upload will finish. Longer term, I'd like to see support for resumable uploads, just like today's browsers can resume HTTP downloads in some select scenarios.
</p>
<p>
It's clear to me that large file uploads will become increasingly prevalent on the web as video trickles down to the mainstream. <b>Uploads are not the freakish edge conditions they might have been in 2001.</b> I hope future browsers can extend the same great support they have for file downloads to file uploads. But that doesn't help us today. Perhaps more sophisticated browser plugin environments-- such as <a href="http://silverlight.net/">Silverlight</a> and <a href="http://labs.adobe.com/technologies/air/">AIR</a> -- can enable a better user experience for these large file uploads, sooner rather than later.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-are-web-uploads-so-painful/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Computer Display Calibration 101 ]]></title>
<link>https://blog.codinghorror.com/computer-display-calibration-101/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you've invested in a quality monitor for your computer, you owe it to yourself-- and your eyes-- to spend 15 minutes setting it up properly for your viewing environment. I'm not talking about <a href="http://www.dansdata.com/spyder.htm">a high-end color calibration</a>, although you can certainly do that. I'm talking about <b>basic computer display calibration 101</b>.
</p>
<p>
The first piece of advice is essential -- make sure your LCD display is connected to your computer via a digital connection.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The DVI port, on the left, is the one you want. Avoid using the standard analog VGA connector, on the right. <b>A DVI connection guarantees that your display is sent a pure, digital stream of bits</b>, shuttled directly from your video card with no analog impurities introduced along the way.
</p>
<p>
In the bad old days of analog CRTs, we had to worry about a whole host of analog issues with the monitor itself, such as convergence, display curvature and geometry, refresh rate, bloom, resolution sizing, and so on. Every time I bought a new CRT, I'd spend a solid hour going through <a href="http://www.softpedia.com/get/Multimedia/Video/Other-VIDEO-Tools/Nokia-Monitor-Test.shtml">Nokia's classic monitor test program</a>, adjusting monitor settings to reduce all the unavoidable analog side effects of an electron scanning CRT. It was a tweaker's paradise.
</p>
<p>
The good news is that a digitally connected LCD is much closer to perfect out of the box than any CRT ever was. There's very little tweaking necessary to get it looking its best.
</p>
<p>
Display calibration probably isn't anyone's idea of a good time, but it can be relatively painless. One of my favorite basic display calibration wizards is the one built into <a href="http://www.microsoft.com/windows/products/windowsvista/features/details/mediacenter.mspx">Windows Media Center</a>. It's accessible via Settings, TV, Configure Your TV or Monitor. It's based on a series of brief, themed video clips that do a great job of explaining why each setting matters without bogging down in display-geek terminology. There are five sections:
</p>
<p>
</p>
<ol>
<li>Onscreen Centering and Sizing
</li>
<li>Aspect Ratio (Shape)
</li>
<li>Brightness (Black &amp; Shadow)
</li>
<li>Contrast (White)
</li>
<li>RGB Color Balance
</li>
</ol>
<p>
The first two are mostly irrelevant for a digitally connected LCD display, provided you're running at the <a href="http://en.wikipedia.org/wiki/Native_resolution">native resolution</a> of the LCD display. I'll assume you are. The last three are the only adjustments that typically matter on a desktop LCD. I'll summarize each, along with a static screenshot from the video, so you can follow along on your display.
</p>
<p>
<b>3. Brightness (Black &amp; Shadow)</b>
</p>
<p>
Locate the brightness control for your display. Adjust the brightness, making sure you can distinguish the shirt from the suit. The suit should be black, not gray. If you see a moving X, turn the brightness down until the X just disappears.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
On a LCD, <a href="http://www.drycreekphoto.com/Learn/Calibration/monitor_black.htm">the brightness control doesn't have quite the same meaning</a> as it does on a CRT. <font color="red">If your LCD has a gamma adjustment, that will be more effective at bringing out the nearly-black details on the shirt than increasing the backlight intensity will</font>. Also, if you're looking for that X, you won't find it. I had trouble capturing the very dark moving X in my static screenshot for some reason. I've seen a very similar calibration technique used in video games which rely on dark environments. The goal is the same-- we want to see the deepest possible blacks on our display, without losing details in the darkness.
</p>
<p>
<b>4. Contrast (White)</b>
</p>
<p>
Locate the contrast control for your display. Set the contrast as high as possible without losing the wrinkles and buttons on the shirt. Lower the contrast if the white cue stick does not appear straight and smooth.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Digital fixed pixel displays <a href="http://www.digitalvideoessentials.com/display_calibration.php">won't have blooming problems</a>, so you can ignore that last bit about the stick. But you can see where this is a complementary operation to the brightness adjustment we just made-- we want to see the brightest white details on our display, without blowing them out.
</p>
<p>
<b>5. RGB Color Balance</b>
</p>
<p>
Locate the RGB color balance control for your display. If your monitor has a color temperature setting, set it to 6500k (sometimes called "Warm" or "Low"). Make sure none of the gray bars have a tinge of red, green, or blue. You may need to fine tune brightness and contrast again after adjusting the color balance.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
And that's it. <b>A few minor adjustments to the Brightness, Contrast, and Color settings of your monitor</b> is all it takes to get the most out of today's LCD displays-- to see all the colors, and the entire range of light to dark, that you paid for.
</p>
<p>
You should always start with the controls on the monitor itself. Unfortunately, some monitors won't allow you to change the brightness, contrast, and color settings in digital mode. Or perhaps you can't quite get the precision you need from the monitor's controls. Most video drivers will allow you to change these settings at the video card level.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Be careful, however, as there are usually <i>two</i> sets of settings: one for video playback, and the other for your desktop itself. I'd avoid changing brightness, contrast, or color settings via the video driver unless you have no other choice. It adds another layer of complexity to an already complex situation.
</p>
<p>
The <a href="http://reviews.cnet.com/4520-11249_7-5582255-1.html?tag=nav">general calibration steps for a LCD television</a> are awfully similar to the Windows Media Center wizard I outlined above. But both are still rudimentary. You'll need to do <a href="http://www.normankoren.com/makingfineprints1A.html">much more involved calibration for professional color work</a>.
</p>
<p>
These calibrations are also video-centric. It's an entirely fair point to note that we <i>are</i> talking about LCD computer displays here, and not LCD televisions. They aren't the same thing. People spend far more time reading text than watching videos on their computer monitors-- and at a distance of two feet, not ten feet. You might find that an optimal brightness for the above test images produces a screen that's <i>painfully</i> bright for workaday reading tasks. This is an important point that's glossed over in most LCD reviews, but Dan covered it with aplomb in <a href="http://www.dansdata.com/3007wfp-hc.htm">his 30" Dell LCD review</a>:
</p>
<p>
</p>
<blockquote>
The minimum brightness setting for the 3007WFP-HC is still pretty bloody bright. The maximum brightness is down a bit from the non-HC model, at a mere 300 candelas per square metre, but that's still outrageously bright. Not nearly as bright as <a href="http://www.ruggedpcreview.com/3_technology_itronix_dynavue.html">sunlight on paper</a>, but way brighter than anybody should set a normal indoor desktop monitor.
<p>
Ideally, your monitor shouldn't be any brighter than a well-lit book (something which is probably new to the <a href="http://www.dansdata.com/gz021.htm">60Hz-CRT brigade</a> who, today, don't know how to adjust their laptop's screen brightness...). But I can't turn the 3007WFP-HC down that far. Well, not without opening the thing up and fooling with the backlight power supply or something.
</p>
<p>
I've rigged up a quick-'n'-dodgy <a href="http://www.instructables.com/id/EE79YDCL0REQZJI1AZ/?ALLSTEPS">bias light</a> behind the monitor to reduce eyestrain, and <a href="http://gyrolabs.com/2006/09/25/jediconcentrate-mod/">JediConcentrate</a> and the <a href="http://lifehacker.com/software/lifehacker-code/invert-web-page-colors-with-the-darken-bookmarklet-259456.php">Darken bookmarklet</a> help to reduce the number of minutes I spend with millions of bright white pixels tanning my retinas.
</p>
</blockquote>
<p>
Far too much default brightness is easily the number one problem I see on most LCDs these days. Keep Dan's rule of thumb in mind as you're adjusting the brightness and contrast on your LCD against the reference images. Most display calibration guides care only about accuracy, not your eyeballs. <b>For reading purposes, your monitor shouldn't end up any brighter than a well-lit book.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-09-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/computer-display-calibration-101/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Pushing Operating System Limits ]]></title>
<link>https://blog.codinghorror.com/pushing-operating-system-limits/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Raymond Chen notes that if you have to ask where the operating system limits are, you're <a href="http://blogs.msdn.com/oldnewthing/archive/2007/03/01/1775759.aspx">probably doing something wrong</a>:
</p>
<p>
</p>
<blockquote>
If you're
<a href="http://blogs.msdn.com/oldnewthing/archive/2003/12/18/44379.aspx">
nesting windows more than 50 levels deep</a> or
<a href="http://blogs.msdn.com/oldnewthing/archive/2003/12/30/46594.aspx">
nesting menus more than 25 levels deep</a> or
<a href="http://blogs.msdn.com/oldnewthing/archive/2004/06/21/161375.aspx">
creating a dialog box with more than 65535 controls</a>,
or nesting tree-view items more than 255 levels deep,
then your user interface design is in serious need of rethought,
because you just created a usability nightmare.
<p>
If you have to ask about <a href="http://blogs.msdn.com/oldnewthing/archive/2005/07/29/444912.aspx">
the maximum number of threads a process can create</a> or <a href="http://blogs.msdn.com/oldnewthing/archive/2003/12/10/56028.aspx">
the maximum length of a command line</a> or <a href="http://blogs.msdn.com/oldnewthing/archive/2006/07/06/657868.aspx">
the maximum size of an environment block</a> or
<a href="http://support.microsoft.com/kb/256986/"> the maximum amount of data you can store in the registry</a>, then you probably have some rather serious design flaws in your program.
</p>
<p>
I'm not saying that knowing the limits isn't useful, but in many cases,
<a href="http://listserv.linguistlist.org/cgi-bin/wa?A2=ind0405c&amp;L=ads-l&amp;P=12106"> if you have to ask, you can't afford it</a>.
</p>
</blockquote>
<p>
In general, I agree with Raymond. Asking these kinds of questions definitely raises red flags. Edge conditions should never be a goal, and if your design is skirting that close to an operating system edge condition, you're either doing something incredibly brilliant or incredibly stupid. Guess which one is <a href="http://worsethanfailure.com/">more common?</a>
</p>
<p>
However, it can also be surprising <b>how quickly you can run into operating system limits</b>-- even when you're not doing anything that unusual.
</p>
<p>
When researching blog posts, I tend to open a lot of browser windows and tabs. At least twice per week, I have so many browsers and tabs open that I run into some internal limitation of the browser and I can't open any more. My system gets a little wonky in this state, too: right-clicking no longer shows a menu, and I'm prevented from launching other applications. But if I close a few errant browser windows or tabs, everything goes back to normal.
</p>
<p>
I <a href="http://www.codinghorror.com/blog/archives/000789.html">prefer to use Internet Explorer for day-to-day browsing chores</a>, but it appears that IE 7 is particularly vulnerable to these limitations. I ran a quick test in which I opened as many instances of the Yahoo home page as I could, with nothing else running:
</p>
<p>
</p>
<table width="400">
<tr>
<td>Maximum number of IE7 windows I can open</td>
<td align="right"><b>39</b></td>
</tr>
<tr>
<td>Maximum number of IE7 tabs I can open</td>
<td align="right"><b>47</b></td>
</tr>
</table>
<p>
I don't think having 47 typical web pages open, spread across a couple instances of Internet Explorer on my three monitors, is so unreasonable. And yet that's a hard limit I run into on a semi-regular basis. It's annoying. It looks like IE6 had a similar limit; Theodore Smith found that <a href="http://www.incendiary.ws/node/177">he could only open 38 pages</a> before new windows were frozen. Firefox fares quite a bit better in the same test:
</p>
<p>
</p>
<table width="400">
<tr>
<td>Maximum number of Firefox 2 windows I can open</td>
<td align="right"><b>55</b></td>
</tr>
<tr>
<td>Maximum number of Firefox 2 tabs I can open</td>
<td align="right"><b>100+</b></td>
</tr>
</table>
<p>
These aren't hard limits in Firefox; they're practical limits. After I opened 55 Firefox windows, Vista automatically kicked me into Vista Basic mode due to Aero performance degradation. I was unable to close all the instances of Firefox, and I had to kill the task. Tabs worked better; I got bored opening new Yahoo homepage tabs after about seventy and gave up. I was able to close all the tabs without incident. I'm guessing you could have at least a hundred tabs open in Firefox before something suitably weird happened.
</p>
<p>
So we've learned that Internet Explorer sucks, right? Maybe. The results I saw are largely due to a key architectural difference between the two browsers. IE allows you to choose between opening web pages in the same iexplore.exe process (Open New Tab, Open New Window), or opening web pages in a new, isolated instance of iexplore.exe. <b>Unlike IE, Firefox only allows one Firefox.exe process, ever.</b> This clearly helps it scale better. But there is a downside: if any web page crashes, it will take down the entire firefox.exe process and every other web page you have open.
</p>
<p>
I understand the need for practical limits in the operating system. Most of the limits Raymond cites are so high that they're borderline absurd. Can you imagine subjecting a user to a menu with 254 nesting levels? Open a zillion copies of notepad, and you'll eventually have problems, too. I get that. The point is to <b>keep those operating system limits far enough above typical usage that developers and users-- even power users-- aren't likely to run into them</b>.
</p>
<p>
I'm not sure if we're running into an application or operating system limit here; I suspect a little bit of both. Still, I'm disappointed. A limit of only 47 tabbed web pages open at any time under Internet Explorer 7 seems artificially and unacceptably low to me. The introduction of the tabbed browsing metaphor makes it much more likely that users will open lots of web pages at the same time. I'd expect the developers on the IE team to test their application for moderately heavy usage scenarios like this. It's another case of <a href="http://www.codinghorror.com/blog/archives/000957.html">failing to test with a reasonably large data set</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/pushing-operating-system-limits/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Branching and Parallel Universes ]]></title>
<link>https://blog.codinghorror.com/software-branching-and-parallel-universes/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Source control is <a href="http://www.codinghorror.com/blog/archives/000660.html">the very bedrock of software development</a>. Without some sort of version control system in place, you can't reasonably call yourself a software engineer. If you're using a source control system of any kind, you're versioning files almost by definition. The concept of versioning is deeply embedded in every source control system. You can't avoid it.
</p>
<p>
But there's another concept, equally fundamental to source control, which is much less frequently used in practice. That concept is <b>branching</b>. The Subversion documentation has a decent <a href="http://svnbook.red-bean.com/en/1.1/ch04.html">layman's description of branching</a>:
</p>
<p>
</p>
<blockquote>
Suppose it's your job to maintain a handbook for a particular division of your company. One day a different division asks you for the same handbook-- but with a few parts modified specifically for them, as they do things slightly differently.
<p>
What do you do in this situation? You do the obvious thing: you make a second copy of your document, and begin maintaining the two copies separately. As each department asks you to make small changes, you incorporate them into one copy or the other. But you often find yourself wanting to make the same change to both copies. For example, if you discover a typo in the first copy, it's very likely that the same typo exists in the second copy. The two documents are almost the same, after all; they only differ in small, specific ways.
</p>
<p>
This is the basic concept of a branch-- a line of development that exists independently of another line, yet still shares a common history. A branch always begins life as a copy of something, and moves on from there, generating its own history.
</p>
</blockquote>
<p>
If you don't ever use the branching feature of your source control system, <i>are you really taking full advantage of your source control system?</i>
</p>
<p>
I find that <b>almost every client I visit is barely using branching at all</b>. Branching is widely misunderstood, and rarely implemented-- even though branching, like versioning, lies at the very heart of source control, and thus software engineering.
</p>
<p>
Perhaps the most accessible way to think of branches is as <b>parallel universes</b>. They're places where, for whatever reason, history didn't go quite the same way as it did in your universe. From that point forward, that universe can be slightly different-- or it can be radically and utterly transformed. Like the Marvel comic book series <a href="http://en.wikipedia.org/wiki/What_If_(comics)">What If?</a>, branching lets you answer some interesting and possibly even dangerous "what if" questions with your software development.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/What_If_(comics)"><img alt="image placeholder" >
</p>
<p>
Parallel universes offer infinite possibility. They also allow you to stay safely ensconced in the particular universe of your choice, completely isolated from any events in other alternate universes. An alternate universe where the Nazis won World War II is an interesting idea, so long as we don't have to <i>live</i> in that universe. There could potentially be thousands of these parallel universes. Although branching offers the seductive appeal of infinite possibility with very little risk, it also brings along something far less desirable: <b>infinite complexity</b>.
</p>
<p>
The DC comic book series <a href="http://en.wikipedia.org/wiki/Crisis_on_Infinite_Earths">Crisis on Infinite Earths</a> is a cautionary tale of the problems you can encounter if you start spinning off too many parallel universes.
</p>
<p>
</p>
<blockquote>
Prior to Crisis on Infinite Earths, DC was notorious for its continuity problems. No character's backstory, within the comic books, was entirely self-consistent and reliable. For example, Superman originally couldn't fly (he could instead leap over an eighth of a mile), and his powers came from having evolved on a planet with stronger gravity than Earth's. Over time, he became able to fly, his powers were explained as coming from the sun, and a more complex backstory (the now-familiar "last survivor of Krypton" origin story) was invented. Later it was altered to include his exploits as Superboy. It was altered further to include Supergirl, the bottled city of Kandor, and other survivors of Krypton, further watering down the original idea of Superman having been the sole Kryptonian to survive the destruction of his world. There was also an issue of character aging; for instance, Batman, an Earth-born human being without super powers, retained his youth and vitality well into the 1960s despite having been an active hero during World War II, and his sidekick Robin never seemed to age beyond adolescence in over 30 years.
<p>
<a href="http://en.wikipedia.org/wiki/Crisis_on_Infinite_Earths"><img alt="image placeholder" >
</p>
<p>
These issues were addressed during the Silver Age by DC creating parallel worlds in a multiverse: Earth-One was the contemporary DC Universe, which had been depicted since the advent of the Silver Age; Earth-Two was the parallel world where the Golden Age events took place, and where the heroes who were active during that period had aged more or less realistically since that time; Earth-Three was an "opposite" world where heroes were villains, and historical events happened the reverse of how they did in real life (such as, for instance, President John Wilkes Booth being assassinated by a rebel named Abraham Lincoln); Earth Prime was ostensibly the "real world," used to explain how real-life DC staffers (such as Julius Schwartz) could occasionally appear in comics stories; and so forth. If something happened outside current continuity (such as the so-called "Imaginary Stories" that were a staple of DC's Silver Age publications), it was explained away as happening on a parallel world, a premise not dissimilar to the company's current "Elseworlds" imprint.
</p>
</blockquote>
<p>
Start juggling too many parallel universes at once, and you're bound to drop a few. In most source control systems, you can create hundreds of branches with no performance issues whatsoever; it's the <b>mental overhead</b> of keeping track of all those branches that you really need to worry about. Your developer's brains can't exactly be upgraded the same way your source control server can, so this is a serious problem.
</p>
<p>
I find that the analogy of parallel universes helps developers grasp the concept of branching, along with its inevitable pros and cons. But it doesn't get much easier from there. Branching is a complex beast. There are dozens of ways to branch, and nobody can really tell you if you're doing it right or wrong. Here are a <a href="http://msdn2.microsoft.com/en-us/library/aa730834(VS.80).aspx">few common branching patterns</a> you might recognize.
</p>
<p>
<b>Branch per Release</b><br>
Every release is a new branch; common changes are merged between the releases. Branches are killed off only when the releases are no longer supported.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Branch per Promotion</b><br>
Every tier is a permanent branch. As changes are completed and tested, they pass the quality gate and are "promoted" as merges into successive tiers.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Branch per Task</b><br>
Every development task is a new, independent branch. Tasks are merged into the permanent main branch as they are completed.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Branch per Component</b><br>
Each architectural component of the system is a new, independent branch. Components are merged into the main branch as they are completed.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Branch per Technology</b><br>
Each technology platform is a permanent branch. Common parts of the codebase are merged between each platform.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You may notice a few emerging themes in these branch patterns:
</p>
<p>
</p>
<ul>
<li>All branches have a clearly defined lifecycle. They either live forever, or they are eventually killed off.
</li>
<li>All branches are created with the intention of eventually merging, somewhere. A branch without a merge is pointless.
</li>
<li>As we add branches, our development model gets complicated.
</li>
</ul>
<p>
But that complication is often justified. The more developers you have on a project, the higher the chances are that one of those developers will check something really bad into source control and disrupt everyone else's work. It's simple statistics. People make mistakes. The more developers you have, the more mistakes you'll have. And the more developers you have, the greater the consequences when everyone's work is simultaneously disrupted by a bad checkin. So what are our options?
</p>
<p>
</p>
<ol>
<li>
<b>Maximum Productivity</b><br>
Everyone works in the same common area. There are no branches, just a long, unbroken straight line of development. There's nothing to understand, so checkins are brainlessly simple-- but each checkin can break the entire project and bring all progress to a screeching halt.
<p>
</p>
</li>
<li>
<b>Minimum Risk</b><br>
Every single person on the project works in their own private branch. This minimizes risk; everyone works independently, and nobody can disrupt anyone else's work. But it also adds incredible process overhead. Collaboration becomes almost comically difficult-- every person's work has to be painstakingly merged with everyone else's work to see even the smallest part of the complete system.
</li>
</ol>
<p>
The answer usually lies somewhere between these two extremes. Like everything else, branching can be abused. Chris Birmele notes that <b>branching has its own set of anti-patterns</b> you should <a href="http://blogs.msdn.com/chrisbirmele/archive/2006/05/31/611179.aspx">watch out for</a>:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td valign="top"><b>Merge Paranoia</b></td>
<td valign="top">Merging is avoided at all cost, due to a fear of the consequences.</td>
</tr>
<tr>
<td valign="top"><b>Merge Mania</b></td>
<td valign="top">The team spends an inordinate amount of time merging software assets rather than developing them.</td>
</tr>
<tr>
<td valign="top"><b>Big Bang Merge</b></td>
<td valign="top">Merging has been deferred to the very end of the development effort and an attempt is made to merge all branches simultaneously.</td>
</tr>
<tr>
<td valign="top"><b>Never Ending Merge</b></td>
<td valign="top">Merge activity never seems to end; there's always more to merge.</td>
</tr>
<tr>
<td valign="top"><b>Wrong Way Merge</b></td>
<td valign="top">A software asset is merged with a <i>previous</i> version.</td>
</tr>
<tr>
<td valign="top"><b>Branch Mania</b></td>
<td valign="top">Branches are created often and for no apparent reason.</td>
</tr>
<tr>
<td valign="top"><b>Cascading Branches</b></td>
<td valign="top">Branches are never merged back to the main development line.</td>
</tr>
<tr>
<td valign="top"><b>Mysterious Branches</b></td>
<td valign="top">Nobody can tell you what the branches are for.</td>
</tr>
<tr>
<td valign="top"><b>Temporary Branches</b></td>
<td valign="top">The purpose of a branch keeps changing; it effectively serves as a permanent "temporary" workspace.</td>
</tr>
<tr>
<td valign="top"><b>Volatile Branches</b></td>
<td valign="top">An unstable branch is shared by other branches or merged into another branch.</td>
</tr>
<tr>
<td valign="top"><b>Development Freeze</b></td>
<td valign="top">All development activities are stopped during branching, merging and building new baselines</td>
</tr>
<tr>
<td valign="top"><b>Berlin Wall</b></td>
<td valign="top">Branches are used to divide the development team members, rather than divide the work they are performing.</td>
</tr>
</table>
<p>
If you've managed to read this far, perhaps you can understand why so many software development teams are completely sold on version control, but hesitant to take on branching and merging. It's a powerful, fundamental source control feature, sure, but it's also complicated. If you're not careful, the wrong branching strategy could do more harm to your project than good.
</p>
<p>
Still, I urge developers to make an effort to understand branching-- <i>really</i> understand it-- and explore using branching strategies where appropriate on their projects. Done right, the mental cost of the branching tax pales in comparison to <a href="http://www.ericsink.com/scm/scm_branches.html">the benefits of concurrent development</a> it enables. <b>Embrace the idea of parallel universes in your code</b>, and you may find that you can get more done, with less risk. Just try to avoid a crisis on infinite codebases while you're at it.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-branching-and-parallel-universes/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Revisiting Programming Fonts ]]></title>
<link>https://blog.codinghorror.com/revisiting-programming-fonts/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've experimented with <a href="http://www.codinghorror.com/blog/archives/000157.html">programming fonts</a> and <a href="http://www.codinghorror.com/blog/archives/000682.html">IDE color schemes</a> plenty in the past. But now that I've <a href="http://www.codinghorror.com/blog/archives/000651.html">given in to the inevitability of ClearType</a> on large LCDs, I've basically settled on Consolas. It's hard to beat Consolas. It's darn close to the ultimate monospace programming font in my estimation. That's why I was so intrigued when I read about <a href="http://www.levien.com/type/myfonts/inconsolata.html">Inconsolata</a>, a <b>non-denominational OpenType relative of Consolas</b>, which unlike Consolas, works equally well with <a href="http://en.wikipedia.org/wiki/ClearType">ClearType</a> enabled or disabled.
</p>
<p>
Once I tried out Inconsolata, I figured I might as well revisit all the common, popular programming fonts under the same conditions. So here goes. These are rendered under Windows Vista, with ClearType enabled, using my standard <a href="http://www.codinghorror.com/blog/archives/000682.html">programming font comparison code sample</a>.
</p>
<p>
<a href="http://www.microsoft.com/downloads/details.aspx?familyid=22e69ae4-7e40-4807-8a86-b3d36fab68d3">Consolas</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://www.levien.com/type/myfonts/inconsolata.html">Inconsolata</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://www.webdevkungfu.com/textmate-envy-aka-monaco-font-for-windows/">Monaco</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://damieng.com/fonts/envy-code-r">Envy R</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://ftp.gnome.org/pub/GNOME/sources/ttf-bitstream-vera/1.10/">Vera Sans Mono</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://www.fsd.it/fonts/pragma.htm">Pragmata</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Courier_(typeface)">Courier New</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://www.codinghorror.com/blog/files/LucidaTypewriter.zip">Lucida Typewriter</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://www.codinghorror.com/blog/archives/000328.html">The Font of the Gods</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://sourceforge.net/project/showfiles.php?group_id=34153">Andale Mono</a>, 11 point.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Choice of programming font is as much a personal preference as anything else. Decide for yourself what works for you. I'll limit my comments to a few observations:
</p>
<p>
</p>
<ol>
<li>Please don't use the default Courier New typeface. Be kind to your eyes.
</li>
<li>Personally, I still don't think anything beats <a href="http://www.microsoft.com/downloads/details.aspx?familyid=22e69ae4-7e40-4807-8a86-b3d36fab68d3">Consolas</a>; it's an outstanding monospace typeface design, highly optimized for ClearType display on LCDs.
</li>
<li>I'll never understand the appeal of Monaco amongst the Mac crowd. It's an unreadable mess to my eye.
</li>
</ol>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/revisiting-programming-fonts/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Do Not Buy This Book ]]></title>
<link>https://blog.codinghorror.com/do-not-buy-this-book/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A few friends and I just wrote a book together: <a href="http://www.amazon.com/exec/obidos/ASIN/098028581X/codihorr-20">The ASP.NET 2.0 Anthology: 101 Essential Tips, Tricks &amp; Hacks</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/098028581X/codihorr-20"><img alt="image placeholder" >
</p>
<p>
I met <a href="http://odetocode.com/Blogs/scott/">K. Scott Allen</a>, <a href="http://weblogs.asp.net/jgalloway/">Jon Galloway</a>, and <a href="http://haacked.com">Phil Haack</a> through their excellent blogs. That online friendship carried over into real life. We always thought it'd be fun to work on something together, and when the book project materialized, we took it on. It was a natural fit for a group of established bloggers who have suffered the slings and arrows of three versions of ASP.NET; we have war stories to share.
</p>
<p>
But <b>do not buy this book</b>.
</p>
<p>
Why buy what you can get for free? <s>As long as you have a blog, live in the US or Canada, and promise to write a review of the book, I'll mail you a free review copy. (I apologize to my international readers, but the international mailing process is just too onerous.) Shoot me an email containing a link to your blog, and your mailing address, and I'll send out the book. I have five to send, plus my fellow authors might have a few additional copies to contribute.</s> I sent as many as I could on a first come, first served basis.
</p>
<p>
But there's another, more important reason <b>you shouldn't buy this book</b>. It's a technical book tied to a specific technology, and I'm not sure those kinds of books have a future. Don't get me wrong. This blog was founded on the concept of a <a href="http://www.codinghorror.com/blog/archives/000020.html">recommended developer reading list</a>. I have a deep respect for books and authors. I recommend books all the time-- but never highly technical books. I stock my shelves with books about timeless concepts such as design, process, people, and craftsmanship. Do highly technical books tied to a specific technology have any reason to exist in an era of ubiquitous, high speed internet access? I wonder. I think they're increasingly irrelevant, and almost by definition out of date by the time they manage to hit bookshelves.
</p>
<p>
I think back to the highly-rated technical books I bought on Amazon in 2002 when I was learning .NET. Embarrassingly, I never even cracked open most of those books. I spent the majority of my time learning by browsing articles on the web, downloading and modifying code. Maybe I'm too impatient, but I found the internet such an effective and immediate companion that the books I bought couldn't possibly compete. I realized five years ago that technical books were almost obsolete. I don't see anything today that would cause me to change my mind; if anything, the <a href="http://www.charlespetzold.com/blog/2007/04/290143.html">rate of obsolescence has accelerated</a>.
</p>
<p>
As I went through the book writing process for the very first time, I also found that being an author isn't nearly as glamorous as one might imagine.
</p>
<p>
</p>
<ol>
<li>
<b>Writing a book is hard work</b>. For me, writing blog entries feels completely organic, like a natural byproduct of what I already do. It's not effortless by any means, but it's enjoyable. I can put a little effort in, and get immediate results out after I publish the entry. The book writing process is far more restrictive. Instead of researching and writing about whatever you find interesting at any given time, you're artificially limited to a series of chapters that fit the theme of the book. You <a href="http://blogs.msdn.com/ericgu/articles/396328.aspx">slave away for your publisher</a>, writing for weeks on end, and you'll have nothing to show for it until the book appears (optimistically) six months down the road. Writing a book felt a lot like old fashioned <i>hard work</i>-- of the indentured servitude kind.
<p>
</p>
</li>
<li>
<b>Writing a book doesn't pay</b>. I'd be fine with the relentless grind of writing a book if you could make a reasonable living at it. According to Mike Gunderloy, <a href="http://www.larkware.com/Articles/AdviceforWritersPart4.html">less than 30% of computer books sell enough to generate <i>any</i> royalties whatsoever</a>. I suspect far fewer sell enough for the authors to achieve the same wage they could by working a traditional job.
<p>
</p>
</li>
<li>
<b>Anyone can write a book</b>. Even if books make no financial sense, perhaps the ancillary benefits can make the effort worthwhile. I won't lie: you'll get a little thrill the first time you ego-search Amazon and see your book in the results. There is a certain prestige factor associated with being published; <a href="http://www.fasterj.com/articles/bookwriting.shtml">people are impressed by authors</a>. To me, these are ultimately empty accolades. Anybody can write a book. The bar to publishing a book is nonexistent; with sufficient desire, any would-be author can get published. Just because you've published doesn't mean your book is worth reading. It doesn't mean your book matters. It just means your book <i>exists</i>. Far from being impressive, that's barely meaningful at all.
<p>
</p>
</li>
<li>
<b>Very few books succeed</b>. Anyone can author a book. But precious few can author a <i>successful</i> book. For books, the only meaningful success metric is sales, as you have no way of directly measuring eyeballs. In the physical world of published atoms, blockbusters rule. Nothing other than the biggest of hits moves the sales needle enough to register. Bruce Eckel says <a href="http://mail.python.org/pipermail/python-list/2002-January/120681.html">less than 1% of books are actually successful</a>. At best, 99% of books will have a brief peak of sales-- hopefully enough to earn back your advance-- and then crash directly into irrelevance and permanent out-of-print obscurity.
</li>
</ol>
<p>
In short, <b>do not write a book</b>. You'll put in mountains of effort for precious little reward, tangible or intangible. In the end, all you will have to show for it is an out-of-print dead tree tombstone. The only people who will be impressed by that are the clueless and the irrelevant.
</p>
<p>
As I see it, for the kind of technical content we're talking about, the <b>online world of bits completely trumps the offline world of atoms</b>:
</p>
<p>
</p>
<ul>
<li>it's forever searchable
</li>
<li>you, not your publisher, will own it
</li>
<li>it's instantly available to anyone, anywhere in the world
</li>
<li>it can be cut and pasted; it can be downloaded; it can even be interactive
</li>
<li>it can potentially generate ad revenue for you in perpetuity
</li>
</ul>
<p>
And here's the best part: you can always opt to <a href="http://gettingreal.37signals.com/">create a print version of your online content</a>, and <b>instantly get the best of both worlds</b>. But it only makes sense in that order. Writing a book may seem like a worthy goal, but your time will be better spent channeling the massive effort of a book into creating content online. Every weakness I listed above completely melts away if you redirect your effort away from dead trees and spend it on growing a living, breathing website presence online.
</p>
<p>
That said, some people are quite successful writing technical books. Did I mention that I <a href="http://www.amazon.com/exec/obidos/ASIN/098028581X/codihorr-20">co-wrote a technical book</a> with my friends? Many people find such books quite useful.
</p>
<p>
Unfortunately, I'm not one of them.
</p>
<p>
<font color="red">Update</font>: Charles Petzold has posted <a href="http://www.charlespetzold.com/blog/2007/10/081247.html">his thoughts on the current state of technical book publishing</a>. Needless to say, it's highly recommended, as Charles has a lifetime's worth of experience on this topic.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/do-not-buy-this-book/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ YouTube: The Big Copyright Lie ]]></title>
<link>https://blog.codinghorror.com/youtube-the-big-copyright-lie/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm a big <a href="http://en.wikipedia.org/wiki/YouTube">YouTube</a> fan.
</p>
<p>
We can thank YouTube for <a href="http://www.codinghorror.com/blog/archives/000755.html">cutting the gordian knot of video codecs</a>. Instead of futzing around with codecs and media players, YouTube's universal, Flash-based web video "just works". After all this time, it turns out the killer app for Flash wasn't advertising or web games. It was video. It's a cross-platform model Microsoft is aping with <a href="http://silverlight.net/">Silverlight</a>, and for good reason.
</p>
<p>
YouTube feels like a web institution already, even though the site is less than 2 years old. I love the fact that (almost) any video ephemera I can think of can be found on YouTube, and instantly shared with anyone in the world using nothing more than a web browser and a hyperlink. It's a beautiful thing.
</p>
<p>
But one thing bugs me about YouTube. On their upload page, you'll find this disclaimer:
</p>
<p>
</p>
<blockquote>
<b>Do not upload any TV shows, music videos, music concerts, or commercials without permission unless they consist entirely of content you created yourself.</b> Please refer to our <a href="http://www.youtube.com/t/howto_copyright">Copyright Tips</a> page for some guidelines and links to help you determine whether your video infringes someone else's copyright.
</blockquote>
<p>
Take a minute to read <a href="http://www.youtube.com/t/howto_copyright">YouTube's copyright tips page</a>. I'm serious. Read it. It's full of gems like this:
</p>
<p>
</p>
<ul>
<li>It doesn't matter how long or short the clip is, or exactly how it got to YouTube. If you taped it off cable, videotaped your TV screen, or downloaded it from some other website, it is still copyrighted, and requires the copyright owner's permission to distribute.
</li>
<li>It doesn't matter whether or not you give credit to the owner/author/songwriter -- it is still copyrighted.
</li>
<li>It doesn't matter that you are not selling the video for money -- it is still copyrighted.
</li>
<li>It doesn't matter whether or not the video contains a copyright notice -- it is still copyrighted.
</li>
<li>It doesn't matter whether other similar videos appear on our site -- it is still copyrighted.
</li>
<li>It doesn't matter if you created a video made of short clips of copyrighted content -- even though you edited it together, the content is still copyrighted.
</li>
</ul>
<p>
Now think back through all the videos you've watched on YouTube. How many of them contained <i>any</i> original content? Let's see. Recently I've linked to <a href="http://tinyurl.com/29gw3o">the faux Machete trailer from Grindhouse</a>, a <a href="http://tinyurl.com/2gdkht">classic Kids in the Hall skit</a> (and <a href="http://youtube.com/watch?v=uVyHgK5QV7s">another one</a>), a surreal computer animated skit called <a href="http://tinyurl.com/yw9pvv">Bingo the Clown-O</a>, and the <a href="http://www.youtube.com/watch?v=JTioGKAXrGM">Writer's Award intro from the 2007 Emmys</a>. Notice anything in common here? That's right. Virtually everything of interest on YouTube is <b>copyrighted content</b>.
</p>
<p>
It's perhaps the ultimate case of cognitive dissonance: <b>by YouTube's own rules, YouTube cannot exist</b>. And yet it does.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
How do we reconcile YouTube's official hard-line position on copyright with the reality that 90% of the content on their site is <i>clearly</i> copyrighted and <i>clearly</i> used without permission? It seems YouTube has an awfully convenient "don't ask, don't tell" policy-- <b>they make no effort to verify that the uploaded content is either original content or fair use</b>. The copyrighted content stays up until the copyright owner complains. Then, and only then, is it removed.
</p>
<p>
</p>
<blockquote>
Anytime we become aware that a video or any part of a video on our site infringes the copyrights of a third party, we will take it down from the site. We are required to do so by law. If you believe that a video on the site infringes your copyright, <a href="http://www.youtube.com/t/dmca_policy">send us a copyright notice</a> and we will take it down.
</blockquote>
<p>
It's completely glossed over on the YouTube copyright page in favor of 100% original content, but the loophole in copyright is <a href="http://en.wikipedia.org/wiki/Fair_use">fair use</a>. Under the banner of fair use, you could legally upload a video without the copyright holder's permission. Anyone who contributes <i>anything</i> to the web should have <a href="http://fairuse.stanford.edu/Copyright_and_Fair_Use_Overview/chapter9/9-b.html">the four factors of fair use</a> commited to memory by now:
</p>
<p>
</p>
<ol>
<li>the <b>purpose</b> of the use
</li>
<li>the <b>nature</b> of the copyrighted work
</li>
<li>the <b>relative amount</b> of the portion used
</li>
<li>the <b>market effect</b> of the use on the copyrighted work
</li>
</ol>
<p>
These are the four factors courts use to determine if something is fair use. It's worth digging a little deeper to see how these could potentially apply to a typical YouTube video clip.
</p>
<p>
<a href="http://www.copyrightwebsite.com/Info/FairUse/FairUse.aspx"><img alt="image placeholder" >
</p>
<p>
1. <b>Was it transformative?</b> Uploading a 2 minute clip from <a href="http://en.wikipedia.org/wiki/The_Kids_in_the_Hall">Kids in the Hall</a> isn't transformative in the least. Nothing new was added. No context was provided. It's not a parody, it's not research, it's not commentary. It's a small segment of the original content, transplanted to the web. It's only "transformative" in the sense that it's much more readily available to the public.
</p>
<p>
2. <b>What is the nature of the source material?</b> The majority of clips on YouTube are there to amuse; they draw their source material from works of entertainment. Entertainment is an enjoyable pastime, but it's not a public good. Dissemenation of facts or information benefits the public; <a href="http://www.youtube.com/watch?v=W27U6T54u_E">video clips of man getting hit in the groin with football</a>.. not so much.
</p>
<p>
3. <b>How much was taken?</b> YouTube instituted a 10 minute length limit, probably to prevent excessive use claims from taking root. It's a policy that seems to work. Most clips tend to be fairly small, even after factoring in the 10 minute limit.
</p>
<p>
4. <b>What's the market effect?</b> I find it very difficult to believe that the short, grainy, low-resolution clips on YouTube could have any kind of measurable negative financial effect on content providers. This is one case where YouTube's below-the-bottom-of-the-barrel video quality works in their favor.
</p>
<p>
The typical YouTube clip does well on the last two factors of the fair use test, but utterly fails the first two. This is not good, because the factors are listed in order of importance; the transformative and nature tests are considered the most significant factors by courts. <b>It is not possible to make a supportable fair use case for most video clips using copyrighted material on YouTube</b>.
</p>
<p>
I'm not attacking YouTube here. I think having access to all this copyrighted content in bite-size embeddable form is ultimately a net good for both consumers and creators. What I don't understand is why YouTube continues to get away with <b>the big copyright lie</b> they've perpetuated from day one. They pay lip service to copyright, while building their business on an empire of unauthorized, copyrighted content. It's so brazen-- so blatant.
</p>
<p>
You can argue that copyright law is broken. I won't disagree with you. But I still dislike YouTube's massive hypocrisy in this area, and I wonder why other people and companies don't get the free ride from the hyper-litigious entertainment industry that YouTube seems to enjoy.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/youtube-the-big-copyright-lie/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Geek Diet and Exercise Programs ]]></title>
<link>https://blog.codinghorror.com/geek-diet-and-exercise-programs/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Software developers aren't typically known for their superior levels of physical fitness. I'm not overweight, exactly, but I don't think I'll be pursuing that dream career in <a href="http://www.imdb.com/title/tt0196229/">male modelling</a> anytime soon. I charitably call myself an <i>indoor enthusiast</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
At the risk of generalizing-- yes, I know <i>you</i> happen to be the exceptionally fit software engineer that proves the rule-- being tethered to <a href="http://www.codinghorror.com/blog/archives/000761.html">the machines we love so much</a> often leads to a sedentary lifestyle for programmers, and a high occupational correlation with obesity.
</p>
<p>
But it doesn't have to be that way. If we can whip computer software and hardware into shape, we should be amply equipped to whip the body's software and hardware into shape, too. Consider <a href="http://www.fourmilab.ch/hackdiet/www/part1_1.html#SECTION0100000000000000000">the advice of John Walker</a>:
</p>
<p>
</p>
<blockquote>
I'm an engineer by training, a computer programmer by avocation, and an businessman through lack of alternatives. From grade school in the 1950's until 1988 I was fat--anywhere from 30 to 80 pounds overweight. This is a diet book by somebody who spent most of his life fat.
<p>
The absurdity of my situation finally struck home in 1987. "Look," I said to myself, "you founded one of the five biggest software companies in the world, Autodesk. You wrote large pieces of AutoCAD, the world standard for computer aided design. You've made in excess of fifty million dollars without dropping dead, going crazy, or winding up in jail. You've succeeded at some pretty difficult things, and you can't control your flippin' weight?''
</p>
<p>
Through all the years of struggling with my weight, the fad diets, the tedious and depressing history most fat people share, I had never, even once, approached controlling my weight the way I'd work on any other problem: a malfunctioning circuit, a buggy program, an ineffective department in my company.
</p>
</blockquote>
<p>
John compiled his advice into something he calls <a href="http://www.fourmilab.ch/hackdiet/">The Hacker's Diet</a>. According to John, <a href="http://www.fourmilab.ch/hackdiet/www/subsection1_1_1_0_3.html">all we need</a> is:
</p>
<p>
</p>
<ul>
<li>An eye firmly fixed on the goal.
</li>
<li>Will power.
</li>
<li>A high tolerance for pain.
</li>
</ul>
<p>
In other words, <i>we are so totally screwed</i>. Jeremy Zawodny used the Hacker's Diet as a template, and came up with <a href="http://jeremy.zawodny.com/blog/archives/006836.html">this kinder, gentler set of diet advice</a> that's a bit less intimidating:
</p>
<p>
</p>
<blockquote>
If you're seriously thinking about trying to lose weight, give this a shot. It's one of the easiest non-fad and non-gimmick plans you'll run across, mostly because the "plan" is very simple and tangible. It's not quite "the simplest thing that could possibly work" but it sure comes close:
<p>
</p>
<ul>
<li>Small changes have a major impact on weight loss because they're compounded over time. It's just like saving for retirement. The sooner you start doing just a little bit every day, the better off you'll be.
</li>
<li>Anyone can do this. Anyone.
</li>
<li>The process is self-reinforcing once you start to see real results. That means you need to commit to a month--a very difficult month. After that first month, though, it's easy. And the more weight you have to lose, the easier it is.
</li>
<li>During that first month, you'll be developing <a href="http://jeremy.zawodny.com/blog/archives/006845.html">three new habits</a>. Only one of them is likely to conflict with an existing habit. The other two will consume maybe 5 minutes of your daily routine.
</li>
</ul>
</blockquote>
<p>
Like any proper geek diet program, Jeremy's is <a href="http://jeremy.zawodny.com/blog/archives/006851.html">powered by a spreadsheet</a>. In the end, it's basic math -- calories in minus calories out. Since programmers are <a href="http://www.codinghorror.com/blog/archives/000490.html">legendarily obsessive</a>, tracking everything we eat is a natural fit for us.
</p>
<p>
But reducing calorie intake through diet is only half of the equation. The other half is increasing calorie burn by exercising, or at least staying moderately physically active. A contributor to OmniNerd <a href="http://www.omninerd.com/blogs/Daily_Calories_Burned">wore a heart rate monitor and measured exactly how many calories he burned</a> during typical daily activities:
</p>
<p>
</p>
<ul>
<li>100 calories burned per hour sitting in a chair "working"
</li>
<li>5 calories burned riding an elevator up twenty-seven flights
</li>
<li>100 calories burned per hour watching TV or surfing the Internet at home
</li>
<li>750 calories burned for eight hours of sleeping
</li>
<li>220 calories burned in twenty minutes walking 11/4 miles downhill to my bus (+50 calories burned "cooling")
</li>
<li>60 calories burned walking one New York City block (west-east) (+10 calories "cooling")
</li>
<li>25 calories burned walking up five flights of stairs (+35 calories burned "cooling")
</li>
<li>315 calories burned walking 11/4 miles uphill from my bus (+75 calories burned "cooling")
</li>
<li>150 calories burned walking a dog for twenty minutes (Note: It was a slow walk, the dog is very old.)
</li>
<li>660 calories burned in forty minutes of weightlifting
</li>
<li>900+ calories burned in fifty minutes on an elliptical trainer
</li>
</ul>
<p>
It's a reasonable set of advice: <b>eat less, exercise more</b>. We may do it more analytically than the average joe, but it's nothing you haven't heard a dozen times before. The problem is getting off our collective butts to do it. It's difficult to get motivated, particularly when exercise almost by definition draws you away from <a href="http://www.codinghorror.com/blog/archives/000874.html">your obsession</a>.
</p>
<p>
<b>But what if we could combine our computing obsession with exercise?</b>
</p>
<p>
<a href="http://www.slimgeek.com/index.html"><img alt="image placeholder" >
</p>
<p>
Now we're talking.
</p>
<p>
The <a href="http://www.slimgeek.com/index.html">geek-a-cycle</a> may look vaguely ridiculous. Still, I've often wondered if there was some way to combine all that time I spend sifting through content on the internet with some kind of physical exercise, instead of passively sitting in a chair. It's an interesting concept.
</p>
<p>
Greg used a similar recumbent trainer arrangement to <a href="http://theweightlifter.blogspot.com/2006/10/low-cal-6011-min-warbiking-3-months-41.html">lose weight while playing the massively multiplayer online game World of Warcraft</a>.
</p>
<p>
<a href="http://theweightlifter.blogspot.com/2006/10/low-cal-6011-min-warbiking-3-months-41.html"><img alt="image placeholder" >
</p>
<p>
Greg calls this "Warbiking". It's a clever symbiosis of carrot and stick that really worked for him.
</p>
<p>
</p>
<blockquote>
One of the bad parts of Warcraft is it can really suck you in - I tend to lose track of time and get pretty unaware of anything but the game. It's addictive as hell! One of the bad parts of doing Cardio is that it is <i>very</i> boring, so I tend to be very aware of how much I'm not enjoying it and how slow time seems to get. And I hate doing it!
<p>
Warbiking is the best of both worlds. I get to do 2+ hours of cardio without being aware that I'm really doing it. And as I can only play Warcraft while doing cardio (that's a self imposed rule - no cardio, no Warcraft), it's self regulating. No way am I going to play for 6 hours; my legs wouldn't do it. I did hit 4.5 hours one insane Sunday afternoon, but I won't be doing that again any time soon.
</p>
</blockquote>
<p>
If you're more of a console gamer, there's the <a href="http://www.gamercize.net/">Gamercize</a>. You insert the device between your controller and your console. The device monitors your physical activity, and will disconnect your controller if you fail to sustain a certain minimum level of physical activity.
</p>
<p>
<a href="http://www.gamercize.net/"><img alt="image placeholder" >
</p>
<p>
The gamercize is appealing because it's universal. It works with any game, but it's not exactly interactive.
</p>
<p>
Perhaps the best example of a game that integrates physical activity with actual <i>gameplay</i> is <a href="http://en.wikipedia.org/wiki/Dance_Dance_Revolution">Dance Dance Revolution</a>.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Dance_Dance_Revolution"><img alt="image placeholder" >
</p>
<p>
DDR is one of the few games my wife enjoys playing with me. It's available on <a href="http://www.ebgames.com/search.asp?Ntk=TitleKeyword&amp;Ntx=mode%2Bmatchallpartial&amp;Ntt=dance+dance+revolution&amp;N=0">every platform under the sun</a>, and even has a free open source PC equivalent in <a href="http://www.stepmania.com/">StepMania</a>. The songs have a wide selection of skill levels, from ultra-klutz to ninja. If you can get past the natural aversion most people have to making themselves look ridiculous while doing something approximating dancing, it's really quite entertaining. And it's <a href="http://www.nytimes.com/2007/04/30/health/30exer.html?_r=1&amp;oref=slogin">definitely a workout</a>.
</p>
<p>
You might argue that none of this is really necessary. <b>Wouldn't it be easier to drop all the diet spreadsheets and electric exercise contraptions and cultivate a traditional physical activity as a hobby?</b> Say, something like soccer, or tennis, or cycling?
</p>
<p>
Sure. It <i>would</i> be easier-- if don't you mind losing all your geek street cred in the process.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/geek-diet-and-exercise-programs/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Lesson in Control Simplicity ]]></title>
<link>https://blog.codinghorror.com/a-lesson-in-control-simplicity/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was struck, the other day, by <a href="http://www.codinghorror.com/blog/archives/000377.html">how much I had to <i>think</i></a> when attempting to heat up my sandwich in the microwave. There are so many controls: a clock, a set of food-specific buttons, defrost and timer controls, and of course a full numeric keypad. Quick! What do you press?
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
I wonder if older microwaves weren't <a href="http://www.codinghorror.com/blog/archives/000726.html">a better, simpler design</a>, with their single giant analog knob. I noticed that <a href="http://www.target.com/b/ref=sc_fe_l_0_1038580_15/602-6641377-6679015?ie=UTF8&amp;node=1041762">every microwave for sale at Target</a>, even the most inexpensive ones, now use a complete set of digital controls.
</p>
<p>
This is progress?
</p>
<p>
Maybe something to think about, the next time you're about to add <a href="http://www.codinghorror.com/blog/archives/000548.html">just one more field</a>, <a href="http://www.codinghorror.com/blog/archives/000920.html">button</a>, or <a href="http://www.codinghorror.com/blog/archives/000985.html">link</a> to that form.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-lesson-in-control-simplicity/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Visual Explanation of SQL Joins ]]></title>
<link>https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I thought Ligaya Turmelle's <a href="http://www.khankennels.com/blog/index.php/archives/2007/04/20/getting-joins">post on SQL joins</a> was a great primer for novice developers. Since SQL joins <i>appear</i> to be set-based, the use of <a href="http://en.wikipedia.org/wiki/Venn_diagram">Venn diagrams</a> to explain them seems, at first blush, to be a natural fit. However, like the commenters to her post, I found that the Venn diagrams didn't quite match the <a href="http://en.wikipedia.org/wiki/Join_(SQL)">SQL join syntax</a> reality in my testing.</p>
<p>I love the concept, though, so let's see if we can make it work. Assume we have the following two tables. <strong>Table A</strong> is on the left, and <strong>Table B</strong> is on the right. We'll populate them with four records each.</p>
<pre>id name       id  name
-- ----       --  ----
1  <span style="color:red">Pirate</span>     1   Rutabaga
2  Monkey     2   <span style="color:red">Pirate</span>
3  <span style="color:red">Ninja</span>      3   Darth Vader
4  Spaghetti  4   <span style="color:red">Ninja</span></pre>
<p>Let's join these tables by the name field in a few different ways and see if we can get a conceptual match to those nifty Venn diagrams.</p>
<table cellpadding="6" cellspacing="4" width="900">
<thead></thead>
<tbody>
<tr>
<td valign="top">
<pre>SELECT * FROM TableA
<b>INNER JOIN</b> TableB
ON TableA.name = TableB.name
<p>id  name       id   name</p>
<hr>
<p>1   Pirate     2    Pirate<br>
3   Ninja      4    Ninja<br>
</p></pre>
<br>
<strong>Inner join</strong> produces only the set of records that match in both Table A and Table B.
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">
<pre>SELECT * FROM TableA
<b>FULL OUTER JOIN</b> TableB
ON TableA.name = TableB.name
<p>id    name       id    name</p>
<hr>
<p>1     Pirate     2     Pirate<br>
2     Monkey     <span style="color:#ccc">null</span>  <span style="color:#ccc">null</span><br>
3     Ninja      4     Ninja<br>
4     Spaghetti  <span style="color:#ccc">null</span>  <span style="color:#ccc">null</span><br>
<span style="color:#ccc">null</span>  <span style="color:#ccc">null</span>       1     Rutabaga<br>
<span style="color:#ccc">null</span>  <span style="color:#ccc">null</span>       3     Darth Vader<br>
</p></pre>
<p><strong>Full outer join</strong> produces the set of all records in Table A and Table B, with matching records from both sides where available. If there is no match, the missing side will contain null.</p>
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">
<pre>SELECT * FROM TableA
<b>LEFT OUTER JOIN</b> TableB
ON TableA.name = TableB.name

id  name       id    name
--  ----       --    ----
1   Pirate     2     Pirate
2   Monkey     <span style="color:#ccc">null</span>  <span style="color:#ccc">null</span>
3   Ninja      4     Ninja
4   Spaghetti  <span style="color:#ccc">null</span>  <span style="color:#ccc">null</span>
</pre>
<p><strong>Left outer join</strong> produces a complete set of records from Table A, with the matching records (where available) in Table B. If there is no match, the right side will contain null.</p>
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">
<pre>SELECT * FROM TableA
LEFT OUTER JOIN TableB
ON TableA.name = TableB.name
<b>WHERE TableB.id IS null</b>
<p>id  name       id     name</p>
<hr>
<p>2   Monkey     <span style="color:#ccc">null</span>   <span style="color:#ccc">null</span><br>
4   Spaghetti  <span style="color:#ccc">null</span>   <span style="color:#ccc">null</span><br>
</p></pre>
<p>To produce the set of records only in Table A, but not in Table B, we perform the same left outer join, then <strong>exclude the records we don't want from the right side via a where clause</strong>.</p>
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">
<pre>
SELECT * FROM TableA
FULL OUTER JOIN TableB
ON TableA.name = TableB.name
<b>WHERE TableA.id IS null
OR TableB.id IS null</b>
<p>id    name       id    name</p>
<hr>
<p>2     Monkey     <span style="color:#ccc">null</span>  <span style="color:#ccc">null</span><br>
4     Spaghetti  <span style="color:#ccc">null</span>  <span style="color:#ccc">null</span><br>
<span style="color:#ccc">null</span>  <span style="color:#ccc">null</span>       1     Rutabaga<br>
<span style="color:#ccc">null</span>  <span style="color:#ccc">null</span>       3     Darth Vader<br>
</p></pre>
<br>
To produce the set of records unique to Table A and Table B, we perform the same full outer join, then <strong>exclude the records we don't want from both sides via a where clause</strong>.
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
</tbody>
</table>
<p>There's also a cartesian product or <strong>cross join</strong>, which as far as I can tell, can't be expressed as a Venn diagram:</p>
<pre>SELECT * FROM TableA
<b>CROSS JOIN</b> TableB
</pre>
<p>This joins "everything to everything", resulting in 4 x 4 = 16 rows, far more than we had in the original sets. If you do the math, you can see why this is a <em>very</em> dangerous join to run against large tables.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Mouse Ballistics ]]></title>
<link>https://blog.codinghorror.com/mouse-ballistics/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Let me be completely honest with you. I have a <a href="http://www.codinghorror.com/blog/archives/000286.html">full-blown mouse fetish</a>. I've owned every single major mouse model from Microsoft and Logitech since the bad old days of the original Microsoft "Dove bar" mouse, and the Logitech MouseMan. I remember quite clearly bringing home my first mouse, an add-on for my Apple //c, and demonstrating this novel method of input to friends. I've been obsessing over these essential input devices since way before the days when USB was just a glint in Intel's collective eye; I have more than my share of mousing experience.
</p>
<p>
These days, I can't claim experience with every mouse under the sun; there are too many models out there. Mice have long since split into two distinct family trees: premium "performance" mice for gamers and enthusiasts; less expensive vanilla models for everyone else. As an enthusiast and a gamer, I've followed the enthusiast mouse family tree with great gusto. My current mouse of choice is the <a href="http://www.amazon.com/exec/obidos/ASIN/B000H16G3W/codihorr-20">Microsoft Habu</a>. But that was way back in March. Since then two very interesting new models have emerged.
</p>
<p>
The <a href="http://www.amazon.com/exec/obidos/ASIN/B000TTQFIS/codihorr-20">Microsoft Sidewinder Mouse</a>:
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000TTQFIS/codihorr-20"><img alt="image placeholder" >
</p>
<p>
The <a href="http://www.amazon.com/exec/obidos/ASIN/B000UHE8Y2/codihorr-20">Logitech G9 Mouse</a>:
</p>
<p>
<a href="http://www.logitech.com/index.cfm/mice_pointers/mice/devices/3053&amp;cl=us,en"><img alt="image placeholder" >
</p>
<p>
I've now used both models for a few days, long enough to generate some informed opinions. They do have a quite a few things in common, things I'd consider relatively standard for current generation enthusiast mice:
</p>
<p>
</p>
<ul>
<li>Five buttons (left, center, right, back, forward)
</li>
<li>Weight cartridges for adjustable "heft"
</li>
<li>Textured aluminum scroll wheels
</li>
<li>Hardware DPI adjustable "on the fly" with visual indicators
</li>
<li>Oversize glide pads on the bottom
</li>
<li>Mouse settings are permanently stored in on-board firmware
</li>
</ul>
<p>
Each model also has a few unique features of its own:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td><a href="http://www.microsoft.com/hardware/gaming/ProductDetails.aspx?pid=100&amp;active_tab=systemRequirements">Microsoft Sidewinder</a></td>
<td><a href="http://www.logitech.com/index.cfm/mice_pointers/mice/devices/3053&amp;cl=us,en">Logitech G9</a></td>
</tr>
<tr>
<td valign="top">
<ul>
<li>LED display that shows the current DPI setting
</li>
<li>Glide pads can be swapped out; includes three sets, of varying slickness
</li>
<li>Accessory box is weighted and doubles as cable anchor
</li>
<li>Record macro button in front of the thumb buttons
</li>
<li>Quick launch button on body
</li>
<li>Vertical side button arrangement
</li>
</ul>
</td>
<td valign="top">
<ul>
<li>Grip body can be swapped out; two different bodies are provided
</li>
<li>DPI indicator LED color can be changed in software
</li>
<li>Wheel can be switched between gear and frictionless modes
</li>
<li>Offers one more DPI setting (4 total)
</li>
</ul>
</td>
</tr>
</table>
<p>
I noticed that neither of the <a href="http://www.codinghorror.com/blog/archives/000865.html">mouse wheels</a> allow horizontal (left-right) scrolling. This is a good thing, because horizontal scrolling has always struck me as a dubious sort of feature at best. I think you'd need something other than a wheel to do it justice, more like a mini-trackball, and even then I'm not sure the complexity is worth it. How often do you <i>need</i> to scroll horizontally? I'd rather have a firm, bi-directional mouse wheel that's locked to up-down, anyway.
</p>
<p>
So which one do I prefer? <a href="http://www.codinghorror.com/blog/archives/000832.html">My old Habu</a> wasn't exactly chopped liver-- nor was <a href="http://www.codinghorror.com/blog/archives/000286.html">the Logitech MX 518</a> I used before that-- but on the whole, <b>I prefer the Logitech G9</b>. The Sidewider is arguably the more innovative model, but I have a few concerns with it:
</p>
<p>
</p>
<ol>
<li>It is a large mouse. The shape, while unusual, is plenty comfortable-- but bulky. I prefer smaller mice in general.
</li>
<li>The thumb buttons are in an unusual location. I've trained my thumb to move up, not forward. Every time I hit the "back" thumb button, I have to think and stretch a bit to reach it.
</li>
<li>It's a bit more awkward in general. Even with equivalent DPI and mouse speed/acceleration settings, I miss small click targets that I had no problem hitting with the G9 or the Habu. I don't think it's a technical limitation; it might be a consequence of the fit.
</li>
</ol>
<p>
The G9, on the other hand, is a flawless mouse upgrade. I have no complaints whatsoever-- it's a solid step forward in every respect. Well, there is one minor niggle worth mentioning: the body, because it's designed to be interchangeable, is a tiny bit loose when you pick up the mouse. If you frequently pick up the mouse to adjust the position, you might find that annoying. Also, the frictionless mouse wheel option is fun-- it reminds me of the spinner control in classic arcade games like <a href="http://en.wikipedia.org/wiki/Tempest_(game)">Tempest</a>-- but useless in practice. It is an option, not a requirement, so I don't deduct anything for that. I'll stick with the Sidewinder at work for a while longer and see if I can adapt. I admire all the innovation at a relatively low price (for this type of enthusiast mouse, at least), but I am sorely tempted to <a href="http://www.amazon.com/exec/obidos/ASIN/B000UHE8Y2/codihorr-20">buy another G9</a>.
</p>
<p>
During all this mouse testing, I spent a lot of time normalizing the pointer speed between the control panel mouse options and the DPI settings in the mouse's hardware. I don't think I realized until now <b>how essential it is to enable mouse pointer acceleration</b> for best pointer "feel" with <i>any</i> mouse. I strongly recommend that you double check to make sure this this feature is enabled. It's available in Control Panel, Mouse, Pointer Options under "Enhance Pointer Precision".
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
What does Enhance Pointer Precision do? It's a simple concept. When enabled, <b>the pointer moves more precisely when you move the mouse slowly, and more nimbly when you move the mouse quickly</b>. It decouples pointer movement ever so slightly from a basic 1:1 relationship with mouse movement, and introduces something called the mouse acceleration curve.
</p>
<p>
The translation from physical mouse movement to pointer movement is more sophisticated and more subtle than you might think. It's all documented in <a href="http://www.microsoft.com/whdc/device/input/pointer-bal.mspx">an excellent Microsoft article on mouse ballistics</a>. It introduced me to the amusing concept of the <i>mickey</i>: the smallest unit of measurement that the mouse's hardware can produce.
</p>
<p>
Let's think about this like programmers. If it was our job to translate mouse mickeys into pointer movements, how would we do it? Our first order of business is to figure out how fast the mouse is moving on the table or mousepad-- the mouse <i>velocity</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The accuracy of the mickeys coming from our mouse is strongly influenced by the bus update rate. The math proves it. I talked about this in an earlier post on <a href="http://www.codinghorror.com/blog/archives/000832.html">Mouse DPI and USB Polling Rate</a>. The good news is that fancy enthusiast mice always override the default 125 Hz USB update rate. Both of these mice bump it up to 500 Hz as soon as they're plugged in, which I verified using the <a href="http://www.codinghorror.com/blog/files/dx_mouse_timer_dialog.zip">Direct Input Mouse Rate tool</a>.
</p>
<p>
The number of mickeys/inch is similarly influenced by the capabilities of the mouse's sensor hardware, also known as DPI. It should more accurately be called MPI, <b>mickeys per inch</b>. A "dot" isn't a dot at all; it's a completely arbitrary unit, nothing more than the smallest unit of movement that the hardware can measure. The Sidewinder ranges from 200 DPI to 2000 DPI; the G9 from 200 DPI to 3200 DPI. This is dynamically switchable via the buttons on the mouse, and configurable in software as well. Don't get hung up on the fact that the Sidewinder "only" goes up to 2000 DPI; the packets going over the wire only allow a mickey size between 0 and +127, so there's a practical limit on how precise you can be.
</p>
<p>
Now that we have mouse velocity in the physical world, let's determine how that will map to <i>pointer</i> velocity on the virtual world of our screen.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Screens are bounded by obvious, concrete physical limitations. Refresh rate is typically fixed at 60 Hz for modern LCD displays. Screen resolution varies from 800 x 600 to astronomically huge for those that can afford 30" displays, but <a href="http://www.codinghorror.com/blog/archives/000886.html">the DPI ranges are fairly similar for most monitors</a>.
</p>
<p>
Let's try plugging in some typical values into our formulas:
</p>
<p>
V<sub>mouse</sub> = 3 mickeys * 500 Hz / 1600 DPI = 0.9375 inches/sec<br>
V<sub>pointer</sub> = 3 mickeys * 60 Hz / 80 DPI =  2.25 inches/sec
</p>
<p>
You can immediately see the disconnect-- <b>1 inch of physical mouse movement resulted in 2.25 inches of screen pointer movement</b>. There's a physical to virtual gain of 2.4x. Without the mouse acceleration curve, this is as sophisticated as it gets. We might use a simple multiplier based on the pointer speed slider, but that's about it. The relationship is linear. We're doing a basic one to one mapping.
</p>
<p>
But with "Enhance Pointer Precision", we use a variable curve to determine how far the pointer moves for any given mouse speed. The different colored curves shown here represent different values of the pointer speed slider with acceleration enabled.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It is possible to edit these curves via the <code>SmoothMouseXCurve</code> and <code>SmoothMouseYCurve</code> registry settings, but there's absolutely no documentation I could find on these settings, so be careful. Getting the curve right is crucial. According to <a href="http://www.microsoft.com/whdc/device/input/pointer-bal.mspx?pf=true">the article</a>, the mouse acceleration curves in Windows were determined by a usability study. For example, <a href="http://db.tidbits.com/article/8893">many people dislike the default mouse acceleration curve in OS X</a>:
</p>
<p>
</p>
<blockquote>
So what's wrong with Mac OS X's mouse acceleration curve? Simply put, it's the wrong shape. For mouse motion to feel natural (at least for most people), the curve has to start by moving upward fairly moderately, then gradually flattening out as the value of X increases. Mac OS X's, curve, however, starts off by being too steep, staying too steep for too long, and then flattening out too abruptly. In practical terms this means that, frequently, as a user tries to use the mouse to move the pointer from point A to point B, the pointer motion feels sluggish. The user then tries to compensate for the sluggishness by moving the mouse faster, and the pointer suddenly goes flying across the screen and overshoots point B. A comfortable and useful curve is actually shaped like a curve. Mac OS X's curve, however, is shaped more like a cliff.
</blockquote>
<p>
Windows may have better curves, as long as that "Enhance Pointer Precision" checkbox is ticked.
</p>
<p>
Who knew mouse ballistics could be this sophisticated? Heck, who knew that mouse ballistics even <i>existed</i> until now? Experiment with the "Enhance Pointer Precision" setting for yourself, but <b>I believe it should always be enabled</b>-- it results in mouse pointer movement most people will find both easier to control and more accurate.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/mouse-ballistics/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Torrent Informatics ]]></title>
<link>https://blog.codinghorror.com/torrent-informatics/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><a href="http://www.utorrent.com/">uTorrent</a> is my favorite torrent client. It's such a joy to use – a tiny, native application that offers a best-of-breed implementation of the <a href="http://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a> protocol. <a href="http://www.codinghorror.com/blog/archives/000795.html">Everybody loves BitTorrent</a>, and I love it too. I'm not the only one. By some estimates, torrent data may account for as much as 35% of all internet traffic.</p>
<p>I recently rented the television series <a href="http://en.wikipedia.org/wiki/Boomtown">Boomtown</a> from Netflix, but I belatedly realized that the particular episode I really wanted to see was a part of season two. Unfortunately, Boomtown, like so many other great shows, was cancelled in its prime. In this case, it was cancelled right in the middle of season two – and the incomplete season was never released on DVD. What's a poor, law-abiding citizen of the United States of America to do?</p>
<p>BitTorrent to the rescue. I was able to locate a torrent of all the Boomtown episodes, and I'm downloading it now.</p>
<p>I've talked before about the <a href="http://www.codinghorror.com/blog/archives/000815.html">remarkable parity between the uTorrent web user interface and the windows user interface</a>. However, as good as the web UI is, it pales in comparison to <strong>the incredibly deep informatics that uTorrent provides on the state of your BitTorrent download</strong>. I love poring over the torrent metrics; they're beautifully presented – an excellent example of how to visually depict a complex set of data in a meaningful way. Let's take a quick visual tour through the main tabs in uTorrent; I'll point out the most interesting parts.</p>
<p>On the <strong>General Tab</strong>, we can see that the torrent is fairly well seeded. That's important, because the biggest weakness of the torrent system is that it requires a certain level of popularity to work at all. In our case, the availability graphic is a nice, solid blue – there are no red bars indicating missing sections. The darker the bars, the more copies of that particular section are available in the swarm.</p>
<p>It's also indicated numerically; an availability of 1 means the entire file is available. That's the minimum, assuming you want to download everything. An availability of 5.93 indicates there are almost 6 complete copies of the torrent data in the swarm. It's no coincidence that there are also 6 peers with a complete copy of the data – these critically important peers are known as "seeds". The other 19 peers will remain peers until they manage to download 100% of the data, and then they become seeds too. If a torrent loses all its seeds, it is in deep trouble.</p>
<p><img alt="image placeholder" >
<p>On the <strong>Files Tab</strong>, we can see the state of individual files in the torrent. There's a nice little graphic next to each file that shows how many pieces of the files have been downloaded. The blue sections indicate parts of the file that have been successfully downloaded; green sections indicate parts of the file that are being downloaded right now.</p>
<p>You can also tag files with a priority, so they're retrieved in a particular order. Well, roughly – the torrent protocol retrieves in random order from whatever's available in the peer swarm, so order is never guaranteed. Or, you can set them to "skip" if you don't want to retrieve those files. Since I already rented all the season 1 DVDs, I set all the season 1 epsiodes to skip, and I switched the particular season 2 episode I wanted to "high". This will prevent me from becoming a seed, but it dramatically shortens my download time.</p>
<p><img alt="image placeholder" >
<p>On the <strong>Peers Tab</strong>, we can get a glimpse into the democratic nature of the BitTorrent protocol. These are our fellow peers and seeds, sharing whatever bits of the data they have with everyone else in the swarm. Given enough peers, downloads are fast for everyone. uTorrent conveniently does a DNS lookup and shows little flags next to each peer, so you can get a sense of how global the BitTorrent protocol really is.</p>
<p><img alt="image placeholder" >
<p>On the <strong>Pieces Tab</strong>, we can see the real-time state of the current pieces we're downloading from our peers in the swarm. Dark blue means downloaded; light blue means requested but not yet downloaded.</p>
<p><img alt="image placeholder" >
<p>On the <strong>Speed Tab</strong>, we can view a history of transfer rates over time, including both upload and download speeds. BitTorrent is a shared download, so you're supposed to give as much as you get – although altruism is difficult to enforce.</p>
<p><img alt="image placeholder" >
<p>Another section of the <strong>Speed Tab</strong> shows an incredibly detailed breakdown of disk activity. BitTorrent is designed to download <em>enormous</em> files. This torrent is over 8 GB in size, for example. With such large amounts of data in play, managing disk caches and optimizing disk activity is unusually important.</p>
<p><img alt="image placeholder" >
<p>Most of this is also explained in the official <a href="http://www.utorrent.com/faq.php">uTorrent FAQ</a>, and it goes into greater detail, too.</p>
<p>I'll admit that I tend to completely geek out on the way Torrent <strong>exposes all the inner workings of the BitTorrent protocol in such a beautiful, highly visual way</strong>. It never takes the easy way out and renders as a boring table of numbers when a visualization would work better. I think many programs could learn a lot from the way uTorrent so effortlessly presents the mountain of data it is processing internally.</p>
<p>I think there's a deeper lesson here as well. <strong>The commercial market failed me</strong>. As far as I can tell, there's no way I could obtain these elusive season 2 Boomtown episodes through legitimate channels. I was only able to obtain them through a torrent graciously seeded and shared by fellow Boomtown enthusiasts. Perhaps that's the real beauty of BitTorrent – it's the world's most efficient and democratic distribution network, because it's driven entirely by us.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/torrent-informatics/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Remember, This Stuff Is Supposed To Be Fun ]]></title>
<link>https://blog.codinghorror.com/remember-this-stuff-is-supposed-to-be-fun/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I distinctly remember the tribulations my father went through in his career. He worked hard to achieve an MBA from a prestigious business school. The degree opened up many opportunities for him, but I don't think he ever found exactly what he was looking for. We moved throughout my childhood, travelling from job to job, never staying in one place for more than a year or so. I'm not sure he ever found work that satisfied him, even to this day. Copies of <a href="http://www.amazon.com/exec/obidos/ASIN/1580087272/codihorr-20">What Color is Your Parachute</a> were staples in our household.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/1580087272/codihorr-20"><img alt="image placeholder" >
</p>
<p>
It can take a long time to figure out what you want out of your work life.
</p>
<p>
Like my Dad, I spent many years after college flitting from job to job. I had nothing to complain about. I was making a great living. I was never on the market for particularly long before some new opportunity would come up. I enjoyed my work. But I wasn't choosing a career path. I was letting happenstance determine what I was, and what I was becoming.
</p>
<p>
At some point in your career, you have to stop floating through life like the symbolic feather in <a href="http://www.imdb.com/title/tt0109830/">Forrest Gump</a>.
</p>
<p>
<a href="http://www.imdb.com/title/tt0109830/"><img alt="image placeholder" >
</p>
<p>
Unfortunately, I don't think my father ever figured out what he loved to do. He never determined the color of his parachute. But I got lucky. A few years ago I realized that what I loved to do, what I really <i>loved to do</i> more than anything else, was write software and fool around with computers. Seems obvious, I know, but you have the advantage of not being me. Self-awareness is a perplexingly difficult thing from here on the inside.
</p>
<p>
Life is too short to stay at a job where you're not doing the things you want to do, where you're not enjoying yourself. And yet here I was, a guy hopelessly in love with all things computer and software, working at a company where <a href="http://www.softwarebyrob.com/2007/10/15/q-a-on-leaving-management-for-development/">where software was considered a byproduct, a cost center, a necessary evil</a>:
</p>
<p>
</p>
<blockquote>
A close friend of mine works for a company that has experienced a mass exodus of developers. The best left first, the mid-range followed. What's left are the people who clock in 9 to 5 for the paycheck and don't take pride in what they're building. The company now has what they asked for: a team of low-level code jockeys. The people with initiative, energy, and passion have left.
<p>
Enterprises that consider developers "commodities and low level craftsmen" are doomed to have (at best) average developers working for them.
</p>
</blockquote>
<p>
To be fair, it was post-bubble, and jobs were hard to come by. The work was interesting, but it was abundantly clear that software was not the lifeblood of this organization. Outsourcing was in the air. Although my coworkers were competent, nobody was quite as obsessed with the software as I was. My passion for software, and everything around it, was clearly not shared.
</p>
<p>
I set out to change that. Companies would no longer be able to select me from a generic lineup of candidates. Instead, I would select companies. Companies that I respected, companies that shared my passion for software. Armed with thirty years of hindsight, I would no longer let random, chance opportunities determine my career path. <b>I will choose where <i>I</i> want to work</b>.
</p>
<p>
In <a href="http://www.inc.com/magazine/20071001/how-hard-could-it-be-unfocused-and-unabashed_Printer_Friendly.html">a recent article</a>, Joel Spolsky describes the guiding philosophy behind his software company:
</p>
<p>
</p>
<blockquote>
Frankly, <b>the main reason I had to start this company was to have fun at work</b>. Working at Fog Creek is intentionally designed to be pleasant. We started the business because we wanted a great place to work, to spend our daylight hours. And we have a disturbing tendency to try to do a lot of things ourselves, especially if it's going to be fun or if we think we can do a better job. It takes us a little longer that way, but I figure the journey is the reward.
</blockquote>
<p>
That's exactly why I chose to work at <a href="http://www.vertigo.com">Vertigo Software</a>. We have the same philosophy. At Vertigo, I'm surrounded by incredibly talented software engineers who are all passionate about software. And <i>dammit, we have fun</i>.
</p>
<p>
If you love software as much as I do, you deserve to work at a company where people come to work not to punch a clock, but because they love software, too. You deserve to work at a company where software engineering is respected. You deserve to work at a company where peers meet to <i>enjoy</i> building software together.*
</p>
<p>
We're in the middle of a huge tech boom; <a href="http://www.codinghorror.com/blog/archives/000843.html">some might even call it another bubble</a>. Opportunities abound.
</p>
<p>
Choose wisely. And remember, <b>this stuff is supposed to be fun</b>.
</p>
<p>
* did I mention that <a href="http://www.vertigo.com/Jobs.aspx">we're hiring?</a>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/remember-this-stuff-is-supposed-to-be-fun/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Does Software Spoil? ]]></title>
<link>https://blog.codinghorror.com/why-does-software-spoil/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In the software industry, the release of newer, better versions is part of the natural order. It's a relentless march towards perfection that <a href="http://www.codinghorror.com/blog/archives/000718.html">started with the first personal computers</a>, and continues today. We expect software to get larger and more sophisticated over time, to track with the hardware improvements that <a href="http://www.codinghorror.com/blog/archives/000741.html">Moore's law has provided us</a> for so many years. Rapid evolution is a good thing, and it's one reason the computer industry is so exciting to work in. If you don't like the way things are today, <a href="http://www.codinghorror.com/blog/archives/000545.html">just wait five years</a>; everything will be different.
</p>
<p>
</p>
<blockquote>
Letts' Law: All programs evolve until they can send email.
<p>
<a href="http://www.catb.org/~esr/jargon/html/Z/Zawinskis-Law.html">Zawinski's Law</a>: Every program attempts to expand until it can read mail.
</p>
<p>
<a href="http://www.furrygoat.com/2005/05/furrygoats_law.html">Furrygoat's Law</a>: Every program attempts to expand until it can read RSS feeds.
</p>
</blockquote>
<p>
I love the prospect of upgrading my favorite software. Done right, it's like watching a caterpillar shed its skin and become a beautiful butterfly. Or at least a <a href="http://en.wikipedia.org/wiki/Hyalophora_cecropia">decent-looking moth</a>.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Hyalophora_cecropia"><img alt="image placeholder" >
 
<a href="http://en.wikipedia.org/wiki/Hyalophora_cecropia"><img alt="image placeholder" >
</p>
<p>
But for some software packages, something goes terribly, horribly wrong during the process of natural upgrade evolution. Instead of becoming <i>better</i> applications over time, they become <i>worse</i>. They end up more bloated, more slow, more complex, more painful to use.
</p>
<p>
<b>They spoil.</b>
</p>
<p>
I know this first hand because I'm a long-time <a href="http://en.wikipedia.org/wiki/Paint_Shop_Pro">Paint Shop Pro</a> user. As a programmer who doesn't need the kitchen sink of graphics editor features, I found it an <a href="http://www.codinghorror.com/blog/archives/000849.html">ideal match for my modest programmer needs</a>. I didn't upgrade to every new version, but when I did, for every new feature I could actually use and benefit from, there were dozens of other features included that I didn't care about. These new features cluttered up the user interface and often interfered with what I wanted to do. My computers kept getting faster, and yet PSP kept taking longer and longer to start up with each new version.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="300">
<tr>
<td>2.0</td>
<td>1994?</td>
<td>0.4 MB</td>
</tr>
<tr>
<td>3.11</td>
<td>1995</td>
<td>1.8 MB</td>
</tr>
<tr>
<td>4.12</td>
<td>1997</td>
<td>2.4 MB</td>
</tr>
<tr>
<td>5.0</td>
<td>1998</td>
<td>6.7 MB</td>
</tr>
<tr>
<td>6.0</td>
<td>1999</td>
<td>?</td>
</tr>
<tr>
<td>7.0</td>
<td>2000</td>
<td>32 MB</td>
</tr>
<tr>
<td>8.0</td>
<td>2003</td>
<td>54 MB</td>
</tr>
<tr>
<td>9.0</td>
<td>2004</td>
<td>108 MB</td>
</tr>
<tr>
<td>10.0</td>
<td>2005</td>
<td>104 MB</td>
</tr>
<tr>
<td>11.00</td>
<td>2006</td>
<td>211 MB</td>
</tr>
<tr>
<td>12.00</td>
<td>2007</td>
<td>326 MB</td>
</tr>
</table>
<p>
If this spoilage goes on long enough, <b>eventually you begin to loathe and fear the upgrade process</b>. And that strikes me as profoundly sad, because it rips the heart out of the essential enjoyment of software engineering. We write software. If we inevitably end up making software <i>worse</i>, then why are we bothering? What are we doing wrong?
</p>
<p>
I'm not against progress by any means. But it sure seems to me that certain software packages have truly lost their way. In their never-ending quest to add feature bullets, they've somehow forgotten their users and their core values. In trying to be everything to everyone, they progressively destroy that tiny core of uniqueness that they started with. I'm singling out Paint Shop Pro here, but this same software spoilage principle applies to many other applications. <a href="http://www.pcworld.com/article/id,137703-page,1-c,software/article.html">PC World compiled an annotated list of 13 software applications</a> they liked better before they were "improved":
</p>
<p>
</p>
<ul>
<li>AIM
</li>
<li>ICQ
</li>
<li>Windows Live Messenger
</li>
<li>Windows Media Player
</li>
<li>iTunes
</li>
<li>QuickTime
</li>
<li>iMovie
</li>
<li>Paint Shop Pro
</li>
<li>ACDSee
</li>
<li>Adobe Acrobat Reader
</li>
<li>Eudora
</li>
</ul>
<p>
They helpfully provide links to <a href="http://www.oldversion.com/">oldversion.com</a>, <a href="http://oldapps.com/">oldapps.com</a>, and <a href="http://old-versions.net/">old-versions.net</a>, where you can go back in time and obtain those classic, unspoiled versions.
</p>
<p>
</p>
<blockquote>
My favorite version is Winamp 2.95. That's before they started bulking up the client and adding completely unnecessary things. I just want something that plays my MP3s. I don't need it to burn CDs for me or download new music or cook my breakfast or massage my feet.
</blockquote>
There are also some emerging lightweight alternatives to choose from in each category. Instead of <a href="http://www.oldversion.com/program.php?n=acrobat">Adobe's 20 MB Acrobat Reader</a>, you could opt for the <a href="http://www.foxitsoftware.com/pdf/rd_intro.php">2 MB Foxit PDF Reader</a>. Instead of suffering through another 300+ MB Paint Shop Pro upgrade, chock full of features I'll never use, I could opt for the open source <a href="http://www.getpaint.net/">Paint.NET</a>.
<p>
It's depressing to me that there are very few apps I can stick with for more than five years before they become an untenable, unbearable mess. I can think of so many that I've liked and since discarded: Nero Burning ROM, WinAmp, ACDSee, Microsoft Money, WinZip, and many others.
</p>
<p>
I suppose features sell software. For many companies, putting users on the version upgrade treadmill is their business model; it's how they generate revenue. But if this fiscally rewarding feature creep goes on long enough, spoilage inevitably sets in. So I wonder: <b>Is all software destined to spoil over time?</b> Is it possible for software packages with long histories to avoid the trap of becoming bloated and irrelevant? What are your favorite bits of software that <i>haven't</i> spoiled over the years-- and what is their secret?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-does-software-spoil/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Are Features The Enemy? ]]></title>
<link>https://blog.codinghorror.com/are-features-the-enemy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Mark Minasi is <a href="http://www.imdb.com/title/tt0074958/quotes">mad as hell</a>, and he's not going to take it any more. In his online book <a href="http://www.softwareconspiracy.com/">The Software Conspiracy</a>, he
examines in great detail the paradox I struggled with yesterday-- new features are used to
<i>sell</i> software, but they're also the primary reason that software
<a href="http://www.codinghorror.com/blog/archives/000973.html">spoils over time</a>.</p>
<blockquote>
If a computer magazine publishes a roundup of word processors, the central piece of that article will be the "feature matrix," a table showing what word processing programs have which features. With just a glance, the reader can quickly see which word processors have the richest sets of features, and which have the least features. You can see an imaginary example in the following table:
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td></td>
<td><b>MyWord 2.1</b></td>
<td><b>BugWord 2.0</b></td>
<td><b>SmartWords 3.0</b></td>
</tr>
<tr>
<td>Can boldface text</td>
<td style="text-align: center">X</td>
<td style="text-align: center">X</td>
<td> </td>
</tr>
<tr>
<td>Runs on the Atari 520</td>
<td> </td>
<td style="text-align: center">X</td>
<td> </td>
</tr>
<tr>
<td>Automatically indents first line of a paragraph</td>
<td style="text-align: center">X</td>
<td> </td>
<td> </td>
</tr>
<tr>
<td>Includes game for practicing touch typing</td>
<td> </td>
<td style="text-align: center">X</td>
<td style="text-align: center">X</td>
</tr>
<tr>
<td>Lets you design your own characters</td>
<td> </td>
<td style="text-align: center">X</td>
<td style="text-align: center">X</td>
</tr>
<tr>
<td>Generates document tables of contents</td>
<td style="text-align: center">X</td>
<td> </td>
<td>
 </td>
</tr>
<tr>
<td>Can do rotating 3D bullet points in color</td>
<td> </td>
<td style="text-align: center">X</td>
<td style="text-align: center">X</td>
</tr>
<tr>
<td>Can do bulleted lists</td>
<td style="text-align: center">X</td>
<td> </td>
<td>
 </td>
</tr>
<tr>
<td>Supports Cyrillic symbol set</td>
<td> </td>
<td style="text-align: center">X</td>
<td>
 </td>
</tr>
<tr>
<td>Includes Malaysian translater</td>
<td> </td>
<td style="text-align: center">X</td>
<td style="text-align: center">X</td>
</tr>
</table>
<p>
It looks like BugWord 2.0 is the clear value -- there are lots more check boxes in its column. However, a closer look reveals that it lacks some very basic and useful word processing features, which MyWord 2.1 has. But the easy-to-interpret visual nature of a feature matrix seems to mean that the magazine's message is: <b>Features are good, and the more the better.</b> As Internet Week senior executive editor Wayne Rash, a veteran of the computer press, says, "Look at something like PC Magazine, you'll see this huge comparison chart. Every conceivable feature any product could ever do shows up, and if a package has that particular feature, then there's a little black dot next to that product. What companies want is to have all the little black dots filled in because it makes their software look better."
</p>
</blockquote>
<p>Mark maintains that software companies give bugs in their existing software a low priority, while developing new features for the next
version is considered critically important. As a result, quality suffers. He trots out this Bill Gates quote as a prime
example:</p>
<blockquote>
There are no significant bugs in our released software that any significant
number of users want fixed... <b>The reason we come up with new versions is not
to fix bugs</b>. It's absolutely not. It's the stupidest reason to buy a new
version I ever heard... And so, in no sense, is stability a reason to move to a
new version. It's never a reason.</blockquote>
<p>It's hard to argue with the logic. Customers will pay for new features. But
customers will never pay companies to fix bugs in their software. Unscrupulous
software companies can exploit this by fixing bugs in the next version, which just so
happens to be jam packed full of exciting new features that will induce
customers to upgrade. </p>
<p>
Unlike Mark, I'm not so worried about bugs. All software has bugs, and if you accrue enough of them, your users will eventually revolt. Yes, the financial incentives for fixing bugs are weak, but the market seems to work properly when faced with buggy software.
</p>
<p>
A much deeper concern, for me, is <b>the subtle, creeping feature-itis that destroys my favorite software</b>. It's the worst kind of affliction-- a degenerative disease that sets in over time. As I've regrettably discovered in many, many years of using software, adding more features rarely results in better software. The commercial software market, insofar as it forces vendors to engage in bullet point product feature one-upsmanship, could be actively harming the very users it is trying to satisfy.
</p>
<p>
And the worst part, the absolute worst part, is that <i>customers are complicit in the disease</i>, too. Customers ask for those new features.  And customers will use the dreaded "feature matrix" as a basis for comparing what applications they'll buy. Little do they know that they're slowly killing the very software that they love.
</p>
<p>
Today, as I was starting up WinAmp, I was blasted by this upgrade dialog.
</p>
<img alt="image placeholder" >
<p>
Do I care about any of these new features? No, not really. Album art sounds interesting, but the rest are completely useless to me. I don't have to upgrade, of course, and there's nothing forcing me to upgrade. Yet. My concern here isn't for myself, however. It's for WinAmp. For every new all-singing, all-dancing feature, WinAmp becomes progressively slower, even larger, and more complicated. Add enough well-intentioned "features", and eventually WinAmp will destroy itself.
</p>
<p>
<b>Sometimes, I wonder if the current commercial software model is doomed.</b> The neverending feature treadmill it puts us on almost always results in extinction. Either the application eventually becomes so bloated and ineffective that smaller, nimbler competitors replace it, or the application slowly implodes under its own weight. In either case, nothing is truly fixed; the cycle starts anew. Something always has to give in the current model. Precious few commercial software packages are still around after 10 years, and most of the ones that are feel like dinosaurs.
</p>
<p>
Perhaps we should <b>stop blindly measuring software as a bundle of features</b>, as some kind of endless, digital all-you-can eat buffet. Instead, we could measure software by <i>results</i>-- how productive or effective it makes us at whatever task we're doing. Of course, measuring productivity and results is hard, whereas counting bullets on a giant feature matrix is brainlessly easy. Maybe that's exactly the kind of cop-out that got us where we are today.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/are-features-the-enemy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Let's Play Planning Poker! ]]></title>
<link>https://blog.codinghorror.com/lets-play-planning-poker/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the most challenging aspects of any software project is estimation-- determining how long the work will take. It's so difficult, some call it a black art. That's why I highly recommend McConnell's book, <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art</a>; it's the definitive work on the topic. Anyone running a software project should own a copy. If you think you <i>don't</i> need this book, take the estimation challenge: <a href="http://www.codinghorror.com/blog/archives/000625.html">how good an estimator are you?</a>
</p>
<p>
How'd you do? If you're like the rest of us, <b><i>you suck</i></b>. At estimating, I mean.
</p>
<p>
Given the uncertainty and variability around planning, it's completely appropriate that there's a game making the rounds in agile development circles called <a href="http://en.wikipedia.org/wiki/Planning_poker">Planning Poker</a>.
</p>
<p>
<a href="http://www.crisp.se/planningpoker/"><img alt="image placeholder" >
</p>
<p>
There are even <a href="http://www.crisp.se/planningpoker/">cards for it</a>, which makes it feel a lot more poker-ish in practice. And like poker, the stakes in software development are real money-- although we're usually playing with someone else's money. If you have a distributed team, card games may seem like a cruel joke. But there's a nifty <a href="http://www.planningpoker.com/">web-based implementation of Planning Poker</a>, too.
</p>
<p>
Planning Poker is a form of the estimation technique known as <a href="http://www.stellman-greene.com/aspm/content/view/23/26/">Wideband Delphi</a>. Wideband Delphi was <a href="http://www.rand.org/pubs/research_memoranda/RM5888/">created by the RAND corporation in 1968</a>. I assume by Delphi they're referring to <a href="http://en.wikipedia.org/wiki/Pythia">the oracle at Delphi</a>. If anything says "we have no clue how long this will take", it's naming your estimation process after <a href="http://news.nationalgeographic.com/news/2001/08/0814_delphioracle.html">ancient, gas-huffing priestesses</a> who offered advice in the form of cryptic riddles. It doesn't exactly inspire confidence, but that's probably a good expectation to set, given the risks of estimation.
</p>
<p>
Planning Poker isn't quite as high concept as Wideband Delphi, but the process is <a href="http://www.planningpoker.com/detail.html">functionally identical</a>:
</p>
<p>
</p>
<ol>
<li>Form a group of no more than 10 estimators and a moderator. The product owner can participate, but cannot be an estimator.
</li>
<li>Each estimator gets a deck of cards: 0, 1, 2, 3, 5, 8, 13, 20, 40, and 100.
</li>
<li>The moderator reads the description of the user story or theme. The product owner answers brief questions from the estimators.
</li>
<li>Every estimator selects an estimate card and places it face down on the table. After all estimates are in, the cards are flipped over.
</li>
<li>If the estimates vary widely, the owners of the high and low estimates discuss the reasons why their estimates are so different. All estimators should participate in the discussion.
</li>
<li>Repeat from step 4 until the estimates converge.
</li>
</ol>
<p>
There's nothing magical here; it's the power of group dialog and <a href="http://www.codinghorror.com/blog/archives/000611.html">multiple estimate averaging</a>, delivered in an approachable, fun format.
</p>
<p>
Planning Poker is a good option, particularly if your current estimation process resembles throwing darts at a printout of a Microsoft Project Gantt chart. But <b>the best estimates you can possibly produce are those based on historical data</b>. Steve McConnell has <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">a whole chapter on this</a>, and here's his point:
</p>
<p>
</p>
<blockquote>
If you haven't previously been exposed to the power of historical data, you can be excused for not currently having any data to use for your estimates. But now that you know how valuable historical data is, you don't have any excuse not to collect it. Be sure that when you reread this chapter next year, you're not still saying "I wish I had some historical data!"
</blockquote>
<p>
In other words, if you don't have historical data to base your estimates on, <i>begin collecting it as soon as possible</i>. There are tools out there that can help you do this. Consider the latest version of <a href="http://www.fogcreek.com/FogBugz/">Fogbugz</a>; its marquee feature is <a href="http://www.fogcreek.com/FogBugz/learnmore.html#hist_PredictShipDates">evidence-based scheduling</a>. Armed with the right historical evidence, you can..
</p>
<p>
<b>Predict when your software will ship</b>. Here you can see we have a 74% chance of shipping by December 17th.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Determine which developers are on the critical path</b>. Some developers are better at estimating than others; you can shift critical tasks to developers with a proven track record of meeting their estimates.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>See how accurate an estimator you really are</b>. How close are your estimates landing to the actual time the task took?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>See your predicted ship dates change over time</b>. We're seeing the 5%, 50%, and 95% estimates on the same graph here. Notice how they converge as development gets further along; this is evidence that the project will eventually complete, and you won't be stuck in some kind of <a href="http://en.wikipedia.org/wiki/Duke_Nukem_Forever#Development_history">Duke Nukem Forever limbo</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Witness, my friends, the power of historical data on a software project.
</p>
<p>
The dirty little secret of evidence based scheduling is that collecting this kind of historical data isn't trivial. Garbage in, garbage out. It takes discipline and concerted effort to enter the effort times-- even greatly simplified versions-- and to keep them up to date as you're working on tasks. Fogbugz does its darndest to make this simple, but your team has to buy into the time tracking philosophy for it to work.
</p>
<p>
You don't have to use Fogbugz. But however you do it, I urge you to begin capturing historical estimation data, if you're not already. It's a tremendous credit to Joel Spolsky that he made this crucial feature the centerpiece of the <a href="http://www.fogcreek.com/FogBugz/">new Fogbugz</a>. I'm not aware of any other software lifecycle tools that go to such great lengths to help you produce good estimates.
</p>
<p>
Planning Poker is a reasonable starting point.  But the fact that two industry icons, Joel Spolsky and Steve McConnell, are both hammering home the same point isn't a coincidence. Historical estimate data is fundamental to the science of software engineering. Over time, try to reduce your reliance on outright gambling, and begin basing your estimates on <i>real data</i>. Without some kind of institutional estimation memory-- without <b>appreciating the power of historical data</b>-- you're likely to keep <a href="http://www.codinghorror.com/blog/archives/000889.html">repeating the same estimation errors over and over</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/lets-play-planning-poker/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Virtual Machine Server Hosting ]]></title>
<link>https://blog.codinghorror.com/virtual-machine-server-hosting/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
My employer, <a href="http://www.vertigo.com/">Vertigo Software</a>, graciously hosted this blog for the last year. But as blog traffic has grown, it has put a noticeable and increasing strain on our bandwidth. Even on an average day, blog traffic consumes a solid 30 percent of our internet connection-- and much more if <a href="http://www.codinghorror.com/blog/archives/000781.html">something happens to be popular</a>. And that's <i>after</i> factoring in <a href="http://www.codinghorror.com/blog/archives/000807.html">all the bandwidth-reducing tricks I could think of</a>.
</p>
<p>
While I greatly appreciate my employer's generosity, I don't like causing all my coworkers' internet connections to slow to a crawl. So when my friend and <a href="http://www.codinghorror.com/blog/archives/000971.html">co-author</a> Phil Haack mentioned that we could share a dedicated server through a contact of his, I jumped at the chance.
</p>
<p>
I'm a <a href="http://www.codinghorror.com/blog/archives/000491.html">big believer in virtualization</a>, so I wanted a beefy physical server that could handle running at least four virtual servers. And I wanted it to run a 64-bit host operating system, as <a href="http://www.codinghorror.com/blog/archives/000435.html">64-bit offers huge performance benefits for servers</a>. Nobody in their right mind should build up a 32-bit server today.
</p>
<p>
The contact he was referring to works at <a href="http://crystaltech.com/dedicated-windows.aspx?uid=101">CrystalTech</a>. And boy, did CrystalTech <i>ever</i> hook us up:
</p>
<p>
</p>
<ul>
<li>Windows Server 2003 R2 x64
</li>
<li>Quad-core Xeon X3210 @ 2.13 Ghz
</li>
<li>4 GB RAM
</li>
<li>300 GB RAID-5 array
</li>
</ul>
<p>
Not too shabby. It is, of course, an obscene amount of power for our relatively modest needs. Have I mentioned how much I like my new friends at CrystalTech? Or what <a href="http://crystaltech.com/dedicated-windows.aspx?uid=101">great deals they have on hosting?</a>
</p>
<p>
<a href="http://crystaltech.com/dedicated-windows.aspx?uid=101"><img alt="image placeholder" >
</p>
<p>
But in all seriousness, it's effectively a new sponsor for this blog, so welcome aboard.
</p>
<p>
I was already hosting this server as a VM, so here's what I did to switch over to completely new hardware:
</p>
<p>
</p>
<ol>
<li>shut down my VM
</li>
<li>compacted and compressed it
</li>
<li>transferred it to the new server
</li>
<li>booted it up again
</li>
</ol>
<p>
All I had to do was change the IP address in the VM and I was up and running as if nothing had changed. That's the easiest server migration I've ever experienced, all thanks to virtualization.
</p>
<p>
Phil and I are both Windows ecosystem developers, so we went with what we knew. But virtualization provides total flexibility. I could spin up a new Linux server at a moment's notice if I decided to switch this blog over to the LAMP stack. Or I could play with the latest release candidate of Windows Server 2008. And they can all run in parallel, assuming we have enough memory. That's what I love most about virtualization-- the freedom.
</p>
<p>
Although Phil and I share admin access to the host machine, we have our own private playgrounds in our virtual servers. We're completely isolated from each other's peculiarities and weirdnesses: nothing we do (well, <i>almost</i> nothing) can affect the other person's virtual machine. Reboot? No problem. Install some stupid software I can't stand? Go for it. Format the drive and start over? Don't care. It's your machine. Do whatever.
</p>
<p>
The only downside to virtual machine server hosting is that <b>it can be difficult to share IPs between virtual machines</b>. CrystalTech has provided us with a block of 6 public IP addresses, so fortunately we don't have to worry about this. One IP is occupied by the host, but that still leaves five IPs for virtual machines of our creation. That's plenty.
</p>
<p>
But let's say we only had two public IP addresses-- or we wanted to run lots and lots of virtual machines with a small pool of public IP addresses. What then?  How could <a href="http://www.codinghorror.com/blog/">codinghorror.com</a> and <a href="http://haacked.com/">haacked.com</a> share the same IP address (and port 80), when they're on two different virtual machines? They clearly can't occupy the same IP.
</p>
<p>
</p>
<pre>
codinghorror.com   10.0.0.1:80
haacked.com        10.0.0.1:80
</pre>
<p>
On a single physical server, the answer is easy-- <a href="http://httpd.apache.org/docs/1.3/vhosts/">virtual hosting</a>, or <a href="http://www.microsoft.com/technet/prodtechnol/WindowsServer2003/Library/IIS/288bd8ef-c12d-43bc-9b66-264bc572c87a.mspx?mfr=true">host header routing</a>. But that requires our websites to live side by side on the same server. Phil and I don't share our wives, so why would we share a server? No offense intended to either of our wives-- or our respective servers-- but sharing is an unacceptable solution. I like you, Phil... but not <i>that</i> much.
</p>
<p>
If you want two different machines (physical or virtual) to share an IP, it takes some clever trickery. In the Windows ecosystem, that clever trickery often comes in the form of Microsoft's <a href="http://www.microsoft.com/isaserver/default.mspx">ISA Server</a>. (I'm not sure what the open source equivalent is, but I'm confident it's out there.)
</p>
<p>
ISA Server acts as our public interface to the world, talking through a public IP address. All DNS entries, and thus HTTP traffic, would be directed to that single public IP address. As our gatekeeper, ISA Server is in a unique position to do lots of cool stuff for us, like firewalling, caching, and so on. But we only care about one particular feature right now: the ability to share an IP address between multiple machines. This is known as a "web rule" in ISA parlance. With appropriate web rules in effect for both of our sites, ISA Server will shuttle the HTTP requests back and forth to the correct private IP addresses based on the host headers. It basically extends the host header routing concepts we saw in Apache and IIS outside the confines of a particular machine.
</p>
<p>
</p>
<pre>
ISA Server         10.0.0.1:80
codinghorror.com   192.168.0.1:80
haacked.com        192.168.0.2:80
</pre>
<p>
That's one way you can host fifty websites, all running on fifty different machines, with a single public IP address. It's a very clever trick indeed. Unfortunately, ISA Server isn't the simplest of products to configure and administer. I'm glad we have enough public IPs that we don't have to worry about sharing them between multiple machines. But it's definitely something you should be aware of, as virtual servers become increasingly commonplace.. and <a href="http://www.networkworld.com/news/2007/062807-ipv6-deadline.html">the pool of available IP addresses continues to dwindle</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/virtual-machine-server-hosting/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Hardware Assisted Brute Force Attacks: Still For Dummies ]]></title>
<link>https://blog.codinghorror.com/hardware-assisted-brute-force-attacks-still-for-dummies/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Evidently <a href="http://technology.newscientist.com/article.ns?id=dn12825">hardware assisted brute force password cracking</a> has arrived:
</p>
<p>
</p>
<blockquote>
A technique for cracking computer passwords using inexpensive off-the-shelf computer graphics hardware is causing a stir in the computer security community.
<p>
Elcomsoft, a software company based in Moscow, Russia, has filed a US patent for the technique. It takes advantage of the "massively parallel processing" capabilities of a graphics processing unit (GPU) - the processor normally used to produce realistic graphics for video games.
</p>
<p>
Using an $800 graphics card from nVidia called the GeForce 8800 Ultra, Elcomsoft increased the speed of its password cracking by a factor of 25, according to the company's CEO, Vladimir Katalov. The toughest passwords, including those used to log in to a Windows Vista computer, would normally take months of continuous computer processing time to crack using a computer's central processing unit (CPU). By harnessing a $150 GPU - less powerful than the nVidia 8800 card - Elcomsoft says they can be cracked in just three to five days. Less complex passwords can be retrieved in minutes, rather than hours or days.
</p>
</blockquote>
<p>
GPUs, with their <a href="http://www.codinghorror.com/blog/archives/000732.html">massive built-in paralellism</a>, were <a href="http://www.codinghorror.com/blog/archives/000823.html">built to do things like this</a>. I'm encouraged that we're finally able to harness all that video silicon to do useful things beyond rendering Doom at 60 frames per second with anti-aliasing and <a href="http://www.codinghorror.com/blog/archives/000484.html">anisotropic filtering</a>.
</p>
<p>
There's a bit more detail on the elecom approach in their <a href="http://www.elcomsoft.com/EDPR/gpu_en.pdf">one-page PDF</a>. They provide actual numbers there.
</p>
<p>
</p>
<blockquote>
Using the "brute force" technique of recovering passwords, it was possible, though time-consuming, to recover passwords from popular applications. For example, the logon password for Windows Vista might be an eight-character  string composed of uppercase and lowercase alphabetic characters. There would about 55 trillion (52 to the eighth power) possible passwords. Windows Vista uses NTLM hashing by default, so using a modern dual-core PC you could test up to 10,000,000 passwords per second, and perform a complete analysis in about two months. <b>With ElcomSoft's new technology, the process would take only three to five days, depending upon the CPU and GPU</b>.
<p>
Preliminary tests using Elcomsoft Distributed Password Recovery show that <b>the [brute force password cracking] speed has increased by a factor of twenty, simply by hooking up with a $150 video card's onboard GPU</b>. ElcomSoft expects to find similar results as this new technology is incorporated into their password recovery products for Microsoft Office, PGP, and dozens of other popular applications.
</p>
</blockquote>
<p>
It's fun, and it makes for a <a href="http://www.pbs.org/wnet/insidelocalnews/behind_leads.html">shocking</a> "Password Cracking Supercomputers On Every Desktop Make Passwords Irrelevant" headline, but password cracking supercomputers on every desktop <i>doesn't</i> mean the end of password-protected civilization as we know it.  Let's do the math.
</p>
<p>
<b>How many passwords can we attempt per second?</b>
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td>Dual Core CPU</td>
<td align="right">10,000,000</td>
</tr>
<tr>
<td>GPU</td>
<td align="right">200,000,000</td>
</tr>
</table>
<p>
<b>How many password combinations do we have to try?</b>
</p>
<p>
52<sup>8</sup> = 53,459,728,531,456
</p>
<p>
That's a lot of potential passwords. Let's stop playing Quake Wars for a few days and get cracking:
</p>
<p>
</p>
<pre>
53,459,728,531,456 /  10,000,000 pps / 60 / 60 / 24 = 61.9 days
53,459,728,531,456 / 200,000,000 pps / 60 / 60 / 24 =  3.1 days
</pre>
<p>
As promised by elecom, that works out to a little over <b>three days at the GPU crack rate</b>, and two months at the CPU crack rate. Oooh. Scary. Worried yet? If so, you shouldn't be. Watch what happens when I add four additional characters to the password:
</p>
<p>
</p>
<pre>
52<sup>12</sup> / 200,000,000 pps / 60 / 60 / 24 =  22,620,197 days
</pre>
<p>
For those of you keeping score at home, with a 12 character password this hardware assisted brute-force attack would take <b>61,973 years</b>. Even if we increased the brute force attack rate by <i>a factor of a thousand</i>, it would <i>still</i> take 62 years.
</p>
<p>
Elecom's idea of an 8 character password is awfully convenient, too. Only lowercase and uppercase letters, a total of 52 possible choices per character. Who has passwords without at least one number? <a href="http://www.schneier.com/blog/archives/2006/12/realworld_passw.html">Even MySpace users are smarter than that</a>. If you include a number in your 8 character password, or a non-alphanumeric character like "%", attack times increase substantially. Not enough to mitigate the potential attack completely, mind you, but you'd definitely put a serious dent in any brute forcing effort by switching out a character or two.
</p>
<p>
</p>
<pre>
62<sup>8</sup> / 200,000,000 pps / 60 / 60 / 24 =  13 days
72<sup>8</sup> / 200,000,000 pps / 60 / 60 / 24 =  42 days
</pre>
<p>
Personally, <a href="http://www.codinghorror.com/blog/archives/000342.html">I think it's easier to go with a pass phrase</a> than a bunch of random, difficult to remember gibberish characters as a password. Even if your pass phrase is in all lower-case-- a mere 26 possible characters -- that exponent is <i>incredibly</i> potent.
</p>
<p>
</p>
<pre>
26<sup>10</sup> / 200,000,000 pps / 60 / 60 / 24 =  8 days
26<sup>12</sup> / 200,000,000 pps / 60 / 60 / 24 =  15 years
26<sup>14</sup> / 200,000,000 pps / 60 / 60 / 24 =  10,228 years
</pre>
<p>
By the time you get to a mere 14 characters-- even if they're all lowercase letters-- you can pretty much forget about anyone brute forcing your password. Ever.
</p>
<p>
So what have we learned?
</p>
<p>
Brute force attacks, even fancy hardware-assisted brute force attacks, are <a href="http://www.codinghorror.com/blog/archives/000631.html">still for dummies</a>. If this is the best your attackers can do, they're too stupid to be dangerous. Brute forcing is almost always a waste of time, when <a href="http://www.codinghorror.com/blog/archives/000852.html">vastly more effective social vectors</a> and <a href="http://www.codinghorror.com/blog/archives/000949.html">superior technical approaches</a> are readily available.
</p>
<p>
<b>Hardware-assisted brute force attacks will never be a credible threat. But short, simple passwords are still dangerous.</b> <i>If</i> your password is only 8 alphabet characters, and <i>if</i> it's exposed in a way that allows brute force hardware assisted attack, you could be in trouble. All you need to do to sleep soundly at night (well, at least as far as brute force attacks are concerned) is choose a slightly longer password. It's much safer to think of your security in terms of passphrases instead of passwords. And unlike "secure" 8 character passwords, passphrases are easy to remember, too. Have you considered <a href="http://www.codinghorror.com/blog/archives/000360.html">helping me evangelize passphrases?</a>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/hardware-assisted-brute-force-attacks-still-for-dummies/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I'd Consider That Harmful, Too ]]></title>
<link>https://blog.codinghorror.com/id-consider-that-harmful-too/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><a href="http://en.wikipedia.org/wiki/Considered_harmful"></a></p>
<p>One of the seminal papers in computer science is <a href="http://en.wikipedia.org/wiki/Edsger_Dijkstra">Edsger Dijkstra's</a> 1968 paper <a href="http://www.u.arizona.edu/~rubinson/copyright_violations/Go_To_Considered_Harmful.html">GOTO Considered Harmful</a>.</p>
<blockquote>For a number of years I have been familiar with the observation that the quality of programmers is a decreasing function of the density of go to statements in the programs they produce. More recently I discovered why the use of the go to statement has such disastrous effects, and I became convinced that the go to statement should be abolished from all "higher level" programming languages (i.e. everything except, perhaps, plain machine code).</blockquote>
<p>The abuse of GOTO is, thankfully, a long forgotten memory in today's modern programming languages.  Of course, it's only a minor hazard compared to the <a href="http://en.wikipedia.org/wiki/COMEFROM">COMEFROM statement</a>, but I'm glad to have both of those largely behind us.</p>
<p><a href="http://globalnerdy.com/2007/10/23/the-real-reason-goto-is-considered-harmful/"><img alt="image placeholder" >
<p><a href="http://stevemcconnell.com/ccgoto.htm">GOTO isn't all bad</a>, though. It still has some relevance to today's code. Along with many other programmers, I always recommend using guard clauses to <a href="http://www.codinghorror.com/blog/archives/000486.html">avoid arrow code</a>, and I also recommend exiting early from a loop as soon as you find the value you're looking for. What is an early <code>Return</code>, or an early <code>Exit For</code> other than <strong>a tightly scoped GOTO?</strong></p>
<pre>foreach my $try (@options) {
next unless exists $hash{$try};
do_something($try);
goto SUCCESS;
}
log_failure();
SUCCESS: ...
</pre>
<p>The publication of such an influential paper in this particular format led to an almost immediate <a href="http://en.wikipedia.org/wiki/Snowclone">snowclone effect</a>, as <a href="http://en.wikipedia.org/wiki/Considered_harmful">documented on Wikipedia</a>:</p>
<blockquote>Frank Rubin published a criticism of Dijkstra's letter in the March 1987 CACM where it appeared as <em>'GOTO Considered Harmful' Considered Harmful</em>. The May 1987 CACM printed further replies, both for and against, as <em>'"GOTO Considered Harmful" Considered Harmful' Considered Harmful?</em>. Dijkstra's own response to this controversy was titled <a href="http://www.cs.utexas.edu/users/EWD/transcriptions/EWD10xx/EWD1009.html">"On a somewhat disappointing correspondence"</a>.</blockquote>
<p>That's easily one of the funniest things I've ever read in Wikipedia. Who says computer scientists don't have a sense of humor? But I digress. Most software developers are probably familiar, at least in passing, with Dijkstra's <a href="http://www.u.arizona.edu/~rubinson/copyright_violations/Go_To_Considered_Harmful.html">GOTO Considered Harmful</a>. But here's what they might <em>not</em> know about it:</p>
<ol>
<li>The paper was originally titled "A Case Against the Goto Statement"; the editor of the CACM at the time, <a href="http://en.wikipedia.org/wiki/Niklaus_Wirth">Niklaus Wirth</a>, changed the title to the more inflammatory version we know today. </li>
<li>In order to speed up its publication, the paper was converted into a "Letter to the Editor". </li>
</ol>
<p>In other words, Wirth poked and prodded the content until it became incendiary, to maximize its impact. The phrase "considered harmful" was used quite intentionally, <a href="http://itre.cis.upenn.edu/~myl/languagelog/archives/004675.html">as documented on the always excellent Language Log</a>:</p>
<blockquote>However, "X considered harmful" was already a well-established journalistic cliche in 1968 -- which is why Wirth chose it. The illlustration below shows the headline of a letter to the New York Times published August 12, 1949: "Rent Control Controversy / Enacting Now of Hasty Legislation Considered Harmful".
<p><img alt="image placeholder" >
<p>I'm sure it's not the earliest example of this phrase used in a headline or title, either -- I chose it only as a convenient illustration of susage a couple of decades before the date of Dijkstra's paper.</p>
<p>Note that this example is also in the title of a slightly cranky letter to the editor - it's probably not an accident that the first example that came to hand of "considered harmful" in a pre-Dijkstra title was of this type.</p>
</blockquote>
<p>So when you emulate the "considered harmful" style predicated on the work of these famous computer scientists in 1968, keep that history in mind. <strong>You're emulating a slightly cranky letter to the editor</strong>. It's frighteningly common-- there are now <a href="http://www.google.com/search?&amp;q=intitle%3A%22considered+harmful%22">28,800 web pages with the exact phrase "considered harmful" in the title</a>.</p>
<p>This leads, perhaps inevitably, to Eric Meyer's <a href="http://meyerweb.com/eric/comment/chech.html">"Considered Harmful" Essays Considered Harmful</a>. He points out that choosing this style of dialogue is ultimately counterproductive:</p>
<blockquote>There are three primary ways in which "Considered Harmful" essays cause harm.
<ol>
<li>The writing of a "considered harmful" essay often serves to inflame whatever debate is in progress, and thus makes it that much harder for a solution to be found through any means. Those who support the view that the essay attacks are more likely to dig in and defend their views by any means necessary, and are less receptive to reasoned debate. By pushing the opposing views further apart, it becomes more likely that the essay will cause a permanent break between opposing views rather than contribute to a resolution of the debate.
</li>
<li>"Considered harmful" essays are most harmful to their own causes. The publication of a "considered harmful" essay has a strong tendency to alienate neutral parties, thus weakening support for the point of view the essay puts forth. A sufficiently dogmatic "considered harmful" essay can end a debate in favor of the viewpoint the essay considers harmful.
</li>
<li>They've become boring cliches. Nobody really wants to read "considered harmful" essays any more, because we've seen them a thousand times before and didn't really learn anything from them, since we were too busy being annoyed to really listen to the arguments presented. </li>
</ol>
</blockquote>
<p>If you have a point to make, by all means, <a href="http://www.codinghorror.com/blog/archives/000906.html">write a great persuasive essay</a>. If you want to maximize the effectiveness of your criticisms, however, you'll leave "considered harmful" out of your writing. The "considered harmful" technique may have worked for Wirth and Dijkstra, but unless you're planning to become a world famous computer scientist like those guys, I'd suggest leaving it back in 1968 where it belongs.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/id-consider-that-harmful-too/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How To Achieve Ultimate Blog Success In One Easy Step ]]></title>
<link>https://blog.codinghorror.com/how-to-achieve-ultimate-blog-success-in-one-easy-step/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><a href="http://web.archive.org/web/20070715113357/http://www.knowing.net/PermaLink,guid,e5aadb98-0a69-44e3-94cb-0afa583b0c0e.aspx">Always Be Jabbing</a>. <a href="http://www.codinghorror.com/blog/archives/000809.html">Always Be Shipping</a>. <a href="http://www.joelonsoftware.com/articles/fog0000000339.html">Always Be Firing</a>. It's the same advice, stated in different ways for different audiences.</p>
<blockquote>My theory is that lead generation derives from Google rank and that the best way to increase Google rank is to be like a professional fighter: neither jabs nor haymakers are enough. <strong>You must be always jabbing and you must regularly throw haymakers</strong>. Blog continuously to keep your hit-rate and link-traffic high and write longer pieces, containing the high-value words associated with your niche, occasionally.</blockquote>
<p>When people ask me for advice on blogging, I always respond with yet another form of the same advice: <strong>pick a schedule you can live with, and <em>stick to it</em>. Until you do that, none of the other advice I could give you will matter.</strong> I don't care if you <a href="http://www.codinghorror.com/blog/archives/000516.html">suck at writing</a>. I don't care if <a href="http://www.codinghorror.com/blog/archives/000536.html">nobody reads your blog</a>. I don't care if you have <a href="http://www.codinghorror.com/blog/archives/000297.html">nothing interesting to say</a>. If you can demonstrate a willingness to write, and a desire to keep continually improving your writing, you will eventually be successful.</p>
<p><img alt="image placeholder" >
<p>But success takes time – a <em>lot</em> of time. I'd say a year at minimum. That's the element that weeds out so many impatient people. I wrote this blog for a year in utter obscurity, but I kept at it because I enjoyed it. I made a commitment to myself, under the banner of personal development, and I planned to meet that goal. My schedule was six posts per week, and <strong>I kept jabbing, kept shipping, kept firing</strong>. Not every post was that great, but I invested a reasonable effort in each one. Every time I wrote, I got a little better at writing. Every time I wrote, I learned a little more about the topic, how to research topics effectively, where the best sources of information were. Every time I wrote, I was slightly more plugged in to the rich software development community all around me. Every time I wrote, I'd get a morsel of feedback or comments that I kept rolling up into future posts. Every time I wrote, I tried to write something just the <em>tiniest bit</em> better than I did last time.</p>
<p>The changes, to me, were almost imperceptible. But from a very modest start – a 2004 new year's resolution for professional development – I'd say writing this blog is now, without a doubt, <em>the most important thing I've ever done in my entire career</em>.</p>
<p>I won't say I got <a href="http://www.codinghorror.com/blog/archives/000979.html">my job here at Vertigo</a> back <a href="http://www.codinghorror.com/blog/archives/000280.html">in 2005</a> because of this blog, but it was definitely a factor. I was <a href="http://www.codinghorror.com/blog/archives/000847.html">interviewed on .NET rocks</a>, and I've been interviewed online not <a href="http://www.dailyblogtips.com/interview-with-jeff-atwood-from-coding-horror/">once</a> but <a href="http://scribesonic.com/Blog/Archive/2007/10/04/Coding-Horror-Interview.aspx">twice</a>. I've been invited to speak at conferences. I am approached for <a href="http://www.codinghorror.com/blog/archives/000971.html">book deals</a> every few months. I exchange email regularly with Steve McConnell, one of my programming idols as a young adult, and he once asked <em>me</em> for advice on blogging. Joel Spolsky actually <em>recognized me</em> and invited conversation when I attended the Emeryville leg of his world tour. Charles Petzold sent me, completely unprompted, <a href="http://www.codinghorror.com/blog/archives/000934.html">a signed copy of his latest book</a>. People offer to send me <a href="http://www.codinghorror.com/blog/archives/000959.html">incredibly cool free swag</a> on a regular basis.</p>
<p>As near as I can tell, between RSS stats and log stats, <strong>around 100,000 people read this blog every day</strong>. Ad revenues that I've only <a href="http://www.codinghorror.com/blog/archives/000893.html">reluctantly taken</a> are significant enough now that I've actually entertained the idea, in my weaker moments, of becoming a full-time blogger. <em>That</em> is how crazy it's gotten. I would never have predicted this outcome in a million years, and writing it all down like this actually freaks me out a little bit.</p>
<p>I mention these things not because I'm a big fat showoff (or at least that's not the <em>only</em> reason), but because I achieved all this <a href="http://www.codinghorror.com/blog/archives/000187.html">without being particularly talented</a>. It was done one small post at a time, with no real planning or strategy whatsoever, beyond the simple incremental <a href="http://www.codinghorror.com/blog/archives/000530.html">suck less every year</a> kind. I am continually amazed and completely humbled by the success of this blog. All it took was a basic commitment to <em>keep</em> jabbing, <em>keep</em> shipping, <em>keep</em> firing.</p>
<p>If anything, what I've learned is this: <strong>if I can achieve this kind of success with my blog, so can you</strong>. So if you're wondering why the first thing I ask you when I meet you is "do you have a blog?" or "why don't you post to your blog more regularly?", or "could you turn that into a blog post?", now you know why. It's not just because I'm that annoying blog guy; it's because I'd like to wish the kind of amazing success I've had on everyone I meet.</p>
<p><a href="http://comics.com/pearls_before_swine/2008-11-16/"><img alt="image placeholder" >
<p>I'm just trying to share <strong>my easy one step plan to achieve Ultimate Blog Success</strong>: find a posting schedule you can live with, and stick to it for a year. Probably several years. Okay, so maybe that one step is really not quite so easy as I made it out to be. But everyone has to start somewhere, and the sooner the better.</p>
<p>So when was the last time <em>you</em> wrote a blog post?</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-achieve-ultimate-blog-success-in-one-easy-step/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Your Desktop Is Not a Destination ]]></title>
<link>https://blog.codinghorror.com/your-desktop-is-not-a-destination/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm of two minds on the desktop.
</p>
<p>
If you're really <i>using</i> your computer, <b>your desktop should almost never be visible</b>. Your screen should be covered with information, with whatever data you're working on. I can't imagine why you'd willingly stare at a static background image-- or even a background image covered with a <a href="http://www.codinghorror.com/blog/archives/000612.html">sea of icons</a>. Unless you consider your computer a really expensive digital picture frame, I suppose.
</p>
<p>
The desktop background, as I see it, is completely superfluous. My desktop "background" right now is plain black. And that doesn't bother me in the least, because none of it is visible. I have browser windows and programs-- the things I'm actually <i>doing</i> -- covering all three monitors. When I'm using a computer, <b>I make it my goal to never see the desktop background</b>. Every time the desktop background is visible, that means I'm making poor use of my monitor pixels. Whenever the desktop background peeks through, I treat it like a reprimand.
</p>
<p>
I won't lie to you. I don't always achieve my goal. The desktop is sometimes visible when I'm working. But I do try my darndest to cover all my monitors with something useful, and a static desktop background just isn't <i>useful</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
That said, <b>it is fun to have a unique desktop background.</b> Even if you rarely see it. In the above official screenshots from Apple and Canonical, the  desktop background images were picked quite intentionally. I've done this myself; when I put together <a href="http://www.codinghorror.com/blog/archives/000959.html">those pictures of the monitor arms</a>, I specifically chose <a href="http://interfacelift.com/wallpaper/details.php?id=1355">an interesting desktop background</a> to show it off.
</p>
<p>
<a href="http://www.codinghorror.com/blog/archives/000959.html"><img alt="image placeholder" >
</a>
</p>
<p>
Sometimes you just want to show off, even if it's only for yourself. When I graduated to my first triple monitor configuration, back in 2004, I used <a href="http://desktopgaming.com/display.php?file_id=225">this 3200 x 1200 image of the entire first level of Super Mario brothers</a> as my desktop background.
</p>
<p>
But I felt very, very dirty afterwards. I worry that if we spend too much time obsessing over our desktop backgrounds, we'll start <a href="http://www.codinghorror.com/blog/archives/000186.html">treating our computers like fashion accessories instead of tools</a>. We should be filling our screens with <i>information</i>, not distracting ourselves with pretty frippery.
</p>
<p>
However, if we do it responsibly, if we keep reminding ourselves that <b>our desktop is not a destination</b>, it's OK to obsess over our desktop backgrounds a little bit. The desktop is like an aesthetically pleasing airport we must occasionally pass through before arriving at our <i>real</i> destinations: a web browser, a word processor, an IDE, a graphics editor, etcetera. You know, the places we really want to go. A good-looking airport gives every traveller a positive feeling about where they're going, so feel free to spruce it up. Just don't go so far that you become one of those weird people who hangs out in airports.
</p>
<p>
In my original research, I ran across a lot of sites with great wallpaper resources. There's a heavy emphasis on extra-wide wallpapers here, as I run triple monitor configurations at home and at work. If you, too, rock a multi-mon setup under Windows, you'll need a utility to get different background images on each monitor, or to span a single image across all your monitors. I use <a href="http://www.realtimesoft.com/ultramon/">Ultramon</a> which does this and much more; <a href="http://www.binaryfortress.com/displayfusion/">Display Fusion</a> does less, but it works for this, and it's free.
</p>
<p>
Personally, I don't care for photographs on my desktop. I prefer abstract backgrounds. This must be an unusual preference, because most desktop background websites are completely dominated by photographs. Still, I found a few sites with good abstract backgrounds, even though I had to sift through a <i>lot</i> of photographs to get to them.
</p>
<p>
</p>
<ul>
<li>
<a href="http://interfacelift.com">InterfaceLIFT</a>
</li>
<li>Flickr <a href="http://www.flickr.com/groups/wallpapers/pool/">wallpapers</a> pool, <a href="http://www.flickr.com/groups/wallpaperxchange/pool/">wallpaper exchange</a> pool, <a href="http://www.flickr.com/explore/interesting/7days/">most interesting</a> last 7 days
</li>
<li>
<a href="http://www.mandolux.com/">Mandolux</a>
</li>
<li>
<a href="http://digitalblasphemy.com/dbhome.shtml">Digital Blasphemy</a>
</li>
<li>
<a href="http://images.google.com/images?svnum=10&amp;hl=en&amp;lr=&amp;q=eboy&amp;btnG=Search">eBoy</a>
</li>
<li>
<a href="http://www.veer.com/ideas/wallpaper/">Veer</a>
</li>
<li>
<a href="http://pic.templetons.com/brad/pano/index.html">Panoramic Photography by Brad Templeton</a>
</li>
<li>
<a href="http://memory.loc.gov/ammem/collections/panoramic_photo/">Library of Congress Panoramic Photographs</a>
</li>
<li>
<a href="http://www.gamewallpapers.com/dual-screen%20wallpapers.php">Game Wallpapers</a> new school, dual-screen
</li>
<li>
<a href="http://desktopgaming.com/browse.php">Desktop Gaming</a> old school
</li>
<li>
<a href="http://search.deviantart.com/?search=in:customization/wallpaper/multidisplay">Deviant Art</a> multi-display
</li>
<li>
<a href="http://squidfingers.com/patterns/1/">SquidFingers</a> repeating patterns
</li>
<li>
<a href="http://citrusmoon.typepad.com/patterns/">Citrus Moon</a> repeating patterns
</li>
<li>
<a href="http://www.k10k.net/pixelpatterns/">k10k</a> pixel patterns
</li>
<li>
<a href="http://www.theinspirationgallery.com/wallpaper/damask/wp_damask01.htm">Damask wallpaper patterns</a>
</li>
<li>
<a href="http://www.dualmonitorbackgrounds.com/">Dual</a>, <a href="http://www.triplemonitorbackgrounds.com/">Triple</a>, <a href="http://www.quadmonitorbackgrounds.com/">Quad</a> monitor backgrounds
</li>
<li>
<a href="http://vladstudio.com/wallpaper/?545">Vlad Studios</a>
</li>
<li>
<a href="http://www.pixeldecor.com/patterns.shtml">Pixeldecor</a> repeating patterns
</li>
</ul>
<p>
For abstract backgrounds, I had the best luck with <b>Flickr</b> and <b>InterfaceLIFT</b>.
</p>
<p>
If you spend the next hour searching for the perfect desktop background, don't blame me. I tried to warn you. I'm hoping you don't see that special desktop background of yours <i>too</i> often.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-28T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/your-desktop-is-not-a-destination/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Embracing Languages Inside Languages ]]></title>
<link>https://blog.codinghorror.com/embracing-languages-inside-languages/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Martin Fowler <a href="http://www.martinfowler.com/bliki/FluentInterface.html">loosely defines a fluent interface</a> thusly: "The more the use of the API has that language like flow, the more fluent it is." If you detect a whiff of skepticism here, you're right: I've never seen this work. <a href="http://www.codinghorror.com/blog/archives/000672.html">Computer languages aren't human languages</a>.
</p>
<p>
</p>
<p>
Let's look at a concrete example <a href="http://flimflan.com/blog/ReadableRegularExpressions.aspx">from Joshua Flanagan</a>. Here's how we define a regular expression in the standard way:
</p>
<p>
</p>
<pre>
&lt;divs*class="game"s*id="(?&lt;gameID&gt;d+)-game"(?&lt;content&gt;.*?)
&lt;!--gameStatuss*=s*(?&lt;gameState&gt;d+)--&gt;
</pre>
<p>
Here's how we'd define that same regular expression in Joshua's fluent interface.
</p>
<p>
</p>
<pre>
Pattern findGamesPattern = Pattern.With.Literal(@"&lt;div")
.WhiteSpace.Repeat.ZeroOrMore
.Literal(@"class=""game""").WhiteSpace.Repeat.ZeroOrMore.Literal(@"id=""")
.NamedGroup("gameId", Pattern.With.Digit.Repeat.OneOrMore)
.Literal(@"-game""")
.NamedGroup("content", Pattern.With.Anything.Repeat.Lazy.ZeroOrMore)
.Literal(@"&lt;!--gameStatus")
.WhiteSpace.Repeat.ZeroOrMore.Literal("=").WhiteSpace.Repeat.ZeroOrMore
.NamedGroup("gameState", Pattern.With.Digit.Repeat.OneOrMore)
.Literal("--&gt;");
</pre>
<p>
So <b>we're replacing a nice, succinct one line regular expression with ten lines of objects, methods, and named enumerations.</b> This is progress?
</p>
<p>
I'll grant you that I am probably unusually familiar with regular expressions, even by developer standards. There's a reason they have a reputation for being dense and inscrutable. I've definitely <a href="http://www.codinghorror.com/blog/archives/000214.html">seen some incredibly bad regular expressions</a> in my day. But in my professional opinion, that regex was a well written one. I had no problem reading it. Adding a ton of hyper-dense object wrappers to that regex makes it <i>harder</i> for me to understand what it does.
</p>
<p>
The new syntax Joshua invented is great, but it's specific to his implementation. Although it may seem like a good idea to use these kinds of training wheels to "learn" regular expressions, I'd argue that you aren't learning them at all. And that's a shame, because regular expression syntax is a mini-language of its own. Once you learn it, you can use it anywhere; it works (<a href="http://www.regular-expressions.info/refext.html">almost</a>) the same in every environment.
</p>
<p>
The <a href="http://www.subsonicproject.com">Subsonic project</a> attempts to do something similar for SQL. Consider this SQL query:
</p>
<p>
</p>
<pre>
SELECT * from Customers WHERE Country = "USA"
ORDER BY CompanyName
</pre>
<p>
Here's how we would express that same SQL query in SubSonic's fluent interface:
</p>
<p>
</p>
<pre>
CustomerCollection c = new CustomerCollection();
c.Where(Customer.Columns.Country, "USA");
c.OrderByAsc(Customer.Columns.CompanyName);
c.Load();
</pre>
<p>
I've mentioned before that <a href="http://www.codinghorror.com/blog/archives/000617.html">I'm no fan of object-oriented rendering</a> when a simple string will suffice. That's exactly the reaction I had here; why in the world would I want to use four lines of code instead of one? This seems like a particularly egregious example. <b>The SQL is harder to write and more difficult to understand when it's wrapped in all that proprietary SubSonic object noise.</b> Furthermore, if you don't learn the underlying SQL-- and how databases work-- you're in serious trouble as a software developer.
</p>
<p>
But I can see the rationale behind these types of database code generation tools:
</p>
<p>
</p>
<ol>
<li>They "solve" <a href="http://www.codinghorror.com/blog/archives/000621.html">the object-relational mapping problem</a> for you (and if you believe that, I have a bridge you might be interested in)
</li>
<li>you get intellisense
</li>
<li>your database is strongly typed
</li>
<li>the compiler now "understands" the database, or at least the generated classes that represent the database.
</li>
</ol>
<p>
I definitely sympathize with the desire to produce less code, and that's the whole point of database code generation tools. Personally, I would argue that most of these benefits could be realized with smarter IDEs that actually understood native SQL strings (or regular expressions), rather than relying on a slew of generated code and complicated, proprietary object syntax.
</p>
<p>
But let's take a step back and think about what's <i>really</i> happening here. In both cases, <b>we are embedding one language inside another</b>. SQL is a language. Regular expressions are a language. Wrapping those languages inside a bunch of mega-verbose fluent interface ObjectJunk-- just so we can pretend we're writing code in our primary language-- is a <i>total cop-out</i>. Fluent interface object wrappers feel like a nasty hack to me.
</p>
<p>
Why can't we embrace the language-inside-a-language paradigm, rather than running and hiding from it? These domain specific languages exist because they are optimized for processing strings and data efficiently. Avoiding them is counterproductive.
</p>
<p>
Perhaps the ultimate solution is to <b>redefine the underlying language to incorporate the features of another language</b>.
</p>
<p>
Consider how Perl integrates the regular expression language:
</p>
<p>
</p>
<pre>
while (my $line = &lt;IN&gt;) {
while ( $line =~ /(Romeo|Juliet|Mercutio|Tybalt|Friar w+)/g ) {
my $character = $1;
++$counts{ $character };
}
}
</pre>
<p>
Here's how C# 3.0, with <a href="http://en.wikipedia.org/wiki/Language_Integrated_Query">LINQ</a>, integrates the SQL language:
</p>
<p>
</p>
<pre>
var c = from Customer in Customers
where Customer.Country == "USA"
orderby Customer.CompanyName
select Customer;
</pre>
<p>
Note the conspicuous lack of ObjectJunk. No explosion at the parens and periods factory. No MassivelyLongTextEnumerations to deal with. There's nothing but code that <i>looks like exactly what it does</i>. And that's a beautiful thing. </p>
<p>
<b>Embrace the idea of languages inside languages</b>. In The Land of Strings, we speak regular expressions. In The Land of Data, we speak SQL. Oh sure, you can pretend those languages don't exist, and hide out in the <a href="http://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html">Kingdom of Nouns</a>-- but you're only cheating yourself out of a deeper understanding of how things <i>really</i> work in those other places. Fluent interface object wrappers may seem like a helpful convenience, but they're actually an ugly hack, and a terrible substitute for true language integration.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-30T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/embracing-languages-inside-languages/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The F5 Key Is Not a Build Process ]]></title>
<link>https://blog.codinghorror.com/the-f5-key-is-not-a-build-process/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Hacknot's <a href="http://web.archive.org/web/20071013071537/http:/www.hacknot.info/hacknot/action/showEntry?eid=97">If They Come, How Will They Build It?</a> is a harrowing series of 29 emails sent over a two week period.
</p>
<blockquote>
<strong>To: Mike Cooper</strong><br>
<strong>From: Ed Johnson</strong><br>
<p>
Mike,
</p>
<p>
I finally got CVS access today from Arnold. So I've checked out the AccountView module OK, but it won't compile. The Eclipse project has dependencies on about five other projects. I tried checking those dependent projects out as well, but a few of them won't build at all? How are you managing to develop this thing when the dependent projects don't build?
</p>
<p>
Ed
</p>
<p>
<strong>From: Mike Cooper</strong>
<strong>To: Ed Johnson</strong></p>
<p>
Oh yeah - I forgot to tell you about the dependent projects. I always forget about them. I'm not so surprised some of them don't build for you. I've got versions on my machine that build OK but I haven't checked them in for a while. Gimme about 15 minutes and I'll check them in, then you should be right to go.
</p>
<p>
M.
</p>
</blockquote>
<p>
It's a cautionary tale about a serious software project pathology: the pain of getting a new developer up and running on an existing software project. It's startlingly common.
</p>
<p>
This points us to one of the most important health metrics on a software development project. <strong>How long does it take for you to get a new team member working productively on your project?</strong> If the answer is more than one day, <em>you have a problem</em>. Specifically, you don't have a proper build process in place.
</p>
<p>
I've talked before about <a href="http://www.codinghorror.com/blog/archives/000713.html">the importance of a build server as the heartbeat for your project</a>. A sane software development project has automatic daily builds, performed on a neutral build server. If your team is in the habit of producing those kind of daily builds, it's difficult to accumulate the <a href="http://blogs.construx.com/blogs/stevemcc/archive/2007/11/01/technical-debt-2.aspx">deep technical debt</a> enumerated in <a href="http://web.archive.org/web/20071013071537/http:/www.hacknot.info/hacknot/action/showEntry?eid=97">all those emails</a>. If the build server can do it, so can your newly hired coworkers.
</p>
<p>
But based on the development practices I've often seen on site with customers, I think setting up a build server might be an unrealistic goal, at least initially. It might not get done. We should shoot for a more modest goal to start with.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's how most clients I work with build a project:
</p>
<ol>
<li>Open the IDE
</li>
<li>Load the solution
</li>
<li>Get latest
</li>
<li>Press F5 (or CTRL+SHIFT+B)
</li>
</ol>
<p>
<strong>If your "build process" is the F5 key, <em>you have a problem</em>.</strong> If you think this sounds ridiculous-- <em>who would possibly use their IDE as a substitute for a proper build process?</em> -- then I humbly suggest that you haven't worked much in the mainstream corporate development world. The very idea of a build script outside the IDE is alien to most of these teams.
</p>
<p>
<strong>Get your build process out of the IDE and into a build script</strong>. That's the first step on the road to build enlightenment.
</p>
<p>
The value of a build script is manifold. Once you have a build script together, you've <strong>created a form of living documentation</strong>: here's how you build this crazy thing. And naturally this artifact is checked into source control, right alongside the files necessary to build it (and <a href="http://www.codinghorror.com/blog/archives/000743.html">even the database necessary to run it</a>, too). From there, you can begin to think about having that script run on a neutral build server to avoid the <a href="http://www.codinghorror.com/blog/archives/000818.html">"Works On My Machine" syndrome</a>. You can also consider all the nifty ways you could enhance the script with stuff like <a href="http://blogs.msdn.com/steverowe/archive/2007/10/25/testing-a-daily-build.aspx">BATs, BVTs, and Functional Tests</a>. Your build server can become <a href="http://www.codinghorror.com/blog/archives/000713.html">the heartbeat of your project</a>. There's no upper limit on how clever you can be, and how many different build scripts you can come up with. Build scripts can be incredibly powerful-- but you'll never know until you start using them.
</p>
<p>
<strong>The F5 key is not a build process</strong>. It's a quick and dirty substitute. If that's how you build your software, I regret that I have to be the one to tell you this, but <em>your project is not based on solid software engineering practices</em>.
</p>
<p>
So, if you don't have a build script on your project, what are you waiting for?
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-10-31T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-f5-key-is-not-a-build-process/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Not All LCD Panels Are Created Equal ]]></title>
<link>https://blog.codinghorror.com/not-all-lcd-panels-are-created-equal/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
</p>
<p>
When I <a href="http://www.codinghorror.com/blog/archives/000744.html">purchased my last set of LCD monitors</a>, I didn't fully understand that <strong>
not all LCD panels are created equal</strong>. There are three distinct families of LCD display technology, each with their own tradeoffs and peculiarities. Before you buy a new LCD display,
you should take note of <a href="http://www.pchardwarehelp.com/guides/lcd-panel-types.php">
what kind of panel technology</a> you're investing in.</p>
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td>
</td>
<td>
<strong>
Color Reproduction</strong>
</td>
<td>
<strong>
Viewing Angle</strong>
</td>
<td>
<strong>Response Time</strong>
</td>
<td>
<strong>
Price</strong>
</td>
<td>
<strong>
Quirks</strong>
</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/TFT_LCD#IPS">*-IPS</a><br>
In Plane Switching</td>
<td valign="top">
Excellent</td>
<td valign="top">
Excellent</td>
<td valign="top">
Good</td>
<td valign="top">
Expensive</td>
<td valign="top">
Slight color tinges may be visible at an angle.</td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/TFT_LCD#MVA">*VA</a><br>
Vertical Alignment</td>
<td valign="top">
Good</td>
<td valign="top">
Good</td>
<td valign="top">
Average</td>
<td valign="top">
Reasonable</td>
<td valign="top">
Colors shift when viewed at an angle. </td>
</tr>
<tr>
<td valign="top">
<a href="http://en.wikipedia.org/wiki/TFT_LCD#TN_.2B_film">TN</a><br>
Twisted Nematic</td>
<td valign="top">
Average</td>
<td valign="top">
Average</td>
<td valign="top">
Excellent</td>
<td valign="top">
Inexpensive</td>
<td valign="top">
Limited to 6-bit color; restricted vertical viewing angles.</td>
</tr>
</table>
<p>
<strong>Most panels these days are TN</strong>, which isn't much of a surprise;
if a consumer has the choice between a 22" or 24" display at the same price, they're
naturally going to go with the larger one. Although TN displays can be quite good,
they all suffer to some degree from the genetic defects of their TN family
lineage.
</p>
<p>
Right now, one of my monitors is PVA, and the other two are TN. The color
reproduction is slightly more pleasing on the PVA monitor, but the TN is in the
ballpark. I'm only able to tell because the monitors are literally right next to each other. What I <i>do</i> notice in regular use on my TN displays, however, is their <strong>
incredibly limited vertical view angle</strong>. I'm <a href="http://www.codinghorror.com/blog/archives/000849.html">
no graphics designer</a>, but even I can see that colors vary quite noticeably
in intensity from top-to-bottom on my TN display. You have to keep your head perfectly
aligned in the tiny "sweet spot" to see consistent vertical color on these displays.
Horizontally, it's fine, but vertically, it is far too sensitive.</p>
<p>
Unfortunately, the vast majority of LCDs on the market now are TN. You can opt to pay a little bit more for one of the few models with *VA -- if there are any available
in the size you want. *-IPS is widely considered the best all around LCD display
technology, but it is rapidly being pushed into the vertical "pro" graphics designer
market due to the big jump in price. It's usually not an option, unless you're willing
to pay more than twice as much for a monitor.</p>
<p>
But even within the TN and *VA families, there are new improvements and variants being introduced
all the time. For example, LED backlighting, which is just now catching on for laptops, should
eventually trickle down to the humble TN display. That one upgrade will allow it to reproduce all 100% of the NTSC color gamut for the first time.
There's a <a href="http://lcdresource.com/tools/matrix-of-all-matrices.htm">more detailed
chart at LCD Resource</a> that illustrates
how the various LCD display technologies have evolved over time. I've adapted it here in simple HTML: </p>
<table border="0" cellpadding="5" cellspacing="0" width="700">
<tr>
<td width="50"></td>
<td style="text-align: center" valign="bottom" width="50">Bright</td>
<td style="text-align: center" valign="bottom" width="50">Black Level</td>
<td style="text-align: center" valign="bottom" width="50">Resp Time</td>
<td style="text-align: center" valign="bottom" width="50">Color<br>Depth</td>
<td style="text-align: center" valign="bottom" width="50">Gamma</td>
<td style="text-align: center" valign="bottom" width="50">
Sat</td>
<td style="text-align: center" valign="bottom" width="50">View Angle (H)</td>
<td style="text-align: center" valign="bottom" width="50">View Angle (V)</td>
<td style="text-align: center" valign="bottom" width="50">Input Lag</td>
<td style="text-align: center" valign="bottom" width="50">Cost</td>
</tr>
<tr>
<td style="text-align: right" valign="middle">TN</td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">20/22" TN</td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">P-MVA</td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">20"+ P-MVA</td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">PVA</td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">20"+ PVA</td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">S-PVA</td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">S-IPS</td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">20" S-IPS</td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#c5be97;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">AS-IPS</td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
</tr>
<tr>
<td style="text-align: right" valign="middle">A-TW-IPS</td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#4f6228;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#75923c;  border-bottom: #ddd 1px solid"> </td>
<td style="background-color:#953735;  border-bottom: #ddd 1px solid"> </td>
</tr>
</table>
<p></p>
<p>
Don't get discouraged, though. Modern, inexpensive TN based LCDs can still perform
quite well, as you can see in <a href="http://www.xbitlabs.com/articles/other/display/24inch_16.html#sect0">
this review of the Samsung 245BW</a>. The main downside is-- you guessed it-- the severely limited vertical viewing angles.</p>
<p>
The next time you set out to buy a LCD, <b>be informed about the underlying display
technology you're getting</b>. If you're in the market, I recommend paging through the
<a href="http://www.xbitlabs.com/articles/other/display/lcd-guide-f2007.html">excellent
LCD Monitor Buying guide</a> at X-bit Labs, which covers that crucial aspect, and much more.</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-01T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/not-all-lcd-panels-are-created-equal/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Click Here: The Art of Hyperlinking ]]></title>
<link>https://blog.codinghorror.com/dont-click-here-the-art-of-hyperlinking/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I've often thought there is <strong>a subtle art to the humble hyperlink</strong>, that stalwart building block of hypertext, the stuff that <a href="http://www.wired.com/wired/archive/3.06/xanadu_pr.html">Ted Nelson's Xanadu dream</a> was made of.</p>
<blockquote>The word hypertext was coined by Nelson and published in a paper delivered to a national conference of the Association for Computing Machinery in 1965. Adding to his design for a nonsequential writing tool, Nelson proposed a feature called "zippered lists," in which elements in one text would be linked to related or identical elements in other texts. Nelson's two interests, screen editing and nonsequential writing, were merging. With zippered lists, links could be made between large sections, small sections, whole pages, or single paragraphs. The writer and reader could manufacture a unique document by following a set of links between discrete documents that were "zipped" together.
<p>Many precedents for the idea of hypertext existed in literature and science. <a href="http://en.wikipedia.org/wiki/Talmud">The Talmud</a>, for instance, is a sort of hypertext, with blocks of commentary arranged in concentric rectangles around the page. So are scholarly footnotes, with their numbered links between the main body of the text and supplementary scholarship.</p>
<p>In July 1945, long before Nelson turned his attention to electronic information systems, Vannevar Bush published <a href="http://en.wikipedia.org/wiki/As_We_May_Think">an essay titled "As We May Think"</a> in The Atlantic Monthly, which described a hypothetical system of information storage and retrieval called "memex." Memex would allow readers to create personal indexes to documents, and to link passages from different documents together with special markers. While Bush's description was purely speculative, he gave a brilliant and influential preview of some of the features Nelson would attempt to realize in <a href="http://en.wikipedia.org/wiki/Project_Xanadu">Xanadu</a>.</p>
<p>The inventor's original hypertext design predicted most of the essential components of today's hypertext systems. Nonetheless, his talk to the Association for Computing Machinery had little impact. There was a brief burst of interest in this strange researcher, but although his ideas were intriguing, Nelson lacked the technical knowledge to prove that it was possible to build the system he envisioned.</p>
</blockquote>
<p>I distinctly remember reading <a href="http://www.wired.com/wired/archive/3.06/xanadu_pr.html">this 1995 Wired article on Ted Nelson and Xanadu</a> when it was published. It had a profound impact on me. I've always remembered it, long after that initial read. I know it's novella long, but it's arguably the best single article I've ever read in Wired; I encourage you to read it in its entirety when you have time. It speaks volumes about the souls of computers – and the software developers <a href="http://www.codinghorror.com/blog/archives/000761.html">who love them</a>.</p>
<p>Xanadu was vaporware long before the term even existed. You might think that Ted Nelson would be pleased that HTML and the world wide web have delivered much of the Xanadu dream, almost 40 years later. But you'd be wrong:</p>
<blockquote>HTML is precisely what we were trying to <em>prevent</em> – ever-breaking links, links going outward only, quotes you can't follow to their origins, no version management, no rights management.</blockquote>
<p>I suspect Wikipedia may be closer to Ted's vision of Xanadu: a self-contained constellation of highly interlinked information, with provisions for identity, versioning, and rights management.</p>
<p>But enough about the history of the hyperlink. How can we use them effectively in the here and now? I thoroughly enjoyed Philipp Lenssen's recent <a href="http://blogoscoped.com/archive/2007-10-24-n27.html">link usability tips</a>. I liked it so much, in fact, that I'm using it as a template for a visual compendium of link usability tips – the art of hyperlinking.</p>
<ol>
<li>
<strong>Ensure your links are large enough to easily click.</strong> When building links, don't run afoul of <a href="http://www.codinghorror.com/blog/archives/000642.html">Fitt's Law</a>. If what you're linking is small, make it bigger. If you can't make it bigger, at least fluff it up a bit with clickable borders so it's easier for people to accurately click. In the below screenshot, <em>only</em> the numbers are linked, which is a shame.
<p><img alt="image placeholder" >
</li>
<li>
<strong>The first link is the most important one.</strong> The first link will garner most of the reader's attention, and the highest clickthrough rates. Choose your first link appropriately. Start with the important stuff. Don't squander your first link on a triviality.
<p><img alt="image placeholder" >
</li>
<li>
<strong>Don't link everything.</strong> Using too many links will turn your text into noise. This works in two dimensions: excessive linking makes text difficult to read, and excessive linking causes deflation in the value of all your existing links. Link in moderation. Only link things important enough to warrant a link.
<p><a href="http://studentaffairs.case.edu/support/web/webstyle/linking.html"><img alt="image placeholder" >
</li>
<li>
<strong>Don't radically alter link behavior.</strong> Links are the cornerstone of the web. Users have built up years of expectactions based on existing behavior in their web browsers. When you change the way hyperlinks work, you're redefining a fundamental part of the web. Is this really what you want? Is this really what your <em>readers</em> want?
<p><img alt="image placeholder" >
</li>
<li>
<strong>Don't title your link "Click Here".</strong> Don't even use the words "Click" or "Here" anywhere in your link text. Describe what the link will <em>do</em> for the user when they click on it.
<p><img alt="image placeholder" >
</li>
<li>
<strong>Don't link things the user might want to select and copy.</strong> Woe upon the poor user who needs to select and copy hyperlinked text. It requires a complex ballet of very precise mouse movements to get it to work at all. Here, I'm trying to select the name "Ralph Waldo Emerson", which is part of the hyperlink. Granted, this is not a terribly common scenario – it's probably the most subtle tip on Philipp's list. But when it happens, it's awkward and unpleasant, so do give it some consideration.
<p><img alt="image placeholder" >
</li>
<li>
<strong>Don't include icons on every link.</strong> If we're linking in moderation, we should be using link icons in <em>extreme</em> moderation. If every other link has an icon, it's noise. Only highly unusual or irregular links should include icons. I'd also argue that your text, if written properly, can easily communicate the type of link as well as an icon can, but this gets into the realm of personal preference.
<p><a href="http://www.askthecssguy.com/2006/12/showing_hyperlink_cues_with_cs_1.html"><img alt="image placeholder" >
</li>
<li>
<strong>Don't make your content depend on links to work.</strong> Not everyone will click on your hyperlinks. Either they're too busy to click every single link you put in front of them, or maybe they're reading your article in another format where they can't click on the links: print, offline, or mobile. Either way, it's important to provide the context necessary to make your content understandable <em>without</em> the need to visit whatever is behind those hyperlinks. (If you're wondering what this example is about, I should warn you – it's not worth it. For once the inanity of Digg comments was totally appropriate: <em>"retarded blog war"</em>.)
<p><a href="http://www.ryanholiday.net/archives/violentacres_makes_the_world_a.phtml"><img alt="image placeholder" >
</li>
<li>
<strong>Don't hide your links.</strong> Hyperlinks should look like hyperlinks. Give them a distinct style, so they cannot be confused with any of the other text on the page. Definitely choose a unique color not used anywhere else on your page, and consider using the well-worn convention of the link underline when necessary. What's clickable here?
<p><img alt="image placeholder" >
</li>
<li>
<strong>Don't mix advertising and links.</strong> These look like hyperlinks, but they're actually advertising. Which type of link is which, again? And why should the user have to think about this?
<p><img alt="image placeholder" >
</li>
<li>
<strong>Don't obfuscate your URLs.</strong> Users can preview where your link will ultimately send them by hovering their mouse over it and viewing the URL in the status bar. Avoid using redirects or URL shortening services which make the URL totally opaque. The user shouldn't have to take a leap of faith when clicking on your links.
<p><a href="http://graysmatter.codivation.com/ThePragmaticProgrammerTheBestWayToPadYourBlogContentFor30Dollars.aspx"><img alt="image placeholder" >
</li>
</ol>
<p>To head off any potential hate mail headed my way, these are guidelines, not rules. If you know what you're doing, you also know that rules were made to be broken in the right circumstances. The problem is that most people writing HTML <em>don't</em> know what they're doing. A <a href="http://www.google.com/search?as_q=&amp;hl=en&amp;num=10&amp;btnG=Google+Search&amp;as_epq=click+here&amp;as_oq=&amp;as_eq=&amp;lr=&amp;as_ft=i&amp;as_filetype=&amp;as_qdr=all&amp;as_nlo=&amp;as_nhi=&amp;as_occt=body&amp;as_dt=i&amp;as_sitesearch=&amp;as_rights=&amp;safe=images">search for "click here"</a> is ample proof of that.</p>
<p>Most of this is advice on writing HTML – which, in my estimation, is <em>basic writing advice</em> in today's online world. Hyperlinking should be taught alongside <a href="http://www.amazon.com/exec/obidos/ASIN/020530902X/codihorr-20">Strunk &amp; White</a> as far as I'm concerned. Knowing how to hyperlink effectively is fundamental. But as software developers, we can go farther when writing <em>code</em> – we can control the text of the links we generate, too. I touched on this briefly in <a href="http://www.codinghorror.com/blog/archives/000093.html">Don't Devalue The Address Bar</a>, but it's worthy of an entire blog post. In the meantime, Keyvan Nayyeri's <a href="http://keyvan.io/simplify-your-urls">Simplify your URLs</a> is a fantastic starting point.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-click-here-the-art-of-hyperlinking/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Who Wrote This Crap? ]]></title>
<link>https://blog.codinghorror.com/who-wrote-this-crap/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Does this sound familiar?
</p>
<p>
</p>
<blockquote>
<b><i>your program</i></b> (n): a maze of non-sequiturs littered with clever-clever tricks and irrelevant comments. Compare <i>MY PROGRAM</i>.
<p>
<b><i>my program</i></b> (n): a gem of algorithmic precision, offering the most sublime balance between compact, efficient coding on the one hand, and fully commented legibility for posterity on the other. Compare <i>YOUR PROGRAM</i>.
</p>
</blockquote>
<p>
I first read this in the original 1993 edition of <a href="http://www.amazon.com/exec/obidos/ASIN/0735619670/codihorr-20">Code Complete</a>. It's quoted from a much earlier book, Stan Kelley-Bootle's <a href="http://www.amazon.com/exec/obidos/ASIN/0070340226/codihorr-20">The Devil's Dp Dictionary</a>, which was published in 1981. It's still true, more than 25 years later. There's a knee-jerk predisposition to look at code you didn't write, and for various reasons large and small, proclaim it <i>absolute crap</i>. But figuring out who's actually <i>responsible</i> for that crappy code takes some detective work.
</p>
<p>
The upcoming Visual Studio 2008, or at least the <a href="http://msdn2.microsoft.com/en-us/teamsystem/default.aspx">Team System</a> flavor of it, finally delivers a feature I've wanted for years: <b>it can display the code side-by-side with the person who last changed that code.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The last person to change any particular line is identified right there, next to the lines they changed, along with the date and revision number. Hovering over the revision number reveals a tooltip containing any checkin comments associated with that change. Clicking on the revision number brings up the full details dialog for that checkin.
</p>
<p>
Although I have mixed feelings about source control integration with the IDE, I think this is a fairly compelling argument in favor of it. Sometimes you just want to know <b>who wrote this crap</b>, and having that information directly next to the code in your editor saves many tedious steps of manually tracking down the owner of those particular lines.
</p>
<p>
This feature is called "annotate" <a href="http://blogs.msdn.com/bharry/archive/2006/09/07/744993.aspx">in Team System</a> source control, but it's called "blame" <a href="http://svnbook.red-bean.com/en/1.0/re02.html">in Subversion</a> and <a href="http://www.ericsink.com/scm/scm_history.html">in Vault</a>. So if you're wondering who to blame, now you know. It's all those <i>other</i> developers. Obviously.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/who-wrote-this-crap/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Making Donations Easy ]]></title>
<link>https://blog.codinghorror.com/making-donations-easy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In my continuing quest for a decently full-featured graphics editor that <a href="http://www.codinghorror.com/blog/archives/000973.html">hasn't succumbed to feature bloat</a>, I recently installed <a href="http://www.getpaint.net/">Paint.NET</a> for the first time. I'lll admit that I had low expectations based on the abysmal user interfaces I've experienced in other open source projects. Imagine my surprise when Paint.NET turned out to be.. well, incredibly freaking great. Not only is the UI actually friendly, modern, and easy to use, but the whole thing is so <i>polished</i>: the installer, the website, the tutorials and forums. It's the complete package.
</p>
<p>
But enough of my gushing about how great Paint.NET is. Last year, I declared December 1st <a href="http://www.codinghorror.com/blog/archives/000735.html">"Support Your Favorite Small Software Vendor" day</a>.
</p>
<p>
</p>
<blockquote>
Check your hard drive, and I'm sure you, too, will find some bit of software written by a small software development shop, maybe even a single developer. Something you find incredibly useful. Something you rely on every day. Something you recommend without reservation to friends and peers. Something that makes using the computer that much more enjoyable. Or at least less painful.
<p>
<b>Stop reading this post <i>right now</i> and buy that software.</b> If it's not commercial software, don't let that stop you. Share the love by sending money to the person/shop/organization that created it.
</p>
<p>
This month it's MediaMonkey. Next month it might be <a href="http://bluemars.org/clipx/">ClipX</a>, or <a href="http://www.scootersoftware.com/">Beyond Compare</a>, or <a href="http://www.regexbuddy.com/cgi-bin/affref.pl?aff=jatwood">RegexBuddy</a>, or <a href="http://timesnapper.com/">TimeSnapper</a>. It's time to stop floating by on the "free" version and give something back. If I can't come up with the scratch to spend <b>a measly $20 a month supporting the very best work of my fellow independent software developers</b>, can I really call myself a <i>professional</i> software developer? Can you?
</p>
<p>
As a Windows user, I work extra hard to avoid reinforcing all these negative stereotypes. <b>I believe in the little guy writing cool Windows software.</b> And by "believe in", I mean "pay". And so should you. Whatever operating system you choose to run, try to support the little guys writing the apps <i>you</i> use. We owe it to them. And, more importantly, we owe it to ourselves.
</p>
</blockquote>
<p>
I've set a goal for myself, and I intend to stick to that goal. Whenever I encounter truly excellent software, I vote with my wallet. I pay them. Paint.NET is an open source project, though, and it can sometimes be difficult to figure out how to vote with your wallet when there's nothing to buy, and nobody to pay.
</p>
<p>
But look how easy the Paint.NET project has made it for me. The install dialog provides a gentle, unobtrusive link for me to "show my appreciation and support future development". That's <i>exactly</i> what I want to do.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The <a href="http://www.getpaint.net/donate.html">donation page</a> is similarly helpful, providing one-click PayPal donation buttons for common currency types-- along with the snail mail address if you're old school.
</p>
<p>
<a href="http://www.getpaint.net/donate.html"><img alt="image placeholder" >
</p>
<p>
This is yet another way Paint.NET demonstrates that it is a thoroughly professional open source project. It raises the quality bar, particularly in the .NET ecosystem, where open source is often a second-class citizen.
</p>
<p>
Life is easier for commercial projects-- they <i>have</i> to ask you for money. But open source projects don't -- so they often have no provision for payment of any kind. That is a mistake. If I want to vote with my wallet, <b>make it easy for me to give you my money</b>. Set up a clearly marked donation page, and pre-populate it with brainlessly simple, one click methods to donate. If you don't want my money, that's fine too. Just tell me what charity I can donate to on behalf of your project.
</p>
<p>
I think <b>it's hugely important to ask for donations on any non-commercial project</b>. Not everyone can contribute time and effort. Help us help your project. Let us vote with our wallets.
</p>
<p>
(Speaking of contributions, yes, I am still planning to <a href="http://www.codinghorror.com/blog/archives/000894.html">donate $10,000 to open-source projects in the .NET ecosystem</a>. The money is set aside and earmarked. I'm sorry it has taken so long to set up, but I promise that it <i>will</i> happen by the end of the year.)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/making-donations-easy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is It Time for 64-bit on the Desktop? ]]></title>
<link>https://blog.codinghorror.com/is-it-time-for-64-bit-on-the-desktop/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've been wary of 64-bit on the desktop, as <a href="http://www.codinghorror.com/blog/archives/000435.html">the benefits are usually outweighed by the compatibility problems</a>. I agree that 64-bit operating systems are inevitable in the big scheme of things, but I've struggled to see the relevance of 64-bit for typical desktop and laptop users. It's a novelty, albeit a necessary one for particular niche applications. However, I'm now beginning to think <b>we could see a fairly broad switch to 64-bit desktop operating systems over the next few years</b>-- much sooner than I anticipated.
</p>
<p>
Why?
</p>
<p>
</p>
<ol>
<li>
<b>64-bit versions of popular consumer desktop operating systems are commonly available</b>. Both Vista and OS X 10.5 fully support 64-bit apps out of the box, although <a href="http://arstechnica.com/reviews/os/mac-os-x-10-5.ars/6">evidently the OS X kernel is still 32-bit</a>.
<p>
</p>
</li>
<li>
<b>Memory is cheap. Dirt cheap.</b> As of this writing, you can buy 4 gigabytes of quality DDR2 memory for around $120. The memory industry has a nasty habit of switching to newer, faster, more expensive memory types over time, but it looks like this plateau might be here to stay. 4 GB of memory is no longer a rare extravagance for rich users; it's becoming commonplace, even mundane.
<p>
</p>
</li>
<li>
<b>The 32-bit x86 architecture doesn't scale very well beyond 2 gigabytes.</b> If you install 4 gigabytes of memory, you may find yourself wondering -- <a href="http://www.codinghorror.com/blog/archives/000811.html">Dude, Where's My 4 Gigabytes of RAM?</a> Good luck explaining to the average user why their computer says they only have 3 GB of memory, even though they <i>paid</i> for 4. It's a tough sell. And honestly, who has time to listen to a bunch of arcane technical explanations for this bizarre limitation? People just want full use of the memory they paid for.
<p>
</p>
</li>
<li>
<b>Modern video cards do not play well with 32-bit memory limits.</b> Newer operating systems emphasize the importance of good, discrete video hardware. To get the full suite of cool desktop effects, through <a href="http://en.wikipedia.org/wiki/Windows_Aero">Aero</a>, <a href="http://www.beryl-project.org/">Beryl</a>, or <a href="http://developer.apple.com/macosx/coreimage.html">Core Image</a>, you need a decent midrange video card. I'd say the average amount of memory on a midrange video card today is 256 megabytes, and in the enthusiast class it's closer to 512 megabytes. I can easily see that doubling over the next two years. That's a massive chunk of the 32-bit address space carved out for required hardware. And if you're a hardcore gamer or multiple monitor enthusiast with more than one video card, it's worse. <a href="http://www.dansdata.com/askdan00015.htm">Much worse</a>.
</li>
</ol>
<p>
The switch to 64-bit is interesting because there's a certain air of finality to it. <b>It may be the last <a href="http://www.codinghorror.com/blog/archives/000950.html">bit transition</a> in our lifetimes.</b>
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="300">
<tr>
<td align="right">8-bit</td>
<td align="right">2<sup>8</sup>
</td>
<td align="right">256 bits
</td>
</tr>
<tr>
<td align="right">16-bit</td>
<td align="right">2<sup>16</sup>
</td>
<td align="right">64 KB
</td>
</tr>
<tr>
<td align="right">32-bit</td>
<td align="right">2<sup>32</sup>
</td>
<td align="right">4 GB
</td>
</tr>
<tr>
<td align="right">64-bit</td>
<td align="right">2<sup>64</sup>
</td>
<td align="right">2 EB</td>
</tr>
</table>
<p>
Sure, <a href="http://www.faktoider.nu/640kb_eng.html">nobody will ever need more than 640 kilobytes of memory</a>, but this is a whole new ballgame. To put the size of the 64-bit memory address space in context, here's a chart showing the respective sizes of each. Note that the scale is <i>logarithmic</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The transition from 16 to 32 bit increased our address space by a factor of 65 thousand. That's big. We've been in the 32-bit era since about 1992; that address space has been good for about thirty years, give or take a few. The transition from 32 to 64 bit, whenever we finally make it, will <b>increase our address space by a factor of <i>four billion</i></b>. Will there be a transition to 128-bit machines and operating systems? Absolutely. But I'm not sure it'll happen while we're still alive.
</p>
<p>
You certainly <b>won't be upgrading to 64-bit applications for better performance</b>. Or at least you shouldn't be, unless you enjoy disappointment. <a href="http://www.codinghorror.com/blog/archives/000435.html">64-bit offers compelling performance benefits on servers</a>, but on desktops, it's a bit of a wash. On one hand, the x86 architecture <a href="http://arstechnica.com/reviews/os/mac-os-x-10-5.ars/6">simply works better in 64-bit mode</a>:
</p>
<p>
</p>
<blockquote>
The x86 instruction set was created in the 16-bit era and has accumulated quite a bit of cruft going from 16-bit to 32-bit. Some of that cruft was wisely abandoned during <a href="http://arstechnica.com/articles/paedia/cpu/x86-64.ars">the transition from 32-bit to 64-bit</a>. <b>Applications compiled for x86_64 don't just get larger registers, they get more registers, plus a more modern calling convention and more addressing modes</b>. Every 32-bit x86 application can benefit from these changes, it's just a question of how significant that benefit will be.
</blockquote>
<p>
On the other hand, stuff is just plain <i>larger</i> in 64-bit land-- your pointers and data structures now take up twice as much room. That 2 megabytes of cache on your CPU won't be able to fit as many things in as it used to.
</p>
<p>
Once you factor in the pros and cons, you end up with a 64-bit machine that runs desktop applications a few percentage points faster than the 32-bit machine it replaced. There are some exceptions, of course-- most notably games and audio/video editing-- but on average, performance remains roughly the same for typical desktop applications. It's hard to find a definitive set of benchmarks that tell the entire 64-bit versus 32-bit performance story, but all the ones I've seen show rough parity.
</p>
<p>
I recently upgraded both my work and home machines to 4 GB of memory. Based on the positive Vista x64 experiences related by coworkers and Scott Hanselman, I took the plunge and upgraded to Vista x64. <b>It was the only way to use anything close to the full 4 GB of memory.</b> I resisted mightily, because I expected 64-bit driver and software problems, but much to my surprise, I've had none. Zero. Zilch. It's been unbelievably smooth. Perhaps it's because I waited a good six months after the initial release of Vista to move to x64, but everything "just works". All my hardware has 64-bit drivers. Many of my applications even come in x64 flavors, and the ones that don't still work flawlessly. I didn't change any of the hardware other than adding memory, but I'd <i>swear</i> my system is more responsive under x64 in daily use. And I no longer run into <a href="http://www.codinghorror.com/blog/archives/000966.html">certain aggravating 32-bit operating system limits</a>.
</p>
<p>
Of course, my original advice regarding 64-bit operating systems hasn't changed. <b>Unless you have more than 2 GB of memory, there's no reason to bother with 64-bit.</b> But have you priced memory recently? Now that 4 GB configurations are approaching mainstream, it's encouraging to know that 64-bit operating systems are out there, and that they work with a minimum of fuss. It's certainly taken long enough to tackle this problem. Hopefully we can stay with 64-bit for the forseeable future, and leave that pesky 128-bit problem for our kids to deal with.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-it-time-for-64-bit-on-the-desktop/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Sad State of Digital Software Distribution ]]></title>
<link>https://blog.codinghorror.com/the-sad-state-of-digital-software-distribution/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In this era of <a href="http://www.codinghorror.com/blog/archives/000599.html">pervasive broadband</a>, I'm constantly surprised how often I am forced to buy a physical CD or DVD to obtain the software I want. Physical distribution methods have their place, but they should be on the decline by now. Software is best distributed digitally through our high-speed internet connections-- <a href="http://www.codinghorror.com/blog/archives/000795.html">using BitTorrent</a> if necessary.
</p>
<p>
Instead, I find that download options for commercial software are quite rare. <b>Even when the download option is available, you end up paying the same price as retail or <i>even more</i></b>. Here's a typical example. I purchased <a href="http://www.amazon.com/exec/obidos/ASIN/B000WCCURW/codihorr-20">Titan Quest: Gold</a> from <a href="http://www.steampowered.com/v/index.php">Steam</a> about a month ago. I paid $29.95, which is the standard retail box price. But <a href="http://www.gogamer.com/">online discounters</a> sell boxed copies of the very same game for $22.90.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td>Digital Distribution: <font color="red">$29.95</font>
</td>
<td>Retail Copy: <font color="red">$22.90</font>
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
Selling directly to the consumer via download means bypassing the entire brick and mortar sales chain. This should result in cheaper prices than retail, not the same prices-- and it should <i>never</i> result in higher prices. Paying a premium for the privilege of downloading software is complete ripoff, and yet it happens all the time.
</p>
<p>
In this case, Valve is the distributor, so they're getting a healthy cut of the sale price (rumor says 50%). That's still a fantastic deal compared to retail software sales, where the authors will be lucky to get 10% of the sale price. But this "download is the same cost as retail" pricing strategy is <i>particularly</i> egregious when you buy the software directly from the company who created it. That's pure profit, <a href="http://www.costik.com/weblog/2007/02/economics-of-selling-games-online.html">as Greg Costikyan points out</a>:
</p>
<p>
</p>
<blockquote>
If you can retain the right to sell [your software] off your own site, do, obviously. Even if your traffic is low, <b>you keep 90% of the revenues</b>, and that's gravy.
</blockquote>
<p>
Microsoft does allow us to <a href="http://www.windowsmarketplace.com/content.aspx?ctId=390">purchase and download upgrade versions of Vista digitally</a>. But as usual, you'll be paying full retail price for the privilege. The <a href="http://www.windowsmarketplace.com/details.aspx?view=info&amp;itemid=3268636">downloadable Vista Ultimate upgrade</a> is $259.95, but you can <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16832116141">purchase the same product in a retail box</a> for $249.99.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td>Digital Distribution: <font color="red">$259.95</font>
</td>
<td>Retail Copy: <font color="red">$249.99</font>
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
I don't mean to single out Microsoft here. At least they provide the download option for Vista (but, oddly, not for Office, their other cash cow). I've also purchased games directly from EA using their <a href="http://www.ea.com/ealink/">EA Link download service</a>, and you always pay full retail price there, too. Sadly, paying full retail price to download software is a standard practice in the software industry. Oh sure, sometimes they'll throw in some cheesy extras like downloadable soundtracks and so forth -- but does that really make up for the fact that <b>you just increased their profit margin on the sale by a factor of five?</b> I don't think so. About the only "benefit" of buying game software digitally is that they'll (sometimes) let you unlock it on midnight of the street date, so you get a few bonus hours of play before everyone else.
</p>
<p>
I can understand the desire not to undercut their own distribution channel. I'm sure Best Buy wouldn't be too happy with Microsoft or EA selling software directly to consumers for less than they can on their store shelves. But do vendors assume we are completely ignorant of basic retail economics? Digital software distribution <i>should</i> cost less:
</p>
<p>
</p>
<ol>
<li>When vendors sell direct, it's <i>insanely</i> profitable (90% profit)
</li>
<li>When selling through a third-party portal, it's still extremely profitable, far more than retail sales. (50% profit)
</li>
<li>It's more efficient. There are no trucks full of boxes, manuals, jewelcases, and other atoms to be distributed across the world. Distribution costs effectively drop to zero.
</li>
<li>It's more work for consumers. There are a bunch of additional hoops you don't have with physical media, such as DRM wrappers, helper software to install, and a long download period. It shouldn't be like this. Standard Vista style online activation from an ISO image should be all that's required. But you typically get hogtied into vendor-specific downloaders and wrappers that have to be installed on your machine, such as Steam, and the EA downloader.
</li>
</ol>
<p>
Unfortunately, the state of digital software distribution is so bad right now that it's almost a parody of itself. It should be a wondrous, democratizing tool that pushes software pricing down by naturally leveraging the inherent efficiency of bits over atoms. Instead, as it exists today, <b>the digital distribution of commercial software is intentionally crippled</b>. It's only useful for the rich and impatient, a fact vendors exploit to line their pockets with obscene profit margins (even by software industry standards, which is saying a lot). The average consumer avoids digital software distribution entirely in favor of retail discounters. Can you blame them? With every download at retail prices, you're effectively paying vendors five times as much for the same software, and that's a huge ripoff.
</p>
<p>
It seems to me that, in the area of digital distribution efficiencies, commercial software still has a lot to learn from the open source world-- where everything is downloadable by design. I hope they can adapt before they're forced into extinction.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-sad-state-of-digital-software-distribution/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's in a Project Name? ]]></title>
<link>https://blog.codinghorror.com/whats-in-a-project-name/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Since I started at <a href="http://www.vertigo.com">Vertigo</a>, here are a few of the projects I've worked on:<br>
</p>
<ul>
<li>Michelangelo</li>
<li>Nash</li>
<li>Whiskeytown</li>
<li>Gobstopper</li>
</ul>
<p>
These are our <strong>internal project code names</strong>.
The names are chosen alphabetically from a set of items; every new project gets a name
from the set. We start with A, and when we finally arrive at Z, we pick
a new set of items for project name inspiration. Can you guess which set each of the above project
names is from? No cheating!<br>
<br>
We've come up with the following loose guidelines for project naming:</p>
<p>
</p>
<ol>
<li>We prefer one word names.</li>
<li>They should be relatively easy to pronounce and easy to spell.</li>
<li>They have to be client friendly.</li>
<li>They should be globally unique across the company. No duplicates.</li>
<li>We need a reasonable number of items in the set to choose from, in A-Z order.</li>
</ol>
<p>
Of course, no entry on naming would be complete without a reference to the classic Salon article from the pinnacle of the dot-com craze, <a href="http://salon.com/media/col/shal/1999/11/30/naming/print.html">The Name Game</a>:
</p>
<p>
</p>
<blockquote>
In the end, however, attempting to quantify the benefits of a naming project may be just as small-minded as, well, attempting to quantify the benefits of a name. For the lucky client who truly clicks with his or her namer, the collateral benefits go far beyond nomenclature. There are new words to learn. Fun games to play. And, in the case of the Monkeys, unimpeachable warmth and love. "We got so much more than a name," says Robin Bahr of 98point6. "I mean, I got a name for my daughter. One of our senior executives identified strongly with 'Mescalanza.' No one calls him Jim anymore. His name is Mescalanza." Meanwhile, she says, "our senior manager for Internet development just fell in love with the name 'Jamcracker.' And so today, the Harvey meeting is known as the Jamcracker meeting. There are 300 people at this company who identify Jamcracker with Harvey."
<p>
Bahr claps her hands over her mouth. "Oh my God," she says. "I forgot. I shouldn't be mentioning these names to a reporter. Technically, we don't have ownership of those names. Jamcracker is still the Monkeys' property."
</p>
<p>
Bahr stops for a moment, as if listening to herself. Then she bursts out laughing. "Listen," she says. "I take it back. You write whatever you want to write. If <a href="http://www.jamcracker.com/">someone out there wants to name their company Jamcracker</a>, God bless them. And good luck to them."
</p>
</blockquote>
<p>
The challenge, then, is <strong>coming up with new sets to inspire project names</strong>.
We began with <a href="http://en.wikipedia.org/wiki/Microsoft_codenames">Microsoft's list of project code names</a> and <a href="http://applemuseum.bott.org/sections/codenames.html">Apple's list of project code names</a>
as our spirit guides.</p>
<p>
Here are some of the sets we've considered for project naming at various
points:</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td valign="top" width="200">
Types of Food<br>
Video games (<a href="http://en.wikipedia.org/wiki/List_of_Atari_2600_games">Atari 2600</a>, <a href="http://www.klov.com/">Arcade</a>, etc)<br>
<a href="http://en.wikipedia.org/wiki/List_of_commercial_brands_of_beer">Brands of Beer</a><br>
<a href="http://www.roman-emperors.org/impindex.htm">Roman Emperors</a><br>
Cartoon characters / shows<br>
Mythological names / <a href="http://www.godchecker.com/">gods</a><br>
<a href="http://en.wikipedia.org/wiki/List_of_cars">Cars</a><br>
GUIDs (a <a href="http://www.codinghorror.com/blog/archives/000399.html">personal favorite</a>)<br>
<a href="http://en.wikipedia.org/wiki/User:Miwasatoshi/List_of_gemstones">Gemstones</a><br>
Types of Coffee drinks<br>
States<br>
Counties<br>
Plants<br>
<a href="http://www.imdb.com/name/nm0000033/">Hitchcock films</a><br>
<a href="http://en.wikipedia.org/wiki/List_of_cheeses"></a>
</td>
<td valign="top" width="200">
<a href="http://en.wikipedia.org/wiki/List_of_dog_breeds">Dog breeds</a><br>
<a href="http://en.wikipedia.org/wiki/List_of_colors">Colors</a><br>
Famous Explorers<br>
<a href="http://en.wikipedia.org/wiki/List_of_trees">Trees</a><br>
<a href="http://www.completetax.com/Forms-Tables-Worksheets.asp">IRS Tax Forms</a><br>
English <a href="http://en.wikipedia.org/wiki/List_of_monarchs">monarchs</a><br>
Famous People (eg, <a href="http://en.wikipedia.org/wiki/Carl_Sagan">Sagan</a>)<br>
<a href="http://www.wikipedia.com">Wikipedia</a> article names<br>
Single letters (including unicode)<br>
Radio <a href="http://en.wikipedia.org/wiki/NATO_phonetic_alphabet">alphabet</a><br>
Candy brands<br>
<a href="http://en.wikipedia.org/wiki/List_of_dinosaurs">Dinosaurs</a><br>
Historical Sites<br>
City street names<br>
<a href="http://www.ikea.com">IKEA</a> product names<br>
</td>
<td valign="top" width="200">
Types of Fasteners (nut, bolt, rivet, etc)<br>
<a href="http://www.skicentral.com/resorts.html">Ski resorts</a><br>
<a href="http://www.nps.gov/applications/parksearch/atoz.cfm">National Parks</a><br>
<a href="http://www.peakbagger.com/listindx.aspx">Mountain Peaks</a><br>
<a href="http://en.wikipedia.org/wiki/List_of_World_War_II_ships">World War II era ships</a><br>
<a href="http://en.wikipedia.org/wiki/List_of_bridges">Birds</a><br>
<a href="http://en.wikipedia.org/wiki/List_of_beaches%20">Beaches</a><br>
<a href="http://en.wikipedia.org/wiki/List_of_bridges">Bridges</a><br>
Web 2.0 <a href="http://www.andrewwooldridge.com/myapps/webtwopointoh.html">names</a><br>
Warcraft realm names<br>
<a href="http://en.wikipedia.org/wiki/List_of_cheeses">
Cheeses<br>
</a>
Countries<br>
Cereal brands</td>
</tr>
</table>

<p>
If there are there any sets I haven't listed here that you think would make for
good project names, feel free to link them in the comments.</p>
<p>
It's always fun to pick out a new name when starting a project. It's amazing
how quickly we plow through an entire A-Z series in a set; we've been through almost
four since I started in 2005. That's how we do it. But how do you name <em>your</em> projects?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-in-a-project-name/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Forget To Lock Your Computer ]]></title>
<link>https://blog.codinghorror.com/dont-forget-to-lock-your-computer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I encourage my coworkers to <b>lock their computers</b>. Security, after all, is everyone's business. But often gentle encouragement is not enough. Sometimes, more.. <i>persuasive</i> methods are necessary.
</p>
<p>
I first learned about the noble art of goating from <a href="http://www.shahine.com/omar/USBPCLock.aspx">from Omar Shahine</a>:
</p>
<p>
</p>
<blockquote>
We have this problem in Hotmail. If you walk away from your desk, even for a brief moment, and your PC is left unlocked, someone will walk in, and send mail to a broad distribution list with something silly. Like "I like oranges", or worse things, some downright embarrassing. <b>For some reason this is called "Goating".</b> I find it incredibly annoying. My office has a lock on the door, so I am in the habit of keeping my door locked when I walk away.
</blockquote>
<p>
Goating techniques vary from insidious and subtle to invasive, borderline vandalism. I prefer the milder forms:
</p>
<ul>
<li>Installing <a href="http://www.codinghorror.com/blog/archives/000452.html">the bluescreen screensaver</a>.
</li>
<li>Replacing the desktop with a screenshot of the desktop, and hiding all the visible items on it.
</li>
<li>Switching the mouse from right to left handed.
</li>
<li>Using the video driver settings to rotate the display left, right, or upside down.
</li>
<li>Switching the keyboard layout from QWERTY to Dvorak (or vice-versa).
</li>
</ul>
<p>
Goating can be quite literal. I once walked back to my computer to find this:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's disturbingly common here, which is why I've learned to reflexively <a href="http://www.codinghorror.com/blog/archives/000378.html">press Windows+L</a> when I get up from my desk.
</p>
<p>
One of my all-time favorite goating techniques, however, is to install <a href="http://www.rjlsoftware.com/software/entertainment/clippy/default.shtml">the Clippy parody applet</a> on a victi.. er, coworker's machine. Who doesn't love <a href="http://en.wikipedia.org/wiki/Clippy">our old pal Clippy!</a>
</p>
<p>
<a href="http://www.rjlsoftware.com/software/entertainment/clippy/default.shtml"><img alt="image placeholder" >
 
<a href="http://www.rjlsoftware.com/software/entertainment/clippy/default.shtml"><img alt="image placeholder" >
 
<a href="http://www.rjlsoftware.com/software/entertainment/clippy/default.shtml"><img alt="image placeholder" >
</p>
<p>
After one particuarly inspired installation of Clippy, an email titled "What The Heck" went out to all employees:
</p>
<p>
</p>
<blockquote>
Is this another prank or something? What the heck is this Ã¢â‚¬Â¦ It's rude.
<p>
Look at the right hand corner of this image.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
So far this stupid thing has told me:
</p>
<ol>
<li>My typing speed is slow.
</li>
<li>My productivity has been decreasing, I hope everything is Ok?
</li>
<li>My posture is degrading and I should reposition myself.
</li>
<li>Finally: It's time to play a game. Let's play hide-and-seek?
</li>
</ol>
</blockquote>
<p>
Much hilarity ensued, and more importantly, <b>crucial lessons were learned about computer security by all</b>.
</p>
<p>
It's up to each of us to go forth and spread the good word! If just <i>one</i> person learns how important computer security is, your work here is done. Many additional goating techniques can be found in <a href="http://ask.metafilter.com/46747/Tell-me-a-good-computer-prank">these</a> <a href="http://ask.metafilter.com/45744/Boo-I-just-MacPwned-you">two</a> metafilter threads; <a href="http://officepoltergeist.com/">Office Poltergeist</a> looks quite promising, as does <a href="http://www.errmess.com/products.php">ErrMess</a>. And you really can't go wrong with <a href="http://www.rjlsoftware.com/software/entertainment/clippy/default.shtml">Clippy</a>.
</p>
<p>
But don't forget to lock <i>your</i> computer while you're out there spreading the word.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-forget-to-lock-your-computer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ You're Now Competing With The Internet ]]></title>
<link>https://blog.codinghorror.com/youre-now-competing-with-the-internet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Reginald Braithwaite writes consistently great stuff on <a href="http://weblog.raganwald.com/">his blog</a>, but I think my absolute favorite thing he's ever written is <a href="http://weblog.raganwald.com/2007/09/we-have-lost-control-of-apparatus.html">We Have Lost Control of the Apparatus</a>.
</p>
<p>
</p>
<blockquote>
But we programmers have lost and we must be realistic about things. The fact of the matter is this: people own their own computers, and our applications are no longer the primary way they learn how computers ought to work. I know, I know, they stare at our work for eight, ten, or twelve hours a day. So you would think that we would set the standard for how computers ought to be. But the Good Old Days when most of users had never seen a computer before work have gone. Some of our users, fresh out of school, have already been using computers for ten years!
<p>
As if that wasn't enough, the really bad news is, when our users go home they have this thing called the Internet. I know, IT locked that down in the office. But we can't stop them from getting on it at home, on their mobiles, and now even on those insidious Apple iPods! <b>And when people use the Internet, they are actually using other people's applications.</b> I'm not kidding. Our users are being exposed to applications we don't control. And it messes things up. You see, the users get exposed to other ways of doing things, ways that are more convenient for users, ways that make them more productive, and they incorrectly think we ought to do things that way for them.
</p>
</blockquote>
<p>
Over the last five years, the internet has evolved from a traditional HTML content delivery system into an application delivery platform. One that competes with every sort of software application, not just other websites. Every bit of software we write, on any platform, is judged against things users are <i>already</i> doing on the internet. <b>We're all competing with the internet.</b>
</p>
<p>
<a href="http://www.tricornerhumor.com/"><img alt="image placeholder" >
</p>
<p>
Reg provides a number of specific examples where internet applications have raised users' expectations. Possibly the greatest shift in expectations is around search:
</p>
<p>
</p>
<blockquote>
[Google] is <a href="http://www.codinghorror.com/blog/archives/000767.html">practically the home page of the Internet</a>. Which means, to a close approximation, they are the most popular application in the world.
<p>
And what have they taught our users? <b>Full-text search wins.</b> If you give them a search page with a field for searching the account number and a field for searching the SSN and a field for searching the zip code and a field for searching the phone number, they want to know why they can't just type <code>4165558734</code> and <i>find Reg by phone number?</i> And right after we make that work for them, those greedy and ungrateful sods'll want to type <code>(416) 555-8734</code> and have it work too. Bastards.
</p>
<p>
I have tried explaining that there's an ambiguity if an account number is also <code>4165558734</code>. They think we should just show them what we find and let them sort it out. They're idiots, obviously, but they're our idiots and I'm pretty sure that if we fire them all we'll have to clean our own desks out the following day.
</p>
</blockquote>
<p>
This is particularly hard on the internal applications Reg seems to be focusing on here. Internal apps are already the shakiest part of the software ecosystem; as Joel points out, <a href="http://www.joelonsoftware.com/articles/FiveWorlds.html">lots of internal software sucks pretty badly</a>. (I know because I've certainly <a href="http://www.codinghorror.com/blog/archives/000099.html">written my share of it</a>.) Having this pervasive, instantly accessible world of reasonably good software available through your browser-- and it's only <i>one tiny click away</i> -- is like pouring salt in the user's wounds. It's impossible to justify the pain of badly written internal software when there's a universe of better choices practically beating down your door, even on locked down corporate desktops.
</p>
<p>
If I was a user, I'd be angry, too. If you're writing software that <a href="http://www.codinghorror.com/blog/archives/000773.html">you want users to actually <i>use</i></a>, then no matter what kind of software you're delivering, you better <a href="http://www.codinghorror.com/blog/archives/000883.html">pay attention to your online competition</a>. It's going to be rough, even for commercial desktop applications. I'm not sure many internal applications can legitimately compete with superior options emerging on the internet every day. It's survival of the fittest alongside a vibrant new species of internet competitors -- does your software <i>deserve</i> to survive?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/youre-now-competing-with-the-internet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Pair Programming vs. Code Reviews ]]></title>
<link>https://blog.codinghorror.com/pair-programming-vs-code-reviews/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Tom Dommett wrote in to share his positive experience with <a href="http://en.wikipedia.org/wiki/Pair_programming">pair programming</a>:
</p>
<p>
</p>
<blockquote>
The idea is two developers work on the same machine. Both have keyboard
and mouse. At any given time one is driver and the other navigator. The
roles switch either every hour, or whenever really. The driver codes, the navigator is reading, checking, spell-checking and sanity testing the code, whilst thinking through problems and where to go next. If the driver hits a problem, there are two people to find a solution, and one of the two usually has a good idea.
<p>
Other advantages include the fact that where two people have differing
specialities, these skills are transferred. Ad-hoc training occurs as one person shows the other some tricks, nice workarounds, etcetera.
</p>
<p>
The end result is that both developers are fully aware of the code, how it works, and why it was done that way. Chances are the code is better than one developer working alone, as there was somebody watching. It's less likely to
contain bugs and hacks and things that cause maintenance problems later.
</p>
<p>
In a bigger team, the pairing can change each week so each team member is partnered with somebody different. This is a huge advantage, as it gets developers talking and communicating ideas in the common language of code.
</p>
<p>
We found this to be as fast as working separately. The code got written
quicker and didn't require revisiting. And when it did need to change, more than one person was familiar with the code.
</p>
</blockquote>
<p>
It's an encouraging result. I applaud anything that gets teams to communicate better.
</p>
<p>
I'm intrigued by the idea of pair programming, but <b>I've never personally lived the pair programming lifestyle</b>. I do, however, enjoy working closely with other developers. Whenever I sit down to work side by side with a fellow developer, I always absorb a few of their tricks and techniques. It's a fast track learning experience for both participants. But I've only done this in small doses. I'm a little wary of spending a full eight hours working this way. I suspect this might be fatiguing in larger doses, <a href="http://geekswithblogs.net/dlussier/archive/2007/08/10/114551.aspx">unless you're very fortunate in your choice of pairing partner</a>.
</p>
<p>
I've <a href="http://www.codinghorror.com/blog/archives/000495.html">written about the efficacy of code reviews</a> before. That is something I have personal experience with; I can vouch for the value of code reviews without reservation. I can't help <b>wondering if pair programming is nothing more than code review on steroids</b>. Not that one is a substitute for the other-- you could certainly do both-- but I suspect that many of the benefits of pair programming could be realized through <a href="http://www.processimpact.com/pubs.shtml#pr">solid peer review practices</a>.
</p>
<p>
But code reviews aren't a panacea, either, <a href="http://jcooney.net/archive/2004/01/31/355.aspx">as Marty Fried pointed out</a>:
</p>
<p>
</p>
<blockquote>
My experience with code reviews has been a mixed bag. One of the problems seems to be that nobody wants to spend the time to really understand new code that does anything non-trivial, so the feedback is usually very general. But later, when someone is working on the code to either add functionality or fix bugs, they usually have lots of feedback (sometimes involving large hammers), but then it may be too late to be effective; the programmer may not even be around. I think it might be useful to have one anyway, but it's hard to get a fellow progammer to tell his boss that another programmer did a bad job.
</blockquote>
<p>
<b>The advantage of pair programming is its gripping immediacy: it is impossible to ignore the reviewer when he or she is sitting right next to you.</b> Most people will passively opt out if given the choice. With pair programming, that's not possible. Each half of the pair <i>has</i> to understand the code, right then and there, as it's being written. Pairing may be invasive, but it can also force a level of communication that you'd otherwise never achieve.
</p>
<p>
On the other hand, peer review scales a heck of a lot better than stacking physical bodies in the same area. Consider <a href="http://www.macadamian.com/index.php?option=com_techarticle&amp;task=view&amp;id=1">the experiences of Macadamian with code review</a> while working on the <a href="http://en.wikipedia.org/wiki/Wine_(software)">WINE project</a>:
</p>
<p>
</p>
<blockquote>
There were two processes in the WINE project that we weren't used to: public peer reviews, where new code and patches were distributed in a mailing list to everyone involved in the project; and single committer, where the project leader had the final say over which patches were accepted into the source tree.
<p>
We soon found out that Alexandre Julliard, who has been the maintainer of WINE and one of the key developers since 1994, was very particular about code going into the source tree. Our team's patches were scrutinized, and when some were rejected, there was a lot of grumbling. "My code works, who does this guy think he is? We're on a deadline here!" But as the project progressed, we realized we were producing our best code ever. Producing clean, well-designed code that was admitted into the source tree at first pass soon became a matter of pride. We also found that, despite the fact that the project was huge and spread worldwide, we knew exactly how the whole project was progressing since we saw every patch on the mailing list. We now conduct code reviews on every project, and on larger projects, we set up an internal mailing list and designate a single committer. It may be painful to set up code review at your company, and there may be some grumbling, but you will see big improvements in the quality and maintainability of your code.
</p>
</blockquote>
<p>
I think both techniques are clearly a net <i>good</i>, although they each have their particular pros and cons. I encourage people who have experience with both pair programming and code reviews to share their experiences in the comments. Is one more effective than the other? Should we do both?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In the end, I don't think it's a matter of picking one over the other so much as <b>ensuring you have more than one pair of eyes looking at the code you've written</b>, however you choose to do it. When your code is reviewed by another human being -- whether that person is sitting right next to you, or thousands of miles away -- you <i>will</i> produce better software. That I can guarantee.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/pair-programming-vs-code-reviews/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Living the Dream: Rock Band ]]></title>
<link>https://blog.codinghorror.com/living-the-dream-rock-band/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm a huge fan of the <a href="http://en.wikipedia.org/wiki/Guitar_Hero">Guitar Hero</a> series. After reading the first reviews in November 2005, I <a href="http://www.codinghorror.com/blog/archives/000437.html">rushed out to get one of the few available copies</a> at my local Best Buy. It was an obscure title at the time-- I had no idea it was even being released until I read the initial reviews, and <a href="http://www.fakeplasticrock.com/index.php/about/">I'm a fan of the rhythm genre</a>. Guitar Hero is now such a massive success that everyone reading this has probably at least <i>heard</i> of it. It achieved pop culture critical mass, which is the ultimate and final level of success for any video game. It's what every game aspires to, and precious few achieve.
</p>
<p>
But it was far from a foregone success when it was under development. In fact, Guitar Hero was a highly questionable software development project from a publisher's perspective:
</p>
<p>
</p>
<ul>
<li>New, unproven franchises are risky.
</li>
<li>Games that require peripherals to play don't typically sell well.
</li>
<li>Games that cost $70 - $80 don't typically sell well.
</li>
<li>Games with a giant honking box tend to suffer for lack of shelf space.
</li>
<li>The Japanese title "Guitar Freaks", a very similar game, flopped in the US.
</li>
</ul>
<p>
Beyond that, the studio behind the game, Harmonix, had a poor track record. Their previous two rhythm games, <a href="http://en.wikipedia.org/wiki/FreQuency">Frequency</a> and <a href="http://en.wikipedia.org/wiki/Amplitude_(video_game)">Amplitude</a>, were not exactly hits. Despite great playtester impressions, positive reviews and many design awards, both games sold, in the words of co-founder Alex Rigopulos, "mouse nuts".
</p>
<p>
This disconnect between creative output and sales took its toll on the team, as <a href="http://www.gameinformer.com/News/Story/200702/N07.0219.1006.10335.htm?Page=1">Alex explained in a recent interview</a>:
</p>
<p>
</p>
<blockquote>
It's torture for the creative team that's making the game, because when you make a game that the reviewers are loving and the playtesters love it and whatnot, you feel like just on a creative level that you've succeeded. But as I mentioned this morning, it's only half the battle, because <b>if you make an experience that can't be effectively marketed, then you're just dramatically capping the number of people who will ever have access to that experience.</b> For us, it was really hard to go through that experience, but we came out of it having learned an important lesson, which is that we needed to think up how to sort of wrap up these experiences in a form that sort of made it easier to reach out to a wider audience of people.
</blockquote>
<p>
Alex <a href="http://kotaku.com/gaming/dice07/harmonix-lives-the-dream-235431.php">gave a talk at DICE 2007</a> where he explained the internal debate over Guitar Hero in slide form.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This graph of twelve years of Harmonix' financial results illustrates, as Alex labels it, "The Dream".
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It took Harmonix <i>ten full years</i> to finally find success with 2005's Guitar Hero, through dogged persistence pursuing the rhythm game genre.
</p>
<p>
Harmonix went on to create Guitar Hero II, which greatly amplified the multiplayer and polished the overall experience. After that, there was a schism-- the Guitar Hero franchise, including Guitar Hero III, is in the hands of different developers. Harmonix went on to develop the innovative <a href="http://en.wikipedia.org/wiki/Rock_band">Rock Band</a>. Instead of the two player bass and lead guitar multiplayer of Guitar Hero, <b>in Rock Band, you have four players-- bass guitar, lead guitar, drums, and vocals</b>.
</p>
<p>
<a href="http://arstechnica.com/reviews/games/rock-band-review.ars/4"><img alt="image placeholder" >
</p>
<p>
It's a <a href="http://www.oxmonline.com/article/features/presses/rock-bands-alex-rigopulos-oxm-interview?page=0%2C0">continuing evolution of the dream</a>:
</p>
<p>
</p>
<blockquote>
My biggest hope is that this game deepens people's connection with the rock music that they love. Playing this game changes people's understanding of music. Most people, they listen to rock, they don't even separate the music into the different instrumental components. They don't hear the drums and the bass and the guitar separately, it all sort of blends together into a mash for them. Playing this game changes that. Playing this game changes the way that people hear rhythms. It changes the way they hear the interrelation between different parts. The act of playing it just connects people in a very visceral, physical way with the music that they don't otherwise experience. <b>So really what it's all about for us is just making peoples' connection with the music that they love much more profound. I really do think that on a mass scale millions of people will understand and feel music in a different way because of this game.</b>
</blockquote>
<p>
I'd like to think a big part of Harmonix' success is -- to steal a phrase from the greatly missed Kathy Sierra -- their dedication not to gameplay, not to code, not to sales, but to <a href="http://headrush.typepad.com/creating_passionate_users/2005/09/subvert_from_wi.html">helping users kick ass</a>:
</p>
<p>
</p>
<blockquote>
Phrase everything in terms of the user's personal experience rather than the product. Keep asking, no matter what, "So, how does this help the user kick ass?" and "How does this help the user do what he really wants to do?" <b>Don't focus on what the user will think about the product, focus everyone around you on what the user will think about himself as a result of interacting with it.</b>
</blockquote>
<p>
This is how all software should be written: with the user's goals at the forefront.
</p>
<p>
There's absolutely no better way to experience the sublime feeling of personal success Kathy is describing here than to <a href="http://www.amazon.com/exec/obidos/ASIN/B000TT4GBG/codihorr-20">play Rock Band with your friends and coworkers</a>. If you haven't tried it yet, I envy the experience you're about to have.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/living-the-dream-rock-band/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Has CAPTCHA Been "Broken"? ]]></title>
<link>https://blog.codinghorror.com/has-captcha-been-broken/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A recent Wall Street Journal describes <a href="http://online.wsj.com/public/article/SB119153995723149557.html">Ticketmaster's problems with online scalpers</a>:
</p>
<p>
</p>
<blockquote>
The Internet era has brought speed and convenience to all sorts of consumer transactions. For concertgoers, however, it has also led to ever-faster sellouts for hot events. Ticketmaster deploys technology that is supposed to stop brokers from gaining access to large numbers of seats via online sales. But it says brokers' software circumvents the company's protections.
<p>
That has placed large numbers of seats in the hands of brokers who use eBay Inc.'s StubHub, Craigslist and other online venues to resell the tickets at a big mark up.
</p>
<p>
One situation roiling consumers involves the 54-concert "Best of Both Worlds" tour in which singer-actress Miley Cyrus is performing sets as herself and as her fictional alter ego, Hannah Montana. Parents and children have found finding tickets for the shows difficult and expensive. The issue is drawing the attention of government officials. On Thursday -- in a rare Internet-age example of authorities enforcing antiscalping laws -- the attorneys general of Missouri and Arkansas filed lawsuits against people accused of illegally reselling Hannah Montana tickets.
</p>
<p>
According to StubHub, tickets for "Best of Both Worlds" are currently selling for an average $237, making them pricier than seats for the Police ($209), Justin Timberlake ($182) and Beyonc ($212). The highest face value for a ticket on the Hannah Montana tour: $63.
</p>
</blockquote>
<p>
They must have <i>really</i> pissed off some high ranking political parents to get that kind of attention. Not that they don't deserve it-- scalpers are evil, profiteering bastards, to be sure. They deserve all the pain we can send their way.
</p>
<p>
The "technology that is supposed to stop brokers" they're referring to is <a href="http://en.wikipedia.org/wiki/Captcha">CAPTCHA</a>.
</p>
<p>
</p>
<blockquote>
For instance, companies like Ticketmaster require customers searching for tickets online to replicate a set of the squiggly letters and numbers, known as a "Captcha." Theoretically, only human customers can correctly identify the characters despite the odd fonts, screening out automated purchasing programs. But RMG's software, according to Mr. Kovach, can also "figure out the randomly generated characters and retype them automatically." Mr. Kovach said RMG employees also gave him advice on fooling Ticketmaster's computers into thinking his requests were coming from different Internet addresses. Neither Mr. Kovach nor his lawyer could be reached for comment.
</blockquote>
<p>
So if online scalpers are somehow beating the system, does that mean CAPTCHA has been broken? I <a href="http://www.codinghorror.com/blog/archives/000712.html">covered this topic a year ago</a>, and my opinion has not changed. <b>If CAPTCHAs were well and truly broken, Google, Yahoo, and Hotmail would stop using them.</b> Why would they continue to use something that doesn't work? I'm not going to rehash all the arguments here, but if you have strong feelings on this topic, <a href="http://www.codinghorror.com/blog/archives/000712.html">I urge you to read my earlier post before commenting</a>.
</p>
<p>
Ticketmaster's problem is that their CAPTCHA is <i>not good enough</i>. Programmers don't seem to understand what makes a CAPTCHA difficult to "break". But it's not difficult to find out. Heck, the hackers themselves will <i>tell</i> you how to do CAPTCHA correctly if you just know where to look. For example, <a href="http://www.lafdc.com/captcha/">this Chinese hacker's page breaks down a number of common CAPTCHAs</a>, and the price of software he sells to defeat them at a certain percentage success rate:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td valign="top" width="125">the9<br><font color="red">100%</font><br>$500
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">dvbbs<br><font color="red">95%</font><br>$1,000
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">Shanda<br><font color="red">90%</font><br>$1,500
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">Baidu<br><font color="red">80%</font><br>$3,000
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">eBay<br><font color="red">70%</font><br>$4,000
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">Ticketmaster<br><font color="red">50%</font><br>$6,000
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">Google<br>(unbreakable)
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">Hotmail<br>(unbreakable)
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">Yahoo<br>(unbreakable)
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
It seems an awful lot of programmers subscribe to the "add some crazy patterns and/or colors to the text and pray for the best" school of CAPTCHA design. That's not only sloppy, it just doesn't work. The top of this chart is littered with their failed attempts. On some sites, this is OK. They don't need the same world-class level of protection from bots and scripts that Ticketmaster does-- there's tremendous financial incentive for scalpers to break their system.
</p>
<p>
This particular hacker estimates a 50% success rate against the Ticketmaster captcha, long before the above article was published. No wonder those parents weren't able to buy their kids Hannah Montana tickets-- <b>it's not because of failings in CAPTCHA protection, it's because the ticketmaster programmers failed to implement CAPTCHA correctly.</b>
</p>
<p>
Instead of hacking together their own partially effective (and often <a href="http://forums.worsethanfailure.com/forums/post/116253.aspx">not even human solvable</a>) CAPTCHA, what Ticketmaster's programmers <i>should</i> have done is studied prior art-- in particular, by outright copying the high-volume, extensively researched Yahoo, Google, and Hotmail CAPTCHAs. I'm awfully fond of Google's CAPTCHA technique; in my professional opinion, it is simultaneously the most readable and the most hellishly difficult to OCR correctly. If you need industrial strength protection from bots and scripts, <i>that's</i> where you want to start.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/has-captcha-been-broken/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Two Types of Programmers ]]></title>
<link>https://blog.codinghorror.com/the-two-types-of-programmers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Contrary to myth, there aren't <a href="http://undefined.com/ia/2006/10/05/the-fourteen-types-of-programmers/">fourteen types of programmers</a>. There are <a href="http://blog.red-bean.com/sussman/?p=79">really only two</a>, as Ben Collins-Sussman reminds us.
</p>
<p>
</p>
<blockquote>
There are two "classes" of programmers in the world of software development: I'm going to call them the 20% and the 80%.
<p>
The 20% folks are what many would call "alpha" programmers  --  the leaders, trailblazers, trendsetters, the kind of folks that places like Google and Fog Creek software are obsessed with hiring. These folks were the first ones to install Linux at home in the 90's; the people who write lisp compilers and learn Haskell on weekends "just for fun"; they actively participate in open source projects; they're always aware of the latest, coolest new trends in programming and tools.
</p>
<p>
The 80% folks make up the bulk of the software development industry. They're not stupid; they're merely vocational. They went to school, learned just enough Java/C#/C++, then got a job writing internal apps for banks, governments, travel firms, law firms, etc. The world usually never sees their software. They use whatever tools Microsoft hands down to them -- usally VS.NET if they're doing C++, or maybe a GUI IDE like Eclipse or IntelliJ for Java development. They've never used Linux, and aren't very interested in it anyway. Many have never even used version control. If they have, it's only whatever tool shipped in the Microsoft box (like SourceSafe), or some ancient thing handed down to them. They know exactly enough to get their job done, then go home on the weekend and forget about computers.
</p>
</blockquote>
<p>
As I work with teams of programmers in the field, I'm consistently struck by the yawning abyss between that 20% and the rest of the world. It makes <a href="http://www.codinghorror.com/blog/archives/000845.html">the divide between the open-source and Microsoft camps</a> look like a shallow ditch.
</p>
<p>
</p>
<blockquote>
<b>Shocking statement #1</b>: <i>Most of the software industry is made up of 80% programmers</i>. Yes, most of the world is small Windows development shops, or small firms hiring internal programmers. Most companies have a few 20% folks, and they're usually the ones lobbying against pointy-haired bosses to change policies, or upgrade tools, or to use a sane version-control system.
<p>
<b>Shocking statement #2:</b> <i>Most alpha-geeks forget about shocking statement #1</i>. People who work on open source software, participate in passionate cryptography arguments on Slashdot, and download the latest GIT releases are extremely likely to lose sight of the fact that "the 80%" exists at all. They get all excited about the latest Linux distro or AJAX toolkit or distributed SCM system, spend all weekend on it, blog about itÃ¢â‚¬Â¦ and then are confounded about why they can't get their office to start using it.
</p>
</blockquote>
<p>
Perhaps not shocking to me, but an excellent and important reminder for everyone, nonetheless.
</p>
<p>
I often think we're wasting our time writing blogs which are largely read by the same 20%. In my experience, there's precious little trickle-down effect from the alpha programmers to everyone else. And if there is, <a href="http://www.codinghorror.com/blog/archives/000686.html">it takes decades</a>. If you <i>really</i> want to change the software development status quo, if you want to make a difference <i>this year</i>, you have to help us reach outside our insular little group of alpha programmers and <b>effect change in the other 80% of the world</b>. And that is far, <i>far</i> more difficult than preaching to the converted 20%. It's why I admire people like Scott Mitchell so much, because he <a href="http://scottonwriting.net/sowblog/posts/5595.aspx">understands the importance of reaching out to the other 80%</a>:
</p>
<p>
</p>
<blockquote>
I like programming and really enjoy ASP.NET. I think it's neat and fun and interesting and cool how you can go from literally nothing to having a data-driven web application that can be used by people around the world in an amazingly fast amount of time. Furthermore, I want to spread that enthusiasm to folks. I want to say to those who may have never programmed, or to those who are using competing technologies, or to those who are just starting out - "Come over here and try out this ASP.NET stuff. Here, let me show you what it can do!" That's why I teach (which pays pennies compared to consulting). That's why I write (which pays better than teaching, but still is not anywhere near as lucrative as consulting). That's why I give free talks at local user groups and community-sponsored conferences here in Southern California. To get the word out!
<p>
To me, saying that titles like <a href="http://www.codinghorror.com/blog/archives/000560.html">Teach Yourself X in 24 Hours cheapen the craft</a> is tantamount to saying, "Our club is full. Go away." It's not saying, "Let's welcome the newbies and get them excited about this technology." Rather, it's saying, "Newbies are ok, but they must first realize how hard this is, how hard we've worked, and how much more we know than them." I worry that such sentiment from the community will come across as pompousness to those very people whom we should be welcoming.
</p>
</blockquote>
<p>
I wish this was easier for me, because I agree with Scott. I'm terrible at the things he's describing. I think the true measure of success isn't how many alpha geeks you can get to pay attention to you. It's <b>how many typical, average programmers you've reached out to</b>, if only in some small way. If you really care about the craft of software development, you'll help us build that bridge between the 20% and the 80%, too.
</p>
<p>
<font color="red">Update:</font> This was a controversial post. See <a href="http://www.codinghorror.com/blog/archives/001004.html">my followup to this post</a> for further explanation.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-two-types-of-programmers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Big Ball of Mud and Other Architectural Disasters ]]></title>
<link>https://blog.codinghorror.com/the-big-ball-of-mud-and-other-architectural-disasters/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Mistakes are inevitable on any software project. But mistakes, if handled appropriately, are OK. Mistakes can be intercepted, adjusted, and ultimately addressed. The root of deep, fatal software project problems is <i>not knowing when you're making a mistake</i>. These types of mistakes tend to fester into massive, systemic project failure. That's why I'm fond of <a href="http://www.codinghorror.com/blog/archives/000889.html">citing McConnell's list of classic mistakes</a>; I find it helpful to review every so often as a sort of <a href="http://www.codinghorror.com/blog/archives/000498.html">triage self-check</a>. I ask myself-- <b>am I making any of these mistakes without even realizing it?</b>
</p>
<p>
I suppose this could lead to a sort of project hypochondria, where you're constantly defending against mysterious, unseen project illnesses. I don't know about you, but I'd much rather be working on a project with a paranoid project manager than an oblivious one. <a href="http://www.intel.com/pressroom/kits/bios/grove/paranoid.htm">Only the paranoid survive</a>.
</p>
<p>
Perhaps that's also why I enjoy Brian Foote and Joseph Yoder's <a href="http://www.laputan.org/mud/">Big Ball of Mud paper</a> so much. This paper was originally presented at the 1997 <a href="http://st-www.cs.uiuc.edu/~plop/">conference on Patterns Languages of Programs</a>, amusingly acryonymed PLoP. It describes <b>classic <i>architectural</i> mistakes in software development</b>.
</p>
<p>
</p>
<blockquote>
The architecture that actually predominates in practice is the BIG BALL OF MUD.
<p>
A BIG BALL OF MUD is haphazardly structured, sprawling, sloppy, duct-tape and bailing wire, <a href="http://www.cs.brandeis.edu/~dkw/C-humor/pasta.txt">spaghetti code jungle</a>. We've all seen them. These systems show unmistakable signs of unregulated growth, and repeated, <a href="http://home.swbell.net/mck9/cobol/style/rewrite.html">expedient repair</a>. Information is shared promiscuously among distant elements of the system, often to the point where nearly all the important information becomes global or duplicated. The overall structure of the system may never have been well defined. If it was, it may have eroded beyond recognition. Programmers with a shred of architectural sensibility shun these quagmires. Only those who are unconcerned about architecture, and, perhaps, are comfortable with the inertia of the day-to-day chore of patching the holes in these failing dikes, are content to work on such systems.
</p>
<p>
Still, this approach endures and thrives. Why is this architecture so popular? Is it as bad as it seems, or might it serve as a way-station on the road to more enduring, elegant artifacts? What forces drive good programmers to build ugly systems? Can we avoid this? Should we? How can we make such systems better?
</p>
</blockquote>
<p>
It's a great read. The authors enumerate seven architectural pathologies:
</p>
<p>
1. <a href="http://www.laputan.org/mud/mud.html#BigBallOfMud"><b>Big Ball of Mud</b></a><br>
(a.k.a. <i>Shantytown</i>, <i>Spaghetti Code</i>)
</p>
<p>
</p>
<blockquote>
Shantytowns are usually built from common, inexpensive materials and simple tools. Shantytowns can be built using relatively unskilled labor. Even though the labor force is "unskilled" in the customary sense, the construction and maintenance of this sort of housing can be quite labor intensive. There is little specialization. Each housing unit is constructed and maintained primarily by its inhabitants, and each inhabitant must be a jack of all the necessary trades. There is little concern for infrastructure, since infrastructure requires coordination and capital, and specialized resources, equipment, and skills. There is little overall planning or regulation of growth. Shantytowns emerge where there is a need for housing, a surplus of unskilled labor, and a dearth of capital investment. Shantytowns fulfill an immediate, local need for housing by bringing available resources to bear on the problem. Loftier architectural goals are a luxury that has to wait.
<p>
<img alt="image placeholder" >
</p>
<p>
Maintaining a shantytown is labor-intensive and requires a broad range of skills. One must be able to improvise repairs with the materials on-hand, and master tasks from roof repair to ad hoc sanitation. However, there is little of the sort of skilled specialization that one sees in a mature economy.
</p>
<p>
All too many of our software systems are, architecturally, little more than shantytowns. Investment in tools and infrastructure is too often inadequate. Tools are usually primitive, and infrastructure such as libraries and frameworks, is undercapitalized. Individual portions of the system grow unchecked, and the lack of infrastructure and architecture allows problems in one part of the system to erode and pollute adjacent portions. Deadlines loom like monsoons, and architectural elegance seems unattainable.
</p>
</blockquote>
<p>
2. <a href="http://www.laputan.org/mud/mud.html#ThrowAwayCode"><b>Throwaway Code</b></a><br>
(a.k.a. <i>Quick Hack, Kleenex Code, Disposable Code, Scripting, Killer Demo, Permanent Prototype, Boomtown</i>)
</p>
<p>
</p>
<blockquote>
A homeowner might erect a temporary storage shed or car port, with every intention of quickly tearing it down and replacing it with something more permanent. Such structures have a way of enduring indefinitely. The money expected to replace them might not become available. Or, once the new structure is constructed, the temptation to continue to use the old one for "a while" might be hard to resist.
<p>
<img alt="image placeholder" >
</p>
<p>
Likewise, when you are prototyping a system, you are not usually concerned with how elegant or efficient your code is. You know that you will only use it to prove a concept. Once the prototype is done, the code will be thrown away and written properly. As the time nears to demonstrate the prototype, the temptation to load it with impressive but utterly inefficient realizations of the system's expected eventual functionality can be hard to resist. Sometimes, this strategy can be a bit too successful. The client, rather than funding the next phase of the project, may slate the prototype itself for release.
</p>
</blockquote>
<p>
3. <a href="http://www.laputan.org/mud/mud.html#PiecemealGrowth"><b>Piecemeal Growth</b></a><br>
(a.k.a. <i>Urban Sprawl, Iterative-Incremental Development</i>)
</p>
<p>
</p>
<blockquote>
Urban planning has an uneven history of success. For instance, Washington D.C. was laid out according to a master plan designed by <a href="http://en.wikipedia.org/wiki/Pierre_Charles_L'Enfant">the French architect L'Enfant</a>. The capitals of Brazil (Brasilia) and Nigeria (Abuja) started as paper cities as well. Other cities, such as Houston, have grown without any overarching plan to guide them. Each approach has its problems. For instance, the radial street plans in L'Enfant's master plan become awkward past a certain distance from the center. The lack of any plan at all, on the other hand, leads to a patchwork of residential, commercial, and industrial areas that is dictated by the capricious interaction of local forces such as land ownership, capital, and zoning. Since concerns such as recreation, shopping close to homes, and noise and pollution away from homes are not brought directly into the mix, they are not adequately addressed.
<p>
<img alt="image placeholder" >
</p>
<p>
Most cities are more like Houston than Abuja. They may begin as settlements, subdivisions, docks, or railway stops. Maybe people were drawn by gold, or lumber, access to transportation, or empty land. As time goes on, certain settlements achieve a critical mass, and a positive feedback cycle ensues. The city's success draws tradesmen, merchants, doctors, and clergymen. The growing population is able to support infrastructure, governmental institutions, and police protection. These, in turn, draw more people. Different sections of town develop distinct identities. With few exceptions, (Salt Lake City comes to mind) the founders of these settlements never stopped to think that they were founding major cities. Their ambitions were usually more modest, and immediate.
</p>
</blockquote>
<p>
4. <a href="http://www.laputan.org/mud/mud.html#KeepItWorking"><b>Keep It Working</b></a><br>
(a.k.a. <i>Vitality, Baby Steps, Daily Build, First Do No Harm</i>)
</p>
<p>
</p>
<blockquote>
Once a city establishes its infrastructure, it is imperative that it be kept working. For example, if the sewers break, and aren't quickly repaired, the consequences can escalate from merely unpleasant to genuinely life threatening. People come to expect that they can rely on their public utilities being available 24 hours per day. They (rightfully) expect to be able to demand that an outage be treated as an emergency.
<p>
Software can be like this. Often a business becomes dependent upon the data driving it. Businesses have become critically dependent on their software and computing infrastructures. There are numerous mission critical systems that must be on-the-air twenty-four hours a day/seven days per week. If these systems go down, inventories can not be checked, employees can not be paid, aircraft cannot be routed, and so on.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
There may be times where taking a system down for a major overhaul can be justified, but usually, doing so is fraught with peril. However, once the system is brought back up, it is difficult to tell which from among a large collection of modifications might have caused a new problem. Every change is suspect. Deferring such integration is a recipe for misery.
</p>
</blockquote>
<p>
5. <a href="http://www.laputan.org/mud/mud.html#ShearingLayers"><b>Shearing Layers</b></a><br>
</p>
<p>
</p>
<blockquote>
The notion of SHEARING LAYERS is one of the centerpieces of Brand's <a href="http://www.amazon.com/exec/obidos/ASIN/0140139966/codihorr-20">How Buildings Learn</a>. Brand, in turn synthesized his ideas from a variety of sources, including British designer Frank Duffy, and ecologist R. V. O'Neill.
<p>
Brand quotes Duffy as saying: "Our basic argument is that there isn't any such thing as a building. A building properly conceived is several layers of longevity of built components".
</p>
<p>
Brand distilled Duffy's proposed layers into these six: Site, Structure, Skin, Services, Space Plan, and Stuff. Site is geographical setting. Structure is the load bearing elements, such as the foundation and skeleton. Skin is the exterior surface, such as siding and windows. Services are the circulatory and nervous systems of a building, such as its heating plant, wiring, and plumbing. The Space Plan includes walls, flooring, and ceilings. Stuff includes lamps, chairs, appliances, bulletin boards, and paintings.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
These layers change at different rates. Site, they say, is eternal. Structure may last from 30 to 300 years. Skin lasts for around 20 years, as it responds to the elements, and to the whims of fashion. Services succumb to wear and technical obsolescence more quickly, in 7 to 15 years. Commercial Space Plans may turn over every 3 years. Stuff is, like software, subject to unrelenting flux.
</p>
</blockquote>
<p>
6. <a href="http://www.laputan.org/mud/mud.html#SweepingItUnderTheRug"><b>Sweeping It Under The Rug</b></a><br>
(a.k.a. <i>Potemkin Village, Housecleaning, Pretty Face, Quarantine, Hiding it Under the Bed, Rehabilitation</i>)
</p>
<p>
</p>
<blockquote>
One of the most spectacular examples of sweeping a problem under the rug is the concrete sarcophagus that Soviet engineers constructed to put a 10,000 year lid on the infamous reactor number four at <a href="http://en.wikipedia.org/wiki/Chernobyl_disaster">Chernobyl</a>, in what is now Ukraine.
<p>
<img alt="image placeholder" >
</p>
<p>
If you can't make a mess go away, at least you can hide it. Urban renewal can begin by painting murals over graffiti and putting fences around abandoned property. Children often learn that a single heap in the closet is better than a scattered mess in the middle of the floor.
</p>
</blockquote>
<p>
7. <a href="http://www.laputan.org/mud/mud.html#Reconstruction"><b>Reconstruction</b></a><br>
(a.k.a. <i>Total Rewrite, Demolition, Plan to Throw One Away, Start Over</i>)
</p>
<p>
</p>
<blockquote>
Atlanta's Fulton County Stadium was built in 1966 to serve as the home of baseball's Atlanta Braves, and football's Atlanta Falcons. In August of 1997, the stadium was demolished. Two factors contributed to its relatively rapid obsolescence. One was that the architecture of the original stadium was incapable of accommodating the addition of the "sky-box" suites that the spreadsheets of ÃƒÂ¢Ã¢â€šÂ¬Ã‹Å“90s sporting economics demanded. No conceivable retrofit could accommodate this requirement. Addressing it meant starting over, from the ground up. The second was that the stadium's attempt to provide a cheap, general solution to the problem of providing a forum for both baseball and football audiences compromised the needs of both. In only thirty-one years, the balance among these forces had shifted decidedly. The facility is being replaced by two new single-purpose stadia.
<p>
<img alt="image placeholder" >
</p>
<p>
Might there be lessons for us about unexpected requirements and designing general components here?
</p>
</blockquote>
<p>
The first step in dealing with a problem is to <b>admit you have one</b>. If you catch glimpses of any of these themes in your current software project, I encourage you to <a href="http://www.laputan.org/mud/">read the relevant sections in the paper</a>, which goes into much more detail-- and provides ideas for remediation strategies.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-big-ball-of-mud-and-other-architectural-disasters/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What If They Gave a Browser War and Microsoft Never Came? ]]></title>
<link>https://blog.codinghorror.com/what-if-they-gave-a-browser-war-and-microsoft-never-came/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Two weeks ago, Apple announced <a href="http://webkit.org/blog/122/webkit-3-10-new-things/">a new version of WebKit</a>, the underlying rendering technology of their Safari web browser. The feature list is impressive:
</p>
<p>
</p>
<ul>
<li>Enhanced Rich Text Editing
</li>
<li>Faster JavaScript and DOM (~ 2x)
</li>
<li>Faster Page Loading
</li>
<li>
<a href="http://www.w3.org/Graphics/SVG/">SVG</a> support
</li>
<li>
<a href="http://www.w3.org/TR/xpath">XPath</a> support
</li>
<li>Improved JavaScript XML technology (<a href="http://www.xulplanet.com/references/objref/XSLTProcessor.html">XSLT</a>, <a href="http://developer.mozilla.org/en/docs/DOMParser">DOMParser</a>, <a href="http://developer.mozilla.org/en/docs/XMLSerializer">XMLSerializer</a>, and enhanced <a href="http://www.w3.org/TR/XMLHttpRequest/">XMLHttpRequest</a> support)
</li>
<li>Styleable form controls
</li>
<li>Additional advanced CSS support: 2.1, 3.0, and experimental.
</li>
<li>Reduced memory use (~14%)
</li>
<li>Web Developer Tools included
</li>
</ul>
<p>
That's a awfully compelling list of new features for an essential application I spend many, many hours a day in-- my web browser. Although <a href="http://www.apple.com/safari/download/">Safari on Windows</a> is little more than a glorified, feature-poor Mac emulator, the killer core WebKit feature list is enough to convince me to download it and run it through its paces. Apple is a serious competitor in the browser space.
</p>
<p>
Last week, <a href="http://www.mozilla.com/en-US/firefox/all-beta.html">the first Beta of Firefox 3.0</a> was released. I'm similarly impressed with <a href="http://www.mozilla.com/en-US/firefox/3.0b1/releasenotes/">the giant list of improvements and new features</a> in this browser, too. It appears to have some <a href="http://blog.mozilla.com/faaborg/2007/06/01/the-user-interface-of-firefox-3-features/">innovative changes to the UI</a>, along with native GUI rendering which was <a href="http://www.codinghorror.com/blog/archives/000789.html">one of my pet peeves</a> with previous versions of Firefox. Firefox has been a contender since version 1.5, and it looks like version 3.0 will push up their mindshare even further. Deservedly so. Firefox is great stuff, and the add-on ecosystem is second to none.
</p>
<p>
Clearly, <b>the browser wars are heating up to a level we haven't seen since the heady bubble days of the late 90's</b>. That's good news for everyone who uses the web. Nothing drives innovation quite like competition.
</p>
<p>
Given the level of fierce competition out there now, Microsoft must have some really <i>killer</i> features up their sleeves for Internet Explorer 8, right?
</p>
<p>
(Pretend that I've inserted the sound of gently chirping crickets here.)
</p>
<p>
<b>Microsoft hasn't released <i>any</i> information on Internet Explorer 8</b>. None. Nada. Zilch. Believe me, <a href="http://blog.seattlepi.nwsource.com/microsoft/archives/114747.asp">I've tried to pry it out of them</a>:
</p>
<p>
</p>
<blockquote>
During a session at Mix today, attendee Jeff Atwood asked Internet Explorer platform architect <a href="http://blogs.msdn.com/cwilso/">Chris Wilson</a> for more information about when it might be released. The five-year gap between IE 6 and IE 7 notwithstanding, Atwood noted that people have come to expect a new version of a browser every couple of years. He asked whether the next IE would come with the next Windows version or before then -- "out of band," as they say.
<p>
Wilson reiterated Microsoft's promise that it will never again go five years "without an upgrade to the platform." He noted that the company was suggesting a 12- to 18-month development cycle at last year's Mix conference. "There's no exact date," he said, adding later, "I think that your expectation of having a new browser platform every couple of years is definitely a valid one."
</p>
</blockquote>
<p>
Chris is an extremely nice guy, and clearly very technically competent. I'm sure he's under some kind of bizarre corporate gag order to say nothing. But how, exactly, does silence help the massive audience of people who use Internet Explorer on a daily basis? We're all left wondering-- <b>what if they gave a browser war, and Microsoft never came?</b><a href="http://ask.metafilter.com/56968/What-if">*</a>
</p>
<p>
<a href="http://www3.iath.virginia.edu/sixties/HTML_docs/Exhibits/Track16.html"><img alt="image placeholder" >
</p>
<p>
IE 6 <i>was</i> a great browser-- in 2001. By 2005, not so much. IE 7 was a critical stopgap, because <a href="http://www.codinghorror.com/blog/archives/000242.html">IE 6 devolved into Netscape 4.7x</a> during the five years it was the latest and greatest and only version.  So consider the history. <a href="http://www.codinghorror.com/blog/archives/000606.html">The entire world was trapped in an abusive relationship with Microsoft</a> for that long, dark five year period. <b>I think we'd like-- no, I think we <i>deserve</i>-- some assurances that this abusive cycle will not repeat itself.</b>
</p>
<p>
My friend and colleague, <a href="http://weblogs.asp.net/jgalloway/">Jon Galloway</a>, said it best in a <a href="http://twitter.com/jongalloway/statuses/427564752">recent twitter update</a>:
</p>
<p>
</p>
<blockquote>
Just about every "Microsoft doesn't get it" problem boils down to long and secretive development cycles. Where's the IE 8 CTP?
</blockquote>
<p>
Exactly. I don't think there's a more important single application on the planet right now than the web browser. If they can't get this right-- and soon-- I'm not sure there's any hope left.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/what-if-they-gave-a-browser-war-and-microsoft-never-came/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Mort, Elvis, Einstein, and You ]]></title>
<link>https://blog.codinghorror.com/mort-elvis-einstein-and-you/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Earlier this week I wrote about <a href="http://www.codinghorror.com/blog/archives/001002.html">The Two Types of Programmers</a>. Based on the huge number of comments, it seemed to strike a nerve. Or two. This surprised me, because it was never meant to be the inflammatory, provocative diatribe that many people interpreted it as. It got so out of hand that Ben Collins-Sussman, the original author of the post I quoted, was <a href="http://blog.red-bean.com/sussman/?p=82">driven to post a followup clarifying his original post</a>.</p>
<p>Many of the commenters were offended that I somehow lumped them into a vast unwashed eighty-percent sea of vocational programmers. Here's what's particularly ironic: <b>the very act of commenting on an article about software development automatically means you're <i>not</i> a vocational eighty-percenter</b>. Trust me. I absolutely <a href="http://secretgeek.net/inadequate.asp">was not calling any of my readers inadequate</a>. I don't say that because I'm a world class suckup; my blog isn't some kind of special case or even particularly good. I say it because if you're reading <i>any</i> programming blog whatsoever, you're demonstrated a willingness to improve your skills and learn more about your chosen profession.</p>
<p>Thus, if you read the article, you are most assuredly in the twenty percent category. <b>The other eighty percent are not actively thinking about the craft of software development.</b> They would never find that piece, much less <i>read</i> it. They simply don't read programming blogs – other than as the result of web searches to find quick-fix answers to a specific problem they're having. Nor have they read any of the books in my <a href="http://www.codinghorror.com/blog/archives/000020.html">recommended reading list</a>. The defining characteristic of the vast majority of these so-called "vocational" programmers is that <i>they are unreachable</i>. It doesn't matter what you, I or anyone else writes here – they'll never see it.</p>
<p>The problem isn't the other 80%. The problem is that <i>we're</i> stuck inside our own insular little 20% world, and <i>we</i> forget that there's a very large group of programmers we have almost no influence over. Very little we do will make any difference outside our relatively small group. The problem, as I obviously failed to make clear in the post, is figuring out <b>how to reach the unreachable</b>. That's how you make lasting and permanent changes in the craft of software development. Not by catering to the elite – these people take care of themselves – but by reaching out to the majority of everyday programmers.</p>
<p>That was my point. I'm sorry I did such a bad job of communicating it. But on the plus side, at least it got people thinking and talking about the issue.</p>
<p>Some people objected to the very idea of categorizing programmers into groups of any kind. But there's a rich history of doing exactly that, with interesting and sometimes unintended consequences. In early 2004, Nikhil Kothari <a href="https://web.archive.org/web/20080218051638/http://www.nikhilk.net/Personas.aspx">wrote about three personas</a> Microsoft came up with while working on Visual Studio 2005.</p>
<blockquote>
<p>We have three primary personas across the developer division: Mort, Elvis and Einstein.</p>
<p><b>Mort</b>, the opportunistic developer, likes to create quick-working solutions for immediate problems. He focuses on productivity and learns as needed.</p>
<img alt="image placeholder" >
<p><b>Elvis</b>, the pragmatic programmer, likes to create long-lasting solutions addressing the problem domain, and learning while working on the solution.</p>
<img alt="image placeholder" >
<p><b>Einstein</b>, the paranoid programmer, likes to create the most efficient solution to a given problem, and typically learn in advance before working on the solution.</p>
<img alt="image placeholder" >
<p>These personas helped guide the design of features during the Visual Studio 2005 product cycle.</p>
<p>The description above is only a rough summarization of several characteristics collected and documented by our usability folks. During the meeting, a program manager on our team applied these personas in the context of server controls rather well:</p>
<ul>
<li>
<b>Mort</b> would be a developer most comfortable and satisfied if the control could be used as-is and it just worked.</li>
<li>
<b>Elvis</b> would like to able to customize the control to get the desired behavior through properties and code, or be willing to wire up multiple controls together.</li>
<li>
<b>Einstein</b> would love to be able to deeply understand the control implementation, and want to be able to extend it to give it different behavior, or go so far as to re-implement it.</li>
</ul>
</blockquote>
<p>I can't quite date exactly when these personas came to exist at Microsoft. Wesner Moise has <a href="http://wesnerm.blogs.com/net_undocumented/2003/09/who_are_you_mor.html">an even earlier reference to these personas</a>, wherein he amusingly refers to himself as "used to be an Einstein." Wes, old buddy, I'm afraid you're the archetypal Einstein, no matter how much you might think otherwise.</p>
<p>These personas have been controversial for <i>years</i>; they've sparked a <a href="http://www.hanselman.com/blog/BeyondElvisEinsteinAndMortNewProgrammingStereotypesForWeb20.aspx">lot</a> of <a href="http://blogs.msdn.com/ericlippert/archive/2004/03/02/cargo-cultists-part-three-is-mort-a-cargo-cultist.aspx">intense discussion</a>. Evidently <a href="http://codebetter.com/blogs/scott.bellware/archive/2006/04/25/143303.aspx">there's a fine line between "persona" and "stereotype"</a>:</p>
<blockquote>
<p>The Microsoft developer personas that include Mort, Elvis, and Einstein are ultimately an ethically bankrupt mechanism to pigeonhole software developers into the kind of overly simplified categories that a typical marketing staffer is comfortable with. While intended to help this particular parasitic segment of the corporate world to behaviorally model the psychological predispositions of software developers at their work in an unrealistically simple way, it has instead turned into a system of limitations that developers have begun to impose upon themselves to the detriment of the advancement of software development practice and industry. It appears to be a bid by developers to rid themselves of the capacity for rational thought in favor of tribal identification with corporate brands and software rock stars.</p>
</blockquote>
<p>Personas, in and of themselves, are not a bad thing. I've written before about <a href="http://www.codinghorror.com/blog/archives/000239.html">the importance of API usability</a>, and personas let you get a leg up on usability by considering the different audiences that will be using your code.</p>
<p>But I can empathize. <b>As a long time Visual Basic and VB.NET developer by trade, I truly resented being lumped in with Mort</b>. I'm not just some clock-punching <a href="http://blogs.vertigosoftware.com/jatwood/archive/2006/07/25/Code_Monkey_very_simple_man.aspx">code monkey</a> – I actually <i>care</i> about the craft of software development. So what if I happen to write code in a language that doesn't <a href="http://www.codinghorror.com/blog/archives/000458.html">brutalize me with case sensitivity</a> and curly-bracket megalomania? My language choice is ultimately no more meaningful than <a href="http://www.codinghorror.com/blog/archives/000519.html">the choice between caffeinated cola beverages</a>, so it's an illusory difference at that.</p>
<p>Paul Vick works on the VB language team at Microsoft and he <a href="http://www.panopticoncentral.net/archive/2006/04/26/11851.aspx">echoes some of my concerns</a>:</p>
<blockquote>
<p>The fundamental error I think most people make with the personas is that they see them as mutually exclusive rather than points along the experience spectrum. When I'm working on the VB compiler, I'm definitely an Einstein, thinking at a very high level. When I'm working on stuff like the VBParser sample, I'm generally an Elvis, thinking at a somewhat lower level. And when I'm writing batch scripts or ad-hoc data analysis tools, I'm definitely a Mort, hacking around to figure out what I'm trying to do.</p>
<p><b>The point really is that most people are usually Mort, Elvis and Einstein all at the same time, depending on what they're doing.</b> And by building tools that target one or the other, we're artificially segregating people's work into buckets that don't really map onto their daily lives. (I would also argue that the past several releases of Visual Studio has emphasized some personas over others.) Finding a way to better serve people as they move through the flow of the day-to-day work is something that is need of some serious attention.</p>
</blockquote>
<p>Mort, like the twenty percent analogy Ben originally came up with, is more than a persona or a stereotype. It's <a href="https://web.archive.org/web/20120421233245/http://haacked.com/archive/2005/08/03/DoesMortKnowWeAreTalkingSmackAboutHimBehindHisBack.aspx">a call to action</a>.</p>
<blockquote>
<p><b>I think the solution is to quit pandering to Mort with our condescending paternalistic attitude, and instead demand better from Mort.</b> If the capabilities of the average developer truly is as bleak as many make it out to be, we shouldn't just accept it, but work to raise the quality of the average developer. "Average developer" should describe an acceptable level of competence.</p>
<p>We have to realize that Mort is responsible for a lot of important systems. Systems that affect the general population. When I hear of recent cases of identity thefts at Choicepoint, especially those caused by lax security such as using default passwords for the database, I think of Mort. When I read that $250 million worth of taxpayer money has gone into an overhaul of the FBI Case File system, and the system has to be scrapped, I think of Mort.</p>
<p>Given this much responsibility, we should expect more from Mort. So Mort, I hate to say this, but software development is not like working the register at McDonalds where putting in your 9 to 5 is enough. I am all for work-life balance, but you have to understand that software development is an incredibly challenging field, requiring intense concentration and strong mental faculty. It's time for you to attend a conference or two to improve your skills. It's time for you to subscribe to a few blogs and read a few more books. But read deeper books than How to program the VCR in 21 days. For example, read a book on Design Patterns or Refactoring. Mort, I am afraid it's time for you to quit coasting. It's time for you to step it up a notch.</p>
</blockquote>
<p>I firmly believe it is our job to <b>leave the craft of software development better than we found it</b>. If you're anything like me, you wrote horrible code when you started out as a fledgling programmer, too. But through concerted effort and practice, I was determined to <a href="http://www.codinghorror.com/blog/archives/000530.html">suck less every year</a>. I'll admit this is sort of painful, because us programmers <a href="http://www.codinghorror.com/blog/archives/000890.html">aren't exactly known for our people skills</a>. But we owe it to our craft – and to ourselves – to reach out and help our fellow programmers, at least in some small way.</p>
<p>Being a professional programmer is more than just writing great code. Being a professional programmer means helping <i>other</i> programmers become professionals, too. We're all in this thing together. Not everyone can be reached. But some can.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-11-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/mort-elvis-einstein-and-you/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Presentation: Be Vain ]]></title>
<link>https://blog.codinghorror.com/presentation-be-vain/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://fretsonfire.sourceforge.net/">Frets on Fire</a> is an open source clone of <a href="http://en.wikipedia.org/wiki/Guitar_Hero">Guitar Hero</a>. It's a great idea. Think of all the user-created songs we could play! My excitement quickly faded after I downloaded it and tried it out.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I'll be first in line to champion gameplay over graphics, but the presentation in Frets on Fire is <i>so</i> bare-bones, <i>so</i> rudimentary that it's hard to muster any enthusiasm for the game whatsoever. Even equipped with <a href="http://img520.imageshack.us/img520/874/rainingbloodguitarxplorpm0.jpg">a nice plastic USB guitar</a>, there's only so much rocking you can do when you're staring at the loose OpenGL equivalent of <a href="http://www.loonygames.com/content/1.28/feat/">a completely ASCII interface</a>. It is <i>incredibly</i> primitive.
</p>
<p>
For comparison, here's a screenshot I captured of <a href="http://www.amazon.com/exec/obidos/ASIN/B000W5UNLY/codihorr-20">Guitar Hero III</a> running on my PC.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
These rhythm games are <b>functionally identical</b>. Press some combination of the five colored buttons on the USB plastic guitar and strum in time to the pre-recorded music. It's <a href="http://www.news.com/Is-tomorrows-Clapton-playing-Guitar-Hero/2100-1043_3-6220398.html">hardly guitar practice</a>, but it is a fun new way to enjoy the music you already love.
</p>
<p>
Based on these screenshots, <i>which fake plastic guitar rhythm game would you rather play?</i>
</p>
<p>
Despite the universe of modding and custom songs possible with Frets on Fire, I'd much rather spend my time hacking new songs into the PC version of Guitar Hero III, even with the additional reverse engineering hurdles. The lesson I take from this is that <b>presentation matters</b>.
</p>
<p>
Of course, this comparison is grossly unfair to Frets on Fire. It is <a href="http://fretsonfire.sourceforge.net/documentation/source/">open source and completely free</a> -- whereas the <a href="http://www.amazon.com/exec/obidos/ASIN/B000W5UNLY/codihorr-20">Mac and PC version of Guitar Hero III</a> costs $79.99 bundled with the guitar. There's a commercial army of artists, developers, and producers behind Guitar Hero III. It's unreasonable to expect Frets on Fire to have the same production values. I'm not exactly going to march over to the SourceForge page and demand my money back or anything. I applaud what they've done.
</p>
<p>
But playing Frets on Fire makes me feel like a keyboard jockey instead of a rock god. This isn't just a personal deficiency of mine-- it's a presentation problem with real world ramifications. Better presentation would win many converts to the Frets on Fire camp, and woo them away from the alternatives. <b>I think this presentation rule applies to <i>all</i> software.</b> If you want people to get excited about your software, you have to make it look reasonably good, <a href="http://www.joelonsoftware.com/articles/fog0000000356.html">as Joel Spolsky points out</a>:
</p>
<p>
</p>
<blockquote>
I learned this lesson as a consultant, when I did a demo of a major web-based project for a client's executive team. The project was almost 100% code complete. We were still waiting for the graphic designer to choose fonts and colors and draw the cool 3-D tabs. In the meantime, we just used plain fonts and black and white, there was a bunch of ugly wasted space on the screen, basically it didn't look very good at all. But 100% of the functionality was there and was doing some pretty amazing stuff.
<p>
What happened during the demo? The clients spent the entire meeting griping about the graphical appearance of the screen. They weren't even talking about the UI. Just the graphical appearance. "It just doesn't look slick," complained their project manager. That's all they could think about. We couldn't get them to think about the actual functionality. Obviously fixing the graphic design took about one day. It was almost as if they thought they had hired painters.
</p>
</blockquote>
<p>
I'd argue that presentation <a href="http://www.nytimes.com/2003/11/30/magazine/30IPOD.html?ei=5007&amp;en=750c9021e58923d5&amp;ex=1386133200">cuts a little deeper</a> than Joel is insinuating:
</p>
<p>
</p>
<blockquote>
''Most people make the mistake of thinking design is what it looks like,'' says Steve Jobs, Apple's C.E.O. ''People think it's this veneer -- that the designers are handed this box and told, 'Make it look good!' That's not what we think design is. It's not just what it looks like and feels like. Design is how it works.''
</blockquote>
<p>
Avoid creating software that's beautiful on the inside but ugly on the outside. <b>Be vain. Make something that looks as good as it works.</b> If you pay attention to the presentation of your software, you just may find the rest of the world is a lot more willing to pay attention, too.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/presentation-be-vain/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Shuffling ]]></title>
<link>https://blog.codinghorror.com/shuffling/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Pop quiz, hotshot. <strong>How would you write code to shuffle a deck of cards?</strong></p>
<p><img alt="image placeholder" >
<p>I was thinking about this after reading <a href="http://www.mikepope.com/blog/AddComment.aspx?blogid=1851">Mike's card-shuffling algorithm woes</a>:</p>
<blockquote>Here's where the non-CS mind comes into play. My first thought was to generate an unshuffled deck as an array-like structure -- all cards in order by suit. Then I'd create a second array-like structure. I'd walk through each card in the unshuffled deck, pick a random number, and insert the card at the randomly selected spot in the second array. If the randomly chosen position in the second array was already occupied, I'd choose another random number, see if it was used, and so on until the random selection happened to land on a free spot. I'll call this the Random Insert approach.</blockquote>
<p>It seemed an odd approach to me, but unlike Mike, I have the dubious benefit of a programming background. I went immediately for my old friend, the loop. Let's assume we have an array with 52 members representing the 52 cards in the deck.</p>
<pre>var rand = new Random();
for (int i = cards.Length - 1; i &gt; 0; i--)
{
int n = rand.Next(i + 1);
int temp = cards[i];
cards[i] = cards[n];
cards[n] = temp;
}
</pre>
<p>So we loop through the deck, switching each card with another card from a random position in the deck. Seems straightforward enough, although I do wish there was a built in Swap command in the C# language to simplify the code a bit. It's eerily similar to <a href="http://en.wikipedia.org/wiki/Knuth_shuffle">the Knuth or Fisher-Yates shuffle</a>, which doesn't mean I'm particularly smart, but that shuffling is an easily solved problem.</p>
<p>Or is it? This <em>looks</em> correct; there's nothing obviously wrong here. But <strong>there are two problems with this code</strong>. Can you see them?</p>
<p>The first problem is right here:</p>
<pre>new Random();
</pre>
<p><a href="http://www.codinghorror.com/blog/archives/000728.html">Computers are lousy random number generators</a>. <strong>Any shuffling you do, whatever the algorithm, will only be as good as your random number generator.</strong> So if you're running, say, an online casino, you need to be <a href="http://en.wikipedia.org/wiki/Knuth_shuffle#Potential_sources_of_bias">very careful</a> when you start throwing around the word "Random" in your code. If you aren't careful, <a href="http://www.ibm.com/developerworks/library/s-playing/">there will be.. problems</a>.</p>
<blockquote>The flaw exists in the card shuffling algorithm used to generate each deck. Ironically, the code was publicly displayed at www.planetpoker.com/ppfaq.htm with the idea of showing how fair the game is to interested players (the relevant question has since been removed). In the code, a call to randomize() is included to produce a random deck before each deck is generated. The implementation, built with Delphi 4 (a Pascal IDE), seeds the random number generator with the number of milliseconds since midnight according to the system clock. That means the output of the random number generator is easily predicted. A predictable "random number generator" is a very serious security problem.
<p>By synchronizing our clock with the clock on the online casino and hitting the "shuffle" button, our program can calculate the exact shuffle. That means we know all the cards that have yet to appear, everyone's hand, and who will win. The screen shot below shows the information displayed by our program in realtime during an actual game. Our program knows what cards are to appear <em>in advance</em>, before they are revealed by the online game.</p>
</blockquote>
<p>To be fair, this was 1999. I'd assume most online casinos have hired competent cryptographers and statisticians by now. With the ever looming specter of <a href="http://freakonomics.blogs.nytimes.com/2007/09/20/how-not-to-cheat/">insider cheating</a> and <a href="http://www.codinghorror.com/blog/archives/000374.html">poker bots</a>, they'd be fools not to.</p>
<p>The second problem with this code is that <strong>it's too complicated</strong>. Eric <a href="http://www.codinghorror.com/blog/archives/000750.html">"purplicious"</a> Lippert explains why, in his own inimitable way:</p>
<blockquote>The standard way of implementing this algorithm is: associate each card with a random real number between 0.0 and 1.0. Sort the list based on its associated number. That's O(n log n) and has no bias.</blockquote>
<p>As it turns out, <a href="http://www.secureprogramming.com/?action=view&amp;feature=recipes&amp;recipeid=23">the easiest way to implement a shuffle is by sorting</a>. It's not exactly <em>faster</em>, as <a href="http://www.codinghorror.com/blog/archives/000957.html">the typical sort</a> is O(n log n) compared to the O(n) of the Knuth Fisher-Yates shuffle algorithm. We'll just sort by a random number-- in this case, a <a href="http://en.wikipedia.org/wiki/Globally_Unique_Identifier">GUID</a>.</p>
<pre>var cards = Enumerable.Range(0, 51);
var shuffledcards = cards.OrderBy(a =&gt; Guid.NewGuid());
</pre>
<p>So we can ultimately implement a secure, unbiased shuffle as a one-liner in a modern programming language.</p>
<p>Which proves.. well, nothing, I suppose, but like so many other programming problems, there are a lot of ways to get shuffling wrong if you're not careful.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/shuffling/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Please Don't Steal My Focus ]]></title>
<link>https://blog.codinghorror.com/please-dont-steal-my-focus/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Has this ever happened to you? You're merrily typing away in some application, minding your own business, when-- suddenly-- <b>a dialog pops up and steals the focus from you</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
At best, your flow is interrupted. You'll have to switch back to the window that you were using, figure out where you were, and resume your work.
</p>
<p>
But it can be worse. So, so much worse. If you happen to be typing something that can be interpreted as an action by that dialog-- and remember, pressing the space bar is the same as clicking a button when it happens to have the focus -- you could suddenly and very much accidentally be in a world of pain. Like this poor, unfortunate soul, who recently <a href="http://www.codinghorror.com/blog/archives/000294.html">posted a plaintive comment to my XP Automatic Update Nagging post</a>.
</p>
<p>
</p>
<blockquote>
Great news! Microsoft developed a solution to this problem! Microsoft's most talented programmer figured out how to make "Reboot later" mean "Reboot when user says reboot". It only took some tweaking to 1 line of code, 180 days for approvals from 80 managers, 80 resource files for different languages, and 18 days for testing in one of the languages. It worked.
<p>
The programmer opened a SourceSafe^H^H^H^H^H^H^H^H^H^H^H Team Foundation window in order to check in the fix. An expert programmer, she was used to using the keyboard. She didn't click her mouse on the "OK" button, she just hit the Enter key.
</p>
<p>
<b>The "Reboot now" / "Reboot later" prompt flashed so briefly, she didn't even notice it. She thought she hadn't pounded the Enter key hard enough.</b> Looking at Team Foundation's "OK" button still waiting there for her to hit the Enter key to check in her work, she hit the Enter key again.
</p>
<p>
The check in started. The check in got killed while her workstation rebooted. There we remain today, with the check in half-in and half-out, unusable, with no good copy of the code. So that's why the fix was never released.
</p>
</blockquote>
<p>
It's a perfect example of how <b>stealing the user's focus can lead to catastrophic results</b> if the user is particularly unlucky. Unfortunately, this burden falls heaviest on us keyboarders.
</p>
<p>
Another classic example is the IE download notification window, which loves to pop up, steal the focus, and tell you the great news: your download is complete! Oh, and your newly downloaded file is copying to its destination! Hooray! Unfortunately, this very same download notification dialog <i>also</i> contains a "Cancel" button. Guess which button just so happens to have the focus when this pops up? Why you'd want to cancel a download after it is complete is a mystery to me, but I've inadvertently pressed the space bar on this dialog more than once.
</p>
<p>
<b>Stealing focus from the user is never acceptable</b>. I can't imagine any circumstance where this would be desirable or even defensible behavior. Modal dialogs <a href="http://www.codinghorror.com/blog/archives/000019.html">are bad enough</a>, but this is even worse-- it's almost a system modal dialog, so self-important that all work must cease as the user is forced to pay attention to whatever earth-shattering message it urgently has to deliver. It's an extreme form of <a href="http://www.codinghorror.com/blog/archives/000676.html">stopping the proceedings with idiocy</a>. I'm not the first person to complain about this, of course. Fellow members of the "Don't Steal My Focus" club <a href="http://radio.weblogs.com/0103807/stories/2002/06/07/dontStealMyFocus.html">wrote about this back in 2002</a>, <a href="http://useful-sounds.de/pivot/entry.php?id=102">again in 2005</a>, and <a href="http://www.rafb.net/cohen/blog/2007/08/30/stealing-focus/">a few months ago</a>. It's not exactly an unknown or new problem. So why do we have to keep talking about it and dealing with it? What gives?
</p>
<p>
The strange thing is, there are provisions built into the operating system to protect us from badly written, focus stealing applications. The <a href="http://www.microsoft.com/technet/prodtechnol/windows2000serv/reskit/regentry/55200.mspx?mfr=true">ForegroundLockTimeout registry setting</a> is <i>expressly designed</i> to prevent applications from stealing focus from the user. The OS silently converts that inappropriate focus stealing behavior into friendlier, less invasive taskbar button flashing, which is the subject of the <a href="http://www.microsoft.com/technet/prodtechnol/windows2000serv/reskit/regentry/55200.mspx?mfr=true">ForegroundFlashCount registry setting</a>.
</p>
<p>
I've seen this work. Most of the time, it <i>does</i> work. This setting is enabled by default in Windows XP and Vista. And yet, applications are occasionally able to steal the focus from me and screw up my flow. I'd say it happens a few times a week on average. It's perplexing. I'm wondering if it's because badly behaved programmers abuse the "Always on Top" window flag in a <a href="http://blogs.msdn.com/oldnewthing/archive/2006/12/19/1325024.aspx">misguided attempt to get the user's attention</a>. I suppose as long as there are bad programmers, there will be some unorthodox way they can devise to steal the focus from the user. At some level, sufficiently advanced incompetence is indistinguishable from malice. Maybe we'd have better luck educating programmers on the evils of focus stealing and, more generally, the futility of <a href="http://jcooney.net/archive/2007/09/12/54550.aspx">unnecessary notifications the user isn't going to read anyway</a>.
</p>
<p>
But in the meantime, <b>please don't steal my focus</b>. I'm using it right now. Really. I am.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/please-dont-steal-my-focus/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Sharing The Customer's Pain ]]></title>
<link>https://blog.codinghorror.com/sharing-the-customers-pain/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In this <a href="http://www.acmqueue.com/modules.php?name=Content&amp;pa=showpage&amp;pid=388&amp;page=1">interview with Werner Vogels</a>, the CTO of Amazon, he outlines how Amazon's developers stay in touch with their users:
</p>
<p>
</p>
<blockquote>
Remember that most of our developers are in the loop with customers, so they have a rather good understanding about what our customers like, what they do not like, and what is still missing.
<p>
We have a lot of feedback coming out of customer service. <b>Many Amazonians have to spend some time with customer service every two years, actually listening to customer service calls, answering customer service e-mails, really understanding the impact of the kinds of things they do as technologists.</b> This is extremely useful, because they begin to understand that our user base is not necessarily the techno-literate engineer. Rather, you may get a call from a grandma in front of a computer in a library who says she wants to buy something for her grandson who is at college and who has a Wishlist on Amazon.
</p>
<p>
Customer service statistics are also an early indicator if we are doing something wrong, or what the real pain points are for our customers. Sometimes in meetings we use a "voice of the customer," which is a realistic story from a customer about some specific part of the Amazon experience. This helps managers and engineers to connect with the fact that we build many of these technologies for real people.
</p>
</blockquote>
<p>
It's easy to fall into <a href="http://www.codinghorror.com/blog/archives/000206.html">a pattern of ivory tower software development</a>. All too often, software developers are merely tourists in their own codebase. Sure, they <i>write</i> the code, but they don't <i>use it</i> on a regular basis like their customers do. They will visit from time to time, but they lack the perspective and understanding of users who -- either by choice or by corporate mandate-- live in that software as a part of their daily routine. As a result, problems and concerns are hard to communicate. They arrive as dimly heard messages from a faraway land.
</p>
<p>
<b>When was the last time you even <i>met</i> a customer</b>, much less tried to talk to them about a problem they're having with your website or software?
</p>
<p>
It's incredibly important for developers to be in the trenches with the customers-- the people who have to live with their code. Without a basic understanding of your users and customers, it's impossible to build <a href="http://www.codinghorror.com/blog/archives/000550.html">considerate software</a>. And nothing builds perspective like being on the front lines of support. I'm not proposing that all programmers pull double duty as support. It'd be impossible to get any work done. But a brief rotation through support would do wonders for the resulting quality and usability of your software, exactly as described by Mr. Vogels.
</p>
<p>
<a href="http://www.codinghorror.com/blog/archives/000287.html">Dogfooding</a> can be difficult. But manning the support desk, if only for a short while, isn't. <b>Software developers should share the customer's pain.</b> I know it's not glamorous. But until you've demonstrated a willingness to help the customers using the software you've built-- and more importantly, learn <i>why</i> they need help-- you haven't truly finished building that software.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/sharing-the-customers-pain/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Hashtables, Pigeonholes, and Birthdays ]]></title>
<link>https://blog.codinghorror.com/hashtables-pigeonholes-and-birthdays/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the most beloved of all data structures in computer science is the <a href="http://en.wikipedia.org/wiki/Hash_table">hash table</a>.
</p>
<p>
</p>
<blockquote>
A hash table is a data structure that associates keys with values. The primary operation it supports efficiently is a lookup: given a key (e.g. a person's name), find the corresponding value (e.g. that person's telephone number). It works by transforming the key using a hash function into a hash, a number that is used to index into an array to locate the desired location ("bucket") where the values should be.
</blockquote>
<p>
Key-value pairs are quite common in real world data, and hashtables are both reasonably efficient in storage and quite fast at lookups, offering O(1) performance in most cases. That's why hashtables are the go-to data structure for many programmers. It may not be the optimal choice, but unlike so many things in computer science, it's rarely a <i>bad</i> choice.
</p>
<p>
But hash tables do have one crucial weakness: <b>they are only as good as the hash function driving them</b>. As we add each new item to the hashtable, we compute a hash value from the key for that item, and drop the item in the bucket represented by that hash value. So how many buckets do we need? Let's consider the extremes:
</p>
<p>
</p>
<ul>
<li>If we had <b>one giant bucket</b>, everything would get piled in together. We'd have to look at each and every item in our one bucket to find the one we want, which reduces us to worst-case performance: an O(n) linear search.
<p>
</p>
</li>
<li>If we had <b>exactly the same number of buckets as items</b>, each item is placed in its own unique, individual bucket. We know each bucket will contain one, and <i>only</i> one, item. That's a perfect hash function, delivering best-case performance: an O(1) lookup.
</li>
</ul>
<p>
Reality, of course, lies somewhere in between these two extremes. The choice of hash function is critical, so you don't end up with a bucket shortage. As you place more and more items in each bucket (ie, "collisions") you edge closer to the slow O(n) end of the performance spectrum.
</p>
<p>
There's something magical about these hash functions that drive the hashtable. The idea of the hash as a <a href="http://haacked.com/archive/2007/01/22/Identicons_as_Visual_Fingerprints.aspx">unique digital fingerprint</a> for every chunk of data in the entire world is a fascinating one. It's a fingerprint that cleverly fits into a mere 32 bits of storage, yet is somehow able to uniquely identify any set of data ever created.
</p>
<p>
Of course, <b>this is a lie</b>, for several reasons. Let's start with the most obvious one. Consider all possible values of a 32-bit hash function:
</p>
<p>
2<sup>32</sup> ~= 4.3 billion
</p>
<p>
The current population of the earth is about 6.6 billion people. If we were to apply a <i>perfect</i> 32-bit hash function to the DNA of every man, woman, and child on the planet, we could not guarantee uniqueness-- <b>we simply don't have enough possible hash values to represent them all!</b>
</p>
<p>
This is known as the <a href="http://en.wikipedia.org/wiki/Pigeonhole_principle">pigeonhole principle</a>. It's not complicated. If you try to put 6 pigeons in 5 holes, one will inevitably be left out in the cold.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You'll definitely want to <b>use a large enough hash value</b> so you can avoid the pigeonhole principle. How much you care about this depends on how many things you're planning to store in your hashtable, naturally.
</p>
<p>
The other reason hashes can fail as digital fingerprints is because <b>collisions are a lot more likely than most people realize</b>. The <a href="http://en.wikipedia.org/wiki/Birthday_paradox">birthday paradox</a> illustrates how quickly you can run into collision problems for small hash values. I distinctly remember the birthday paradox from <a href="http://www.virginia.edu/">my college</a> calculus class, and I'll pose you the same question our TA asked us:
</p>
<p>
</p>
<blockquote>
In a typical classroom of 30 students, what are the odds that two of the students will have the same birthday?
</blockquote>
<p>
Don't read any further until you've taken a guess. What's your answer?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Everyone has completely unique DNA, but shares one of 365* possible birthdays with the rest of us. <b>Birthdays are effectively a tiny 365 value hash function.</b> Using such a small hash value, there's a 50% chance of two people sharing the same birthday after a mere <i>23 people</i>. With the 30 students in our hypothetical classroom, the odds of two students having a shared birthday rise to 70%. The statistics don't lie: when the question was posed in that classroom so many years ago, there were in fact two students who shared the same birthday.
</p>
<p>
A rule of thumb for estimating the number of values you need to enter in a hashtable before you have a 50 percent chance of an existing collision is to take the square root of 1.4 times the number of possible hash values.
</p>
<p>
</p>
<pre>
SQRT(1.4 * 365) = 23
SQRT(1.4 * 2<sup>32</sup>) = 77,543
</pre>
<p>
When using a 32-bit hash value, we have a 50% chance that a collision exists after about 77 thousand entries-- a pretty far cry from the 4 billion possible values we could store in that 32-bit value. This is not a big deal for a hashtable; so what if a few of our buckets have more than one item? But it's a huge problem if you're relying on the hash as a unique digital fingerprint.
</p>
<p>
The hashing functions behind our precious hashtables may be a lie. <b>But they're a <i>convenient</i> lie.</b> They work. Just keep the pigeonhole principle and the birthday paradox in mind as you're using them, and you'll do fine.
</p>
<p>
* No, let's forget leap years for now. And other variables like birth patterns. Yes, I know this is how programmers think. Imagine how much it would suck to have one birthday every four years, though. Ouch.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/hashtables-pigeonholes-and-birthdays/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Danger of Naïveté ]]></title>
<link>https://blog.codinghorror.com/the-danger-of-naivete/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In my <a href="http://www.codinghorror.com/blog/archives/001008.html?r=31644">previous post on shuffling</a>, I glossed over something very important. The very first thing that came to mind for a shuffle algorithm is this:</p>
<pre>for (int i = 0; i &lt; cards.Length; i++)
{
  int n = rand.Next(cards.Length);
  Swap(ref cards[i], ref cards[n]);
}
</pre>
<p>It's a nice, simple solution to the shuffling problem:</p>
<ol>
<li>Loop through each card in the deck. </li>
<li>Swap the current card with another randomly chosen card. </li>
</ol>
<p>At first blush, this seems like a perfectly reasonable way to shuffle. It's simple, it's straightforward, and the output looks correct. It's the very <em>definition</em> of a <a href="http://en.wikipedia.org/wiki/Na%C3%AFve_algorithm">naïve algorithm</a>:</p>
<blockquote>A naïve algorithm is a very simple solution to a problem. It is meant to describe a suboptimal algorithm compared to a "clever" (but less simple) algorithm. Naïve algorithms usually consume larger amounts of resources (time, space, memory accesses, ...), but are simple to devise and implement.
<p>An example of a naïve algorithm is bubble sort, which is only a few lines long and easy to understand, but has a O(n<sup>2</sup>) time complexity. A more "clever" algorithm is quicksort, which, although being considerably more complicated than bubble sort, has a O(n log n) average complexity.</p>
</blockquote>
<p>But there's a deep, dark problem with this naïve shuffling algorithm, a problem that most programmers won't see. <strong>Do you see it?</strong> Heck, I had the problem explained to me and I <em>still</em> didn't see it.</p>
<p>Watch what happens when I use this naïve shuffling algorithm to shuffle a three-card deck 600,000 times. There are 3! or 6 possible combinations in that deck. If the shuffle is working properly, we should see each combination represented around 100,000 times.</p>
<p><img alt="image placeholder" >
<p>As you can see, 231, 213, and 132 are over-represented, and the other three possibilities are under-represented. <strong>The naïve shuffle algorithm is biased and fundamentally broken.</strong> Moreover, the bias isn't immediately obvious; you'd have to shuffle at least a few thousand times to see real statistical evidence that things aren't working correctly. It's a subtle thing.</p>
<p>Usually, naïve algorithms aren't <em>wrong</em> -- just oversimplified and inefficient. The danger, in this case, is rather severe. A casual programmer would implement the naïve shuffle, run it a few times, see reasonably correct results, and move on to other things. Once it gets checked in, this code is a landmine waiting to explode.</p>
<p>Let's take a look at the correct <a href="http://en.wikipedia.org/wiki/Knuth_shuffle">Knuth-Fisher-Yates shuffle algorithm</a>.</p>
<pre>for (int i = cards.Length - 1; i &gt; 0; i--)
{
  int n = rand.Next(i + 1);
  Swap(ref cards[i], ref cards[n]);
}
</pre>
<p>Do you see the difference? I missed it the first time. Compare the swaps for a 3 card deck:</p>
<table cellspacing="4" cellpadding="4" width="500">
<tbody>
<tr>
<td><strong>Naïve shuffle</strong></td>
<td><strong>Knuth-Fisher-Yates shuffle</strong></td>
</tr>
<tr>
<td valign="top">
<pre>rand.Next(3);
rand.Next(3);
rand.Next(3);
</pre>
</td>
<td valign="top">
<pre>rand.Next(3);
rand.Next(2);
</pre>
</td>
</tr>
</tbody>
</table>
<p>The naive shuffle results in 3<sup>3</sup> (27) possible deck combinations. That's odd, because the mathematics tell us that there are really only 3! or 6 possible combinations of a 3 card deck. In the KFY shuffle, we start with an initial order, swap from the third position with any of the three cards, then swap again from the second position with the remaining two cards.</p>
<p><img alt="image placeholder" >
<p>The KFY shuffle produces <em>exactly</em> 3 * 2 = 6 combinations, as pictured above. Based on your experience shuffling physical cards, you might think the more shuffling that goes on, the more random the deck becomes. But <strong>more shuffling results in <em>worse</em>, not better, results</strong>. That's where the naïve algorithm goes horribly wrong. Let's compare all possible permutations of a 3 card deck for each algorithm:</p>
<table cellspacing="4" cellpadding="4" width="100%">
<tbody>
<tr>
<td valign="top">Naïve shuffle</td>
<td valign="top">Knuth-Fisher-Yates shuffle</td>
</tr>
<tr>
<td valign="top">
<table>
<tbody>
<tr>
<td valign="top">123<br> 123<br> 123<br> 123</td>
<td valign="top">132<br> 132<br> 132<br> 132<br> 132</td>
<td valign="top">213<br> 213<br> 213<br> 213<br> 213</td>
<td valign="top">231<br> 231<br> 231<br> 231<br> 231</td>
<td valign="top">312<br> 312<br> 312<br> 312</td>
<td valign="top">321<br> 321<br> 321<br> 321</td>
</tr>
</tbody>
</table>
</td>
<td valign="top">
<table>
<tbody>
<tr>
<td>123</td>
<td>132</td>
<td>213</td>
<td>231</td>
<td>312</td>
<td>321</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
<p>You can plainly see how some of the deck combinations appear unevenly in the 27 results of the naïve algorithm. Stated mathematically, <strong>27 is not evenly divisible by six</strong>.</p>
<p>Enough theory. Let's see more results. How about a four card deck, shuffled 600,000 times?</p>
<p><img alt="image placeholder" >
<p>600,000 divided by 24 is 25,000; that's almost exactly what we see right down the line for every possible combination of cards with the KFY shuffle algorithm. The naïve algorithm, in comparison, is all over the map.</p>
<p>It gets worse with larger decks. Here's the same comparison for a six card deck.</p>
<p><img alt="image placeholder" >
<p>With a 6 card deck, the differences between the two algorithms grow even larger. The math, yet again, explains why.</p>
<pre>6! = 720
6<sup>6</sup> = 46,656
</pre>
<p>With 46,656 paths to only 720 real world outputs, it's inevitable that some of those paths will be severely over-represented or under-represented in the output. And are they ever. If you shipped a real card game with a naïve shuffle, you'd have some serious exploits to deal with.</p>
<p>I know this may seem like remedial math to some of you, but I found this result strikingly counterintuitive. I had a very difficult time understanding why the naïve shuffle algorithm, which is barely different from the KFY shuffle algorithm, produces such terribly incorrect results in practice. It's a minute difference in the code, but a profound difference in results. Tracing through all the permutations and processing the statistics helped me understand <em>why</em> it was wrong.</p>
<p>Naïve implementations are often preferred to complex ones. Simplicity is a virtue. It's better to be simple, slow, and understandable than complex, fast, and difficult to grasp. Or at least it <em>usually</em> is. Sometimes, as we've seen here with our shuffling example, the simplicity of the naïve implementation can mislead. <strong>It is possible for the code to be both simple and wrong</strong>. I suppose the real lesson lies in testing. No matter how simple your code may be, there's no substitute for testing it to make sure it's actually doing what you think it is.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-danger-of-naivete/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Gifts for Geeks: 2007 Edition ]]></title>
<link>https://blog.codinghorror.com/gifts-for-geeks-2007-edition/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In case you hadn't noticed, it's that time of year again: let the wholesale buying of crap begin!
</p>
<p>
As a technology enthusiast with a bad impulse purchase habit, I get a lot of complaints that I am difficult to buy for. That's sort of intentional. I spent my entire childhood waiting to grow into an adult partially so I could afford to buy myself all the crap my parents wouldn't buy me when I was a kid.
</p>
<p>
I now regret that. Well, a little. Man, it's <i>fun</i> to buy crap.
</p>
<p>
So here are <b>my favorite lists of cool, quirky, offbeat geek gifts for 2007</b>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://arstechnica.com/guides/buyer/holiday-2007.ars?bub">Ars Technica 2007 holiday gift guide</a>
</li>
<li>
<a href="http://www.x-tremegeek.com/index.asp">X-treme Geek</a>
</li>
<li>
<a href="http://www.sciam.com/slideshow.cfm?id=gadgets-guide-home-office-toys">Scientific American's 20 Gadgets We Love</a>
</li>
<li>
<a href="http://www.core77.com/ultimategiftguide/">Core77's 77 design gifts under $77</a>
</li>
<li>
<a href="http://infosthetics.com/archives/2007/12/information_addiction_christmas_shopping_guide.html">Information Addiction Christmas Shopping Guide</a>
</li>
<li>
<a href="http://blogs.msdn.com/coding4fun/archive/2007/12/05/6644348.aspx">Coding4Fun Holiday gift gide</a>
</li>
<li>
<a href="http://www.thinkgeek.com/holiday2007.shtml">ThinkGeek Holiday Gift Center</a>
</li>
<li>
<a href="http://www.redhatmagazine.com/2007/12/05/geek-gift-guide-2007/">Red Hat Magazine's Geek Gift Guide</a>
</li>
<li>Engadget: <a href="http://www.engadget.com/2007/11/24/engadgets-holiday-gift-guide-for-him/">for him</a>, <a href="http://www.engadget.com/2007/11/26/engadgets-holiday-gift-guide-for-her/">for her</a>, <a href="http://www.engadget.com/2007/12/02/engadgets-holiday-gift-guide-for-son/">for son</a>, <a href="http://www.engadget.com/2007/12/06/engadgets-holiday-gift-guide-for-daughter/">for daughter</a>, <a href="http://www.engadget.com/2007/12/12/engadgets-holiday-gift-guide-for-dad/">for dad</a>, <a href="http://www.engadget.com/2007/12/17/engadgets-holiday-gift-guide-for-mom/">for mom</a>, <a href="http://www.engadget.com/2007/12/22/engadgets-holiday-gift-guide-for-colleague/">for colleague</a>
</li>
<li>
<a href="http://blog.makezine.com/archive/2007/12/open_source_hardware_gift.html">MAKE magazine open-source hardware gift guide</a>
</li>
<li>
<a href="http://www.unclemark.org/unclemark2008.pdf">Uncle Mark's 2008 gift guide and almanac</a> (pdf)
</li>
<li>Federated Media <a href="http://holidaygadgetguide.federatedmedia.net/">2007 Holiday Gadget Guide</a>
</li>
<li>
<a href="http://usb.brando.com.hk/">Brando: USB <i>freaking everything</i></a>
</li>
<li>Popular Science's <a href="http://www.popsci.com/popsci/whatsnew/d5840ee43bec6110vgnvcm1000004eecbccdrcrd.html">Gifts by Geeks, for Geeks</a>
</li>
</ul>
<p>
Phew. If that doesn't give you some solid gift ideas for your favorite geek (or incite your <i>own</i> techno-gadget-lust frenzy), then I can't help you.
</p>
<p>
This year, I treated myself to the <a href="http://www.amazon.com/exec/obidos/ASIN/B000Z7AKGC/codihorr-20">D-Link DGL-4500 Xtreme N Gaming Router</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Do I <i>need</i> a new router? Well, no, <a href="http://www.codinghorror.com/blog/archives/000337.html">my DGL-4300</a> still works well enough. But just look at this thing -- it's bristling with <a href="http://games.dlink.com/products/?pid=643&amp;#DGL-4500"><i>awesomeness</i></a>:
</p>
<p>
</p>
<ul>
<li>Onboard OLED real-time network activity <a href="http://images.dlink.com/products/DGL-4500/DGL-4500_network_display.gif">display</a>
</li>
<li>Dual-band 2.4 Ghz and 5 GHz alphabet soup 802.11, including 802.11n (draft 2.0)
</li>
<li>Four gigabit ethernet networking ports
</li>
<li>Upstream and downstream Quality of Service "GameFuel" support
</li>
<li>USB port for optional <a href="http://www.microsoft.com/windowsxp/using/networking/getstarted/windowsconnectnow.mspx">windows connect now</a> technology
</li>
<li>Three, count 'em, <i>three</i> antennas
</li>
</ul>
<p>
I loved my DGL-4300, and I love its big brother the DGL-4500 even more. I know QoS isn't exactly a new feature, but having it work out of the box is a huge perk -- I can <a href="http://www.codinghorror.com/blog/archives/000978.html">saturate my connection with torrents</a> and still experience perfect, lag-free online gaming. It's still amazing to me that this works. Although you pay a premium for a "gaming" class router versus a generic one, it's not too much of a premium -- <a href="http://www.amazon.com/exec/obidos/ASIN/B000Z7AKGC/codihorr-20">the DGL-4500 is currently $169 at Amazon</a> and that includes the <a href="http://www.gamerankings.com/htmlpages2/932462.asp">well-reviewed World in Conflict</a> real time strategy game. So, that's my indulgence, and I can recommend it.
</p>
<p>
Enjoy this year's crap-buying season. I'll leave you with one final bit of gifting advice-- if there's any serious doubt whether the recipient will find the gift useful, <b>go for gift cards</b>. <a href="http://www.nytimes.com/2007/01/07/magazine/07wwln_freak.t.html?ex=1325826000&amp;en=970d53de24147ae4&amp;ei=5090&amp;partner=rssuserland&amp;emc=rss">The economics of gift cards may be a little wonky</a>, but personally, I'd much prefer receiving a gift certificate/card over some physical item that requires trudging to the store to return.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/gifts-for-geeks-2007-edition/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Are You a Doer or a Talker? ]]></title>
<link>https://blog.codinghorror.com/are-you-a-doer-or-a-talker/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Today's lesson comes to you courtesy of <a href="http://www.johntaber.com/?p=75">your local Department of Transportation</a>:</p>
<p> </p>
<blockquote>The Utah DOT is spending $6 million on a feasibility study for a bridge across a lake. Meanwhile, the DOT doesn't have enough money to put up traveler information video cameras at dangerous mountain passes and canyons to help motorists make safe driving choices. That $6 million could have easily paid for the cameras, while still leaving money for a reasonable analysis of a bridge feasibility.
<p>In Washington State, budgeted money for a drainage project has been tied up in studies. Meanwhile, recent flooding has wiped out several small cities with damages in the tens of millions, destroying many people's lives. And $16 million is being spent on a rail trail conversion study. That money would be enough to build a new freeway interchange and relieve millions in congestion delay and improved safety today.</p>
</blockquote>
<p>John Taber, the author of the article, is professionally involved in exactly these kinds of studies. <a href="http://www.johntaber.com/?p=75">His opinion?</a></p>
<p> </p>
<blockquote>Heck, I make a living off transportation studies and <strong>even I'm saying there's too much study and not enough construction</strong>.</blockquote>
<p>It's an easy conceptual trip from <a href="http://www.codinghorror.com/blog/archives/000298.html">building bridges</a> to building software. In software, <a href="http://www.codinghorror.com/blog/archives/000165.html">some developers take up residence on planet architecture</a>, an otherworldly place where software is eternally planned and discussed but never actually constructed. Having endless discussions about software in a conference room or mailing list feels like useful work-- but is it? Until you've produced a working artifact for the rest of the world to experience, have you really <em>done</em> anything?</p>
<p>One of my favorite quotes on this subject comes from <a href="http://baus.net/doersandtalkers">Christopher Baus</a>.</p>
<p> </p>
<blockquote>
<strong>Software isn't about methodologies, languages, or even operating systems. It is about working applications.</strong> At Adobe I would have learned the art of building massive applications that generate millions of dollars in revenue. Sure, PostScript wasn't the sexiest application, and it was written in old school C, but it performed a significant and useful task that thousands (if not millions) of people relied on to do their job. There could hardly be a better place to learn the skills of building commercial applications, no matter the tools that were employed at the time. I did learn an important lesson at ObjectSpace. A UML diagram can't push 500 pages per minute through a RIP.
<p>There are two types of people in this industry. Talkers and Doers. ObjectSpace was a company of talkers. Adobe is a company of doers. Adobe took in $430 million in revenue last quarter. ObjectSpace is long bankrupt.</p>
</blockquote>
<p>So that's what you have to ask yourself: <a href="http://www.chadmyers.com/Blog/archive/2007/12/10/dear-alt.net.aspx">are you a doer, or a talker?</a> Ideally, you'd be a little of both, as I've said many times here. There's certainly value in <em>some</em> discussion and planning on your team. But if you must pick one or the other, try to err on <a href="http://www.codinghorror.com/blog/archives/000293.html">the side that produces useful, working code</a>:</p>
<p> </p>
<blockquote>The best way to start an open source project is with code. Working code. Hack away at home on weekends, maybe get a couple of friends to help you out, and don't go public until you have something to show people that does something interesting, and that other people can use to build more interesting stuff on top of. You need this for a bunch of different reasons: it establishes the original contributor's bona fides in the open-source meritocracy, it shortcuts all sorts of damaging debates about coding styles and architecture that can stop a project before it starts, and so on.
<p><strong>Working code attracts people who want to code. Design documents attract people who want to <em>talk</em> about coding.</strong></p>
</blockquote>
<p>There's a definite upper bound on the value of pure, theoretical discussion and planning in software. The trick is knowing when you've reached that limit, and how to funnel that effort into producing real code assets instead of letting it dissipate in a harmless puff of hot air.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/are-you-a-doer-or-a-talker/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Blacklists Don't Work ]]></title>
<link>https://blog.codinghorror.com/blacklists-dont-work/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://weblogs.asp.net/jgalloway/">Jon Galloway</a> and I got into a heated debate a few weeks ago about the efficacy of anti-virus software. My position is that <a href="http://www.codinghorror.com/blog/archives/000929.html">anti-virus software sucks</a>, and worst of all, it doesn't work anyway. That's what I've been saying all along, and it's exactly what I told Jon, too:
</p>
<p>
</p>
<blockquote>
The <a href="http://www.codinghorror.com/blog/archives/000803.html">performance cost of virus scanning</a> (lose 50% of disk performance, plus some percent of CPU speed) does not justify the benefit of a 33% detection rate and marginal protection. I would argue the <i>illusion</i> of protection is very, very dangerous as well.
<p>
Ask yourself this: why don't Mac users run anti-virus software? Why don't UNIX users run anti-virus software? Because they don't <i>need</i> to. They don't run as administrators. Sadly, the <a href="http://www.codinghorror.com/blog/archives/000891.html">cost of running as non-admin is severe</a> on Windows, because MS made some early, boneheaded architectural decisions and perpetuated them over a decade. But the benefit is substantial. There's almost nothing a virus, malware, or trojan can do to a user who isn't running as an administrator.
</p>
<p>
I believe we should invest our money, time, and effort in things that make sense, things that work. Things like <a href="http://www.codinghorror.com/blog/archives/000891.html">running as a non-administrator</a>. And we should stop wasting our time on voodoo, which is what anti-virus software ultimately is.
</p>
</blockquote>
<p>
To be fair, anti-virus software is more effective than I realized. In the <a href="http://www.av-comparatives.org/seiten/ergebnisse_2007_08.php">August 2007 Anti-Virus Comparatives</a>, the lowest detection rate was 90%, and the highest was 99.6%.
</p>
<p>
But I have a problem with <a href="http://www.av-comparatives.org/seiten/home.html">the test methodology</a> that produced these results. If we build a library of tests using all the viruses and malware in all of recorded history, we'll get an absurdly high detection rate. But who really cares if Kapersky can detect a year old virus, much less a three or four year old one? What matters most, I think, is <b>detection rate for new threats</b>. That's what's <i>really</i> dangerous, not some ancient strain of a long-forgotten DOS virus. I'm sure anti-virus vendors love comparatives like this. It makes for great ad copy: we can detect 99.7% of threats! The bad news, which is hidden by a footnote marker and placed in 4-point text at the bottom of the page, is that 99.3% of them are so old as to be utterly irrelevant and meaningless. (<font color="red">Update</font>: in a comment, Anders pointed out that <a href="http://www.av-comparatives.org/seiten/ergebnisse/report16.pdf">a November 27th "proactive/retrospective" test</a> (pdf) from the same site, using threats only a month old, showed far lower detection rates: between 80% and 33%.)
</p>
<p>
We could appeal to the data. Of the top 5 threats on <a href="http://www.virus-radar.com/index_c31d_enu.html">the virus radar</a>, only one is younger than six months. However, <a href="http://www.virus-radar.com/stat_01_current/virus_0202_c31d_enu.html">the youngest</a> dates from December 4th, a mere eight days ago. And it only takes one. If <i>anything</i> gets through your anti-virus software, you're just as compromised as you would be if you were running no anti-virus software at all.
</p>
<p>
But for now, let's assume these comparative statistics are correct. The heroic anti-virus teams can detect 99.7% of all the evil code in the world, and protect you from them, in the name of truth, justice, and the American Way. But it's far from automatic. It only works if you stick to the plan. You know, <i>the plan</i>:
</p>
<p>
</p>
<ol>
<li>Purchase the best, most effective third party anti-virus software available. On a subscription plan. And install it.
</li>
<li>Suck up <a href="http://www.codinghorror.com/blog/archives/000803.html">the massive real-time virus check performance penalty</a>.
</li>
<li>Keep your anti-virus religiously up to date at all times. (Hourly? Daily? Weekly?)
</li>
<li>Pray your anti-virus vendor can deliver signature updates faster than all the combined virus, trojan, and malware writers on the internet can create and deliver their payloads.
</li>
</ol>
<p>
Wow, not much can go wrong there. And then you only have a 0.33% chance (or a 20% chance, depending which set of data you believe) of getting in very big trouble. Problem solved!
</p>
<p>
Or you could just, y'know, <b>not run as an administrator</b>, and then you'd <i>never</i> have any chance of getting in trouble. Ever. Well, at least not from trojans, malware, or viruses. But evidently a few children's programs fail to run as non-administrator, and programming as a non-administrator is difficult, so that's a deal-breaker for Jon.
</p>
<p>
After a lot (really, <i>a lot</i>) of back and forth with Jon on this topic, I realized that my position boiled down to one core belief:
</p>
<p>
<b>Blacklists don't work.</b>
</p>
<p>
At its heart, anti-virus software is little more than a glorified blacklist. It maintains an internal list of evil applications and their unique byte signatures, and if it sees one on your system, kills it for you. Sure, anti-virus vendors will dazzle you with their ad copy, their <i>heuristic</i> this and <i>statistical</i> that; they'll tell you (with a straight face, even) that their software is far more than a simple blacklist. It's a blacklist with <i>lipstick</i>. It's the prettiest, shiniest, most kissable blacklist you've ever seen!
</p>
<p>
I could waste your time by writing a long diatribe here about how blacklisting is a deeply flawed approach to security. But I don't have to. We can turn to our old friend Mark Pilgrim for <a href="http://diveintomark.org/archives/2003/11/15/more-spam">the most radical deconstruction of blacklisting you'll probably ever read</a>.
</p>
<p>
</p>
<blockquote>
I see from Jay's Comment Spam Clearinghouse that <b>the latest and greatest tool available to us is a master [black]list of domain names and a few regular expressions.</b> No offense to Jay or all the people who have contributed to the list so far, but how quaint! I mean really. Savor this moment, folks. You can tell your children stories of how, back in the early days of weblogging, you could print out the entire spam blacklist on a single sheet of paper. Maybe with two or three columns and a smallish font, but still. Boy, those were the days.
<p>
And they won't last. They absolutely won't last. They won't last a month. The domain list will grow so unwieldy so quickly, you won't know what hit you. It'll get so big that it will take real bandwidth just to host it. Keeping it a free download will make you go broke. Code is free, but bandwidth never will be. Do you have a business plan? You'll need one within 6 months.
</p>
<p>
And then people will start complaining because a regex matches their site. Or spammers will set up fake identities to report real sites and try to poison the list. Are you manually screening new contributions? That won't scale. Are you not manually screening new contributions? That won't work either. Weighing contributions with a distributed Whuffie system? Yeah, that's possible, but it's a tricky balance, and still open to manipulation.
</p>
<p>
It's all been done. It's all been done before, and it was completely all-consuming, and it still didn't work. Spammers register dozens of new domains each day; you can't possibly keep up with them. They're bigger and smarter and faster than you. It's an arms race, and you'll lose, and along the way there will be casualties, massive casualties as innocent bystanders start getting blacklisted. (You do have a process for people to object to their inclusion, right? Yeah, except the spammers will abuse that too.)
</p>
</blockquote>
<p>
Oh, and it goes on. That's a mere slice. <a href="http://diveintomark.org/archives/2003/11/15/more-spam">Read the rest</a>. Like Mark, <b>blacklists make me angry</b>. Angry because I have to waste my time manually entering values in a stupid blacklist. Angry because the resulting list really doesn't work worth a damn, and I'll have to do the same exact thing again tomorrow, like clockwork. And most of all, angry because they're a dark mirror into the absolute worst parts of human nature.
</p>
<p>
I've had plenty of experience with blacklists. A miniscule percentage of spammers have the resources to <a href="http://www.codinghorror.com/blog/archives/000712.html">bypass my naive CAPTCHA</a>. They hire human workers to enter spam comments. That's why I enter URLs into a blacklist every week on this very site. It's an ugly, thankless little thing, but it's necessary. I scrutinize every comment, and I remove a tiny percentage of them: they might be outright spam, patently off-topic, or just plain mean. I like to refer to this as weeding my web garden. It's a productivity tax you pay if you want to grow a bumper crop of comments, which, <a href="http://www.joelonsoftware.com/items/2007/07/20.html">despite what Joel says</a>, often <a href="http://www.codinghorror.com/blog/archives/000538.html">bear such wonderful fruit</a>. The labor can be minimized with improved equipment, but it's always there in some form. And I'm OK with that. The myriad benefits of a robust comment ecosystem outweighs the minor maintenance effort.
</p>
<p>
I've also had some experience with <a href="http://www.codinghorror.com/blog/archives/000715.html">the fancy, distributed crowdsourcing style of blacklist</a>. It's a sort of consensual illusion; many hands may make light work, but they won't miraculously fix the fundamentally broken security model of a blacklist. You'll have the same core problems I have with the unpleasant little blacklist I maintain, writ much larger. The world's largest decentralized blacklist is still, well, a blacklist.
</p>
<p>
So, in the end, perhaps I should apologize to Jon. I suppose anti-virus software <i>does</i> work, in a fashion... at a steep mental and physical cost. Like any blacklist, the effort necessary to maintain an anti-virus blacklist will slowly expand to occupy all available space and time. In philosophical terms, keeping an exhaustive and authoritative list of all the evil that men can do is an infinitely large task. At best, you can only hope to be ahead at any particular moment, <i>if</i> you're giving 110%, and <i>if</i> you're doing everything exactly the right way. Every single day. And sleep lightly, because tomorrow you'll wake up to face a piping hot batch of fresh <i>new</i> evil.
</p>
<p>
If a blacklist is your only option, then by all means, use it.
</p>
<p>
With comments, I'm stuck. There's no real alternative to the blacklist approach as a backup for my CAPTCHA. Furthermore, the ultimate value of a comment is subjective, so some manual weeding is desirable anyway. But <b>when it comes to anti-virus we <i>do</i> have another option</b>. A much better option. We can <a href="http://www.codinghorror.com/blog/archives/000891.html">run as non-administrators</a>. Running as a non-administrator has historically proven to be completely effective on OS X and UNIX, where the notion of anti-virus software barely exists.
</p>
<p>
Isn't that the way it <i>should</i> be? <b>Relying on a blacklist model for security is tantamount to admitting failure before you've even started.</b> Why perpetuate the broken anti-virus blacklist model when we don't have to?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/blacklists-dont-work/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Sorting for Humans : Natural Sort Order ]]></title>
<link>https://blog.codinghorror.com/sorting-for-humans-natural-sort-order/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The default sort functions in almost every programming language are <b>poorly suited for human consumption</b>. What do I mean by that? Well, consider the difference between sorting filenames in Windows explorer, and sorting those very same filenames via <code>Array.Sort()</code> code:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td>Explorer shell sort
</td>
<td>
<code>Array.Sort()</code>
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
Quite a difference.
</p>
<p>
I can say without the slightest hint of exaggeration that <b>this exact sorting problem has been a sore point on every single project I've ever worked on</b>. Users will inevitably complain that their items aren't sorting properly, and file bugs on these "errors". Being <a href="http://www.codinghorror.com/blog/archives/000091.html">card-carrying members of the homo logicus club</a>, we programmers produce a weary sigh, and try to keep any obvious eye-rolling in check as we patiently inform our users that this <i>isn't</i> an error. Items <i>are</i> sorting in proper order. Proper <i>ASCII</i> order, that is. As we're walking away, hopefully you won't hear us mutter under our breath what we're actually thinking-- "Stupid users! They don't even understand how sorting works!"
</p>
<p>
I always felt a pang of regret when rejecting these requests. Honestly, look at those two lists-- <b>what sane person would want ASCII order?</b> It's a completely nonsensical ordering to anyone who doesn't have <a href="http://www.cdrummond.qc.ca/cegep/informat/Professeurs/Alain/files/ascii.htm">the ASCII chart</a> committed to memory (and by the way, uppercase A is decimal 65). I never really understood that there was another way to sort, even though natural sort has been right in front of us all along in the form of Mac Finder and Windows Explorer file listings. I had language-induced blinders on. If our built-in <code>sort</code> returns in ASCII order, then that must be correct. It was bequeathed upon us by the Language Gods. Can there <i>be</i> any other way?
</p>
<p>
Kate Rhodes is a bit up in arms about <a href="http://weblog.masukomi.org/2007/12/10/alphabetical-asciibetical">our collective ignorance of ASCIIbetical vs. Alphabetical</a>. Can't say I blame her. I'm as guilty as anyone. Turns out the users weren't the stupid ones after all -- <i>I was</i>.
</p>
<p>
</p>
<blockquote>
Silly me, I just figured that alphabetical sorting was such a common need (judging by the number of people asking how to do it I'm not wrong either) that I wouldn't have to write the damn thing. But I didn't count on the stupid factor. Jesus Christ people. You're programmers. You're almost all college graduates and none of you know what the f**k "Alphabetical" means. You should all be ashamed. If any of you are using your language's default sort algorithm, which is almost guaranteed to be ASCIIbetical (for good reason) to get alphabetical sorting you proceed to the nearest mirror and slap yourself repeatedly before returning to your desks and fixing your unit tests that didn't catch this problem.
</blockquote>
<p>
It isn't called "Alphabetical sort"; it's collectively known as <b>natural sort</b>. But she's right about one thing: it's hard to find information on natural sorting, and many programmers are completely ignorant of it. None of the common computer languages (that I know of) implement anything other than ASCIIbetical sorts. There are a few places you can find natural sort algorithms, however:
</p>
<p>
</p>
<ul>
<li>Dave Koelle's <a href="http://www.davekoelle.com/alphanum.html">The Alphanum Algorithm</a>
</li>
<li>Martin Pool's <a href="http://sourcefrog.net/projects/natsort/">Natural Order String Comparison</a>
</li>
<li>Ian Griffiths' <a href="http://www.interact-sw.co.uk/iangblog/2007/12/13/natural-sorting">Natural Sorting in C#</a>
</li>
<li>Ned Batchelder's <a href="http://nedbatchelder.com/blog/200712.html#e20071211T054956">Compact Python Human Sort</a>, along with Jussi Salmela's <a href="http://personal.inet.fi/cool/operator/Human%20Sort.py">internationalized version</a> of same.
</li>
</ul>
<p>
Don't let Ned's clever Python ten-liner fool you. Implementing a natural sort is more complex than it seems, and not just for <a href="http://www.codinghorror.com/blog/archives/000813.html">the gnarly i18n</a> issues I've hinted at, above. But the Python implementations are impressively succinct. One of Ned's commenters posted this version, which is even shorter:
</p>
<p>
</p>
<pre>
import re
def sort_nicely( l ):
""" Sort the given list in the way that humans expect.
"""
convert = lambda text: int(text) if text.isdigit() else text
alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]
l.sort( key=alphanum_key )
</pre>
<p>
I tried to come up with a clever, similarly succinct C# 3.0 natural sort implementation, but I failed. I'm not interested in a one-liner contest, necessarily, but it does seem to me that a basic natural sort shouldn't require the 40+ lines of code it takes in most languages.
</p>
<p>
As programmers, we'd do well to keep Kate's lesson in mind: <b>ASCIIbetical does not equal alphabetical</b>. ASCII sorting serves the needs of the computer and the compiler, but what about us human beings? <b>Perhaps a more human-friendly natural sort option should be built into mainstream programming languages</b>, too.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/sorting-for-humans-natural-sort-order/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Our Fractured Online Identities ]]></title>
<link>https://blog.codinghorror.com/our-fractured-online-identities/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.dashes.com/anil/">Anil Dash</a> has been blogging since 1999. He's a member of the Movable Type team from the earliest days. As you'd expect from a man who has lived in the trenches for so long, his blog is excellent. It's well worth a visit if you haven't been there already. I was recently reading through <a href="http://www.dashes.com/anil/2002/09/some-commendati.html">his 2002 blog recommendations</a> and marvelling at the hardy few who survived through five long years of the internet. The way I figure, that's equivalent to thirty-five people years.
</p>
<p>
I also noticed something interesting lodged in the sidebar of his blog. A long list of Anil Dash's <b>many online identities</b>, spread across no less than 29 different websites:
</p>
<p>
<a href="http://www.dashes.com/anil/"><img alt="image placeholder" >
</p>
<p>
Laurel Krahn created one of the first 30 weblogs back in 1998. Her <a href="http://www.laurelkrahn.net/">home page</a> paints a similarly <b>fractured picture of her online identity</b>. I count 21 different websites that represent some part of Laurel:
</p>
<p>
<a href="http://www.laurelkrahn.net/"><img alt="image placeholder" >
</p>
<p>
There's no way any one person could truly keep these 20 or 30 websites up to date. So which one of these websites represents the <i>real</i> Laurel Krahn, the <i>real</i> Anil Dash? Or do all these tiny fragments of identity cumulatively sum to a whole? Browsing around their sites, it's fairly easy to determine what is getting the lion's share of attention, and pare away the neglected parts. Still, it's unclear.
</p>
<p>
I suppose my online identity is similarly fractured, although somewhat less so than Anil and Laurel. I obviously have this primary blog, which represents me professionally. But I also have a <a href="http://twitter.com/codinghorror">twitter stream</a>, which I alternately treat as my inner monologue, a link blog, and as a <a href="http://www.codinghorror.com/blog/archives/000840.html">form of public instant messaging</a>. Then there are my Vertigo blogs, a handful of online games I play semi-frequently, and various other online forums that I regularly participate in for particular special interests. All these things are me.
</p>
<p>
But which one is the <i>real</i> me? Is my online identity even a reasonable approximation of who I am? I think it could be. What you read here is mostly what you get, minus some corner-case peculiarities that probably aren't interesting to anyone but me (and my wife, but she's bound by law). It's reassuring to have a single central authoritative place that represents <i>me</i> online.
</p>
<p>
Mostly, <b>I'm just amazed that these veteran bloggers feel they can actually maintain twenty or thirty different facets of their identity across all those disparate websites</b>. I certainly can't. I struggle to <a href="http://www.codinghorror.com/blog/archives/000983.html">write one lousy blog four to five times a week</a>. I'm more interested in shrinking my focus into an ever narrower and sharper point than I am in diluting my effort across dozens of different websites.
</p>
<p>
There's no right or wrong answer here, of course. You should follow your interests wherever they lead you, and to as many different websites as necessary. But I do think <a href="http://www.codinghorror.com/blog/archives/000515.html">building a strong online identity is an important strategy for distinguishing yourself</a> in an increasingly online world. So choose carefully, and focus on those things that best represent <i>you</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/our-fractured-online-identities/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ On The Meaning of "Coding Horror" ]]></title>
<link>https://blog.codinghorror.com/on-the-meaning-of-coding-horror/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In a recent web search, I found <a href="http://programming.reddit.com/info/1hdx7/comments">the following comment</a> in a <a href="http://programming.reddit.com">programming.reddit.com</a> thread from eight months ago, completely by accident:</p>
<blockquote>
<p>I think prog.reddit will continue to move in phases... a couple of days ago, someone complained about a drop-off in Haskell articles, today there were 4 or 5 ... next time Django or Rails does something worth noting, there'll be a plethora of Python/Ruby stuff. <strong>Despite its limb-gnawing tedium, Coding Horror will continue to rank high.</strong></p>
</blockquote>
<p>I personally think describing what I do here as "limb-gnawing tedium" is a bit hyperbolic. But it made me laugh.</p>
<p>I can understand where the commenter is coming from; the web is chock full of content that absolutely bores me to tears. If I stopped and wrote a comment bemoaning every boring blog post or web page I've ever found, I'd scarcely have time to do anything else. Such comments would also be a bit of a downer for the author, as I'm sure <em>someone</em> is interested in that particular topic. The whole point of putting content on the internet is to find an audience, however tiny that audience might end up being. Maybe you're not a member of the audience, and that's OK.</p>
<p>I try to avoid <a href="http://blog.codinghorror.com/blogging-about-blogging/">blogging about blogging</a> because it's <a href="http://blog.codinghorror.com/thirteen-blog-cliches/">such a cliche</a>. And it's boring. However, after digging a bit deeper in the programming.reddit.com comments, I <a href="http://programming.reddit.com/info/62hzb/comments/">became concerned</a>:</p>
<blockquote>
<p>What I don't like about "Coding Horror": <strong>the title promises "Daily WTF" style entertainment, but doesn't deliver</strong>. "Coding Horror" ought to be about people coding dynamic web pages entirely in SQL, or having some mission critical system written in a cryptic version of csh.</p>
</blockquote>
<p>This is a profound misunderstanding. If you're coming here looking for that sort of entertainment, you're bound to be disappointed.  I'd like to think this site is <a href="http://blog.codinghorror.com/whats-wrong-with-the-daily-wtf/">the opposite of The Daily WTF</a>.</p>
<p>I apologize for the confusion. Allow me to explain.</p>
<p>First, the literal explanation. The sidebar of Steve McConnell's seminal book, <a href="http://www.amazon.com/exec/obidos/ASIN/0735619670/codihorr-20">Code Complete</a>, contains a series of icons denoting particular areas. There's a "Hard Data" icon, a "Key Point" icon, and a "Coding Horror" icon.</p>
<p><a href="https://blog.codinghorror.com/content/images/2016/01/codinghorror_page_340_large.png"><img alt="image placeholder" >
<p>I have to talk a little bit about the influence this book had on me as a young developer.</p>
<p>I graduated from college in 1992, and entered the field of professional software development at that point, at least in terms of being paid to do so. I loved it, but I really had no idea what I was doing. I was a young, inexperienced developer working in small business, where there aren't a lot of other developers to look to as mentors. Nor was the internet a factor; the internet didn't really hit until '95 for most people. I was living in Denver at the time, and I frequented <a href="http://www.tatteredcover.com/">the Tattered Cover</a>, a great independent bookstore. Code Complete was originally published in May 1993; I stumbled across it while browsing the computer book section at the Tattered Cover sometime in 1994. I was floored. Here's this entire book about <strong>becoming a professional software developer</strong>, written in this surprisingly friendly, humane voice. And it was backed by rational research and real data, not the typical developer "my brain is bigger than yours" chest-thumping.</p>
<p>I had found my muse. Reading Code Complete was a watershed event in my professional life. I read it three times in one week. It immediately became my Joy of Cooking. I didn't even know it existed, but it showed me that if you loved food enough, it was possible to go from being a mere cook to a real chef.</p>
<p>One of the most striking and memorable things about Code Complete, even to this day, is that Coding Horror illustration in the sidebar. Every time I saw it on the page, I would chuckle. Not because of other people's code, mind you. Because of <em>my own code</em>. That was the revelation. <strong>You're an amateur developer until you realize that <a href="http://blog.codinghorror.com/sucking-less-every-year/">everything you write sucks</a>.</strong></p>
<p>YOU are the Coding Horror.</p>
<p>The minute you realize that, you've crossed the threshold from being an amateur software developer into the realm of the professionals. Half of being a good, competent software developer is realizing that you're going to make tons of mistakes. You will be your own worst enemy almost all the time. It's a lifestyle. You're living it right now. You, me, all of us. The problems start with us. <strong>We're <em>all</em> coding horrors.</strong> This story from the Tao that <a href="http://weblog.raganwald.com/2007/10/three-stories-about-tao.html">Reginald Braithwaite posted</a> is as good an explanation as any:</p>
<blockquote>
<p>There was once a monk who would carry a mirror wherever he went. A priest noticed this one day and thought to himself, "This monk must be so preoccupied with the way he looks that he has to carry that mirror all the time. He should not worry about the way he looks on the outside. It's what's inside that counts." So the priest approached the monk and asked "Why do you always carry that mirror?", thinking this would surely prove his guilt.</p>
<p>The monk took the mirror from his bag and pointed it at the priest. He said, "I use it in times of trouble. I look into it and it shows me the source of my problems as well as the solution to my problems."</p>
</blockquote>
<p>If you're horrified by what you see in the mirror, you are not alone.</p>
<p>I chose that title for my blog – with explicit permission from Steve – because it's a clever in-joke about <a href="http://blog.codinghorror.com/why-im-the-best-programmer-in-the-world/">becoming a humble professional programmer</a>. That's what I try to do here. I write to learn and explore topics that deal with computers and programming, and because I'm easily bored, the topics I find most interesting tend to apply to a wide audience of programmers. Maybe even people who don't know they're programmers yet. To steal a phrase from <a href="http://www.skrenta.com/2007/08/crypto_vs_the_working_coder.html">the talented Rich Skrenta</a>, <em>I blog to help others and also to learn. As it turns out both are aided by getting folks to actually read the stuff.</em></p>
<p>But that's not the complete story. I'd be lying if I didn't admit that there's an element of selfishness at work here. <a href="http://blog.codinghorror.com/remember-this-stuff-is-supposed-to-be-fun/">I love computers and programming</a>. I love it so much it borders on obsession. When I saw the movie <a href="http://www.imdb.com/title/tt0758758/">Into The Wild</a>, I was transfixed by the final note written into the margins of <a href="http://en.wikipedia.org/wiki/Doctor_Zhivago_(novel)">Dr. Zhivago</a> by a doomed <a href="http://en.wikipedia.org/wiki/Christopher_McCandless">Christopher McCandless</a>: "Happiness only real when shared."</p>
<video poster="/content/images/2016/01/happiness-only-real-when-shared.jpg" width="100%" preload="none" controls>
<source src="http://discourse.codinghorror.com/uploads/default/original/3X/f/b/fb26d231f00a510d809ed1f260f5de1f19c74825.mp4">
</source></video>
<p>I realized, that's it. That's it exactly. That is what is so intensely satisfying about writing here. My happiness only becomes real when I share it with all of you.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/on-the-meaning-of-coding-horror/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Registration Keys ]]></title>
<link>https://blog.codinghorror.com/software-registration-keys/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Software is digital through and through, and yet there's one unavoidable aspect of software installation that remains thoroughly analog: entering the registration key.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The aggravation is intentional. Unique registration keys exist only to prevent piracy. Like all piracy solutions-- short of completely server hosted applications and games, where piracy means you'd have to host your own rogue server-- it's an incomplete client-side solution. How effective is it? One vendor implemented code to <b>detect false registration keys</b> and phone home with some basic information such as the IP address when these false keys are entered. <a href="http://sharewarejustice.com/software_piracy.htm">Here's what they found:</a>
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="400">
<tr>
<td>Software Connectivity</td>
<td>Ratio of pirated<br>to legitimate keys</td>
</tr>
<tr>
<td>no internet connection required</td>
<td>45 : 1</td>
</tr>
<tr>
<td>occasional internet connection necessary</td>
<td>60 : 1</td>
</tr>
<tr>
<td>internet must be "always on"</td>
<td>110 : 1</td>
</tr>
</table>
<p>
I have no idea how reliable this data is. The vendor is never named, and given that the title of the URL is <a href="http://sharewarejustice.com/software_piracy.htm">sharewarejustice.com/software-piracy.htm</a>, I'd expect it to be biased. But it is data, and without the registration key concept (and pervasive internet connectivity), we'd have no data whatsoever to quantify how much piracy actually exists. The BSA <a href="http://www.bsa.org/country/News%20and%20Events/News%20Archives/Worldwide%20Software%20Piracy%20Rate%20Holds%20Steady.aspx">estimated 35% of all software was pirated</a> in 2006, but it is just that-- an estimate. I'll choose biased data over no data whatsoever, every time.
</p>
<p>
I don't have a problem with registration keys. You could, in fact, argue that registration key validation actually works. Microsoft recently stated that <a href="http://www.news.com/8301-13860_3-9828305-56.html">the piracy rate of Vista is half that of XP</a>, largely due to improvements in their <a href="http://en.wikipedia.org/wiki/Windows_Genuine_Advantage">Windows Genuine Advantage program</a>-- Microsoft's global registration key validation service.
</p>
<p>
As a software developer, I can empathize with Microsoft to a degree. Unless you oppose the very concept of commercial software, there has to be <i>some</i> kind of enforcement in place. The digital nature of software makes it both easy and impersonal for people to avoid paying (note that I did not say "steal"), which is an irresistible combination for many. <b>Unless you provide some disincentives, that's exactly what people will do-- they'll pay nothing for your software.</b>
</p>
<p>
Microsoft's history with piracy goes way, way back-- all the way back to the original microcomputers. Witness Bill Gates' <a href="http://www.digibarn.com/collections/newsletters/homebrew/V2_01/gatesletter.html">Open Letter To Hobbyists</a>, written in 1976.
</p>
<p>
</p>
<blockquote>
Almost a year ago, Paul Allen and myself, expecting the hobby market to expand, hired Monte Davidoff and developed Altair BASIC. Though the initial work took only two months, the three of us have spent most of the last year documenting, improving and adding features to BASIC. Now we have 4K, 8K, EXTENDED, ROM and DISK BASIC. The value of the computer time we have used exceeds $40,000.
<p>
The feedback we have gotten from the hundreds of people who say they are using BASIC has all been positive. Two surprising things are apparent, however, 1) Most of these "users" never bought BASIC (less than 10% of all Altair owners have bought BASIC), and 2) The amount of royalties we have received from sales to hobbyists makes the time spent on Altair BASIC worth less than $2 an hour.
</p>
<p>
Why is this? As the majority of hobbyists must be aware, most of you steal your software. Hardware must be paid for, but software is something to share. Who cares if the people who worked on it get paid?
</p>
<p>
Is this fair? One thing you don't do by stealing software is get back at MITS for some problem you may have had. MITS doesn't make money selling software. The royalty paid to us, the manual, the tape and the overhead make it a break-even operation. One thing you do do is prevent good software from being written. Who can afford to do professional work for nothing? What hobbyist can put 3-man years into programming, finding all bugs, documenting his product and distribute for free? The fact is, no one besides us has invested a lot of money in hobby software. We have written 6800 BASIC, and are writing 8080 APL and 6800 APL, but there is very little incentive to make this software available to hobbyists. Most directly, the thing you do is theft.
</p>
</blockquote>
<p>
Although computers have changed radically in the last thirty years, human behavior hasn't. (Alternately, you could argue that the economics of computing and the emergence of an ad-supported software ecosystem have fundamentally changed the rules of the game since 1976. But that's a topic for another blog post.)
</p>
<p>
I accept that <b>software registration keys are a necessary evil for commercial software</b>, and I resign myself to manually keeping track of them, and keying them in. But why do they have to be so painful? You <i>do</i> realize a human being has to type this stuff in, right? Here are some things that I've seen vendors get wrong with their registration key process:
</p>
<p>
</p>
<ol>
<li>
<b>Using commonly mistaken characters in the key</b>
<p>
Quick! Is that an 'O' or an '0'? A '6' or a 'G'? An 'I' or an 'l'? A 'B' or an '8'? At least have the courtesy to scour your registration key character set of those characters that are commonly mistaken for other characters. And please print the key in a font that minimizes the chances of confusion.
</p>
<p>
</p>
</li>
<li>
<b>Excessively long keys</b>
<p>
The most rudimentary grasp of mathematics tells us that a conservative 10 character alphanumeric registration key is good for 197 trillion unique users. Even <a href="http://www.codinghorror.com/blog/archives/001014.html">factoring in the pigeonhole principle</a>, we can estimate about 14 million random registration key combinations before we have a 50 percent risk of a collision. So why, then, do software developers insist on 20+ character registration keys? It's ridiculous. Are they planning to sell licenses to every grain of sand on every beach?
</p>
<p>
</p>
</li>
<li>
<b>Not separating the key into blocks</b>
<p>
Rather than smashing your key into one long string, make it a group of small 4 to 5 characters, separated by a delimiter. It's the same reason phone numbers are listed as 404-555-1212 and not 4045551212: <a href="http://www.codinghorror.com/blog/archives/000658.html">People have an easier time handling and remembering small chunks of information</a>.
</p>
<p>
</p>
</li>
<li>
<b>Making it difficult to enter the key</b>
<p>
Short of providing every customer a handy USB barcode scanner, at least make the registration key entry form as user friendly as possible:
</p>
<p>
</p>
<ul>
<li>Let the user enter the key in <i>any</i> format. With dashes, without dashes, using spaces, whatever. Be flexible. Accept a variety of formats.
</li>
<li>Do not provide five input boxes that require us to tab through each one to enter the key. It's <a href="http://www.codinghorror.com/blog/archives/000532.html">death by a thousand tiny textboxes</a>.
</li>
<li>Tell me as soon as I've entered a bad value in the key. Why should I have to go back and pore over my entry to figure out which letter or number I've screwed up? You're the computer, remember? This is what you're good at.
</li>
<li>Accept pasting from the clipboard. Once we've installed the software, we'll probably install it again, and nobody likes keying these annoying resgistration keys in more than once. I've seen some clever software that proactively checks the clipboard and enters the key automatically if it finds it there. (Kudos to you, <a href="http://www.codinghorror.com/blog/archives/000454.html">Beyond Compare</a>.)
</li>
<li>Don't passively-aggressively inform me that "the key you entered <i>appears</i> to be valid." Is it? Or isn't it? What's the point of unique registration keys if you can't be sure? I guess paying customers can't be trusted.
</li>
</ul>
</li>
<p>
</p>
<li>
<b>Where's the %*@# key?</b>
<p>
The key is important. Without it we can't install or use the software. So why is it buried in the back of the manual, or on an easy-to-overlook interior edge of the package? Make it easy to find-- and difficult to lose. Provide multiple copies of the key in different locations, maybe even as a peelable sticker we can place somewhere useful. And if the software was delivered digitally, please keep track of our key for us. We're forgetful.
</p>
<p>
</p>
</li>
</ol>
<p>
Software registration keys are a disconcerting analog hoop we force users to jump through when using commercial software. Furthermore, <b>registration keys are often the user's first experience with our software</b>-- and first impressions matter. If you're delivering software that relies on registration keys, give that part of the experience some consideration. Any negative feelings generated by an unnecessarily onerous registration key entry process will tend to color users' perception of your software.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-registration-keys/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Nobody Cares What Your Code Looks Like ]]></title>
<link>https://blog.codinghorror.com/nobody-cares-what-your-code-looks-like/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://avatraxiom.livejournal.com/58084.html">The Problems of Perl: The Future of Bugzilla</a>, Max Kanat-Alexander* laments the state of the Bugzilla codebase:
</p>
<p>
</p>
<blockquote>
Once upon a time, <a href="http://www.bugzilla.org">Bugzilla</a> was an internal application at Netscape, written in TCL. When it was open-sourced in 1998, Terry (the original programmer), decided to re-write Bugzilla in Perl. My understanding is that he re-wrote it in Perl because a lot of system administrators know Perl, so that would make it easier to get contributors.
<p>
In 1998, there were few advanced, object-oriented web scripting languages. In fact, Perl was pretty much it. PHP was at version 3.0, python was at version 1.5, Java was just starting to become well-known, ruby was almost unheard of, and some people were still writing their CGI scripts in C or C++.
</p>
<p>
Perl has many great features, most of all the number of libraries available and the extreme flexibility of the language. However, Perl would not be my first choice for writing or maintaining a large project such as Bugzilla. The same flexibility that makes Perl so powerful makes it very difficult to enforce code quality standards or to implement modern object-oriented designs.
</p>
<p>
Since 1998 there have been many advances in programming languages. PHP has decent object-oriented features, python has many libraries and excellent syntax, Java has matured a lot, and Ruby is coming up in the world quickly. <b>Nowadays, almost all of our competitors have one advantage: they are not written in Perl.</b> They can actually develop features more quickly than we can, not because of the number of contributors they have, but because the language they're using allows it. There are at least two bug-trackers that I can think of off the top of my head that didn't even exist in 1998 and were developed rapidly up to a point where they could compete with Bugzilla.
</p>
<p>
In 1998, Perl was the right choice for a language to re-write Bugzilla in. In 2007, though, having worked with Perl extensively for years on the Bugzilla project, I'd say the language itself is our greatest hindrance. Without taking some action, I'm not sure how many more years Bugzilla can stay alive as a product. Currently, our popularity is actually <i>increasing</i>, as far as I can see. So we shouldn't abandon what we're doing now. But I'm seeing more and more products come into the bug-tracking arena, and I'm not sure that we can stay competitive for more than a few more years if we stick with Perl.
</p>
</blockquote>
<p>
It's a credit to Max that he cares enough about the future of his work to surface these important issues. Perhaps it would make sense to <a href="http://wiki.mozilla.org/Bugzilla:Languages">rewrite Bugzilla in a friendlier, more modern language</a>.
</p>
<p>
Neither Perl nor the circa-1998 Bugzilla codebase have aged particularly well over the last 10 years. I don't think Bugzilla is anyone's favorite bug tracking product. It is utilitarian bordering on downright ugly. But-- and here's the important part-- <i>Bugzilla works</i>. It's actively used today by some of the largest and most famous open source projects on the planet, including the <a href="http://bugzilla.kernel.org/">Linux Kernel</a>, <a href="https://bugzilla.mozilla.org/">Mozilla</a>, <a href="http://issues.apache.org/bugzilla/">Apache</a>, and <a href="http://www.bugzilla.org/installation-list/">many others</a>.
</p>
<p>
I have a friend who works for an extremely popular open source database company, and he says their code is some of the absolute worst he's ever seen. This particular friend of mine is no stranger to bad code-- he's been in a position to see some <i>horrifically</i> bad codebases. Adoption of this open source database isn't slowing in the least because their codebase happens to be poorly written and difficult to troubleshoot and maintain. <b>Users couldn't care less whether the underlying code is pretty.</b> All they care about is whether or not it <i>works</i>. And it must work-- otherwise, why would all these people all over the world be running their businesses on it?
</p>
<p>
I gave Joel Spolsky a hard time for his <a href="http://www.codinghorror.com/blog/archives/000679.html">Wasabi language boondoggle</a>, but I'm now reconsidering that stance. Fog Creek Software isn't funded by the admiration of other programmers. It's funded by selling their software to customers. And to the customer, <a href="http://www.codinghorror.com/blog/archives/000371.html">the user interface is the application</a>. I might point and laugh at an application written in some crazy hand rolled in-house language. But language choice is completely invisible to potential customers. As long as the customers are happy with the delivered application and sales are solid, who gives a damn what I-- or any other programmers, for that matter-- think?
</p>
<p>
Sure, we programmers are paid to care what the code looks like. We worry about the guts of our applications. It's our job. We <i>want</i> to write code in friendly, modern languages that make our work easier and less error-prone. We'd <i>love</i> any opportunity to geek out and rewrite everything in the newest, sexiest possible language. It's all perfectly natural.
</p>
<p>
The next time you're knee deep in arcane language geekery, remember this: <b>nobody cares what your code looks like</b>. Except for us programmers. Yes, well-factored code written in a modern language is a laudable goal. But perhaps we should also focus a bit more on things the customer will see and care about, and less on the things they <i>never</i> will.
</p>
<p>
* I desperately want to provide full name attribution here, but I was unable to find Max's last name on any of his pages-- which drives me absolutely bonkers (<a href="http://www.codinghorror.com/blog/archives/000834.html">see # 3</a>).
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/nobody-cares-what-your-code-looks-like/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Great Browser JavaScript Showdown ]]></title>
<link>https://blog.codinghorror.com/the-great-browser-javascript-showdown/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/000509.html">The Day Performance Didn't Matter Any More</a>, I found that <b>the performance of JavaScript improved a hundredfold between 1996 and 2006</b>. If Web 2.0 is built on a backbone of JavaScript, it's largely possible only because of those crucial <a href="http://www.codinghorror.com/blog/archives/000741.html">Moore's Law performance improvements</a>.
</p>
<p>
But have we hit a performance wall? <b>Is it possible for browsers to run JavaScript significantly faster than they do today?</b> I've always thought that just-in-time optimizing (or even compiling) JavaScript was an unexplored frontier in browser technology. And now the landscape has shifted:
</p>
<ol>
<li>Apple's WebKit team <a href="http://webkit.org/blog/152/announcing-sunspider-09/">just announced</a> a great new JavaScript benchmark, SunSpider.
</li>
<li>The browser market is <a href="http://www.codinghorror.com/blog/archives/001006.html">more competitive than it has been in years</a>, with Opera 9.5, Firefox 3, Safari 3, and IE 8 all vying for the coveted default browser position.
</li>
</ol>
<p>
Perhaps browser teams will begin to consider JavaScript performance a competitive advantage.  The <a href="http://www.codinghorror.com/blog/archives/000509.html">last time</a> I looked for common JavaScript benchmarks, I came away deeply disappointed. That's why I'm particularly excited by <a href="http://webkit.org/perf/sunspider-0.9/sunspider.html">the SunSpider benchmark</a>: it's remarkably well thought out, easy to run, and comprehensive.
</p>
<p>
</p>
<blockquote>
It's <b>based on real code that does interesting things</b>; both things that the web apps of today are doing, and more advanced code of the sorts we can expect as web apps become more advanced. Very few of the tests could be classed as microbenchmarks.
<p>
It's <b>balanced between different aspects of the JavaScript language</b> -- not dominated by just a small handful of different things. In fact, we collected test cases from all over the web, including from other benchmarks. But at the same time, we avoided DOM tests and stuck to the core JavaScript language itself.
</p>
<p>
It's super <b>easy to <a href="http://webkit.org/perf/sunspider-0.9/sunspider.html">run in the browser</a></b> or from the command line, so you can test both pure engine performance, and the results you actually get in the browser.
</p>
<p>
We included <b>statistical analysis</b> so you can see how stable the results you're getting really are.
</p>
</blockquote>
<p>
<a href="http://webkit.org/blog/">Maciej Stachowiak</a>, a member of Apple's WebKit team, graciously explained what each subsection of the benchmarks do in the comments:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td valign="top">3d</td>
<td>Pure JavaScript computations of the kind you might use to do 3d rendering, but without the rendering. This ends up mostly hitting floating point math and array access.</td>
</tr>
<tr>
<td valign="top">access</td>
<td>Array, object property and variable access.</td>
</tr>
<tr>
<td valign="top">bitops</td>
<td>Bitwise operations, these can be useful for various things including games, mathematical computations, and various kinds of encoding/decoding. It's also the only kind of math in JavaScript that is done as integer, not floating point.</td>
</tr>
<tr>
<td valign="top">controlflow</td>
<td>Control flow constructs (looping, recursion, conditionals). Right now it mostly covers recursion, as the others are pretty well covered by other tests.</td>
</tr>
<tr>
<td valign="top">crypto</td>
<td>Real cryptography code, mostly covers bitwise operations and string operations.</td>
</tr>
<tr>
<td valign="top">date</td>
<td>Performance of JavaScript's "date" objects.</td>
</tr>
<tr>
<td valign="top">math</td>
<td>Various mathematical type computations.</td>
</tr>
<tr>
<td valign="top">regexp</td>
<td>Regular expressions. Pretty self-explanatory.</td>
</tr>
<tr>
<td valign="top">string</td>
<td>String processing, including code to generate a giant "tagcloud", extracting compressed JS code, etc.
</td>
</tr>
</table>
<p>
<a href="http://webkit.org/perf/sunspider-0.9/sunspider.html">SunSpider</a> is the best JavaScript benchmark I've seen, something we desperately need in an era where <a href="http://www.codinghorror.com/blog/archives/000857.html">JavaScript is the Lingua Franca of the web</a>. I was so excited, in fact, that I ran some quick benchmarks to compare the four major players in the browser market:
</p>
<p>
</p>
<ul>
<li>Windows Vista 32-bit
</li>
<li>4 GB RAM
</li>
<li>dual-core 3.0 GHz Core 2 Duo CPU
</li>
<li>all browser extensions disabled (clean install)
</li>
</ul>
<p>
<img alt="image placeholder" >
</p>
<p>
What surprised me here is that Firefox is substantially slower than IE, once you factor out that <a href="http://blogs.msdn.com/jscript/archive/2007/10/17/performance-issues-with-string-concatenation-in-jscript.aspx">wildly anomalous string result</a>. I had to use a beta version of Opera to get something other than invalid (NaN) results for this benchmark, which coincidentally summarizes my opinion of Opera. Great when it works! I expected Opera to do well; it was handily winning JavaScript benchmarks <a href="http://www.codinghorror.com/blog/archives/000211.html">way back in 2005</a>. The new kid on the block, Safari, shows extremely well particularly considering that it is running outside its native OS X environment. Kudos to Apple. Well, except for <a href="http://www.codinghorror.com/blog/archives/000884.html">that whole font thing</a>.
</p>
<p>
If you're curious how each browser stacked up in each benchmark area, I broke that down, too:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If you need greater detail-- including variances-- you can <a href="http://www.codinghorror.com/blog/files/sunspider-09-benchmark-results.txt">download my complete set of SunSpider 0.9 results as a text file</a>.
</p>
<p>
If I've learned anything from the computer industry, it's that competition benefits everyone. Here's hoping that <b>a great JavaScript browser performance showdown</b> spurs the browser teams on to better performance in this increasingly crucial area.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-great-browser-javascript-showdown/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Digital Certificates: Do They Work? ]]></title>
<link>https://blog.codinghorror.com/digital-certificates-do-they-work/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The most obvious badge of internet security is <a href="http://info.ssl.com/Article.aspx?id=10068">the "lock" icon</a>. The lock indicates that the website is backed by a <a href="http://en.wikipedia.org/wiki/Digital_certificate">digital certificate</a>:
</p>
<p>
</p>
<ol>
<li>This website is the real deal, <i>not</i> a fake set up by criminals to fool you.
</li>
<li>All data between your browser and that website is sent encrypted. Nobody in the middle can read any sensitive information you submit to that website, such as your credit card number.
</li>
</ol>
<p>
Here's what PayPal looks like in Internet Explorer 7. The lock icon and green background of the address bar let us know that this website is backed by a digital certificate.  Clicking on the lock provides additional detail about the certificate.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's PayPal in Firefox 2, which follows the same conventions. The address bar color changes, and the lock icon is present. Clicking on the lock produces a dialog with similar summary information.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The summary is reasonable enough. The certificate authority instutution, VeriSign, vouches that this site is indeed PayPal. One question I've always had, though, is this: <b>who decided VeriSign is a trusted authority?</b> There's some kind of whitelist built into IE and Firefox that <a href="http://en.wikipedia.org/wiki/Root_certificate">blesses these certificate authorities with "root" status</a>. According to Wikipedia, a 2007 survey identified <a href="http://en.wikipedia.org/wiki/Certificate_authority">6 major certificate authorities</a>:
</p>
<p>
</p>
<ol>
<li>VeriSign (57.6%)
</li>
<li>Comodo (8.3%)
</li>
<li>GoDaddy (6.4%)
</li>
<li>DigiCert (2.8%)
</li>
<li>Network Solutions (1.3%)
</li>
<li>Entrust (1.1%)
</li>
</ol>
<p>
The certificate authority business has always struck me as an odd relationship, because it's completely commercial and superficial. Fork over your $300-$2,500, some nominal proof of your identity, and you're granted a certificate for a year. Does that imply trust? I'm not the only person to share these concerns; Bruce Schneier has an excellent whitepaper which examines <a href="http://www.schneier.com/paper-pki-ft.txt">the risks of certification authorities and public-key infrastructure</a>:
</p>
<p>
</p>
<blockquote>
Certificates provide an attractive business model. They cost almost nothing to make, and if you can convince someone to buy a certificate each year for $5, that times the population of the Internet is a big yearly income. If you can convince someone to purchase a private CA and pay you afee for every certificate he issues, you're also in good shape.  It's no wonder so many companies are trying to cash in on this potential market.With that much money at stake, it is also no wonder that almost all the literature and lobbying on the subject is produced by PKI vendors.  And this literature leaves some pretty basic questions unanswered: What good are certificates anyway? Are they
secure?  For what?  In this essay, we hope to explore some of those questions.
</blockquote>
<p>
The other problem with certificates is that, as an end user, it's nearly impossible to tell a good, valid certificate provided by a reputable certificate authority from a bad one. If we click through to examine the PayPal certificate details, we're presented with these three dense tabs:
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
I don't know about you, but none of that makes any sense to me. And I'm a programmer. Imagine the poor end user trying to make heads or tails of this. What does it all mean? Of course, most users simply won't pay attention -- it's questionable <a href="http://www.codinghorror.com/blog/archives/000852.html">whether they'll even notice</a> the presence of the lock icon and the color difference in the address bar.
</p>
<p>
Certificates aren't just for websites; they can also be applied to executables, too. Here's what happens when I double-click on the Safari 3.0.4 beta installer. It's been signed by Apple using their digital certificate.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Clicking on the word "Apple" opens detailed information about the certificate. Again, what does all this mean? How can we tell if it is valid?
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
I understand the value of digital certificates in theory-- to definitively establish the identity of a program or website before entrusting your data to it. Consider a real-world analog. What if I walked up to you on the street and told you I was a policeman? You might check to see if I'm wearing an appropriate uniform. You might ask to see my badge. You might wonder where my partner or squad car is. We use all these things to judge the authenticity of human interactions.
</p>
<p>
However, I don't understand how the current digital certificate infrastructure prevents criminals from obtaining their own certificates with ease. Even though I could potentially fake a policeman's badge and uniform in the real world, that pales compared with how trivially easy it is to <a href="http://www.shahine.com/omar/AuthenticodeSigning.aspx">obtain a digital certificate for code signing from TuCows</a>:
</p>
<p>
</p>
<ul>
<li>Create an account at Tucows
</li>
<li>Buy a Cert ($300)
</li>
<li>Email them your Drivers License
</li>
<li>Download the Cert
</li>
<li>Export your certificate from the machine and store in a safe place
</li>
<li>Grab signtool.exe from the .NET 2.0 SDK
</li>
<li>Sign your binary using the certificate from step 4
</li>
</ul>
<p>
If the only validation is an emailed copy of a drivers' license, that doesn't exactly give me the warm fuzzies. And even if we enhance that with (more expensive, naturally) <a href="http://blogs.msdn.com/ie/archive/2005/11/21/495507.aspx">"extended validation"</a>, I fail to see how this would prevent a determined, resourceful criminal from getting whatever certificate they need.
</p>
<p>
I suppose digital certificates are better than nothing. But I also worry that they're incredibly confusing for the end user, easy to game, and ultimately provide a false sense of security-- and that's the most dangerous risk of all.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/digital-certificates-do-they-work/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Size Is The Enemy ]]></title>
<link>https://blog.codinghorror.com/size-is-the-enemy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Steve Yegge's latest, <a href="http://steve-yegge.blogspot.com/2007/12/codes-worst-enemy.html">Code's Worst Enemy</a>, is like all of his posts: rich, rewarding, and <i>ridiculously freaking long</i>. Steve doesn't write often, but when he does, it's a doozy. As I <a href="http://www.codinghorror.com/blog/archives/000699.html">mentioned a year ago</a>, I've started a cottage industry mining Steve's insanely great but I-hope-you-have-an-hour-to-kill writing and condensing it into its shorter form points. So let's begin:
</p>
<p>
</p>
<ol>
<li>Steve began writing a multiplayer game in Java, <a href="http://www.cabochon.com/">Wyvern</a>, around 1998. If you're curious what it looks like, see fan screenshots <a href="http://img153.imageshack.us/img153/3919/winglesgroupwy29om.jpg">one</a> and <a href="http://img159.imageshack.us/img159/1353/maps2tu.jpg">two</a>.
</li>
<li>Over the last 9 years, Wyvern has grown to 500,000 lines of Java code.
</li>
<li>Steve realized that it is impossible for a single programmer to singlehandedly maintain and support half a million lines of code. Even if you're Steve Yegge.
</li>
</ol>
<p>
There's much more, but I want to pause here for a moment. <b>It is absolutely true that any programmer who personally maintains half a million lines of code is automatically in a pretty rarified club.</b> Steve's right about this. Most developers will never have the superhuman privilege of personally maintaining 500k LOC or more. On any rational software development project, you'd have a team of developers working on it, or you'd open source the thing entirely to spread the effort across a community.
</p>
<p>
But here's what I don't understand:
</p>
<p>
</p>
<blockquote>
I happen to hold a hard-won minority opinion about code bases. In particular I believe, quite staunchly I might add, that the worst thing that can happen to a code base is size.
</blockquote>
<p>
So Steve believes the <i>majority</i> of developers, when encountering a code base approximately the size of the <a href="http://en.wikipedia.org/wiki/Death_Star">Death Star</a>, would think:
</p>
<p>
<b><i>I could totally build that.</i></b>
</p>
<p>
It's a telling indicator of the <a href="http://www.mikepope.com/blog/AddComment.aspx?blogid=1875">impressively bearded computer scientist crowd</a> that Steve runs with. They probably wear flip-flops to work, too. Amongst the programmers I know, the far more common-- and certainly more rational-- reaction to a code base that large would be to <a href="http://www.youtube.com/results?search_query=monty+python+rabbit">run away, screaming, as fast as they could</a>. And I'd be right behind them.
</p>
<p>
I don't think you necessarily have to spend ten years writing 500k worth of fairly complicated Java code to independently reach the same conclusion. <b>Size is the enemy</b>. Simply going from 1k to 10k LOC-- assuming you're sufficiently self-aware as a programmer-- is <i>more</i> than enough of a glimpse into the maw of madness that lies beyond. Even if you've written zero lines of code, if you've ever read any <a href="http://www.amazon.com/s/ref=nb_ss_gw/102-0292990-3586571?url=search-alias%3Daps&amp;field-keywords=steve+mcconnell">Steve McConnell books</a>, the <a href="http://www.codinghorror.com/blog/archives/000637.html">size rule is pounded home</a>, time and time again:
</p>
<p>
</p>
<blockquote>
Project size is easily the most significant determinant of effort, cost and schedule [for a software project]. People naturally assume that a system that is 10 times as large as another system will require something like 10 times as much effort to build. But the effort for a 1,000,000 LOC system is <i>more</i> than 10 times as large as the effort for a 100,000 LOC system.
</blockquote>
<p>
One of the most fundamental and truly effective pieces of advice you can give a software development team-- <i>any</i> software development team-- is to <b>write less code, by any means necessary</b>. Break the project into smaller subprojects. Deliver it in complementary fragments. Try iterative development. Stop writing everything in assembly language and APL. Hire better programmers who naturally write less code. Buy code from a third party. Do absolutely whatever it takes to write as little code as possible, because <a href="http://www.codinghorror.com/blog/archives/000878.html">the best code is no code at all</a>.
</p>
<p>
We're not done yet. I warned you that this was a long post. Continuing from above:
</p>
<p>
</p>
<ol start="4">
<li>Because Java is a statically typed language, it requires lots of tedious, repetitive boilerplate code to get things done.
</li>
<li>That tedious, repetitive boilerplate code has been codified into Java faith as the seminal books "Design Patterns" and "Refactoring".
</li>
<li>Java developers fervently believe, almost to a man/woman, that IDEs can overcome the unavoidable LOC bloat of Java.
</li>
<li>A rewrite of Wyvern from Java into a dynamic language that runs on the JVM could reduce the raw code size by 50% to 75%.
</li>
</ol>
<p>
Here's where Steve not-so-gently segues from "size is the problem" to "Java is the problem".
</p>
<p>
</p>
<blockquote>
Bigger is just something you have to live with in Java. Growth is a fact of life. <b>Java is like a variant of the game of Tetris in which none of the pieces can fill gaps created by the other pieces, so all you can do is pile them up endlessly.</b>
<p>
<img alt="image placeholder" >
</p>
<p>
Going back to our crazed Tetris game, imagine that you have a tool that lets you manage huge Tetris screens that are hundreds of stories high. In this scenario, stacking the pieces isn't a problem, so there's no need to be able to eliminate pieces. This is the cultural problem: [Java programmers] don't realize they're not actually playing the right game anymore.
</p>
</blockquote>
<p>
Steve singles out <a href="http://martinfowler.com/">Martin Fowler</a>, who recently "abandoned" the static-language Java fold in favor of the dynamically typed Ruby. Fowler quite literally <a href="http://www.amazon.com/exec/obidos/ASIN/0201485672/codihorr-20">wrote the book on refactoring</a>, so perhaps there's some truth to Steve's claim that the rigid architecture of classic, statically typed languages ultimately prevent you from refactoring the code down as far as you need to go. If Fowler can't refactor the Java pieces to fit, who can?
</p>
<p>
Bruce Eckel is another notable Java personality who apparently <a href="http://www.mindview.net/WebLog/log-0053">reached many of the same conclusions about Java</a> years ago.
</p>
<p>
</p>
<blockquote>
I can't quantify [the cost of strong typing]. I haven't been able to come up with a from-first- principles mathematical proof, probably because it depends on human factors, like how much time it takes to remember how to open a file and put the try block in the right places and remember how to read lines and then remember what you were really trying to accomplish by reading that file. In Python, I can process each line in a file by saying:
<p>
</p>
<pre>
for line in file("FileName.txt"):
# Process line
</pre>
<p>
I didn't have to look that up, or to even think about it, because it's so natural. I <i>always</i> have to look up the way to open files and read lines in Java. I suppose you could argue that Java wasn't intended to do text processing and I'd agree with you, but unfortunately it seems like Java is mostly used on servers where a very common task is to process text.
</p>
</blockquote>
<p>
Lines of code are, and always have been, the enemy. More lines of code means more to read, more to understand, more to troubleshoot, more to debug. But it <i>is</i> possible to go too far in the other direction as well. If you're not careful, you could end up playing yet another game entirely-- yes, you've cleverly avoided the trap of Java's infinitely tall Tetris, but have you slipped into <a href="http://en.wikipedia.org/wiki/Perl#Perl_golf">Perl's Golf</a> instead?
</p>
<p>
</p>
<blockquote>
Perl "golf" is the pastime of reducing the number of characters used in a Perl program to the bare minimum, much as how golf players seek to take as few shots as possible in a round.
<p>
<img alt="image placeholder" >
</p>
<p>
It originally focused on the JAPHs used in signatures in Usenet postings and elsewhere, but the use of Perl to write a program which performed RSA encryption prompted a widespread and practical interest in this pastime. In subsequent years, code golf has been taken up as a pastime in other languages besides Perl.
</p>
</blockquote>
<p>
In our war on verbosity, there's an inevitable <a href="http://weblog.raganwald.com/2007/12/golf-is-good-program-spoiled.html">tradeoff between verbosity and understandability</a>. Steve acknowledges this by hinging his JVM language choice on what is "syntactically mainstream": JRuby, Groovy, Rhino (JavaScript), and Jython. I'll spoil the not-so-surprise ending for you: Steve is rewriting Wyvern in Rhino, and in the process he'll help bring Rhino up to spec with the forthcoming <a href="http://www.ecmascript.org/">EcmaScript Edition 4</a> update to JavaScript. It's <a href="http://www.dehora.net/journal/2007/12/21/type-declarations-in-method-signatures-es4-gradual-typing/%0A">no magic bullet</a>, but it seems like a reasonable compromise based on his goals.
</p>
<p>
So ends the epic ten year tale of Stevey and his <a href="http://www.wyverneers.biz/">merry band of Wyverneers</a>. But where does that leave us? I have my opinions, naturally:
</p>
<p>
</p>
<ul>
<li>If you personally write 500,000 lines of code in any language, you are so totally screwed.
</li>
<li>If you personally rewrite 500,000 lines of static language code into 190,000 lines of dynamic language code, you are still pretty screwed. And you'll be out a year of your life, too.
</li>
<li>If you're starting a new project, consider using a dynamic language like Ruby, JavaScript, or Python. You may find you can write less code that means more. A lot of incredibly smart people like Steve present a compelling case that the grass really <i>is</i> greener on the dynamic side. At the very least, you'll learn how the other half lives, and maybe remove some blinders you didn't even know you were wearing.
</li>
<li>If you're stuck using exclusively static languages, ask yourself this: why <i>do</i> we have to write so much damn code to get anything done-- and how can this be changed? <a href="http://en.wikiquote.org/wiki/Alan_Kay">Simple things should be simple, complex things should be possible</a>. It's healthy to question authority, <i>particularly</i> language authorities.
</li>
</ul>
<p>
Remember: <b>size really <i>is</i> the enemy</b>. Right after ourselves, of course.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/size-is-the-enemy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Modern Logo ]]></title>
<link>https://blog.codinghorror.com/modern-logo/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Leon recently <a href="http://www.secretgeek.net/logotree.asp">posted</a> a link to a <a href="http://www.cs.nyu.edu/~michaels/blog/?p=6">great blog entry on rediscovering Logo</a>. You know, <a href="http://en.wikipedia.org/wiki/Logo_(programming_language)">Logo</a> -- the one with the turtle.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I remember being exposed to Logo way back in high school. All I recall about Logo is the <a href="http://en.wikipedia.org/wiki/Turtle_graphics">turtle graphics</a>, and the primitive digital Etch-a-Sketch drawings you could create with it. What I didn't realize is that Logo is "an easier to read adaptation of the Lisp language.. [with] significant facilities for handling lists, files, I/O, and recursion", at least if the <a href="http://en.wikipedia.org/wiki/Logo_(programming_language)">Wikipedia entry on Logo</a> is to be believed.
</p>
<p>
Although I was eternally fascinated with programming, Logo held no interest for me. It seemed like a toy language, only useful for silly little graphical tricks and stunts with the turtle. But apparently there was a real language lurking underneath all that turtle graphics stuff. <a href="http://www.cs.berkeley.edu/~bh/">Brian Harvey</a> is a Berkeley professor who not only co-wrote Berkeley Lisp, but authored three books that, amazingly, <i>teach the whole of computer science using nothing but Logo</i>.
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.cs.berkeley.edu/~bh/v1-toc2.html">Computer Science Logo Style: Symbolic Computing</a><br>concentrates on natural language processing rather than the graphics most people associate with Logo.
</li>
<li>
<a href="http://www.cs.berkeley.edu/~bh/v2-toc2.html">Computer Science Logo Style: Advanced Techniques</a><br>discussions of more advanced Logo features alternate with sample projects using those features, with commentary on the structure and style of each.
</li>
<li>
<a href="http://www.cs.berkeley.edu/~bh/v3-toc2.html">Computer Science Logo Style: Beyond Programming</a><br>a brief introduction to six college-level computer science topics.
</li>
</ul>
<p>
If you have no time to skim the material, and you're still convinced Logo is a graphics language for little kids, check out <a href="http://www.cs.berkeley.edu/~bh/logo-sample.html">a sample Logo program</a> that Brian put together to impress us. I'm impressed, anyway.
</p>
<p>
Logo is much more than the thin wrapper over turtle graphics I thought it was in 1986. But turtle graphics still-- how shall I put this? -- <i>suck</i>. I took two new books with me over the holiday vacation, and both deal with something akin to the spiritual successor to Logo-- <a href="http://www.codinghorror.com/blog/archives/000777.html">the Processing environment</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0262182629/codihorr-20"><img alt="image placeholder" >
 
<a href="http://www.amazon.com/exec/obidos/ASIN/0596514557/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Both <a href="http://www.amazon.com/exec/obidos/ASIN/0262182629/codihorr-20">Processing: A Programming Handbook for Visual Designers and Artists</a> and <a href="http://www.amazon.com/exec/obidos/ASIN/0596514557/codihorr-20">Visualizing Data</a> paint a picture of the Processing environment that strongly reminds me of Logo. But Processing doesn't offer up a new Lisp syntax -- it sticks with good old-fashioned Java.
</p>
<p>
</p>
<blockquote>
If we didn't care about speed, it might make sense to use Python, Ruby, or many other scripting languages. That is especially true on the education side. If we didn't care about making a transition to more advanced languages, we'd probably avoid a C++ or Java-style syntax. But Java is a nice starting point for a sketching language because it's far more forgiving than C/C++ and also allows users to export sketches for distribution via the Web.
</blockquote>
<p>
The focus of the Processing environment is squarely on learning while doing, which is definitely one of the tenets of Logo.
</p>
<p>
</p>
<blockquote>
If you're already familiar with programming, it's important to understand how Processing differs from other development environments and languages. The Processing project encourages a style of work that builds code quickly, understanding that either the code will be used as a quick sketch or that ideas are being tested before developing a final project. This could be misconstrued as software engineering heresy. Perhaps we're not far from "hacking", but this is more appropriate for the roles in which Processing is used. Why force students or casual programmers to learn about graphics contexts, threading, and event handling methods before they can show something on the screen that interacts with the mouse? The same goes for advanced developers: why should they always need to start with the same two pages of code whenever they begin a project?
<p>
In another scenario, if you're doing scientific visualization, the ability to try things out quickly is a far higher priority than sophisticated code structure. Usually you don't know what the outcome will be, so you might build something one week to try an initial hypothesis and build something new the next week based on what was learned in the first week.
</p>
</blockquote>
<p>
It's an admirable philosophy, and it's especially appropriate for a domain-specific language. If you're interested in graphics and visualization -- if you're truly looking for a modern Logo-- leave the turtles behind and <a href="http://www.codinghorror.com/blog/archives/000777.html">check out Processing</a> instead.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/modern-logo/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ An Inalienable Right to Privacy ]]></title>
<link>https://blog.codinghorror.com/an-inalienable-right-to-privacy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Privacy has always been a concern on the internet. But as more and more people let it all hang out on the many social networking websites popping up like weeds all over the web, there's much more at risk. Every other week, it seems, I'm reading about some new privacy gaffe. Last month, it was <a href="http://500hats.typepad.com/500blogs/2007/12/facebook-beacon.html">Facebook's Beacon opt-out policy</a>; this week, it's <a href="http://fhonearth.blogspot.com/2007/12/google-reader-shares-private-data-ruins.html">Google Reader sharing private data</a>. The privacy problems just <a href="http://www.slate.com/id/2180881/fr/rss/">keep piling up </a> as more people tune in and turn on.
</p>
<p>
</p>
<blockquote>
Nearly a decade ago, Sun Microsystems CEO Scott McNealy snapped out a warning to the worriers of the Internet Age: "You don't have any privacy. Get over it." McNealy's words look more prescient every year. In 2006, AOL <a href="http://www.slate.com/id/2147590/">unwittingly divulged</a> the personal lives of 650,000 customers by publishing their search histories as research data. Despite AOL's attempts to anonymize the info, the New York Times quickly outed a 62-year-old lady in Georgia whose searches revealed her dog was wetting the upholstery. The Justice Department <a href="http://www.nytimes.com/2006/01/20/technology/20google.html">has subpoenaed</a> Google, Yahoo!, MSN, and AOL for lists of search queries. More recently, Facebook employees were <a href="http://valleywag.com/tech/scoop/facebook-employees-know-what-profiles-you-look-at-315901.php">caught reading the customer logs</a>.
</blockquote>
<p>
Nothing warms the cockles of a user's heart quite like the tender mercies of your friendly neighborhood CEO. That privacy stuff you're so worried about? Get over it! You might wonder if Mr. McNealy has the same glib attitude towards the privacy of himself and his own family. <b>Only criminals have stuff to hide, right?</b> Here's Bruce Schneier's take on <a href="http://www.schneier.com/blog/archives/2006/05/the_value_of_pr.html">the value of privacy</a>:
</p>
<p>
</p>
<blockquote>
Last week, revelation of yet another NSA surveillance effort against the American people has rekindled the privacy debate. Those in favor of these programs have trotted out the same rhetorical question we hear every time privacy advocates oppose ID checks, video cameras, massive databases, data mining, and other wholesale surveillance measures: "If you aren't doing anything wrong, what do you have to hide?"
<p>
<a href="http://www.pritchettcartoons.com/skeletons.htm"><img alt="image placeholder" >
</p>
<p>
Some clever answers: "If I'm not doing anything wrong, then you have no cause to watch me." "Because the government gets to define what's wrong, and they keep changing the definition." "Because you might do something wrong with my information." My problem with quips like these -- as right as they are -- is that they accept the premise that privacy is about hiding a wrong. It's not. <b>Privacy is an inherent human right, and a requirement for maintaining the human condition with dignity and respect.</b>
</p>
</blockquote>
<p>
I promote openness and <a href="http://www.codinghorror.com/blog/archives/000840.html">making things public</a>. Not everything, of course; just the good and publicly useful sections you've culled from the repertoire of your life. If you don't consider any part of your life worthy of public consumption in any form, are you really <i>doing</i> anything?
</p>
<p>
Even as a proponent of selectively exhibiting parts of your life in public, there's a huge part of my life that's private. I didn't realize it, but I've relied on privacy through obscurity until now. My life is so utterly mundane that I can't imagine anyone caring what I do, what I buy, what I read, and who I talk to. I thought <b>privacy was overrated</b>. I certainly never considered privacy a basic human right, on par with <a href="http://www.law.indiana.edu/uslawdocs/declaration.html">life, liberty, and the pursuit of happiness</a>. But it is.
</p>
<p>
</p>
<blockquote>
Too many wrongly characterize the debate as "security versus privacy." The real choice is liberty versus control. Tyranny, whether it arises under threat of foreign physical attack or under constant domestic authoritative scrutiny, is still tyranny. Liberty requires security without intrusion, security plus privacy. Widespread police surveillance is the very definition of a police state. And <b>that's why we should champion privacy even when we have nothing to hide</b>.
</blockquote>
<p>
If power corrupts, then access to a pure, unfettered stream of data on every American corrupts absolutely. <b>The default strategy of privacy through obscurity</b> may have worked by default in the hodepodge, sporadically digital worlds of the 80's and 90's. Not any more. Now that so much of the world is online or stored in a vast database somewhere, all those tiny digital artifacts of who you are and what you do can be woven into a complete tapestry of your life. And you better believe it will be, because it makes some people a lot of money.
</p>
<p>
So what can we do about it? <a href="http://www.msnbc.msn.com/id/3078854/">Is privacy possible in the digital age?</a>
</p>
<p>
</p>
<blockquote>
The truth is, fighting to protect privacy is a quixotic venture. Sure, there are any number of technologies, techniques and work-arounds you can employ, all in the effort to protect your privacy. But such a quest is like trying to dig a hole in middle of a fast flowing river. <b>The rich and powerful gain some amount of privacy only because they can afford to grid their personal lives with a kind of digital body armor.</b>
<p>
Garfinkel says we need to rethink privacy in the 21st Century. "It's not about the man who wants to watch pornography in complete anonymity over the Internet. It's about the woman who's afraid to use the Internet to organize her community against a proposed toxic dump - afraid because the dump's investors are sure to dig through her past if she becomes too much of a nuisance."
</p>
</blockquote>
<p>
I'm <a href="http://www.schneier.com/blog/archives/2006/05/the_value_of_pr.html">with Bruce</a> on this one. <b>Demand privacy even if you don't think you need it.</b> Consider that the next time you sign up for some new social networking service, or a grocery discount card, or give out your telephone or social security number for some trivial reason. Neglecting to protect our right to privacy is, in effect, giving up on privacy altogether. And that's not a world I want to live in. Openness is important-- but so is privacy, in equal measure. I believe we can have both, but not without active effort on our part.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-12-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/an-inalienable-right-to-privacy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Trouble with PDFs ]]></title>
<link>https://blog.codinghorror.com/the-trouble-with-pdfs/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Adobe's <a href="http://en.wikipedia.org/wiki/Portable_Document_Format">Portable Document Format</a> is so advanced it makes you wonder why anyone bothers with primitive HTML. It's a completely vector-based layout format, both display and resolution independent. With PDF, you sacrifice almost nothing compared to traditional book and magazine layouts except <a href="http://www.codinghorror.com/blog/archives/000742.html">the obvious limitation of resolution</a>. Here's Kevin Kelly <a href="http://www.kk.org/cooltools/archives/002537.php">extolling the virtues of PDFs</a>:
</p>
<p>
</p>
<blockquote>
A PDF is able to retain the highly evolved grammar, design and syntax that one thousand years of bookmaking has attained. Because of the idiosyncratic way web browsers work, designers do not have full control of what you as a reader see on the web. The web page, including its fonts, fonts sizes, and placement of material and size of the window, partly depends on the viewer's preferences. In my experience as a reader, a web designer, and a book designer, the reading experience on paper -- and PDFs -- is much more refined and elegant. As a publisher and designer I can direct the flow of attention with better tools (font choices, rules, lines, columns) and better control. The benefit to me as a reader is that this sophisticated design translates into increased clarity, smoothness, comprehension, and enjoyment.
</blockquote>
<p>
But <b>I have a problem with PDF files</b>.
</p>
<p>
</p>
<ol>
<li>Every time I link to a PDF, I have to tag the link (pdf) to indicate that the hyperlink will whisk you away, not to another web page as you might expect, but to a strange, otherworldly out-of-browser experience.
</li>
<li>Links to PDF files assume the user has a PDF viewer installed. Do they? And how will the link be handled? As <i>in situ</i> navigation, presenting the user with a weird new set of PDF controls? Or as an undesirable popup window? Browser support for PDF is so weird there are <a href="http://www.pdfdownload.org/">entire PDF add-ons</a> to deal with it.
</li>
<li>The layout better be mind-blowingly good to justify the use of the PDF format. For most of the PDFs I encounter, the information could have been presented in HTML and CSS markup with almost no aesthetic loss at all. The "refined, elegant, sophisticated design" offered by PDF is often wasted.
</li>
<li>You might argue that PDFs make sense as a secondary, print-optimized version of existing HTML content. But why not stick to <i>one</i> version of the content? Why repeat ourselves? Do we really want to maintain two different versions of the same content?
</li>
</ol>
<p>
I'm not the first person to note <a href="http://www.useit.com/alertbox/20030714.html">the usability problems of PDF</a>, but I consider this a classic case of <a href="http://www.codinghorror.com/blog/archives/000047.html">worse is better</a>. The advantages of PDF rarely outweigh the many disadvantages compared to plain old HTML. I suppose relying on PDF was more defensible in 2001, when browser printing support was notoriously poor, and HTML layout was not well understood. But it's 2008. I'm surprised how many authors <i>still</i> reach for the safety blanket of PDF when they and their audience would be much better served with modern HTML.
</p>
<p>
The other problem with PDFs is a bit more subtle. A PDF is not merely a PDF; it's a <i>statement</i>. An implicit protest against the terrible limitations of the HTML used by the unwashed masses. PDF content yearns to be free of the constraints of common HTML-- <a href="http://www.dashes.com/anil/2003/11/tools-affect-co.html">this content, you see, signifies something</a>:
</p>
<p>
</p>
<blockquote>
It seems that the PDF format signifies something now, and it's something more than just user inconvenience. In addition to requiring the user to shift mental modes, ("I'm seeing something designed as a PDF now, this must be <i>serious information</i>...") the requirement that a document either be downloaded or viewed in a context that's radically different from standard web pages seems like a subtle assertion of authority by a document's creator. The decision to switch from standard HTML to PDF isn't arbitrary, but it isn't based on technical requirements either. It's based on the value that an author wants to assign to the work, and it benefits from the still-prevalent, though rapidly fading, consensus that print work is somehow more inherently valuable and authoritative than web pages and other online content.
</blockquote>
<p>
The <b>massive inconvenience of PDF for the user</b> rarely outweighs the minor HTML injustices righted through the power of PDF layout. Consider Kevin Kelly's own <a href="http://www.kk.org/cooltools/archives/002538.php">True Films 3.0 PDF</a>:
</p>
<p>
<a href="http://www.kk.org/cooltools/archives/002538.php"><img alt="image placeholder" >
</p>
<p>
Kevin went to the trouble of packaging this content up as a PDF, even adding Adobe's brand new support for contextual PDF advertising. All in the name of better formatting. But I don't see any advanced formatting here! Everything in that PDF would render perfectly as HTML. And <b>it'd be <i>better</i> as HTML</b>: easier to hyperlink and search, more accessible to a wide audience, and it would <i>certainly</i> generate greater advertising revenue through the existing web ad ecosystem.
</p>
<p>
I don't dispute Mr. Kelly's taste in movies for a second. And I worship at the altar of his <a href="http://www.kk.org/cooltools/index.php">Cool Tools</a>. But I'll never understand how <a href="http://en.wikipedia.org/wiki/Kevin_Kelly_%28editor%29">the founding editor of Wired</a> could fall prey to such shallow PDF elitism-- completely missing the obvious and inherent power of the world's HTML common denominator.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-trouble-with-pdfs/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Understanding User and Kernel Mode ]]></title>
<link>https://blog.codinghorror.com/understanding-user-and-kernel-mode/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Most operating systems have some method of displaying CPU utilization. In Windows, this is <a href="http://www.codinghorror.com/blog/archives/000393.html">Task Manager</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
CPU usage is generally represented as a simple percentage of <a href="http://www.codinghorror.com/blog/archives/000873.html">CPU time spent on non-idle tasks</a>. But this is a bit of a simplification. In any modern operating system, the CPU is actually spending time in two very distinct modes:
</p>
<p>
</p>
<ol>
<li>
<b>Kernel Mode</b>
<p>
In Kernel mode, the executing code has complete and unrestricted access to the underlying hardware. It can execute any CPU instruction and reference any memory address. Kernel mode is generally reserved for the lowest-level, most trusted functions of the operating system. Crashes in kernel mode are catastrophic; they will halt the entire PC.
</p>
<p>
</p>
</li>
<li>
<b>User Mode</b>
<p>
In User mode, the executing code has no ability to <i>directly</i> access hardware or reference memory. Code running in user mode must delegate to system APIs to access hardware or memory. Due to the protection afforded by this sort of isolation, crashes in user mode are always recoverable. Most of the code running on your computer will execute in user mode.
</p>
</li>
</ol>
<p>
It's possible to enable display of Kernel time in Task Manager, as I have in the above screenshot. The <font color="green">green line</font> is total CPU time; the <font color="red">red line</font> is Kernel time. The gap between the two is User time.
</p>
<p>
These two modes aren't mere labels; <b>they're enforced by the CPU hardware</b>. If code executing in User mode attempts to do something outside its purview-- like, say, accessing a privileged CPU instruction or modifying memory that it has no access to -- a trappable exception is thrown. <b>Instead of your entire system crashing, only that particular application crashes. That's the value of User mode.</b>
</p>
<p>
x86 CPU hardware actually provides four <a href="http://en.wikipedia.org/wiki/Ring_(computer_security)">protection rings</a>: 0, 1, 2, and 3. Only rings 0 (Kernel) and 3 (User) are typically used.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Ring_(computer_security)"><img alt="image placeholder" >
</p>
<p>
If we're only using two isolation rings, it's a bit unclear where device drivers should go-- the code that allows us to use our video cards, keyboards, mice, printers, and so forth. <b>Do these drivers run in Kernel mode, for maximum performance, or do they run in User mode, for maximum stability?</b> In Windows, at least, the answer is <i>it depends</i>.  Device drivers <a href="http://technet2.microsoft.com/windowsserver/en/library/eb1936c0-e19c-4a17-a1a8-39292e4929a41033.mspx?mfr=true">can run in either user or kernel mode</a>. Most drivers are shunted to the User side of the fence these days, with the notable exception of video card drivers, which need bare-knuckle Kernel mode performance. But even that is changing; in Windows Vista, <a href="http://msdn2.microsoft.com/en-us/library/aa480220.aspx">video drivers are segmented into User and Kernel sections</a>. Perhaps that's why gamers complain that Vista performs about 10 percent slower in games.
</p>
<p>
The exact border between these modes is still somewhat unclear. What code should run in User mode? What code should run in Kernel mode? Or maybe we'll just redefine the floor as the basement-- the rise of virtualization drove the creation of <a href="http://www.codinghorror.com/blog/archives/000580.html">a new ring below all the others, Ring -1</a>, which we now know as x86 hardware virtualization.
</p>
<p>
User mode is clearly a net public good, but it <a href="http://en.wikipedia.org/wiki/TANSTAAFL">comes at a cost</a>. <b>Transitioning between User and Kernel mode is expensive</b>. <i>Really</i> expensive. It's why <a href="http://www.codinghorror.com/blog/archives/000358.html">software that throws exceptions is slow</a>, for example. Exceptions imply kernel mode transitions. Granted, <a href="http://www.codinghorror.com/blog/archives/000509.html">we have so much performance now</a> that we rarely have to care about transition performance, but when you need ultimate performance, you definitely start caring about this stuff.
</p>
<p>
Probably the most public example of redrawing the user / kernel line is in webservers. Microsoft's IIS 6 <a href="http://redmondmag.com/news/article.asp?EditorialsID=1959">moved a sizable chunk of its core functionality into Kernel mode</a>, most notably after <a href="http://en.wikipedia.org/wiki/TUX_web_server">a particular open-source webserver</a> leveraged Kernel mode to create a <a href="http://evolt.org/node/3392">huge industry benchmark victory</a>. It was kind of a pointless war, if you ask me, since the kernel optimizations (in both camps) only apply to static HTML content. But such is the way of all wars, benchmark or otherwise.
</p>
<p>
The CPU's strict segregation of code between User and Kernel mode is completely transparent to most of us, but it is quite literally <b>the difference between a computer that crashes all the time and a computer that <a href="http://www.codinghorror.com/blog/archives/000452.html">crashes catastrophically</a> all the time.</b> This is what we extra-crashy-code-writing programmers like to call "progress". So on behalf of all programmers everywhere, I'd like to say <i>thanks User mode.</i> You rock!
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/understanding-user-and-kernel-mode/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ My Racing Simulation Rig ]]></title>
<link>https://blog.codinghorror.com/my-racing-simulation-rig/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One advantage of being a geek is that our habits-- as such habits go-- are not terribly expensive. I've written before about <a href="http://www.codinghorror.com/blog/archives/000476.html">my interest in auto racing</a>. Instead of spending $100,000 on a sports car, I've <b>built a nifty racing simulation rig that delivers many of the same thrills at a tiny fraction of the price</b>. It's one of my few indulgences, and I'd like to share how I built it with you.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here are the ingredients:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td><a href="http://www.amazon.com/exec/obidos/ASIN/B000K9Q5UK/codihorr-20">Playseats Evolution (black)</a></td>
<td align="right">$299</td>
</tr>
<tr>
<td><a href="http://www.gogamer.com/Playseats---Evolution-Gear-Shift-Holder-Front-Page_stcVVproductId11233973VVcatId444710VVviewprod.htm">Playseats Evolution shifter add-on</a></td>
<td align="right">$39</td>
</tr>
<tr>
<td><a href="http://www.amazon.com/exec/obidos/ASIN/B000GP8448/codihorr-20">Logitech G25 racing wheel</a></td>
<td align="right">$229</td>
</tr>
<tr>
<td>
<a href="http://www.partsexpress.com/pe/showdetl.cfm?&amp;Partnumber=299-028">50 watt Aura bass shaker</a> x 2</td>
<td align="right">$80</td>
</tr>
<tr>
<td><a href="http://www.partsexpress.com/pe/showdetl.cfm?Partnumber=300-802">Generic 100 watt subwoofer amp</a></td>
<td align="right">$100</td>
</tr>
</table>
<p>
It's worth noting that <b>the Playseat Evolution is designed to mate with the G25 wheels, pedal, and shifter</b>. The mounting holes match up <i>perfectly</i>. That was a pleasant surprise, as I had to do quite a bit of drilling on the older, original Playseat to get things mounted in <a href="http://blogs.vertigosoftware.com/jatwood/archive/2006/01/13/1861.aspx">the first version of this rig</a>. With the Evolution and G25 combo, it's almost plug and play, although you still have to do some drilling to get the shifter add-on mounted properly.
</p>
<p>
The premium leather-and-metal (well, mostly) G25 kit includes some fairly esoteric features from a major brand vendor like Logitech, notably <b>a clutch pedal and full shifter kit</b>.
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
I know $229 may seem like a lot, but it's actually a <i>great</i> deal considering what you'd have to pay for an aftermarket shifter or clutch. You don't <i>have</i> to use these advanced realism features, of course. You can always ignore the clutch pedal, and the shifter can be switched between simple up/down mode and a full 6 speed + reverse layout.
</p>
<p>
The other item of interest here is the <b>bass shakers</b>. I split the PC audio between the PC and the 100 watt subwoofer amplifier, which is strategically mounted under the seat via bungee cords. I also tuck most of the wires under there.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The amp is dedicated to driving the two 50 watt Aura shakers, which I've drilled and mounted on each side of the seat platform. The bottom of the aura has a cork backing, so there's no metal-to-metal contact.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The wiring is quite basic, but if you'd like more detail there's a great <a href="http://home.comcast.net/~davemats/hooking_up_bass_shakers.html">walkthrough on hooking up bass shakers</a> on Dave's site. The net effect of the bass shakers is pretty wonderful-- all the low-end bass is converted to tactile rumbling you feel in the driver's seat. You'll instantly know when you hit a rumble strip, and when revving a powerful engine you can <i>feel</i> the roar. Bass shakers are a clever, if decidedly low-tech, way to extend the sophisticated force feedback effects of the wheel to the rest of your body. It's no <a href="http://youtube.com/results?search_query=force-dynamics">force dynamics simulator</a>, but the bang for the buck is off the charts.
</p>
<p>
The "brains" behind this simulator is a franken-machine of parts left over from various PC upgrades I've made over the last year or so. PCs are so cheap these days, it's hardly worth listing the hardware specs. Any vaguely modern dual core CPU with 2 GB of memory will do fine. There are only two bits worth worrying about:
</p>
<p>
</p>
<ul>
<li>
<b>Video card</b>. Don't skimp here. I'd recommend the NVIDIA 8800GT or better, as games tend to be heavily video card dependent these days.
</li>
<li>
<b>Sound card</b>. Get a discrete sound card with enough outputs to drive a 5.1 surround system. I need three analog outputs to drive the necessary 6 channels on the old <a href="http://www.amazon.com/exec/obidos/ASIN/B00007AKDP/codihorr-20">Logitech Z-680</a> surround system I used in this room. A simple stereo plug isn't enough.
</li>
</ul>
<p>
For the display, I opted for an inexpensive projection system.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I used a typical 4:3 business class projector, mounted on a shelf at the rear top of the room. The screen is the largest that would fit in the space. I've also mounted the 5.1 speakers on the wall, as you can see. The two rear speakers are on the opposite wall behind us, and the subwoofer sits in a rear corner.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td>Business class projector (1024x768)</td>
<td align="right">~$800</td>
</tr>
<tr>
<td>8 foot projector screen</td>
<td align="right">~$150</td>
</tr>
<tr>
<td><a href="http://www.amazon.com/exec/obidos/ASIN/B0002WPSBC/codihorr-20">Logitech 5.1 surround speaker system</a></td>
<td align="right">$220</td>
</tr>
</table>
<p>
Between the booming sound, the huge eight foot screen, the realistic racing "cockpit", and the force feedback of the leather-wrapped wheel and rumbling bass shakers, it's an impressive driving experience.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I've always loved racing simulations, and now I've assembled a rig that does them justice. Some of my current favorite racing sims are:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000OPPR72/codihorr-20">Dirt</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B00068UXW6/codihorr-20">Richard Burns Rally</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000U5RRX8/codihorr-20">Race 07: The official WTCC Game</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000PIK1G0/codihorr-20">GTR 2</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000VOSQ0Q/codihorr-20">rFactor</a>
</li>
<li>
<a href="http://www.lfs.net/">Live for Speed</a>
</li>
</ul>
<p>
There's something about the programmer in me that <a href="http://channel9.msdn.com/Showpost.aspx?postid=314874">delights in the physics playground</a> afforded by these simulations:
</p>
<p>
</p>
<blockquote>
Simulation, by definition, needs to be accurate. Otherwise, well, it's not simulating reality, really, which is of course the idea of simulation. Games like Forza simulate <a href="http://phors.locost7.info/contents.htm">the real physics of racing</a> in a predictable and mathematically precise manner.
<p>
The past, present and future of computer simulation of real-time physical events, or simply computer-based simulations that involve highly accurate representations of things moving/changing in space and time that are precisely affected by multiple variables like wind, rain, gravity, mud, oil, planets, waves, etc are fascinating topics for gamers (many may not realize this explicitly, but they sure experience it!), mathematicians, programmers and physicists alike.
</p>
</blockquote>
<p>
I know this racing simulation rig probably barely scratches the surface of what it would <i>actually</i> be like to drive a $100k sports car on a race track. It certainly won't get you as much attention from the opposite sex as a real sports car would. But it's still a heck of a lot of fun, nonetheless-- and it can be built by mere mortals like you and I.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/my-racing-simulation-rig/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Magpie Developer ]]></title>
<link>https://blog.codinghorror.com/the-magpie-developer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I've often thought that software developers were akin to <a href="http://en.wikipedia.org/wiki/Magpie">Magpies</a>, birds notorious for stealing shiny items to decorate their complex nests. Like Magpies, software developers are unusually smart and curious creatures, almost by definition. But <strong>we are too easily distracted by shiny new toys and playthings</strong>.</p>
<p><img alt="image placeholder" >
<p>I no longer find Scott Hanselman's <a href="http://www.hanselman.com/blog/ScottHanselmans2007UltimateDeveloperAndPowerUsersToolListForWindows.aspx">Ultimate Developer Tool list</a> inspiring. Instead, it's fatiguing. The pace of change in the world of software <a href="http://www.codinghorror.com/blog/archives/000545.html">is relentless</a>. We're so inundated with the Shiny and the New that the very concepts themselves start to disintegrate, the words repeated over and over and over until they devolve into a meaningless stream of vowels and consonants. "Shiny" and "new" become mundane, even commonplace. It's no longer unique for something to be new, no longer interesting when something is shiny. Eventually, <strong>you grow weary of the endless procession of shiny new things</strong>.</p>
<p>I'm not alone. Jeremy Zawodny also notes <a href="http://jeremy.zawodny.com/blog/archives/009248.html">the diminishing luster of shiny new things</a>:</p>
<blockquote>Over a year ago I unsubscribed from <a href="http://www.micropersuasion.com/">Steve's blog</a> because he had a habit of writing in breathless fashion about the latest shiny new thing – often several times a day. I see too many people I know getting caught up in the breathless hype and <strong>forgetting to think about whether the latest shiny new thing really matters in the grand scheme of things</strong>.</blockquote>
<p>Dave Slusher <a href="http://www.evilgeniuschronicles.org/wordpress/2007/07/17/why-i-dropped-scoble-and-seceded-from-the-hunt-for-newer-shinier-things/">concurs</a>:</p>
<blockquote>[Robert Scoble] says that he gets too much email and that is ineffective for getting PR releases to him. He suggests that what you should do now is leave him a message on his Facebook wall. Dear god and/or Bob. In the time I've followed Scoble, I must have seen something like this a dozen times from him. Don't email, Twitter me. Don't Twitter, Pwnce. Jaiku me. Leave a wall message, send an SMS, just call me, email me, don't email me, don't call me. Enough already! I'm not even trying to get in contact with him, and I find this constant migration from platform to platform to be a load of shit that just wearies me. I felt the same way when I dropped TechCrunch, well over a year ago. I got so tired of hearing about another slightly different way of doing what we were already doing and why that tiny difference was worth dropping everything and moving over. <strong>I officially renounce the search for the newer and shinier.</strong>
</blockquote>
<p>It isn't just the neverending stream of tech news. It's also the tidal push and pull of a <a href="http://www.codinghorror.com/blog/archives/000247.html">thousand software religious wars</a> that continually wears us down, like errant rocks in a rapidly flowing stream. I bet <a href="http://www.megginson.com/blogs/quoderat/2006/03/06/programming-languages-of-distinction/">the process David Megginson outlines</a> sounds awfully familiar:</p>
<blockquote>1. Elite (guru) developers notice too many riff-raff using their current programming language, and start looking for something that will distinguish them better from their mediocre colleagues.
<p>2. Elite developers take their shopping list of current annoyances and look for a new, little-known language that apparently has fewer of them.</p>
<p>3. Elite developers start to drive the development of the new language, contributing code, writing libraries, etc., then evangelize the new language.  Sub-elite (senior) developers follow the elite developers to the new language, creating a market for books, training, etc., and also accelerating the development and testing of the language.</p>
<p>4. Sub-elite developers, who have huge influence (elite developers tend to work in isolation on research projects rather than on production development teams), begin pushing for the new language in the workplace.</p>
<p>5. The huge mass of regular developers realize that they have to start buying books and taking courses to learn a new language.</p>
<p>6. Elite developers notice too many riff-raff using their current programming language, and start looking for something that will distinguish them better from their mediocre colleagues.</p>
</blockquote>
<p>I hope you're sitting down, because I've got some bad news for you. That Ruby on Rails thing you were so interested in? That's <a href="http://zedshaw.com/rants/rails_is_a_ghetto.html">so last year</a>. We've <a href="http://stuffthathappens.com/blog/2008/01/02/scala-will-do/">moved on</a>.</p>
<p>If you consider that, statistically, the vast majority of programmers have yet to experience a dynamic language of <em>any</em> kind – much less Ruby – the absurdity here is sublime. Some dynamic language features are trickling down to the bastions of Java and .NET, but slowly, and with varying levels of success. These so-called thought leaders have left a virtual ghost town before <a href="http://www.codinghorror.com/blog/archives/000686.html">anyone else had a chance to arrive</a>.</p>
<p>I became a programmer because I love computers, and to love computers, <a href="http://www.codinghorror.com/blog/archives/000761.html">you must love change</a>. And I do. But I think <strong>the magpie developer sometimes loves change to the detriment of his own craft</strong>. Andy Hunt and Dave Thomas, the <a href="http://www.codinghorror.com/blog/archives/000052.html">Pragmatic Programmers</a> who were a big part of the last sea change in Ruby, said it quite well in <a href="http://media.pragprog.com/articles/sep_04_imaginate.pdf">a 2004 IEEE column</a> (pdf).</p>
<blockquote>Users don't care whether you use J2EE, Cobol, or a pair of magic rocks. They want their credit card authorization to process correctly and their inventory reports to print. You help them discover what they really need and jointly imagine a system.
<p>Instead of getting carried away with the difficult race up the cutting edge of the latest technology, Pete concentrated on building a system [in COBOL] that works for him and his clients. It's simple, perhaps almost primitive by our lofty standards. But it's easy to use, easy to understand, and fast to deploy. Pete's framework uses a mixture of technologies: some modeling, some code generation, some reusable components, and so on. He applies the fundamental pragmatic principle and uses what works, not what's merely new or fashionable.</p>
<p><strong>We fail (as an industry) when we try to come up with the all-singing, all-dancing applications framework to end all applications frameworks.</strong> Maybe that's because there is no grand, unified theory waiting to emerge. One of the hallmarks of postmodernism – which some think is a distinguishing feature of our times – is that there's no "grand narrative," no overarching story to guide us. Instead, there are lots of little stories.</p>
</blockquote>
<p><a href="http://www.codinghorror.com/blog/archives/000575.html">Don't feel inadequate</a> if you aren't lining your nest with the shiniest, newest things possible. <strong>Who cares what technology you use</strong>, as long as it <em>works</em>, and both you and your users are happy with it?</p>
<p>That's the beauty of new things: there's always a new one coming along. Don't let the pursuit of new, shiny things accidentally become your goal. Avoid becoming a magpie developer. Be selective in your pursuit of the shiny and new, and you may find yourself a better developer for it.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-magpie-developer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Pollute User Space ]]></title>
<link>https://blog.codinghorror.com/dont-pollute-user-space/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
What is user space? User space is the location in the filesystem where users put their personal files-- their "stuff". Here's the user space folder structure in the <b>Windows XP</b> operating system:
</p>
<p>
</p>
<pre>
Documents and SettingsUser
<font color="silver">Application Data</font>
Cookies
Desktop
Favorites
<font color="silver">Local Settings</font>
My Documents
My Music
My Pictures
My Recent Documents
<font color="silver">NetHood</font>
<font color="silver">PrintHood</font>
<font color="silver">SendTo</font>
Start Menu
</pre>
<p>
And here's the user space folder structure in the <b>Windows Vista</b> operating system:
</p>
<p>
</p>
<pre>
UsersUser
<font color="silver">AppData</font>
<font color="silver">Local</font>
<font color="silver">Roaming</font>
Contacts
Desktop
Documents
Downloads
Favorites
Links
Music
Pictures
Saved Games
Searches
Videos
</pre>
<p>
This <a href="http://www.shahine.com/omar/MyDocumentsInVista.aspx">new Vista user space folder structure</a> may seem oddly familiar to people using operating systems based on Unix. It gives new life to the <a href="http://mailman.postel.org/pipermail/internet-history/2001-November/000068.html">famous quote</a> "Those who do not understand Unix are condemned to reinvent it, poorly". Regardless, I'm glad we no longer have to deal with a <a href="http://www.codinghorror.com/blog/archives/000729.html">scarily long default user path</a> -- with aggravating embedded spaces, even-- to our personal stuff. If a user is keeping notes in a text file, we can reasonably expect to find those notes at the following path:
</p>
<p>
</p>
<pre>
Documents and SettingsUserMy Documentsnotes.txt
UsersUserDocumentsnotes.txt
</pre>
<p>
Now that we've established what and where user space is, I have a message for all the programmers reading this-- including myself. <b>Keep your dirty, filthy paws out of my personal user space!</b>
</p>
<p>
Take a look in your <code>Documents</code> folder right now. Go ahead. Look. Do you see any files or folders in there that you personally did not create? If so, you've been victimized. Applications should never create or modify anything in <i>your</i> documents folder without <i>your</i> permission. And yet, sadly, it happens all the time. Applications, and more specifically, the programmers who wrote those applications, think it's perfectly A-OK to carpet bomb your personal user space with their junk.
</p>
<p>
Well, it isn't.
</p>
<p>
As Omar Shahine <a href="http://www.shahine.com/omar/MyDocuments.aspx">originally pointed out almost two years ago</a>, we should be mad as hell, and we shouldn't take it any more. If applications need to store shared files, that's what the <code>AppData</code> and <code>Application Data</code> folders are for. In OS X, which inherits a lot of filesystem conventions from BSD Unix, Apple has a great set of guidance appropriately titled <a href="http://developer.apple.com/documentation/MacOSX/Conceptual/BPFileSystem/Articles/WhereToPutFiles.html">Don't Pollute User Space</a>:
</p>
<p>
</p>
<blockquote>
It is important to remember that the user domain (<code>/Users</code>) is intended for files created by the user. With the exception of the <code>~/Library</code> directory, your application should never install files into the user's home directory. In particular, you should never install files into a user's <code>Documents</code> directory or into the <code>/Users/Shared</code> directory. <b>These directories should only be modified by the user. </b>
<p>
Even if your application provides clip art or sample files that the user would normally manipulate, you should place those files in either the local or user's <code>Library/Application</code> Support directory by default. The user can move or copy files from this directory as desired. If you are concerned about the user finding these files, you should include a way for the user to browse or access them directly from your application's user interface.
</p>
</blockquote>
<p>
Discovering this made me realize how much I missed the good old days of strict operating system and GUI conventions. Granted, Apple is cheating quite a bit by inheriting the well-worn conventions of classic Unix operating systems. But so much of Windows seems dangerously ad-hoc in comparison.
</p>
<p>
At any rate, it is our obligation as programmers to let the user's folders belong to the user. Do the responsible thing and store your application files in an appropriate location, not as virtual litter amongst the user's other files. Please <b>don't pollute user space</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-pollute-user-space/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ No Matter What They Tell You, It's a People Problem ]]></title>
<link>https://blog.codinghorror.com/no-matter-what-they-tell-you-its-a-people-problem/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Bruce Eckel deftly identifies <a href="http://www.artima.com/weblogs/viewpost.jsp?thread=221622">the root cause of all software development problems</a>:
</p>
<p>
</p>
<blockquote>
We are in <a href="http://www.codinghorror.com/blog/archives/000686.html">a young business</a>. Primitive, really -- we don't know much about what works, and we keep thinking we've found the silver bullet that solves all problems. As a result, we go through these multi-year boom and bust cycles as new ideas come in, take off, exceed their grasp, then run out of steam. But some ideas seem to have staying power. For example, a lot of the ideas in agile methodologies seem to be making some real impacts in productivity and quality. This is because they focus more on the issues of people working together and less on technologies.
<p>
A man I've learned much from, Gerald Weinberg, wrote his first couple of books on the technology of programming. Then he switched, and wrote or coauthored 50 more on the process of programming, and he is most famous for saying <b>"no matter what they tell you, it's always a people problem."</b>
</p>
<p>
Usually the things that make or break a project are process and people issues. The way that you work on a day-to-day basis. Who your architects are, who your managers are, and who you are working with on the programming team. How you communicate, and most importantly how you solve process and people problems when they come up. The fastest way to get stuck is to think that it's all about the technology and to believe that you can ram your way through the other things. Those other things are the most likely ones to stop you cold.
</p>
</blockquote>
<p>
Bruce misremembers <a href="http://www.softwarequotes.com/ShowQuotes.asp?ID=605&amp;Name=Weinberg,_Gerald_M.&amp;Type=Q">the actual quote</a>; it's "no matter what the problem is, it's always a people problem." But Bruce's reformulation has a certain ineffable truthiness to it that is certainly in the spirit of <a href="http://www.amazon.com/gp/search/ref=sr_adv_b/?search-alias=stripbooks&amp;unfiltered=1&amp;field-author=gerald+weinberg&amp;sort=relevancerank">Gerald Weinberg's writing</a>.
</p>
<p>
Let's say I was tasked with determining <a href="http://www.codinghorror.com/blog/archives/000917.html">whether your software project will fail</a>. With the responses to these three questions in hand, I can tell you with almost utter certainty whether your project will fail:
</p>
<p>
</p>
<ol>
<li>How many <a href="http://www.codinghorror.com/blog/archives/000637.html">lines of code</a> will your team write?
</li>
<li>What <a href="http://www.joelonsoftware.com/articles/FiveWorlds.html">kind of software</a> are you building?
</li>
<li>
<b>Do you like your coworkers?</b>
</li>
</ol>
<p>
That last question isn't a joke. I'm not kidding. Do you like the company of your teammates on a personal level? Do you respect your teammates professionally? If you were starting at another company, would you invite your coworkers along? Do you have spirited team discussions or knock-down, drag-out, last man standing filibuster team arguments? Are there any people on your team you'd "vote off the island" if you could?
</p>
<p>
It may sound trivial to focus on the people you work with over more tangible things like, say, the actual work, or the particular technology you're using to do that work. But it isn't. <b>The people you choose to work with are the most accurate predictor of job satisfaction I've ever found</b>.  And job satisfaction, based on my work experience to date, correlates perfectly with success. I have <i>never</i> seen a happy, healthy, gelled, socially functional software development team fail. It's a shame such teams are so rare.
</p>
<p>
As Weinberg said, <i>it's always a people problem</i>. If you aren't working with people you like, people you respect, people that challenge and inspire you-- then why not? What's stopping you?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/no-matter-what-they-tell-you-its-a-people-problem/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Enduring Art of Computer Programming ]]></title>
<link>https://blog.codinghorror.com/the-enduring-art-of-computer-programming/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I saw on reddit that today, January 10th, is <a href="http://en.wikipedia.org/wiki/Donald_Knuth">Donald Knuth's</a> seventieth birthday.</p>
<p><a href="http://geekz.co.uk/shop/"><img alt="image placeholder" >
<p>Knuth is arguably <b>the most famous living computer scientist</b>, author of the seminal <a href="http://en.wikipedia.org/wiki/The_Art_of_Computer_Programming">Art of Computer Programming</a> series. Here's how serious Mr. Knuth is – his books are dedicated, not to his wife or a loved one, but to a <i>computer</i>:</p>
<blockquote>
<p>This series of books is affectionately dedicated<br><br>
to the <a href="http://en.wikipedia.org/wiki/IBM_650">Type 650 computer</a> once installed at<br>Case Institute of Technology,<br>in remembrance of many pleasant evenings.</p>
</blockquote>
<p>Jeffrey Shallit compiled an <a href="http://recursed.blogspot.com/2008/01/happy-birthday-donald-knuth.html">excellent set of links</a> commemorating the 70th birthday of this legendary figure:</p>
<ul>
<li>
<a href="http://scienceblogs.com/goodmath/2008/01/the_genius_of_donald_knuth_typ.php">The Genius of Donald Knuth: Typesetting with Boxes and Glue</a>. "I don't know of any other software other than TeX implemented in the 1970s that remains absolutely and unquestionably dominant in its domain. And the glue-and-boxes model of text layout was a piece of absolute genius - one of the most masterful examples of capturing an extremely complex problem using an extremely simple model. It's beautiful. And it's typical of the kind of thing that Knuth does."</li>
<li>
<a href="http://www.math.rutgers.edu/~zeilberg/Opinion86.html">Opinion 86</a> "So Knuth is very right to worry about constants. And he gets his hands dirty and does the coding all by himself, and he gave us such great programs as TeX, and its fully-detailed manuals. He taught us by example the art of computer programming, and he modestly claims that it is art in the sense of the artisan rather than that of the artist. But his perfect artisanship became the most refined of fine arts."</li>
<li>
<a href="http://11011110.livejournal.com/128249.html">Analyzing Algorithm X</a> "Knuth was the first to use the phrase 'analysis of algorithms,' at the 1970 ICM in Nice. He popularized and extended O-notation (previously used in functional analysis) as an essential tool for algorithm analysis. And his Art of Computer Programming set the standards for the field and is still well worth reading today."</li>
<li>
<a href="http://scottaaronson.com/blog/?p=303">Volume 4 is already written (in our hearts)</a>. "But this being a lecture series, Knuth also fields questions from the audience about everything from sin and redemption to mathematical Platonism. He has a habit of parrying all the <i>really</i> difficult questions with humor; indeed, he does this so often one comes to suspect humor <i>is</i> his answer."</li>
<li>
<a href="http://in-theory.blogspot.com/2008/01/don-knuth-is-70.html">Don Knuth is 70</a> "As a member of a community whose life is punctuated by twice-yearly conferences, what I find most inspiring about Knuth is his dedication to perfection, whatever time it might take to achieve it."</li>
<li>
<a href="http://weblog.fortnow.com/2008/01/today-is-knuths-70th-birthday.html">Today is Knuth's 70th birthday!!</a> "He was one of the first people to realize that an algorithm can be analysed in a mathematical and intelligent way without running it. This is one of the most important starting points for computer science theory. Perhaps even for computer science."</li>
<li>
<a href="http://geomblog.blogspot.com/2008/01/happy-birthday-don-knuth.html">Happy Birthday, Don Knuth!</a> "Don Knuth straddled both worlds effortlessly, gaining respect from 15 year old hackers and 50 year old researchers alike. And that's the most tremendous feat of all."</li>
<li>
<a href="http://recursed.blogspot.com/2008/01/donald-knuth-and-me.html">Donald Knuth and Me</a>: "Later, when I attended university, I began to understand Knuth's wider influence. Almost everywhere I turned, Knuth had been there before."</li>
</ul>
<p>For mainstream press coverage of Donald Knuth, Jeffrey recommends:</p>
<ul>
<li>
<a href="http://www.salon.com/tech/feature/1999/09/16/knuth/index.html">The Art of Don E. Knuth</a> (Salon)</li>
<li><a href="http://www.larry.denenberg.com/Knuth-3-16/">Knuth 3:16</a></li>
<li>
<a href="http://www.npr.org/templates/story/story.php?storyId=4532247">Donald Knuth, Founding Artist of Computer Science</a> (NPR)</li>
<li><a href="http://www-cs-faculty.stanford.edu/~knuth/news.html">Knuth's own home page</a></li>
</ul>
<p>My very favorite thing about Mr. Knuth is that, despite the profound and enduring depth of his contributions to the field of computer science, he has a <a href="http://en.wikipedia.org/wiki/Donald_Knuth#Knuth.27s_humor">great sense of humor</a>. For proof, let's go back in time. Way, way back, to <a href="http://en.wikipedia.org/wiki/Mad_(magazine)">Mad Magazine</a> #33, originally published in 1957.</p>
<p><img alt="image placeholder" >
<p><img alt="image placeholder" >
<p>These images are from <a href="http://www.amazon.com/exec/obidos/ASIN/B000HKMQ64/codihorr-20">Absolutely Mad: 50 Years of Mad Magazine</a>, a DVD-ROM containing (almost) every issue of Mad. Surprisingly, the disc isn't encumbered by any bizarre DRM scheme; every issue is a simple PDF file in a folder on the disc. The resolution isn't as high as I would like, but I'm not about to complain after paying thirty-three measly bucks for a nearly complete digital library of Mad.</p>
<p>(And now, even better, you can get <a href="https://www.comixology.com/Mad-Magazine/comics-series/302"><em>extremely</em> high resolution versions of early Mad Magazines from Comixology</a>. Sadly, it only goes up to issue #23 at the moment.)</p>
<p>As a long time fan of Mad Magazine, I was delighted to discover that Donald Knuth contributed an article to Mad, "The Potrzebie System of Weights and Measures", while he was still in high school. It's a little difficult to read the introductory text that ties the article to Knuth, so I'll quote it here.</p>
<blockquote>
<p>When Milwaukee's <b>Donald Knuth</b> first presented his revolutionary system of weights and measures to the members of the <i>Wisconsin Academy of Science, Arts, and Letters</i>, they were astounded... mainly because Donald also has two heads. All kidding aside, Donald's system won first prize as the "most original presentation". So far, the system has been adopted in Tierra del Fuego, Afghanistan, and Southern Rhodesia. The U.N. is considering it for world adoption.</p>
<p>This new system of measuring, which is destined to become the measuring system of the future, has decided improvements over the other systems now in use. It is based on measurements taken 6-9-12 at the Physics Lab of <b>Milwaukee Lutheran High School</b>, in Milwaukee, Wis., when the thickness of Mad Magazine #26 was determined to be 2.263348517438173216473 mm. This length is the basis for the entire system, and is called one <a href="http://en.wikipedia.org/wiki/Potrzebie">potrzebie</a> of length. The Potrzebie has also been standardized at 3515.3502 wave lengths of the red line in the spectrum of cadmium. A partial table of the Potrzebie System, the measuring system of the future, is given below.</p>
</blockquote>
<p>I still subscribe to <a href="http://en.wikipedia.org/wiki/Mad_(magazine)">Mad Magazine</a>; the biting satire and political humor haven't aged a bit in the intervening fifty years. I know it sounds crazy for a grown man to extol the virtues of what most charitably consider to be a kids' humor rag. But I'm not the only one. Just <a href="http://www.tdn.com/articles/2007/03/25/this_day/news01.txt">ask the Los Angeles Times' Robert Boyd</a>:</p>
<blockquote>
<p>[Mad Magazine] instilled in me a habit of mind, a way of thinking about a world rife with false fronts, small print, deceptive ads, booby traps, treacherous language, double standards, half truths, subliminal pitches and product placements; it warned me that I was often merely the target of people who claimed to be my friend; it prompted me to mistrust authority, to read between the lines, to take nothing at face value, to see patterns in the often shoddy construction of movies and TV shows; and it got me to think critically in a way that few actual humans charged with my care ever bothered to.</p>
</blockquote>
<p>Programming algorithms are hard science, backed by some serious math. Thanks for the reminder, Mr. Knuth, that computer science is indeed serious stuff, but <a href="http://www.codinghorror.com/blog/archives/000979.html">it's also a lot of fun</a>. Here's to you – and to <b>the enduring art of computer programming</b> you introduced us all to.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-enduring-art-of-computer-programming/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Should We Teach Computer Science? ]]></title>
<link>https://blog.codinghorror.com/how-should-we-teach-computer-science/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.cs.toronto.edu/~gvwilson">Greg Wilson</a> recently emailed me the following question:
</p>
<p>
</p>
<blockquote>
I'm teaching a software engineering class to third-year students at the University of Toronto starting in January, and would like to include at least one hour on deployment --- <b>[deployment] never came up in any of my classes, and it's glossed over pretty quickly in most software engineering textbooks</b>, but I have learned the hard way that it's often as big a challenge as getting the application written in the first place.
</blockquote>
<p>
Deployment is a huge hurdle. It's a challenge even for the best software development teams, and it's incredibly important: if users can't get past the install step, none of the code you've written matters! And yet, as Greg notes, existing software engineering textbooks give this crucial topic only cursory treatment. Along the same lines, a few weeks ago, a younger coworker noted to me in passing that <b>he never learned anything about source control</b> in any of his computer science classes. How could that be? Source control is the very <a href="http://www.codinghorror.com/blog/archives/000643.html">bedrock of software engineering</a>.
</p>
<p>
If we aren't teaching fundamental software engineering skills like deployment and source control in college today, we're <b>teaching computer science the wrong way</b>. What good is learning to write code in the abstract if you can't work on that code as a team in a controlled environment, and you can't deploy the resulting software? As so many computer science graduates belatedly figure out after landing their first real programming job, it isn't any good at all.
</p>
<p>
Today's computer science students should <b>develop software under conditions as close as possible to the real world</b>, or the best available approximation thereof. Every line of code should be written under source control at all times. This is not negotiable. When it's time to deploy the code, try deploying to a commercial shared web host, and discovering everything that entails. If it's an executable, create a standalone installer package that users have to download, install, and then have some mechanism to file bug reports when they inevitably can't get it to work. Students should personally follow up on each bug filed for the software they've written.
</p>
<p>
Will this be painful? Boy, oh boy, will it ever. It'll be <i>excruciating</i>. Students will hate it. They'll begin to question why anyone in their right mind would want to write software.
</p>
<p>
Welcome to the real world.
</p>
<p>
After I wrote my response to Greg, Joel Spolsky posted an <a href="http://www.joelonsoftware.com/items/2008/01/08.html">entry on computer science education</a> that, at least to my eye, seemed hauntingly similar to the advice I offered:
</p>
<p>
</p>
<blockquote>
I think the solution would be to create a programming-intensive BFA in Software Development -- a Julliard for programmers. Such a program would consist of a practical studio requirement developing significant works of software on teams with very experienced teachers, with a sprinkling of liberal arts classes for balance.
<p>
When I said BFA, Bachelor of Fine Arts, I meant it: software development is an art, and the existing Computer Science education, where you're expected to learn a few things about NP completeness and Quicksort is singularly inadequate to training students how to develop software.
</p>
<p>
Imagine instead an undergraduate curriculum that consists of 1/3 liberal arts, and 2/3 software development work. The teachers are experienced software developers from industry. The studio operates like a software company. You might be able to <b>major in Game Development and work on a significant game title, for example, and that's how you spend most of your time, just like a film student spends a lot of time actually making films and the dance students spend most of their time dancing.</b>
</p>
</blockquote>
<p>
This is not to say that computer science programs should neglect theory. Fundamental concepts such as algorithms and data structures are still important. My algorithms class was my favorite and by <i>far</i> the most useful class I ever took for my own computer science degree. But teaching these things at the <i>expense</i> of neglecting more prosaic real world software engineering skills-- skills that you'll desperately need as a practicing software developer-- is a colossal mistake. It's what Steve Yegge was alluding to in his <a href="http://steve-yegge.blogspot.com/2006/07/wizard-school.html">fantastical Wizard School essay</a>.. I think.
</p>
<p>
There is the concern that all those highfalutin' computer science degrees could degenerate into little more than vocational school programs, something Joel mentioned in his <a href="http://www.joelonsoftware.com/items/2007/12/03.html">excellent Yale address</a>:
</p>
<p>
</p>
<blockquote>
At Ivy League institutions, everything is Unix, functional programming, and theoretical stuff about state machines. As you move down the chain to less and less selective schools Java starts to appear. Move even lower and you literally start to see classes in topics like Microsoft Visual Studio 2005 101, three credits. By the time you get to the 2 year institutions, you see the same kind of SQL-Server-in-21-days "certification" courses you see advertised on the weekends on cable TV. Isn't it time to start your career in (different voice) Java Enterprise Beans!
</blockquote>
<p>
You can have it both ways. That's why I'm so gung-ho for internships. College CS classes tend to be so dry and academic that you <i>must</i> spend your summers working in industry, otherwise you won't have the crucial software engineering skills you'll need to survive once you graduate. Unimportant little things like, say, source control and deployment and learning to deal with users.  I constantly harp on internships whenever I meet college students pursuing a computer science degree. It's for your own good.
</p>
<p>
It does strike me as a bit unfair to force students to rely on internships to complete their education in computer science. Or, perhaps, something even worse. "Want to learn computer science? No college necessary! Just download some ISO images and found your own social networking startup!" Unleashing the naked greed of the TechCrunch crowd on tender young programming minds seems downright cruel.
</p>
<p>
So <b>how should we teach computer science?</b> The more cynical among us might say <a href="http://www.codinghorror.com/blog/archives/000635.html">you can't</a>. I think that's a cop-out. If students want to prepare themselves for a career in software development, they need to shed the theory and spend a significant portion of their time creating software with all the warty, prickly, unglamorous bits included. Half of software engineering is pain mitigation. If you aren't cursing your web hosting provider every week, fighting with your source control system every day, deciphering angry bug reports from your users every hour-- you aren't being taught computer science.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-should-we-teach-computer-science/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's On Your Keychain, 2008 Edition ]]></title>
<link>https://blog.codinghorror.com/whats-on-your-keychain-2008-edition/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Over the last few years, I've become mildly obsessive about the contents of my keychain. Here's what's on my keychain today:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In internet parlance, this is known as EDC or <a href="http://en.wikipedia.org/wiki/Every_day_carry">every-day carry</a>. There's <a href="http://www.edcforums.com/">an entire internet forum</a> dedicated to the art and science of determining what goes in your pocket. As expected, in terms of strip-mining an obsession, the internet <i>delivers</i>.
</p>
<p>
I originally wrote about the evolution of my keychain <a href="http://www.codinghorror.com/blog/archives/000251.html">in 2005</a> and again <a href="http://www.codinghorror.com/blog/archives/000608.html">in 2006</a>. Here's the current lineup:
</p>
<p>
</p>
<ol>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B0007UQ1DI/codihorr-20">Leatherman Squirt S4</a> multitool
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000J35DR8/codihorr-20">Corsair 8 GB Flash Voyager</a> thumb drive
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000N2J9MA/codihorr-20">Fenix L0D-CE</a> AAA LED flashlight
</li>
</ol>
<p>
The one constant is the <a href="http://www.amazon.com/exec/obidos/ASIN/B0007UQ1DI/codihorr-20">Leatherman Squirt</a>. Mine is actually personalized with a Pulp Fiction joke that not everyone gets; I opted to flip it over this year so I wouldn't offend. You can view the text in previous years' photos, if you're curious. I absolutely adore the Squirt. There's a reason I've been carrying this great little multitool since 2005; I use it almost every single day. Prior to the Squirt, I carried the <a href="http://www.amazon.com/exec/obidos/ASIN/B0007UQ1B0/codihorr-20">Leatherman Micra</a>, but the Squirt is a far more versatile multitool in almost the same form factor and weight. <b>If you're open to carrying a small multitool, I recommend the Squirt without reservation</b>. I have yet to discover anything better in its weight class. Note that the Squirt comes in a few flavors, which do vary slightly:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.leatherman.com/products/tools/s4/default.asp">Squirt S4</a> with scissors
</li>
<li>
<a href="http://www.leatherman.com/products/tools/p4/default.asp">Squirt P4</a> with needlenose pliers
</li>
<li>
<a href="http://www.leatherman.com/products/tools/e4/default.asp">Squirt E4</a> with wire strippers
</li>
</ul>
<p>
I was, however, sorely tempted to get a <a href="http://www.amazon.com/exec/obidos/ASIN/B000XU43IC/codihorr-20">Leatherman Skeletool</a>. It's beautiful.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000XU43IC/codihorr-20"><img alt="image placeholder" >
</p>
<p>
(The carbon fiber <a href="http://www.amazon.com/exec/obidos/ASIN/B000XU43IC/codihorr-20">CX model</a> is pictured; it also comes in an <a href="http://www.amazon.com/exec/obidos/ASIN/B000XU9NXW/codihorr-20">all-metal version</a> which is $20 cheaper.) According to the Leatherman site, it's twice the weight and size of the Squirt, which puts it squarely out of EDC contention for me.
</p>
<p>
In 2005, I carried a 512 MB thumb drive. In 2006, 1 GB. In 2007, 4 GB. This year it's a whopping <b>8 gigabytes</b>. As capacities increase, speed of the thumb drive becomes paramount. What good is a gigantic 16 GB thumb drive if it takes you an hour to transfer your data? I'd prefer to carry a <a href="http://www.hanselman.com/blog/TinyUSBKeychainDrives.aspx">tiny USB thumb drive</a>, but my research indicated that all the svelte, sexy, impossibly tiny USB thumb drives inevitably come with a <b>hefty speed penalty</b>. My previous 4 GB drive was tiny, the size of a half-stick of gum, but slow enough that I found it awkward to use in practice. After doing a bit more research for this generation of my keychain, I finally arrived at the <a href="http://www.amazon.com/exec/obidos/ASIN/B000J35DR8/codihorr-20">Corsair 8 GB Flash Voyager</a> thumb drive, which offered the best blend of size, speed, and cost. In my testing, I can read from the Flash Voyager at around 25 MB/sec (5 minutes to dump), and write to it at about 7 MB/sec (19 minutes to fill). Not too shabby. Be sure to <b>consider speed when buying <i>your</i> next high capacity USB drive</b>, or like me, you may end up disappointed.
</p>
<p>
I didn't realize how obsolete my barely two year old AAA battery powered LED flashlight was until I picked up the new <a href="http://www.amazon.com/exec/obidos/ASIN/B000N2J9MA/codihorr-20">Fenix L0D-CE</a>. A commenter to my previous keychain post recommended this brand, which sports a fancy new Cree LED. I figured it'd be a minor upgrade, but I was blown away by the difference in brightness compared to my old LED flashlight-- the Fenix L0D is <i>incredibly</i> bright! Don't take my word for it; <a href="http://www.flashlightreviews.com/reviews/fenix_l0dce.htm">this experienced flashight reviewer was impressed too</a>:
</p>
<p>
</p>
<blockquote>
The sheer volume of light produced is amazing for a single AAA cell light. My readings show that on the "high" setting <b>the L0D-CE produces more overall light than a 3-D cell Maglite</b>. On "medium" it produces more overall light than a common 2-D cell light. All this from one AAA cell.
</blockquote>
<p>
You read that right: this little LED dynamo produces more light from a single teeny-tiny AAA than an older, traditional bulb technology Maglite produced from <i>three enormous D cell batteries</i>. Amazing! As alluded to in the review-- and unlike my previous LED flashlight-- this model has five different modes, all selectable by rapidly switching it off, then back on:
</p>
<p>
</p>
<ol>
<li>Medium (default), 3.5 hours @ 20 lumens
</li>
<li>High, 1 hour @ 60 lumens
</li>
<li>Low, 8.5 hours @ 7.5 lumens
</li>
<li>Strobe light
</li>
<li>SOS pattern
</li>
</ol>
<p>
The AAA model is constrained by the limitations of the battery. Imagine how bright the other, larger models in the Fenix family can get:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000ND7W46/codihorr-20">AA model</a>, 90 lumens
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000YW607G/codihorr-20">2 x AA model</a>, 180 lumens
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000ZFAKQ4/codihorr-20">CR123 model</a>, 180 lumens
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000YAX9D6/codihorr-20">2 x CR123 model</a>, 215 lumens
</li>
</ul>
<p>
I had no idea LED technology was advancing so rapidly. Honestly, unless you enjoy blinding people for fun (this does have its charms), the single AAA model should suffice. It is astonishingly bright in any dim area.
</p>
<p>
That's probably far more than you wanted to know about what's on my keychain. So what's on <i>your</i> keychain this year, and why?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-on-your-keychain-2008-edition/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Five Browser Shortcuts Everyone Should Know ]]></title>
<link>https://blog.codinghorror.com/the-five-browser-shortcuts-everyone-should-know/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Nobody has time to memorize <a href="http://www.codinghorror.com/blog/archives/000513.html">a complete list of web browser keyboard shortcuts</a>, and really, why should they? I only know a handful of web browser keyboard shortcuts, myself, and <strong>I probably use the same five shortcuts a hundred times a day</strong>. But not everyone knows about these five essential browser keyboard shortcuts. Let's fix that.</p>
<p>I spend more time in my browser than any other single application on my computer. Launching such a commonly used application should be completely frictionless. I use <a href="http://blogs.msdn.com/tims/archive/2006/09/20/windows-vista-secret-5-running-quick-launch-items.aspx">the built in Windows Vista quick launch shortcuts</a>. My web browser is the first item on my quick launch bar, so all I need to do is tap Windows+1 to bring up a new browser instance.</p>
<p><kbd><img alt="image placeholder" >
<p><strong>Have you set up a keyboard shortcut to launch your preferred web browser?</strong> If not, why not? Once the browser is up, I usually want to be in one of two places: the address bar, or the search box.</p>
<p>To navigate to the <strong>address bar</strong>, press <kbd>Alt</kbd>+<kbd>D</kbd>.</p>
<p><img alt="image placeholder" >
<p>To navigate to the <strong>search box</strong>, press <kbd>Ctrl</kbd>+<kbd>E</kbd>.</p>
<p><img alt="image placeholder" >
<p>Another nifty thing about these two shortcuts is that, if you're running Windows Vista, they <strong>work identically in Vista's File Explorer</strong>. Some keyboard conventions can follow you from the web back to your desktop, too.</p>
<p>Once you've entered the URL or search term, normally you'd press Enter, right? Wait a second. If you press enter, whatever's currently displayed in your browser will be replaced with a different website. But it doesn't have to be. Rather than pressing enter, press <kbd>Alt</kbd>+<kbd>Enter</kbd> to <strong>open the website or search in a new tab</strong>.</p>
<p><img alt="image placeholder" >
<p>These four key sequences probably constitute 99% of the typing I do while browsing the web. If you want to get <a href="http://www.codinghorror.com/blog/archives/000513.html">extra fancy</a> you can use Ctrl+Tab to iterate through all those tabs you now have open in your browser, but it's not required. I'm no keyboard purist. I promote <strong>fully two-handed computer usage</strong>, whether those two hands are tapping away on the keyboard or split between the keyboard and the mouse. I'm often mousing away while I use these shortcuts.</p>
<p>The final shortcut is obvious, once you know it. A few days ago, I received a very nice email from Antonio complimenting my blog, while asking for a change in the design:</p>
<blockquote>I have been reading your blog for a while now and have noticed that on almost all posts there are links to either past posts or other sites. My suggestion is to make the links open in a new window (or in my case a new tab). I want to continue reading your blog post and just have a tab open with the URL of the new link and not make the page I am on load the link's URL. I know I can just right click and then select "open on new tab", but it would be much easier to just click on the links :)</blockquote>
<p>It's a great suggestion. So great, in fact, that this behavior is already built into the web browser. While you're reading, <strong>press the middle mouse button (the "mouse wheel" button) to open related links in a new tab</strong>. The links will open in a new tab in the background, so they don't interrupt the flow of what you're doing. When you're done, you can go back and explore the related sites in all those newly opened tabs at your convenience.</p>
<p><img alt="image placeholder" >
<p>What you end up with is a pile of new tabs. If the middle mouse button giveth, the middle mouse button can also taketh away: <strong>click the middle mouse button on a tab to close it</strong>. I've grown so enamored of this behavior, <a href="http://paulstovell.net/blog/index.php/the-mouse-button-of-death/">like Paul Stovell, I expect middle click conventions to work everywhere</a>. I curse every time I middle-click on a taskbar button, expecting that app to close.</p>
<p>I apologize if you feel I've insulted your intelligence with such basic shortcuts. But realize that <em>not everyone knows what you know</em>. And that's a shame, because these five simple tips …</p>
<ol>
<li>Set up a keyboard shortcut to launch your browser </li>
<li>
<kbd>Alt</kbd>+<kbd>D</kbd> to navigate to the browser address bar </li>
<li>
<kbd>Ctrl</kbd>+E to navigate to the browser search box </li>
<li>
<kbd>Alt</kbd>+<kbd>Enter</kbd> to open searches or websites in a new tab </li>
<li>The middle mouse button opens links in a new tab, and also closes tabs </li>
</ol>
<p>… sure could make browsing the web a much more pleasant experience, if everyone knew about them.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-five-browser-shortcuts-everyone-should-know/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Typography: Where Engineers and Designers Meet ]]></title>
<link>https://blog.codinghorror.com/typography-where-engineers-and-designers-meet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Over the christmas break, my wife and I visited New York City for the first time. One of the many highlights of our trip was the <a href="http://moma.org/">Museum of Modern Art</a>, which is running a year-long special exhibit, <a href="http://www.moma.org/exhibitions/exhibitions.php?id=4506">50 Years of Helvetica</a>. It's a tiny exhibit tucked away in a corner of MoMA. Blink and you'll miss it amongst all the other wonderful art. But even a small exhibit provides ample physical evidence that <b>Helvetica-- a humble font, nothing more than a collection of mathematical curves shaped into letterforms-- had a huge impact on the world</b>.
</p>
<p>
Helvetica is so highly regarded in the design world there's a full length documentary on the topic: <a href="http://www.helveticafilm.com/">Helvetica the Movie</a>.
</p>
<p>
<a href="http://www.helveticafilm.com/"><img alt="image placeholder" >
</p>
<p>
Another little-known fact about Helvetica is the relationship between this timeless classic and another font you've almost certainly encountered before: Arial. <a href="http://daringfireball.net/2007/07/iphone_fonts">John Gruber explains</a>:
</p>
<p>
</p>
<blockquote>
Helvetica is perhaps the most popular typeface in the world, and is widely acclaimed as one of the best. Arial is a tawdry, inferior knock-off of Helvetica, but which, to the detriment of the world, Microsoft chose to license for Windows simply because it was cheaper. Because Arial is a default Windows font and Helvetica is not, it is ubiquitous. <a href="http://www.ms-studio.com/articles.html">Mark Simonson's "The Scourge of Arial"</a> is an excellent resource on both Arial's history and its typographic deficiencies; his <a href="http://www.ms-studio.com/articlesarialsid.html">accompanying sidebar</a> is an excellent primer on the specific differences between Arial and Helvetica.
</blockquote>
<p>
You do have to be something of a font geek to appreciate the subtle differences between <a href="http://en.wikipedia.org/wiki/Helvetica">Helvetica</a> and <a href="http://en.wikipedia.org/wiki/Arial">Arial</a>, much less Helvetica and its precursor, <a href="http://en.wikipedia.org/wiki/Akzidenz-Grotesk">Grotesk</a>. But the discussion leads directly to another hugely important twenty-first century problem: how do you copyright the completely abstract, pure intellectual property that is a <i>font</i>?
</p>
<p>
All computer geeks tend to fall in love with typography at some point in their careers. <a href="http://www.codinghorror.com/blog/archives/001034.html">Donald Knuth</a> is a fine example; frustrated with the limited typesetting options available for his books in the late 70's, Knuth went on a "brief hiatus" to come up with something better. Seven years later, he <a href="http://www.stanfordalumni.org/news/magazine/2006/mayjun/features/knuth.html">unleashed TeX upon the world</a>.
</p>
<blockquote>
In 1977, Knuth halted research on his books for what he expected to be a one-year hiatus. Instead, it took 10. Accompanied by Jill, Knuth took design classes from Stanford art professor Matthew Kahn. Knuth, trying to train his programmer's brain to think like an artist's, wanted to create a program that would understand why each stroke in a typeface would be pleasing to the eye. "I wanted to try to capture the intelligence of the design, not just the outcome of the design," he says. For example, how do you insert line breaks into a paragraph so there isn't too much space between words and so that most of the lines don't end in hyphens? Although this seems like an aesthetic challenge to be solved by human taste, Knuth says, computers do it well. "This is a combinatorial problem," he explains. "There might be a thousand ways to break a paragraph into lines and each way has a score." His solution was to build a computer program capable of ranking the thousand options and picking the best one.
</blockquote>
<p>
<b>Typography and fonts are a rare and vital intersection point between software engineers and designers.</b> And there's absolutely no better book on the topic than <a href="http://www.amazon.com/exec/obidos/ASIN/1568984480/codihorr-20">Thinking with Type: A Critical Guide for Designers, Writers, Editors, &amp; Students</a>. I recommend it without hesitation to all of the above, and certainly to software engineers with even the slightest passing interest in typography.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/1568984480/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Like all great books, it <a href="http://www.codinghorror.com/blog/archives/000189.html">teaches you "why", not "how"</a>:
</p>
<p>
</p>
<blockquote>
This is not a book about fonts. It is a book about how to use them. Typefaces are an essential resource employed by graphic designers, just as glass, stone, steel, and countless other materials are employed by architects. Graphic designers sometimes create their own fonts and custom lettering. More commonly, however, they tap the vast library of existing typefaces, choosing and combining them in response to a particular audience or situation. To do this with wit and wisdom requires knowledge of how-- and why-- letterforms have evolved.
</blockquote>
<p>
I think I can trace my initial interest in fonts way, way back to the pirate crack credit screens on Apple // software I encountered as a wayward teenager.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I count four fonts on this crack screen. There were countless disk sets of these low-resolution bitmap fonts to choose from. Even back in the mid-80s, these primitive fonts added a particular style, a feeling, an intonation to the text-- and we only had a dismal little 280 x 192 screen to work with. How wonderfully liberating it must feel to have thousands of RGB anti-aliased pixels to render beautiful fonts with today, much less the millions we'll <a href="http://www.codinghorror.com/blog/archives/000742.html">eventually have</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/typography-where-engineers-and-designers-meet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ See You at CUSEC 2008 ]]></title>
<link>https://blog.codinghorror.com/see-you-at-cusec-2008/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I have the distinct honor of speaking at this year's CUSEC, which runs from today until Saturday.
</p>
<p>
<a href="http://2008.cusec.net/en/index.php"><img alt="image placeholder" >
</p>
<p>
<a href="http://2008.cusec.net/en/cusecFAQ.php">So what, exactly, is CUSEC?</a>
</p>
<p>
</p>
<blockquote>
CUSEC is the Canadian University Software Engineering Conference, an annual conference about the most interesting topics in software engineering organized for and by students from universities across Canada. What makes CUSEC unique is that it is the only software specific conference that targets students. This means that the presentations you'll see at CUSEC will be about things that matter to you, not just things that matter to professional developers. That doesn't mean that the speakers we get are nobodies, either. Past speakers include David Lorge Parnas, Kathy Sierra, Ralph Johnson, Kent Beck, Alistair Cockburn, Dave Thomas, and many more.
</blockquote>
<p>
They weren't kidding about the impressive speaker list. <a href="http://2008.cusec.net/en/speakers.php">This year's keynote speakers</a> are:
</p>
<p>
</p>
<ul>
<li>
<a href="http://infolab.stanford.edu/~ullman/">Dr. Jeffrey Ullman</a>
</li>
<li>
<a href="http://www.zedshaw.com/">Zed Shaw</a>
</li>
<li>
<a href="http://www.tbray.org/ongoing/">Tim Bray</a>
</li>
<li>
<a href="http://blog.jonudell.net/">Jon Udell</a>
</li>
<li>
<a href="http://users.encs.concordia.ca/~grogono/">Dr. Peter Grogono</a>
</li>
<li>yours truly
</li>
</ul>
<p>
It's hard to shake the feeling that one of these things is not like the others, but I suppose the conference organizers had their reasons for inviting me, however crazy those reasons may seem to me.To provide a sense of history, the <a href="http://2007.cusec.net/presentations.html#keynote">CUSEC keynote speakers from 2007</a>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.pragmaticprogrammer.com/">Dave Thomas</a>
</li>
<li>
<a href="http://www.mcbreen.ab.ca/">Pete McBreen</a>
</li>
<li>
<a href="http://st-www.cs.uiuc.edu/users/johnson/">Ralph E. Johnson</a>
</li>
<li>
<a href="http://www.cs.queensu.ca/~cordy/">James R. Cordy</a>
</li>
<li>
<a href="http://www.pragprog.com/titles/pad">Dr. Venkat Subramanian</a>
</li>
</ul>
<p>
And the CUSEC <a href="http://cusec2006.soen.info/keynote-presentations/">keynote speakers for 2006</a>.
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.cs.concordia.ca/~grogono/index.shtml">Peter Grogono</a>
</li>
<li>
<a href="http://www.loudthinking.com/">David Heinemeier Hansson</a>
</li>
<li>
<a href="http://headrush.typepad.com/creating_passionate_users/">Kathy Sierra</a>
</li>
<li>
<a href="http://chadfowler.com/">Chad Fowler</a>
</li>
<li>
<a href="http://chacs.nrl.navy.mil/ISRE97/heitmeyer.bio">Connie Heitmeyer</a>
</li>
</ul>
<p>
I think you get the idea, so there's no need to list the <a href="http://cusec2006.soen.info/history/cusec-2005/">2005 speakers</a>. It's an honor to be among such distinguished speakers. How distinguished? Many of these folks <i>have their own Wikipedia entries!</i> I had the opportunity to meet <a href="http://en.wikipedia.org/wiki/Tim_Bray">Tim Bray</a> today, for example. Since 2004, CUSEC has grown into the premier conference <i>by</i> computer science students, <i>for</i> computer science students-- across the whole of Canada. It's too bad there isn't an equivalent student-run conference for American computer science students.
</p>
<p>
This is also my first trip to Canada. After many years of wanting to visit our northern neighbors, I've finally made it. I have to agree with William Gibson; as he <a href="http://www.thestar.com/printArticle/247702">wrote in his book Spook Country</a>, <i>Canadian cities look the way American cities do on television.</i> I'm enjoying Montreal and the Canadian perspective on life tremendously. It's refreshing, although I am not sure I needed the televised Capital One Grand Slam of <a href="http://en.wikipedia.org/wiki/Curling">Curling</a>.
</p>
<p>
I wasn't able to find any video archives of previous CUSEC keynotes, but I was told by <a href="http://edwardog.net/">Edward Ocampo-Gooding</a>, our keynote host, that they're capturing hi-def video of this year's keynotes. Assuming my talk isn't a total disaster, <s>I'll update this post with a link to my keynote when it is available.</s>
</p>
<p>
<font color="red">Update: 1/11/09</font> <a href="https://vimeo.com/2796392">Video of my CUSEC keynote is now available</a>.
<iframe src="https://player.vimeo.com/video/2796392" width="500" height="283" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe> </p>
<p><a href="https://vimeo.com/2796392">Jeff Atwood - Is Writing More Important Than Programming?</a> from <a href="https://vimeo.com/cusec">CUSEC</a> on <a href="https://vimeo.com">Vimeo</a>.</p>
<p>
<font color="red">Update: 1/23/08</font> My CUSEC 2008 keynote slides, "Is Writing More Important Than Programming?", <a href="http://www.codinghorror.com/blog/files/cusec-2008-presentation-jeff-atwood.zip">are available for local download</a> (ppt, 3mb).<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2008-01-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/see-you-at-cusec-2008/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Sesame Street Presentation Rule ]]></title>
<link>https://blog.codinghorror.com/the-sesame-street-presentation-rule/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
After being on both the giving and receiving end of plenty of presentations, I now realize there's one golden rule which applies to all of them:
</p>
<p>
<b>Entertain your audience.</b>
</p>
<p>
Every slide of your presentation should serve this fundamental vision statement. Is it <i>entertaining?</i> I don't mean each slide has to contain a wacky joke of some kind. Every slide should <b>provoke a reaction from the audience</b> -- be it controversial, unexpected, amusing, or a meditative Zen koan. Prod your audience. Do this not only to keep them awake, but to engage their brains. Deliver a series of short, sharp shocks that jolt your audience into a heightened state of engagement.
</p>
<p>
Once your audience has engaged with your presentation, <i>that's</i> when you trick them into learning. The very best presentations entertain <i>and</i> educate-- the common <a href="http://en.wikipedia.org/wiki/Portmanteau">portmanteau</a> is <a href="http://en.wikipedia.org/wiki/Edutainment">edutainment</a>. The archetypal example of edutainment is <a href="http://en.wikipedia.org/wiki/Sesame_Street">Sesame Street</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Sesame_Street">Sesame Street</a> is the second longest running children's show in the world, racking up 4,160 episodes over 38 seasons so far. They must be doing <i>something</i> right.
</p>
<p>
</p>
<blockquote>
The show's format called for the humans to be intermixed with the segments of animation, live-action shorts and Muppets. These segments were created to be like commercials-- quick, catchy and memorable-- and made the learning experience much more like fun. <b>The format became a model for what is known today as edutainment-based programming.</b>
<p>
CTW aired the program for test groups to determine if the revolutionary new format was likely to succeed. Results showed that test watchers were entranced when the ad-like segments aired, especially those with the jovial puppets, but were remarkably less interested in the street scenes. Psychologists warned CTW against a mixture of fantasy and reality elements, but producers soon decided to mix the elements. A simple dose of cartoon-like characters lets the humans deliver messages without causing viewers to lose interest.
</p>
</blockquote>
<p>
You might think it's patronizing to lift techniques from a television show aimed at preschoolers, but I find that people of all ages need to be entertained to fully engage with what whatever it is you're presenting. That's why <b>your primary goal for any presentation is to entertain</b>. If the audience doesn't walk out of your presentation thinking "gee, that was fun!", then I can practically guarantee they'll remember little about you or your talk. There's nothing more stultifying than walking out of yet another interminable, droning presentation to realize that all you have to show for it is another hour of your life ticked away. If you design to entertain first and teach second, even if your presentation bombs, at least the audience will get some fleeting entertainment out of the time they invested in you.
</p>
<p>
So the next time you're putting a presentation together, remember <b>the Sesame Street Presentation Rule</b> -- don't forget to add the muppets!
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-sesame-street-presentation-rule/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Reinventing the Clipboard ]]></title>
<link>https://blog.codinghorror.com/reinventing-the-clipboard/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Over time, I've become something of a desktop mimimalist. Sure, I'll change a few settings to my liking, but <a href="http://www.codinghorror.com/blog/archives/000382.html">I no longer spend a lot of time customizing my desktop configuration</a>. I've learned that if the defaults aren't reasonably close to correct out of the box, then the software is probably doomed anyway. For most users <a href="http://www.codinghorror.com/blog/archives/000290.html">the default settings are the only settings</a>.</p>
<p>One of the things I <em>always</em> have to change, much to my chagrin, is the default clipboard behavior. I <a href="http://www.codinghorror.com/blog/archives/000431.html">originally wrote about this in 2005</a>:</p>
<blockquote>In this era of 3 GHz processors, 1 GB memory, and 500 GB hard drives, <strong>why is the Windows clipboard only capable of holding a single item?</strong> Sure, you have fancy multi-level undo and redo in applications like Microsoft Word and Visual Studio. But not the clipboard. It holds <em>exactly one item</em>. Copy another item to the clipboard and your previous clipboard item is irrevocably lost.</blockquote>
<p>The only improvement since then, sadly, is in the PC specifications. Three years later, we're stuck with the same old single-item clipboard model. The clipboard isn't some obscure operating system feature, either. People use it all the time. There's actually hard data to back this up, at least <a href="http://blogs.msdn.com/jensenh/archive/2006/04/07/570798.aspx">for Word 2003</a>:</p>
<blockquote>Top 5 Most-Used Commands in Microsoft Word 2003
<ol>
<li>
<strong>Paste</strong> </li>
<li>Save </li>
<li>
<strong>Copy</strong> </li>
<li>Undo </li>
<li>Bold </li>
</ol>
<p>Together, these five commands account for around 32% of the total command use in Word 2003. Paste itself accounts for more than 11% of all commands used, and has more than twice as much usage as the #2 entry on the list, Save.</p>
</blockquote>
<p>Granted, we're talking about a word processing program here, but we live in a <a href="http://www.urbandictionary.com/define.php?term=copypasta">copypasta</a> culture. I find that even when I'm not writing, per se, I rely on my clipboard throughout the day. The clipboard is so important that Walter Mossberg specifically mentioned it as a negative in <a href="http://solution.allthingsd.com/20070626/the-iphone-is-breakthrough-handheld-computer/">his iPhone review</a>:</p>
<blockquote>There's also no way to cut, copy, or paste text.</blockquote>
<p>This is on a <em>phone</em>, mind you. I'm totally with Walt on this one; it applies to all smartphones. I was surprised how quickly I ran into situations where I wanted to copy and paste something on my Windows Mobile phone, but I couldn't figure out how to. It's not a crippling limitation, but it does illustrate how fundamental the clipboard is, even for the smallest of computers.</p>
<p>It always seemed strange to me that applications had to implement their own oddball per-app clipboard queues to <strong>spackle over deficiencies in the operating system's braindead "I can only remember one thing at a time" clipboard implementation</strong>. We've long since left the days of applications writing their own quirky little file open dialog behind, but it's somehow OK to implement your own wacky clipboard behaviors in Visual Studio, or Office?</p>
<p>If, like me, you'd prefer operating system level improvements in the clipboard, there are quite a few options out there. I've been quite happy with <a href="http://www.bluemars.org/clipx/">ClipX</a>. After installing this lightweight little app, instead of pressing</p>
<kbd>Ctrl</kbd> + <kbd>V</kbd>
<p>to paste a single item, you can opt to press</p>
<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>V</kbd>
<p>whereupon you're presented with a menu of recent clipboard items, in a nice visual menu browser format:</p>
<p><img alt="image placeholder" >
<p>Your clipboard history is dynamically saved to disk and will <strong>survive a reboot</strong>, so you can begin to rely on your clipboard as a sort of quick and dirty digital scrapbook. Isn't that how it should have been all along?</p>
<p>I've become terribly reliant on this improved clipboard behavior, so I always install <a href="http://www.bluemars.org/clipx/">ClipX</a> on any machine I'm working on. It has some additional default clipboard functions that I've also found quite useful:</p>
<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>G</kbd>
<p>perform a Google search using the contents of the clipboard.</p>
<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>N</kbd>
<p>open a browser and navigate to the address in the clipboard.</p>
<p>It doesn't matter whether you specifically choose ClipX. It's these <strong>three key improvements in the operating system clipboard</strong> that I think are important:</p>
<ol>
<li>history </li>
<li>persistence </li>
<li>visual browser </li>
</ol>
<p>It's a mystery to me why none of the major operating systems have bothered improving the clipboard. It seems entirely possible to add these enhancements without breaking the simple clipboard paradigms that have been around since the days of Xerox PARC.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/reinventing-the-clipboard/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Getting the Interview Phone Screen Right ]]></title>
<link>https://blog.codinghorror.com/getting-the-interview-phone-screen-right/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The job market for software developers is hot. This is great news for programmers, but it makes the interview process challenging for potential employers. A reader recently wrote me expressing some concern about the interview process:
</p>
<p>
</p>
<blockquote>
You mention Vertigo requiring <b>a code sample, then a phone screening, then a hands-on test in the face-to-face</b>. We have a very similar process, but somehow a large percentage of the candidates who make it to the hands-on test are very poor and should have been eliminated at step 1 or 2. The signal to noise ratio is terrible. It costs a great deal to spend so much time doing face-to-face interviews with people who often should not be developers in the first place. I am curious how much light you might be able to shed on the specifics of your requirements on candidates. What part of the process is the most effective in separating the cream, how and why?
</blockquote>
<p>
It is <b>very expensive to get the phone screen wrong</b>-- a giant waste of time for everyone involved.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The best phone screen article you'll ever find is Steve Yegge's <a href="http://steve.yegge.googlepages.com/five-essential-phone-screen-questions">Five Essential Phone-Screen Questions</a>, another gift to us from Steve's stint at Amazon.
</p>
<p>
Steve starts by noting two critical mistakes that phone screeners should do their best to avoid:
</p>
<p>
</p>
<ol>
<li>
<b>Don't let the candidate drive the interview.</b> The interviewer should do most of the talking, guiding the conversation along until they're satisfied the candidate knows the answers to the questions (or has given up).
</li>
<li>
<b>Watch out for one-trick ponies.</b> Candidates who only know one particular language or programming environment, and protest complete ignorance of everything else, are a giant red warning flag.
</li>
</ol>
<p>
The point of the phone screen is not for the candidate to drone on about what they've done. The interviewer should push them out of their comfort zone a bit and ask them <i>related</i> questions about things they haven't seen or done before. Ideally, you want to know how this person will react when they face something new, such as <i>your</i> codebase.
</p>
<p>
</p>
<blockquote>
In an effort to make life simpler for phone screeners, I've put together this list of Five Essential Questions that you need to ask during an SDE screen. They won't guarantee that your candidate will be great, but they will help eliminate a huge number of candidates who are slipping through our process today.
<p>
1) <b>Coding.</b> The candidate has to write some simple code, with correct syntax, in C, C++, or Java.
</p>
<p>
2) <b>OO design.</b> The candidate has to define basic OO concepts, and come up with classes to model a simple problem.
</p>
<p>
3) <b>Scripting and regexes.</b> The candidate has to describe how to find the phone numbers in 50,000 HTML pages.
</p>
<p>
4) <b>Data structures.</b> The candidate has to demonstrate basic knowledge of the most common data structures.
</p>
<p>
5) <b>Bits and bytes.</b> The candidate has to answer simple questions about bits, bytes, and binary numbers.
</p>
<p>
<font color="red">Please understand:</font> <b>what I'm looking for here is a total vacuum in one of these areas.</b> It's OK if they struggle a little and then figure it out. It's OK if they need some minor hints or prompting. I don't mind if they're rusty or slow. What you're looking for is candidates who are utterly clueless, or horribly confused, about the area in question.
</p>
</blockquote>
<p>
Of course, you'll want to modify this process to reflect the realities at your shop-- so I encourage you to <a href="http://steve.yegge.googlepages.com/five-essential-phone-screen-questions">read the entire article</a>. But Steve does provide some examples to get you started:
</p>
<p>
<b>Coding</b>
</p>
<p>
</p>
<blockquote>
Write a function to reverse a string.<br>
Write function to compute Nth fibonacci number.<br>
Print out the grade-school multiplication table up to 12x12.<br>
Write a function that sums up integers from a text file, one int per line.<br>
Write function to print the odd numbers from 1 to 99.<br>
Find the largest int value in an int array. <br>
Format an RGB value (three 1-byte numbers) as a 6-digit hexadecimal string.<br>
</blockquote>
<p>
Good candidates for the coding problem are verifiably simple, with basic loops or recursion and perhaps a little formatted output or file I/O. All we want to know is whether they really do know how to program or not. Steve's article predates it, but I'd be remiss if I didn't mention <a href="http://www.codinghorror.com/blog/archives/000781.html">Why Can't Programmers.. Program?</a> here. The FizzBuzz problem is quite similar, and it's shocking how often interviewees can't do it. It's a bit hard to comprehend, like a potential truck driver somehow not being able to find the gas pedal or shift gears.
</p>
<p>
<b>Object-Oriented Programming</b>
</p>
<p>
</p>
<blockquote>
Design a deck of cards that can be used for different card game applications. <br>
Model the Animal kingdom as a class system, for use in a Virtual Zoo program. <br>
Create a class design to represent a filesystem. <br>
Design an OO representation to model HTML. <br>
</blockquote>
<p>
We're not saying anything about the pros and cons of OO design here, nor are we asking for a comprehensive, low-level OO design. These questions are here to determine whether candidates are familiar with the basic principles of OO, and more importantly, whether the candidate can produce a reasonable-sounding OO solution. We're looking for understanding of the basic principles, as described in <a href="http://www.codinghorror.com/blog/archives/000628.html">the Monopoly Interview</a>.
</p>
<p>
<b>Scripting and Regular Expressions</b>
</p>
<p>
</p>
<blockquote>
Last year my team had to remove all the phone numbers from 50,000 Amazon web page templates, since many of the numbers were no longer in service, and we also wanted to route all customer contacts through a single page.
<p>
Let's say you're on my team, and we have to identify the pages having probable U.S. phone numbers in them. To simplify the problem slightly, assume we have 50,000 HTML files in a Unix directory tree, under a directory called "/website". We have 2 days to get a list of file paths to the editorial staff. You need to give me a list of the .html files in this directory tree that appear to contain phone numbers in the following two formats: (xxx) xxx-xxxx and xxx-xxx-xxxx.
</p>
<p>
How would you solve this problem? Keep in mind our team is on a short (2-day) timeline.
</p>
</blockquote>
<p>
This is an interesting one. Steve says 25% to 35% of all software development engineer candidates cannot solve this problem at all-- even with lots of hints and given the entire interview hour. What we're looking for is a general reluctance to reinvent the wheel, and some familiarity with scripting languages and regular expressions. To me, this question indicates whether a developer will spend days doing programming work that he or she could have neatly avoided with, perhaps, a quick web search and some existing code that's already out there.
</p>
<p>
<b>Data Structures</b>
</p>
<p>
</p>
<blockquote>
What are some really common data structures, e.g. in <code>java.util</code>? <br>
When would you use a linked list vs. a vector? <br>
Can you implement a Map with a tree? What about with a list? <br>
How do you print out the nodes of a tree in level-order (i.e. first level, then 2nd level, then 3rd level, etc.) <br>
What's the worst-case insertion performance of a hashtable? Of a binary tree? <br>
What are some options for implementing a priority queue? <br>
</blockquote>
<p>
A candidate should be able to demonstrate a basic understanding of the most common data structures. More specifically, the big ones like arrays, vectors, linked lists, hashtables, trees, and graphs. They should also know the fundamentals of "big-O" algorithmic complexity: constant, logarithmic, linear, polynomial, exponential, and factorial. If they can't, that's a huge warning flag.
</p>
<p>
<b>Bits and Bytes</b>
</p>
<p>
</p>
<blockquote>
Tell me how to test whether the high-order bit is set in a byte. <br>
Write a function to count all the bits in an int value; e.g. the function with the signature <code>int countBits(int x)</code> <br>
Describe a function that takes an int value, and returns true if the bit pattern of that int value is the same if you reverse it (i.e. it's a palindrome); i.e. <code>boolean isPalindrome(int x)</code> <br>
</blockquote>
<p>
As Steve says, <i>"Computers don't have ten fingers, they have one. So people need to know this stuff."</i> You shouldn't be treated to an uncomfortable silence after asking a candidate what 2^16 is; it's a special number. They should know it. Similarly, they should know the fundamentals of AND, OR, NOT and XOR-- and how a bitwise AND differs from a logical AND. You might even ask about signed vs. unsigned, and why bit-shifting operations might be important. They should be able to explain why the old programmer's joke, "why do programmers think Oct 31 and Dec 25 are the same day?" is funny.
</p>
<p>
Performing a thorough, detailed phone screen is a lot of work. But it's worth it. Every candidate eliminated through the phone screen saves at least 8 man-hours of time that would have been wasted by everyone in a hands-on test. Each time an unqualified candidate makes it to the hands-on test, you should be asking yourself-- <b>how could we have eliminated this candidate in the phone screen?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/getting-the-interview-phone-screen-right/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What Can You Build in 600 Lines of Code? ]]></title>
<link>https://blog.codinghorror.com/what-can-you-build-in-600-lines-of-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Joseph Cooney reminds us that, in January 2005, <a href="http://jcooney.net/archive/2007/08/16/54435.aspx">37signals went live with a product they built in 579 lines of code</a>:
</p>
<p>
</p>
<blockquote>
You read that right, not 60,000 or 600,000 but instead <b>a commercial project written in less than 600 lines of Ruby code</b>. When I first saw this number I was incredulous -- I've written stored procedures that are longer than that. My current project has more lines of configuration than that. I've even written console apps in notepad, and compiled from the command line with more lines than that, because I thought they were so small they didn't need a whole .sln and .proj file, and yet here is <a href="http://www.37signals.com/svn/archives/001021.php">37signals going live</a> with a <a href="http://www.tadalist.com/">product</a> that is just 579 lines of Ruby.
</blockquote>
<p>
As <a href="http://weblog.rubyonrails.com/2005/01/21/matz-takes-note-of-ta-da-and-rails/">noted in the Rails blog</a>, the original product launch was covered on Ruby language creator <a href="http://en.wikipedia.org/wiki/Yukihiro_Matsumoto">Matz'</a> blog in his native Japanese. Surprisingly, the relevant facts are still readable:
</p>
<p>
<a href="http://www.rubyist.net/~matz/20050120.html#c"><img alt="image placeholder" >
</p>
<p>
Of course, a simple lines of code number isn't the entire story-- they actually built the entire Rails framework first to support building small apps like <a href="http://www.tadalist.com/">ta-da list</a>. None of the required Rails framework code, nor any of the the necessary stylesheets, JavaScript, HTML, and so forth, are included in that number. Still, I agree with Joseph: it's an impressive achievement, and it can lead to some interesting thought experiments:
</p>
<p>
</p>
<blockquote>
I have a few interesting product ideas from time to time. What is the absolute minimum amount of code I could write that would make those ideas work? If I'm prepared to operate within the constraints of the platform (whatever that is) how much effort would that save me? How many more "interesting ideas" could I turn into working products if I was prepared to follow these constraints? How many more cool/useful things could you build if you promised yourself that each one would only be 600 lines of code?
</blockquote>
<p>
<b>What can <i>you</i> build in 600 lines of code?</b> Think of it as an exercise in minimalism. Does your preferred language or environment allow you the freedom to create something interesting and useful with that constraint in place?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/what-can-you-build-in-600-lines-of-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Doesn't Anyone Give a Crap About Freedom Zero? ]]></title>
<link>https://blog.codinghorror.com/why-doesnt-anyone-give-a-crap-about-freedom-zero/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I never quite made the transition from the Apple II series to the Mac. Instead, I migrated from my Apple II to a PC. I always thought the PC ecosystem, although <i>deeply</i> flawed, was more naturally analogous to the eclectic third party hardware and software hacker ecosystem that grew up around the semi-open Apple II hardware platform. This, to me, was the most enduring and beloved quality of the early Apple community. The Mac, in contrast, was underwritten and driven by primarily Apple software running on completely locked down Apple hardware. It's almost first party only –  about as close as you can get to a console platform and still call yourself a computer. I guess you'd say I chose Woz over Jobs. The way Jobs <a href="http://en.wikipedia.org/wiki/Macintosh_clone">ruthlessly crushed the fledgling clone market in 1997</a> only reinforced this lesson for me.</p>
<p>So let's be completely clear: <b>when you buy a new Mac, you're buying a giant hardware dongle</b> that allows you to run OS X software.</p>
<img alt="image placeholder" >
<p>You know, a <a href="http://en.wikipedia.org/wiki/Dongle">dongle</a>:</p>
<blockquote>
<p>A dongle is a small hardware device that connects to a computer, often to authenticate a piece of software. When the dongle is not present, the software runs in a restricted mode or refuses to run. Dongles are used by some proprietary vendors as a form of copy prevention or digital rights management because it is much harder to copy the dongle than to copy the software it authenticates. Vendors of software protection dongles (and dongle-controlled software) often use terms such as hardware key, hardware token, or security device in their written literature. In day-to-day use however, the jargon word "dongle" is much more commonly used.</p>
</blockquote>
<p>There's nothing harder to copy than an entire MacBook. When the dongle –  or, if you prefer, the "Apple Mac" –   is present, OS X and Apple software runs. It's a remarkably pretty, well-designed machine, to be sure. But let's not kid ourselves: it's also one hell of a dongle.</p>
<p>If the above sounds disapproving in tone, perhaps it is. There's something distasteful to me about dongles, no matter how cool they may be. But it's seductive, too. I wonder if the console model that Jobs is aping isn't some temporary evolutionary dead end, but in fact, the model for all future computing. <b>People buy consoles like the Xbox 360 and Wii because they work with a minimum of fuss.</b> Similarly, people buy Apple hardware because of the perfect synergy between the Apple hardware, OS X, iTunes, iLife, iMovie, iPhoto, and countless other software packages expressly designed to run on a closed hardware platform. "It just works." And why wouldn't it? There are no crude, selfish third parties to screw the experience up behind your back. No oddball hardware, no incompatible drivers, no more software which has to deal with a combinatorial explosion of potential configurations. Choosing to run proprietary software and hardware is just that, a choice. If it's working for consumers, who am I to judge?</p>
<p>I find Apple's brand of hardware lock-in particularly egregious. On the other hand, I run Windows, so I'm subject to my own flavor of self imposed software lock-in. Others have made different choices. In <a href="http://web.archive.org/web/20080814232602/http://diveintomark.org/archives/2008/01/17/of-canaries-and-coal-mines">of canaries and coal mines</a>, Mark Pilgrim revisits his choice to <a href="http://web.archive.org/web/20080811183542/http://diveintomark.org/archives/2006/06/02/when-the-bough-breaks">abandon Apple's proprietary software model</a> for the world of free software.</p>
<blockquote>
<p>18 months later, Apple has sold 4 million <a href="http://web.archive.org/web/20080827175841/http://diveintomark.org/archives/2007/10/04/if-wishes-were-iphones">crippled phones</a>, billions of crippled songs, and people are predicting that <a href="http://www.appleinsider.com/articles/08/01/14/mac_sales_up_over_40_percent_year_over_year.html">Mac sales are up 40% year over year</a>. And I wouldn't bet against their new movie rental venture either.</p>
<p>So after 18 months, I think we can safely say that no, Cory and I were not "canaries in the coal mine." There are not hordes of fed-up consumers rejecting Apple's vision of cryptographic lock-in. There are not mass graves where people ceremoniously dump their crippled, non-general-purpose computing devices. Outside of <a href="http://planet.debian.org/">Planet Debian</a> and my own personal echo chamber, <b>nobody gives a sh*t about Freedom 0.</b></p>
<p>You knew this, of course, but I just wanted to let you know that I knew, too.</p>
</blockquote>
<p>Maybe I'm a hypocrite. Maybe the issue cuts philosophically deeper than mere dongles. Maybe it's not only about the freedom to run your operating system on whatever hardware you wish, but also the freedom to run whatever software you want for whatever purpose you need, in perpetuity. That's <a href="http://web.archive.org/web/20080818112510/http://diveintomark.org/archives/2004/05/14/freedom-0">Freedom Zero</a>:</p>
<blockquote>
<p><a href="http://www.gnu.org/philosophy/free-sw.html">Freedom 0 is the freedom to run the program, for any purpose</a>. WordPress gives me that freedom; Movable Type does not. It never really did, but it was free enough so we all looked the other way, myself included. But Movable Type 3.0 changes the rules, and prices me right out of the market. I do not have the freedom to run the program for any purpose; I only have the limited set of freedoms that Six Apart chooses to bestow upon me, and every new version seems to bestow fewer and fewer freedoms. With Movable Type 2.6, I was allowed to run 11 sites. In 3.0, that right will cost me $535.</p>
<p>WordPress is Free Software. Its rules will never change. In the event that the WordPress community disbands and development stops, a new community can form around the orphaned code. It's happened once already. In the extremely unlikely event that every single contributor (including every contributor to the original b2) agrees to relicense the code under a more restrictive license, I can still fork the current GPL-licensed code and start a new community around it. There is always a path forward. There are no dead ends.</p>
<p>Movable Type is a dead end. In the long run, the utility of all non-Free software approaches zero. All non-Free software is a dead end.</p>
</blockquote>
<p>It's compelling rhetoric. As a software developer, there's no denying that open source software is a powerful and transformative force in modern software development.</p>
<p>The console model, and Apple's de-facto first party development model, are about as far as you can get from Mark's freedom zero –  instead, you get <b>zero freedom</b>. You hand the vendor a pile of cash and they allow you to do a handful of specific things with their device, for only so long as they're inclined to do so. It's hardly fair. In fact it's completely <i>unfair</i>; they can legally pull the rug out from under you at any time. But it can still result in some incredibly useful relationships with products that solve very real problems for the user. As Jaron Lanier notes, <a href="http://discovermagazine.com/2007/dec/long-live-closed-source-software">the iPhone was not a product of freedom zero</a>:</p>
<blockquote>
<p>Twenty-five years later, that concern seems to have been justified. Open wisdom-of-crowds software movements have become influential, but they haven't promoted the kind of radical creativity I love most in computer science. If anything, they've been hindrances. Some of the youngest, brightest minds have been trapped in a 1970s intellectual framework because they are hypnotized into accepting old software designs as if they were facts of nature. Linux is a superbly polished copy of an antique, shinier than the original, perhaps, but still defined by it.</p>
<p>Before you write me that angry e-mail, please know I'm not anti-open source. I frequently argue for it in various specific projects. But a politically correct dogma holds that open source is automatically the best path to creativity and innovation, and that claim is not borne out by the facts.</p>
<p>Why are so many of the more sophisticated examples of code in the online world –  like the page-rank algorithms in the top search engines or like Adobe's Flash –  the results of proprietary development? Why did the adored iPhone come out of what many regard as the most closed, tyrannically managed software-development shop on Earth? An honest empiricist must conclude that while the open approach has been able to create lovely, polished copies, it hasn't been so good at creating notable originals. Even though the open-source movement has a stinging countercultural rhetoric, it has in practice been a conservative force.</p>
</blockquote>
<p>So I'll ask again, since Mark brought it up: <b>why <i>doesn't</i> anyone give a crap about freedom zero?</b></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-doesnt-anyone-give-a-crap-about-freedom-zero/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's Your Backup Strategy? ]]></title>
<link>https://blog.codinghorror.com/whats-your-backup-strategy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Jamie Zawinski's <a href="http://jwz.livejournal.com/801607.html">public service backup announcement</a> starts off with a bang:
</p>
<p>
</p>
<blockquote>
<b>Option 1</b>: Learn not to care about your data. Don't save any old email, use a film camera, and only listen to physical CDs and not MP3s. If you have no possessions, you have nothing to lose.
</blockquote>
<p>
This is obviously meant as satire, but it's disturbingly close to reality for me. I suppose everything in my life that's worth capturing... well, let me put it this way: you're reading it. When I said <a href="http://www.codinghorror.com/blog/archives/000840.html">make it public</a>, I really meant it. Still, I'm fairly sure Jamie was kidding, and while Google may be a great service, it's only a so-so backup mechanism. Let's proceed to <b>option 2</b>, which goes something like this:
</p>
<p>
</p>
<blockquote>
1) You have a computer. It came with a hard drive in it. Go buy two more drives of the same size or larger. If the drive in your computer is SATA2, get SATA2. If it's a 2.5" laptop drive, get two of those. Brand doesn't matter, but physical measurements and connectors should match.
<p>
2) Get external enclosures for both of them. The enclosures are under $30.
</p>
<p>
3) Put one of these drives in its enclosure on your desk. Name it something clever like "Backup". If you are using a Mac, the command you use to back up is this:
</p>
<p>
<code>sudo rsync -vaxE --delete --ignore-errors / /Volumes/Backup/</code>
</p>
<p>
If you're using Linux, it's something a lot like that. If you're using Windows, go f*ck yourself.
</p>
</blockquote>
<p>
Yeah! Take that, Windows users! Hey, wait a second. <i>I</i> use Windows. Did I mention that Jamie is a funny guy? Moving on.
</p>
<p>
I've long been a fan of <a href="http://www.codinghorror.com/blog/archives/000714.html">inexpensive hard drive enclosures</a>. Jamie's advice confirms my long held opinion that <b>multiple hard drives are the most effective and easy backup process you'll ever find</b>. The <a href="http://linux.about.com/library/cmd/blcmdl1_rsync.htm"><code>rsync</code> command</a> is more than a simple copy; it actually does a block-by-block comparison, only copying the differences. So instead of backing up the entire contents of your hard drive (again), you only back up the parts that changed since your last backup. This is commonly known as <a href="http://en.wikipedia.org/wiki/Incremental_backup">incremental backup</a>.
</p>
<p>
Incremental backups only have value if you're doing them regularly, so it's only natural to schedule this as a recurring task.
</p>
<p>
</p>
<blockquote>
4) If you have a desktop computer, have this happen every morning at 5AM by creating a temporary text file containing this line:
<p>
<code>0 5 * * * rsync -vaxE --delete --ignore-errors / /Volumes/Backup/</code>
</p>
<p>
and then doing <code>sudo crontab -u root that-file</code>
</p>
<p>
If you have a laptop, do that before you go to bed. Really. Every night when you plug your laptop in to charge.
</p>
<p>
5) If you're on a Mac, that backup drive will be bootable. That means that when (WHEN) your internal drive scorches itself, you can just take your backup drive and put it in your computer and go. This is nice.
</p>
<p>
6) When (WHEN) your backup drive goes bad, which you will notice because your last backup failed, replace it immediately. This is your number one priority. Don't wait until the weekend when you have time, do it now, before you so much as touch your computer again. Do it before goddamned breakfast. The universe tends toward maximum irony. Don't push it.
</p>
<p>
7) That third drive? Do a backup onto it the same way, then take that to your office and lock it in a desk. Every few months, bring it home, do a backup, and immediately take it away again. This is your "my house burned down" backup.
</p>
</blockquote>
<p>
What I like about Jamie's approach is that it's totally <a href="http://en.wikipedia.org/wiki/KISS_principle">KISS</a>, yet it touches all the cornerstones of a solid backup strategy:
</p>
<p>
</p>
<ol>
<li>Pick a simple backup strategy you can live with.
</li>
<li>Make incremental backups a part of your daily routine.
</li>
<li>Include an off-site backup in your strategy.
</li>
</ol>
<p>
And for the dissenters, although I can't imagine too many with the minimalist backup process Jamie outlined, there's this <i>bon mot</i>:
</p>
<p>
</p>
<blockquote>
"OMG, three drives is so expensive! That sounds like a hassle!" <b>Shut up. I know things. You will listen to me. Do it anyway.</b>
</blockquote>
<p>
I'm not sure Windows users have a direct equivalent of rsync. There is, of course, <a href="http://mark.michaelis.net/Blog/RobocopyStandardOnWindowsVista.aspx">RoboCopy</a>, and it looks like someone has <a href="http://www.aboutmyip.com/AboutMyXApp/DeltaCopy.jsp">ported rsync to Windows</a>. But let's face it. I'm a Windows user. When I have a problem, <b>I buy software</b>. That's why, after hearing so many great things about it, I recently purchased a copy of <a href="http://www.amazon.com/exec/obidos/ASIN/B000VLZCEW/codihorr-20">Acronis True Image</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000VLZCEW/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Acronis does a lot of things, but most of all it's <b>drive imaging software, a fancy GUI over the <code>rsync</code> command</b>. With Jamie's recommended two external hard drives in tow, I can use Acronis to create a bootable mirror image of my hard drive. If anything at all goes wrong, I simply <b>swap hard drives, and I'm back in business</b>. I can even create those backup images incrementally and on a schedule. You don't even technically need a second or third hard drive; if you have a large enough primary drive, Acronis will allow you to create a new, hidden partition to store a complete backup image. You can restore these disk images from within Windows proper, during pre-boot, or from bootable USB or optical media. It is very cool, a logical evolution of the more primitive drive imaging products I've used for years.
</p>
<p>
Of course, as much as I am enamored of it, you don't have to spend thirty bucks on Acronis and even more for two external hard drives to have a decent backup strategy. Lots of people use completely internet based backup services, like <a href="http://mozy.com/">Mozy</a>, <a href="http://www.carbonite.com/">Carbonite</a>, or <a href="http://www.jungledisk.com/">JungleDisk</a>, with varying degrees of success. One thing's for sure: until you <i>have</i> a backup strategy of some kind, you're screwed, you just don't know it yet. If backing up your data sounds like a hassle, that's because it is. <b>Shut up. I know things. You will listen to me. Do it anyway.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-your-backup-strategy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is Worse Really Better? ]]></title>
<link>https://blog.codinghorror.com/is-worse-really-better/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
You may think of Steve Martin as a stereotypical family friendly comedian today-- the center of saccharine movies like <a href="http://www.imdb.com/title/tt0098067/">Parenthood</a> and <a href="http://www.imdb.com/title/tt0101862/">Father of the Bride</a>. But it wasn't always this way. Steve hit his stride in the early 80's. At that time, I don't think there were any popular comedians exploring the ragged edge of humor in quite the same way Steve Martin was. I'll forever remember finding a copy of his book <a href="http://www.amazon.com/exec/obidos/ASIN/0399123040/codihorr-20">Cruel Shoes</a> as an impressionable teenager. It's a collection of very strange short stories. At my tender young age, I had certainly never read anything like it. It's hard to explain. Read for yourself. Here's the complete text of the eponymous <i>Cruel Shoes</i> short story:
</p>
<p>
</p>
<blockquote>
Anna knew she had to have some new shoes today, and Carlo had helped her try on every pair in the store. Carlo spoke wearily, "Well, that's every pair of shoes in the place."
<p>
"Oh, you must have one more pair ..."
</p>
<p>
"No, not one more pair...Well, we have the cruel shoes, but no one would want..."
</p>
<p>
Anna interrupted, "Oh yes, let me see the cruel shoes!"
</p>
<p>
Carlo looked incredulous. "No, Anna, you don't understand, you see, the cruel shoes are..."
</p>
<p>
"Get them!"
</p>
<p>
Carlo disappeared into the back room for a moment, then returned with an ordinary shoebox. He opened the lid and removed a hideous pair of black and white pumps. But these were not an ordinary pair of black and white pumps; both were left feet, one had a right angle turn with seperate compartments that pointed the toes in impossible directions. The other shoe was six inches long and was curved inward like a rocking chair with a vise and razor blades to hold the foot in place. Carlo spoke hesitantly, "...Now you see why...they're not fit for humans..."
</p>
<p>
"Put them on me."
</p>
<p>
"But..."
</p>
<p>
"Put them on me!"
</p>
<p>
Carlo knew all arguments were useless. He knelt down before her and forced the feet into the shoes.
</p>
<p>
The screams were incredible.
</p>
<p>
Anna crawled to the mirror and held her bloody feet up where she could see.
</p>
<p>
"I like them."
</p>
<p>
She paid Carlo and crawled out of the store into the street.
</p>
<p>
Later that day, Carlo was overheard saying to a new customer, "Well, that's every shoe in the place. Unless, of course, you'd like to try the cruel shoes."
</p>
</blockquote>
<p>
Funny, yes, but also disturbing-- you feel vaguely uncomfortable while laughing at <i>Cruel Shoes</i>. That awkward feeling is what makes Steve's humor so subversive and thought provoking. I previously cited my lifelong <a href="http://www.codinghorror.com/blog/archives/001034.html">fascination with the subversive humor of Mad Magazine</a>, and I'd hold Steve Martin's brand of strange, experimental comedy right up there next to it. I distinctly remember seeing <a href="http://www.imdb.com/title/tt0079367/">The Jerk</a> in 1979. I could only make sense of about half of it at the time, but the half I <i>did</i> understand blew my young mind. I've been slowly deciphering the genius of this Steve Martin movie ever since.
</p>
<p>
In <a href="http://www.smithsonianmag.com/arts-culture/funny-martin-200802.html?c=y&amp;page=1">a recent interview with Smithsonian Magazine</a>, Steve explains some of the philosophy behind his unique comedy. It's a fantastic article, but one particular passage stood out:
</p>
<p>
</p>
<blockquote>
At the end of my closing-night show at the Troubadour, I stood onstage and took out five bananas. I peeled them, put one on my head, one in each pocket and squeezed one in each hand. Then I read the last line of my latest bad review: "Sharing the bill with Poco this week is comedian Steve Martin ... his 25-minute routine failed to establish any comic identity that would make the audience remember him or the material." Then I walked off the stage.
<p>
<img alt="image placeholder" >
</p>
<p>
The consistent work enhanced my act. I learned a lesson: <b>it was easy to be great</b>. Every entertainer has a night when everything is clicking. These nights are accidental and statistical: like lucky cards in poker, you can count on them occurring over time. <b>What was hard was to be good, consistently good, night after night, no matter what the circumstances.</b>
</p>
</blockquote>
<p>
Steve's insistence that greatness isn't something you can count on, or even something you should strive for, resonates deeply for me. Greatness is far too difficult, too abstract, too daunting. Being good-- <i>consistently</i> good-- is the real goal, and that takes hard work and discipline. Being good-- that's something concrete you can roll up your sleeves and accomplish. Forget greatness. Can we even define what greatness truly is? Like Steve Martin, you <i>become</i> great through applying yourself at being reliably good, night after night, venue after venue, time after time.
</p>
<p>
Voltaire originally said <i>better is the enemy of good</i>; at the risk of creating another <a href="http://en.wikipedia.org/wiki/Snowclone">snowclone</a>, Steve's advice is essentially that <b>great is the enemy of good.</b> It's not exactly a message about software development, but it strongly reminds me of <a href="http://www.codinghorror.com/blog/archives/000047.html">worse is better</a>, at least from where I'm sitting. There's a fascinating history behind this classic essay that I glossed over in <a href="http://www.codinghorror.com/blog/archives/000047.html">my original post on the topic</a>. After doing a bit more research, I found that Richard Gabriel wrote a detailed article <a href="http://www.dreamsongs.com/WorseIsBetter.html">explaining the rich history of worse is better</a>:
</p>
<p>
</p>
<blockquote>
The concept known as "worse is better" holds that in software making (and perhaps in other arenas as well) it is better to start with a minimal creation and grow it as needed. Christopher Alexander might call this "piecemeal growth." This is the story of the evolution of that concept.
<p>
From 1984 until 1994 I had a Lisp company called "Lucid, Inc." In 1989 it was clear that the Lisp business was not going well, partly because the AI companies were floundering and partly because those AI companies were starting to blame Lisp and its implementations for the failures of AI. One day in Spring 1989, I was sitting out on the Lucid porch with some of the hackers, and <b>someone asked me why I thought people believed C and Unix were better than Lisp. I jokingly answered, "because, well, worse is better."</b> We laughed over it for a while as I tried to make up an argument for why something clearly lousy could be good.
</p>
</blockquote>
<p>
The idea being, of course, that enough goodness slowly accreted over time usually trumps any epic (and usually ill-fated) plans to create any brand new great thing. I completely agree, and I think history bears this lesson out a hundredfold. <b>But even the original author, Richard Gabriel, can't decide if worse really is better.</b> He's written a slew of pro and con articles over the years, vacillating back and forth, playing Devil's Advocate to his own position, representing both the "worse" and "better" sides in equal measure:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.dreamsongs.com/WIB.html">Lisp: Good News, Bad News, How to Win Big</a> (original "Worse is Better" talk, 1991)
</li>
<li>
<a href="http://www.dreamsongs.com/Files/worse-is-worse.pdf">Worse Is Better is Worse</a> (pdf, 1991)
</li>
<li>
<a href="http://www.dreamsongs.com/Files/IsWorseReallyBetter.pdf">Is Worse Really Better?</a> (pdf, 1992)
</li>
<li>
<a href="http://www.dreamsongs.com/Files/AcceptanceModels.pdf">Models of Software Acceptance: How Winners Win</a> (pdf presentation, 1995)
</li>
<li>
<a href="http://www.dreamsongs.com/Files/Innovation.pdf">Money Through Innovation Reconsidered</a> (pdf, 1995)
</li>
<li>
<a href="http://www.dreamsongs.com/Files/WorseIsBetterPositionPaper.pdf">Back to the Future: Is Worse (Still) Better?</a> (pdf, 2000)
</li>
<li>
<a href="http://www.dreamsongs.com/Files/ProWorseIsBetterPosition.pdf">Back to the Future: Worse (Still) is Better!</a> (pdf, 2000)
</li>
</ul>
<p>
Richard's final statement on the matter is a bit of a cop out: <i>decide for yourselves</i>. I'm not sure if worse is better or not. Personally, I'm inclined to follow Steve Martin's advice here: <b>strive to be consistently good, and the greatness takes care of itself</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-worse-really-better/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Every User Lies ]]></title>
<link>https://blog.codinghorror.com/every-user-lies/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Heidi Adkisson notes that <a href="http://www.iathink.com/2006/12/features_sell_p.html">features sell products</a>, but the people buying those products often <b>don't use the very features they bought the product for in the first place</b>.</p>
<blockquote>
A few years ago I did an extensive in-home study observing use of a  particular computer hardware peripheral. Most people had high-end models with many features. But in my observation of use, only one "power user" went beyond using anything but the core, basic features. These people had paid a premium for features they didn't use. However, when describing their purchase experience, it was clear <i>they aspired to using these features</i> and sincerely intended to. But, once the product was out of the box, the paradox of the active user took over. They never invested even the smallest amount of time to go beyond the basics (even though the extra features could have saved them time).
<p>
In my experience it's people's <i>aspiration for the experience</i> that drives purchasing decisions. <b>Ultimately, their aspirations may be different than the reality.</b>
</p>
</blockquote>
<p>It's interesting that Heidi used the hedge phrase "may be different" when <b>her own study data showed that users' aspirations and reality were almost <i>always</i> different.</b> Maybe she aspires to live in a world where aspirations and reality aren't so wildly divergent. I don't blame her. It'd be nice.</p>
<p>That disparity is why it's so important to <a href="http://www.codinghorror.com/blog/archives/000880.html">observe how users actually behave</a> versus the way they <i>tell</i> you they behave. People who do this professionally are called "economists". Observation is a powerful skill, and so is learning to disregard what people tell you in favor of judging them by their actions. No actions are more carefully considered than those that result in money flowing out of your pocket. That's why you owe it to yourself to read books like <a href="http://www.amazon.com/exec/obidos/ASIN/0061234001/codihorr-20">Freakonomics</a>, and maybe even <a href="http://en.wikipedia.org/wiki/The_Economist">The Economist</a> magazine. It's also why the <a href="http://freakonomics.blogs.nytimes.com/">Freakonomics blog</a> should be a part of your regular reading routine if it isn't already.</p>
<p>People lie not because they're all evil liars (although a few inevitably will be), but because they're usually lying to <i>themselves</i> in some way. Some lies are useful. Small social "white" lies grease the skids of social reality. Penetrating this veil of lies and intentions is one of the central themes of the excellent television show <a href="http://www.fox.com/house/">House, M.D.</a> :</p>
<p><a href="http://www.fox.com/house/"><img alt="image placeholder" >
<p>The show plays up <a href="http://www.housemd-guide.com/holmesian.php">subtle connections between</a> the House character and <a href="http://en.wikipedia.org/wiki/Sherlock_Holmes">Sherlock Holmes</a>, which is appropriate, because it's very much a detective show at heart. The character Gregory House, as played by the brilliant <a href="http://en.wikipedia.org/wiki/Hugh_Laurie">Hugh Laurie</a>, is fond of stating <b>"Everybody lies."</b> Parsing through all the irrational human behavior, and the inevitable lies – white or otherwise – makes for a gripping detective story indeed when lives are at stake.</p>
<p>Heidi referenced the <a href="http://faculty.ist.psu.edu/rosson/Papers/Paradox.pdf">Paradox of the Active User</a> (pdf), which has been around as a concept since 1987. I highly recommend reading the original paper, but if you don't have time, Jakob Nielsen <a href="http://www.useit.com/alertbox/activeuserparadox.html">summarizes</a>:</p>
<blockquote>
<b>Users never read manuals</b> but start using the software immediately. They are motivated to get started and to get their immediate task done: they don't care about the system as such and don't want to spend time up front on getting established, set up, or going through learning packages.
<p>
The "paradox of the active user" is a paradox because users would <i>save</i> time in the long term by learning more about the system. But that's not how people behave in the real world, so we cannot allow engineers to build products for an idealized rational user when real humans are irrational. <b>We must design for the way users actually behave.</b>
</p>
</blockquote>
<p>There are a bunch of ways to restate the paradox of the active user. Cooper calls it <a href="http://www.codinghorror.com/blog/archives/000098.html">perpetual intermediacy</a>. I think the easiest way to explain it is this: <b>every user lies.</b> Instead of asking users if they love your software – of <i>course</i> they love your software, it'd be rude to tell the people responsible just how mind-numbingly awful it really is – do what Gregory House does. <a href="http://www.codinghorror.com/blog/archives/000779.html">Observe whether or not they use the software, and how they use it</a>. Rely on that <i>behavioral</i> data to design your software, and not the lies of your users, however well intentioned they may be.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-01-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/every-user-lies/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Get Your Database Under Version Control ]]></title>
<link>https://blog.codinghorror.com/get-your-database-under-version-control/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A little over a year ago, I wrote about <a href="http://www.codinghorror.com/blog/archives/000743.html">the importance of version control for databases</a>.
</p>
<p>
</p>
<blockquote>
When I ask development teams whether their database is under version control, I usually get blank stares.
<p>
The database is a critical part of your application. If you deploy version 2.0 of your application against version 1.0 of your database, what do you get? A broken application, that's what. That's why <b>your database should always be under source control, right next to your application code</b>. You deploy the app, and you deploy the database. Like peanut butter and chocolate, they are two great tastes that taste great together.
</p>
<p>
<img alt="image placeholder" >
</p>
</blockquote>
<p>
When it comes to version control, the database is often a second or even third-class citizen. From what I've seen, teams that would <i>never</i> think of writing code without version control in a million years-- and rightly so-- can somehow be completely oblivious to the need for version control around the critical databases their applications rely on. I don't know how you can call yourself a software engineer and maintain a straight face when your database isn't under <i>exactly</i> the same rigorous level of source control as the rest of your code. Don't let this happen to you. <b>Get your database under version control</b>.
</p>
<p>
I was thinking about this again because my friend <a href="http://www.codinghorror.com/blog/archives/000971.html">and co-author</a> K. Scott Allen just wrote a brilliant five part series on the philosophy and practice of database version control:
</p>
<p>
</p>
<ol>
<li>
<a href="http://odetocode.com/Blogs/scott/archive/2008/01/30/11702.aspx">Three rules for database work</a>
</li>
<li>
<a href="http://odetocode.com/Blogs/scott/archive/2008/01/31/11710.aspx">The Baseline</a>
</li>
<li>
<a href="http://odetocode.com/Blogs/scott/archive/2008/02/02/11721.aspx">Change Scripts</a>
</li>
<li>
<a href="http://odetocode.com/Blogs/scott/archive/2008/02/02/11737.aspx">Views, Stored Procedures and the Like</a>
</li>
<li>
<a href="http://odetocode.com/Blogs/scott/archive/2008/02/03/11746.aspx">Branching and Merging</a>
</li>
</ol>
<p>
K is one of the smartest software developers I know. Read it all; even if you currently have your database under version control (and bully for you if you do), there is much food for peanut buttery chocolatey thought here. It <b>doesn't matter what tools you use</b>-- per the <a href="http://agilemanifesto.org/">agile manifesto</a>, <i>individuals and interactions are more important than processes and tools</i>. Just get your database under version control already.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/get-your-database-under-version-control/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Lesson in Apple Economics ]]></title>
<link>https://blog.codinghorror.com/a-lesson-in-apple-economics/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A new in box <a href="http://en.wikipedia.org/wiki/Apple_IIc">Apple //c</a> system was <a href="http://cgi.ebay.com/Vintage-APPLE-IIC-computer-NIB-Sealed-Never-Opened-II-C_W0QQitemZ360014619309QQihZ023QQcategoryZ80286QQssPageNameZWDVWQQrdZ1QQcmdZViewItem">recently sold on eBay</a>. This is quite remarkable; a vintage computer-- twenty-three years old-- that has <i>never been opened</i>. The people who ultimately won the auction posted <a href="http://flickr.com/photos/dansays/sets/72157603835099525/">a beautiful set of unboxing pictures</a>. For a brief moment, it was 1984 all over again.
</p>
<p>
</p>
<blockquote>
On Thursday night, Kathryn and I unboxed my latest eBay acquisition: an Apple //c. There are many vintage Apple II computers available for auction, but this one is special: It's never been opened. Ever. It hasn't seen the light of day since before it was shipped on May 5th, 1988.
<p>
<img alt="image placeholder" >
</p>
<p>
I wrestled with whether I should open the box, or store it and let it accrue collector's value. In the end, I decided that the reason for my purchase wasn't financial. My very first computer was an Apple //c, and I can't see wanting to part with this computer, ever.
</p>
</blockquote>
<p>
It also happens to be <b>the first model of Apple computer I ever owned</b>, so the nostalgia is pretty intense for me, too. The owner paid <b>$2,553</b> for the the privilege of owning and unboxing this Apple //c. Another vintage computer enthusiast <a href="http://www.bytecellar.com/archives/000136.php">expressed some dismay over the final price</a>:
</p>
<p>
</p>
<blockquote>
When I encountered the auction there were 31 minutes left and the bid was at $920. Too rich for my blood these days, sadly. But I was racked with pain in being unable to bid. I felt a little better when I saw the final auction ending price.... $2,553.00. To lend some perspective, back in 1984 the retail price of the Apple //c main unit was $1299. A rare find that went for a rather exorbitant amount.
</blockquote>
<p>
Exorbitant? Hardly. <b>The $1,299 that an Apple //c originally sold for in 1984 should cost about $2,670 in 2007 dollars, after factoring for inflation.</b> I'm not sure what AppleWorks and the monitor originally sold for, but it's amazing how precisely the final auction value tracked the adjusted for inflation value of this 23 year old computer.
</p>
<p>
It wasn't until the Macintosh line was introduced that Apple products got exorbitantly expensive. The original 1984 <a href="http://en.wikipedia.org/wiki/Macintosh_128k">128k Mac</a> model was $2,495, and the 1985 <a href="http://en.wikipedia.org/wiki/Macintosh_512K">512k Mac</a> was $2,795. <b>Expressed in 2007 dollars, that's $5,100 and $5,700 respectively.</b> Like all young geeks, I was instantly enamored with the advanced capabilities of the Mac line, but it was financially beyond the reach of my family. I'm not sure I knew <i>anyone</i> that owned one of the original Macs; that's how far outside the realm of possibility they were, at least in the social circles we moved in. Instead of upgrading from an Apple // to the prohibitively expensive Mac series, I convinced my family to buy me an <a href="http://en.wikipedia.org/wiki/Amiga_1000">Amiga 1000</a> for $1,295 in 1985. Even with the 256 KB memory upgrade and the color monitor, it ended up being about the same price as an Apple //.
</p>
<p>
So I guess this is my point: many pundits <b>forget how expensive Macs really were in the 80s and early 90s</b>. For a very long time, Macs were the exclusive province of the upper middle class. It wasn't until Jobs returned in 1997, and Macs began adopting more and more commodity PC technology over time-- culminating in <a href="http://www.codinghorror.com/blog/archives/000312.html">Apple's reluctant 2005 adoption of Intel CPUs</a>-- that pricing parity was eventually restored. Today's Macs are <a href="http://www.codinghorror.com/blog/archives/000591.html">quite competitively priced</a>, largely because they <i>are</i> (<a href="http://www.codinghorror.com/blog/archives/000769.html">well designed</a>) commodity PCs.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-lesson-in-apple-economics/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ DRM Ignorance is Expensive ]]></title>
<link>https://blog.codinghorror.com/drm-ignorance-is-expensive/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I recently became the reluctant owner of an <a href="http://en.wikipedia.org/wiki/Xbox_360">Xbox 360</a>. Limping along with my ancient Playstation 2-- I remember buying that thing on <a href="http://archive.gamespy.com/articles/october00/ps2launch/">launch day way back in 2000</a>-- was no longer viable in light of <a href="http://www.codinghorror.com/blog/archives/001000.html">my Rock Band addiction</a>. I've been avoiding a new console purchase for as long as humanly possible, but the version of Rock Band offered on the PS2 is almost <em>criminally</em> crippled: it offers no downloadable content, no band customization, and a barely-there practice mode.</p>
<p>Although it was expensive, I've been quite happy with my Xbox 360 upgrade overall. I bought <a href="http://www.amazon.com/exec/obidos/ASIN/B000W91YTA/codihorr-20">the Xbox 360 Pro value bundle</a>, so I own the more modern, much quieter "Falcon" revision of the console along with two games. The <a href="http://www.amazon.com/exec/obidos/ASIN/B000B6MLTG/codihorr-20">optional VGA adapter</a> works perfectly with my projector setup at 1024 x 768, and the Xbox Live internet experience is quite impressive and polished by now. I do wish WiFi was included in the box, rather than being yet another <a href="http://www.amazon.com/exec/obidos/ASIN/B000B6MLV4/codihorr-20">$90 accessory I have to buy</a>, but <strong>hawking overpriced accessories is just the way the console economy works</strong> -- you have to factor the required extra controllers, memory cards, charging stations, audio/video cables, and so on into the overall cost of ownership. That's the way it has always been for every console I've ever owned, going all the way back to the <a href="http://en.wikipedia.org/wiki/Atari_2600">Atari 2600</a>.</p>
<p><a href="http://www.amazon.com/exec/obidos/ASIN/B000W91YTA/codihorr-20"><img alt="image placeholder" >
<p>I've purchased lots of downloadable content on the Xbox 360 at work, primarily new songs for Guitar Hero 2, Guitar Hero 3, and Rock Band. I foolishly assumed all along that it would be <strong>no big deal to transfer that purchased content</strong> if I ever purchased an Xbox 360 for my home.</p>
<p>Big mistake.</p>
<p>I didn't realize <strong>how precarious my understanding was of Xbox 360 digital rights management was</strong>. If, like me, you believe that in the future..</p>
<ul>
<li>most consumer devices will not be complex general purpose computers, but simpler fixed function devices </li>
<li>all content will be downloaded </li>
<li>the hardware will be tightly controlled </li>
<li>the delivery network will be private and commercially locked down </li>
</ul>
<p>.. then <strong>for better or worse, products like the iPhone and Xbox 360 represent the future of computing</strong>. Apple has already taken us <a href="http://www.codinghorror.com/blog/archives/001044.html">quite far down this road</a>, with tremendous commercial success. Thus, it behooves us to understand precisely how the Xbox 360's mature, mainstream DRM model works. The Xbox 360 may or may not be around in five years, but it is quite likely that some form of its DRM will be.</p>
<p>Let me break it down for you, so you don't make the same naive mistake I did. All content you purchase and download on the Xbox 360 is keyed to two specific things:</p>
<ol>
<li>The <strong>hardware signature</strong> of the Xbox 360 you purchased the content on </li>
<li>The <strong>Xbox Live profile</strong> that you purchased the content with </li>
</ol>
<p>If you keep these two variables in mind, it's easier to understand why things work the way they do. Also, remember that any Xbox Live account is inherently "online". You're logging in to a secure internet validation server every time you buy anything through your Xbox Live account.</p>
<p>It's not <em>quite</em> as dire as it sounds, though. Pick your <a href="http://en.wikipedia.org/wiki/Dongle">dongle</a>:</p>
<ol>
<li>
<strong>Xbox 360 hardware dongle</strong>
<p>All purchased content is available for use by <em>any</em> account on that particular console you purchased it on. You can share ownership of that content with anyone else who has physical access to your Xbox 360, whether their account is local (offline) or Xbox Live (online). Note that if your console hardware signature ever changes-- say, if your console fails and you get a replacement-- you're in trouble.</p>
</li>
<li>
<strong>Xbox Live profile dongle</strong>
<p>As long as you're logged in to Xbox Live (and thus by definition using an Xbox 360 connected to the internet), you can re-download purchased content and play it on <em>any</em> Xbox 360. How do you transport your profile? Through the removable hard drive or a memory card. The hard drive works best, as you'll save yourself some download time.</p>
</li>
</ol>
<p>It is not possible to copy an Xbox Live profile; every login writes a unique key to the profile, and all subsequent logins validate the expected key. It is possible to <a href="http://support.microsoft.com/kb/907333">perform an "account recovery"</a> and move the account, but doing so automatically invalidates <em>any</em> other copies of the profile. The cardinal rule is this: <strong>there can only ever be one valid physical copy of an Xbox Live profile at any given time</strong>. Duplication is not allowed and rigorously enforced server-side.</p>
<p>The user penalty for hardware failure, however, is pretty severe; it sounds like iTunes has a <a href="http://perfectcr.com/archives/41-Dude,-Wheres-my-offline-Xbox-Live-Marketplace-Content.html">better hardware failure recovery model for its song DRM</a>:</p>
<blockquote>Microsoft has every right to protect their content, but to punish those who have had their consoles replaced due to failure is unacceptable. I see threads appear daily on all the popular forums about this issue. Typically it takes three to four weeks to get consoles replaced by Microsoft. Little do these users know their [newly repaired Xboxes will appear to be someone else's Xbox to the DRM].
<p>I don't intend to provide a solution to the problem here. I only want to bring attention to the issue. I am sure an iTunes like approach could be implemented where users can "authorize" and "deauthorize" the console tied to their content. I am just surprised that a software company like Microsoft cannot find a better solution than creating dummy accounts and asking users to call 1-800-4-MYXBOX time and time again in the hopes of getting their points refunded just so they can access their content offline.</p>
</blockquote>
<p>Getting back to my specific problem: how do I transfer the licenses for all those songs I bought to my home Xbox? I experimented with Microsoft's recommended solution of storing my Xbox Live profile on a memory card, but this meant I'd be schlepping a memory card dongle back and forth from home to work in perpetuity. That's not practical or tenable.</p>
<p>In the end, I broke down and <strong>re-purchased 11,240 MS Points worth of Guitar Hero 2, Guitar Hero 3, and Rock Band songs through my personal Xbox Live profile on my home Xbox 360</strong>. If you're <a href="http://www.mspconverter.com/">keeping score at home</a> that's $140.50 in real money. To buy the exact same content. Again.</p>
<p>I have nobody to blame but myself, I suppose. DRM sucks, but it's unavoidable and arguably the future, in the form of ubiquitious consumer devices like the Xbox 360 and iPhone. I'm not asking you to like it. Nobody likes it. But at the very least understand how it works, because as I recently found out, <strong>DRM ignorance is expensive</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/drm-ignorance-is-expensive/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Extending Your Wireless Network With Better Antennas ]]></title>
<link>https://blog.codinghorror.com/extending-your-wireless-network-with-better-antennas/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
When I set up my new Xbox 360, I also connected it to my existing wireless network. It's about 50 feet from my access point, with approximately 4 or 5 walls in between. I was able to get online, but <em>barely</em>. The signal strength indicator was at literally <strong>one bar of strength</strong>, and the signal graph was about close as you can get to no connection while still having a connection. That marginal WiFi connection was enough to get me to Xbox Live. But I also wanted to take advantage of the impressive Xbox 360 <a href="http://www.microsoft.com/windows/products/winfamily/mediacenter/features/extender.mspx">media extender</a> functionality – to connect to <a href="http://www.codinghorror.com/blog/archives/000784.html">my existing Vista Media Center home theater PC</a> to listen to music or watch videos. That <em>definitely</em> requires a better wireless connection.
</p>
<p>
I've already positioned everything as optimally as I can; the only thing I could think of to improve the signal even further was to <strong>upgrade to better, more powerful antennas</strong>. <span style="color: red;">Note that my Xbox is in an outside room that is not physically connected to the house, so a wired connection isn't practical.</span>
</p>
<p>
I did some web searching, and I found that <strong>wireless networking feels more like an art than a science</strong>. There are just so many variables:
</p>
<ul>
<li>the physical layout of your equipment
</li>
<li>the environment
</li>
<li>interference from other wireless networks
</li>
<li>the firmware and configuration of your networking hardware
</li>
</ul>
<p>
… and so on. It's almost impossible to tell if an antenna will work until you buy it and run network strength tests in <em>your</em> particular environment.
</p>
<p>
There are a few recurring themes, though. One is <a href="http://www.amazon.com/exec/obidos/ASIN/B00025EKYA/codihorr-20">the "cantenna"</a>; there are many variations of this design on the market.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/B00025EKYA/codihorr-20"><img alt="image placeholder" >
</p>
<p>
As you can see from the picture, the "can" in the name refers to the fact that these antennas can be built with the exact same kinds of cans you'd find at your local grocery store. This one looks like a Pringles potato chip can, and it's a very popular style. Lots of smaller vendors <a href="http://www.etherdesigns.com/cantennaskits.html">sell variations of this design</a>. Reviews of the archetypal cantenna design show <a href="http://www.overclockersclub.com/reviews/wifi_cantenna_review/4.htm">good</a> <a href="http://www.notebookreview.com/default.asp?newsID=2859">results</a>, but it is highly directional – you have to point it at the target, and it's only truly effective in that direction.
</p>
<p>
Part of the appeal of the cantenna is that you can build them quite easily yourself. This <a href="http://www.turnpoint.net/wireless/has.html">comprehensive homebrew antenna comparison</a> showed that self-built cantennas can perform extremely well, if you follow waveguide theory when you build them:
</p>
<blockquote>
The results surprised me! In our test, the Flickenger Pringles can did a little better than my modified Pringles design. Both did no better than the Lucent omnidirectional. Now this is just on raw signal strength, noise rejection due to directivity still makes a directional antenna a better choice for some uses even if there is no gain benefit. <strong>The waveguides all soundly trounced the Pringles can designs. I mean they stomped them into the ground on signal strength - as much as 9 dB better. Every three dB is a doubling in power - that's three doublings (8x increase)!</strong>
<p>
With these results, I'm convinced that the waveguide design is the way to go for cheap wireless networking. The performance is good, the cost is very low and the skill required is minimal. If you can eat a big can of stew, you can make a high performance antenna.
</p>
</blockquote>
<p>
If you're interested in constructing a waveguide cantenna, I found this <a href="http://web.archive.org/web/20110625122209/http://flakey.info/antenna/waveguide/">excellent detailed guide</a>, with lots of step by step photos, a JavaScript size calculator, and recommended off the shelf cans you can buy to start with.
</p>
<p>
There are, of course, any number of commercial aftermarket WiFi antennas to choose from, too. If you're interested in upgrading, first <strong>make sure your router has a removable antenna</strong>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Next, determine what kind of connector the antenna uses on your router. There's an <a href="http://wireless.gumph.org/content/3/7/011-cable-connectors.html">excellent wireless antenna connector visual guide</a> here; the RP-SMA and RP-TNC connectors are common, but it does vary. You'll want to make sure you have the right connector "pigtail" cable for whatever antenna you buy, unless it happens to use the same native connector type. My router uses a RP-SMA connector.
</p>
<p>
After you've gathered this essential information, your goal is to <strong>replace your generic, stock – dare I say <em>wimpy</em> – router antenna</strong> with something better.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
There are lots of aftermarket upgrade antennas to choose from, but I am a sucker for Hawking models. I've <a href="http://www.codinghorror.com/blog/archives/000155.html">used their portable Hi-Gain Wireless USB adapter</a> for years; its compact folding directional antenna is a marvel at picking out signal from the noise. They have a lot of antenna designs to choose from; let's compare:
</p>
<table cellspacing="4" cellpadding="4" width="600">
<tbody>
<tr>
<td align="center">
<a href="http://www.amazon.com/exec/obidos/ASIN/B0000ABPKG/codihorr-20"><img alt="image placeholder" >
<br><a href="http://www.amazon.com/exec/obidos/ASIN/B0000ABPKG/codihorr-20">HAI6SIP</a>
</td>
<td>6 dBi</td>
<td>3" x 3" x 11.6"</td>
<td>$32</td>
</tr>
<tr>
<td align="center">
<a href="http://www.amazon.com/exec/obidos/ASIN/B000AD4JEA/codihorr-20"><img alt="image placeholder" >
<a href="http://www.amazon.com/exec/obidos/ASIN/B000AD4JEA/codihorr-20">HAI7SIP</a>
</td>
<td>7 dBi</td>
<td>3.4" x 3.4" x 8.9"</td>
<td>$40</td>
</tr>
<tr>
<td align="center">
<a href="http://www.amazon.com/exec/obidos/ASIN/B000BDHCMU/codihorr-20"><img alt="image placeholder" >
<br><a href="http://www.amazon.com/exec/obidos/ASIN/B000BDHCMU/codihorr-20">HAI7MD</a>
</td>
<td>7 dBi</td>
<td>2.8" x 2.8" x 6.1"</td>
<td>$38</td>
</tr>
<tr>
<td align="center">
<a href="http://www.amazon.com/exec/obidos/ASIN/B000FG0O0A/codihorr-20"><img alt="image placeholder" >
<a href="http://www.amazon.com/exec/obidos/ASIN/B000FG0O0A/codihorr-20">HAI8DD</a>
</td>
<td>8 dBi</td>
<td>5" x 5" x 5"</td>
<td>$50</td>
</tr>
<tr>
<td align="center">
<a href="http://www.amazon.com/exec/obidos/ASIN/B0000DIET2/codihorr-20"><img alt="image placeholder" >
<a href="http://www.amazon.com/exec/obidos/ASIN/B0000DIET2/codihorr-20">HAI15SC</a>
</td>
<td>15 dBi</td>
<td>2" x 3.9" x 8.6"</td>
<td>$45</td>
</tr>
<tr>
<td align="center">
<a href="http://www.amazon.com/exec/obidos/ASIN/B000B59J8I/codihorr-20"><img alt="image placeholder" >
<a href="http://www.amazon.com/exec/obidos/ASIN/B000B59J8I/codihorr-20">HAO14SDP</a>
</td>
<td>14 dBi</td>
<td>1" x 3" x 9"</td>
<td>$83</td>
</tr>
</tbody>
</table>
<p>
This is only a brief summary of the most likely indoor antenna models; Hawking has <a href="http://hawkingtech.com/products/178.html">a bunch more antennas to choose</a> from on their web site. Be careful, because customer reviews are all over the map on these things, which says more about the immense number of variables in wireless networking than it does about the antennas themselves. <strong>I chose to go with <a href="http://www.amazon.com/exec/obidos/ASIN/B000BDHCMU/codihorr-20">the HAI7MD model</a></strong>, which I thought had a nice blend of some directionality, compact size, and performance/price. I also like that it can be detached from its little stand and connected directly to the router in lieu of the stock antenna, if you don't need the positioning flexibility the stand provides.
</p>
<p>
Here are my results from the media extender network test. The test is a bit variable because I'm experimenting with the antenna positioning to see what produces the strongest connection.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Before I added this antenna, that white line would have been just above the bottom-most black line on the graph. That's how bad it was. <strong>Upgrading my antenna increased my wireless networking connection strength by about 5x.</strong> Here's the final result as shown in the Media Center extender network performance monitor test screen:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As fantastic as this improvement is, now I'm tempted to go back and buy <a href="http://www.amazon.com/exec/obidos/ASIN/B0000DIET2/codihorr-20">that <em>really</em> huge HAI15SC corner antenna</a> to see how much better it can get. At any rate, if you're looking to improve your wireless network performance, definitely consider aftermarket antenna upgrades. In my experience, <strong>a better antenna can make the difference between a completely marginal connection and a rock solid connection</strong>.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/extending-your-wireless-network-with-better-antennas/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Years of Experience Myth ]]></title>
<link>https://blog.codinghorror.com/the-years-of-experience-myth/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I recently received an email from Andrew Stuart of the Australian firm <a href="http://flatraterecruitment.com.au/">Flat Rate Recruitment</a>. Andrew related their technical phone screen process, which is apparently quite similar to the one outlined in <a href="http://www.codinghorror.com/blog/archives/001042.html">Getting the Interview Phone Screen Right</a>. I'm glad to hear it works. A proper phone screen is critical. I completely agree with Andrew: <b>you should be 95% certain that a candidate would be a great hire before they ever set foot in an interview room.</b> Anything less is a colossal waste of everyone's time.
</p>
<p>
But there's one aspect of the recruiting process that often goes awry, even with a great phone screen in place. Andrew presented an excellent anecdote in his email that explains it better than I can:
</p>
<p>
</p>
<blockquote>
I had a client building an advanced security application. I sent them person after person and they kept knocking them back. The reason was almost always because the person "didn't have enough low level coding experience." The people I sent had done things like design and develop operating systems, advanced memory managers and other highly sophisticated applications. But my client wasn't interested. They <i>required</i> previous hands on low level coding experience in a particular discipline. Eventually I got an application from a very bright software engineer who almost single-handedly wrote a classic computer emulator, but had little or no low level coding experience in the particular discipline they required.
<p>
I told the client, "I have a great guy here who has no experience doing low level coding and I think you should hire him."  They were extremely skeptical. I pushed hard to get an interview. "Look, this guy is a superb software engineer who doesn't have low level coding experience in the particular discipline you require now, but if you employ him, within 3-6 months you <i>will</i> have a superb software engineer who <i>does</i> have the low level coding experience you're looking for."
</p>
<p>
They interviewed him and gave him the job. Within a matter of weeks it was clear he was the smartest programmer in the company. He quickly mastered their low level coding and his learning went well beyond that of the other coders in the company. Every time I talk to that client he raves on about this employee, who is now the technical backbone of the company. That company no longer focuses its recruitment on candidates that <i>exactly</i> match previous experience with the required technologies. Instead they focus on finding and employing the smartest and most passionate engineers.
</p>
</blockquote>
<p>
This toxic, counterproductive <b>years of experience myth</b> has permeated the software industry for as long as I can remember. Imagine how many brilliant software engineers companies are missing out on because they are completely obsessed with finding people who match-- exactly and to the letter-- some highly specific laundry list of skills.
</p>
<p>
Somehow, they've forgetten that <b>what software developers do best is <i>learn</i>.</b> Employers should be looking for passionate, driven, flexible self-educators who have a proven ability to code in <i>whatever</i> language -- and serving them up interesting projects they can engage with.
</p>
<p>
It's been shown <a href="http://www.codinghorror.com/blog/archives/000072.html">time</a> and <a href="http://www.codinghorror.com/blog/archives/000354.html">time again</a> that <b>there is no correlation between years of experience and skill in programming.</b> After about six to twelve months working in any particular technology stack, <a href="http://www.codinghorror.com/blog/archives/000543.html">you either get it or you don't</a>. No matter how many years of "experience" another programmer has under their belt, there's about even odds that <i>they have no idea what they're doing</i>. This is why working programmers quickly learn to view their peers with <a href="http://www.codinghorror.com/blog/archives/000824.html">a degree of world-weary skepticism</a>. Perhaps it's the only rational response when the disconnect between experience and skill is so pervasive in the field of software engineering.
</p>
<p>
With that in mind, do you <i>really</i> want to work for a company that still doggedly pursues the years of experience myth in their hiring practices? <a href="http://www.37signals.com/svn/posts/833-years-of-irrelevance">Unlikely.</a>
</p>
<p>
</p>
<blockquote>
Which leads me to my point: Requiring X years of experience on platform Y in your job posting is, well, ignorant. As long as applicants have 6 months to a year of experience, consider it a moot point for comparison. Focus on other things instead that'll make much more of a difference. Platform experience is merely a baseline, not a differentiator of real importance.
<p>
In turn that means you as an applicant can use requirements like "3-5 years doing this technology" as a gauge of how clued-in the company hiring is. The higher their requirements for years of service in a given technology, the more likely that they're looking for all the wrong things in their applicants, and thus likely that the rest of the team will be stooges picked for the wrong reasons.
</p>
</blockquote>
<p>
I'm not saying experience doesn't matter in software development. It does. But consider the <i>entire</i> range of a developer's experience, and realize that <a href="http://www.codinghorror.com/blog/archives/000524.html">time invested does not automatically equal skill</a>. Otherwise, you may be rejecting superb software engineers simply because they lack "(n) years of experience" in your narrow little technological niche-- and that's a damn shame.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-years-of-experience-myth/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Where the Heck is My Focus? ]]></title>
<link>https://blog.codinghorror.com/where-the-heck-is-my-focus/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The web is quite mouse-centric. Ever tried navigating a typical website without your mouse? I'm not saying it can't be done-- if you're sufficiently motivated, <a href="http://weblogs.asp.net/jgalloway/archive/2006/06/14/Mouseless-Computing.aspx">you can indeed navigate the web using nothing but your keyboard</a>-- but it's painful.
</p>
<p>
There's nothing wrong with the point-and-click navigation model of the mouse, although it can degenerate into <a href="http://www.webpagesthatsuck.com/mysterymeatnavigation.html">mystery meat navigation</a> if you're not careful. I don't expect web designers to create keyboard-centric websites; the mouse is a natural and intuitive enough way to navigate web sites. But so is the keyboard, in certain circumstances. What frustrates me is when <b>web developers fail to pay attention to the most rudimentary of keyboard support in their designs</b>.
</p>
<p>
Let's pick on eBay. Here's the eBay signin form.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This form is a perfect example of keyboard navigation trumping mouse navigation. Done right, it <a href="http://www.codinghorror.com/blog/archives/000866.html">reduces user interface friction to a minimum</a>:
</p>
<ol>
<li>Type your user name
</li>
<li>Press Tab to advance to the next field
</li>
<li>Type your password
</li>
<li>Press Enter
</li>
</ol>
<p>
Of course, that assumes the user <i>knows</i> how to use the keyboard. In my experience, this is not a safe assumption. I've seen many users <a href="http://www.codinghorror.com/blog/archives/000754.html">log in using the excruciatingly slow mouse way</a>, and it's not pretty. At the risk of creating a legion of back seat drivers, I suggest that when you see coworkers users using the mouse to log in, you should gently-- <i>gently</i>-- let them know that they might be able to save some time by sticking with the keyboard for these little online forms. I'm not saying you should <a href="http://www.codinghorror.com/blog/archives/000825.html">go commando</a>, but a tiny bit of keyboard expertise will serve you in good stead.
</p>
<p>
This is an <i>incredibly</i> simple little login form. And yet there are <b>at least three ways web developers can screw this form up for keyboard use</b>. That's why I added the caveat <i>done right</i>, above. It almost never is, and keyboard users always seem to get the shaft. To make this HTML form work properly with keyboard input, the eBay developers have to:
</p>
<p>
</p>
<ol>
<li>
<a href="http://miksovsky.blogs.com/flowstate/2007/10/show-mercy-to-k.html">Set the focus to the first field</a> so I can start typing in my user ID.
</li>
<li>Structure the HTML form fields so that when I press the Tab key, it advances through them in a logical order.
</li>
<li>Ensure that the HTML form submits when I press the Enter key.
</li>
</ol>
<p>
You might expect the tab order on the eBay login form to proceed in the same order you read the form (<a href="http://www.codinghorror.com/blog/archives/000813.html">in Western cultures, anyway</a>):
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If so, you would be wrong. I guess <a href="http://en.wikipedia.org/wiki/Two_Out_of_Three_Ain't_Bad">two out of three ain't bad</a>. The tab order, for some unknown reason, goes directly from Password to the Sign In button, completely skipping over the "remember me" checkbox directly under it. This is a mild omission, to be sure. I've seen far worse, web forms with tab orders that resembled a <a href="http://en.wikipedia.org/wiki/Rubik's_Cube">Rubik's cube</a>. But tab order on a login form is so <i>fundamental</i> -- when web developers screw up basic tab ordering on a form with four fields, that's veering dangerously close to "I don't give a damn about my craft" territory.
</p>
<p>
All the developers <i>you</i> know remember to test their web forms using the keyboard. Right?
</p>
<p>
But even if developers do remember to test for basic keyboard behavior, there's a deeper problem here. <b>Keyboard navigation relies heavily on the focus.</b> In order to move from one area to the next, you have to be able to reliably know where you are. Unfortunately, <b>web browsers make it needlessly difficult to tell where the focus is</b>. Can you tell which field has the focus in Internet Explorer 7?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I think it's fair to call that <i>incredibly subtle</i>. Let's see how Firefox 2 does.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Wow. Good luck with that. Now how about the same form in Safari 3?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
No wonder users rely on the mouse so much. Most browsers do an embarassingly bad job of making the focus obvious, so users feel compelled to click on fields to orient themselves.
</p>
<p>
The focus behavior is just as bad when the focus moves to the sign in button. It's technically an image masquerading as a button, but this is still a fairly common technique; it should be handled well. Is it?
</p>
<p>
</p>
<table>
<tr>
<td><img alt="image placeholder" >
<td><img alt="image placeholder" >
<td>
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td>Internet Explorer 7</td>
<td>Firefox 2</td>
<td>Safari 3</td>
</tr>
</table>
<p>
Of the three, <b>only Safari really gets focus right</b> in my estimation. Here's hoping the next versions of Firefox and Internet Explorer copy this more obvious focus indicator. If users can orient themselves using a clear, unambiguous focus, they're a lot more likely to warm up to a little <a href="http://miksovsky.blogs.com/flowstate/2007/11/directional-key.html">time-saving keyboard navigation</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/where-the-heck-is-my-focus/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Dramatic Password Reveal ]]></title>
<link>https://blog.codinghorror.com/the-dramatic-password-reveal/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As far back as I can remember-- which admittedly isn't very far-- GUI toolkits have included a special type of text entry field for passwords. As you type, the password field displays a generic character, usually a dot or asterisk, instead of the character you actually typed.
</p>
<p>
I've <a href="http://www.codinghorror.com/blog/archives/000413.html">criticized the login dialog before</a>, but <b>I definitely understand the need to obfuscate password entry</b>, even if you're using <a href="http://www.codinghorror.com/blog/archives/000785.html">fancy two-factor authentication with smart cards and the like</a>. If password entry was treated as plain old text entry, you'd reveal your password (or PIN code) to anyone who casually happened to be looking at the screen while you're typing. So instead of seeing:
</p>
<p>
<code>**************</code>
</p>
<p>
Everyone in your meeting or presentation would instead see:
</p>
<p>
<code>IHeartBunnies!</code>
</p>
<p>
Which would be sort of traumatic on several levels. Not to mention the security implications.
</p>
<p>
I can't talk about login dialogs without bringing up one in Lotus Notes 6.0. Like everything else in Notes, <a href="http://lotusnotessucks.4t.com/lnEx01.html">it's a massive trainwreck</a>.
</p>
<p>
</p>
<blockquote>
This dialog box contains several security "features":
<p>
<img alt="image placeholder" >
</p>
<p>
</p>
<ul>
<li>The hieroglyphics on the left of the dialog box are supposed to distract anyone who is peering over your shoulder trying to learn your password as you type.
</li>
<li>The number of characters you type is hidden; a random number of X's appear instead of one asterisk per character.
</li>
</ul>
<p>
Is any of this nonsense really necessary? If I want to learn someone's password as he or she types it, I will look at the keyboard, not the screen!
</p>
</blockquote>
<p>
I actually had to use <i>that exact login dialog</i> for my job at the time, and I can tell you from personal experience exactly how mind-bendingly, appallingly awful it truly was. Who reinvents a perfectly standard dialog-- and makes it so much worse? On second thought, perhaps "how can we make this worse?" was the design goal for Notes. It certainly felt that way while I was using it.
</p>
<p>
But I digress. As much as we worry about password obfuscation, at least one dialog in Vista bucks this long-standing GUI trend. Specifically, the dialog where you enter your wireless network password.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Checking the "display characters" checkbox overrides the password obfuscation and reveals the password. At first I was appalled. Reveal my <i>password?</i> Imagine the security implications! The chutzpah of Microsoft's developers, putting my password at risk in such a careless, haphazard manner! What were they thinking?
</p>
<p>
I'm guessing they implemented the reveal option here because network passwords can be unusually long and complex-- and troubleshooting network connectivity is difficult enough even without factoring in the inevitable password typos. But are network passwords really so different from any other type of password? After using this dialog a few times, I began to see how useful the reveal password option truly was. If you think you've made a mistake entering your password, tick the reveal box and find out. It's quite a time saver compared to typing in your password in blindly two, three, or even four times before getting it right. I don't know about you, but that happens to me at least a few times a day on average.
</p>
<p>
I've come full circle. I now think <b>the password reveal option should be available on all login dialogs</b>.
</p>
<p>
It's awfully convienient, and it doesn't seem particularly risky to me. Nobody leaves their password typed in and waiting to be revealed on the login screen. If you're in a public place, you simply refrain from using the reveal option. But at home or in a private work area, why not opt to reveal your password? Traditional GUI password obfuscation is a nice convention, but it's not the alpha and omega of password security. Far from it. If criminals <i>really</i> want to get your password, they'll be watching your fingers on the keyboard or using keylogger hardware.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-dramatic-password-reveal/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Spatial Navigation and Opera ]]></title>
<link>https://blog.codinghorror.com/spatial-navigation-and-opera/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/001055.html">Where the Heck is My Focus</a>, I wondered why web developers don't pay attention to basic keyboard accessibility issues. I don't want to navigate the entire web with my keyboard. That's unrealistic. I was specifically referring to <b>login pages</b>, which tend to be quite spartan and minimal. On a simple login web page, the standard keyboard tab, enter, focus order navigation scheme is quite useful and <a href="http://www.codinghorror.com/blog/archives/000754.html">much more efficient than using the mouse</a>.
</p>
<p>
But why is keyboard navigation so unrealistic for the rest of the web? Probably because <b>the existing keyboard navigation paradigm was developed for the earliest GUIs</b>, where forms had at most <i>dozens</i> of selectable items.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Compare with the modern web, where <b>pages regularly have <i>hundreds</i> of selectable items.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Presented with a 20-fold increase in selectable items, it's not too difficult to see why <b>traditional keyboard navigation techniques completely break down</b>. They were never designed to handle such complex navigation scenarios. Jan Miksovsky <a href="http://miksovsky.blogs.com/flowstate/2007/11/directional-key.html">explains</a>:
</p>
<p>
</p>
<blockquote>
The first issue is one of scale: the page above has twenty times the number of focusable controls as the simple dialog. A user trying to use the keyboard to reach a link in the middle of the page might have to press the Tab key 125 times to reach it. (Or, if they were exceptionally efficient, they could tab around the other direction and only have to press Shift+Tab 75 times.) The second issue is that the page has a much more complex two-dimensional columnar layout that the dialog, but that layout cannot be captured in the one-dimensional tab order. To the user, the behavior of the Tab key is therefore quite unpredictable.
<p>
The other standard keyboard navigation technique-- explicit keyboard shortcuts-- are also inadequate for complex user interfaces. Microsoft Windows allows users to move the focus directly to a control on the dialog by pressing a keyboard shortcut, generally the Alt key plus a single letter in the control's label. (OS/X does this too, although I find it less discoverable and generally weaker in execution.) This system is workable for dialogs with a small number of controls and a reasonable distribution of letter frequencies in control labels, but is obviously unable to scale well beyond a handful of controls.
</p>
</blockquote>
<p>
<a href="http://www.codinghorror.com/blog/archives/000432.html">Incremental search</a> is one way to find what you're looking for on a complex web page. <a href="http://sarathc.wordpress.com/2007/06/16/incremental-search-of-safari-really-makes-sense/">Safari does incremental searching extraordinarily well</a>, Firefox reasonably well, and IE not at all unless you install a <a href="http://www.ie7pro.com/">third-party plugin</a>. As useful as incremental search is, it can be a jarring navigational technique.
</p>
<p>
Jan describes an alternate navigational technique that <i>can</i> scale to hundreds of selectable items. It's not even new. You've probably used it before, but not on your desktop or laptop PC. That technique is <a href="http://miksovsky.blogs.com/flowstate/2007/11/directional-key.html">spatial navigation</a>.
</p>
<p>
</p>
<blockquote>
A much better user interface for navigating screens with lots of elements is already ubiquitous-- but not on PCs. It's found on mobile phone web browsers, which of necessity do a good job at keyboard navigation. <b>They support two-dimensional directional navigation by using Left, Right, Up and Down arrow keys (or a joystick) to move to the "nearest" element in the corresponding direction.</b> For example, if you press the Right key, heuristics determine whether there's an element you might be trying to reach towards the right, and if there are multiple elements, which element you probably want.
<p>
Significantly, <b>these heuristics respect the rendered visual representation of the page</b>, not the structure of the document's object model or the original location of elements at design time. This is necessary to account for the fact that the user may be viewing the page at a different width than the designer used, with different fonts, at different sizes, etc. Directional navigation UIs also tightly connect keyboard focus and scroll position, allowing someone to continually press the Up and Down keys to move through focusable controls and to page over large blocks of text.
</p>
</blockquote>
<p>
Jan said <i>"directional navigation works so well on mobile devices, I'm hoping it will get built into a browser someday."</i> What he apparently didn't realize is that at least one browser <a href="http://www.opera.com/support/tutorials/nomouse/">already implements spatial navigation</a>. That browser is <a href="http://www.opera.com/">Opera</a>. In Opera, you can press shift+arrow to move the focus to the next logical selection in that direction.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Opera's spatial navigation is fun to play with. Combined with the space bar and arrow keys to scroll the page, it's a surprisingly effective navigation technique even outside the constraints of mobile browsers where you usually see it. But there are some quirks. It isn't always obvious what selectable item is next in any particular direction. Also, heavy use of JavaScript page manipulation appears to interfere with spatial navigation in some cases.
</p>
<p>
Try it yourself. Despite the quirks, <b>spatial navigation is worlds better than the insanity of pressing tab 125 times</b>.
</p>
<p>
It's too bad Opera doesn't get more respect. I'm as guilty as anyone; when I'm testing something, I'll use IE, Firefox, and Safari in that order. Opera isn't even on my radar. That's a shame, because as you can see, it's quite innovative in some areas. It's also <a href="http://www.codinghorror.com/blog/archives/000211.html">historically one of the fastest browsers</a> on the market. Opera is the default browser on the Nintendo DS and Wii, and I've heard nothing but raves for <a href="http://en.wikipedia.org/wiki/Opera_Mini">Opera Mini</a> and <a href="http://en.wikipedia.org/wiki/Opera_Mobile">Opera Mobile</a> on mobile phones. Yet Opera's PC market share remains <a href="http://www.w3schools.com/browsers/browsers_stats.asp">vanishingly small</a>, on the order of 1 percent-- a very distant fourth behind the big three. I suppose part of that is Opera's fault; Opera was sold as a product long after browsers were given away for free. That certainly didn't help their market share.
</p>
<p>
Regardless, it's worth checking out Opera for spatial navigation and <a href="http://cybernetnews.com/2007/09/03/cybernotes-exclusive-opera-95-features-video/">other innovations it brings to the table</a>. Now that <a href="http://www.codinghorror.com/blog/archives/001006.html">the browser wars have heated up again</a>, I hope there will be more cross-pollination of innovative features so <i>everyone</i> can benefit.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/spatial-navigation-and-opera/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Ultimate Unit Test Failure ]]></title>
<link>https://blog.codinghorror.com/the-ultimate-unit-test-failure/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We programmers are <a href="http://www.codinghorror.com/blog/archives/000490.html">obsessive by nature</a>. But I often get frustrated with the depth of our obsession over things like code coverage. Unit testing and code coverage are <a href="http://www.codinghorror.com/blog/archives/000640.html">good</a> <a href="http://www.codinghorror.com/blog/archives/000265.html">things</a>. But perfectly executed code coverage doesn't mean users will use your program. Or that it's even <i>worth</i> using in the first place. <b>When users can't figure out how to use your app, when users <a href="http://www.codinghorror.com/blog/archives/000882.html">pass over your app</a> in favor of something easier or simpler to use, <i>that's</i> the ultimate unit test failure.</b> <i>That's</i> the problem you should be trying to solve.
</p>
<p>
I want to run up to my fellow programmers and physically shake them: think bigger!
</p>
<p>
A perfect example of <i>thinking bigger</i> is Alan Cooper's <a href="http://interaction08.ixda.org/">Interaction 08</a> keynote, <b>An Insurgency of Quality</b>.
</p>
<p>
<a href="http://www.brightcove.tv/title.jsp?title=1416866797&amp;channel=1274129191"><img alt="image placeholder" >
</p>
<p>
There's <a href="http://ajaxian.com/archives/interaction08-ixds-in-savannah-alan-cooper">a transcript of his keynote available</a>, or you can <a href="http://www.brightcove.tv/title.jsp?title=1416866797&amp;channel=1274129191">view a video of his keynote video</a> with the slides in place.
</p>
<p>
Alan is a well known <a href="http://www.cooper.com/">interaction designer </a>, and the author of several classic books in the field, such as <a href="http://www.codinghorror.com/blog/archives/000897.html">About Face</a>, and a few others that are on my <a href="http://www.codinghorror.com/blog/archives/000020.html">recommended reading list</a>. In the Q&amp;A after the talk, he had this to say:
</p>
<p>
</p>
<blockquote>
"We are not very important because we don't cut code." (A boo and hiss from the audience.) In the world of high-technology, if you cut code, you control things. It's the power to destroy the spice, it's the power to control the spice. It's not a fine kind of control: it's bruce-force kind of things. [Interaction designers are] largely marginalized. We're constantly asking for permission from the folks who shouldn't be in a position to grant permission. We should be working with business folks and marshalling the technology to meet the solutions to business problems.
<p>
But when it comes time to marshal the solution to the problems, we find ourselves slamming into this kind of Stay-Puft Marshmallow Man of software development.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>We don't need to change interaction design; we need to re-orient organizations to build things right.</b> When we come to programmers and say, "Look at the people I've talked to; look at the personas I've created" and present them with research, programmers understand that, and that's how we will influence.
</p>
</blockquote>
<p>
It pains me to hear that <b>Cooper considers most programmers twenty-story marshmallow barriers to good interaction design</b>. Please don't be one of those programmers. Learn about the science of interaction design. Pick up a copy of <a href="http://www.codinghorror.com/blog/archives/000377.html">Don't Make Me Think</a> as an introduction if you haven't already. There's a reason this book is at the top of my recommended reading list. Keep your unit testing and code coverage in perspective -- the <i>ultimate</i> unit test is whether or not users want to use your application. All the other tests you write are totally irrelevant until you can get that one to pass.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-ultimate-unit-test-failure/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Tivoization and the GPL ]]></title>
<link>https://blog.codinghorror.com/tivoization-and-the-gpl/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The original <a href="http://en.wikipedia.org/wiki/TiVo">Tivo</a> was one of the finest out of box experiences I've <i>ever</i> had as a consumer. I remember how exciting it was to tell friends about our newfound ability to pause live television, and how liberating it felt to be freed from the tyranny of television schedules. Imagine watching whatever you want, whenever you want! Of course, digital video recorders are no longer the rare, expensive creatures they were back in 2002, so some of that original Tivo luster is irretrievably lost.
</p>
<p>
But Tivo was more than a garden variety DVR. Its true beauty was the synthesis of an intuitive user interface, cool hardware, and <a href="http://www.codinghorror.com/blog/archives/000008.html">an elegant remote</a>. It fired on all cylinders. I loved my series one unit with a passion most people reserve for their newborn children. I upgraded it with an ethernet connector, and plopped in a larger hard drive so I could store a week's worth of television. Never mind that I'd have to <i>quit my job</i> to actually have time enough to watch all those shows. Somehow, the mere <i>knowledge</i> that I had a zillion episodes of Seinfeld or the Simpsons available for immediate viewing gave me a warm, fuzzy feeling in the nether regions of my geek brain. It was a kind of beautiful, pure technological freedom.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Under the hood, Tivo was based on Linux. With a series 1 box, you could access <a href="http://www.hackaday.com/2005/01/04/network-and-shell-hacks-for-tivo-series-1/">all the standard *nix tools</a>, and install some cool hacks including a <a href="http://tivowebplus.sourceforge.net/">web UI</a>. But all that ended when I upgraded from my Series 1 Tivo box to a Series 2. This <a href="http://archive.tivocommunity.com/tivo-vb/showthread.php?s=81a24e16965de130d451167d32c6035e&amp;threadid=97352&amp;perpage=20&amp;pagenumber=1">epic 2003 Tivo community forum thread</a> explains why:
</p>
<p>
</p>
<p>
</p>
<blockquote>
<i>Can the stand alone Series2 running 3.2 software be hacked to get a BASH prompt over the USB/Ethernet bridge?</i>
<p>
No. The config files are protected by hashes, and the list and hash check program are in the kernel initrd, which is signed and checked by the boot ROM. Any changes and it will either replace the file or not boot at all.
</p>
<p>
<i>Can the method used by people using DirectTivos running 3.1 be used on a stand alone 3.2?</i>
</p>
<p>
No. Unlocked software exists for the DTivos (before Tivo updated it), but all the Series2 stand alones always had the protected OS and ROMs.
</p>
<p>
<i>If it is not possible, is there any hope that it will be possible in the future?</i>
</p>
<p>
Who knows? There was an initial hack (set a BASH_ENV variable that makes bash run a script), but Tivo now checks for that. Changing the boot ROM is difficult, as it's soldered to the system board. If it's flashable (I haven't seen a definate yes or no), you still have to get into the system to run a flash program.
</p>
</blockquote>
<p>
In other words, <b>Tivo added hardware protection in the Series 2 to prevent anyone from modifying the Tivo software</b>. Tivo became another Xbox or Playstation console-- a locked-down, hardware protected platform. You'd somehow have to defeat the hardware protection (eg, install a modchip or flash ROMs) before you can modify anything. It looks like <a href="http://www.tivocommunity.com/tivo-vb/showthread.php?t=265929">Series 2 protection was finally defeated by 2005</a>, but I was long gone from the Tivo ecosystem by then, so I never saw it happen.
</p>
<p>
It's fair to ask "so what?" at this point. So we can't hack Tivo's series 2 hardware. I may not like it, but it's their hardware, not mine. They can build whatever protections into it they want, right? Ah, but there's the rub. <b>Tivo is based on Linux, and Linux is licensed under the GPL.</b> The GPL uses <a href="http://www.gnu.org/copyleft/">a "copyleft" license</a>:
</p>
<p>
</p>
<blockquote>
The simplest way to make a program free software is to put it in the public domain, uncopyrighted. This allows people to share the program and their improvements, if they are so minded. But it also allows uncooperative people to convert the program into proprietary software. They can make changes, many or few, and distribute the result as a proprietary product. People who receive the program in that modified form do not have the freedom that the original author gave them; the middleman has stripped it away.
<p>
In the GNU project, our aim is to give all users the freedom to redistribute and change GNU software. If middlemen could strip off the freedom, we might have many users, but those users would not have freedom. So instead of putting GNU software in the public domain, we "copyleft" it. Copyleft says that anyone who redistributes the software, with or without changes, must pass along the freedom to further copy and change it. Copyleft guarantees that every user has freedom.
</p>
</blockquote>
<p>
This concept of software freedom is embedded deeply into the GPL. As promised, we indeed have the freedom to see the Tivo source code, copy it, and change it. <b>Since the Tivo's hardware validates the software, access to the Tivo software becomes effectively meaningless.</b> You can modify the software all you want, but you'll never be able to run it on your own Tivo!
</p>
<p>
You might, in fact, argue that <b>Tivo subverted the very principles of the GPL they built their business on</b>. Richard Stallman certainly did. He <a href="http://fsfeurope.org/projects/gplv3/drm-and-gplv3">felt so strongly about this perceived subversion of the GPL</a> that he literally went back and <i>rebuilt the GPL license</i> to prevent what Tivo did:
</p>
<p>
</p>
<blockquote>
However, there are those that want to use GPL-covered software for this purpose, and they want to do so by turning <a href="http://www.codinghorror.com/blog/archives/001044.html">freedom number one</a> into a sham, a facade. So they plan to do something like, make a modified version of the GPL-covered program, which contains code to restrict you, and distribute that to you and somehow arrange that you can't really modify it, or if you modify it it won't run, or if you modify it and operate it, it won't operate on the same data.
<p>
They do this in various ways. This is known as <a href="http://en.wikipedia.org/wiki/Tivoization">Tivoization</a> because this is what the Tivo does. The Tivo includes some GPL-covered software. It includes a GNU+Linux system, a small one, but it does, and you can get the source code for that, as required by the GPL because many parts of GNU+Linux are under the GPL, and once you get the source code, you can modify it, and there are ways to install the modified software in your Tivo and if you do that, it won't run, period. It does a checksum of the software and it verifies that it's a version from them and if it's your version, it won't run at all. This is what we are forbidding, with the text we have written for GPL version three. It says that the source code they must give you includes whatever signature keys, or codes that are necessary to make your modified version run.
</p>
</blockquote>
<p>
Businesses can no longer adopt GPL software, then incorporate hardware protections to effectively prevent the software freedoms that the GPL specifically guarantees. This is nothing less than a full frontal assault on everyone's favorite technology, Digital Rights Management. Note that there is a sizable loophole, however. The final version of GPL v3 (<a href="http://gplv3.fsf.org/dd3-faq">section 6</a>) states that the signing key does not have to be provided when the software is distributed to businesses. But this was clearly done only grudgingly, and after intense resistance; the FAQ chides us: <i>"we think it's unfortunate that people would be willing to give up their freedom like this."</i>
</p>
<p>
The way Tivo built their business around the GPL and then completely subverted it with hardware protection does rankle. But I also wonder how a company like Tivo could make money if users could simply recompile the Tivo software to stop phoning home and billing them. Like consoles, the Tivo hardware is typically sold at a big loss to subsidize the platform. If that hardware could be easily formatted and the software rebuilt, you've created a <i>permanent</i> loss leader. So I can empathize with their desire to control the platform.
</p>
<p>
I'm not sure where I stand on the tivoization clause in GPL v3. For what it's worth, as much as I adored my Tivo, I abandoned the platform years ago as a lost cause. I've already said that I think <a href="http://blogs.zdnet.com/hardware/?p=1229">a compelling product can make me overlook the DRM</a>, so maybe my opinion is already suspect.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/tivoization-and-the-gpl/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ There Ain't No Such Thing as the Fastest Code ]]></title>
<link>https://blog.codinghorror.com/there-aint-no-such-thing-as-the-fastest-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was tickled to see that James Hague chose <a href="http://www.amazon.com/exec/obidos/ASIN/0673386023/codihorr-20">The Zen of Assembly Language Programming</a> as one of <a href="http://prog21.dadgum.com/19.html">five memorable books about programming</a>. I wholeheartedly agree. Even if you <b>never plan to touch a lick of assembly code in your entire professional career</b>, this book is a fantastic and thoroughly useful read. I was a mere <i>Visual Basic</i> programmer when I found this book (along with <a href="http://www.amazon.com/exec/obidos/ASIN/1883577039/codihorr-20">The Zen of Code Optimization</a>), picked it up on a lark, and I could barely put it down. It's that good.
</p>
<p>
Abrash isn't just <a href="http://en.wikipedia.org/wiki/Michael_Abrash">a seminal figure in the software engineering community</a>, he's also one of the best technical writers you'll ever find. That's why <a href="http://www.codinghorror.com/blog/archives/000234.html">he's one of my programming heroes</a>, directly alongside Steve McConnell.
</p>
<p>
His <a href="http://www.amazon.com/exec/obidos/ASIN/1576101746/codihorr-20">Graphics Programming Black Book</a> is similarly great, and covers topics so general and wide ranging that the title becomes a bit of a misnomer. Best of all, it's <a href="http://www.byte.com/abrash/">available online for free courtesy of Byte</a>, so you can sample it yourself.
</p>
<p>
<a href="http://www.byte.com/abrash/"><img alt="image placeholder" >
</p>
<p>
I know what you're thinking. "This book is about graphics. And assembly language. Plus it's from, like, 1996, which is approximately 1928 in computer years. It's of no interest to me as a programmer." Admit it. You are. But you know what you're going to do? You're going to click through anyway and read some of it. Just like in college, <b>the class topic doesn't matter when the instructor is a brilliant teacher</b>. And that's exactly what Abrash is.
</p>
<p>
Abrash is a world class coder and technical writer, but he's also not shy about explaining the perils and dangers of our craft, including <b>the biggest problem of all-- the one that sits behind the keyboard</b>. Allow me to illustrate with one of my very favorite Abrash passages, from Chapter 16 of the <a href="http://www.byte.com/abrash/">Graphics Programming Black Book</a>.
</p>
<p>
</p>
<blockquote>
Not so long ago, Terje Mathisen, who I introduced earlier in this book, wrote a very fast word-counting program, and posted it on <a href="http://en.wikipedia.org/wiki/Byte_Information_Exchange">BIX</a>. When I say it was fast, I mean <i>fast</i>; this code was optimized like nobody's business. We're talking top-quality code here.
<p>
When the topic of optimizing came up in one of the BIX conferences, Terje's program was mentioned, and he posted the following message: "I challenge BIXens (and especially mabrash!) to speed it up significantly. I would consider 5 percent a good result." The clear implication was, "That code is as fast as it can possibly be."
</p>
<p>
Naturally, it wasn't; there ain't no such thing as the fastest code (TANSTATFC? I agree, it doesn't have the ring of TANSTAAFL).
</p>
<p>
[assembly language tricks and useful optimization approaches elided -- <a href="http://www.byte.com/abrash/chapters/gpbb16.pdf">see PDF</a> for full detail]
</p>
<p>
The biggest optimization barrier that Terje faced was that <b>he thought he had the fastest code possible</b>. Once he opened up the possibility that there were faster approaches, and looked beyond the specific approach that he had so carefully optimized, he was able to come up with code that was a lot faster. Consider the incongruity of Terje's willingness to consider a 5 percent speedup significant in light of his later <b>near-doubling of performance</b>.
</p>
</blockquote>
<p>
In the same chapter, Mr. Abrash relates a similar anecdote based on a word counting program. It was published as a challenge in his "Pushing the Envelope" column:
</p>
<p>
</p>
<blockquote>
That initial challenge was sparked by a column David Gerrold wrote concerning the matter of counting the number of words in a document; David turned up some pretty interesting optimization issues along the way. David did all his coding in Pascal, pointing out that while an assembly language version would probably be faster, his Pascal utility worked properly and was fast enough for him.
<p>
It wasn't, however, fast enough for me. The logical starting place for speeding up word counting would be David's original Pascal code, but I'm much more comfortable with C, [so I created] a loose approximation of David's word count program, translated to C.
</p>
</blockquote>
<p>
Mike proceeds to do what he does best-- optimize the word count program into assembly and explain along the way in an easy going, highly articulate way. His results are as follows:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="450">
<tr>
<td>C conversion</td>
<td>4.6 sec</td>
</tr>
<tr>
<td>C + assembly conversion</td>
<td>2.4 sec</td>
</tr>
<tr>
<td>C + assembly conversion with lookup table</td>
<td>1.6 sec</td>
</tr>
</table>
<p>
He then posted his program as a challenge for readers of PC Techniques-- <b>can this optimized assembly word count program, from an acclaimed industry expert on assembly optimization, be made even <i>faster</i>?</b> Well, I think you can guess what happened next.
</p>
<p>
</p>
<blockquote>
So how did the entrants in this particular challenge stack up? More than one claimed a speed-up over my assembly word-counting code of more than three times. On top of the three-times speedup over the original C code that I had already realized, we're almost up to <b>an order of magnitude faster</b>. You are, of course, entitled to your own opinion, but <i>I</i> consider an order of magnitude to be significant.
<p>
Truth to tell, I didn't expect a three-times speedup; around two times was what I had in mind. Which just goes to show that any code can be made faster than you'd expect, if you think about it long enough and from many different perspectives.
</p>
</blockquote>
<p>
Like Mike said, <i>there ain't no such thing as the fastest code</i>. If you think there is, <i>you're</i> probably the barrier standing in the way of further performance, not the code itself.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/there-aint-no-such-thing-as-the-fastest-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Code Isn't Beautiful ]]></title>
<link>https://blog.codinghorror.com/code-isnt-beautiful/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was thrilled to see the book <a href="http://www.amazon.com/exec/obidos/ASIN/0596510047/codihorr-20">Beautiful Code: Leading Programmers Explain How They Think</a> show up in my Amazon recommendations. It seems like exactly the type of book I would enjoy. So of course I bought a copy.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0596510047/codihorr-20"><img alt="image placeholder" >
</p>
<p>
</p>
<p>
Unfortunately, Beautiful Code wasn't nearly as enjoyable of a read as I had hoped it would be. It is by no means a <i>bad</i> book, but there's something about it that's not quite right.
</p>
<p>
Part of the problem is that it's a compilation of disconnected essays, much like <a href="http://www.codinghorror.com/blog/archives/000346.html">The Best Software Writing I</a>. Because there are <a href="http://www.oreilly.com/catalog/9780596510046/toc.html">thirty-three different authors</a>, there's naturally going to be a lot of variance in tone, content, and quality. How you feel about the book is largely dicated by how much you like the individual essays. There's certainly no lack of quality in the authors. There are plenty of famous, highly regarded programmers represented here: Brian Kernighan, Yukihiro Matsumoto, Jon Bentley, Charles Petzold, and many others.
</p>
<p>
Despite all that, I loved <a href="http://www.codinghorror.com/blog/archives/000346.html">The Best Software Writing</a>; why can't I love Beautiful Code? I wasn't able to put my finger on exactly what the deeper problem was with Beautiful Code until I read <a href="http://www.amazon.com/review/R1W0YZZWT53Y9M/ref=cm_cr_rdp_perm">this eloquent reader review from Dmitry Dvoinikov</a>. I suddenly realized what ultimately trips up Beautiful Code. It was right there in front of me, all along. It's even in the title: <b>Code</b>.
</p>
<p>
</p>
<blockquote>
With rare exception, the authors don't even mention the word "beautiful" in their essays. They allude with "There, we have this system, it works like this." What exactly the author finds beautiful about it, and why, remains a secret.
<p>
The chapter written by Yukihiro Matsumoto, the creator of Ruby, was the most impressive standout. It is three pages in which he simply writes about what he believes beautiful code is. He explains his understanding of beautiful code to you. This is what the book should be!
</p>
<p>
Instead, <b>many chapters just reprint a few pages of code and conclude - see, it is beautiful!</b>
</p>
<p>
Many times I was unable to grasp the problem - what was it that required that so-called beauty to emerge? I couldn't see the whole picture, but the authors presume I do. Any possible appreciation of beauty requires deep understanding. What if I show you a magnified fragment of Mona Lisa's background, an area of 3x3 blackish pixels? No doubt Leonardo had to paint them too. But where is the beauty?
</p>
<p>
Only a few authors were wise enough to use pseudocode, something that anyone can read, no matter from which camp. It's just weird when the authors present their beatiful code in Ruby or Perl or Lisp. Look, I haven't touched Ruby yet, I hate Perl and I can't imagine using Lisp in practice. Nevertheless the authors repeatedly say something like "It's easy, I'll show you, this bracket does this and that character does something else. <i>Now</i> do you see how beautiful it is?" <b>They literally show you a piece of poetry in a foreign language and ask you to appreciate it.</b>
</p>
<p>
A classical example of awful poetry in Russian is (transliterated)
</p>
<p>
</p>
<blockquote>
<i>Ya poet, zovus' Neznajka,<br>
ot menya vam balalajka.</i>
</blockquote>
<p>
Can you tell whether this is good or bad and why? What if I told you it's beautiful? Would you believe? Does it appeal to your sense of beauty?
</p>
</blockquote>
<p>
Ideas are beautiful. Algorithms are beautiful. Well executed ideas and algorithms are even more beautiful.  But the code itself is not beautiful. <b>The beauty of code lies in the architecture, the ideas, the grander algorithms and strategies that code <i>represents</i>.</b> The code samples presented are indeed clear, readable, and well written. But they are weak evidence of beauty; it's not the language that is inherently beautiful. Barroom doggerel expressed in French or Russian is never automatically elevated to the level of poetry.
</p>
<p>
So when the Beautiful Code authors proffer pages of code-- real live production code-- and ask us to see the beauty, the code doesn't help. It gets in the way. </p>
<p>
</p>
<blockquote>
It's been a long time since I found *dst++ = *src++ beautiful.
</blockquote>
<p>
Focusing on the code is exactly the wrong approach. It's like a detailed technical description of the paints, brushes, and techniques used to paint the <a href="http://en.wikipedia.org/wiki/Mona_Lisa">Mona Lisa</a>, without any of the historical or artistic context that makes it such an important painting.
</p>
<p>
<b>Can't we expect readers to see past the language?</b> I'd ask the very same question of the authors. So many of them got mired in the minute details of the code and language that they never got around to the "why" underneath -- the beautiful ideas and concepts that code represents. I'd also ask the same question of every working programmer today. <b>I can scarcely post any code snippets in Visual Basic today without a slew of comments complaining about how awfully horrible Basic syntax is</b>, how their eyes are bleeding, it's unreadable, the horrors of End If versus curly brackets, etcetera, etcetera, ad nauseam. Never mind the language-- what about the underlying algorithmic concept I am trying to represent in code? How does <i>that</i> look?
</p>
<p>
Apparently, for many of us, beauty really <i>is</i> skin deep.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2008-02-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/code-isnt-beautiful/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
</channel>
</rss>
