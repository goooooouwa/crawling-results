<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title><![CDATA[ Eric Lippert's Purple Crayon ]]></title>
<link>https://blog.codinghorror.com/eric-lipperts-purple-crayon/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Eric Lippert is one of my <a href="http://blogs.msdn.com/ericlippert/default.aspx">favorite Microsoft bloggers</a>. He's one of those people who reminds you that Microsoft, despite all its problems, still employs a lot of incredibly thoughtful, near-genius programmers. Take a look at his greatest hits:
</p>
<p>
</p>
<ul>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2003/10/28/53298.aspx">How many Microsoft employees does it take to change a lightbulb?</a>
</li>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2006/07/07/659259.aspx">Error messages: diagnostic is preferable to prescriptive</a>
</li>
<li>
<a href="http://www.mikepope.com/blog/AddComment.aspx?blogid=480">Teching the Tech Tech</a>*
</li>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2004/05/04/125893.aspx">Grile #6: Comment Rot</a>
</li>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2004/05/05/126739.aspx">Aargh, Part Six: One More Thing About Comments</a>
</li>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2003/10/17/53237.aspx">How Bad Is Good Enough?</a>
</li>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2003/09/12/52989.aspx">What's up with Hungarian Notation?</a>
</li>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2004/09/09/227461.aspx">Thirty Years of Backwards Compatibility</a>
</li>
<li>You Want Salt With That? (<a href="http://blogs.msdn.com/ericlippert/archive/2005/01/28/362587.aspx">one</a>,<a href="http://blogs.msdn.com/ericlippert/archive/2005/01/31/363844.aspx"> two</a>, <a href="http://blogs.msdn.com/ericlippert/archive/2005/02/03/366274.aspx">three</a>, <a href="http://blogs.msdn.com/ericlippert/archive/2005/02/07/368569.aspx">four</a>)
</li>
<li>Five-Dollar Words for Programmers: <a href="http://blogs.msdn.com/ericlippert/archive/2005/10/26/483900.aspx">Idempotence</a>, <a href="http://blogs.msdn.com/ericlippert/archive/2005/10/28/483905.aspx">Orthogonal</a>
</li>
<li>
<a href="http://blogs.msdn.com/ericlippert/archive/2004/09/27/234826.aspx">Breadth is sometimes better than depth</a>
</li>
</ul>
<p>
But really, it's hard to single out any one post. I could go on and on with the hyperlinks. Eric has the singular gift of all great communicators: <b>he can make any topic interesting</b>.
</p>
<p>
Unfortunately, every time I visit Eric's blog for yet another <a href="http://blogs.msdn.com/ericlippert/">Fabulous Adventure in Coding</a>, my eyes are assaulted by the unholy combination of purple and Lucida Sans Unicode:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Ow. Ow. Ow. Seriously. Ow. Why?
</p>
<p>
I'm reminded of <a href="http://www.amazon.com/Harold-Purple-Crayon-Anniversary-Books/dp/0064430227">a certain Harold who is also quite fond of purple</a>.
</p>
<p>
<a href="http://www.amazon.com/Harold-Purple-Crayon-Anniversary-Books/dp/0064430227"><img alt="image placeholder" >
</p>
<p>
I understand we all have our own personal quirks. But it's been over three years now. I'm staging an intervention, right now, right here. Your content is incredible, Eric, but the presentation is <a href="http://www.codinghorror.com/blog/archives/000340.html">killing your poor readers' eyesight</a>. <b>It's time to let go of the purple crayon.</b> Have pity on your sad, weary-eyed readers. We're begging you.
</p>
<p>
We're not asking you to give up your individuality. You can <a href="http://blogs.msdn.com/ericlippert/archive/2005/01/14/353195.aspx">keep the Tilley Hat</a>.
</p>
<p>
* even Eric's throwaway comments are worthy of entire blog posts.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/eric-lipperts-purple-crayon/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Day The Trackbacks Died ]]></title>
<link>https://blog.codinghorror.com/the-day-the-trackbacks-died/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>You might read a post on this blog and decide I'm full of crap. That's fine. <em>I often am full of crap</em>. I encourage you to leave a comment explaining why you feel this way. And, while you're at it, feel free to point out any errors or inaccuracies in anything I've written. This kind of simple, immediate, highly visible public dialog is why I believe so strongly in <a href="http://www.codinghorror.com/blog/archives/000538.html">comments as an essential part of blogging</a>.</p>
<p>But sometimes a mere comment isn't enough. Maybe you have your own blog. Depending on the depth of your feelings on the matter, you might want to write an entire post on <em>your</em> blog explaining, in great detail, specifically <em>why</em> I'm full of crap. Then you'd publish your post for the world to see. But how do you know that I, the target of your vitriol, have read your post? How do you know that I can even <em>find</em> your post? You could email me directly, but that feels a little too intimate. Or, you could leave a comment linking to your response, but that feels like additional work.</p>
<p>The answer lies in <a href="http://en.wikipedia.org/wiki/Trackback">trackbacks</a>. <strong>Trackbacks are a way of relating conversations across websites</strong>. After you publish your post, you send a trackback to my post. This is usually handled automatically by the blogging software. The trackback links our two posts together. I get notified of any trackbacks to my posts, so I can follow the trackback to read your response. Furthermore, trackbacks are public, just like comments. So any future readers can also follow our conversation thread by directly navigating from my blog to yours with a single click. Tom Coates created <a href="http://www.plasticbag.org/archives/2003/03/what_is_trackback_part_one/">a little diagram</a> which illustrates this process:</p>
<p><img alt="image placeholder" >
<p>They're a great idea. <strong>Unfortunately, trackbacks are so horribly and fundamentally broken that they're effectively useless.</strong></p>
<p>The <a href="http://www.sixapart.com/pronet/docs/trackback_spec">original trackback specification was</a> published by Six Apart in summer 2002. It's very basic. The trackback URL is published in the metadata embedded in every blog post:</p>
<pre>&lt;rdf:Description
rdf:about="http://www.codinghorror.com/blog/archives/000666.html"
<span style="color: red;">trackback:ping="http://www.codinghorror.com/mtype/mt-tb.cgi/666"</span>
dc:title="The Programmer's Bill of Rights"
dc:identifier="http://www.codinghorror.com/blog/archives/000666.html"
dc:creator="Jeff Atwood"
dc:date="2006-08-24T23:59:59-08:00" /&gt;
</pre>
<p>You simply HTTP POST a bit of data to the trackback URL of the post you're commenting on, like so:</p>
<pre>POST http://www.codinghorror.com/mtype/mt-tb.cgi/666
Content-Type: application/x-www-form-urlencoded; charset=utf-8
title=He's+full+of+crap&amp;url=http://www.bar.com/&amp;blog_name=Foo
</pre>
<p>See? Simple. And it works great. In one swell foop, you've created a coherent conversation that flows across two totally different websites!</p>
<p>Well, it <em>was</em> great. Until the spammers realized two things:</p>
<ol>
<li>how high the pagerank is for popular blogs (7+) </li>
<li>how trivially easy it is to abuse the trackback mechanism because trackbacks have <em>no authentication mechanism whatsoever</em>. </li>
</ol>
<p>CAPTCHA has <a href="http://www.codinghorror.com/blog/archives/000712.html">completely solved my comment spam problem</a>. But distinguishing between humans and machines is useless on trackbacks, which are all machine entered by definition. I've fought the good fight against the rising tide of trackbacks <a href="http://www.codinghorror.com/blog/archives/000715.html">with various blacklists</a> over the last three years, but as this blog grows more and more popular, I'm clearly losing the war. Malicious spammers can batch register dirt-cheap domain names and write scripts to mass-POST these URLs all over the blogosphere far, far faster than I can ever hope to blacklist them. Every day starts with a depressing routine of adding 4-8 new spam URLs to my blacklist.</p>
<p>Yes, there are <a href="http://www.codinghorror.com/blog/archives/000715.html">distributed blacklists</a> like <a href="http://akismet.com/">Akismet</a>. Yes, you can put all your trackbacks into a moderation queue and spend 5 minutes every day deleting them all manually. Yes, you could <a href="http://www.hixie.ch/specs/pingback/pingback">retrieve the linking page</a> and make sure it contains the promised link to your post. But these are only slightly larger band-aids over a massive, sucking chest wound. These aren't sustainible solutions. We have a much deeper problem. <strong>Trackbacks, as we currently know them, are dead, kaput, expired.</strong></p>
<p>It's an absolute travesty, and I completely blame Six Apart's <a href="http://www.sixapart.com/pronet/docs/trackback_spec">initial trackback specification</a>. How could they forget the rich history of email spam we've had to deal with for the last ten years? Trackbacks, as a result of Six Apart's incredibly naive initial design, <a href="http://jeremy.zawodny.com/blog/archives/005049.html">are now a total loss</a>. That's what happens when you design social software without <a href="http://www.codinghorror.com/blog/archives/000295.html">considering the impact of malicious users from the very beginning</a>.</p>
<p>Now, hopefully you'll understand why I've disabled all trackbacks for this blog as of today.</p>
<p><strong>But I still believe in the concept of trackbacks.</strong> I <em>want</em> to read your response to my posts, whether it's on your site, or mine as a comment. So rather than relying on direct peer-to-peer links, I'm exploring the use of external indexing services. I experimented with using Google searches to find all the pages that have linked to the URL of a post, but I wasn't happy with the results. For now, I've replaced the automatic trackback with <a href="http://technorati.com/tools/linkcount/">a bit of JavaScript from Technorati</a> which automatically lists any blogs that linked to a particular post. It's not quite as egalitarian as I'd like, because you have to join Technorati to participate. And it's another <a href="http://www.codinghorror.com/blog/archives/000497.html">unwanted external dependency</a> which I'll have to deal with. But it's the best I can do for now.</p>
<p>And please, if you're designing social software, try to avoid repeating the many mistakes of our forefathers. Again. <a href="http://www.codinghorror.com/blog/archives/000295.html">Design from day one with the assumption that a few of your users will be evil</a>. If you don't, like Six Apart, your naivite will make the entire community suffer sooner or later.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-day-the-trackbacks-died/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Assertiveness for Software Developers ]]></title>
<link>https://blog.codinghorror.com/assertiveness-for-software-developers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>As software developers, we're great at communicating with computers. But we're typically not so great at communicating with other people. Esther Schindler's <a href="http://blogs.cio.com/towards-sanity-in-software-project-estimation-a-chat-with-steve-mcconnell">recent interview with Steve McConnell</a> illustrates how this aspect of our personality tends to work against us:</p>
<blockquote>
<p>Marketers, sales staff, and upper management all tend to be better negotiators than technical staff, so when marketing (or whoever) says "get it done," technical staff ends up losing that negotiation. But it isn't really the technical staff that loses. The business loses, because it sets up a situation in which it pretends for months or years that it can do something that it can't.</p>
</blockquote>
<p>We present <a href="http://blog.codinghorror.com/how-long-would-it-take-if-everything-went-wrong/">our best estimates</a>, but we aren't assertive enough to stand up for them.</p>
<img alt="image placeholder" >
<p>Because we don't fight for our estimates, we get negotiated down to an <a href="http://blogs.cio.com/towards-sanity-in-software-project-estimation-a-chat-with-steve-mcconnell">untenable position</a>:</p>
<blockquote>
<p>Executives and managers tend by nature to be more assertive than rank-and-file technical staff, which is not a problem. The problem is that <b>they assume, incorrectly, that technical staff will be assertive with them if they need to be, and that isn't the case.</b> Technical staff often feel that they're being very assertive, but an objective observer would probably say the technical people cave in far too easily.</p>
<p>Business executives with non-technical backgrounds don't have any objective ability to judge the analytical validity of an estimate, so they probe the person they're talking with to see where they hit that person's point of discomfort, and they make an assessment based on that. Technical people who don't push back hard enough, soon enough, are implicitly sending a message that they can do more than they really can. When I talk with executives, I emphasize that they need to account for the fact that technical people are intimidated by them. Most executives assume the people around them are as assertive as they are, but that isn't true –  there's a reason that they're executives!</p>
</blockquote>
<p>Assertiveness doesn't have to mean loudmouthed and obnoxious. Nor is assertiveness "getting all up in someone's face". Assertiveness is, quite simply, the ability to convey your position to others as an equal participant in the conversation. Dr. John Welford <a href="http://www.jwelford.demon.co.uk/brainwaremap/assert.html">explains</a>:</p>
<blockquote>
<p>To be assertive is not, as some people imagine, to be overbearing and aggressive, but to be straightforward, open and honest. It means that you relate well to people, able to express your needs freely, take responsibility for your feelings and stand up for yourself when necessary. In conflict situations you seek, where possible, to reach a 'win-win' outcome, in which the needs of all parties are fully acknowledged.</p>
</blockquote>
<p>I'm <a href="http://blog.codinghorror.com/in-defense-of-the-smackdown-learning-model/">reasonably assertive</a>, to the point that I've found myself interceding on behalf of my teammates. But I really shouldn't do that. I should encourage them to stick up for themselves, instead.</p>
<p>If you'd like to be more assertive, I recommend starting with Dale Carnegie's classic book <a href="http://www.amazon.com/exec/obidos/ASIN/0671723650/codihorr-20">How to Win Friends and Influence People</a>. Dale's central thesis is truly timeless: <b>show a genuine interest in the people you meet, and you'll find it reciprocated tenfold</b>. It's the kind of book you should re-read every year, and it's short enough to make that possible.</p>
<p><a href="http://www.amazon.com/exec/obidos/ASIN/0671723650/codihorr-20"><img alt="image placeholder" >
<p>Beyond the Carnegie book, it's clear that <a href="http://blog.codinghorror.com/being-technologically-savvy-isnt-enough/">being technologically savvy isn't enough</a>. It's important to cultivate your negotiation skills and assertiveness, too, if for no other reason than to <a href="http://bluegraybox.com/blog/2004/12/21/bargaining/">avoid being easy meat at your next salary review</a>. One of my friends took the initiative to <b>sign up for a public speaking class</b>. <a href="http://thoughtcatalog.com/patty-barrett/2013/11/why-every-person-should-take-an-improv-class/">Improv classes</a> would also work.</p>
<p>What are you doing to improve <i>your</i> assertiveness?</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/assertiveness-for-software-developers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Logging in with the Keyboard ]]></title>
<link>https://blog.codinghorror.com/logging-in-with-the-keyboard/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The standard login form is everywhere. It's unavoidable. And it's <a href="http://www.codinghorror.com/blog/archives/000546.html">a giant pain in the butt</a>.</p>
<p><img alt="image placeholder" >
<p>As much as we see login forms every day, you'd think we would have mastered them by now. Unfortunately, we haven't. Here's what I've observed users doing, over and over again:</p>
<ol>
<li>Move the mouse to the username field. </li>
<li>Click the mouse button. </li>
<li>Type a username. </li>
<li>Move the mouse to the password field. </li>
<li>Click the mouse button. </li>
<li>Type a password. </li>
<li>Move the mouse to the login button. </li>
<li>Click the mouse button. </li>
</ol>
<p>Every time I watch someone do this, <em>a little part of me dies inside</em>. And I see it all the time.</p>
<p>I'm not just talking about casual users like our parents. I'm talking about our fellow software developers, and other users who work with the computer for most of the day. People who really should know better.</p>
<p>What kills me about this is all the needless, painful transitions between the mouse and the keyboard. Your fingers are already on the keyboard while you're typing-- <strong>just add a little Tab and Enter to the mix!</strong> I'm no <a href="http://www.codinghorror.com/blog/archives/000209.html">keyboard Nazi</a>. All I want is to save users a few precious seconds as they slog through the endless logins during their work day. And it's so darn easy, too:</p>
<ol>
<li>Type a username. </li>
<li>Press the <kbd>Tab</kbd> key. </li>
<li>Type a password. </li>
<li>Press the <kbd>Enter</kbd> key. </li>
</ol>
<p>See? Wasn't that nice?* Now it's your turn to play Keyboard Appleseed and spread the word so your fellow coworkers can spend less time logging in-- and more time getting actual work done.</p>
<p>* Although this is the accepted standard behavior for login forms, it is possible for incompetent developers to <a href="http://www.mikepope.com/blog/displayblog.aspx?permalink=309">screw this up</a>. But that advice doesn't apply to the developers reading this blog.. right?</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/logging-in-with-the-keyboard/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Did YouTube Cut the Gordian Knot of Video Codecs? ]]></title>
<link>https://blog.codinghorror.com/did-youtube-cut-the-gordian-knot-of-video-codecs/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Playing video on a computer has always been a crapshoot. You must have the correct video codec installed, the same video codec that the clip was encoded with. If you don't, the video won't play.  You'll have to find, download, and install the proper codec first. It's even more of a problem on the web, where users can run any combination of operating system and browser. Just take a look at all the choices in Yahoo's web-based Media Helper:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As the old saying goes, we love standards: that's why we have <a href="http://en.wikipedia.org/wiki/List_of_codecs#Video_codecs">so many of them</a>. Here are a few of the more popular video codecs you're likely to encounter out in the wild:
</p>
<p>
</p>
<ul>
<li>Windows Media Video
</li>
<li>QuickTime
</li>
<li>MPEG-1
</li>
<li>MPEG-2
</li>
<li>MPEG-4
</li>
<li>x264
</li>
</ul>
<p>
It doesn't seem like such a large list, until you consider that there are <b>dozens of variants for each codec</b>. What version of QuickTime? What version of Windows Media? Which MPEG-4 implementation? And this is only a partial list of the <i>popular</i> codecs. Imagine a poor user trying to view a RealVideo clip in this day and age.
</p>
<p>
That's why we call it <a href="http://btfaq.com/serve/cache/69.html">codec hell</a>. It makes the current format war between Blu-Ray and HD-DVD look like a walk in the park.
</p>
<p>
In this hostile environment, it's no wonder that <b>YouTube elected to cut the gordian knot of video codecs: they chose Flash Video, which "just works" on most computers</b>. Even if Flash isn't present on your computer, it's an easy in-place browser download, unlike, say, a QuickTime install. It's the same reason Google Video <a href="http://www.kaourantin.net/2005/09/google-video-pragmatism-at-work.html">switched to Flash in September 2005</a>, long before Google purchased YouTube. Tinic Uro explains:
</p>
<p>
</p>
<blockquote>
<a href="http://en.wikipedia.org/wiki/FLV">The .FLV file format</a> uses the KISS (keep it simple stupid) approach. It offers neither the high fidelity or the flexibility of file formats like QuickTime or Windows Media. But it does what it does well: playing back simple video streams with some meta information.
</blockquote>
<p>
The availability of a common, simple video playback format across all browsers and platforms has ushered in a new era of video sharing on the web. And that's a very good thing.
</p>
<p>
But we've paid an extraordinarily heavy price for this universality: <b>Flash Video quality is, in a word, <i>hideous</i></b>. Let's compare the <a href="http://movies.yahoo.com/feature/transformers_hd.html">Transformers Movie trailer</a>, which is available in a variety of different video formats.
</p>
<p>
<a href="http://www.youtube.com/watch?v=mwyzSNk8Fu8">YouTube</a> version:
</p>
<p>
<a href="http://www.youtube.com/watch?v=mwyzSNk8Fu8"><img alt="image placeholder" >
</p>
<p>
Windows Media Video streaming version:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
QuickTime streaming version:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
QuickTime 480p version:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The Flash Video version of the Transformers movie trailer is a bottom of the barrel, least common denominator experience. It is painfully bad. But I'd also argue that <b>quality is largely irrelevant for <i>most</i> video content on the web</b>. Having video you can embed, play, and link everywhere-- without worrying about whether the video will play back properly on someone's computer-- is far more important than quality alone. Flash Video "just works", and it's never more than one click away from 98% of the web browsers on the planet. It'll never win any quality awards, but it's still recognizable as video. Therefore it wins by default.
</p>
<p>
The codec wars are over, at least for web clips. <b>Flash Video is the new internet video standard.</b> Sometimes <a href="http://www.codinghorror.com/blog/archives/000047.html">worse really is better</a>.
</p>
<p>
That said, I do wish we hadn't cut out ten years of video codec progress to get to this point. When watching YouTube clips, I sometimes feel like I'm watching ancient <a href="http://en.wikipedia.org/wiki/Video_for_Windows">Video for Windows</a> clips circa 1993. Here's hoping the Flash developers can incorporate more modern, higher quality codecs without re-introducing codec hell along the way.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/did-youtube-cut-the-gordian-knot-of-video-codecs/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Will your next computer monitor be a HDTV? ]]></title>
<link>https://blog.codinghorror.com/will-your-next-computer-monitor-be-a-hdtv/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Instead of one giant monitor, I'd rather have <a href="http://www.codinghorror.com/blog/archives/000217.html">multiple moderately large monitors</a>. I'm a card-carrying member of the <a href="http://www.codinghorror.com/blog/archives/000740.html">prestigious three monitor club</a>. But giant monitors have their charms, too; there is something to be said for an enormous, contiguous display area.
</p>
<p>
But large monitors tend to be inordinately, prohibitively expensive all out of scale to their size. Consider Apple's monitor line:
</p>
<p>
</p>
<table width="400">
<tr>
<td>30" Apple Cinema HD Display</td>
<td>2560 x 1600</td>
<td>$1,999
</td>
</tr>
<tr>
<td>23" Apple Cinema HD Display</td>
<td>1920 x 1200</td>
<td>$999
</td>
</tr>
<tr>
<td>20" Apple Cinema Display</td>
<td>1680 x 1050</td>
<td>$699
</td>
</tr>
</table>
<p>
30" is nice, but you're paying <b>2x the price of the 23" for 1.7x the number of pixels</b>. And then there's that insanely high resolution. <a href="http://www.codinghorror.com/blog/archives/000747.html">Additional resolution is always welcome</a>, of course, but resolution has some pitfalls of its own. Greg Vederman, the editor of PC Gamer magazine, <a href="http://www.pcgamer.com/archives/2006/12/im_in_the_very.html">explains</a>:
</p>
<p>
</p>
<blockquote>
30-inch wide-screen displays are all the rage right now - seems like everyone wants one, and when people post saying that they've purchased one, the crowd does a lot of "oooh-ing" and "ahhhh-ing" over it. But, folks, I'm starting to think that the far more affordable 1920x1200 24-inchers are the true sweet spot. Not only is 1920x1200 a more easily attained resolution for most modern video cards, but counter-intuitively, text and fonts are larger on 1920x1200 24-inchers than they are on 2560x1600 30-inchers. You read that right: you'll have to sit closer to a 30-inch monitor than you will a 24-inch monitor in order to comfortably read text.
</blockquote>
<p>
<a href="http://www.istartedsomething.com/20061211/vista-dpi-scaling/">Vista is more scalable than XP</a>, but it's still a far cry from a vector-based, PDF style environment where everything scales perfectly to 1200 DPI or better. We <a href="http://www.codinghorror.com/blog/archives/000137.html">still live in a bitmapped world</a>.
</p>
<p>
But something very interesting is happening: <b>the emergence of inexpensive LCD high-definition televisions</b>. Greg Vederman relates his experiences:
</p>
<p>
</p>
<blockquote>
I've been running my PC on a 37" 1080p HDTV (Westinghouse LVM-37W3) since yesterday morning in anticipation of a review I'll be doing soon, comparing it to a couple of the newest 30" monitors from Dell and HP. I have more testing to do, but barring some sort of catastrophic failure in the next several days, I'm sold on this TV's fitness as a PC monitor. It has a terrific picture, multiple input options (VGA, DVI, component, composite, S-Video), and costs hundreds less than any of the 30" monitors on the market today. Plus, with the Westi, I can comfortably kick back in my office chair and read cnn.com without straining my eyes. (30" monitors run at 2560x1600 natively, and I'm starting to think that that res is simply too high for "typical" use.)
<p>
[this HDTV] proves that at least some of the new, smaller, 1080p sets give PC monitors a real run for their money.
</p>
</blockquote>
<p>
This compares quite favorably with the largest Apple display:
</p>
<p>
</p>
<table>
<tr>
<td valign="bottom">
<img alt="image placeholder" >
</td>
<td valign="bottom">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td>
<a href="http://hometheater.about.com/od/productreviewstoppicks/fr/westi37w3full.htm">Westinghouse LVM-37W3 HDTV</a><br>1920 x 1080, 37"<br><b>$1,099</b>
</td>
<td>
<a href="http://store.apple.com/1-800-MY-APPLE/WebObjects/AppleStore.woa/wa/RSLID?mco=DF54FC1B&amp;nplm=M9179LL%2FA">Apple Cinema HD Display</a><br>2560 x 1600, 30"<br><b>$1,999</b>
</td>
</tr>
</table>
<p>
If you can deal with the lower DPI-- and like Greg Vederman, I'm not convinced the higher DPI of 30" computer monitors is always a good thing-- then <b>LCD HDTVs look like an outstanding deal for large monitor enthusiasts</b>. They're larger, and due to economies of scale, should always be substantially cheaper than computer monitors, too.
</p>
<p>
Assuming you can fit it on your desk, that is. Here's a customer-submitted picture from Amazon of <a href="http://www.amazon.com/gp/product/customer-images/B000EYZ994/ref=cm_ciu_pdp_images_0/102-9013466-8437716?ie=UTF8&amp;s=electronics&amp;index=0#gallery">the 37" Westinghouse on the Ikea Jerker desk</a>. For reference, I have three 20" LCD panels in the same area on the exact same desk.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/will-your-next-computer-monitor-be-a-hdtv/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is your PC capable of Hi-Def? ]]></title>
<link>https://blog.codinghorror.com/is-your-pc-capable-of-hi-def/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As I recently discovered, <a href="http://www.codinghorror.com/blog/archives/000746.html">playback of high definition video is very demanding</a>. You'll need a beefy PC to achieve the holy grail of maximum 1080p (1920x1080) resolution playback. Here are the <a href="http://www.cyberlink.com/english/support/bdhd_support/system_requirement.jsp">minimum system requirements</a> according to Cyberlink:
</p>
<p>
</p>
<ul>
<li>
<i>Very</i> fast single core CPU (3.2+ GHz Pentium 4, 2.0+ GHz Pentium-M, 2.4+ GHz Athlon 64), or almost any dual core CPU
</li>
<li>NVIDIA 7600gt or better, or ATI X1600 or better
</li>
<li>512mb system memory, 256mb video card memory
</li>
<li>for digital <a href="http://en.wikipedia.org/wiki/HDMI">HDMI output</a>, a certified video card with <a href="http://en.wikipedia.org/wiki/High-Bandwidth_Digital_Content_Protection">HDCP</a> support and a HDMI connector
</li>
</ul>
<p>
If you're wondering how your system stacks up for high-definition video, Cyberlink offers its <a href="http://www.cyberlink.com/english/support/bdhd_support/diagnosis.jsp">BD / HD Advisor software</a>, which runs through the requirements checklist automatically. Here's how <a href="http://www.codinghorror.com/blog/archives/000221.html">my current home theater PC</a> scored:
</p>
<p>
<a href="http://www.cyberlink.com/english/support/bdhd_support/diagnosis.jsp"><img alt="image placeholder" >
</p>
<p>
Cyberlink's tool is helpful, but it's also a subtle sales pitch for their <a href="http://www.cyberlink.com/multi/products/main_112_ENU.html">PowerDVD Ultra HD playback software</a>, which was just released a week or so ago. That's fine by me; I already use PowerDVD to enable DVD playback through Windows Media Center. It's the least problematic of all the DVD software I've tried, and believe me, I've tried all the major players at one point or another.
</p>
<p>
Most of the system requirements for Hi-Def are reasonable, but <b>the CPU requirement is off the charts, even by modern <i>gaming</i> standards</b>. Those insanely high CPU requirements are there for a reason. I can personally vouch for that. Although the Pentium-M chip in my home theater PC is overclocked to 1.75 GHz and has a full 2 megabytes of L2 cache, it can't play 1920x1080 (1080p) content without <a href="http://www.codinghorror.com/blog/archives/000746.html">massive stuttering</a>. It's possible the GPU could offload some of the work from the CPU, but getting GPU decode acceleration working is a crapshoot at best. Fast dual core CPUs are cheaper and certainly simpler than dealing with the hassle of offloading the decoding to the video card.
</p>
<p>
For most modern systems, all you'd have to do is..
</p>
<p>
</p>
<ol>
<li>Drop in a new video card, one with <a href="http://en.wikipedia.org/wiki/HDMI">HDMI</a> output and <a href="http://en.wikipedia.org/wiki/High-Bandwidth_Digital_Content_Protection">HDCP</a> support. There are a number of these on the market now; just look for the certified models with the HDMI connector. You will pay a premium over the standard DVI and VGA models, but it's not prohibitive. Capable HDMI+HDCP video cards <a href="http://www.newegg.com/Product/ProductList.asp?Submit=ENE&amp;N=2000380048&amp;Subcategory=48&amp;description=&amp;Ntk=&amp;srchInDesc=hdmi">can be found for under $150</a>.
</li>
<li>Add a HD-DVD or Blu-Ray drive. Internal Blu-Ray drives go for <a href="http://www.newegg.com/Product/Product.asp?Item=N82E16827131034">around $699</a> now. Unfortunately, there are no commercially available internal HD-DVD drives available at the moment, only the (amazingly cheap) external $199 Xbox 360 add-on, which <a href="http://www.pcper.com/article.php?aid=325">also works on the PC</a>.
</li>
<li>Purchase HD playback software, such as Cyberlink's <a href="http://www.cyberlink.com/multi/products/main_112_ENU.html">PowerDVD Ultra</a>. No high-def playback capability is built into any OS that I'm aware of.
</li>
</ol>
<p>
My HTPC uses an analog VGA connection, so it neatly bypass any HDCP requirements. I don't need to buy a new video card unless I want digital output; my old workhorse Radeon 9600 has 256 megabytes of memory and enough muscle to handle very high resolution analog video playback. But then there's this ominous disclaimer on the Cyberlink page:
</p>
<p>
</p>
<blockquote>
Note: <b>Some Blu-ray Discs or HD DVD titles may require a digital output instead of analog.</b> In this case, the digital output requirements listed above must be satisfied in order to play those titles.
</blockquote>
<p>
Scary stuff. Gotta plug <a href="http://en.wikipedia.org/wiki/Analog_hole">that pesky analog hole</a> eventually, I suppose.
</p>
<p>
Most of this is moot to me, as my home theater PC is currently connected to my EDTV plasma, which is only capable of 800 x 480. It's a perfect resolution for DVDs, but high-def, it ain't. Still, I like to think that this system would be capable of 720p (1280x720) playback if I had a reasonably cheap HD or Blu-Ray drive to drop into the drive bay.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-your-pc-capable-of-hi-def/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ On the Use of Cliches ]]></title>
<link>https://blog.codinghorror.com/on-the-use-of-cliches/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>This <a href="http://www.gawker.com/news/blogs/bad-lingo-blogmedia-clichs-222162.php">Gawker post on blog cliches</a> hits very close to home. It's an <em>"annotated list of words, phrases, and terms that have long overstayed their welcome in the media-blogosphere."</em> I'd have to agree. I'm guilty of a few of these, too.</p>
<ul>
<li>Best. [ultimate thing or experience.] Ever/Evar. </li>
<li>[undesirable counter-example], not so much. </li>
<li>FTW, O RLY, lol, FTL, OMG, FWIW, btw, PWND, ROTFL, etc. </li>
<li>[negative experience, situation, or description]; I just threw up a little bit in my mouth. </li>
<li>[purposefully non-ghetto statement], yo. </li>
<li>[undesirable conclusion]. Oy. </li>
<li>[amazed paraphrase of opposing position]. Seriously? Seriously? </li>
<li>What's next? [outlandish scenario]? </li>
<li>I'm looking at you, [example of complaint]. </li>
<li>Um, [condescension]? </li>
<li>[Argument], wait for it, [rhetorical flourish]. </li>
<li>[Undesirable experience] made my [sensory organ] bleed. </li>
<li>[adjective]-y goodness </li>
<li>[any word]-gasm </li>
<li>[x] is the new [y]. </li>
</ul>
<p>There are a bunch of good suggestions in the comments as well:</p>
<ul>
<li>Let me see if I have this straight. [outlandish scenario]. </li>
<li>No, really. </li>
<li>I heart [object, person, place, or thing]. </li>
<li>[statement]. Meh. </li>
<li>Mr. [Blank]y Mc[Blank]erson </li>
<li>I want those (x) [minutes, hours, days] of my life back. </li>
</ul>
<p>Some of these catchphrases are fun – in moderation. But you have to be aware that you're using a common catchphrase, and you should use it selectively and judiciously. Most people don't realize how often they're using a catchphrase, which is why they become overused and cliche in the first place. Using a catchphrase is like ending a sentence with an exclamation point: rarely necessary, but when it is, time it for maximum impact.</p>
<p>If you're worried you might be inadvertently relying on cliches in your writing, try cutting and pasting some of your prose into the <a href="http://cliche.theinfo.org/">online clich finder</a>. It's based on the <em>Associated Press Guide to News Writing</em>.</p>
<p>I try to avoid cliches in my speaking and writing by intentionally mixing things up. <strong>I refrain from using the same words, the same phrases, the same <em>stuff</em> too often.</strong> There are a million ways to communicate any idea. Why limit yourself to narrow, predefined patterns of thinking, writing, and speaking? Stretch a little. Explain it a different way this time. Rephrase. Restate. Riff on the topic.</p>
<p>Using cliches is fine; just be sure you aren't using them as a substitute for real communication.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/on-the-use-of-cliches/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Keeping Time on the PC ]]></title>
<link>https://blog.codinghorror.com/keeping-time-on-the-pc/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I have something of a clock fetish. My latest acquisition is a <a href="http://en.wikipedia.org/wiki/Nixie">nixie tube</a> clock from my wife, as a Christmas gift.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
My computers aren't just <a href="http://www.codinghorror.com/blog/archives/000440.html">giant calculators</a>, they're also clocks. Unfortunately, my nixie clock is a much more reliable timekeeper than any of my PCs are.
</p>
<p>
There's a clever PC time drift graph on <a href="http://vancouver-webpages.com/time/">this webpage</a> derived from the difference between JavaScript time on the client, and the server time the webpage was sent to the client. It's not super accurate, because the resolution is only 1 second, and the time required to send the page to the client is a variable. But it's plenty good enough to illustrate my point:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>PCs aren't very accurate timekeepers.</b> The distribution of times reported here is a little disturbing, as are the giant peaks on the extreme left and right of the graph. The PCs with wildly inaccurate clocks outnumber those with accurate clocks about 2:1.
</p>
<p>
</p>
<table width="450">
<td>PCs with correct time (+/-5 sec)</td>
<td>~3000
</td>
<tr>
<td>PCs whose internal clocks are more than 8 minutes off</td>
<td>~7000
</td>
</tr>
</table>
<p>
You certainly won't mistake PCs for <a href="http://en.wikipedia.org/wiki/Atomic_clock">atomic clocks</a> any time soon. I've noticed that my Media Center PC in the living room is losing a lot of time. It's frequently a minute or more off, even with internet time synchronization turned on in the Windows control panel.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Right now it's fairly accurate, but Windows just performed its internet time sync. Normally you may not care if your PC's clock is off by 5 seconds or even a few minutes. But clock accuracy is important for a PC designed to record television shows that start and stop at specific times.
</p>
<p>
One way to "fix" a skewed PC clock, at least one that's connected to the internet, is to have it synchronize often with a reliable internet time source. Unfortunately, there's no visible UI in Vista or XP to change the synchronization schedule. MSKB article <a href="http://support.microsoft.com/kb/223184">Q223184</a> appears to have a frequency setting, but this only applies to computers on a domain. On a domain, clients time sync with the domain controller-- a dedicated server. Of course, servers are still PCs, so their clocks aren't any more accurate than the one inside your desktop. <b>However, servers tend to be synchronized much more aggressively with authoritative time sources.</b> Compare this graph of <a href="http://vancouver-webpages.com/time/web.html">observed webserver times</a> to the one I presented earlier:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
My computer isn't on a domain. Browsing around the registry keys, I found a <code>SpecialPollInterval</code> setting under the <code>W32TimeTimeProvidersNtpClient</code> key which looked promising. I did a web search and found this <a href="http://www.worldtimeserver.com/atomic-clock/">worldtimeserver.com page</a> which confirms my finding. I changed the setting, stopped and started the w32time service, and it worked. The <a href="http://ntp.isc.org/bin/view/Servers/WebHome">same page</a> also describes how to add more <a href="http://en.wikipedia.org/wiki/Network_Time_Protocol">NTP time server sources</a> through the registry or at the command line. So my clock drift problem is solved, for the moment.
</p>
<p>
But this fix only addresses the symptom, not the problem itself. <b>Why are PC clocks so inaccurate?</b> Part of it is by design. An extremely accurate <a href="http://en.wikipedia.org/wiki/Real-time_clock">real-time clock</a> isn't necessary for your PC to function, and adding one would probably add cost that OEMs like Dell, HP, and Apple don't want to bear. Most manufacturers opt for <a href="http://www.greyware.com/software/domaintime/technical/accuracy/pcclocks.asp">the "good enough" solution</a>:
</p>
<p>
</p>
<blockquote>
The real-time clock (RTC) built into most machines is far from reliable. Unless its battery dies or it encounters a Y2K problem, it does a fairly good job of remembering the time while the computer's power is turned off -- as long as you don't leave the computer off more than several hours, and don't care if the clock is wrong by a minute or two...or three...or more. The resolution of most PC real-time clocks is one full second, and most RTCs drift considerably over time. It is not unusual for an RTC to gain or lose several seconds or even minutes a day, and some of them -- while still considered to be operating correctly by the manufacturer-- can be off by an hour or more after a week or two without correction.
</blockquote>
<p>
To be fair to the manufacturers, the real-time clock inside your PC is good enough for most purposes. One research study (<a href="http://ej.iop.org/links/r5RfV_EGg/vIoTC6Sb2xGXM6HLav5vpA/ej24l3.pdf">pdf</a>) corroborated this conclusion:
</p>
<p>
</p>
<blockquote>
A typical accuracy of 35ms with respect to the UTC scale is attainable from almost any PC connected to the internet. This performance can be considered adequate for the vast majority of real-time data acquisitions, even in professional applications.
</blockquote>
<p>
PC clocks should typically be accurate to within a few seconds per day. If you're experiencing massive clock drift-- on the order of minutes per day-- <b>the first thing to check is your source of AC power.</b> I've personally observed systems with a UPS plugged into another UPS (this is a no-no, by the way) that gained minutes per day. Removing the unnecessary UPS from the chain fixed the time problem. I am no hardware engineer, but I'm guessing that some timing signal in the power is used by the real-time clock chip on the motherboard.
</p>
<p>
<b>There is an entire class of software problems, bugs, and exploits involving the system clock.</b> Whether it's set to the wrong time, or it's drifting too quickly or slowly, the results can be unexpected or possibly painful. Here are a few I can think of offhand:
</p>
<p>
</p>
<ul>
<li>You can't sync your clock with a NTP source if the clock is already too far out of date. How ironic.
</li>
<li>Some versions of Windows will fail during the setup phase with a cryptic error if the clock is set to a very old date.
</li>
<li>Kernel hacks can speed up or slow down the clock to facilitate cheating in online games, as related in <a href="http://www.playnoevil.com/serendipity/index.php?/archives/1000-AhnLab-gets-anti-cheating-patent-for-speed-hack-detector.html">this article</a>. I remember this exact hack happening in the original Counter-Strike; there was suddenly a player on the map running around at breakneck speeds, gunning everyone down before they could respond.
</li>
<li>Some encryption techniques and login mechanisms (Kerberos) will fail if the system clock is too far out of sync.
</li>
<li>A recent Vista activation hack involved setting your system's date back in the BIOS prior to install.
</li>
<li>It's theoretically possible to attack servers by <a href="http://www.lightbluetouchpaper.org/2006/09/04/hot-or-not-revealing-hidden-services-by-their-clock-skew/">measuring their clock skew</a>. I'm extremely skeptical of this particular attack, but <a href="http://www.theinternetpatrol.com/track-any-computer-on-the-internet-using-its-clock-skew-fingerprint">clock skew is an interesting fingerprint</a>.
</li>
</ul>
<p>
I haven't even touched on the tricky issue of synchronizing events between PCs, each of which will have their own idea of what time it is, and how fast time is advancing. This can lead to some problems, as noted in the NIST document <a href="http://tf.nist.gov/service/pdf/win2000xp.pdf">Configuring Windows 2000 and Windows XP to use NIST TIme Servers</a> (pdf):
</p>
<p>
</p>
<blockquote>
The time clock in the computer is used to keep track of when documents (files) are created and last changed, when electronic mail messages are sent and received, and when other time-sensitive events and transactions happen. In order to accurately compare files, messages, and other records residing on different computers, their time clocks must be set from a common standard. It is particularly important that computers that are networked together use a common standard of time.
</blockquote>
<p>
We tend to think of time as an absolute, a universal interval that is the same everywhere. But inside the PC, time is a malleable material. We can go forward into the future, back into the past, or even change the rate of time's passage. This is something that's easy to forget when you're developing software, and it can definitely come back and bite you.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/keeping-time-on-the-pc/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ If Loving Computers is Wrong, I Don't Want to Be Right ]]></title>
<link>https://blog.codinghorror.com/if-loving-computers-is-wrong-i-dont-want-to-be-right/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I happened upon Russ Walter's <a href="http://www.secretfun.com/">Secret Guide to Computers</a> around 1993. By then it was already up to the 18th edition.
</p>
<p>
<a href="http://www.secretfun.com/"><img alt="image placeholder" >
</p>
<p>
The first version of The Secret Guide was published in 1972 as a self-typed 17 page pamphlet. The latest edition is a hulking 607-page monster, <b>a rambling, zine-like love letter to the computer, in all its manifestations and permutations.</b>
</p>
<p>
Russ alternately compares computers with <b>drugs</b>:
</p>
<p>
</p>
<blockquote>
Computers are like drugs: you begin by spending just a little on them but soon get so excited by the experience  --  and so hooked  --  that you wind up spending more and more to feed your habit.
<p>
Your first computer experience seems innocent: you spend just a little money for a cute little computer. You turn the computer on, tell it to play a game, and suddenly the computer's screen shows dazzling superhuman colors that swirl hypnotically before you. You say "Wow, look at all those colors!" and feel a supernatural high.
</p>
<p>
But after two months of freaking out with your new computer, the high wears off and you wonder, "What can I buy that's new, exciting, and gives me an even bigger high?" So you buy more stuff to attach to your computer. Now you're in really deep, financially and spiritually. You're hooked. You've become addicted to computers. Each month you return to your favorite computer store to search for an even bigger high  --  and spend more money.
</p>
<p>
Look at me. I'm a typical computer junkie. I've already bought 50 computers, and I'm still going. Somebody help me! My computers have taken over my home. Whenever I try to go to sleep, I see those computers staring at me, their lights winking, tempting me to spend a few more hours in naughty fun, even if the sun's already beginning to rise.
</p>
</blockquote>
<p>
.. and <b>sex</b>:
</p>
<p>
</p>
<blockquote>
The computer will fascinate you. It'll seduce you to spend more time with it. You'll fall in love with it. You'll start buying it presents:  exotic foods (expensive programs to munch on), new clothes (a pretty little cloth cover to keep dust off), and expensive jewels (a printer and extra disks).
<p>
Then the computer will demand you give it more. While you enjoy an exciting orgy with your computer and think it's the most joyous thing that ever happened to you, suddenly the computer will demand you buy it more memory. It'll refuse to continue the orgy until you agree to its demand. And you'll agree  --  eagerly!
</p>
<p>
The computer's a demanding lover. You'll feel married to it.
</p>
<p>
Marrying a computer is much groovier than marrying a person: computers are good at "getting it on" (they make you feel all electric and tingly) and they never argue (they're always ready to "do it", except when they "have a headache").
</p>
<p>
I wanted to call this book "The <i>Sexual</i> Guide to Computers" and put a photo of my computer wife and me on the cover; but some communities still prohibit mixed marriages. That cover would be banned in Boston, which is where I've lived. So I had to play cool and say "Secret" Guide to Computers. But here's the real secret: this book's about sex.
</p>
<p>
If you marry a computer but already married a human, your human spouse will call you a "bigamist" and feel jealous of the computer. Your marriage to that human can deteriorate and end in divorce.
</p>
</blockquote>
<p>
Although it's primarily targeted at novices, I distinctly remember one long winter weekend in 1993 reading the entire Secret Guide cover to cover. Walter's enthusiasm rings through on every page. His no-nonsense, no-budget D.I.Y. ethos outshines any number of polished, soulless commercial books.
</p>
<p>
Russ is an <a href="http://www.bookofjoe.com/2005/03/russ_walter_is_.html">interesting guy</a>; there's a tiny biography of him in the "about the author" section of <a href="http://www.gtpcc.org/gtpcc/secretguide.htm">this book review</a>. He also has the audacity to publish his phone number in the book, and <i>encourage</i> people to call him, any time, 24 hours a day, with only a few strings attached. His book is completely self-published under a "copywrong" license. And evidently he means it: he offers a CD-ROM version with the unabridged text of the book in various formats, and semi-authorized versions of the text are available all over the web. One of them even has a higher pagerank than <a href="http://www.secretfun.com/">his own site</a>, which is unfortunate.
</p>
<p>
For more enthusiasm that borders on insanity, Russ offers samples of his books online. You can read <a href="http://www.angelfire.com/nh/secret/29.html">24 chapters of the latest edition of the Secret Guide</a>, as well as <a href="http://www.angelfire.com/nh/secret/1.html">24 chapters of the companion book, Tricky Living</a>. I long ago gave away my copy of The Secret Guide, but Russ is exactly the kind of guy I love to support, so I'll be buying new copies.
</p>
<p>
I also own <a href="http://www.amazon.com/exec/obidos/ASIN/0735611319/codihorr-20">Charles Petzold's book, Code</a>. It's another love letter to the computer.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0735611319/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Instead of a long, rambling love letter, Code is a collection of elegantly written sonnets. It has an austere layout, filled with beautiful diagrams. It gently guides you through the history of the computer, at the lowest and most fundamental levels, from Babbage to modern times. But it's no less urgent in its affections.
</p>
<p>
Code is at the absolute opposite end of the spectrum from The Secret Guide. There probably aren't two more different books on the planet. But if you think Charles Petzold's any less dedicated than Russ Walter, consider this: <a href="http://www.codinghorror.com/blog/archives/000427.html">which one has a Windows tattoo?</a> And which one <a href="http://aplawrence.com/Words2005/2005_06_01.html">wears a witch's hat and red kimono over a monk's habit and roller skates to computer fairs?</a> Well, <b>sometimes love makes you do crazy things.</b>
</p>
<p>
I'm with Petzold and Walter. If loving computers is wrong, I don't want to be right.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/if-loving-computers-is-wrong-i-dont-want-to-be-right/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Sugar UI ]]></title>
<link>https://blog.codinghorror.com/the-sugar-ui/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've largely been ignoring Nicholas Negroponte's <a href="http://wiki.laptop.org/go/Main_Page">One Laptop Per Child</a> initiative. I appreciate the nobility of the gesture, but how interesting can sub-$100 hardware running Linux really <i>be</i>? Well, that was before I read about <a href="http://www.cnn.com/2007/TECH/01/02/hundred.dollarlaptop.ap/index.html">the novel user interface</a> they're building into those small green and white laptops.
</p>
<p>
</p>
<blockquote>
For most of these children the XO machine, as it's called, likely will be the first computer they've ever used. Because the students have no expectations for what PCs should be like, the laptop's creators started from scratch in designing a user interface they figured would be intuitive for children.
<p>
<b>The result is as unusual as -- but possibly even riskier than -- other much-debated aspects of the machine, such as its economics and distinctive hand-pulled mechanism for charging its battery.</b> (XO has been known as the $100 laptop because of the ultra-low cost its creators eventually hope to achieve through mass production.)
</p>
<p>
For example, students who turn on the small green-and-white computers will be greeted by a basic home screen with a stick-figure icon at the center, surrounded by a white ring. The entire desktop has a black frame with more icons.
</p>
<p>
This runic setup signifies the student at the middle. The ring contains programs the student is running, which can be launched by clicking the appropriate icon in the black frame.
</p>
<p>
When the student opts to view the entire "neighborhood" -- the XO's preferred term instead of "desktop" -- other stick figures in different colors might appear on the screen. Those indicate schoolmates who are nearby, as detected by the computers' built-in wireless networking capability.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Moving the PC's cursor over the classmates' icons will pull up their names or photos. With further clicks the students can chat with each other or collaborate on things -- an art project, say, or a music program on the computer, which has built-in speakers.
</p>
</blockquote>
<p>
I'm interested now.
</p>
<p>
I've been disappointed in the lack of GUI innovation over the last decade. Sure, Microsoft and Apple take small jabs at each other every couple of years. And the Linux community apes both companies, occasionally throwing in a curveball of their own. <b>But when was the last time anyone tried a radically different UI on the desktop?</b> The Sugar UI featured in the OLPC appears to finally break from the well worn conventions of Windows and MacOS.
</p>
<p>
I wanted to try it out myself. I downloaded <a href="http://wiki.laptop.org/go/OS_images_for_emulation">the emulated OLPC laptop image</a> and ran it under <a href="http://www.h7.dion.ne.jp/~qemu-win/">QEMU</a>. The documentation even warns you to prepare yourself for this alien UI experience.
</p>
<p>
</p>
<blockquote>
Before you launch the emulated image, we strongly recommend reading through the <a href="http://wiki.laptop.org/go/Sugar_Instructions">Sugar Instructions</a> on how to use the environment -- <b>this does not look like the Windows or Mac operating systems! </b>
</blockquote>
<p>
They weren't kidding. It's nothing like any traditional GUI.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
</p>
<p>
I was inclined to like Sugar almost immediately because it embodies a number of experimental GUI concepts I've talked about before:
</p>
<p>
</p>
<ul>
<li>The frame menu makes perfect use of the <a href="http://www.codinghorror.com/blog/archives/000642.html">infinite width at the edges of the screen</a>.
</li>
<li>It <a href="http://www.codinghorror.com/blog/archives/000461.html">abandons files and folders</a> as an organizing concept.
</li>
<li>The start page, a ring of running tasks around a student, is a type of <a href="http://en.wikipedia.org/wiki/Pie_menu">pie menu</a>, which is a <a href="http://www.codinghorror.com/blog/archives/000521.html">no-frills version of mouse gestures</a>.
</li>
<li>The seamless integration of collaboration and sharing-- with or without the internet-- is very Web 2.0.
</li>
</ul>
<p>
Sugar UI development appears to lag quite a bit behind the challenging, sub-$100 design goal of the OLPC hardware itself. This doesn't surprise me, because <a href="http://www.codinghorror.com/blog/archives/000325.html">developing UI is hard</a>. And developing a radically different UI has to be especially difficult. Innovation and experimentation is much riskier than following the roadmaps from Redmond and Cupertino. That's why, despite the rough edges, I'm excited about Sugar.
</p>
<p>
The <a href="http://wiki.laptop.org/go/Sugar_Instructions">Sugar instructions</a> offer an excellent basic overview of the UI, with many more screenshots. If you're a designer, check out the <a href="http://wiki.laptop.org/go/OLPC_Human_Interface_Guidelines/Design_Fundamentals">Sugar UI design guide</a>. There's also a <a href="http://www.youtube.com/watch?v=DwzCsOFxT-U">video walkthrough of the Sugar UI</a> available.
</p>
<p>
I have to admit that I didn't find the Sugar UI particularly intuitive or discoverable, even after using it for 10 minutes and learning the basics. But I'm not a child. Maybe something unusual is necessary to get kids' creative juices flowing. Mr. Negroponte has <a href="http://www.cnn.com/2007/TECH/01/02/hundred.dollarlaptop.ap/index.html">strong feelings on this topic</a>:
</p>
<p>
</p>
<blockquote>
In fact, one of the saddest but most common conditions in elementary school computer labs (when they exist in the developing world), is the children are being trained to use Word, Excel and PowerPoint.  I consider that criminal, because children should be making things, communicating, exploring, sharing, not running office automation tools.
</blockquote>
<p>
He's got a point. I don't know many kids that want to grow up to be "Information Workers".
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-sugar-ui/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Story About PING ]]></title>
<link>https://blog.codinghorror.com/the-story-about-ping/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Everyone loves <a href="http://en.wikipedia.org/wiki/Ping">ping</a>. It's simple. It's utilitarian. And it does exactly what the sonar inspired name implies. Ping tells you if a remote computer is responding to network requests.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The ping utility was written by Mike Muuss, a senior scientist at the <a href="http://www.arl.army.mil/main/Main/default.htm">U.S. Army Research Laboratory</a>. Mike <a href="http://ftp.arl.army.mil/~mike/ttcp.html">also wrote ttcp</a>, which I'm a big fan of. I've <a href="http://www.codinghorror.com/blog/archives/000339.html">used the PC port of ttcp</a> many times to test network throughput.
</p>
<p>
Mike was <a href="http://www.ping127001.com/pingpage/muuss.htm">tragically killed in an automobile accident</a> 7 years ago, but <a href="http://ftp.arl.mil/~mike/ping.html">his legacy lives on in Ping</a>:
</p>
<blockquote>
In December of 1983 I encountered some odd behavior of the IP network at BRL. Recalling Dr. Mills' comments, I quickly coded up the PING program, which revolved around opening an ICMP style SOCK_RAW AF_INET Berkeley-style socket(). The code compiled just fine, but it didn't work -- there was no kernel support for raw ICMP sockets! Incensed, I coded up the kernel support and had everything working well before sunrise. Not surprisingly, Chuck Kennedy (aka "Kermit") had found and fixed the network hardware before I was able to launch my very first "ping" packet. But I've used it a few times since then. If I'd known then that it would be my most famous accomplishment in life, I might have worked on it another day or two and added some more options.
</blockquote>
<p>
Ping isn't very useful on today's internet because <a href="http://www.ping127001.com/pingpage.htm">most routers and hosts filter it out</a>. But it's still quite useful on local networks; not a month goes by that I'm not pinging something. Ping is always a solid starting point, but sometimes you'll <a href="http://www.codinghorror.com/blog/archives/000527.html">need to perform deeper network diagnostics</a>, too.
</p>
<p>
Of course, we can't talk about ping without mentioning <a href="http://www.amazon.com/gp/discussionboard/discussion.html/ref=cm_rdp_st_rd/103-4897864-1679824?ie=UTF8&amp;ASIN=0140502416&amp;store=yourstore&amp;cdThread=Tx2DLBT9UA4M6D2&amp;reviewID=R2VDKZ4X1F992Q&amp;iid=0140502416&amp;displayType=ReviewDetail">one of the most famous Amazon book reviews of all time</a>.
</p>
<p>
</p>
<blockquote>
<a href="http://www.amazon.com/exec/obidos/ASIN/0140502416/codihorr-20"><img alt="image placeholder" >
PING! The magic duck!
<p>
Using deft allegory, the authors have provided an insightful and intuitive explanation of one of Unix's most venerable networking utilities. Even more stunning is that they were clearly working with a very early beta of the program, as their book first appeared in 1933, years (decades!) before the operating system and network infrastructure were finalized.
</p>
<p>
The book describes networking in terms even a child could understand, choosing to anthropomorphize the underlying packet structure. The ping packet is described as a duck, who, with other packets (more ducks), spends a certain period of time on the host machine (the wise-eyed boat). At the same time each day (I suspect this is scheduled under cron), the little packets (ducks) exit the host (boat) by way of a bridge (a bridge). From the bridge, the packets travel onto the internet (here embodied by the Yangtze River).
</p>
<p>
The title character -- er, packet, is called Ping. Ping meanders around the river before being received by another host (another boat). He spends a brief time on the other boat, but eventually returns to his original host machine (the wise-eyed boat) somewhat the worse for wear.
</p>
<p>
If you need a good, high-level overview of the ping utility, this is the book. I can't recommend it for most managers, as the technical aspects may be too overwhelming and the basic concepts too daunting.
</p>
<p>
As good as it is, The Story About Ping is not without its faults. There is no index, and though the ping(8) man pages cover the command line options well enough, some review of them seems to be in order. Likewise, in a book solely about Ping, I would have expected a more detailed overview of the ICMP packet structure.
</p>
<p>
But even with these problems, The Story About Ping has earned a place on my bookshelf, right between Stevens' Advanced Programming in the Unix Environment, and my dog-eared copy of Dante's seminal work on MS Windows, Inferno. Who can read that passage on the Windows API ("Obscure, profound it was, and nebulous, So that by fixing on its depths my sight -- Nothing whatever I discerned therein."), without shaking their head with deep understanding. But I digress.
</p>
</blockquote>
<p>
It's a timeless geek humor classic. The original was posted in March 1999 by an anonymous reviewer from "Upper Volta, Uzbekistan". It must have been deleted by Amazon, because it was reinstated by another reviewer later in 2000.
</p>
<p>
You may be familiar with the command line version of Ping, and maybe even the book, but did you ever play <a href="http://www.somethingawful.com/index.php?a=2305&amp;p=7">the arcade version of Ping</a>?
</p>
<p>
<a href="http://www.somethingawful.com/index.php?a=2305&amp;p=7"><img alt="image placeholder" >
</p>
<p>
It's milliseconds of fun for the entire family.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-story-about-ping/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Test Doubles: A Taxonomy of Pretend Objects ]]></title>
<link>https://blog.codinghorror.com/test-doubles-a-taxonomy-of-pretend-objects/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.nedbatchelder.com/blog/200701.html#e20070108T073027">Ned</a> recently pointed out Martin Fowler's article <a href="http://martinfowler.com/articles/mocksArentStubs.html">Mocks Aren't Stubs</a>.
</p>
<p>
</p>
<blockquote>
The vocabulary for talking about [pretend objects] soon gets messy - all sorts of words are used: stub, mock, fake, dummy. For this article I'm going to follow the vocabulary of <a href="http://xunitpatterns.com/">Gerard Meszaros's upcoming book</a>. It's not what everyone uses, but I think it's a good vocabulary and since it's my essay I get to pick which words to use. Meszaros uses the term <b>Test Double as the generic term for any kind of pretend object used in place of a real object for testing purposes</b>.
</blockquote>
<p>
Personally, I like to think of them as <i>Stunt Objects</i>. Meszaros, via Fowler, defines the following taxonomy of pretend objects:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Dummy objects</b> are passed around but never actually used. Usually they are just used to fill parameter lists.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Fake objects</b> actually have working implementations, but usually take some shortcut which makes them not suitable for production.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Stub objects</b> provide canned answers to calls made during the test, usually not responding at all to anything outside what's programmed in for the test.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Mock objects</b> are pre-programmed with expectations which form a specification of the calls they are expected to receive.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/test-doubles-a-taxonomy-of-pretend-objects/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Typing Trumps Pointing ]]></title>
<link>https://blog.codinghorror.com/typing-trumps-pointing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Windows Vista gets criticized a lot in the press, mostly for not being OS X. Some of the criticisms are valid. It is terribly late. And the feature list has grown less and less impressive as the development process has worn on over the years.
</p>
<p>
But Vista has one killer feature up its sleeve. A feature that, as far as I'm concerned, makes it a must-have upgrade on day one of availability. <b>Vista's Start Menu lets you type what you want instead of pointing at it</b>. Here's what happens when I press the Windows key, then type "studio".
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
</p>
<p>
As I type, Vista's start menu displays real time, full-text search matches across <a href="http://www.istartedsomething.com/20061211/vista-start-menu-search/">multiple locations</a>: the start menu, my user folder, my favorites and browser history, my email history, and so on.
</p>
<p>
I had ways of doing this in Windows XP, but <b>with Vista, typing to navigate is now quite literally the cornerstone of the operating system.</b> I've gone from tedious, manually defined hotkeys and shortcuts in Windows XP to simply <i>typing what I want and letting the computer find it for me</i>. It also utterly obsoletes the <b>Start, Run</b> (or Windows+R) menu because it works for file paths, too:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Best of all, <b>I never have to take my hand off the keyboard.</b> The first match is always selected; I can press Enter to launch it immediately. Alternately, I could use the up and down arrows to highlight the item I want, and press Enter to launch that. Or I could continue typing to further refine my match in real time.
</p>
<p>
The <a href="http://www.codinghorror.com/blog/archives/000273.html">start menu has been a usability trainwreck since its introduction in 1995</a>. I had no idea Microsoft would so completely and thoroughly reinvent the Start Menu in Vista. It has completely changed the way I work with my computer. And it's standard out of the box. There's nothing to install, nothing to configure, <i>nothing to think about</i>. It just works. Like so:
</p>
<p>
</p>
<ul>
<li>To launch <b>Notepad</b><br>
Windows key, type "not", then Enter.
</li>
<li>To set my <b>Mouse options</b><br>
Windows key, type "mou", then Enter.
</li>
<li>To launch <b>Word</b><br>
Windows key, type "word", down arrow, then Enter. (unfortunately, WordPad is still the first match).
</li>
<li>To navigate to my <b>WinAmp folder</b><br>
Windows key, type "c:p", down arrow, type "w", down arrow, Enter.
</li>
<li>To set the <b>date and time</b><br>
Windows key, type "dat", then Enter.
</li>
<li>To play <b>Rainbow 6: Vegas</b><br>
Windows key, type "veg", then Enter.
</li>
<li>To visit <b>codinghorror.com</b><br>
Windows key, type "cod", then Enter.
</li>
</ul>
<p>
This new all-in-one keyboard style of navigation is unbelievably, amazingly efficient. It is by far the single best new feature of Vista in my book. I cannot, I <i>will not</i>, go back to Windows XP, with its <a href="http://www.codinghorror.com/blog/archives/000273.html">horrific mouse-centric cascading start menu</a>, and the utilitarian but unhelpful Windows+R Start Run dialog.
</p>
<p>
Ironically, Microsoft's revamped Start Menu may be the final sign that we've fully entered the Google era of computing. As Bill de hra <a href="http://www.codinghorror.com/blog/archives/000595.html">noted</a>:
</p>
<p>
</p>
<blockquote>Perhaps the hunt and peck approach of searching is becoming the dominant computing metaphor, replacing nearly 3 decades of user interfaces based on the metaphor of an office desktop.
</blockquote>
<p>
No more hunting for the right bunch of pixels to click; it's faster and easier to <i>type to get to what you want</i> instead. It's a tacit acknowledgement that Google was right all along. It's not quite a <a href="http://www.lifehacker.com/software/command-line/geek-to-live--the-command-line-comeback-226223.php">command line renaissance</a>, but it is an implied victory of textual search over traditional point-and-click desktop GUI metaphors. <b>Typing trumps pointing.</b> There's far too much content in the world-- and even on your local computer-- for browsing and pointing to work reliably as a navigation scheme today. Keyboard, text and search are the new bedrock navigation schemes for the 21st century.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/typing-trumps-pointing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Power of Defaults ]]></title>
<link>https://blog.codinghorror.com/the-power-of-defaults/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/000766.html">Typing Trumps Pointing</a>, I extolled the virtues of the full-text search included in Vista's new Start Menu. As many commenters pointed out, the feature itself is nothing new:
</p>
<p>
</p>
<blockquote>
I love keyboard searching, but basically you say you are installing Vista, an entire operating system, just so you don't have to install <a href="http://colibri.leetspeak.org/">Colibri</a>, <a href="http://www.bayden.com/SlickRun/">SlickRun</a>, <a href="http://www.launchy.net/">Launchy</a>, or one of the <a href="http://www.hanselman.com/blog/ReplacingStartRunTheQuestContinues.aspx">many other similar and fully functional tools</a> that give similar results for 10% cost and 1% hassle.
</blockquote>
<p>
It's true. There are dozens of third-party solutions that deliver very similar interactive full-text search UI experiences. But there's one key difference between those solutions and the one in Vista: <b>I have to install them</b>. You may argue that, in the near term, I also have to install Vista. Fair enough. But over the next five years, <i>millions</i> of users will buy computers with Vista pre-installed. And they'll immediately benefit from the built-in, default full-text search UI that's accessible right out of the box with a single press of the Windows key.
</p>
<p>
There's nothing to install. There's nothing to configure. <i>It just works</i>.
</p>
<p>
That's the power of defaults.
</p>
<p>
<b>Defaults are arguably the most important design decisions you'll ever make as a software developer.</b> Choose good defaults, and users will sing the praises of your software and how easy it is to use. Choose poor defaults, and you'll face down user angst over configuration, and probably a host of tech support calls as well.
</p>
<p>
Furthermore, once a default becomes a well-accepted standard, it's an expectation. Other vendors will be peer pressured into at least matching that default. And to truly succeed, they'll have to come up with an even <i>better</i> default. <b>Defaults are how the software industry evolves.</b> It also highlights a problem with the Linux and Unix models; because they're infinitely configurable, it's impossible to tell what you're comparing the next version of the software with. There's no baseline, no standard, only <a href="http://www.codinghorror.com/blog/archives/000382.html">the giant cop-out of endless user configuration</a>.
</p>
<p>
Defaults aren't just important to software developers; they're incredibly important to UI designers, too.  Jakob Nielsen <a href="http://www.useit.com/alertbox/defaults.html%0A">elaborates</a>:
</p>
<p>
</p>
<blockquote>
Users rely on defaults in many other areas of user interface design. For example, they rarely utilize fancy <a href="http://www.useit.com/alertbox/981004.html">customization features</a>, making it important to optimize the default user experience, since that's what most users stick to.
<p>
In forms and applications, pre-populate fields with the most common value if you can determine it in advance. For example, on the registration form for my usability conference, if people register for an event in Boston, the country field will say "United States" by default, but if they register for London, it will say "United Kingdom." Obviously, many people come from other countries, and they'll have to change this entry to specify their own country -- but they'd have to specify it anyway if we'd left it blank. By choosing the most common country as the default, we save many users that bit of work.
</p>
<p>
Defaults make two essential contributions to usability:
</p>
<p>
</p>
<ul>
<li>By showing a representative value, they serve as just-in-time instructions to help users understand how to complete a field.
</li>
<li>By showing a frequent value, they help users understand the commonly expected response, as opposed to more atypical ones. You can use this knowledge for sales purposes -- for example, by pre-selecting the one-year option in a subscription interface that also offers monthly payments. But, if you consistently pick the most expensive option as the default, you'll lose credibility, so don't overdo it.
</li>
</ul>
<p>
By educating and guiding users, default values help reduce errors. It's therefore important to select helpful defaults, rather than those based on the first letter of the alphabet or whatever the first option on your original list happened to be.
</p>
</blockquote>
<p>
Defaults can also affect your company's bottom line. That's why Google, Microsoft, and Yahoo are willing to pay <a href="http://news.com.com/2100-1032_3-6077051.html">millions of dollars</a> to influence the defaults on a user's desktop.
</p>
<p>
For most users, <b>the default value is the only value</b>. Your choice of default values will have a profound impact on how your application is used. You should agonize over every default in your software. If you aren't, you're doing the user, and yourself, a disservice.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-power-of-defaults/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ If It's Not in Google, Does Your Website Really Exist? ]]></title>
<link>https://blog.codinghorror.com/if-its-not-in-google-does-your-website-really-exist/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Rich Skrenta, who <a href="http://www.skrenta.com/cloner/">may have written the first microcomputer virus</a>, calls Google the <a href="http://www.skrenta.com/2007/01/winnertakeall_google_and_the_t.html">start page for the Internet</a>:</p>
<blockquote>
<p>The net isn't a directed graph. It's not a tree. It's a single point labeled G connected to 10 billion destination pages.</p>
<p>If the Internet were a monolithic product, say the work of some alternate-future AT&amp;T that hadn't been broken up, then you'd turn it on and it would have a start page. From there you'd be able to reach all of the destination services, however many there were.</p>
<p>Well, that's how the net has organized itself after all.</p>
<p>From this position, Google derives immense and amazing power. And they make money, but not only for themselves. Google makes advertisers money. Google makes publishers money. Google drives multi-billion dollar industries profiting from Google SEM/SEO.</p>
<p><b>Most businesses on the net get 70% of their traffic from Google.</b> These business are not competitors with Google, they are its partners, and have an interest in driving Google's success. Google has made partners of us all.</p>
</blockquote>
<p>But what happens when the start page for the internet-- the source of <a href="http://www.skrenta.com/2006/12/googles_true_search_market_sha.html">more than 70 percent of your traffic</a>-- decides <i>it will no longer index your web site?</i></p>
<img alt="image placeholder" >
<p>That's <a href="http://www.javalobby.org/java/forums/t87997.html">exactly what happened to JavaLobby</a> over the christmas break:</p>
<blockquote>
<p>It had been aggravating to spend holiday time cleaning up the unwanted [50,000 spam forum messages], but the real problem didn't surface until we started going through our normal morning routine yesterday, having just returned to work from our holiday break. We generally take a look at a variety of statistics in the morning before proceeding into whatever development work we're doing. Having been out of the office for almost two weeks, we had a lot of stats to look at. It took no time to see that something was wrong - traffic was down. A little more investigation revealed the problem.</p>
<p>We had completely disappeared from Google's main index! If you run a website, then you know how serious a problem this is. <b>On any given day over 10,000 visitors arrive at Javalobby as a result of Google searches, and suddenly they stopped coming!</b> We had apparently been grouped together with the spammer's viagra and casino sites, and poof! Suddenly we no longer existed in the eyes of Google, the world's largest search engine. Countless thousands of well-ranked pages gone in a blink. Perhaps you now understand why I would commit a violent crime if I caught those forum spammers? In essence, they have wiped out strategic positioning that we took years to build.</p>
</blockquote>
<p>Google's response in this situation is arguably justified. They can't have query results redirecting users to sex sites; the public good requires that rogue or defaced websites get removed from their index as soon as they're discovered. Google's Matt Cutts, in response to <a href="http://slashdot.org/articles/06/12/03/2049202.shtml">a similar Google delisting incident</a> posted on Slashdot, wrote <a href="http://www.mattcutts.com/blog/how-google-handles-hacked-sites/">an entire blog post documenting exactly how Google handles hacked websites</a>:</p>
<blockquote>
<p>But let's take a step back. This site was hacked and stuffed with a bunch of hidden spammy porn words and links. Google detected the spam in less than 10 days; that's faster than the site owner noticed it. We temporarily removed the site from our index so that users wouldn't get the spammy porn back in response to queries. We made it possible for the webmaster to verify that their site was penalized. Then we emailed the site, with the exact page and the exact text that was causing problems. We provided a link to the correct place for the site owner to request reinclusion. We also made the penalty for a relatively short time (60 days), so that if the webmaster fixed the issue but didn't contact Google, they would still be fine after a few weeks.</p>
<p>Ultimately, each site owner is responsible for making sure that their site isn't spammy. If you pick a bad search engine optimizer (SEO) and they make a ton of spammy doorway pages on your domain, Google still needs to take action. Hacked sites are no different: lots of spammy/hacked sites will try to install malware on users' computers. If your site is hacked and turns spammy, Google may need to remove your site, but we will also try to alert you via <a href="http://www.google.com/webmasters/">our webmaster console</a> and even by emailing you to let you know what happened. To the best of my knowledge, no other search engine confirms any penalties to sites, nor do they email site owners.</p>
</blockquote>
<p>I had completely forgotten about Google's <a href="http://www.google.com/webmasters/">Webmaster console</a> until Matt mentioned it. If you own a website, you should take advantage of these tools. They'll let you diagnose and fix most Google-related problems. On top of that, they'll even give you some basic stats on the search queries people used to get to your website. All you have to do is prove ownership of your website by either uploading a specially-named file, or modifying a page to include a specific META tag.</p>
<p>But let's put aside, for a moment, the fact that the webmaster response to Google's delisting was a little hysterical in the face of Google's excellent webmaster tools. Can you blame them? You'd probably be upset, too, if <b>more than 70 percent of the website to your traffic disappeared overnight</b>.</p>
<p>That's the truly scary part. Google's lead over its competitors is so complete, so total, that <b>if your website isn't in Google, it effectively <i>doesn't exist</i></b>. I'm not sure the Microsoft monopoly has ever wielded that kind of power. And even if they did, it would by definition be limited to desktops. Google has shown few signs of abusing their position so far. But I'm not sure I'm comfortable with a single company having such near-absolute power over the sum of all information on the internet, either.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/if-its-not-in-google-does-your-website-really-exist/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Problem With C++ ]]></title>
<link>https://blog.codinghorror.com/the-problem-with-c/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
MIT's Technology Review recently interviewed <a href="http://en.wikipedia.org/wiki/Bjarne_Stroustrup">Bjarne Stroustrup</a> in a two-part article (<a href="http://www.technologyreview.com/InfoTech/17831/">part one</a>, <a href="http://www.technologyreview.com/Infotech/17868/">part two</a>). You may know Bjarne as the inventor of the <a href="http://en.wikipedia.org/wiki/C++">C++ programming language</a>. Indeed, he even maintains a <a href="http://www.research.att.com/~bs/bs_faq.html">comprehensive C++ FAQ</a> that answers every imaginable C++ question.
</p>
<p>
Here are a few select quotes from the interview that I found notable:
</p>
<p>
</p>
<blockquote>
C++ has indeed become too "expert friendly" at a time where the degree of effective formal education of the average software developer has declined. However, the solution is not to dumb down the programming languages but to use a variety of programming languages and educate more experts. There has to be languages for those experts to use-- and C++ is one of those languages.
<p>
What I did do was to design C++ as first of all a systems programming language: I wanted to be able to write device drivers, embedded systems, and other code that needed to use hardware directly. Next, I wanted C++ to be a good language for designing tools. That required flexibility and performance, but also the ability to express elegant interfaces. My view was that to do higher-level stuff, to build complete applications, you first needed to buy, build, or borrow libraries providing appropriate abstractions. Often, when people have trouble with C++, the real problem is that they don't have appropriate libraries--or that they can't find the libraries that are available.
</p>
<p>
Other languages have tried to more directly support high-level applications. That works, but often that support comes at the cost of specialization. Personally, I wouldn't design a tool that could do only what I wanted--I aim for generality.
</p>
<p>
I think [making computer languages easier for average people] would be misguided. The idea of programming as a semiskilled task, practiced by people with a few months' training, is dangerous. We wouldn't tolerate plumbers or accountants that poorly educated. We don't have as an aim that architecture (of buildings) and engineering (of bridges and trains) should become more accessible to people with progressively less training. Indeed, one serious problem is that currently, too <i>many</i> software developers are undereducated and undertrained.
</p>
</blockquote>
<p>
In the <a href="http://www.research.att.com/~bs/bs_faq.html">FAQ</a> and the <a href="http://www.technologyreview.com/InfoTech/17831/">interview</a>, <b>Bjarne comes off as a little defensive about C++</b> and its role in <a href="http://www.codinghorror.com/blog/archives/000686.html">the history of computer languages</a>. Maybe that's because the importance of C++ has diminished over time, principally for two reasons:
</p>
<p>
</p>
<ol>
<li>
<b>C++ is fast but unforgiving.</b> It was an appropriate solution for an era of limited computing resources. But we've long since left that behind; we live in an <a href="http://longtail.typepad.com/the_long_tail/2005/03/the_tragically_.html">era of abundance</a>. We have more computer power than we possibly know what to do with on the desktop. Even the naive solutions for most computing problems are "fast enough" these days.  Computers get faster every day, but programmers' brains, sadly, do not. It'd be a waste not to trade some of that abundant raw power to make things easier on us. It's time to evolve up <a href="http://www.codinghorror.com/blog/archives/000224.html">the one trillion dollar programming pyramid</a>.
<p>
</p>
</li>
<li>
<b>C++ is designed for any possible programming task, from the lowest level to the highest.</b> It makes sense to use C++ to write operating system kernels and device drivers. But when was the last time you used C++ to write a line of business app or website? C++ is perhaps the ultimate generalist language. Because it can do all these things, it's complicated and <a href="http://en.wikipedia.org/wiki/Buffer_overflow">dangerous</a>. Other languages don't try to span the entire range of low-level to high-level programming tasks; they simplify to attack a specific high-level problem domain.
</li>
</ol>
<p>
C++ is a key historic milestone in the evolution of computer languages. There will always be a place in a programmer's toolbox for C++,  but I'd argue that it's an increasingly a niche language for a very specific subset of programming tasks. The most important question to ask about any language these days isn't how fast it is, or how general it is, but <b>how well does it protect you from yourself?</b> Stroustrup <a href="http://www.research.att.com/~bs/bs_faq.html#really-say-that">has a great quote that says it all</a>:
</p>
<p>
</p>
<blockquote>
C makes it easy to shoot yourself in the foot; C++ makes it harder, but when you do it blows your whole leg off.
</blockquote>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-problem-with-c/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Five Things You Didn't Know About Me (and my office) ]]></title>
<link>https://blog.codinghorror.com/five-things-you-didnt-know-about-me-and-my-office/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've been reluctant to respond to the <a href="http://www.google.com/search?q=five+things+you+didn%27t+know+about+me">Five Things You Didn't Know About Me</a> meme. I generally take <a href="http://headrush.typepad.com/creating_passionate_users/2006/10/better_beginnin.html">Kathy Sierra's advice</a> when it comes to describing my background:
</p>
<p>
</p>
<blockquote>
How many talks do you see where the speaker has multiple bullet points and slides just on their background? I did it once because I thought it would help people understand the context of my talk, and it did NOT go over well because:
<p>
A) Nobody cares.<br>
B) Bullet points do not equal credibility.<br>
C) Nobody cares.<br>
D) You already HAVE credibility going in... you don't have to earn it, you just have to make sure you don't lose it.<br>
E) Nobody cares.<br>
</p>
</blockquote>
<p>
And then there's <a href="http://www.gapingvoid.com/Moveable_Type/archives/003585.html">Hugh MacLeod's take on the Five Things</a>:
</p>
<p>
</p>
<blockquote>
1. I dislike you intensely.<br>
2. I love it when bad things happen to you.<br>
3. When your name is mentioned I immediately try to change the subject.<br>
4. I wouldn't read your blog if you paid me.<br>
5. If we were trapped on a desert island together I would kill myself.<br>
</blockquote>
<p>
It's funny. But it's not really a response to the question. People have shared so generously with the Five Things post, and they've gone out of their way to express an interest in others by tagging them. It would be rude not to respond in kind with equal generosity. Although it's technically off topic, Five Things has made for strangely compelling reading.
</p>
<p>
I like to think that the important part of my blog is the content, not <i>me</i>. After all, <a href="http://www.codinghorror.com/blog/archives/000536.html">users don't care about me</a>. It's about what <i>you</i>, the reader, get out of this blog. I struggled with this for a while until I realized what I was missing. <b>Blogs, for better or worse, are as much about the writer as they are any other topic.</b> Personality is the essential ingredient that makes blogs so interesting, so compelling, so.. human. To avoid writing about yourself is just as much of a mistake as writing about yourself in every post. So Five Things isn't off topic at all. It's very much <i>on topic</i>. Behind every fascinating blog is a fascinating person.
</p>
<p>
With that in mind, I thought I'd offer a small pictorial tour of my office at <a href="http://www.vertigo.com/">Vertigo Software</a>. It's as much a reflection of my personality as anything else in my life.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's the entrance to my office. As you can see, Vertigo does treat developers in accordance with the <a href="http://www.codinghorror.com/blog/archives/000666.html">Programmer's Bill of Rights</a>. The Aeron chair is standard issue to <a href="http://www.codinghorror.com/blog/archives/000240.html">protect developers' second most important asset</a>.
</p>
<p>
I like to keep new and interesting items on the front table for visitors to play with, and to attract people into my office. Here's what I have out on the front table right now:
</p>
<ul>
<li>Slang Flashcards (set <a href="http://www.knockknock.biz/commerce/Flashcards/Slang-Flashcards.html">one</a> and <a href="http://www.knockknock.biz/commerce/Flashcards/Slang-2-Flashcards.html">two</a>)
</li>
<li>three books about signage: <a href="http://www.amazon.com/1000-Signs-Colors/dp/3822831352/">Taschen's 1000 Signs</a>, <a href="http://www.amazon.com/Warning-Nicole-Recchia/dp/0972563695/">Warning</a>, and <a href="http://www.amazon.com/Design-Impact-Fifty-Airline-Safety/dp/1568983875">Design for Impact: Fifty Years of Airline Safety Cards</a>. I wrote about my <a href="http://www.codinghorror.com/blog/archives/000438.html">fascination with signage</a> in an earlier blog post.
</li>
<li>a squishy bloody brain toy, which is totally disgusting and awesome.
</li>
</ul>
<p>
I also have <a href="http://www.puttyworld.com/illusions.html">iridescent thinking putty</a> out permanently. I love putty. It's my absolute all time favorite desk tcotchke. And it's practical, too. As I noted last year, putty is <a href="http://www.codinghorror.com/blog/archives/000605.html">legitimate exercise for your hand <i>and</i> your brain</a>. I can't recommend it highly enough. I like it so much that I took it upon myself to buy every new Vertigo employee a tin of their very own thinking putty in a unique color.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's a closeup of the back wall. The items on the wall aren't art, but wrapping paper from <a href="http://www.knockknock.biz">Knock Knock</a>, the same company behind the flash cards. I spray-mounted them on foamcore backing for a drop-shadow effect and attached them with 3M's amazing <a href="http://solutions.3m.com/wps/portal/3M/en_US/Command/home/us_en/products/picture_hangers/">Command picture mounting strips</a>. I can't find a link to the wrapping paper on their site any more, so I'm not sure if they still sell it. But each one is a little inside joke:
</p>
<ol>
<li>the colorized DNA sequence on the left is the gene for color blindness.
</li>
<li>the barcode is the actual barcode for the actual wrapping paper itself.
</li>
<li>the fingerprint belongs to the person who designed the wrapping paper.
</li>
</ol>
<p>
Also on the table are some of my other favorite things: a <a href="http://www.colorcube.com/">three-dimensional color cube</a>, a <a href="http://www.tangletoys.com/catalog/popup_image.php/pID/65?osCsid=efd6e030c38f4b249d2dccf12d22154a">"museum size" chrome Tangle</a>, and a cheap, generic digital picture frame that I mounted into a fancy gold leaf frame and matted with black construction paper. Trust me, the original frame was hideously ugly. I usually leave the picture frame running The Office (BBC) episodes 1 and 2 encoded into Xvid on a 512mb SD card. I also have Airplane! and Raising Arizona (among others) encoded in the same format, and I swap them out occasionally. I'm a big movie fan, so it's moving art to me.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's my computer. I built it myself. You can see a glimpse of it in the first picture under my desk; it's a <a href="http://www.codinghorror.com/blog/archives/000218.html">green Asus Vento</a>. As I've mentioned many times before, I use <a href="http://www.codinghorror.com/blog/archives/000740.html">three monitors at home and at work</a>. The Logitech MX518 satisifies <a href="http://www.codinghorror.com/blog/archives/000286.html">my mouse fetish</a>, and the Microsoft Natural Keyboard 4000 is, as far as I'm concerned, <a href="http://www.codinghorror.com/blog/archives/000400.html">the Keyboard of the Gods</a>. It just doesn't get any better than that rich corinthian naugahyde under your palms. The speakers are mostly for show; you can see <a href="http://www.codinghorror.com/blog/archives/000463.html">the Sennheiser Headphones I swear by</a> on the left-hand side.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Directly above my monitors is my pride and joy: <a href="http://blogs.vertigosoftware.com/jatwood/archive/2005/12/20/The_Pong_clock.aspx">my very own Pong clock</a>. I'm <a href="http://www.codinghorror.com/blog/archives/000760.html">fascinated with clocks</a>, so the Pong clock was my holy grail: it mixes art with classic video games, and it's a functional clock, too. I waited six months to get this delightful piece of art, and every day was worth it.  Every minute the right side wins. Every hour the left side wins. Forever.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's a closeup of my bobblehead ninja. <a href="http://www.realultimatepower.net/index4.htm">I can't stop thinking about ninjas</a>. You can also see my small collection of <a href="http://www.kikkerland.com/windups.htm">Kikkerland windups</a> in the background behind the monitors. It's fun to wind these things up and watch them grind around, to temporarily leave the digital world behind and revel in the purely analog.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
To my left and behind me, I have a few other items of interest. On the lower level, from left to right:
</p>
<p>
</p>
<ul>
<li>A Kikkerland wall clock, one of my favorites, but quickly demoted after the Pong Clock arrived.
</li>
<li>Some <a href="http://www.codinghorror.com/blog/archives/000481.html">Visibone cheatsheets</a>. As if you needed any more evidence that I cheat my way to the top.
</li>
<li>A <a href="http://www.wengerna.com/browse/sbt.jsp">Swiss Business Tool</a>, so I am ready for any business situation that might befall me. Businesspeople beware!
</li>
<li>A <a href="http://www.thinkgeek.com/gadgets/tools/772b/">mug boss</a> to organize my archaic writing implements. I also own its big brother, <a href="http://www.amazon.com/Bucket-Boss-01056-Pocket-Organizer/dp/B000022439">the bucket boss</a>, for my tools.
</li>
</ul>
<p>
On the upper level, from left to right:
</p>
<p>
</p>
<ul>
<li>Activision's <a href="http://www.atariage.com/software_page.html?SoftwareLabelID=257">Kaboom for the Atari 2600</a>, along with a letter from Activision including the Kaboom patch for reaching a specific high score. No, I didn't earn this, I bought it on eBay and assembled it into the picture box. I was <i>awful</i> at Kaboom, so this is how I exact my revenge.
</li>
<li>The original Thrustmaster joystick I used to play <a href="http://www.mobygames.com/game/star-wars-x-wing">X-Wing</a> on the first PC I owned in 1993. I blew up the death star with this baby, DOS style.
</li>
<li>An original boxed copy of Microsoft Windows 1.0a: Best. OS. Ever.
</li>
<li>An original boxed copy of <a href="http://en.wikipedia.org/wiki/Microsoft_Bob">Microsoft Bob</a>. I still use this as my shell.
</li>
<li>My <a href="http://www.progressquest.com/">ProgressQuest</a> <a href="http://www.cafepress.com/pqm.13910487">Flagon of Mead</a>, to remind me that <a href="http://www.codinghorror.com/blog/archives/000524.html">time invested does not equal skill</a>.
</li>
<li>My <a href="http://www.peda.com/models/">die-cast mathematical models</a>, because I can't afford the <a href="http://www.bathsheba.com/math/">bathsheba math sculptures</a>.
</li>
</ul>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's a shot directly in front and to the left of my desk. I've always wanted a mobile in my office. This one is from <a href="http://www.flensted-mobiles.com/">flensted</a>. It's always moving, and as far as I'm concerned, it's the next best thing to having a window overlooking the ocean. The art on the wall is cheap stuff from <a href="http://www.ikea.com/">IKEA</a> that caught my eye. My wife and I are huge IKEA fans. When we lived in North Carolina, the closest IKEA was in Baltimore, more than 5 hours away. Going there was a rare pleasure. Here in California, there's an IKEA barely 15 minutes away, so we can go any time we want. Life is sweet.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
On the other wall, I have a standard-issue whiteboard, along with more inexpensive wall art from IKEA. Above the whiteboard is <a href="http://www.codinghorror.com/blog/archives/000238.html">my BetaBrite LED sign</a>. I use <a href="http://www.codeproject.com/vb/net/BetaBriteAPI.asp">the .NET API I wrote for the BetaBrite</a> to route the current weather conditions and top RSS news feeds to it.
</p>
<p>
And that concludes my office tour. But in the spirit of Five Things, I'll go even further. Here are five things you didn't know about me:
</p>
<p>
</p>
<ol>
<li>
<b>I do not own any jeans, or any denim clothing whatsoever.</b> I had enough denim in high school to last the rest of my life. I'm done with that.
<p>
</p>
</li>
<li>
<b>I was arrested for wardialing and phreaking by a small telco in 1987.</b> They even tapped my phones and everything. I used a program I wrote in AmigaBasic to repeatedly dial numbers and guess calling codes.  Luckily I had been away for high school senior beach week during part of the investigation, so I hadn't been running the program as much. Since I had no prior record, with the help of a lawyer, I was able to get the charges dropped. And yes, I stopped doing that. In the dark ages before the internet, all we had were BBS systems and modems. And long distance charges were incredibly expensive back then. To get your BBS fix, you <i>had</i> to find some way around the long distance charges. I'm glad today's kids don't face the same dilemma.
<p>
</p>
</li>
<li>
<b>I am terrible at math.</b> How terrible, you ask? Well, I thought I might head off to business school in 1994 so I took the GREs. This was the first standardized test I actually <i>studied</i> for. Not because I'm so smart, mind you, but because I'm very, very lazy. With the additional effort of studying, I did my best on the tests: I scored in the 99.9th percentile on the verbal part of the GRE, but barely made 77th percentile in math. This has always bugged me, because computers and math are so closely linked. I love computers, but I can't stand math. No matter how hard I apply myself, I'm terrible at it. I could never quite wrap my brain around the concepts. But I'm really good at <i>writing about</i> how much I suck at math, for what that's worth.
<p>
</p>
</li>
<li>
<b>I met my wife on the dance floor during 80's night.</b> There I was, minding my own business, getting my groove on to <a href="http://en.wikipedia.org/wiki/The_Safety_Dance">The Safety Dance</a> at this club in Denver in April 1994. As I'm dancing, I suddenly felt a tap on my shoulder. I turned around and there was this cute girl telling me "you're doing it wrong". As in, <i>I was doing the Safety Dance wrong</i>. I thought it was just a song; who knew it was an actual dance? Live and learn. That may be why, to this day, I still have an obsessive love for 80's music. I probably own 60-70 discs worth of 80's song collections (including remixes), and I listen to it regularly.
<p>
</p>
</li>
<li>
<b>I don't really even like computers.</b> Just kidding. My wife often tells me, half-jokingly, that I love computers more than I love her. Of course that's not true. Love is an awfully strong word. But I do think I'd have sex with my computers if it was physically possible.
</li>
</ol>
<p>
I'm tagging my Vertigo Software coworkers who blog in the hope that they'll share five things about themselves, too: <a href="http://blogs.vertigosoftware.com/ericc/default.aspx">Eric Cherng</a>, <a href="http://blogs.vertigosoftware.com/scott/default.aspx">Scott Stanfield</a>, <a href="http://blogs.vertigosoftware.com/alanl/default.aspx">Alan Le</a>, <a href="http://www.polyweb.com/blog/">Dan Swearingen</a>, and last but most of all least, <a href="http://blogs.vertigosoftware.com/matth/default.aspx">Matt Hempey</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/five-things-you-didnt-know-about-me-and-my-office/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ There Are No Design Leaders in the PC World ]]></title>
<link>https://blog.codinghorror.com/there-are-no-design-leaders-in-the-pc-world/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Robert Cringley's 1995 documentary <a href="http://www.codinghorror.com/blog/archives/000718.html">Triumph of the Nerds: An Irreverent History of the PC Industry</a> features dozens of fascinating interviews with icons of the software industry. It included <a href="http://www.youtube.com/watch?v=WfALGcDNEDw">this brief interview segment with Steve Jobs</a>, where he said the following:
</p>
<p>
</p>
<blockquote>
The only problem with Microsoft is they just have no taste. They have absolutely no taste. And what that means is, I don't mean that in a small way, I mean it in a big way. In the sense that they don't think of original ideas, and they don't bring much culture into their product. And you say, well, why is that important? Well, proportionately spaced fonts come from typesetting, and beautiful books. That's where one gets the idea. If it weren't for the Mac, they would never have that in their products. And so I guess I am saddened, not by Microsoft's success. I have no problem with their success. They've earned their success.. for the most part. I have a problem with the fact that they just really make third rate products.
</blockquote>
<p>
It's not credited on YouTube, but the clip is definitely from <a href="http://www.amazon.com/exec/obidos/ASIN/1162826436/codihorr-20">Triumph of the Nerds</a>. I remember it very distinctly.
</p>
<p>
What's remarkable about this brief interview is how succinctly it sums up Jobs' strategy for Apple <i>today</i>. <b>At Apple, taste and culture are designed into every product from day one.</b> Nothing is released until it looks as good on the outside as it works on the inside.
</p>
<p>
Jobs is dead on with his criticism. But the problem is much deeper than Microsoft; it extends to the entire PC industry. <b>In the PC world, taste and culture are rarely considered, and if they are, it's always as an afterthought.</b> Ship it first, make it look good later. If you <i>ever</i> do.
</p>
<p>
Consider PC hardware. Why are most PCs little more than black/silver/beige boxes? I've <i>killed</i> myself <a href="http://www.codinghorror.com/blog/archives/000218.html">trying to find a PC case</a> that isn't either hideously ugly or just plain boring. A well designed PC case is <a href="http://www.atxcases.com/atx-cases.asp">rare to the point of absurdity</a>. If you want a PC that looks as good as it works, you have to <a href="http://www.codinghorror.com/blog/archives/000348.html">make it yourself</a>. The PC industry is so inept they can't even <i>copy</i> Apple correctly; the <a href="http://www.gamepc.com/labs/view_content.asp?id=llv1000&amp;page=1&amp;cookie%5Ftest=1">Lian-Li V1000</a> is ostensibly a copy of the Apple G5 case, but it looks more like its retarded cousin. And it's the same situation for laptops. Only a handful of the most high-end PC laptops can approximate the thoughtful design work that goes into the most basic, inexpensive laptop Apple sells.
</p>
<p>
The PC software situation is no better. If anything, it's <i>worse</i>. I see vendors writing their own <b>custom user interfaces</b> in a vain, misguided attempt to set their craplets apart from everyone else's.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
At the other extreme, there are applications <b>so concerned with being functional and utilitarian that they forget about design entirely</b>, reverting to the bland grey Windows 95 UI style. They've given up.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But I don't blame the third-party vendors. I can hardly expect them to do any better when design barely makes the top 10 priority list for any player in the PC industry. Microsoft is about the only company that's in a position to set PC design standards, and they're not trying very hard. Who else can lead the way on design? Dell? IBM? Compaq? NVIDIA? Gateway? Please. <b>There are no design leaders in the PC world.</b> There's nobody for these third-party vendors to look to as the gold standard of design. There's only the lukewarm, inconsistent, half-hearted design guidelines that Microsoft sets-- and frequently <a href="http://chris.pirillo.com/2006/07/18/windows-vista-lipstick-on-a-pig/">breaks</a> <a href="http://chris.pirillo.com/2006/09/02/windows-vista-rc1-a-piece-of-sith/">themselves</a>.
</p>
<p>
Steve Jobs has always been clear about the integral role of design in his products, as outlined in this <a href="http://americanhistory.si.edu/collections/comphist/sj1.html">Smithsonian interview</a>, which is also from 1995:
</p>
<p>
</p>
<blockquote>
DM: You used an interesting word in describing what you were doing. You were talking about art not engineering, not science. Tell me about that.
<p>
SJ: I actually think there's actually very little distinction between an artist and a scientist or engineer of the highest caliber. I've never had a distinction in my mind between those two types of people. They've just been to me people who pursue different paths but basically kind of headed to the same goal which is to express something of what they perceive to be the truth around them so that others can benefit by it.
</p>
<p>
DM: And the artistry is in the elegance of the solution, like chess playing or mathematics?
</p>
<p>
SJ: No. I think the artistry is in having an insight into what one sees around them. Generally putting things together in a way no one else has before and finding a way to express that to other people who don't have that insight so they can get some of the advantage of that insight that makes them feel a certain way or allows them to do a certain thing. I think that a lot of the folks on the Macintosh team were capable of doing that and did exactly that. If you study these people a little bit more what you'll find is that in this particular time, in the 70's and the 80's the best people in computers would have normally been poets and writers and musicians. Almost all of them were musicians. Alot of them were poets on the side. They went into computers because it was so compelling. It was fresh and new. It was a new medium of expression for their creative talents. The feelings and the passion that people put into it were completely indistinguishable from a poet or a painter. Many of the people were introspective, inward people who expressed how they felt about other people or the rest of humanity in general into their work, work that other people would use. <b>People put a lot of love into these products, and a lot of expression of their appreciation came to these things.</b> It's hard to explain.
</p>
</blockquote>
<p>
Whatever you may think of Jobs, he's had the same vision for the last twenty years: <b>the design of a product, the art of it, is just as important as the engineering.</b> This is a lesson that the PC industry needs to take to heart. They better start learning some design chops quickly, because they're now directly competing in the same x86 market with Apple. Why choose a beige box and a schizophrenic UI when you could have something that's beautiful and thoughtfully designed for about the same price?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/there-are-no-design-leaders-in-the-pc-world/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Do Certifications Matter? ]]></title>
<link>https://blog.codinghorror.com/do-certifications-matter/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Name any prominent software technology, and you'll find <a href="http://en.wikipedia.org/wiki/Professional_certification#Certification_in_the_computer_industry">a certification program for that technology</a>. For a fee, of course.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's a dizzying, intimidating array of acronyms: <a href="http://www.microsoft.com/learning/mcp/default.mspx">MCSD</a>, <a href="http://www.sun.com/training/certification/java/index.xml">SCJD</a>. <a href="https://www.redhat.com/training/certification/">RHCE</a>, <a href="http://train.apple.com/certification/macosx.html">ACSA</a>. And the company offering the certification is quite often <i>the very same one selling the product.</i> No conflict of interest there.
</p>
<p>
But <b>do these certifications actually work?</b> Are they valid credentials? Do people who have these certifications perform better than those who don't? Imagine yourself as a prospective employer, interviewing a candidate who presents you with this:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
My reaction is always the same. That's nice, but <i>show me what you've worked on</i>.
</p>
<p>
Your credentials <a href="http://www.codinghorror.com/blog/archives/000576.html">should be the sum of the projects you've worked on</a>, and specifically <a href="http://www.codinghorror.com/blog/archives/000300.html">how much you learned from your failures</a>.  Certainly your actual experience, <a href="http://www.codinghorror.com/blog/archives/000104.html">your portfolio</a>, counts for a lot more than whether or not you passed some arbitrary, one-time test.
</p>
<p>
That said, I am of two minds on certification.
</p>
<p>
I've worked with so-called "web" developers who didn't understand how HTTP POST and HTTP GET worked. It's developers like this who make me pine for standard certification. Even if they're borderline incompetent, if they were certified, at the very least they would have a grasp on the basic concepts needed to do their jobs. In theory, anyway. At the junior level, it seems rational to require certification in a particular technology before they're even allowed in the building. It's the same reason most companies won't hire anyone who doesn't have, say, a high school degree, or a college degree.
</p>
<p>
On the other hand, I've worked with senior developers who had plenty of certifications under their belt, and they <i>still</i> had no idea what they were doing.
</p>
<p>
The certification debate has raged for years. This <a href="http://systemsguild.com/GuildSite/TDM/certification.html">1998 letter to the editor from Tom DeMarco</a> illustrates how contentious the topic of certification can be.
</p>
<p>
</p>
<blockquote>
Though the rationale for certification is always societal good, the real objective is different: siezure of power. Certification is not something we implement for the benefit of the society but for the benefit of the certifiers. It is heady stuff be be able to decide which of your fellow human beings should be allowed to work and which should not. Those who hope for a share of that heady stuff are the core of the camp that favors certification.
<p>
The entire discussion is somewhat dishonest. The term "certification," for example, conjures up the image of fresh faced young people lining up to be given their mantles of office while parents in the audience blink back tears of pride and a choir softly hums complex harmonies. But the real issue here is not certification; the real issue is de-certification. Certain people are going to be kicked out of the fold, not because they are not useful to the needs of the market, but because they don't jump through the certifiers' hoops. Lost in the shuffle here - at least in Nancy Mead's view - would be people who do not have degrees. Sorry about that Mr. Gates, in the brave new world, you wouldn't be allowed to write software. You can just sense the frustration of the prospective certifiers that companies like Yahoo are hiring kids right out of high school, kids who don't even know what a Data Division is, for gods sakes! Something must be done about that!
</p>
</blockquote>
<p>
DeMarco goes on to humbly suggest that the market is a perfectly fine selection method all by itself:
</p>
<p>
</p>
<blockquote>
I vote that we let poor old Citicorp and poor old Aetna and poor old Microsoft figure out for themselves who they should hire. I suggest that we have a perfectly fine selection mechanism at work today; it's called the market. Some people get hired as software developers and some people don't. It is a lot more competent than any appointed elite would be and a lot more ethical.
</blockquote>
<p>
Personally, I agree with DeMarco. I don't believe in certifications. The certification alphabet is no substitute for a solid portfolio; <b>you should be spending your time building stuff, not studying for multiple choice tests.</b> But that doesn't mean they're worthless, either. I don't think certifications get in the way, as long as you can demonstrate an impressive body of work along with them.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/do-certifications-matter/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A World of Endless Advertisements ]]></title>
<link>https://blog.codinghorror.com/a-world-of-endless-advertisements/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
While reading <a href="http://www.sdtimes.com/fullcolumn/column-20070115-02.html">Larry O'Brien's latest column</a> in SD Times, I couldn't help noticing that the article text was <b>dwarfed by the advertisements</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I was curious exactly <i>how much</i> of the page was dedicated to advertising. There's a clever technique used in the book <a href="http://www.amazon.com/exec/obidos/ASIN/073571102X/codihorr-20">Homepage Usability: 50 Websites Deconstructed</a> to measure the composition of webpages.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/073571102X/codihorr-20"><img alt="image placeholder" >
</p>
<p>
The fifty corporate homepages used in the book didn't contain much advertising, but I was still amazed <b>how little screen real estate is dedicated to actual content</b>. Let's apply the same technique to the SD Times page. I'll highlight navigation, content, and advertising.
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
<b>A full third of the page is dedicated to advertising</b>. That's more than the content itself!
</p>
<p>
I <a href="http://www.scottmccloud.com/home/essays/2003-09-micros/micros.html">carried a torch for micropayments</a> for years, but it's never going to happen. Ad-supported content appears to be <a href="http://www.shirky.com/writings/paying_attention.html">the only sustainible business model on the internet</a>. Clay Shirky has been saying this for years. Just open a web browser and it's painfully obvious that he was right. The web is awash in advertising.
</p>
<p>
</p>
<blockquote>
This model, which generates income by making content widely available over open networks without charging user fees, is usually called 'ad-supported content', and it is currently very much in disfavor on the Internet. I believe however, that not only can ad-supported content work on the Internet, I believe it can't not work. Its success is guaranteed by the net's very makeup - the net is simply too good at gathering communities of interest, too good at freely distributing content, and too lousy at keeping anything locked inside subscription networks, for it to fail. Like TV, the net is better at getting people to pay attention than anything else.
</blockquote>
<p>
Indeed, <b>ad-supported content is the house that AdWords built</b>. It's difficult to criticize a system that works, a system that allows content creators to at least break even on their hosting costs.
</p>
<p>
We watched the movie <a href="http://www.imdb.com/title/tt0387808/">Idiocracy</a> this weekend. It's a brilliant bit of social satire from <a href="http://en.wikipedia.org/wiki/Mike_Judge">Mike Judge</a>, which (among other things) <b>takes ad-subsidized content to its logical extremes</b>. People wear nothing but clothes plastered with corporate logos. Wallpaper and lampshades are made up of patterns of tiny corporate logos. Every square inch of every imaginable surface is covered with billboards and even more advertisements.
</p>
<p>
<a href="http://www.imdb.com/title/tt0387808/"><img alt="image placeholder" >
</p>
<p>
Watching television in Idiocracy bears an unfortunate resemblance to reading that SD Times article. To be fair, Larry's content is a bit more highbrow than "Ow! My Balls!". But it's still <b>a tiny window of content, surrounded by dozens of flashing, animated advertisements</b>. It's a disturbing vision of the future. It's supposed to be funny, but it's <a href="http://www.codinghorror.com/blog/archives/000166.html">uncomfortably close to the experience of reading today's ad-supported internet content</a>.  Are we creating a world of endless advertising?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-world-of-endless-advertisements/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Identicons for .NET ]]></title>
<link>https://blog.codinghorror.com/identicons-for-net/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Don Park invented <a href="http://www.docuverse.com/blog/donpark/2007/01/18/visual-security-9-block-ip-identification">Identicons</a> last week.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
An Identicon is <strong>a small, anonymized visual glyph that represents your IP address</strong>. Don <a href="http://www.docuverse.com/blog/donpark/2007/01/19/identicon-explained">explains it</a> better than I do:
</p>
<blockquote>
I originally came up with this idea to be used as an easy means of visually distinguishing multiple units of information, anything that can be reduced to bits. It's not just IPs but also people, places, and things.
<p>
IMHO, too much of the web what we read are textual or numeric information which are not easy to distinguish at a glance when they are jumbled up together. So I think adding visual identifiers will make the user experience much more enjoyable.
</p>
<p>
I think identicons have many use cases. One use is embedding them in wiki pages to identify authors. Another is using them in CRM to identify customers. I can go on and on. It's not just about IP addresses but information that tends to move in 'herds'.
</p>
</blockquote>
<p>
It's genius. And the simple algorithm Don came up with produces beautiful, unique results. Just <a href="http://web.archive.org/web/20070206213620/http://www.docuverse.com/blog/donpark/2007/01/18/visual-security-9-block-ip-identification">scroll through the comments on his blog</a> to see Identicons in action. They work amazingly well, even at 16x16. <a href="http://weblogs.asp.net/jgalloway/">Jon Galloway</a> and I were inspired. We rolled up our sleeves and ported <a href="http://www.docuverse.com/blog/donpark/2007/01/19/identicon-updated-and-source-released">Don's Identicon code</a> from Java to .NET 2.0.
</p>
<p>
<strong><a href="http://www.codinghorror.com/blog/files/Identicon-sample-vs-2005-v13.zip">Download the Identicon 1.3 sample for .NET 2.0</a> (13 kb)</strong>
</p>
<p>
Identicons aren't just for show. They're quite practical. <strong>Rather than printing everyone's IP address next to their comment, you can show their anonymized Identicon.</strong> It's more private, it's almost as useful, and it's much more fun. Download the sample and try it yourself.
</p>
<p>
(<span style="color: red;">updated 3/18/2007 V1.3: fix a few minor bugs, improve documentation</span>)
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/identicons-for-net/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Shipping Isn't Enough ]]></title>
<link>https://blog.codinghorror.com/shipping-isnt-enough/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Part of <a href="http://www.removingalldoubt.com/PermaLink.aspx/a32977e2-cb7d-42ea-9d25-5e539423affd">Chuck Jazdzewski's fatherly advice to new programmers</a> is this nugget:
</p>
<p>
</p>
<blockquote>
Programming is fun. It is the joy of discovery. It is the joy of creation. It is the joy of accomplishment. It is the joy of learning. It is fun to see your handiwork displaying on the screen. It is fun to have your co-workers marvel at your code. It is fun to have people use your work. It is fun have your product lauded in public, used by neighbors, and discussed in the press. Programming should be fun and if it isn't, figure out what is making it not fun and fix it. However, shipping isn't fun. I often have said that shipping a product feels good, like when someone stops hitting you. Your job is completing the product, fixing the bugs, and shipping. If bugs need fixing, fix them. If documentation needs writing, write it. If code needs testing, test it. All of this is part of shipping. <b>You don't get paid to program, you get paid to ship. Be good at your job.</b>
</blockquote>
<p>
It's true. One key measure of success for any programmer is how much code you've shipped. <b>But merely shipping is not enough.</b> A more meaningful measure of success is to ask yourself how much code you've shipped to <i>living, breathing, real-world users</i>. But then <a href="http://www.codinghorror.com/blog/archives/000664.html">total users doesn't equal total usage</a>, either.
</p>
<p>
<b>How many users actually <i>use</i> your application</b>? Now <i>that's</i> the ultimate metric of success.
</p>
<p>
But it's a little scary when you start doing the math. Rich Skrenta <a href="http://www.skrenta.com/2007/01/market_engineering.html">explains</a>:
</p>
<p>
</p>
<blockquote>
I was just an engineer in this group, but the reality of what was happening in the market to our product line started to seep in. Here I was putting all of this effort into stuff that never would be used by anyone. It was still intellectually challenging...like doing crossword puzzles or something. But it had no utility to the world.
<p>
I started to look around and I saw many other examples of groups working on stuff that no one would ever use or care about. Mobile IP initiatives, endless work around standards that nobody cared about, research from the labs that would never be applied or even cited.
</p>
<p>
Yikes.
</p>
<p>
I had written stuff that people actually used, before. It felt good. I had written a usenet newsreader that was used by hundreds of thousands of people. I was running an online game, as a commercial hobby on the side, which had several hundred paying customers. Sheesh, I thought. <i>My side projects have more customers than my day job.</i>
</p>
<p>
<b>So I made a simple resolution. I wanted to work on stuff that people would actually use. </b>
</p>
<p>
This sounds simple. But if you walk the halls of Sun, AOL, HP, IBM, AOL, Cisco, Siebel, Oracle, any university, many startups, and even Google and Yahoo, you'll find people working on stuff that isn't going to ship. Or that if it does ship, it won't be noticed, or won't move the needle. That's tragic. It's like writing a blog that nobody reads. People make fun of bloggers who are writing "only for their mother". But what about the legion of programmers writing code paths that will never be traversed?
</p>
</blockquote>
<p>
It's for precisely this reason that <a href="http://www.codinghorror.com/blog/archives/000710.html">I've often wondered if writing code is really the most effective way for software developers to spend their time</a>. A software developer that doesn't write code-- sacrilege, right?
</p>
<p>
But wait a minute. A <i>smart</i> software developer knows that there's no point in writing code if it's code that nobody will see, code that nobody will use, code that nobody will ultimately benefit from. Why build a permanently vacant house?
</p>
<p>
A smart software developer realizes that their job is far more than writing code and shipping it; <b>their job is to build software that people will actually want to use</b>. That encompasses coding, sure, but it also includes a whole host of holistic, non-coding activities that are critical to the overall success of the software. Things like <a href="http://www.codinghorror.com/blog/archives/000668.html">documentation</a>, <a href="http://www.codinghorror.com/blog/archives/000325.html">interaction design</a>, <a href="http://www.codinghorror.com/blog/archives/000706.html">cultivating user community</a>, all the way up to the <a href="http://www.codinghorror.com/blog/archives/000351.html">product vision</a> itself. If you get that stuff wrong, it won't matter what kind of code you've written.
</p>
<p>
If, like Rich Skrenta, you want to work on software that people want to use, realize that it's part of your job to make that software <i>worth using</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/shipping-isnt-enough/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ If It Isn't Documented, It Doesn't Exist ]]></title>
<link>https://blog.codinghorror.com/if-it-isnt-documented-it-doesnt-exist/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Nicholas Zakas enumerates <a href="http://www.amazon.com/gp/plog/post.html/ref=cm_blog_pl/104-9847257-2963905?ie=UTF8&amp;pt=personalBlog&amp;aid=PlogMyCustomersAgent&amp;ot=customer&amp;pd=1164175937.423&amp;pid=PMCA1J3TWE84RTHQXat1164175038&amp;iid=A1J3TWE84RTHQX">the number one reason why good JavaScript libraries fail</a>:
</p>
<p>
</p>
<blockquote>
<b>Lack of documentation.</b> No matter how wonderful your library is and how intelligent its design, if you're the only one who understands it, it doesn't do any good. Documentation means not just autogenerated API references, but also <i>annotated</i> examples and in-depth tutorials. You need all three to make sure your library can be easily adopted.
</blockquote>
<p>
James Bennett expresses a similar sentiment in <a href="http://www.b-list.org/weblog/2007/01/22/choosing-javascript-library">choosing a JavaScript library</a>:
</p>
<p>
</p>
<blockquote>
There's one other thing which can really make or break a JavaScript library, and it's surprising how often it's overlooked, because the same thing makes or breaks an awful lot of software in other fields: <b>documentation</b>. The greatest library in the world would fail if the only way to learn it was reading the code (and, in fact, it already has to a large extent). Some packages have managed to overcome this by way of lots of unofficial documentation  --  blog entries and the like  --  but there is absolutely no substitute for full, well-written documentation. The ideal, for me, consists of:
<p>
</p>
<ol>
<li>High-level overviews of each part of the library, touching on key objects and methods.
</li>
<li>Practical examples showing how to handle common use cases.
</li>
<li>Full API documentation for everything in the library. <a href="http://jsdoc.sourceforge.net/">JSDoc</a> is both good and bad for this: good because it makes API docs stupidly easy to generate, and bad because people assume that API docs are all you need. Javadoc, which inspired JSDoc, has wrought much ill on the Java world for largely the same reasons.
</li>
<li>Comments throughout the code itself.
</li>
</ol>
<p>
Pretty much everybody who's developing a JavaScript library has dropped the ball on this; very few libraries manage even one or two of those points, and out of the teeming multitude of JavaScript libraries floating around today I've seen exactly one which manages to hit all four points with any kind of success. <b>Maybe there are other splendidly-documented libraries out there, but I've yet to see them; most treat documentation like an afterthought.</b>
</p>
</blockquote>
<p>
Mike Pope, who writes documentation for a living, <a href="http://www.mikepope.com/blog/DisplayBlog.aspx?permalink=1680"> neatly summarizes both opinions with this zinger</a>:
</p>
<p>
</p>
<blockquote>
We've been known to tell a developer <b>"If it isn't documented, it doesn't exist."</b> Not only does it have to be doc'd, but it was to be explained and taught and demonstrated. Do that, and people will be excited -- not about your documentation, but about your <i>product</i>.
</blockquote>
<p>
Good documentation is hard to find. Particularly on open source projects. That's why I was so pleasantly surprised to see such excellent documentation for the open-source <a href="http://www.urlrewriting.net/en/Default.aspx">UrlRewriting.net project</a>, along with a support forum.
</p>
<p>
<a href="http://www.urlrewriting.net/en/Default.aspx"><img alt="image placeholder" >
</p>
<p>
The <a href="http://www.urlrewriting.net/download/UrlRewritingNet20.English.pdf">UrlRewriting documentation</a> (pdf) is a pleasure to read. Far from being an afterthought, documentation was a first-class citizen on this project, and it shows. The presence of good documentation makes the <i>code</i> a pleasure to use, too.
</p>
<p>
So how do you keep your documentation up to snuff on a rapidly moving project? Maybe it's possible to use agile documentation methods alongside agile coding practices. Mike Pope's recent post on the <a href="http://www.mikepope.com/blog/DisplayBlog.aspx?permalink=1688">"agile little" ASP.NET AJAX documentation set</a> is a hopeful sign that we, too, can generate better documentation, faster.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/if-it-isnt-documented-it-doesnt-exist/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Would you rather be a Navigator or an Explorer? ]]></title>
<link>https://blog.codinghorror.com/would-you-rather-be-a-navigator-or-an-explorer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
There's an interesting comment in this Amazon user review of <a href="http://www.amazon.com/gp/product/1556159390/105-1849539-8990040">The Microsoft Manual of Style for Technical Publications</a>:
</p>
<p>
</p>
<blockquote>
My favorite entry, especially fun to find in light of Microsoft's legal problems arising in part from its relationship to Netscape Navigator, is this Orwellian directive, found on p. 185: "Navigate. Avoid the verb 'navigate' to refer to moving from site to site, page to page within a site, or link to link on the Internet. [...] Instead, use 'explore' to mean looking for sites or pages generally..."
</blockquote>
<p>
Would you rather be a Navigator or an Explorer? And what, exactly, is the implied meaning of this IE error:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The wording of the "Navigation Canceled" error message can't possibly have been a coincidence, given the intense rivalry with <a href="http://en.wikipedia.org/wiki/Netscape_Navigator">Netscape Navigator</a> back in the heady days of <a href="http://en.wikipedia.org/wiki/Internet_Explorer">Internet Explorer</a> 3 and 4. The message now seems quaint in the wake of Netscape's near-irrelevance. Still, I wonder which cheeky little monkey at Microsoft came up with this particular error message way back when.
</p>
<p>
Of course, there's a long history of semi-friendly rivalry between Internet Explorer and its browser competition. In 1997, immediately after the release of Internet Explorer 4, <a href="http://home.snafu.de/tilman/mozilla/stomps.html">Microsoft dropped a giant IE logo on the Netscape campus</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
And more recently, <a href="http://fredericiana.com/2006/10/24/from-redmond-with-love/">the Internet Explorer team sent the Firefox team a cake</a> to congratulate them on the release of Firefox 2.0.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/would-you-rather-be-a-navigator-or-an-explorer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Dynamic, Lightweight Visualization ]]></title>
<link>https://blog.codinghorror.com/dynamic-lightweight-visualization/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Edward Tufte's <a href="http://www.codinghorror.com/blog/archives/000742.html">print world</a> is filled with <a href="http://visualcomplexity.com/vc/">stunningly beautiful visualizations</a>. Even seemingly mundane things like <a href="http://blog.nicksieger.com/articles/2006/10/27/visualization-of-rubys-grammar">visualizations of Ruby, Java, and JavaScript grammars</a> can be beautiful. But they're static. They don't move. They're not interactive.</p>
<p>That's where Ben comes in.</p>
<p>If you haven't visited <a href="http://benfry.com/">Ben Fry's website</a> before, I envy the experience you're about to have. (Be sure to visit <a href="http://acg.media.mit.edu/people/fry/">his old MIT site</a>, too.) Ben Fry is <strong>Edward Tufte armed with a compiler</strong>. Ben produces incredible dynamic visualizations with his custom Java-based, open-source <a href="http://processing.org/">processing language</a>. It even comes with <a href="http://processing.org/faq.html">its own custom IDE</a>:</p>
<blockquote>We think most "integrated development environments" (Microsoft Visual Studio, Codewarrior, Eclipse, etc.) tend to be overkill for the type of audience we're targeting with Processing. For this reason, we've introduced the 'sketchbook' which is a more lightweight way to organize projects. As trained designers, we'd like the process of coding to be a lot more like sketching. The sketchbook setup, and the idea of just sitting down and writing code (without having to write two pages to set up a graphics context, thread, etc) is a small step towards that goal.
<p>The idea of just writing a short piece of code that runs very easily (via a little run button) is a direct descendant of John Maeda's work in <a href="http://dbn.media.mit.edu/">Design By Numbers</a>, and our experiences maintaining it. (Yes, other languages and environments have done this first, but in our case, the concept is drawn from DBN).</p>
</blockquote>
<p>It's amazing stuff, more akin to sketching than coding. Browse through <a href="http://processing.org/learning/index.html">the examples gallery</a> to get a sense of what's possible.</p>
<p>
<a href="http://processing.org/learning/index.html">
<img alt="image placeholder" >
</a>
</p>
<p>Ben's latest Processing visualizations, <a href="http://benfry.com/salaryper/">baseball salary vs. performance</a>, and <a href="http://benfry.com/isometricblocks/">isometric blocks</a>, are like <strong>pages from an Edward Tufte book come to life</strong>. And who can forget his classic <a href="http://acg.media.mit.edu/people/fry/zipdecode/">zipdecode</a>?</p>
<p>If you've gone this far with Java-based visualization, you might as well continue on to <a href="http://services.alphaworks.ibm.com/manyeyes/home">IBM's Many Eyes site</a>. You can't write your own visualization code here; you're stuck with the predefined visualizations they provide. You <em>can</em>, however, upload and share the data sets you're using to visualize from.</p>
<p>But you might wonder, <em>what's with all the Java?</em> Couldn't we do this dynamic visualization stuff with something more lightweight, something more appropriate for a web page?</p>
<ul>
<li>
<strong>JavaScript</strong> is a possibility. After all, we had <a href="http://www.wolf5k.com/index.html">Wolfenstein 5k</a>, a JavaScript clone of Wolfenstein 3D written <a href="http://alistapart.com/articles/5k/">in only 5 kilobytes of JavaScript</a>, way back in 2002. Sadly, it doesn't work in any modern browser, or even in any Microsoft OS newer than Windows XP Service Pack 2. But it's an impressive piece of work nonetheless. It foreshadowed just how reliant the web would become on JavaScript. One such JavaScript visualization, Kyle Scholz's  <a href="http://kylescholz.com/projects/speaking/tae2006/music/#B00004BZ0N">music recommendation connected graph</a>, is ponderously slow. It leaves me wondering if JavaScript is really up to the task of visualization, even with the <a href="http://en.wikipedia.org/wiki/Canvas_(HTML_element)">HTML Canvas element</a>.
</li>
<li>What about <strong>Flash</strong>? Surely visualization is a better use for Flash than the <a href="http://www.codinghorror.com/blog/archives/000772.html">legions of advertisements</a> (and, now, <em>video</em> advertisements) I'm subjected to every day. Although I can find <a href="http://home.iprimus.com.au/dawidbleja/microcosm/pages/BreathingEarth-real.html">some isolated visualizations in Flash</a>, I'm not seeing a vibrant visualization community there.
</li>
<li>On the Windows side, there's some hope for <strong>Windows Presentation Foundation</strong>, which ships in every Vista box. <a href="http://en.wikipedia.org/wiki/Windows_Presentation_Foundation">WPF</a>, and its lightweight cousin WPF/E, could enable lightweight, <em>hardware accelerated</em> visualization – something that's sorely lacking from all the other options. To see what I mean, try <a href="http://thewpfblog.com/?p=53">this WPF 3D sample</a>, which runs entirely in the browser. But the technology is far too new to have any kind of community. </li>
</ul>
<p>If I wanted to see static illustrations, I'd read a book. But dynamic visualizations aren't quite there yet for web pages. Right now, you have to pick your technology poison. They all have their downsides. Still, it's something worth striving for. I yearn for <strong>the day when web pages are regularly illustrated with the kind of beautiful, dynamic visualizations that Ben Fry creates</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dynamic-lightweight-visualization/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Extending The Windows Vista Grace Period to 120 Days ]]></title>
<link>https://blog.codinghorror.com/extending-the-windows-vista-grace-period-to-120-days/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you're on the fence about the impending release of Windows Vista, I recommend trying before you buy. Every Vista DVD includes <b>the ability to install any edition of Vista without a product key.</b> When you install without a product key, you get an automatic 30 day evaluation period.* This probably isn't news to anyone.
</p>
<p>
What may be news to you, however, is that <b>you can easily extend the 30-day Windows Vista grace period to 120 days.</b> No hacks required. This is an official, supported operation directly from Microsoft.
</p>
<p>
To extend the grace period another 30 days, simply start a command prompt as Administrator, and issue this command:
</p>
<p>
</p>
<pre>
slmgr -rearm
</pre>
<p>
Reboot for the change to take effect, and voila, you have 30 more days. You can only extend three times, so the total grace period for a Vista evaluation is 120 days. You do, however, need to be careful that you've installed the correct edition of Vista. At the end of that 120 day grace period, you'll have to <b>pony up a license fee for the edition of Vista you've installed</b>. Now that the OEM editions are out, the pricing <a href="http://www.newegg.com/Product/ProductList.asp?Order=PRICE&amp;SrchInDesc=vista&amp;Page=1&amp;Category=35&amp;Nty=1&amp;N=2000350368+50001149&amp;Submit=ENE&amp;Subcategory=368&amp;Manufactory=1149">breaks down like so, at least at Newegg</a>:
</p>
<p>
</p>
<ul>
<li>Vista Home Basic OEM - $100
</li>
<li>Vista Home Premium OEM - $120
</li>
<li>Vista Business OEM - $150
</li>
<li>Vista Ultimate OEM - $200
</li>
</ul>
<p>
Microsoft is <a href="http://www.pcmag.com/article2/0,1895,2087792,00.asp">semi-officially supporting the OEM versions for resale to end users</a>, but the bad news is that there's not much savings at the low-end. The pricing for the basic OEM editions are nearly identical to the full retail upgrades. The primary difference is that the OEM copies will support full install as well as upgrade install. If you're looking for deeper Vista discounts, you may be interested in <a href="http://www.windowsvista.com/familyoffer">the Vista Family Pack</a>, which includes the option to buy two $49 copies of Vista Home Premium, provided you pay full retail price for a copy of Vista Ultimate.
</p>
<p>
Now that we've gotten the sticky matter of pricing out of the way, let's take a deeper look at this little utility Microsoft provides. It's actually a Windows Script Host file, slmgr.vbs. First, let's <b>switch our default WSH handler to the command-line version</b> so we aren't dealing with aggravating window popups from the command line.
</p>
<p>
</p>
<pre>
cscript /H:Cscript
</pre>
<p>
If you run slmgr without any parameters, you'll get the help.
</p>
<p>
</p>
<pre>
Windows Software Licensing Management Tool
Usage: slmgr.vbs [MachineName [User Password]] [&lt;Option&gt;]
MachineName: Name of remote machine
User:        Account with required privilege
Password:    password for account
Global Options:
-ipk &lt;Product Key&gt;
Install product key (replaces existing key)
-upk
Uninstall product key
-ato
Activate Windows
-dli [Activation ID | All]
Display license information (default: current license)
-dlv [Activation ID | All]
Display detailed license information (default: current license)
-xpr
Expiration date for current license state
Advanced Options:
-cpky
Clear product key from the registry (prevents disclosure attacks)
-ilc &lt;License file&gt;
Install license
-rilc
Re-install system license files
-rearm
Reset the licensing status of the machine
-dti
Display Installation ID for offline activation
-atp &lt;Confirmation ID&gt;
Activate product with user-provided Confirmation ID
</pre>
<p>
I just re-armed tonight and re-booted, and I can verify that the grace period extension worked via the -dli command:
</p>
<p>
</p>
<pre>
C:UsersJeff&gt;slmgr -dli
Name: Windows(TM) Vista, Ultimate edition
Description: Windows Operating System - Vista, RETAIL channel
Partial Product Key: RP8F7
License Status: Initial grace period
Time remaining: 43100 minute(s) (29 day(s))
</pre>
<p>
This is my third and final grace period extension. I now have 29 days to decide if I want Ultimate edition or not.
</p>
<p>
(update: Ed Bott posted how to <a href="http://blogs.zdnet.com/Bott/?p=224">set up a scheduled task so you rearm automatically after 30 days</a>. I set mine up to run monthly for 3 months rather than setting up 3 individual tasks as Ed suggests.)
</p>
<p>
* Note that this does <i>not</i> apply to the Enterprise edition of Vista, which only allows a 3 day grace period. The enterprise edition has an entirely different activation scheme; it uses a local volume license key server.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/extending-the-windows-vista-grace-period-to-120-days/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How To Become a Better Programmer by Not Programming ]]></title>
<link>https://blog.codinghorror.com/how-to-become-a-better-programmer-by-not-programming/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Last year in <a href="http://www.codinghorror.com/blog/archives/000541.html">Programmers as Human Beings</a>, I mentioned that I was reading <a href="http://www.amazon.com/exec/obidos/ASIN/1556152116/codihorr-20">Programmers At Work</a>. It's a great collection of interviews with famous programmers circa 1986. All the interviews are worth reading, but the interview with Bill Gates has one particular answer that cuts to the bone:
</p>
<blockquote>
<i>Does accumulating experience through the years necessarily make programming easier?</i>
<p>
Bill Gates: No. <b>I think after the first three or four years, it's pretty cast in concrete whether you're a good programmer or not.</b> After a few more years, you may know more about managing large projects and personalities, but after three or four years, it's clear what you're going to be. There's no one at Microsoft who was just kind of mediocre for a couple of years, and then just out of the blue started optimizing everything in sight. I can talk to somebody about a program that he's written and know right away whether he's really a good programmer.
</p>
</blockquote>
<p>
We already know <a href="http://www.codinghorror.com/blog/archives/000635.html">there's a vast divide between those who can program and those who cannot</a>.
</p>
<p>
But the dirty little secret of the software development industry is that this is also true <i>even for people who can program</i>: <a href="http://www.codinghorror.com/blog/archives/000072.html">there's a vast divide between good developers and mediocre developers</a>. A mediocre developer can program his or her heart out for four years, but that won't magically transform them into a good developer. And the good developers always seem to have a natural knack for the stuff from the very beginning.
</p>
<p>
I agree with Bill. From what I've seen, there's just no crossing the skill chasm as a software developer. You've either got it, or you don't. No amount of putting your nose to the grindstone will change that. But if you accept that premise, it also presents us with a paradox: if experience doesn't make you a better programmer, what does? Are our skill levels written in stone? Is it <i>impossible</i> to become a better programmer?
</p>
<p>
To answer that question, you have to consider the obsessive nature of programming itself. Good developers are good at programming. Really good at programming. You might even say fanatically good. If they're anything like me, they've spent nearly every waking moment in front of a computer for most of their lives. And naturally, they get better at it over time. Competent software developers have already mastered the skill of programming, which puts them in a very select club. But if you're already in the 97th percentile for programming aptitude, what difference does a few more percentile points really make in the big scheme of things?
</p>
<p>
The older I get, the more I believe that <b>the only way to become a better programmer is by <i>not programming</i></b>. You have to come up for air, put down the compiler for a moment, and take stock of what you're really doing. Code is important, but it's <a href="http://www.codinghorror.com/blog/archives/000710.html">a small part of the overall process</a>.
</p>
<p>
This <a href="http://www.designobserver.com/archives/011848.html">piece in Design Observer</a> offers a nice bit of related advice:
</p>
<p>
</p>
<blockquote>
Over the years, I came to realize that my best work has always involved subjects that interested me, or  --  even better  --  subjects about which I've become interested, and even passionate about, through the very process of doing design work. I believe I'm still passionate about graphic design. But the great thing about graphic design is that it is almost always about something else. Corporate law. Professional football. Art. Politics. Robert Wilson. And if I can't get excited about whatever that something else is, I really have trouble doing a good work as a designer. To me, the conclusion is inexcapable: the more things you're interested in, the better your work will be.
</blockquote>
<p>
Passion for coding is a wonderful thing. But it's all too easy to mindlessly, reflexively entrench yourself deeper and deeper into a skill that you've already proven yourself more than capable at many times over. To truly become a better programmer, you have to to <b>cultivate passion for everything else that goes on <i>around</i> the programming.</b>
</p>
<p>
Bill Gates, in a 2005 interview, <a href="http://www.microsoft.com/presspass/exec/billg/speeches/2005/07-18FacultySummit.aspx">follows up in spirit to his 1986 remarks</a>:
</p>
<p>
</p>
<blockquote>
The nature of these jobs is not just closing your door and doing coding, and it's easy to get that fact out. The greatest missing skill is somebody who's both good at understanding the engineering and who has good relationships with the hard-core engineers, and bridges that to working with the customers and the marketing and things like that. And so that sort of engineering management career track, even amongst all the people we have, we still fall short of finding people who want to do that, and so we often have to push people into it.
<p>
I'd love to have people who come to these jobs wanting to think of it as an exercise in people management and people dynamics, as well as the basic engineering skills. That would be absolutely amazing.
</p>
<p>
And we can promise those people within two years of starting that career most of what they're doing won't be coding, because there are many career paths, say, within that Microsoft Office group where you're part of creating this amazing product, you get to see how people use it, you get to then spend two years, build another version, and really change the productivity in this very deep way, take some big bets on what you're doing and do some things that are just responsive to what that customer wants.
</p>
</blockquote>
<p>
You won't-- you <i>cannot</i>-- become a better programmer through sheer force of programming alone. You can only complement and enhance your existing programming skills by branching out. Learn about your users. Learn about the industry. Learn about your business.
</p>
<p>
The more things you are interested in, the better your work will be.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-become-a-better-programmer-by-not-programming/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Stylesheets for Print and Handheld ]]></title>
<link>https://blog.codinghorror.com/stylesheets-for-print-and-handheld/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A commenter recently noted that it was difficult to print the <a href="http://www.codinghorror.com/blog/archives/000666.html">Programmer's Bill of Rights post</a>. And he's right. It's high time I set up a print stylesheet for this website. I added the following link tag to the page header:
</p>
<p>
</p>
<pre>
&lt;link rel="stylesheet" href="<a href="https://blog.codinghorror.com/blog/styles-site-print.css">/blog/styles-site-print.css</a>"
type="text/css" <font color="red">media="print"</font> /&gt;
</pre>
<p>
The printer-specific CSS is very simple. On a modern site <a href="http://www.codinghorror.com/blog/archives/000474.html">using &lt;div&gt; based layout</a>, optimizing for printers is easy.
</p>
<p>
</p>
<ol>
<li>Hide named &lt;div&gt;s on the page that aren't relevant to printouts.
<p>
</p>
<pre>
#links {
display: none;
}
#searchbox {
display: none;
}
#newcomment {
display: none;
}
</pre>
<p>
</p>
</li>
<li>Adjust a few margins and widths, and set a default font.
<p>
</p>
<pre>
body {
margin: 0; padding: 0;
font-family:calibri, tahoma, arial, sans-serif;
}
#content {
width: 100%;
margin: 0; padding: 0;
}
#container {
width: 100%;
position:relative;
margin: 0; padding: 0;
}
.blog {
padding: 0;
}
</pre>
</li>
</ol>
<p>
The entire printer-friendly CSS file is a mere 35 lines including generous whitespace. Testing the print stylesheet is a piece of cake, too. Just use the <b>File, Print Preview</b> menu:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Looks good to me.
</p>
<p>
Once you've set up a print stylesheet, you might as well set up a mobile stylesheet, too, because they're almost identical. We just add another link tag to the page header:
</p>
<p>
</p>
<pre>
&lt;link rel="stylesheet" href="<a href="https://blog.codinghorror.com/blog/styles-site-mobile.css">/blog/styles-site-mobile.css</a>"
type="text/css" <font color="red">media="handheld"</font> /&gt;
</pre>
<p>
The CSS is a subset of the printer CSS, so I won't reprint it here. I only hide the links &lt;div&gt;. Testing rendering on a mobile device is a bit more difficult, but it is possible.  Here's what it looks like on <a href="http://blogs.vertigosoftware.com/jatwood/archive/2007/01/12/Samsung_Blackjack_tips_and_tricks.aspx">the new Samsung Blackjack phones</a> we received at work:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If you're wondering what your website looks like on a mobile device, wonder no longer. Try it yourself and see. <b>The Windows SmartPhone / PocketPC emulator was surprisingly easy to get up and running</b>.  Here's what you'll need:
</p>
<p>
</p>
<ul>
<li>A clean Windows XP SP2 virtual machine
</li>
<li>The latest version of <a href="http://www.microsoft.com/windowsmobile/activesync/default.mspx">ActiveSync</a>.
</li>
<li>
<a href="http://www.microsoft.com/downloads/details.aspx?FamilyID=c62d54a5-183a-4a1e-a7e2-cc500ed1f19a&amp;DisplayLang=en">Standalone Device Emulator with Windows Mobile OS Images</a> (download both items listed here)
</li>
<li>
<a href="http://www.microsoft.com/downloads/thankyou.aspx?familyId=DC8332D6-565F-4A57-BE8C-1D4718D3AF65&amp;displayLang=en">Virtual Machine Network Driver for Microsoft Device Emulator</a>
</li>
</ul>
<p>
Once you've downloaded it all, install it in this order:
</p>
<p>
</p>
<ol>
<li>Install ActiveSync
</li>
<li>Unzip and install V1Emulator (standalone_emulator_V1.exe)
</li>
<li>Install the Virtual Network Driver (netsvwrap.msi)
</li>
<li>Install the Emulator Images for Windows Mobile 5.0 (efp.msi)
</li>
</ol>
<p>
I chose to launch the "Smartphone QVGA - Coldboot" emulator. Once it's running, the only tricky part is enabling internet connectivity. This post <a href="http://blogs.msdn.com/akhune/archive/2005/11/16/493329.aspx">describes how to enable internet connectivity in the emulator</a>; you place the emulated smartphone in the virtual "cradle" so it can access the network through ActiveSync. Note that you'll also need to set "Allow connections to one of the following" to "DMA" in the File, Connection Settings menu of ActiveSync.
</p>
<p>
Setting up proper print and handheld stylesheets was fun. And easy. I truly regret not doing it sooner. Don't make the same mistake I did. <b>If you don't have print and handheld stylesheets set up on <i>your</i> website, what are you waiting for?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/stylesheets-for-print-and-handheld/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Low-Fi Usability Testing ]]></title>
<link>https://blog.codinghorror.com/low-fi-usability-testing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Pop quiz, hotshot. <b>How do you know if your application <i>works?</i></b> Sure, maybe your app compiles. Maybe it passes all the unit tests. Maybe it ran the QA gauntlet successfully. Maybe it was successfully deployed to the production server, or packaged into an installer. Maybe your beta testers even signed off on it.
</p>
<p>
But that doesn't mean it works.
</p>
<p>
Can users actually <i>understand</i> your application? Can they <i>get their work done</i> in your application? That's what defines a working application. All the other stuff I listed is just noise. <b>You don't know if your application truly works until you've performed usability tests on it with actual users.</b>
</p>
<p>
And you regularly do usability testing on your application, right?
</p>
<p>
That's what I thought. One of the central concepts in Steve Krug's book <a href="http://www.amazon.com/exec/obidos/ASIN/0321344758/codihorr-20">Don't Make Me Think</a> is that usability testing is essential to any software project. Krug calls his simplified approach to usability testing <i>lost our lease, going-out-of-business-sale usability testing</i>:
</p>
<p>
</p>
<blockquote>
Usability testing has been around for a long time, and the basic idea is pretty simple: If you want to know whether your software or your Web site or your VCR remote control is easy enough to use, watch some people while they try to use it and note where they run into trouble. Then fix it, and test it again.
<p>
In the beginning, though, usability testing was a very expensive proposition. You had to have a usability lab with an observation room behind a one-way mirror, and at least two video cameras so you could record the users' reactions and the thing they were using. You had to recruit a lot of people so you could get results that were statistically significant. It was Science. It cost $20,000 to $50,000 a shot. It didn't happen very often.
</p>
<p>
But in 1989 Jakob Nielsen wrote a paper titled <a href="http://www.useit.com/papers/guerrilla_hci.html">"Usability Engineering at a Discount"</a> and pointed out that it didn't have to be that way. You didn't need a usability lab, and you could achieve the same results with a lot fewer users. The idea of discount usability testing was a huge step forward. The only problem is that a decade later most people still perceive testing as a big deal, hiring someone to conduct a test still costs $5,000 to $15,000, and as a result it doesn't happen nearly often enough.
</p>
<p>
What I'm going to commend to you in this chapter is something even more drastic: Lost our lease, going-out-of-business-sale usability testing.
I'm going to try to explain how to do your own testing when you have no money and no time. If you can afford to hire a professional to do your testing, by all means do it --  but <i>don't</i> do it if it means you'll do less testing.
</p>
</blockquote>
<p>
Krug points out that <b>usability testing is only as difficult as you make it</b>. It's possible to get useful results from a usability test with a <i>single user</i>, even:
</p>
<p>
</p>
<blockquote>
[Usability] testing always works, and even the worst test with the wrong user will show you things you can do to improve your site. I make a point of always doing a live user test at my workshops so that people can see it's very easy to do and it always produces an abundance of valuable insights. I ask for a volunteer and have him try to perform a task on a site belonging to one of the other attendees. These tests last less than ten minutes, but the person whose site is being tested usually scribbles several pages of notes. And they always ask if they can have the recording of the test to show their team back home. Once person told me that after his team saw the recording, they made one change to their site which they later calculated had resulted in $100,000 in savings.
</blockquote>
<p>
For more proof that you don't need a lot of users to have an effective usability test, Jakob Neilsen offers <a href="http://www.useit.com/alertbox/20000319.html">the following graph</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Obviously, not doing any usability testing at all is a disaster. But what's not so obvious is that usability testing with just a few users is remarkably effective. And it can be relatively painless if you follow Krug's broad guidelines for low-fidelity usability testing:
</p>
<p>
</p>
<ul>
<li>
<b>When should I test?</b> Ideally, once per month. You should be running small usability tests continuously throughout the development process. The tests should be short and simple, so you can conduct them almost any time with little advance planning.
</li>
<li>
<b>How many users do I need?</b> Three or four max.
</li>
<li>
<b>What kind of users?</b> Grab some people. Anyone who can use a computer will do. The best-kept secret of usability testing is that <i>it doesn't much matter who you test</i>. It's a good idea to get representative users, but it's much more important to test early and often. Don't be embarrassed to ask friends and neighbors.
</li>
<li>
<b>How much time will it take?</b> 45 minutes to an hour per user. Keep it simple. Keep it small. Although it does take extra time to conduct usability tests, even simple ones, ultimately you will save time. The results of the usability tests will prevent you from <a href="http://www.codinghorror.com/images/dont_make_me_think_pg_131_smaller.png">wasting time arguing endlessly</a>, or redoing things at the end of a project.
</li>
<li>
<b>Where do I conduct the test?</b> Any office or conference room. All you need is a room with a desk, a computer, and two chairs where you won't be interrupted.
</li>
<li>
<b>Who should do the testing?</b> Any reasonably patient human being. Choose someone who tends to be patient, calm, emphathetic, and a good listener. With a little practice, most people can get quite good at it.
</li>
<li>
<b>What equipment do I need?</b> All you need is <a href="http://www.codinghorror.com/blog/archives/000721.html">some form of screen recording software</a>, such as <a href="http://www.techsmith.com/products/studio/default.asp">Camtasia</a>. If you want to get really fancy you can bring in a camcorder to record the person and the screen.
</li>
<li>
<b>How do I prepare for the tests?</b> Decide what you want to show. Have <a href="http://www.sensible.com/Downloads/script.doc">a short script</a> (doc) ready to guide the participants through the test.
</li>
<li>
<b>How much will it cost?</b> Minus the moderator's time, a $50-$100 stipend per user.
</li>
<li>
<b>How do we interpret the results?</b> Debrief the development team and any interested stakeholders over lunch the same day. One of the nicest things about usability testing is that the results tend to be obvious to everyone who's watching. The serious problems are hard to miss.
</li>
</ul>
<p>
If you don't already own a copy of <a href="http://www.amazon.com/exec/obidos/ASIN/0321344758/codihorr-20">Don't Make Me Think</a>, shame on you. In the meantime, I highly recommend <a href="http://sensible.com/Downloads/DMMTchapter09_for_personal_use_only.pdf">downloading Chapter 9 of Steve Krug's Don't Make Me Think</a> (pdf), which has much more detail than the summary I've presented.
</p>
<p>
Usability testing doesn't have to be complicated. If you really want to know if what you're building works, <b>ask someone to use it while you watch</b>. If nothing else, grab Joe from accounting, Sue from marketing, <i>grab anyone nearby who isn't directly involved with the project</i>, and have them try it. Don't tell them what to do. Give them a task, and remind them to think out loud while they do it. Then quietly sit back and <i>watch what happens</i>. I can tell you from personal experience that the results are often eye-opening.
</p>
<p>
The benefits of usability testing are clear. You just have to <i>do it</i> to realize any of those benefits.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-01-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/low-fi-usability-testing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Economics of Bandwidth ]]></title>
<link>https://blog.codinghorror.com/the-economics-of-bandwidth/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>One of the sadder recent news stories is <a href="http://www.informationweek.com/news/showArticle.jhtml?articleID=197002918">the disappearance of Turing award-winning researcher Jim Gray</a>. I've <a href="http://www.codinghorror.com/blog/archives/000044.html">written about Jim's research before</a>; he has a knack for explaining fundamental truths of computer architecture in uniquely     clear ways.</p>
<p>For example, in  <a href="http://www.acmqueue.com/modules.php?name=Content&amp;pa=showpage&amp;pid=43">this ACM interview</a>, Jim illustrates how <b>the unusual economics of bandwidth can make a sneakernet worthwhile</b> – <em>if you're sending a terabyte of data</em>.</p>
<blockquote>
<b>JG</b> We built more than 20 of these boxes we call TeraScale SneakerNet boxes. Three of them are in circulation. We have a dozen doing TeraServer work; we have about eight in our lab for video archives, backups, and so on. It's real convenient to have 40 TB of storage to work with if you are a database guy. Remember the old days and the original eight-inch floppy disks? These are just much bigger.
<p><b>DP</b> "Sneaker net" was when you used your sneakers to transport data?</p>
<p><b>JG</b> In the old days, sneaker net was the notion that you would pull out floppy disks, run across the room in your sneakers, and plug the floppy into another machine. This is just TeraScale SneakerNet. You write your terabytes onto this thing and ship it out to your pals. Some of our pals are extremely well connected – they are part of Internet 2, Virtual Business Networks (VBNs), and the Next Generation Internet (NGI). Even so, it takes them a long time to copy a gigabyte. Copy a terabyte? It takes them a very, very long time across the networks they have.</p>
<p><b>DP</b> When they get a whole computer, don't they still have to copy?</p>
<p><b>JG</b> Yes, but it runs around their fast LAN at gigabit speeds as opposed to the slower Internet. The Internet plans to be running at gigabit speeds, but if you experiment with your desktop now, I think you'll find that it runs at a megabyte a second or less.</p>
<p><b>DP</b> Megabyte a second? We get almost 10 megabytes sustained here.</p>
<p><b>JG</b> That translates to 40 gigabytes per hour and a terabyte per day. I tend to write a terabyte in about 8 to 10 hours locally. I can send it via UPS anywhere in the U.S. That turns out to be about seven megabytes per second.</p>
<p><b>DP</b> How do you get to the 7-megabytes-per-second figure?</p>
<p><b>JG</b> UPS takes 24 hours, and 9 hours at each end to do the copy.</p>
<p><b>DP</b> Wouldn't it be a lot less hassle to use the Internet?</p>
<p><b>JG</b> It's cheaper to send the machine. The phone bill, at the rate Microsoft pays, is about $1 per gigabyte sent and about $1 per gigabyte received – about $2,000 per terabyte. It's the same hassle for me whether I send it via the Internet or an overnight package with a computer. I have to copy the files to a server in any case. The extra step is putting the SneakerNet in a cardboard box and slapping a UPS label on it. I have gotten fairly good at that. Tape media is about $3,000 a terabyte. This media, in packaged SneakerNet form, is about $1,500 a terabyte.</p>
</blockquote>
<p>Does transferring a terabyte of data via sneakernet make sense?
</p>
<p>
<a href="http://www.flickr.com/photos/monsterbrick/3217863173/"><img alt="image placeholder" >
</p>
<p>
First, consider the bandwidth capabilities and monthly cost of <a href="http://en.wikipedia.org/wiki/List_of_device_bandwidths"> a few common Internet connections</a>.</p>
<table width="500">
<tbody>
<tr>
<td></td>
<td style="border-bottom: silver 1px dotted;" align="right">Cost<br> (month)</td>
<td style="border-bottom: silver 1px dotted;" align="right">Download rate<br> per second</td>
<td style="border-bottom: silver 1px dotted;" align="right">Upload rate<br> per second</td>
</tr>
<tr>
<td>56.6 Modem</td>
<td align="right">$15</td>
<td align="right">5 KB</td>
<td align="right">4 KB</td>
</tr>
<tr>
<td>DSL</td>
<td align="right">$30</td>
<td align="right">192 KB</td>
<td align="right">24 KB</td>
</tr>
<tr>
<td>DSL, Premium</td>
<td align="right">$50</td>
<td align="right">384 KB</td>
<td align="right">48 KB</td>
</tr>
<tr>
<td>Cable</td>
<td align="right">$50</td>
<td align="right">300 KB</td>
<td align="right">30 KB</td>
</tr>
<tr>
<td>Cable, Premium</td>
<td align="right">$80</td>
<td align="right">600 KB</td>
<td align="right">60 KB</td>
</tr>
<tr>
<td>T1</td>
<td align="right">$300</td>
<td align="right">192 KB</td>
<td align="right">192 KB</td>
</tr>
<tr>
<td>T3</td>
<td align="right">$1,400</td>
<td align="right">5.4 MB</td>
<td align="right">5.4 MB</td>
</tr>
<tr>
<td>OC-3</td>
<td align="right">$7,500</td>
<td align="right">19 MB</td>
<td align="right">19 MB</td>
</tr>
</tbody>
</table>
<p>Of course, costs may vary; I chose costs that jibed with my personal experience     and lined up with a few cursory searches for pricing around the web. Please let me know you think these     costs are way out of line. Assuming for the sake of argument that these are representative costs and throughput rates, how much would it cost to transfer, let's say, a <b>20 gigabyte high definition video file</b>?</p>
<table width="500">
<tbody>
<tr>
<td></td>
<td style="border-bottom: silver 1px dotted;" colspan="2" align="right">Download 20 GB</td>
<td style="border-bottom: silver 1px dotted;" colspan="2" align="right">Upload 20 GB</td>
</tr>
<tr>
<td>56.6 Modem</td>
<td align="right">49 days</td>
<td align="right">$24.27</td>
<td align="right">61 days</td>
<td align="right">$30.34</td>
</tr>
<tr>
<td>DSL</td>
<td align="right">1&amp;half; days</td>
<td align="right">$1.26</td>
<td align="right">10 days</td>
<td align="right">$10.11</td>
</tr>
<tr>
<td>DSL, Premium</td>
<td align="right">15 hours</td>
<td align="right">$1.05</td>
<td align="right">5 days</td>
<td align="right">$8.43</td>
</tr>
<tr>
<td>Cable</td>
<td align="right">19 hours</td>
<td align="right">$1.35</td>
<td align="right">8 days</td>
<td align="right">$13.48</td>
</tr>
<tr>
<td>Cable, Premium</td>
<td align="right">10 hours</td>
<td align="right">$1.08</td>
<td align="right">4 days</td>
<td align="right">$10.79</td>
</tr>
<tr>
<td>T1</td>
<td align="right">1&amp;half;  days</td>
<td align="right">$12.64</td>
<td align="right">1&amp;half;  days</td>
<td align="right">$12.64</td>
</tr>
<tr>
<td>T3</td>
<td align="right">1 hour</td>
<td align="right">$1.98</td>
<td align="right">1 hour</td>
<td align="right">$1.98</td>
</tr>
<tr>
<td>OC-3</td>
<td align="right">17 minutes</td>
<td align="right">$3.05</td>
<td align="right">17 minutes</td>
<td align="right">$3.05</td>
</tr>
</tbody>
</table>
<p>And <b>how much could we upload or download in total</b>, assuming we had these connections         going full-bore, around the clock?</p>
<table width="500">
<tbody>
<tr>
<td></td>
<td colspan="2" align="right">in 24 hours</td>
<td colspan="2" align="right">in 1 month</td>
</tr>
<tr>
<td></td>
<td style="border-bottom: silver 1px dotted;" align="right">Download</td>
<td style="border-bottom: silver 1px dotted;" align="right">Upload</td>
<td style="border-bottom: silver 1px dotted;" align="right">Download</td>
<td style="border-bottom: silver 1px dotted;" align="right">Upload</td>
</tr>
<tr>
<td>56.6 Modem</td>
<td align="right">422 MB</td>
<td align="right">338 MB</td>
<td align="right">12 GB</td>
<td align="right">10 GB</td>
</tr>
<tr>
<td>DSL</td>
<td align="right">16 GB</td>
<td align="right">2 GB</td>
<td align="right">475 GB</td>
<td align="right">59 GB</td>
</tr>
<tr>
<td>DSL, Premium</td>
<td align="right">32 GB</td>
<td align="right">4 GB</td>
<td align="right">949 GB</td>
<td align="right">119 GB</td>
</tr>
<tr>
<td>Cable</td>
<td align="right">25 GB</td>
<td align="right">2 GB</td>
<td align="right">741 GB</td>
<td align="right">74 GB</td>
</tr>
<tr>
<td>Cable, Premium</td>
<td align="right">49 GB</td>
<td align="right">5 GB</td>
<td align="right">1.5 TB</td>
<td align="right">148 GB</td>
</tr>
<tr>
<td>T1</td>
<td align="right">16 GB</td>
<td align="right">16 GB</td>
<td align="right">475 GB</td>
<td align="right">475 GB</td>
</tr>
<tr>
<td>T3</td>
<td align="right">472 GB</td>
<td align="right">472 GB</td>
<td align="right">14 TB</td>
<td align="right">14 TB</td>
</tr>
<tr>
<td>OC-3</td>
<td align="right">1.6 TB</td>
<td align="right">1.6 TB</td>
<td align="right">49 TB</td>
<td align="right">49 TB</td>
</tr>
</tbody>
</table>
<p>Let's say we wanted to send <b>a terabyte of data via sneakernet</b>:</p>
<ul>
<li>Two 500 GB hard drives weigh about five pounds; we can wrap the drives in bubble             wrap and fit them in a standard FedEx box.</li>
<li>It costs about $60 to send five pounds in a standard FedEx box coast-to-coast in             24 hours.</li>
<li>The total transit time is 32 hours: 24 hours, plus 8 hours to copy the data on and off the drives.</li>
</ul>
<p><em>We just transferred data at the rate of 9.1 megabytes per second.</em> The only     internet connection that's capable of our sneakernet throughput level is the OC-3.     None of the others are even close, particularly if you consider the highly asymmetric     nature of consumer connections, where upload rate is a fraction of the download     rate.<br> <br> And what about the cost? Not including the $300 expense of the two hard drives (which I think     is fair, beause they're reusable), the total cost per gigabyte breaks down like     so:</p>
<table width="315">
<tbody>
<tr>
<td></td>
<td style="border-bottom: silver 1px dotted;" align="right">Cost per GB<br> Downloaded</td>
<td style="border-bottom: silver 1px dotted;" align="right">Cost per GB<br> Uploaded</td>
</tr>
<tr>
<td>56.6 Modem</td>
<td align="right">$1.21</td>
<td align="right">$1.52</td>
</tr>
<tr>
<td>DSL</td>
<td align="right">$0.06</td>
<td align="right">$0.51</td>
</tr>
<tr>
<td>DSL, Premium</td>
<td align="right">$0.05</td>
<td align="right">$0.42</td>
</tr>
<tr>
<td>Cable</td>
<td align="right">$0.07</td>
<td align="right">$0.67</td>
</tr>
<tr>
<td>Cable, Premium</td>
<td align="right">$0.05</td>
<td align="right">$0.54</td>
</tr>
<tr>
<td>T1</td>
<td align="right">$0.63</td>
<td align="right">$0.63</td>
</tr>
<tr>
<td>T3</td>
<td align="right">$0.10</td>
<td align="right">$0.10</td>
</tr>
<tr>
<td>OC-3</td>
<td align="right">$0.15</td>
<td align="right">$0.15</td>
</tr>
<tr>
<td>Sneakernet</td>
<td align="right"><span style="color: red;">$0.06</span></td>
<td align="right"><span style="color: red;">$0.06</span></td>
</tr>
</tbody>
</table>
<p>It wasn't obvious to me, but the sneakernet math clearly works. This is exactly the kind of     insight Jim Gray was famous for.<br> <br> Jim also says <b>the cost of internet bandwidth was roughly a dollar a gigabyte for Microsoft     in 2003</b>. Is that still how much internet bandwidth costs today? According to     the figures I found, the only connection that expensive today is a modem. And <a href="http://www.codinghorror.com/blog/archives/000599.html">who uses modems any         more?</a> It seems implausible that consumer internet bandwidth would be sold     cheaper than large blocks of commercial internet bandwidth. Let's take a look.</p>
<ul>
<li>Amazon's S3 service <a href="http://docs.amazonwebservices.com/AmazonS3/2006-03-01/Pricing.html"> charges 20 cents per gigabye to transfer data</a>.</li>
<li>Robert X Cringely regularly gets charged 20 cents per gigabyte for NerdTV, and guesses             that <a href="http://www.pbs.org/cringely/pulpit/2006/pulpit_20061013_001021.html">large                 bandwidth consumers like YouTube can negotiate rates as low as 10 cents per gigabyte</a>.</li>
<li>Mitch Ratcliffe did a survey of internet providers and found that <a href="http://blogs.zdnet.com/Ratcliffe/?p=186"> most charge 85 cents per gigabyte</a>, and he proposes YouTube could negotiate a             rate of 45 cents per gigabyte.</li>
</ul>
<p>I'm not sure who to believe. It's a good sign that most estimates are under the         $1.00 per gigabyte rate that Jim quoted in 2003. <b>I'd like to think that the             cost of internet bandwidth is getting less expensive over time.</b> <a href="http://www.codinghorror.com/blog/archives/000044.html"> High bandwidth costs lead to a de-facto "popularity tax"</a>, and that's         like a giant wet blanket over content creators. Cheaper bandwidth is a net public good: it leads directly         to more content, and higher quality content, for everyone.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-economics-of-bandwidth/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Windows Vista Media Center ]]></title>
<link>https://blog.codinghorror.com/windows-vista-media-center/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As far as I'm concerned, <b>Windows Media Center is one of the best-- if not <i>the</i> best-- applications Microsoft has ever created</b>. And <a href="http://www.codinghorror.com/blog/archives/000542.html">it was written in .NET</a> to boot.
</p>
<p>
I've been a huge MCE enthusiast since the original version was released in 2003, so I was greatly looking forward to the Vista edition of Media Center. I've slowly been upgrading <a href="http://www.codinghorror.com/blog/archives/000221.html">my Home Theater PC</a> over the last two years in anticipation of the shift to Vista:
</p>
<p>
</p>
<ul>
<li>2.1 GHz Pentium-M "Dothan"
</li>
<li>AOpen i855GMEm mobo
</li>
<li>GeForce 7600GS, 256 MB, AGP 4x
</li>
<li>2 GB RAM
</li>
<li>
<a href="http://www.hauppauge.com/pages/products/data_pvr500mce.html">Hauppauge PVR-500 MCE dual tuner</a> (highly recommended)
</li>
<li>1 TB storage (dual 500 GB <a href="http://www.silentpcreview.com/article617-page1.html">low-noise SATA drives</a>)
</li>
</ul>
<p>
Eventually I want to <a href="http://www.codinghorror.com/blog/archives/000746.html">plop an internal HD-DVD drive</a> in this machine once prices and configurations stabilize. But that's probably another 8-12 months out.
</p>
<p>
This weekend I took the plunge and upgraded my HTPC from Windows XP Media Center Edition 2005 to Windows Vista Home Premium. I wasn't disappointed. <b>Vista's Media Center is a vast improvement over XP's Media Center</b>. It's faster, it's prettier, and it's thoroughly improved in every way.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The default UI makes better use of the horizontal, widescreen arrangements most home theater setups will have. Recorded shows are now displayed as a linear timeline with a graphic still, rather than plain text in a list.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Under Vista's Media Center, my 60+ GB music library is now a pleasure to navigate. Like videos, much better use of horizontal screen real estate; I can see dozens of albums at once. And the music library is <i>dramatically</i> faster. Displaying, searching, scrolling-- it's all nearly instantaneous now. I love the new "play all" shuffle mode, too.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The program guide-- which is completely free, no monthly charges whatsoever-- now overlays the live video as a transparency. There's also a new popup Mini-Guide (not pictured) which lets you browse nearby channels without obscuring playback.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The main menu no longer stops whatever I'm doing and zaps me back to a flat menu screen. It's more of a pop-up style menu, which can be accessed at any time through the big green MCE button. I can now continue watching my program in the background while navigating the main menu, too.
</p>
<p>
Another big quality of life improvement in Vista's Media Center is that <a href="http://www.codinghorror.com/blog/archives/000197.html">a DVD codec is included right out of the box</a>. So Vista's Media Center, unlike the one in Windows XP, is fully usable after a clean install. It even works with my SPDIF out for Dolby Digital sound playback. There's no longer any need to rely on questionable, expensive third-party DVD playback apps.
</p>
<p>
Did I mention burning TV shows to DVD is now included out of the box, too? As far as I'm concerned, <b>Media Center is the killer app for Vista</b>. And at $120 for the OEM Home Premium edition, it's a flat-out bargain for a better-than-Tivo experience-- without all those onerous monthly fees.
</p>
<p>
If you're interested in a home theater PC, all you need is the following:
</p>
<p>
</p>
<ol>
<li>Vista Home Premium (or Ultimate)
</li>
<li>relatively modern PC
</li>
<li>
<a href="http://www.pcalchemy.com/index.php/cName/pvr-cardstv-tuners">MCE compatible PVR card</a>
</li>
<li>
<a href="http://www.pcalchemy.com/product_info.php/pName/microsoft-mce-remote-control-for-windows-xp-mce/cName/remote-controls">MCE remote</a>
</li>
</ol>
<p>
One caveat: I've stuck exclusively and intentionally with analog cable. All my digital video needs are satisified at the moment through DVD rentals and downloads. However, <b>it is possible to record and play back over the air HDTV signals with Media Center</b>, assuming you have a MCE compatible HDTV tuner installed (such as the <a href="http://www.pcalchemy.com/index.php/cName/hdtv-tuner-cards">AverMedia MCE A180</a>). The only unresolved issue at this point is <a href="http://www.engadget.com/2007/01/06/windows-vista-digital-cable-tuners-dont-call-it-ocur/">CableCard</a>, for digital cable.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/windows-vista-media-center/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What You Have, What You Know, What You Are ]]></title>
<link>https://blog.codinghorror.com/what-you-have-what-you-know-what-you-are/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I'm no fan of the classic login/password scheme. <a href="http://www.codinghorror.com/blog/archives/000546.html">I can barely remember any of the zillion logins and passwords I have</a>. More often than not, I end up using the "forgot password" link. Which means, in effect, that <b>my email account is my global password</b>. And if you're like most people, <a href="http://www.codinghorror.com/blog/archives/000360.html">your email password isn't very secure</a>. As Bruce Schneier recently <a href="http://www.schneier.com/essay-144.html">observed</a>:</p>
<blockquote>
<p>We used to quip that "password" is the most common password. Now it's "password1." Who said users haven't learned anything about security?</p>
</blockquote>
<p>It's a depressing state of affairs. <a href="http://www.codinghorror.com/blog/archives/000342.html">Switching to passphrases helps</a>, but is a band-aid at best.</p>
<p>The relentless increase in phishing attacks may soon force some changes on this front. I saw in the news that <a href="http://www.cnet.com/news/paypal-to-offer-password-key-fobs-to-users/">PayPal is switching to two-factor authentication</a>. Specifically, they're providing users with a keyfob that produces a new six-digit code every 30 seconds. Users will now have to type in their name, password, <i>and</i> a valid code from the keyfob.</p>
<img alt="image placeholder" >
<p>The PayPal system isn't <a href="http://en.wikipedia.org/wiki/SecurID">SecurID</a>, but I'm sure the implementation is very similar. There's a matching seed value stored on the server for each keyfob, so the server can calculate what the correct code should be. If the user enters the correct password <i>and</i> the correct code (within 30 seconds), they're allowed in.</p>
<p>So what's the value in doing this? It's more hassle and more expense. Well, consider that all security is based on three things:</p>
<h4>What you have</h4>
<h4>What you know</h4>
<h4>What you are</h4>
<p>We all use logins and passwords. That's <i>something we know</i>. When we enter the code from the keyfob, we've added <i>something we have</i> to the mix. That's <a href="https://en.wikipedia.org/wiki/Two-factor_authentication">two factor authentication</a>, and it increases security dramatically.</p>
<p>But even with the keyfob, we haven't quite removed the risk of phishing entirely. All we've done is make the window of opportunity smaller. If a phishing site can relay the user-provided data to the server in real time (or close enough), they will still be authenticated.</p>
<p>A common form of <i>local</i> two-factor authentication is the Smart Card.</p>
<img alt="image placeholder" >
<p>Smart cards have an embedded microprocessor that uniquely identifies each card, a private key of sorts. Some even have the ability to store data. The secrets on each card stay secret because it's impossible to extract the data without destroying the chip in the process. Since smart cards are read by hardware on your PC, they're of no use online. But they can dramatically enhance security locally. For example, Windows has embedded support for smart cards; <b>it's possible to log into the operating system using nothing but a smart card and a short PIN code</b>. The PIN code is still a password of sorts, but it's much shorter and easier to remember.</p>
<p>Once you switch over to smart cards, it's no longer possible to log in using a traditional username and password. Your underlying password becomes a randomly generated 64-character string. As you can imagine, this is a <i>huge</i> boon for local security <a href="http://www.schneier.com/essay-144.html">compared to user-selected passwords</a>. I don't personally care for smart cards, but I can certainly understand why organizations choose to use them.</p>
<p>But two-factor authentication, although more secure, isn't a panacea. Bruce Schneier is quick to remind us that <a href="http://www.schneier.com/blog/archives/2005/03/the_failure_of.html">two-factor authentication is vulnerable to two primary forms of attack</a>:</p>
<blockquote>
<p><b>Man-in-the-Middle attack</b>. An attacker puts up a fake bank website and entices user to that website. User types in his password, and the attacker in turn uses it to access the bank's real website. Done right, the user will never realize that he isn't at the bank's website. Then the attacker either disconnects the user and makes any fraudulent transactions he wants, or passes along the user's banking transactions while making his own transactions at the same time.</p>
<p><b>Trojan attack</b>. Attacker gets Trojan installed on user's computer. When user logs into his bank's website, the attacker piggybacks on that session via the Trojan to make any fraudulent transaction he wants.</p>
</blockquote>
<p>We already knew about the man-in-the-middle attack; we refer to it as real-time phishing. As for trojans, it might be a little unfair to blame two-factor authentication for not protecting the user from a compromised system. I'm not sure <i>any</i> security measures can work on a compromised system with trojan keyloggers and screenloggers installed.</p>
<p>Despite Schneier's skepticism, I think two-factor authentication is worthwhile. Anything that moves the security bar beyond the <b>hopelessly insecure and ineffective username/password combos</b> we're currently stuck with is a welcome change.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/what-you-have-what-you-know-what-you-are/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Software "Check Engine" Light ]]></title>
<link>https://blog.codinghorror.com/the-software-check-engine-light/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Raymond Chen notes that, in his personal experience, <a href="http://www.codinghorror.com/blog/archives/000114.html">users don't read dialogs</a>:
</p>
<p>
</p>
<blockquote>
<b>How do I make this error message go away? It appears every time I start the computer.</b>
<p>
RC: What does this error message say?<br>
User: It says, 'Updates are ready to install.' I've just been clicking the X to make it go away, but it's really annoying.
</p>
<p>
<b>Every time I start my computer, I get this message that says that updates are ready to install. What does it mean?</b>
</p>
<p>
RC: It means that Microsoft has found a problem that may allow a computer virus to get into your machine, and it's asking for your permission to fix the problem. You should click on it so the problem can be fixed.<br>
User: Oh, that's what it is? I thought it was a virus, so I just kept clicking No.
</p>
<p>
<b>When I start the computer I get this big dialog that talks about Automatic Updates. I've just been hitting Cancel. How do I make it stop popping up?</b>
</p>
<p>
RC: Did you read what the dialog said?<br>
User: No. I just want it to go away.
</p>
<p>
<b>Sometimes I get the message saying that my program has crashed and would I like to send an error report to Microsoft. Should I do it?</b>
</p>
<p>
RC: Yes, we study these error reports so we can see how we can fix the problem that caused the crash.<br>
User: Oh, I've just been hitting Cancel because that's what I always do when I see an error message.<br>
RC: Did you read the error message?<br>
User: <a href="http://www.codinghorror.com/blog/archives/000114.html">Why should I?</a> It's just an error message. All it's going to say is 'Operation could not be performed because blah blah blah blah blah.'
</p>
</blockquote>
<p>
He wonders <a href="http://blogs.msdn.com/oldnewthing/archive/2003/09/01/54734.aspx">if software should have a Check Engine light</a>:
</p>
<p>
</p>
<blockquote>
Automobile manufacturers have learned to consolidate all their error messages into one message called "Check engine". People are conditioned to take the car in to a mechanic when the "Check engine" light goes on, and let the mechanic figure out what is wrong. Can we have a "Check engine" light for computers? Would it be feasible?
</blockquote>
<p>
It's an interesting concept, insofar as it relieves the users from having to look at dialogs they won't understand anyway. But it seems highly unlikely to me that these users would pay any more attention to a subtle software Check Engine light than they do to the giant, screaming dialogs it's replacing.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
And there's another problem with the automobile analogy, too. Unlike a car, computers-- at least the ones connected to the internet-- are perfectly capable of diagnosing and fixing themselves.  <b>The examples Raymond provides shouldn't have asked the user <i>anything</i>; they should have quietly gone about their business.</b>
</p>
<p>
If you need to update, do so. if you need to download and apply security patches in the background, do so. If you need to send crash data, do so. Silently. And do it in the background, when the PC is idle-- without bothering the user.
</p>
<p>
If you're an advanced user who want to change and control this behavior, or view the status of these activities, you can certainly do so through control panels, options dialogs, and event logs. But the rest of the world doesn't care; they're relying on your software to do the right thing on their behalf without subjecting them to a barrage of questions they'll neither read nor understand.
</p>
<p>
A software check engine light is a mildly less invasive form of <a href="http://www.codinghorror.com/blog/archives/000676.html">stopping the proceedings with idiocy</a>. Your software should be <a href="http://www.codinghorror.com/blog/archives/000550.html">more considerate</a> than that.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-software-check-engine-light/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Boyd's Law of Iteration ]]></title>
<link>https://blog.codinghorror.com/boyds-law-of-iteration/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><a href="http://blogs.vertigosoftware.com/scott/default.aspx">Scott Stanfield</a> forwarded me a link to Roger Sessions' <a href="http://msdn2.microsoft.com/en-us/library/aa479371.aspx">A Better Path to Enterprise Architecture</a> yesterday. Even though it's got <a href="http://www.codinghorror.com/blog/archives/000227.html">the snake-oil word "Enterprise"</a> in the title, the article is surprisingly good.</p>
<p>I particularly liked the unusual analogy Roger chose to illustrate the difference between iterative and recursive approaches to software development. It starts with Air Force <a href="http://en.wikipedia.org/wiki/John_Boyd_(military_strategist)">Colonel John Boyd</a> researching a peculiar anomaly in the performance of 1950's era jet fighters:</p>
<blockquote>
<p>Colonel John Boyd was interested not just in any dogfights, but specifically in dogfights between <a href="http://en.wikipedia.org/wiki/Mikoyan-Gurevich_MiG-15">MiG-15s</a> and <a href="http://en.wikipedia.org/wiki/F-86_Sabre">F-86s</a>. As an ex-pilot and accomplished aircraft designer, Boyd knew both planes very well. He knew the MiG-15 was a better aircraft than the F-86. The MiG-15 could climb faster than the F-86. The MiG-15 could turn faster than the F-86. The MiG-15 had better distance visibility.</p>
<p>The F-86 had two points in its favor. First, it had better side visibility. While the MiG-15 pilot could see further in front, the F-86 pilot could see slightly more on the sides. Second, the F-86 had a hydraulic flight control. The MiG-15 had a manual flight control.</p>
<p>The standing assumption on the part of airline designers was that maneuverability was the key component of winning dogfights. Clearly, the MiG-15, with its faster turning and climbing ability, could outmaneuver the F-86.</p>
<p>There was just one problem with all this. Even though the MiG-15 was considered a superior aircraft by aircraft designers, the F-86 was favored by pilots. The reason it was favored was simple: in one-on-one dogfights with MiG-15s, the F-86 won nine times out of ten.</p>
</blockquote>
<p>How can an inferior aircraft consistently win over a superior aircraft? Boyd, who was himself one of the best dogfighters in history, had a theory:</p>
<blockquote>
<p>Boyd decided that the primary determinant to winning dogfights was not observing, orienting, planning, or acting better. The primary determinant to winning dogfights was observing, orienting, planning, and acting <i>faster</i>. In other words, how quickly one could iterate. <i>Speed of iteration</i>, Boyd suggested, <i>beats quality of iteration</i>.</p>
<p>The next question Boyd asked is this: why would the F-86 iterate faster? The reason, he concluded, was something that nobody had thought was particularly important. It was the fact that the F-86 had a hydraulic flight stick whereas the MiG-15 had a manual flight stick.</p>
<img alt="image placeholder" >
<p>Without hydraulics, it took slightly more physical energy to move the MiG-15 flight stick than it did the F-85 flight stick. Even though the MiG-15 would turn faster (or climb higher) once the stick was moved, the amount of energy it took to move the stick was greater for the MiG-15 pilot.</p>
<p>With each iteration, the MiG-15 pilot grew a little more fatigued than the F-86 pilot. And as he gets more fatigued, it took just a little bit longer to complete his OOPA loop. The MiG-15 pilot didn't lose because he got outfought. He lost because he got out-OOPAed.</p>
</blockquote>
<p>This leads to <b>Boyd's Law of Iteration: speed of iteration beats quality of iteration.</b></p>
<p>You'll find this same theme echoed throughout every discipline of modern software engineering:</p>
<ul>
<li>Unit tests should be <a href="http://www.artima.com/weblogs/viewpost.jsp?thread=126923">small and fast</a>, so you can run them with every build.</li>
<li>Usability tests work best if you <a href="http://www.uie.com/articles/fast_iterations/">make small changes every two weeks and quickly discard what isn't working</a>.</li>
<li>Most agile approaches recommend iterations <a href="http://www.mountaingoatsoftware.com/article/view/30">no longer than 4 weeks</a>.</li>
<li>Software testing is about <a href="http://blogs.msdn.com/micahel/archive/2005/08/17/FailFast.aspx">failing early and often</a>.</li>
<li>Functional specifications are best when they're <a href="http://www.codinghorror.com/blog/archives/000448.html">concise and evolving</a>.</li>
</ul>
<p>When in doubt, <i>iterate faster</i>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/boyds-law-of-iteration/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Non-Native UI Sucks ]]></title>
<link>https://blog.codinghorror.com/non-native-ui-sucks/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's common knowledge that <strong>Mac users prefer Safari to Firefox</strong>. It is the browser bundled with the OS – and <a href="http://www.codinghorror.com/blog/2005/03/because-ie6-is-the-new-netscape-47x.html">we know how that generally works out</a>. But it's not just a monopoly play; there are <a href="http://www.oreillynet.com/mac/blog/2006/02/safari_vs_firefox_the_yellow_b.html">legitimate reasons for Mac users to choose Safari</a>:
</p>
<blockquote>
Mac users favor [Safari] for its rendering speed, clean interface and fast launch times.
</blockquote>
<p>
Safari is, of course, a completely competent browser that <a href="http://weblogs.mozillazine.org/hyatt/archives/2005_04.html">stands on its technical merits</a>, very much <a href="http://www.codinghorror.com/blog/2005/03/because-ie6-is-the-new-netscape-47x.html">unlike IE6</a>. But if you ask Mac users why they chose Safari, and if you keep pressing them, you'll probably find the deciding factor was that <em>Safari feels like a native Mac app</em>.
</p>
<p>
<a href="http://plasticbugs.com/?p=312"><img alt="image placeholder" >
</p>
<p>
The next version of Firefox <a href="http://blog.wired.com/monkeybites/2007/02/firefox_3_alpha.html">will use some native UI elements in OS X</a>. But it's <a href="http://blog.wired.com/monkeybites/2007/02/firefox_3_quest.html">still not a native Cocoa app</a>. The lack of a completely native UI on OS X may seem like a minor implementation detail, but it's actually a showstopper for a lot of people, like this <a href="http://blog.wired.com/monkeybites/2007/02/firefox_3_alpha.html">commenter</a>:
</p>
<blockquote>
"Native cocoa widgets" refers to the use of the natively rendered components such as scroll bars and submit buttons. These are the same buttons and scroll bars used in nearly all Cocoa apps for OSX (basically every program you've ever used). The default theme for OSX FF2 uses these really ugly widgets that are really blocky and Netscape 4-y looking.
<p>
<strong>As vain as it may sound, those ugly widgets are actually one of the major reasons I use Safari instead of FF on OSX</strong>.
</p>
</blockquote>
<p>
When two applications with rough feature parity compete, the application with the native UI will win. Every time. If you truly want to win the hearts and minds of your users, you go to the metal and take full advantage of the native UI.
</p>
<p>
Java has struggled with this problem for years, producing results spanning the continuum between "terrible" and "awful", depending on who you ask. Most Java developers have <a href="http://mooseyard.com/Jens/2007/01/in-which-i-think-about-java-again-but-only-for-a-moment/">given up completely on GUI applications</a>:
</p>
<blockquote>
Me, I defected long ago. I'm another of those Apple Java engineers who dropped out. I spent five years as a raving Java fanboy, but I gave up after optimizing AWT, implementing drag and drop, and trying to make 1,200 pages of crappy APIs do the right thing on the Mac. Then I took a one-week Cocoa training course, and wrote the first prototype of iChat.
<p>
Desktop Java never worked because Sun tried to build their own OS on top of the real OS, duplicating every API and feature. This led to terrible bloat, making every app as heavyweight to launch as Photoshop. Worse, the GUI portions of the Java platform are awful, because Sun is a server company with no core competency at GUIs. The APIs are too clumsy to code to, and <strong>compared to any decent Mac app, the results look like a Soviet tractor built on a Monday</strong>.
</p>
</blockquote>
<p>
Ultimately, the best any Java app can do is <em>pretend</em> to be a native app. To fake it. And more often than not, <a href="http://www.ibiblio.org/java/oldnews/news2007February7.html">it can't even manage to do that</a>:
</p>
<blockquote>
<a href="https://substance.dev.java.net/">This project</a> should be a cautionary tale for people who think programmers should be interface designers. Apple and Microsoft at least recognize that these are different skill sets, and that looks and feels should be created by a team of programmers, graphic designers, and interaction designers. Sadly the Linux and Java communities haven't really figured this out yet, and are still trying to have programmers do it all, with predictable results. The bottom line is that we don't really need different look-and-feels in Java. The best Java can or should do is faithfully mimic the native user interface. Unless your name is <a href="http://en.wikipedia.org/wiki/Bruce_Tognazzini">Bruce Tognazzini</a> or <a href="http://en.wikipedia.org/wiki/Kai_Krause">Kai Krause</a>, you almost certainly won't do better than that; and you'll be very, very lucky if you don't do worse. Pluggable look-and-feels are necessary in Swing only because Swing apps have to run on multiple platforms. They should be changed only from operating system to operating system, not application to application. <strong>The goal of a Java application is to fit in with other native applications, not to stand out.</strong>
</blockquote>
<p>
<a href="http://gaim.sourceforge.net/">GAIM</a> has a cross-platform UI based on <a href="http://en.wikipedia.org/wiki/GTK+">GTK</a>, which produces predictably bland, least-common-denominator results:
</p>
<p>
<img alt="image placeholder" > 
<img alt="image placeholder" >
</p>
<p>
Most of all, I find myself empathizing with Mac Safari users because <strong>I haven't been able to switch away from IE7 on Vista.</strong> Firefox feels so dowdy in Vista. It just doesn't fit in. It scrolls very slowly, the <a href="http://cssbeauty.com/skillshare/discussion/1487/firefox-20-bug-keyboard-stops-workingloses-focus/">keyboard stops working at random</a>, and the overall GUI is jarringly out of place, including the <a href="http://www.codinghorror.com/blog/archives/000397.html">legacy main menu</a>. There's no doubt whatsoever that Firefox is a <em>vastly</em> superior browser for web development, with a <a href="http://www.codinghorror.com/blog/archives/000706.html">vibrant developer community</a>. Firefox absolutely should be a part of every developer's core toolkit.
</p>
<p>
But when it comes to day-to-day browsing, <strong>I'll always pick native speed and native look and feel</strong> over the ability to install a dozen user extensions, or the ability to run on umpteen different platforms. Every single time.
</p>
<p>
If that makes me shallow, then <a href="http://www.codinghorror.com/blog/archives/000769.html">I'm in good company</a>. Non-native UI sucks.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/non-native-ui-sucks/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Remotely Waking Up Your PC ]]></title>
<link>https://blog.codinghorror.com/remotely-waking-up-your-pc/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
My home theater PC is set to <b>automatically enter a low-power sleep mode after 25 minutes of inactivity</b>. This works well with Vista's Media Center, which wakes the machine up when it's scheduled to record. This way I can avoid <a href="http://www.codinghorror.com/blog/archives/000426.html">the additional electricity cost of a computer turned on around the clock</a>. My HTPC doesn't use that much power, but even at <a href="http://www.codinghorror.com/blog/archives/000353.html">a miserly 60 watts idle</a>, that still works out to about $80 per year here.
</p>
<p>
This arrangement works out fine most of the time. I don't mind waking the machine manually when I want to watch television-- after all, I'm in the same room and I'm walking towards the couch anyway. It's on the way. But <b>a sleeping PC can be incredibly annoying when I'm sitting at my desk and I need to access that machine remotely</b>. I use my HTPC as my digital media file server, so I often need to transfer files back and forth. But now I can't, because the machine is often asleep. Zzzzz. I desperately need it to WAKE UP. This always reminds me of <a href="http://www.tjande.com/tje2.html">ToeJam &amp; Earl</a> on the <a href="http://en.wikipedia.org/wiki/Sega_Mega_Drive">Sega Genesis</a>. If you left the controller alone for a minute, your character would fall alseep.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You had to frantically bash all the controller buttons to wake your character up, which he did only reluctantly. Unfortunately, mashing all the buttons on my keyboard didn't seem to work. What I need is a way to remotely wake a sleeping computer.
</p>
<p>
Fortunately, one already exists: it's called <a href="http://en.wikipedia.org/wiki/Wake-on-LAN">Wake-on-LAN</a>. Most modern motherboards have integrated ethernet ports that support Wake-on-LAN. Here's how to tell if yours does: <b>put your computer to sleep, then take a look at the ethernet port and see if the transmit and receive LEDs are still blinking</b>. If they are, it's likely you can use Wake-on-LAN. That was true in my case, so I figured it should work.
</p>
<p>
I downloaded a few Wake-on-LAN tools, but the one I liked most was Vitaly Evseenko's small, <a href="http://www.matcode.com/wol.htm">free command-line utility, mc-wol.exe</a>. These utilities send a specially crafted "magic ethernet packet" to the target PC which initiates the wake-up sequence. Note that <b>you have to identify the target PC by MAC address, not IP address</b>. I checked my router's DHCP tables, which included the following MAC entry for my HTPC:
</p>
<p>
<code>00:01:80:5c:d3:24</code>
</p>
<p>
Armed with that information, I gave it a shot. But nothing happened. Zzzzz. Darn! I checked the PC's BIOS settings, but there was nothing relevant. And then I remembered the properties page for the network adapter in Device Manager:
</p>
<p>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Bingo. It's in two different places under Device Manager, Network Adapters, Properties:
</p>
<p>
</p>
<ul>
<li>Advanced tab, Wake from Shutdown property, Value = On
</li>
<li>Power Management tab, Allow this device to wake the computer, check
</li>
</ul>
<p>
I'm not sure which one is the "right" one to set. I set both just to be sure. Once did, I was able to wake up the machine remotely exactly as desired:
</p>
<p>
</p>
<pre>
C:UsersJeffDesktoptest&gt;mc-wol 00:01:80:5c:d3:24
WakeOnLAN v1.0 Copyright (c)2001, MATCODE Software.
Web: http://www.matcode.com
Author: Vitaly Evseenko, ve@matcode.com
Sending "Magic Packet" to 00:01:80:5c:d3:24 - Success!
C:UsersJeffDesktoptest&gt;ping mce
Pinging mce [192.168.0.110] with 32 bytes of data:
Reply from 192.168.0.110: bytes=32 time&lt;1ms TTL=128
Reply from 192.168.0.110: bytes=32 time&lt;1ms TTL=128
Reply from 192.168.0.110: bytes=32 time&lt;1ms TTL=128
Reply from 192.168.0.110: bytes=32 time&lt;1ms TTL=128
Ping statistics for 192.168.0.110:
Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),
Approximate round trip times in milli-seconds:
Minimum = 0ms, Maximum = 0ms, Average = 0ms
</pre>
<p>
You know, I think there's an inspiring moral to this story: <b>why get out of your chair and walk 20 feet when you can spend two hours figuring out how to do it without moving at all?</b> It's a symbolic victory for lazy people everywhere.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/remotely-waking-up-your-pc/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Does Offline Mode Still Matter? ]]></title>
<link>https://blog.codinghorror.com/does-offline-mode-still-matter/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's the classic achilles heel of web applications-- without an internet connection, they're useless. It's why both Firefox and Internet Explorer still have Work Offline under the File menu, hanging there like a vestigial tail.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But do you know anyone that actually uses <i>work offline</i>? Is there anything more futile than a web browser without a connection to the internet?
</p>
<p>
By now, <a href="http://www.codinghorror.com/blog/archives/000599.html">more than 50 percent of Americans have broadband internet</a>. Add the ubiquity of WiFi access points, and the increasing availability of high-speed 3G cellular networks, and it's difficult to find any place that you <i>can't</i> be online, if you really want to be.
</p>
<p>
And people, not just geeks, really want to be online. We've long since reached the critical mass that <a href="http://en.wikipedia.org/wiki/Metcalfe's_Law">Metcalfe's Law</a> predicts-- as greater numbers of people gain access to the internet, the more inexorable the draw is on everyone else to get connected. Asking someone if they have an email address these days feels almost as ridiculous as asking them whether they have a telephone. Of course they do. How could they live without one?
</p>
<p>
Which leads me to wonder: <b>does offline mode still matter in an increasingly online world?</b> I can definitely see value in building an occasionally connected app. The network isn't always reliable. Or fast. But the idea that an application has to be completely functional with <i>no</i> connection to the internet grows more and more absurd with every passing year.
</p>
<p>
I think Dare Obasanjo <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=d88189d3-759d-44ca-aa45-4117b5a03143">put it best</a>:
</p>
<p>
</p>
<blockquote>
For a lot of computer users, their computer is an overpriced paperweight if it doesn't have an Internet connection. They can't read the news, can't talk to their friends via IM, can't download music to their iPods, can't people watch on Facebook or MySpace, can't share the pictures they just took with their digital cameras, can't catch up on the goings on at work via email, they can't look up driving directions, can't check the weather report, can't do research for any reports they have to write, and the list goes on.
</blockquote>
<p>
I already feel like my home computers are nearly useless without a connection to the internet. And internet connectivity is an absolute requirement when I'm on-site with customers; without it, I can't research any problems I might encounter. Lack of internet connectivity is a major impediment today. But in another five or ten years, it'll be paralyzing.
</p>
<p>
If you think you need a pure offline mode in your application, consider carefully. Do you really want to bet against the internet?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/does-offline-mode-still-matter/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Code Smaller ]]></title>
<link>https://blog.codinghorror.com/code-smaller/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Unless you've been living under a rock for the last few years, you've probably heard about the game <a href="http://en.wikipedia.org/wiki/Katamari_Damacy">Katamari Damacy</a>. The gameplay consists of little more than <i>rolling stuff up</i> into an ever-increasing ball of stuff. That's literally all you do. You start by rolling up small things like matchsticks, thimbles, pushpins, and so on. As the ball gets larger, you roll up ever larger and larger items. Eventually, your Katamari ball gets so large you end up rolling together cities, mountains, clouds-- eventually entire <i>planets</i>. It's unbelievably fun, and completely mesmerizing.
</p>
<p>
After I played for a while, I realized that <b>Katamari Damacy is a game about <i>the scale of life</i></b>, reminiscent of <a href="http://www.powersof10.com/">the classic Eames powers of ten movie</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
</p>
<p>
As Bob Koss points out, <a href="http://blog.objectmentor.com/articles/2006/12/21/size-matters">code has a natural tendency to become a giant Katamari ball of "stuff"</a>, too:
</p>
<p>
</p>
<blockquote>
I travel a lot and I get to visit a lot of different companies. No matter which industry a company is in or which programming language a team is using, there is one commonality in all of the code that I see Ã¢â‚¬â€œ classes are just too damn big and methods are just too damn long.
<p>
We programmers must take matters into our own hands and become masters of our domains. Unless we take action, things are just going to get bigger and bigger until we have a real mess on our hands.
</p>
</blockquote>
<p>
Bob's <a href="http://blog.objectmentor.com/articles/2006/12/21/size-matters">article</a> is about <b>managing the scale of your code</b>:
</p>
<p>
</p>
<blockquote>
This notion of breaking a class into smaller and smaller pieces is exactly opposite to what I learned when I first started studying OO. Way back when I worried about bad-hair days, people believed that a class should encapsulate everything that concerned it. A Customer class would know the business rules of being a Customer as well as how to retrieve itself from the database and display it's data. That's a fine idea, provided the database schema never changes, the display never changes, or the business rules never change. If any one of those responsibilities change, we are at a high risk of breaking other things that are coupled to it.
</blockquote>
<p>
So many aspects of software development can be summarized as <b>small is beautiful</b>:
</p>
<ul>
<li>The odds of failure for a software project are <a href="http://www.codinghorror.com/blog/archives/000637.html">directly proportional to the size of the project</a>. Slicing a large project into several smaller subprojects is the single most direct way to increase your project's chances of success.
</li>
<li>The relationship between lines of code and bugs is completely linear. Fewer code means fewer bugs.
</li>
<li>Smaller code avoids TL; DR (Too Long; Didn't Read) syndrome.  The less code there is to read, the higher the odds are that someone <i>will</i> actually read it.
</li>
<li>If you <a href="http://www.codinghorror.com/blog/archives/000497.html">keep your dependencies to a minimum</a>, your code will be simpler and easier to understand.
</li>
</ul>
<p>
It's up to us to resist the natural tendency of any project to snowball into a giant rolling Katamari ball of code. <b>Code smaller!</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/code-smaller/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Origami Software and Crease Patterns ]]></title>
<link>https://blog.codinghorror.com/origami-software-and-crease-patterns/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Robert J. Lang isn't just a physicist and a software developer-- he's also <a href="http://www.newyorker.com/printables/fact/070219fa_fact_orlean">one of the world's foremost paper-folding artists</a>:
</p>
<p>
</p>
<blockquote>
The laser cutter was growling away, scoring one of Lang's Hanji sheets. He twiddled with his computer. On the screen was a lacy geometric pattern. Lang had designed it with software he started writing in 1990 called <a href="http://www.langorigami.com/science/treemaker/treemaker5.php4">TreeMaker</a>, which is well known in origami circles; it was the first software that would translate "tree" forms -- that is, anything that sort of resembles a stick figure, such as people or bugs -- into crease patterns. Another program he wrote, <a href="http://www.langorigami.com/science/reffinder/reffinder.php4">ReferenceFinder</a>, converts the patterns into step-by-step folding instructions. This secured his position as the most technologically ambitious of the origami masters. In 2004, he was an artist-in-residence at M.I.T., and gave a now famous lecture about origami and its relationship to mathematical notions, like circle packing and tree theory.
</blockquote>
<p>
On <a href="http://www.langorigami.com/">Mr. Lang's website</a>, you'll find the amazing <a href="http://www.langorigami.com/art/creasepatterns/creasepatterns.php4">crease patterns</a> produced by his software.
</p>
<p>
</p>
<blockquote>
To the non-origami person, the sequence that transforms a sheet of paper into a beautiful folded object can seem miraculous. Even to the origami aficionado, however, the idea that a single drawing of the creases conveys the full folding sequence can seem equally miraculous. But in fact, a crease pattern can sometimes be more illuminating than a detailed folding sequence, conveying not just "how to fold," but also how the figure was originally designed. And thus, it can actually give the folder insight into the thought processes of the origami composer in a way that a step-by-step folding sequence cannot.
</blockquote>
<p>
The crease patterns are almost as beautiful as the origami art itself:
</p>
<p>
<a href="http://www.langorigami.com/art/gallery/gallery.php4?name=mt_diablo_tarantula"><img alt="image placeholder" >
</p>
<p>
<a href="http://www.langorigami.com/art/insects/mt_diablo_tarantula_cp.pdf"><img alt="image placeholder" >
</p>
<p>
It's fascinating stuff. And the science of folding isn't just art; it has numerous real-world uses:
</p>
<p>
</p>
<blockquote>
For centuries, origami patterns had at most thirty steps; now they could have hundreds. And as origami became more complex it also became more practical. Scientists began applying these folding techniques to anything -- medical, electrical, optical, or nanotechnical devices, and even to strands of DNA -- that had a fixed size and shape but needed to be packed tightly and in an orderly way.
</blockquote>
<p>
Lang provides three practical implementations of Origami on his site: the design of <a href="http://www.langorigami.com/science/optigami/optigami.php4">laser optics</a>, <a href="http://www.langorigami.com/science/airbag/airbag.php4">car airbags</a>, and <a href="http://www.langorigami.com/science/eyeglass/eyeglass.php4">telescopes</a>.
</p>
<p>
(via <a href="http://www.kottke.org/07/02/folding-origami-robert-lang">Jason Kottke</a>)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/origami-software-and-crease-patterns/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's In a Version Number, Anyway? ]]></title>
<link>https://blog.codinghorror.com/whats-in-a-version-number-anyway/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I remember when Microsoft announced that Windows 4.0 would be known as <a href="http://en.wikipedia.org/wiki/Windows_95">Windows 95</a>. At the time, it seemed like a radical, unnecessary change -- naming software with <i>years</i> instead of <i>version numbers</i>? Inconceivable! How will users of Windows 3.1 possibly know what software version they should upgrade to?
</p>
<p>
In retrospect, switching away from software version numbers to years seems like one of the wisest decisions Microsoft ever made.
</p>
<p>
</p>
<ul>
<li>
<b>Users don't care about version numbers.</b> Major, minor, alpha, beta, build number.. what does it all mean?  What users <i>might</i> care about is knowing whether or not the software they're running is current. A simple date is the most direct way to communicate this to the user.
<p>
</p>
</li>
<li>
<b>A model year is easy to understand.</b> Why should it take two arbitrary numbers and a decimal point to identify what software you're using? We identify tons of consumer products using a simple model year designator. Software should be no different.
<p>
</p>
</li>
<li>
<b>Version numbers don't scale.</b> Once you get beyond ten versions, what's the point of meticulously counting every new release? Better to stamp it with a date and move on.
</li>
</ul>
<p>
Microsoft Office 2003 is a far more meaningful name than Microsoft Office 11. And Firefox 2007 would be a much better name than Firefox 2.0 for all the same reasons.
</p>
<p>
But version numbers live on, at least for programmers. Here's a quick survey of version numbers for the software running on my machine at the moment:
</p>
<p>
</p>
<pre>
7.0.6000.16386
8.1.0178.00
11.11
2.7.0.0
2.5.10 / build 6903
2.0 build 0930
0122.1848.2579.33475
2.0.50727.312
2.0.0.1
1.8.20061.20418
</pre>
<p>
As you can see, there's not even a commonly accepted pattern for version numbers. In .NET, the <a href="http://msdn2.microsoft.com/en-us/library/system.version.aspx">version number convention</a> is:
</p>
<p>
<code>(Major version).(Minor version).(Revision number).(Build number)</code>
</p>
<p>
But it's hardly universal. And even if it was, what does all this meticulously numbered version data get us? What does it mean? Why have version numbers at all? It's partly because version number is an expected software convention. And partly because programmers never met a piece of arbitrarily detailed metadata they didn't love. Personally, <b>I like to think of version numbers as dogtags for your software</b>. Like dogtags, they're primarily designed for use <i>in the event of an emergency</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In the event of a software problem-- if, on the battlefield, you hear someone screaming "medic!"-- it is useful to consult the dogtags so you know exactly what version of the software you're dealing with.
</p>
<p>
But software version numbers, even arbitrarily detailed programmer version numbers, can't seem to avoid dates, either. Jensen Harris <a href="http://blogs.msdn.com/jensenh/archive/2005/11/11/491779.aspx">explains the Microsoft Office version numbering scheme</a>:
</p>
<p>
</p>
<blockquote>
The most interesting thing to watch for is the first 4-digit number you encounter.  In the examples above, 5608 and 3417.  These are what we refer to as the "build number."  Every few days during the development cycle, we compile all of the code in Office and turn it into a "build": essentially an installable version of all the work everyone's done up until that point.  Eventually, a build becomes "final" and that is the one that ends up on CDs and in the store.
<p>
The 4-digit build number is actually an encoded date which allows you tell when a build was born.  The algorithm works like this:
</p>
<p>
</p>
<ul>
<li>Take the year in which a project started.  For Office "12", that was 2003.
</li>
<li>Call January of that year "Month 1."
</li>
<li>The first two digits of the build number are the number of months since "Month 1."
</li>
<li>The last two digits are the day of that month.
</li>
</ul>
<p>
So, if you have build 3417, you would do the following math: "Month 1" was January 2003.  "Month 13" was January 2004.  "Month 25" was January 2005.  Therefore, "Month 34" would be October 2005. 3417 = October 17, 2005, which was the date on which Office 12 build 3417 started. For Office 2003 and XP both, "Month 1" was January 2000.  So, the final build of Office 2003, 5608, was made on August 8, 2003.
</p>
</blockquote>
<p>
So Microsoft Office version numbers end up containing three relevant bits of data:
</p>
<p>
</p>
<ol>
<li>the software generation (Office 97, Office XP, Office 2003, Office 2007), which is patently obvious to anyone using the software-- and can be directly inferred from the build date anyway.
</li>
<li>the date of the build.
</li>
<li>the number of builds done after "code freeze".
</li>
</ol>
<p>
Of those three, how many are actually useful to users? How many are useful to developers?
</p>
<p>
On the whole, I encourage software developers to <b>avoid confounding users with version numbers</b>. That's what leads to crappy ideas like <a href="http://www.cyberpunkreview.com/movie/decade/1990-1999/virtuosity/">SID 6.7</a> and even crappier movies like <a href="http://en.wikipedia.org/wiki/Virtuosity">Virtuosity</a>. We brought it on ourselves by letting our geeky, meaningless little construct of major and minor version numbers spill over into pop culture. It's not worth it. Let's reel it back in.
</p>
<p>
Whenever possible, <b>use simple dates instead of version numbers</b>, particularly in the public names of products. And if you absolutely, positively must use version numbers internally, make them dates anyway: be sure to encode the date of the build somewhere in your version number.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-in-a-version-number-anyway/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Beyond JPEG ]]></title>
<link>https://blog.codinghorror.com/beyond-jpeg/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's surprising that the venerable <a href="http://en.wikipedia.org/wiki/JPEG">JPEG image compression standard</a>, which dates back to 1986, is <strong>still the best we can do for photographic image compression</strong>. I can't remember when I encountered my first JPEG image, but JPEG didn't appear to enter practical use <a href="http://www.vias.org/pngguide/chapter07_01.html">until the early 90's</a>.
</p>
<p>
There's nothing <em>wrong</em> with JPEG. It's a perfectly serviceable image compression format. But there are newer, more modern choices these days. There's even a sequel of sorts to JPEG known as <a href="http://en.wikipedia.org/wiki/JPEG_2000">JPEG 2000</a>. It's the logical heir to the JPEG throne.
</p>
<p>
The promise of JPEG 2000 is <strong>higher image quality in much smaller file sizes</strong>, at the minor cost of <a href="http://wilshipley.com/blog/2005/09/jpeg2000-cool-but-slow.html">additional CPU time</a>. And since <a href="http://www.codinghorror.com/blog/archives/000044.html">we always seem to have a lot more CPU time than bandwidth</a>, this is a perfect tradeoff. You may remember my <a href="http://www.codinghorror.com/blog/archives/000629.html">comparsion of JPEG compression levels</a> entry from last year. Let's see what happens when we take the two worst-looking images from that comparison – the ones with JPEG compression factor 40 and 50 – and use JPEG 2000 to produce images of (nearly) the exact same size:
</p>
<table>
<tbody>
<tr>
<td>JPEG, ~8,200 bytes</td>
<td>JPEG 2000, ~8,200 bytes
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.codinghorror.com/files/lena512color-50.jp2"><img alt="image placeholder" >
</td>
</tr>
<tr>
<td>JPEG, ~10,700 bytes</td>
<td>JPEG 2000, ~10,700 bytes
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<a href="http://www.codinghorror.com/files/lena512color-40.jp2"><img alt="image placeholder" >
</td>
</tr>
</tbody>
</table>
<p>
No current web browsers can render JPEG 2000 (.jp2) images, so what you're seeing are extremely high quality JPEG versions of the JPEG 2000 images. Click on the images to download the actual JPEG 2000 files; most modern photo editing software can view them natively.
</p>
<p>
JPEG 2000 not only compresses more efficiently, it also does <a href="http://ai.fri.uni-lj.si/~aleks/jpeg/artifacts.htm">a better job of hiding its compression artifacts</a>, too. It takes a lot more bits per pixel to create a JPEG image that looks as good as a JPEG 2000 image. But if you're willing to <a href="http://www.fnordware.com/j2k/jp2samples.html">pump up the file size</a>, you aren't losing any fidelity by presenting JPEG images.
</p>
<p>
Microsoft, as Microsoft is wont to do, offers a closed-source alternative to JPEG 2000 known as <a href="http://en.wikipedia.org/wiki/HD_Photo">HD Photo or Windows Media Photo</a>. As of late 2006, Microsoft <a href="http://blogs.msdn.com/billcrow/archive/2006/11/17/introducing-hd-photo.aspx">made the format 100% royalty free</a>, and support for HD Photo is <a href="http://news.com.com/Vista+to+give+HD+Photo+format+more+exposure/2100-1045_3-6153730.html">included in Windows Vista</a> and .NET Framework 3.0. According to <a href="http://www.compression.ru/video/codec_comparison/wmp_codecs_comparison_en.html">this Russian study</a>, Files in Microsoft's HD Photo format (.hdp, .wdp) are comparable to-- but <em>not better than</em>-- JPEG 2000. The <a href="http://www.compression.ru/video/codec_comparison/pdf/wmp_codec_comparison_en.pdf">study PDF</a> has lots of comparison images, so you can decide for yourself.
</p>
<p>
Unfortunately, it doesn't really matter which next-generation image compression format is better, since <em>nobody uses them</em>. Microsoft neglected to include support for HD Photo in Internet Explorer 7. And Firefox doesn't currently support JPEG 2000, either. It's a bit of a mystery, because there's an <a href="http://bugzilla.mozilla.org/show_bug.cgi?id=36351">seven year-old open bug on JPEG 2000</a>, and the <a href="http://www.openjpeg.org/index.php?menu=main">OpenJPEG library</a> seems like a logical fit.
</p>
<p>
Until a commonly used web browser supports JPEG 2000 or HD Photo, there's no traction. I hope the next browser releases can <strong>move us beyond the ancient JPEG image compression format</strong>.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/beyond-jpeg/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Everybody Loves BitTorrent ]]></title>
<link>https://blog.codinghorror.com/everybody-loves-bittorrent/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The traditional method of distributing large files is to put them on a central server. Each client then downloads the file directly from the server. It's a gratifyingly simple approach, but <i>it doesn't scale</i>. For every download, the server consumes bandwidth equal to the size of the file. You probably don't have enough bandwidth to serve a large file to a large audience, and even if you did, your <a href="https://blog.codinghorror.com/the-economics-of-bandwidth/">bandwidth bill would go through the roof</a>. The larger the file, the larger the audience, the worse your bandwidth problem gets. It's <a href="https://blog.codinghorror.com/the-popularity-tax/">a popularity tax</a>.</p>
<p>With <a href="http://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a>, you also start by placing your large file on a central server. But once the downloading begins, something magical happens: as clients download the file, <strong>they share whatever parts of the file they have with each other</strong>. Clients can opportunistically connect with any other client to obtain multiple parts of the file at once. And it scales perfectly: as file size and audience size increases, the bandwidth of the BitTorrent distribution network also increases. Your server does less and less work with each connected client. It's an elegant, egalitarian way of sharing large files with large audiences.</p>
<p><strong>BitTorrent radically shifts the economics of distribution</strong>. It's one of the most miraculous ideas ever conceived on the internet. As far as I'm concerned, there should be a Nobel prize for computing, and <a href="http://en.wikipedia.org/wiki/Bram_Cohen">the inventor of BitTorrent</a> should be its first recipient.</p>
<p>There's a great <a href="http://www.codinghorror.com/blog/archives/000777.html">Processing visualization</a> of BitTorrent in action which explains it far better than I can. The <a href="http://aphid.org/btsim/">original visualization</a> is not only down semi-permanently, but also written for an ancient version of <a href="http://processing.org/">Processing</a>. I grabbed a cached copy of the code and updated it for the latest version of Processing.</p>
<p><img alt="image placeholder" >
<p>This meager little animated GIF doesn't do the highly dynamic, real-time nature of the visualization justice. I highly recommend <a href="http://processing.org/download/index.html">downloading Processing</a> and <a href="http://www.codinghorror.com/blog/files/bittorrent-visualization-processing.txt">downloading the updated bittorrent visualization code</a>, so you can see the process from start to finish on your own machine. It's beautiful.</p>
<p>But as as wonderful and clever as BitTorrent is, it isn't perfect. As an avid BitTorrent user, I've noticed the following problems:</p>
<ol>
<li>
<p><strong>BitTorrent is a terrible Long Tail client</strong>.</p>
<p>The efficiency of BitTorrent is predicated on popularity. The more people downloading, the larger the distribution network gets. But if what you want is obscure or unpopular – part of <a href="http://www.thelongtail.com/">the long tail</a> – BitTorrent is painfully, brutally slow. With only a handful of clients sharing the workload, you're better off using traditional distribution methods.</p>
</li>
<li>
<p><strong>BitTorrent, although distributed, is still centralized</strong>.</p>
<p>Download work is shared by the clients, but how do the clients locate each other? Traditionally this is done through a centralized server "tracker", or list of peers. This means BitTorrent is vulnerable to attacks on the centralized server. Once the server is out of commission, the clients have no way of locating each other, and the whole distribution network grinds to a halt. There are alternatives which allow clients to share the list of peers amongst themselves, such as <a href="http://en.wikipedia.org/wiki/Distributed_hash_table">distributed hash tables</a>, but centralized tracking is more efficient.</p>
<p>Also, in order to even begin a BitTorrent download, you must first know where to obtain a .torrent file. It's a chicken-and-egg problem which also implies the existence of a centralized server out there somewhere.</p>
</li>
<li>
<p><strong>BitTorrent is unsuitable for small files, even if they are extremely popular.</strong></p>
<p>The BitTorrent distribution network is predicated on clients sharing pieces of the file during the download period. But if the download period is small, the opportunity window for sharing is also small; at any given time only a few users will be downloading. This is another scenario where you're unlikely to find any peers, so you're better off with traditional distribution methods.</p>
</li>
<li>
<p><strong>BitTorrent relies on client altruism.</strong></p>
<p>There's no rule that says clients <i>must</i> share bandwidth while they're downloading. Although most BitTorrent clients default to uploading the maximum amount a user's upstream connection allows, it's possible to dial the upload rate down to nothing if you're greedy. And some users may have their firewalls configured in such a way that they <i>can't</i> upload data, even if they wanted to. There's no way to punish bad peers for not sharing, or reward good peers for sharing more.</p>
<p>Furthermore, every torrent needs a "seed" – a peer with 100% of the file downloaded – connected at all times. If there is no seed, no matter how many peers you have, none of the peers will never be able to download the entire file. It's considered a courtesy to stay connected if you have 100% of the file downloaded and no other seeds are available. But again, this is a convention, not a requirement. It's entirely possible for a torrent to "die" when there are no seeds available.</p>
</li>
</ol>
<p>The BitTorrent model is innovative, but it isn't suitable for every distribution task. The centralized server model is superior in most cases. But <strong>centralized distribution is a tool for the rich</strong>. Only highly profitable organizations can afford massive amounts of bandwidth. BitTorrent, in comparison, is highly democratic. BitTorrent gives the people whatever they want, whenever they want it – by collectively leveraging the tiny trickle of upstream bandwidth doled out by most internet service providers.</p>
<p>But just because it's democratic doesn't mean BitTorrent has to be synonymous with intellectual piracy. BitTorrent has legitimate uses, such as <a href="http://arstechnica.com/news/posts/1079538547.html">distributing World of Warcraft patches</a>. And Amazon's S3 directly <a href="http://noisemore.wordpress.com/2006/03/14/amazon-s3-has-bittorrent-support/">supports the torrent protocol</a>.</p>
<p>BitTorrent, in short, <strong>puts distribution choices back in the hands of the people</strong>. And that's why everybody loves BitTorrent. Everyone, that is, except the <a href="http://en.wikipedia.org/wiki/MPAA">MPAA</a> and <a href="http://en.wikipedia.org/wiki/RIAA">RIAA</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/everybody-loves-bittorrent/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Because They All Suck ]]></title>
<link>https://blog.codinghorror.com/because-they-all-suck/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The release of Windows Vista has caused an unfortunate resurgence in that eternal flame of computer religious wars, <a href="http://www.worth1000.com/galleries.asp?rel=Mac+vs%2E+PC&amp;display=photoshop&amp;id=5478"><strong>Mac vs. PC</strong></a>. Everywhere I go, somebody's explaining in impassioned tones why their pet platform is better than yours. It's all so tedious.</p>
<p><img alt="image placeholder" >
<p>Personally, I had my fill of Mac versus PC arguments by 1994. I remember spending untold hours on the America Online forums endlessly debating the merits of PCs and Macs with <a href="http://www.rossrubin.com/outofthebox/">Ross Rubin</a> and other unsavory characters. But all that arguing never seemed to result in anything other than more arguments. Eventually, if you're more interested in <em>using</em> computers than endlessly arguing about them, you outgrow the arguments. And yet somehow, nearly fifteen years later, we're all happily retreading the same tired old Mac vs. PC ground.</p>
<p>I have a problem with this.</p>
<p>You might read Charles Petzold's ironically titled <a href="http://www.charlespetzold.com/blog/2006/12/250913.html">It Just Works</a> as an anti-Mac diatribe. It certainly casts Apple in an unflattering light; Petzold's poor mother can't seem to catch a break.</p>
<p> </p>
<blockquote>Perhaps if my mother used lots of various Mac applications and stuck in lots of external devices, the machine would "just work" quite well. But she basically only uses email, so perhaps that's the problem. Just about every time I visit my mother in Jersey, I am called upon to boot up that dreadful machine and do something so it "just works" once again. For awhile she had a problem where certain spam emails would hang the email program upon viewing, but they couldn't be deleted without first being viewed. (Gosh, that was fun.) Presumably some patch to fix this little problem is among the 100 megabytes of updates waiting to be downloaded and installed, but my mother has a dial-up and we're forced to forego this 100 meg download. And besides, the slogan isn't "It just works with 100 megabytes of updates."</blockquote>
<p>But if you read closely, as I did, you'll see that <strong>the experience wouldn't have been any better on a Windows PC</strong>. For a PC of that vintage, it's likely Petzold would have had to install the enormous Windows XP Service Pack 2 update to bring it up to date, which is certainly no less of a hassle than going from OS X 10.2 to OS X 10.4.</p>
<p>That's because Macs and PCs share one crucial flaw: <strong>they're both computers</strong>.</p>
<p>My computer frustrates and infuriates me on a daily basis, and it's been this way since I first laid my hands on a keyboard. Every computer I've ever owned-- including the ones with an Apple logo-- has been a colossal pain in the neck. Some slightly more so than others, but any device designed as a general purpose "do-everything" computing machine is destined to disappoint you eventually. It's inevitable.</p>
<p>The only truly sublime end-user experiences I've had have been with computers that <em>weren't</em> computers-- specialized devices, such as <a href="http://www.tivo.com/">Tivo</a>, the <a href="http://en.wikipedia.org/wiki/Pilot_1000">original Palm Pilot</a>, the <a href="http://wii.com/">Nintendo Wii</a>, and so forth.</p>
<p>General purpose computing devices are designed to be all things to all people. As a direct consequence, they will always be rife with compromises, pitfalls, and disappointments. <strong>That's the first secret of using computers: they all suck.</strong> Which makes the entire Mac vs. PC debate relative degrees of moot. I learned this lesson early in life; evidently some people are still struggling with it.</p>
<p>Computers do have one strong suit: they're unparalleled tools for writing, photography, programming, composing music, and creating art. It's the only reason to deal with the pain of owning one. As the Guardian's Charlie Brooker notes, <a href="http://www.guardian.co.uk/commentisfree/story/0,,2006031,00.html">the Mac vs. PC debate has an insidious side-effect</a> that can distract you from this key benefit:</p>
<p> </p>
<blockquote>Ultimately the <a href="http://www.youtube.com/results?search_query=%22get+a+mac%22">[Get a Mac advertising] campaign's</a> biggest flaw is that it perpetuates the notion that consumers somehow "define themselves" with the technology they choose. If you truly believe you need to pick a mobile phone that "says something" about your personality, don't bother. You don't have a personality. A mental illness, maybe - but not a personality. Of course, that hasn't stopped me slagging off Mac owners with a series of sweeping generalisations for the past 900 words, but that is what the ads do to PCs. Besides, that's what we PC owners are like - unreliable, idiosyncratic and gleefully unfair. And if you'll excuse me now, I feel an unexpected crash coming.</blockquote>
<p>That's the other problem with the Mac vs. PC debate: it completely misses the point. <a href="http://www.codinghorror.com/blog/archives/000186.html">Computers aren't couture, they're screwdrivers</a>. Your screwdriver rocks, and our screwdriver sucks. So what? They're screwdrivers. If you really want to convince us, <strong>stop talking about your screwdriver, and show us what you've created with it</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/because-they-all-suck/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ URL Rewriting to Prevent Duplicate URLs ]]></title>
<link>https://blog.codinghorror.com/url-rewriting-to-prevent-duplicate-urls/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As a software developer, you may be familiar with <a href="http://www.artima.com/intv/dry.html">the DRY principle</a>: don't repeat yourself. It's absolute bedrock in software engineering, and it's covered beautifully in <a href="http://www.amazon.com/exec/obidos/ASIN/020161622X/codihorr-20">The Pragmatic Programmer</a>, and even more succinctly in <a href="http://www.pragmaticprogrammer.com/articles/may_04_oo1.pdf">this brief IEEE software article</a> (pdf). If you haven't committed this to heart by now, go read these links first. We'll wait.
</p>
<p>
Scott Hanselman <a href="http://www.hanselman.com/blog/GooglePageRanksConsideredSubtle.aspx">recently found out the hard way</a> that the DRY principle also applies to URLs. Consider the multiple ways you could get to this very page:
</p>
<p>
</p>
<ul>
<li>http://codinghorror.com/blog/
</li>
<li>http://www.codinghorror.com/blog/
</li>
<li>http://www.codinghorror.com/blog/index.htm
</li>
</ul>
<p>
It's even more problematic for Scott because he has two different domain names that reference the same content.
</p>
<p>
Having multiple URLs reference the same content is undesirable not only from a sanity check DRY perspective, but also because <b>it lowers your PageRank</b>. <a href="http://en.wikipedia.org/wiki/PageRank">PageRank</a> is calculated per-URL. If 50% of your incoming backlinks use one URL, and 50% use a different URL, you aren't getting the full PageRank benefit of those backlinks. The link juice is watered down and divvied up between the two different URLs instead of being concentrated into <i>one</i> of them.
</p>
<p>
So the moral of this story, if there is one, is to <b>keep your URLs simple and standard</b>. This is something the REST crowd has been <a href="http://www.megginson.com/blogs/quoderat/2007/02/15/rest-the-quick-pitch/">preaching for years</a>. You can't knock simplicity. Well, you <a href="http://patricklogan.blogspot.com/2006/02/rest-and-soap.html">can</a>, but you'll be <a href="http://google-code-updates.blogspot.com/2006/12/beyond-soap-search-api.html">crushed by simplicity's overwhelming popularity eventually</a>, so why fight it?
</p>
<p>
Normalizing your URLs isn't difficult if you take advantage of <a href="http://en.wikipedia.org/wiki/Rewrite_engine">URL Rewriting</a>. URL Rewriting has been a <a href="http://httpd.apache.org/docs/2.0/misc/rewriteguide.html">de-facto standard on Apache</a> for years, but has yet to reach mainstream acceptance in Microsoft's IIS. I'm not even sure if <a href="http://www.iis.net/default.aspx?tabid=7">IIS 7</a> supports URL Rewriting out of the box, although its new, highly modular architecture would make it <a href="http://pietschsoft.com/Blog/Post.aspx?PostID=1312">very easy to add support</a>. It's critical that Microsoft get a good reference implementation of an IIS7 URL rewriter out there, preferably one that's compatible with the <a href="http://www.myhtaccess.com/">vast, existing library of mod_rewrite rules</a>.
</p>
<p>
But that doesn't help us today. If you're using IIS today, you have two good options for URL rewriting; they're both installable as <a href="http://www.iis-resources.com/modules/wfsection/article.php?articleid=9">ISAPI filters</a>. I'll show samples for both, using a few common URL rewriting rules that I personally use on my website.
</p>
<p>
The first is <a href="http://www.isapirewrite.com/">ISAPI Rewrite</a>. ISAPI Rewrite isn't quite free, but it's reasonably priced, and most importantly, it's <b>nearly identical in syntax to the Apache mod_rewrite standard</b>. It's also quite mature, as it's been through quite a few revisions by now.
</p>
<p>
</p>
<pre>
[ISAPI_Rewrite]
# fix missing slash on folders
# note, this assumes we have no folders with periods!
RewriteCond Host: (.*)
RewriteRule ([^.?]+[^.?/]) http://$1$2/ [RP]
# remove index pages from URLs
RewriteRule (.*)/default.htm$ $1/ [I,RP]
RewriteRule (.*)/default.aspx$ $1/ [I,RP]
RewriteRule (.*)/index.htm$ $1/ [I,RP]
RewriteRule (.*)/index.html$ $1/ [I,RP]
# force proper www. prefix on all requests
RewriteCond %HTTP_HOST ^test.com [I]
RewriteRule ^/(.*) http://www.test.com/$1 [RP]
# only allow whitelisted referers to hotlink images
RewriteCond Referer: (?!http://(?:www.good.com|www.better.com)).+
RewriteRule .*.(?:gif|jpg|jpeg|png) /images/block.jpg [I,O]
</pre>
<p>
The second option, <a href="http://cheeso.members.winisp.net/IIRF.aspx">Ionic's ISAPI Rewrite Filter</a>, is completely free. This filter has improved considerably since the last time I looked at it, and it appears to be a viable choice now. However, it uses its own rewrite syntax that is <i>similar</i> to the Apache mod_rewrite standard, but different enough to require some rework.
</p>
<p>
</p>
<pre>
# fix missing slash on folders
# note, this assumes we have no folders with periods!
RewriteRule (^[^.]+[^/]$) $1/ [I,RP]
# remove index pages from URLs
RewriteRule  (.*)/default.htm$ $1/ [I,RP]
RewriteRule  (.*)/default.aspx$ $1/ [I,RP]
RewriteRule  (.*)/index.htm$ $1/ [I,RP]
RewriteRule  (.*)/index.html$ $1/ [I,RP]
# force proper www. prefix on all requests
RewriteCond %{HTTP_HOST} ^test.com [I]
RewriteRule ^/(.*) http://www.test.com/$1 [I,RP]
# only allow whitelisted referers to hotlink images
RewriteCond %{HTTP_REFERER} ^(?!HTTP_REFERER)
RewriteCond %{HTTP_REFERER} ^(?!http://www.good.com) [I]
RewriteCond %{HTTP_REFERER} ^(?!http://www.better.com) [I]
RewriteRule .(?:gif|jpg|jpeg|png)$ /images/block.jpg [I,L]
</pre>
<p>
The Ionic filter still has some quirks, but I loved its default logging capability. I could tell exactly what was happening with my rules, blow by blow, with a quick glance at the log file. However, I had a lot of difficulty getting the Ionic filter to install-- I could only get it to work in IIS 5.0 isolation mode, no matter what I tried. Clearly a work in progress, but a very promising one.
</p>
<p>
Of course, the few rewrite rules I presented above-- URL normalization and <a href="http://www.codinghorror.com/blog/archives/000561.html">image hotlink prevention</a>-- are merely the tip of the iceberg.
</p>
<p>
They don't call it the Swiss Army Knife of URL Manipulation for nothing. <b>URL rewriting should be an integral part of every web developer's toolkit.</b> It'll increase your DRYness, it'll increase your PageRank, and <a href="http://www.megginson.com/blogs/quoderat/2007/02/15/rest-the-quick-pitch/">it's also central to the concept of REST</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/url-rewriting-to-prevent-duplicate-urls/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Use ZIP, Use RAR ]]></title>
<link>https://blog.codinghorror.com/dont-use-zip-use-rar/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
When I wrote <a href="http://www.codinghorror.com/blog/archives/000735.html">Today is "Support Your Favorite Small Software Vendor Day"</a>, I made a commitment to spend at least $20 per month supporting my fellow independent software developers. <a href="http://www.win-rar.com/rarproducts.html">WinRAR</a> has become increasingly essential to my toolkit over the last year, so this month, <a href="http://www.win-rar.com/125.html?prod=winrar">I'm buying a WinRAR license</a>.
</p>
<p>
Sure, ZIP support is built into most operating systems, but the support is rudimentary at best. I particularly dislike the limited "compressed folder wizard" I get by default in XP and Vista. In contrast, WinRAR is full-featured, powerful, and integrates seamlessly with the shell. There's a reason <a href="http://www.donationcoder.com/Reviews/Archive/ArchiveTools/index.html">WinRAR won the best archive tool roundup at DonationCoder</a>. And WinRAR is very much a living, breathing piece of software. It's frequently updated with neat little feature bumps and useful additions; two I noticed over the last year were dual-core support and real-time stats while compressing, such as estimated compression ratio and predicted completion time.
</p>
<p>
WinRAR fully supports creating and extracting ZIP archives, so choosing WinRAR doesn't mean you'll be forced into using the RAR compression format. But you should use it, because <b>RAR, as a compression format, <i>clobbers</i> ZIP. It produces much smaller archives in roughly the same time</b>. If you're worried the person on the receiving end of the archive won't have a RAR client, you can create a self-extracting executable archive (or SFX) at a minimal cost of about 60 KB additional filesize.
</p>
<p>
RAR also supports <a href="http://www.win-rar.com/solidarchive.html">solid archives</a>, so it can exploit intra-file redundancies. ZIP does not. This is a big deal, because it can result in a substantially smaller archive when you're compressing a lot of files. When I <a href="http://www.codinghorror.com/blog/archives/000522.html">compressed all the C# code snippets</a>, the difference was enormous:
</p>
<p>
</p>
<table width="150">
<tr>
<td>ZIP</td>
<td align="right">229 KB
</td>
</tr>
<tr>
<td>RAR</td>
<td align="right">73 KB
</td>
</tr>
</table>
<p>
But even in an apples-to-apples comparison, RAR offers some of the very best "bang for the byte" of all compression algorithms. Consider this recent, comprehensive <a href="http://www.maximumcompression.com/data/summary_mf3.php">multiple file compression benchmark</a>. The author measured both compression size and compression time to produce an efficiency metric:
</p>
<p>
</p>
<blockquote>
The most efficient (read: useful) program is calculated by multiplying the compression time (in seconds) it took to produce the archive with the power of the archive size divided by the lowest measured archive size.
<p>
2 ^ (((Size/SmallestSize)) - 1) / 0.1) * ArchiveTime
</p>
<p>
The lower the score, the better. The basic idea is a compressor X has the same efficiency as compressor Y if X can compress twice as fast as Y and resulting archive size of X is 10% larger than size of Y.
</p>
</blockquote>
<p>
And sure enough, if you sort the results by efficiency, WinRAR rises directly to the top. Its scores of 1871 (Good) and 1983 (Best) rank third and fourth out of 200. The top two spots are held by an archiver I've never heard of, <a href="http://www.geocities.com/sbcarchiver/">SBC</a>.
</p>
<p>
</p>
<blockquote>
WinRAR and SBC 0.970 score very well on efficiency. Both SBC and WinRK are capable of compressing the 301 MB testset down to 82 MB [a ~73% compression ratio] in under 3 minutes. People looking for good (but not ultimate) and fast compression should have a look at those two programs.
</blockquote>
<p>
The <a href="http://www.maximumcompression.com/data/summary_mf3.php">raw data on the comparison page</a> is a little hard to parse, so I pulled the data into Excel and created some alternative views of it. Here's a graph of <b>compression ratio versus time</b>, sorted by compression ratio, for all compared archive programs:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
What I wanted to illustrate with this graph is that beyond about 73% compression ratio, <a href="http://www.codinghorror.com/blog/archives/000313.html">performance falls off a cliff</a>. This is something I've <a href="http://www.codinghorror.com/blog/archives/000313.html">noted before</a> in previous compression studies.  You don't just hit the point of diminishing returns in compression, you slam into it like a brick wall. That's why <b>the time scale is logarithmic</b> in the above graph. Look at the massive differences in time as you move toward the peak compression ratio:
</p>
<p>
</p>
<table width="300">
<tr>
<td>72.58%</td>
<td align="right">02:54</td>
<td align="right">WinRAR 3.62
</td>
</tr>
<tr>
<td>75.24%</td>
<td align="right">11:20</td>
<td align="right">UHARC 0.6b
</td>
</tr>
<tr>
<td>77.16%</td>
<td align="right">30:38</td>
<td align="right">DRUILCA 0.5
</td>
</tr>
<tr>
<td>78.83%</td>
<td align="right">05:51:19</td>
<td align="right">PAQ8H
</td>
</tr>
<tr>
<td>79.70%</td>
<td align="right">08:30:03</td>
<td align="right">WinRK 3.0.3
</td>
</tr>
</table>
<p>
Note that I cherry-picked the most efficient archivers out of this data, so this represents <i>best case</i> performance. Is an additional two percent of compression worth taking five times longer? Is an additional four percent worth <i>ten</i> times longer? Under the right conditions, possibly. But the penalty is severe, and the reward miniscule.
</p>
<p>
If you're interested in crunching <a href="http://www.maximumcompression.com/data/summary_mf3.php">the multiple file compression benchmark study data</a> yourself, I converted it to a few different formats for your convenience:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/files/compression-comparison-excel-file.zip">Download Excel spreadsheet</a> (36 KB)
</li>
<li>
<a href="http://spreadsheets.google.com/pub?key=pKxDW35algYclyZXMRfMLOA">Google Spreadsheet</a> (view-only)
</li>
<li>
<a href="http://spreadsheets.google.com/ccc?key=pKxDW35algYclyZXMRfMLOA&amp;hl=en_US">Google Spreadsheet</a> (editable, but need Google login)
</li>
</ul>
<p>
Personally, I recommend the Excel version. I had major performance problems with the Google spreadsheet version.
</p>
<p>
After poring over this data, I'm more convinced than ever. RAR offers a nearly perfect blend of compression efficiency and speed across all modern compression formats. And WinRAR is an exemplary GUI implementation of RAR. It's almost a no-brainer. Except in cases where backwards compatibility trumps all other concerns, <b>we should abandon the archaic ZIP format-- and switch to the power and flexibility of WinRAR.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-use-zip-use-rar/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Revisiting 7-ZIP ]]></title>
<link>https://blog.codinghorror.com/revisiting-7-zip/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In my previous post, I <a href="http://www.codinghorror.com/blog/archives/000798.html">extolled the virtues of WinRAR and the RAR archive format</a>. I disregarded <a href="http://www.7-zip.org/">7-ZIP</a> because it didn't do well in <a href="http://www.maximumcompression.com/data/summary_mf3.php">that particular compression study</a>, and because my previous experiences with it had shown it to be <a href="http://www.codinghorror.com/blog/archives/000313.html">efficient, but brutally slow</a>.</p>
<p>But that's no longer true. Consider the following test I just conducted:</p>
<ul>
<li>Two files: a 587 MB virtual hard disk file, and a 11 KB virtual machine file.
</li>
<li>Test rig is a Dual Core Athlon X2 4800+.
</li>
<li>All default GUI settings were used.
</li>
<li>All extracting and archiving done from one physical hard drive to another, to reduce impact of disk contention.
</li>
</ul>
<table width="600px">
<tr>
<td></td>
<td align="right">Extraction</td>
<td align="right">Compression</td>
<td align="right">Size
</td>
</tr>
<tr>
<td>WinRAR 3.70 beta 2</td>
<td align="right">0:39</td>
<td align="right">3:09</td>
<td align="right">135 MB
</td>
</tr>
<tr>
<td>7-ZIP 4.20</td>
<td align="right">-</td>
<td align="right">6:04</td>
<td align="right">127 MB
</td>
</tr>
<tr>
<td>7-ZIP 4.44 beta</td>
<td align="right">0:40</td>
<td align="right">3:03</td>
<td align="right">125 MB
</td>
</tr>
</table>
<p><b>7-ZIP performance has doubled over the last two years.</b> And it's slightly more efficient at compression, too. That's impressive.</p>
<p>Performance is no longer a reason to choose WinRAR over 7-ZIP. Granted, this is a sample size of one, a single test on a single machine, but it's hard to ignore the dramatic reversal of fortune.</p>
<p>I still like WinRAR's ultra-slick shell integration. But 7-ZIP is a viable competitor now in terms of raw clock time performance, and as always, it tends to produce smaller archives than RAR. This more than addresses my previous criticisms. Mea culpa, 7-ZIP.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/revisiting-7-zip/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ You Want a 10,000 RPM Boot Drive ]]></title>
<link>https://blog.codinghorror.com/you-want-a-10000-rpm-boot-drive/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I don't go out of my way to recommend building your own computer. I do it, but I'm an OCD-addled, pain-loving masochist. You're usually better off buying whatever cut-rate OEM box Dell is hawking at the moment, particularly now that Intel has finally abandoned the awful Pentium 4 CPU series and is back in the saddle with its excellent Core Duo processor. PC parts are so good these days it's difficult to make a bad choice, no matter what you buy.
</p>
<p>
If you really <i>must</i> build your own computer, sites like Tech Report provide excellent advice in the form of <a href="http://techreport.com/etc/2007q1/system-guide/index.x?pg=2">their system guides</a>. However, their guide sets the bar a little too low for my tastes. There are a few <b>baseline requirements for any new computer build</b> that aren't negotiable for me:
</p>
<p>
</p>
<ul>
<li>current dual core chip, such as the Core Duo 2 or Athlon 64 X2
</li>
<li>minimum of 2 GB of memory
</li>
<li>modern PCI express video card with 256mb or more of memory, such as the NVIDIA 7600GS, or the ATI Radeon X1650. Both of these cards can be found for about $100. Whatever you do, avoid on-board video, because it's universally crappy. The rule of thumb I use is this: if you're spending significantly less than $100 on your video card, you're making a terrible mistake.
</li>
</ul>
<p>
It's not expensive. At today's prices, you're looking at around $800 for a new system based on these parts. Build that up and you've got a machine that can handle anything you throw at it, from cutting-edge games to full resolution high definition video playback. Oh yeah, and it compiles code pretty fast, too. If you're an avid gamer you might possibly want to throw another $50 to $100 at the video card for higher resolutions, but that's about it.
</p>
<p>
But one of the recommendations I make often gets some unexpected resistance. I believe every new PC build should have <b>two hard drives</b>:
</p>
<p>
</p>
<ol>
<li>small 10,000 RPM boot drive
</li>
<li>large 7,200 RPM data/apps/games/media drive
</li>
</ol>
<p>
I am a total convert to the <a href="http://www.wdc.com/en/products/Products.asp?DriveID=189">Western Digital Raptor series</a> of 10,000 RPM SATA hard drives. Maybe you're skeptical that a hard drive could make that much difference to a computer's performance. Well, I started out as a skeptic, too. But once I sat down and actually <i>used</i> a computer with a 10,000 RPM drive, my opinion did a complete about-face. I was blown away by how responsive and snappy it felt compared to my machine with a 7,200 RPM hard drive. It's a substantial difference that I continue to feel every day in typical use. <b>Don't underestimate the impact of hard drive performance on your everyday use of the computer.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The difference in performance between a 7,200 RPM boot drive and a 10,000 RPM boot drive is not subtle in any way. But don't take my word for it. Surf the benchmarks yourself:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.storagereview.com/articles/200601/WD1500ADFD_4.html">StorageReview.com's review of the 150GB WD Raptor</a>
</li>
<li>
<a href="http://www.anandtech.com/storage/showdoc.aspx?i=2760&amp;p=7">AnandTech's review of the 150GB WD Raptor</a>
</li>
<li>
<a href="http://techreport.com/reviews/2006q2/raptor-wd1500/index.x?pg=1">TechReport's review of the 150GB WD Raptor</a>
</li>
</ul>
<p>
Unfortunately, the Raptors aren't large drives, and they're expensive on a per-megabyte basis. Current pricing is about $140 for the 74 GB model, and $180 for the 150 GB model. But once you factor in the incredible performance, and the idea that your don't need a lot of space on your primary drive because your secondary drive will be the large workhorse storage area, I think it's a completely reasonable tradeoff.
</p>
<p>
A number of people have expressed concerns that a 10,000 RPM drive will be run hot and noisy. I am <a href="http://www.codinghorror.com/blog/archives/000665.html">a noise fanatic</a>, and I can assure you that this is not the case. According to the <a href="http://www.storagereview.com/article...500ADFD_7.html">StorageReview noise and heat analysis</a>, the Raptor is squarely in the ballpark with its 7,200 RPM peers. I mount all my drives with <a href="http://www.sorbothane.com/">sorbothane</a>, and I use eggcrate foam on nearby surfaces to further reduce any reflected noise. Once I do this, the Raptor is no noisier than any other 3.5" desktop hard drive I've used.
</p>
<p>
Setting aside the performance argument for a moment, using two hard drives also provides additional flexibility. Although <a href="http://www.codinghorror.com/blog/archives/000335.html">I cannot recommend RAID 0 on the desktop</a>, there are clear benefits to using two standalone hard drives. You can isolate your essential user data from the operating system by storing it on the larger, secondary drive. This gives you the freedom to blow away your primary OS drive with relative impunity. It's also <a href="http://www.codinghorror.com/blog/archives/000714.html">optimal for virtual machine use</a>, as one drive can be dedicated to OS functions and the other can act exclusively as a virtual disk. There are plenty of usage scenarios where taking advantage of two hard drive spindles can provide a serious performance boost, such as extracting a large archive from one drive to another.
</p>
<p>
It's gotten to the point now where <b>I won't even consider building a machine <i>without</i> a Raptor as the boot drive</b>. Sure, your computer may have 2 or even 4 gigabytes of memory, but going to disk is inevitable. And every time you go to disk, you'll become thoroughly spoiled by the speed of the Raptor.
</p>
<p>
You may not know it yet, but <b>you want a 10,000 RPM boot drive, too</b>. In the words of Scott Hanselman: <a href="http://www.hanselman.com/blog/ImTotallyVistaedNowUpgradingTheFamilyToVista.aspx">Go on. Treat yourself</a>. I guarantee you won't be disappointed.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/you-want-a-10000-rpm-boot-drive/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Can't Programmers.. Program? ]]></title>
<link>https://blog.codinghorror.com/why-cant-programmers-program/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I was incredulous when I read <a href="http://weblog.raganwald.com/2007/01/dont-overthink-fizzbuzz.html">this observation from Reginald Braithwaite</a>:</p>
<blockquote>
Like me, the author is having trouble with the fact that <a href="http://www.joelonsoftware.com/items/2005/01/27.html">199 out of 200</a> applicants for every programming job can't write code at all. I repeat: <i>they can't write any code whatsoever</i>.
</blockquote>
<p>The author he's referring to is Imran, who is evidently <a href="http://tickletux.wordpress.com/2007/01/24/using-fizzbuzz-to-find-developers-who-grok-coding/">turning away lots of programmers who can't write a simple program</a>:</p>
<blockquote>
<p>After a fair bit of trial and error I've discovered that people who struggle to code don't just struggle on big problems, or even smallish problems (i.e. write a implementation of a linked list). <i>They struggle with tiny problems</i>.</p>
<p>So I set out to develop questions that can identify this kind of developer and came up with a class of questions I call "FizzBuzz Questions" named after a game children often play (or are made to play) in schools in the UK. An example of a Fizz-Buzz question is the following:</p>
<p>Write a program that prints the numbers from 1 to 100. But for multiples of three print "Fizz" instead of the number and for the multiples of five print "Buzz". For numbers which are multiples of both three and five print "FizzBuzz".</p>
<p>Most good programmers should be able to write out on paper a program which does this in a under a couple of minutes. Want to know something scary? <b>The majority of comp sci graduates can't. I've also seen self-proclaimed senior programmers take more than 10-15 minutes to write a solution.</b></p>
</blockquote>
<p>Dan Kegel <a href="http://www.kegel.com/academy/getting-hired.html">had a similar experience hiring entry-level programmers</a>:</p>
<blockquote>
<p>A surprisingly large fraction of applicants, even those with masters' degrees and PhDs in computer science, fail during interviews when asked to carry out basic programming tasks. For example, I've personally interviewed graduates who can't answer "Write a loop that counts from 1 to 10" or "What's the number after F in hexadecimal?" Less trivially, I've interviewed many candidates who can't use recursion to solve a real problem. These are basic skills; anyone who lacks them probably hasn't done much programming.</p>
<p>Speaking on behalf of software engineers who have to interview prospective new hires, I can safely say that we're tired of talking to candidates who can't program their way out of a paper bag. If you can successfully write a loop that goes from 1 to 10 in every language on your resume, can do simple arithmetic without a calculator, and can use recursion to solve a real problem, you're already ahead of the pack!</p>
</blockquote>
<p>Between Reginald, Dan, and Imran, I'm starting to get a little worried. I'm more than willing to cut freshly minted software developers slack at the beginning of their career. Everybody has to start somewhere. But <b>I am disturbed and appalled that any so-called programmer would apply for a job without being able to write the simplest of programs.</b> That's a slap in the face to anyone who writes software for a living.</p>
<p>The <a href="http://www.codinghorror.com/blog/archives/000635.html">vast divide between those who can program and those who cannot program</a> is well known. I assumed anyone applying for a job as a programmer had already crossed this chasm. Apparently this is not a reasonable assumption to make. Apparently, FizzBuzz style screening is <i>required</i> to keep interviewers from wasting their time interviewing programmers who can't program.</p>
<p>Lest you think the FizzBuzz test is too easy –  and it is blindingly, intentionally easy –  a commenter to Imran's post notes its efficacy:</p>
<blockquote>
<p>I'd hate interviewers to dismiss [the FizzBuzz] test as being too easy - in my experience it is genuinely astonishing how many candidates are incapable of the simplest programming tasks.</p>
</blockquote>
<p><b>Maybe it's foolish to begin interviewing a programmer without looking at their code first.</b> At Vertigo, we require a code sample before we even proceed to the phone interview stage. And our on-site interview includes a small coding exercise. Nothing difficult, mind you, just a basic exercise to go through the motions of building a small application in an hour or so. Although there have been one or two notable flame-outs, for the most part, this strategy has worked well for us. It lets us focus on actual software engineering in the interview without <a href="http://www.codeslate.com/2007/01/you-dont-bury-survivors.html">resorting to tedious puzzle questions</a>.</p>
<p>It's a shame you have to do so much pre-screening to <b>have the luxury of interviewing programmers who can actually <i>program</i></b>. It'd be funny if it wasn't so damn depressing. I'm <a href="http://www.codinghorror.com/blog/archives/000771.html">no fan of certification</a>, but it does make me wonder if Steve McConnell was on to something with all his talk of <a href="http://www.amazon.com/exec/obidos/ASIN/0321193679/codihorr-20">creating a true profession of software engineering</a>.</p>
<p><font color="red">Due to high volume, comments for this entry are now closed.</font></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-cant-programmers-program/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ FizzBuzz: the Programmer's Stairway to Heaven ]]></title>
<link>https://blog.codinghorror.com/fizzbuzz-the-programmers-stairway-to-heaven/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Evidently writing about <a href="http://blog.codinghorror.com/why-cant-programmers-program/">the FizzBuzz problem</a> on a programming blog results in a nigh-irresistible urge to code up a solution. The comments <a href="http://discourse.codinghorror.com/t/fizzbuzz-solution-dumping-ground/1752">here</a>, <a href="http://www.digg.com/programming/Why_Can_t_Programmers_Program">on Digg</a>, and <a href="http://programming.reddit.com/info/16swb/comments">on Reddit</a> – nearly a thousand in total – are filled with <a href="http://www.haacked.com/archive/2007/02/27/Why_Cant_Programmers._Read.aspx">hastily coded</a> solutions to FizzBuzz. Developers are nothing if not compulsive problem solvers.</p>
<p>It certainly wasn't my intention, but a large portion of the audience interpreted <a href="http://blog.codinghorror.com/why-cant-programmers-program/">FizzBuzz</a> as a challenge. I suppose <strong>it's like walking into Guitar Center and yelling 'most guitarists can't play Stairway to Heaven!'</strong><sup>*</sup></p>
<p>You might be shooting for a rational discussion of Stairway to Heaven as a way to measure minimum levels of guitar competence. But what you'll get, instead, is a <em>blazing guitarpocalypse</em>.</p>
<p><a href="http://www.ironicsans.com/2007/01/celebrity_patents.html"><img alt="image placeholder" >
<p>I'm invoking the <a href="http://www.imdb.com/title/tt0105793/">Wayne's World</a> rule here: Please, <strong>No Stairway to Heaven</strong>.</p>
<iframe width="420" height="315" src="https://www.youtube.com/embed/FOt3r_aNNxE?start=27" frameborder="0" allowfullscreen></iframe>
<p>FizzBuzz was presented as the lowest level of comprehension required to illustrate adequacy. There's no glory to be had in writing code that establishes a <em>minimum</em> level of competency. Even if you can write it in five different languages or in under 50 bytes of code.</p>
<p><strong>The whole point of the original article was to think about <em>why</em> we have to ask people to write FizzBuzz.</strong> The mechanical part of writing and solving FizzBuzz, however cleverly, is irrelevant. Any programmer who cares enough to read programming blogs is already far beyond such a simple problem. FizzBuzz isn't meant for us. It's the ones we can't reach – the programmers who don't read anything – that we're forced to give the FizzBuzz test to.</p>
<p>Good software developers, <a href="http://blog.codinghorror.com/how-not-to-become-a-rockstar-programmer/">even the ones who think they are Rockstars</a>, don't play Stairway to Heaven. And instead of writing FizzBuzz code, they should be thinking about ways to prevent us from <em>needing</em> FizzBuzz code in the first place.</p>
<p>* via <a href="http://weblogs.asp.net/jgalloway">Jon Galloway</a> and Steven Burch.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/fizzbuzz-the-programmers-stairway-to-heaven/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Choosing Anti-Anti-Virus Software ]]></title>
<link>https://blog.codinghorror.com/choosing-anti-anti-virus-software/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Now that Windows Vista has been available for almost a month, the comparative performance benchmarks are in.
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.tomshardware.com/2007/01/29/xp-vs-vista/page11.html#conclusion_ko_for_windows_vista">Windows XP vs. Vista: The Benchmark Rundown</a> (Tom's Hardware)
</li>
<li>
<a href="http://www.anandtech.com/systems/showdoc.aspx?i=2917&amp;p=20">Windows Vista Performance Guide</a> (Anandtech)
</li>
</ul>
<p>
It's about what I expected; rough parity with the performance of Windows XP. Vista's a bit slower in some areas, and a bit faster in others. <b>But shouldn't new operating systems perform <i>better</i> than old ones? There are plenty of low-level improvements under the hood. Why does Vista only <i>break even</i> in performance?</b>
</p>
<p>
To be fair, Vista does a lot more than XP. I don't want to get into the whole XP vs. Vista argument here, but suffice it to say that <a href="http://en.wikipedia.org/wiki/Features_new_to_Windows_Vista">the list of new features in Vista is quite extensive</a>-- although perhaps not as extensive as some would like.  <a href="http://www.codinghorror.com/blog/archives/000766.html">Vista's integrated search</a> alone is enough for me to banish XP from my life forever.
</p>
<p>
Microsoft has gotten a giant security shiner from Windows XP over the last five years. That's why Windows Vista goes out of its way to radically improve security, with new features like User Account Control (UAC) and Windows Defender. The existing security features in XP, such as Windows Firewall and System Protection (aka restore points) were significantly overhauled and improved for Vista, too. Enhanced security is a good thing, but it's never free. <b>In fact, Vista's new security features will slow your PC down more than almost any other kind of software you can install</b>.
</p>
<p>
For best performance, the first thing I do on any new Vista install is this:
</p>
<p>
</p>
<ol>
<li>Turn off Windows Defender
</li>
<li>Turn off Windows Firewall
</li>
<li>Disable System Protection
</li>
<li>Disable UAC
</li>
</ol>
<p>
I've had friends remark how "slow" Vista feels compared to XP, but when I ask them whether they've disabled Defender or UAC, the answer is typically no. Of course your system is going to be slower with all these added security checks. Security is expensive, and <a href="http://en.wikipedia.org/wiki/TANSTAAFL">there ain't no such thing as a free lunch</a>.
</p>
<p>
You might argue that three out of these four security features wouldn't even be necessary in the first place <b>if Windows had originally followed the well-worn UNIX convention of separating standard users from privileged administrators</b>. I won't disagree with you. But Windows' long historical precedent of setting user accounts up by default as privileged adminstrators is Microsoft's cross to bear. I can't rewrite history, and neither can Microsoft. That's why they came up with these painful, performance-sapping workarounds.
</p>
<p>
But this doesn't mean you have to give up on security entirely in the name of performance. If you're really serious about security, then <b>create a new user account with non-Administrator privileges, and log in as that user</b>. This isn't the default behavior in Vista, sadly. Post install, you get an Administrator-But-Not-Really-Just-Kidding account which triggers UAC on any action that requires administrator privileges. I'm sure this torturous hack was conceived in the name of backwards compatibility, but that doesn't mean <i>we</i> need to perpetuate it. The good news is that Vista is probably the first Microsoft operating system ever where you can actually work effectively as a standard, non-privileged user. As a standard user, you get all the benefits of UAC, Defender, and System Protection.. without all the performance drain.
</p>
<p>
Let me be clear here. I'm not against security. I'm against retrograde, band-aid, <i>destroy all my computer's performance</i> security.
</p>
<p>
Speaking of retrograde, band-aid, <i>destroy all my computer's performance</i> security, the one security feature Vista doesn't bundle is anti-virus software. <b>And nothing cripples your PC's performance quite like anti-virus software.</b> This isn't terribly surprising if you consider what anti-virus software has to do: examine every single byte of data that passes through your computer for evidence of malicious activity. But who needs theory when we have Oli at The PC Spy. Oli conducted <a href="http://www.thepcspy.com/articles/other/what_really_slows_windows_down/5">a remarkably thorough investigation of the real world performance impact of security software on the PC</a>. The results are truly eye-opening:
</p>
<p>
</p>
<table border="0" cellpadding="0" cellspacing="0" width="415">
<tr>
<td>
</td>
<td align="center" colspan="3">Percent slower
</td>
</tr>
<tr>
<td>
</td>
<td align="right" style="border-bottom: silver 1px dotted">Boot<br>
</td>
<td align="right" style="border-bottom: silver 1px dotted">CPU<br>
</td>
<td align="right" style="border-bottom: silver 1px dotted">Disk<br>
</td>
</tr>
<tr>
<td>Norton Internet Security 2006</td>
<td align="right" width="59">46%</td>
<td align="right" width="64">20%</td>
<td align="right" width="64">2369%</td>
</tr>
<tr>
<td>McAfee VirusScan Enterprise 8</td>
<td align="right">7%</td>
<td align="right">20%</td>
<td align="right">2246%</td>
</tr>
<tr>
<td>Norton Internet Security 2007</td>
<td align="right">45%</td>
<td align="right">8%</td>
<td align="right">1515%</td>
</tr>
<tr>
<td>Trend Micro PC-cillin AV  2006</td>
<td align="right">2%</td>
<td align="right">0%</td>
<td align="right">1288%</td>
</tr>
<tr>
<td>ZoneAlarm ISS</td>
<td align="right">16%</td>
<td align="right">0%</td>
<td align="right">992%</td>
</tr>
<tr>
<td>Norton Antivirus 2002</td>
<td align="right">11%</td>
<td align="right">8%</td>
<td align="right">658%</td>
</tr>
<tr>
<td>Windows Live OneCare</td>
<td align="right">11%</td>
<td align="right">8%</td>
<td align="right">512%</td>
</tr>
<tr>
<td>Webroot Spy Sweeper</td>
<td align="right">6%</td>
<td align="right">8%</td>
<td align="right">369%</td>
</tr>
<tr>
<td>Nod32 v2.5</td>
<td align="right">7%</td>
<td align="right">8%</td>
<td align="right">177%</td>
</tr>
<tr>
<td>avast! 4.7 Home</td>
<td align="right">4%</td>
<td align="right">8%</td>
<td align="right">115%</td>
</tr>
<tr>
<td>Windows Defender</td>
<td align="right">5%</td>
<td align="right">8%</td>
<td align="right">54%</td>
</tr>
<tr>
<td>Panda Antivirus 2007</td>
<td align="right">20%</td>
<td align="right">4%</td>
<td align="right">15%</td>
</tr>
<tr>
<td>AVG 7.1 Free</td>
<td align="right">15%</td>
<td align="right">0%</td>
<td align="right">19%</td>
</tr>
</table>
<p>
The worst offenders are the anti-virus suites with real-time protection. According to these results, <b>the latest Norton Internet Security degrades boot time by nearly 50 percent. And no, that isn't a typo in the disk column. It also makes all disk access <i>sixteen times slower!</i></b> Even the better performers in this table would have a profoundly negative impact on your PC's performance. Windows Defender, for example, "only" makes hard drive access 54 percent slower.
</p>
<p>
And yet, despite the crushing performance penalty, anti-virus software is <i>de rigeur</i> in the PC world. Most PC vendors would no sooner ship a PC without preinstalled anti-virus software than they would ship a PC without an operating system (yeah, <a href="http://buranen.info/?p=77">you wish</a>). The very thought of running a PC naked, vulnerable, unprotected from viruses sends system administrators screaming from the room in a panic. When you tell a sysadmin you dislike running anti-virus software, they'll look at you mouth agape, as if you've just told them that you hate puppies and flowers.
</p>
<p>
I don't see why they're so shocked. anti-virus software itself, while not self-propagating like a virus, certainly fits the definition of a Trojan Horse. Once installed on your system, it has a hidden, unadvertised payload: it decimates your computer's performance and your productivity. In my opinion, <b>what we really need is Anti-Anti-Virus software to keep us safe from the ongoing Anti-Virus software pandemic.</b>
</p>
<p>
I've never run any anti-virus software. And Mac or Linux (aka UNIX) users almost never run anti-virus software, either. Am I irresponsible to run all my computers without anti-virus software? Are Mac and Linux users irresponsible for not participating in the culture of fear that Windows anti-virus software vendors propagate? I think it's braver and more responsible to recognize that anti-virus software vendors are not only telling us to be afraid, they are selling us fear. The entire anti-virus software industry is predicated on a bad architectural decision made by Microsoft fifteen years ago. And why, exactly, would any of these vendors want to solve the virus problem and put themselves out of business?
</p>
<p>
I'll certainly agree that <a href="http://www.codinghorror.com/blog/archives/000347.html">you can't stop users from clicking on dancing bunnies</a> if they have their mind set on it. You should have a few different security layers in any modern operating system. But we should also be treating the disease first -- <i>too many damn users running as administrators</i>-- instead of the symptoms.
</p>
<p>
As for remediation strategies, I'm a fan of <a href="http://www.codinghorror.com/blog/archives/000491.html">the virtual machine future</a>. We should treat our operating system like a roll of paper towels. If you get something on it you don't like, you ball it up and throw it away, and rip off a new, fresh one. But if that's too radical for you, I think Jan Goyvaerts is on to something with <a href="http://www.shareware-beach.com/2007/02/the-value-of-os-disk-images/">good old plain common sense backups</a>:
</p>
<p>
</p>
<blockquote>
In fact, with a proper backup system in place, you don't have to be afraid of messing up your system. <b>I don't use any anti-virus or anti-spyware software.</b> If my system starts acting up, I'll restore the backup, and have a guaranteed clean system. No spyware remover can beat that. If I want to play with beta software, I don't have to inconvenience myself by running it in a virtual machine. I do use VMware for testing my applications on clean installs of Windows. But when beta testing new versions of tools I use for development, I want to test them in my actual development environment rather. When the beta expires, I wipe it off by restoring the OS backup.
</blockquote>
<p>
It's not terribly different from my virtual machine solution. Either way, you go back to a known good checkpoint. And I'll take a backup strategy over a computer with hobbled performance any day.
</p>
<p>
This also begs the question of what safety really means. No matter how much security software you install, nagging users with dozens of security dialogs <a href="http://www.codinghorror.com/blog/archives/000571.html">clearly doesn't make users any safer</a>. We should give users a basic level of protection as standard non-adminstrator users. But beyond that, let users make mistakes, and <b>provide automatic, unlimited undo.</b> That's the ultimate safety blanket.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-02-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/choosing-anti-anti-virus-software/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Curly's Law: Do One Thing ]]></title>
<link>https://blog.codinghorror.com/curlys-law-do-one-thing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://blog.objectmentor.com/articles/2007/02/26/outliving-the-great-variable-shortage">Outliving the Great Variable Shortage</a>, Tim Ottinger invokes Curly's Law:
</p>
<p>
</p>
<blockquote>
A variable should mean one thing, and one thing only. It should not mean one thing in one circumstance, and carry a different value from a different domain some other time. It should not mean two things at once. It must not be both a floor polish and a dessert topping. It should mean One Thing, and should mean it all of the time.
</blockquote>
<p>
The late, great Jack Palance played grizzled cowboy Curly Washburn in the 1991 comedy <a href="http://www.imdb.com/title/tt0101587/">City Slickers</a>. Curly's Law is defined in this bit of dialog from the movie:
</p>
<p>
</p>
<blockquote>
<img alt="image placeholder" >
Curly: Do you know what the secret of life is?
<p>
Curly: This.  [holds up one finger]
</p>
<p>
Mitch: Your finger?
</p>
<p>
Curly: One thing. Just one thing. You stick to that and the rest don't mean shit.
</p>
<p>
Mitch: But what is the "one thing?"
</p>
<p>
Curly: [smiles] That's what <i>you</i> have to find out.
</p>
</blockquote>
<p>
<b>Curly's Law, Do One Thing</b>, is reflected in several core principles of modern software development:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.artima.com/intv/dry.html">Don't Repeat Yourself</a>
<br>
If you have more than one way to express the same thing, at some point the two or three different representations will most likely fall out of step with each other. Even if they don't, you're guaranteeing yourself the headache of maintaining them in parallel whenever a change occurs. And change <i>will</i> occur. Don't repeat yourself is important if you want flexible and maintainable software.
<p>
</p>
</li>
<li>
<a href="http://c2.com/xp/OnceAndOnlyOnce.html">Once and Only Once</a>
<br>
Each and every declaration of behavior should occur once, and only once. This is one of the main goals, if not <i>the</i> main goal, when refactoring code. The design goal is to eliminate duplicated declarations of behavior, typically by merging them or replacing multiple similar implementations with a unifying abstraction.
<p>
</p>
</li>
<li>
<a href="http://www.faqs.org/docs/artu/ch04s02.html">Single Point of Truth</a>
<br>
Repetition leads to inconsistency and code that is subtly broken, because you changed only some repetitions when you needed to change all of them. Often, it also means that you haven't properly thought through the organization of your code. Any time you see duplicate code, that's a danger sign. Complexity is a cost; don't pay it twice.
</li>
</ul>
<p>
Although Curly's Law definitely applies to normalization and removing redundancies, <i>Do One Thing</i> is more nuanced than the various restatements of <i>Do Each Thing Once</i> outlined above. It runs deeper. Bob Martin refers to it as <a href="http://butunclebob.com/ArticleS.UncleBob.SrpInRuby">The Single Responsibility Principle</a>:
</p>
<p>
</p>
<blockquote>
<b>The Single Responsibility Principle says that a class should have one, and only one, reason to change</b>. As an example, imagine the following class:
<p>
</p>
<pre>
class Employee
{
public Money calculatePay()
public void save()
public String reportHours()
}
</pre>
<p>
This class violates the SRP because it has three reasons to change:
</p>
<p>
</p>
<ol>
<li>The business rules having to do with calculating pay.
</li>
<li>The database schema.
</li>
<li>The format of the string that reports hours.
</li>
</ol>
<p>
We don't want a single class to be impacted by these three completely different forces. We don't want to modify the Employee class every time the accounts decide to change the format of the hourly report, or every time the DBAs make a change to the database schema, as well as every time the managers change the payroll calculation. Rather, we want to separate these functions out into different classes so that they can change independently of each other.
</p>
</blockquote>
<p>
Curly's Law is about choosing a single, clearly defined goal for any particular bit of code: Do One Thing. That much is clear. But in choosing one thing, you are ruling out an infinite universe of other possible things you <i>could</i> have done. <b>Curly's Law also means consciously choosing what your code <i>won't</i> do.</b> This is much more difficult than choosing what to do, because it runs counter to all the natural generalist tendencies of software developers. It could mean breaking code apart, violating traditional OOP rules, or introducing duplicate code. It's taking one step backward to go two steps forward.
</p>
<p>
Each variable, each line of code, each function, each class, each project should Do One Thing. Unfortunately, we usually don't find out what that one thing <i>is</i> until we've <a href="http://www.codinghorror.com/blog/archives/000071.html">reached the end of it</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/curlys-law-do-one-thing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Your Code: OOP or POO? ]]></title>
<link>https://blog.codinghorror.com/your-code-oop-or-poo/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm not a fan of object orientation for the sake of object orientation. Often the proper OO way of doing things ends up being <a href="http://www.codinghorror.com/blog/archives/000617.html">a productivity tax</a>. Sure, objects are the backbone of any modern programming language, but sometimes I can't help feeling that <a href="http://www.codinghorror.com/blog/archives/000033.html">slavish adherence to objects is making my life a lot more difficult</a>. I've always found <a href="http://www.codinghorror.com/blog/archives/000042.html">inheritance hierarchies to be brittle and unstable</a>, and then there's the massive <a href="http://www.codinghorror.com/blog/archives/000621.html">object-relational divide</a> to contend with. OO seems to bring at least as many problems to the table as it solves.
</p>
<p>
Perhaps Paul Graham <a href="http://www.paulgraham.com/noop.html">summarized it best</a>:
</p>
<p>
</p>
<blockquote>
Object-oriented programming generates a lot of what looks like work. Back in the days of fanfold, there was a type of programmer who would only put five or ten lines of code on a page, preceded by twenty lines of elaborately formatted comments. Object-oriented programming is like crack for these people: it lets you incorporate all this scaffolding right into your source code. Something that a Lisp hacker might handle by pushing a symbol onto a list becomes a whole file of classes and methods. So it is a good tool if you want to convince yourself, or someone else, that you are doing a lot of work.
</blockquote>
<p>
Eric Lippert observed a similar occupational hazard among developers. It's something he calls <a href="http://blogs.msdn.com/ericlippert/archive/2004/03/18/92422.aspx">object happiness</a>.
</p>
<p>
</p>
<blockquote>
What I sometimes see when I interview people and review code is symptoms of a disease I call Object Happiness. Object Happy people feel the need to apply principles of OO design to small, trivial, throwaway projects. They invest lots of unnecessary time making pure virtual abstract base classes -- writing programs where IFoos talk to IBars but there is only one implementation of each interface! I suspect that early exposure to OO design principles divorced from any practical context that motivates those principles leads to object happiness. People come away as OO True Believers rather than OO pragmatists.
</blockquote>
<p>
I've seen so many problems caused by excessive, slavish adherence to OOP in production applications. Not that object oriented programming is inherently bad, mind you, but <b>a little OOP goes a very long way</b>. Adding objects to your code is like adding salt to a dish: use a little, and it's a savory seasoning; add too much and it utterly ruins the meal. Sometimes it's better to err on the side of simplicity, and I tend to favor the approach that results in <i>less</i> code, not <i>more</i>.
</p>
<p>
Given my ambivalence about all things OO, I was amused when <a href="http://weblogs.asp.net/jgalloway/">Jon Galloway</a> forwarded me a link to <a href="http://smacchia.chez-alice.fr/en/Articles.html">Patrick Smacchia's web page</a>. Patrick is a French software developer. Evidently the acronym for object oriented programming is spelled a little differently in French than it is in English: POO.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
That's exactly what I've imagined when I had to work on code that abused objects.
</p>
<p>
But POO code can have another, more constructive, meaning. This blog author argues that OOP pales in importance to POO. <a href="http://a-nickels-worth.blogspot.com/2006/08/eop.html">Programming fOr Others</a>, that is.
</p>
<p>
</p>
<blockquote>
The problem is that programmers are taught all about how to write OO code, and how doing so will improve the maintainability of their code. And by "taught", I don't just mean "taken a class or two". I mean: have pounded into head in school, spend years as a professional being mentored by senior OO
"architects" and only then finally kind of understand how to use properly, some of the time. Most engineers wouldn't consider using a non-OO language, even if it had amazing features. The hype is that major.
<p>
So what, then, about all that code programmers write before their 10 years OO apprenticeship is complete? Is it just doomed to suck?  Of course not, as long as they apply other techniques than OO. These techniques are out there but aren't as widely discussed.
</p>
<p>
The improvement [I propose] has little to do with any specific programming technique. It's more a matter of empathy; in this case, empathy for the programmer who might have to use your code. The author of this code actually thought through what kinds of mistakes another programmer might make, and strove to make the computer tell the programmer what they did wrong.
</p>
<p>
In my experience the best code, like the best user interfaces, seems to magically anticipate what you want or need to do next. Yet it's discussed infrequently relative to OO. Maybe what's missing is a buzzword. So let's make one up, Programming fOr Others, or POO for short.
</p>
</blockquote>
<p>
The principles of object oriented programming are far more important than mindlessly, robotically instantiating objects everywhere:
</p>
<p>
</p>
<ul>
<li>
<a href="http://stevemcconnell.com/ieeesoftware/bp02.htm">Information hiding and encapsulation</a>
</li>
<li>Simplicity
</li>
<li>Re-use
</li>
<li>Maintainability and empathy
</li>
</ul>
<p>
Stop worrying so much about the objects. Concentrate on satisfying the <i>principles</i> of object orientation rather than object-izing everything. And most of all, <b>consider the poor sap who will have to read and support this code after you're done with it</b>. That's why POO trumps OOP: programming as if people mattered will always be a more effective strategy than satisfying the <a href="http://www.codinghorror.com/blog/archives/000165.html">architecture astronauts</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/your-code-oop-or-poo/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Reducing Your Website's Bandwidth Usage ]]></title>
<link>https://blog.codinghorror.com/reducing-your-websites-bandwidth-usage/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Over the last three years, this site has become <a href="http://www.alexa.com/data/details/traffic_details?site0=www.codinghorror.com/blog/&amp;range=3y&amp;url=http://www.codinghorror.com/blog/">far more popular than I ever could have imagined</a>. Not that I'm complaining, mind you. Finding an audience and opening a dialog with that audience is the whole point of writing a blog in the first place.
</p>
<p>
But on the internet, <a href="http://www.codinghorror.com/blog/archives/000044.html">popularity is a tax</a>. Specifically, a bandwidth tax. When <a href="http://www.codinghorror.com/blog/archives/000781.html">Why Can't Programmers.. Program?</a> went viral last week, outgoing bandwidth usage spiked to <b>nearly 9 gigabytes in a single day</b>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
That was enough to completely saturate two T1 lines-- nearly 300 KB/sec-- for most of the day. And that includes the time we disabled access to the site entirely in order to keep it from taking out the whole network.* After that, it was clear that something had to be done. <b>What can we do to reduce a website's bandwidth usage?</b>
</p>
<p>
</p>
<p>
<b>1. Switch to an external image provider.</b>
</p>
<p>
</p>
<div style="margin-left:20px; margin-bottom:15px;">
Unless your website is an all-text affair, images will always consume the lion's share of your outgoing bandwidth. Even on this site, which is <i>extremely</i> minimalistic, the size of the images dwarf the size of the text. Consider <a href="http://www.codinghorror.com/blog/archives/000801.html">my last blog post</a>, which is fairly typical:
<p>
</p>
<table width="275">
<tr>
<td>Size of post text</td>
<td align="right">~4,900 bytes
</td>
</tr>
<tr>
<td>Size of post image</td>
<td align="right">~46,300 bytes
</td>
</tr>
<tr>
<td>Size of site images</td>
<td align="right">~4,600 bytes
</td>
</tr>
</table>
<p>
The text only makes up about ten percent of the content for that post. To make a dent in our bandwidth problem, we must deal with the other ninety percent of the content-- the images-- first.
</p>
<p>
Ideally, we shouldn't have to serve up any images at all: we can outsource the hosting of our images to an external website. There are a number of free or nearly-free image sharing sites on the net which make this a viable strategy:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.imageshack.us/">Imageshack</a><br>
ImageShack offers free, unlimited storage, but has a 100 MB per hour bandwidth limit for each image. This sounds like a lot, but do the math: that's 1.66 MB per minute, or about 28 KB per second. And the larger your image is, the faster you'll burn through that meager allotment. But it's incredibly easy to use-- you don't even have to sign up-- and according to their <a href="http://reg.imageshack.us/content.php?page=faq">common questions page</a>, anything goes as long as it's not illegal.
<p>
</p>
</li>
<li>
<a href="http://www.flickr.com/">Flickr</a><br>
Flickr offers a free basic account with limited upload bandwidth and limited storage. Download bandwidth is unlimited. Upgrading to a paid Pro account for $25/year removes all upload and storage restrictions. However, Flickr's <a href="http://www.flickr.com/terms.gne?legacy=1">terms of use</a> warn that "professional or corporate uses of Flickr are prohibited", and all external images require a link back to Flickr.
<p>
</p>
</li>
<li>
<a href="http://www.photobucket.com/">Photobucket</a><br>
Photobucket's free account has a storage limit and a download bandwidth limit of 10 GB per month (that works out to a little over 14 MB per hour). Upgrading to a paid Pro account for $25/year removes the bandwidth limit. I couldn't find any relevant restrictions in their <a href="http://photobucket.com/terms.php">terms of service</a>.
<p>
</p>
</li>
<li>
<a href="http://aws.amazon.com/s3">Amazon S3</a><br>
Amazon's S3 service allows you to direct-link files at a cost of 15 cents per GB of storage, and 20 cents per GB transfer. It's unlikely that would add up to more than the ~ $2 / month that seems to be the going rate for the other unlimited bandwidth plans. It has worked well for <a href="http://www.holovaty.com/blog/archive/2006/04/07/0927">at least one other site</a>.
</li>
</ul>
<p>
I like ImageShack a lot, but it's unsuitable for any kind of load, due to the hard-coded bandwidth limit. Photobucket offers the most favorable terms, but Flickr has a better, more mature toolset. Unfortunately, I didn't notice the terms of use restrictions at Flickr until I had already purchased a Pro account from them. So we'll see how it goes. <font color="red">Update: it looks like Amazon S3 may be the best long-term choice, as many (if not all) of these photo sharing services are blocked in corporate firewalls.</font>
</p>
<p>
Even though this ends up costing me $25/year, it's still an incredible bargain. I am offloading 90% of my site's bandwidth usage to an external host for <a href="http://imdb.com/title/tt0088794/quotes">a measly 2 dollars</a> a month.
</p>
<p>
And as a nice ancillary benefit, I no longer need to <a href="http://www.codinghorror.com/blog/archives/000561.html">block image bandwidth theft with URL rewriting</a>. Images are free and open to everyone, whether it's abuse or not. This makes life much easier for legitimate users who want to view my content in the reader of their choice.
</p>
<p>
Also, don't forget that <a href="http://en.wikipedia.org/wiki/Favicon">favicon.ico</a> is an image, too. It's retrieved more and more often by today's readers and browsers. Make favicon.ico as small as possible, because it can have a <a href="http://www.hanselman.com/blog/FavIconicoCanBeABandwidthHog.aspx">surprisingly large impact on your bandwidth</a>.
</p>
</div>
<p></p>
<p></p>
<b>2. Turn on HTTP compression.</b>
<p>
</p>
<div style="margin-left:20px; margin-bottom:15px;">
Now that we've dealt with the image content, we can think about ways to save space on the remaining content-- the text. This one's a no-brainer. Enable HTTP compression on your webserver for roughly two-thirds reduction in text bandwidth. Let's use <a href="http://www.codinghorror.com/blog/archives/000801.html">my last post</a> as an example again:
<p>
</p>
<table width="325">
<tr>
<td>Post size</td>
<td align="right">63,826 bytes
</td>
</tr>
<tr>
<td>Post size with compression</td>
<td align="right">21,746 bytes
</td>
</tr>
</table>
<p>
We get a 66% reduction in file size for every bit of text served up on our web site-- including all the JavaScript, HTML, and CSS-- by simply flipping a switch on our web server. The benefits of HTTP compression are so obvious it <i>hurts</i>. It's reasonably straightforward to set up <a href="http://www.codinghorror.com/blog/archives/000059.html">in IIS 6.0</a> , and it's extremely easy to set up <a href="http://httpd.apache.org/docs/2.0/mod/mod_deflate.html">in Apache</a>.
</p>
<p>
Never serve content that isn't HTTP compressed. It's as close as you'll ever get to free bandwidth in this world. If you aren't sure that HTTP compression is enabled on your website, use this <a href="http://www.port80software.com/products/httpzip/compresscheck">handy web-based HTTP compression tester</a>, and <i>be</i> sure.
</p>
</div>
<p></p>
<p></p>
<b>3. Outsource Your RSS feeds.</b>
<p>
</p>
<div style="margin-left:20px; margin-bottom:15px;">
Many web sites offer RSS feeds of updated content that users can subscribe to (or "syndicate") in RSS readers. Instead of visiting a website every day to see what has changed, RSS readers automatically pull down the latest RSS feed at regular intervals. Users are free to read your articles at their convenience, even offline. Sounds great, right?
<p>
It is great. Until your ealize just how much bandwidth all that RSS feed polling is consuming. It's <a href="http://blogs.feedburner.com/feedburner/archives/2004/04/feedburner_saved_my_bandwidth.php">staggering</a>. Scott Hanselman told me that <b>half his bandwidth was going to RSS feeds</b>. And Rick Klau noted that 60% of his page views were <a href="http://www.rklau.com/tins/archives/2004/09/10/scoble-on-rss-costs.php">RSS feed retrievals</a>. The entire RSS ecosystem depends on properly coded RSS readers; a single badly-coded reader could pummel your feed, pulling uncompressed copies of your RSS feed down hourly-- even when it hasn't changed since the last retrieval. Now try to imagine <i>thousands</i> of poorly-coded RSS readers, all over the world. That's pretty much where we are today.
</p>
<p>
Serving up endless streams of RSS feeds is something I'd just as soon outsource. That's where <a href="http://www.feedburner.com/">FeedBurner</a> comes in. Although I'll gladly outsource image hosting for the various images I use to complement my writing, I've been hesitant to hand control for something as critical as my RSS feed to a completely external service. I emailed <a href="http://www.hanselman.com/blog/">Scott Hanselman</a>, who switched his site over to FeedBurner a while ago, to solicit his thoughts. He was gracious enough to call me on the phone and address my concerns, even walking me through FeedBurner using his login.
</p>
<p>
I've switched my feed over to FeedBurner as of 3pm today. The switch should be transparent to any readers, since I used some <s>mod_rewrite</s><a href="http://www.codinghorror.com/blog/archives/000797.html">ISAPIRewrite</a> rules to do a seamless, automatic permanent redirect from the old feed URL to <a href="http://feeds.feedburner.com/codinghorror/">the new feed URL</a>:
</p>
<p>
</p>
<pre>
# do not redirect feedburner, but redirect everyone else
RewriteCond User-Agent: (?!FeedBurner).*
RewriteRule .*index.xml$|.*index.rdf$|.*atom.xml$
http://feeds.feedburner.com/codinghorror/ [I,RP,L]
</pre>
<p>
And the best part is that immediately after I made this change, I noticed a huge drop in per-second and per-minute bandwidth on the server. I suppose that's not too surprising if you consider that the feedburner stats page for this feed are currently showing about <b>one RSS feed hit per second</b>. But even compressed, that's still about 31 KB of RSS feed per second that my server no longer has to deal with.
</p>
<p>
It's a substantial savings, and FeedBurner brings lots of other abilities to the table beyond mere bandwidth savings.
</p>
</div>
<p></p>
<p></p>
<b>4. Optimize the size of your JavaScript and CSS</b>
<p>
</p>
<div style="margin-left:20px; margin-bottom:15px;">
The only thing left for us to do now is reduce the size of our text content, with a special emphasis on the elements that are common to every page on our website. CSS and JavaScript resources are a good place to start, but the same techniques can apply to your HTML as well.
<p>
There's a handy <a href="http://www.cssdrive.com/index.php/main/csscompressor/">online CSS compressor</a> which offers three levels of CSS compression. I used it on <a href="http://www.codinghorror.com/blog/styles-site.css">the main CSS file for this page</a>, with the following results:
</p>
<p>
</p>
<table width="325">
<tr>
<td>original CSS size</td>
<td align="right">2,299 bytes
</td>
</tr>
<tr>
<td>after removing whitespace</td>
<td align="right">1,758 bytes
</td>
</tr>
<tr>
<td>after HTTP compression</td>
<td align="right">615 bytes
</td>
</tr>
</table>
<p>
We can do something similar to the JavaScript with this <a href="http://fmarcia.info/jsmin/test.html">online JavaScript compressor</a>, based on Douglas Crockford's <a href="http://javascript.crockford.com/jsmin.html">JSMin</a>. But before I put the JavaScript through the compressor, I went through and refactored it, using shorter variables and eliminating some redundant and obsolete code.
</p>
<p>
</p>
<table width="325">
<tr>
<td>original JS size</td>
<td align="right">1232 bytes
</td>
</tr>
<tr>
<td>after refactoring</td>
<td align="right">747 bytes
</td>
</tr>
<tr>
<td>after removing whitespace</td>
<td align="right">558 bytes
</td>
</tr>
<tr>
<td>after HTTP compression</td>
<td align="right">320 bytes
</td>
</tr>
</table>
<p>
It's possible to use similar whitespace compressors <a href="http://www.alentum.com/ahc/index.htm">on your HTML</a>, but I don't recommend it. I only saw reductions in size of about 10%, which wasn't worth the hit to readability.
</p>
<p>
Realistically, whitespace and linefeed removal is doing work that the compression would be doing for us. We're just adding a dab of human-assisted efficiency:
</p>
<p>
</p>
<table width="375">
<tr>
<td></td>
<td align="right">Raw</td>
<td align="right">Compressed
</td>
</tr>
<tr>
<td>Unoptimized CSS</td>
<td align="right">2,299 bytes</td>
<td align="right">671 bytes
</td>
</tr>
<tr>
<td>Optimized CSS</td>
<td align="right">1,758 bytes</td>
<td align="right">615 bytes
</td>
</tr>
</table>
<p>
It's only about a 10 percent savings once you factor in HTTP compression. The tradeoff is that CSS or JavaScript lacking whitespace and linefeeds has to be pasted into an editor to be effectively edited. I use Visual Studio 2005, which automatically "rehydrates" the code with proper whitespace and linefeeds when I issue the autoformat command.
</p>
<p>
Although this is definitely <a href="http://www.codinghorror.com/blog/archives/000185.html">a micro-optimization</a>, I think it's worthwhile since it reduces the payload of every single page on this website. But there's a reason it's the last item on the list, too. We're just cleaning up a few last opportunities to squeeze every last byte over the wire.
</p>
</div>
<p>
After implementing all these changes, I'm very happy with the results. I see a considerable improvement in bandwidth usage, and my page load times have never been snappier. But, these suggestions aren't a panacea. <b>Even the most minimal, hyper-optimized compressed text content can saturate a 300 KB/sec link if the hits per second are coming fast enough.</b> Still, I'm hoping these changes will let my site weather the next Digg storm with a little more dignity than it did the last one-- and avoid taking out the network in the process.
</p>
<p>
* the ironic thing about this is that <a href="http://www.codinghorror.com/blog/archives/000781.html">the viral post in question</a> was completely HTTP compressed text content <i>anyway</i>. So of all the suggestions above, only the RSS outsourcing would have helped.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/reducing-your-websites-bandwidth-usage/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Using Amazon S3 as an Image Hosting Service ]]></title>
<link>https://blog.codinghorror.com/using-amazon-s3-as-an-image-hosting-service/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/000807.html">Reducing Your Website's Bandwidth Usage</a>, I concluded that my best outsourced image hosting option was <a href="http://www.amazon.com/gp/browse.html?node=16427261">Amazon's S3</a> or Simple Storage Service.
</p>
<p>
S3 is <a href="http://gigaom.com/2006/07/13/startups-embracing-amazon-s3/">a popular choice for startups</a>. For example, SmugMug <a href="http://blogs.smugmug.com/onethumb/2006/11/10/amazon-s3-show-me-the-money/">uses S3 as their primary data storage source</a>. There have been <a href="http://blogs.smugmug.com/onethumb/2007/01/30/amazon-s3-outages-slowdowns-and-problems/">a few minor S3-related bumps at SmugMug</a>, but overall the prognosis appears to be good. After experimenting with S3 myself, I'm sold. The costs are reasonable:
</p>
<p>
</p>
<ul>
<li>No start up fees, no minimum charge
</li>
<li>$0.15 per GB for each month of storage
</li>
<li>$0.20 per GB of data transferred
</li>
</ul>
<p>
It's not exactly unlimited bandwidth, but I was planning to spend $2 a month on image hosting anyway. That buys me 10 GB per month of highly reliable, pure file transfer bandwidth through S3. Beyond that, it's straight pay-as-you-go.
</p>
<p>
Unfortunately, Amazon doesn't provide a GUI or command-line application for easily transferring files to S3; it's only <a href="http://docs.amazonwebservices.com/AmazonS3/2006-03-01/">a set of SOAP and REST APIs</a>.
</p>
<p>
There is <a href="http://www.jungledisk.com/">Jungle Disk</a>, which allows S3 to show up as a virtual drive on your computer, but Jungle Disk offers no way to make files accessible through public HTTP. And as I found out later, Jungle Disk also uses a strange, proprietary file naming and storage structure on S3 when you view it directly. Jungle Disk is a fine backup and offline storage tool (particularly considering how cheap S3 disk storage costs are), but it doesn't offer the level of control that I need.
</p>
<p>
Amazon does provide a number of <a href="http://developer.amazonwebservices.com/connect/kbcategory.jspa?categoryID=47">API code samples</a> in various languages, along with some <a href="http://developer.amazonwebservices.com/connect/kbcategory.jspa?categoryID=55">links to tutorial articles</a>, but beyond that, you're basically on your own. Or so I thought.
</p>
<p>
That was before I found the <a href="http://www.rjonna.com/ext/s3fox.php">S3Fox Organizer for FireFox</a>.
</p>
<p>
<a href="http://www.rjonna.com/ext/s3fox.php"><img alt="image placeholder" >
</p>
<p>
S3Fox is like a dream come true after futzing around with the S3 API. Using S3Fox, I can easily experiment with the S3 service to figure out how it works instead of spending my time struggling with arcane S3 API calls in a development environment. It's a shame Amazon doesn't offer a tool like this to help people understand what the S3 service is and how it works.
</p>
<p>
At any rate, <b>my goal is to use S3 as an image hosting service</b>. I started by uploading an entire folder of images with S3Fox. I had a few problems where S3Fox would mysteriously fail in the middle of a transfer, forcing me to exit all the way out of Firefox. Fortunately, S3Fox also has folder synchronization support, so I simply restarted the entire transfer and told it to skip all files that were already present in S3. After a few restarts, all the files were successfully uploaded. I then granted anonymous access to the entire folder and all of its contents. This effectively exposed all the uploaded images through the public S3 site URL:
</p>
<p>
<code>http://s3.amazonaws.com/</code>
</p>
<p>
All S3 content has to go in what Amazon calls a "Bucket". Bucket names must be <i>globally unique</i>, and you can only create a maximum of 100 Buckets per account. It's easy to see why when you form the next part of the URL:
</p>
<p>
<code>http://s3.amazonaws.com/codinghorrorimg/</code>
</p>
<p>
Each Bucket can hold an unlimited number of "Objects" of essentially unlimited size, with as much arbitrary key-value pair metadata as you want attached. Objects default to private access, but they have explicit access control lists (for Amazon accounts only), and you can make them public. Once we've added an Object, if we grant public read permission to it, we can then access it via the complete site / Bucket / Object URL:
</p>
<p>
<code>http://s3.amazonaws.com/codinghorrorimg/codinghorror-bandwidth-usage.png</code>
</p>
<p>
There's no concept of folders in S3. You can only emulate folder structures by adding Objects with tricky names like <code>subfolder/myfile.txt</code>. And you can't rename Buckets or Objects, as far as I can tell. But at least I can control the exact filenames, which I was unable to do with any other image hosting service.
</p>
<p>
In my testing I ended up uploading the entire contents of my /images folder twice. That cost me a whopping two cents according to my real-time S3 account statement:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's almost like micropayments in action.
</p>
<p>
S3 will probably end up costing me slightly more than the "Unlimited" $25/year accounts available on popular personal photo sharing sites. With S3, there's no illusion of unlimited bandwidth use unconstrained by cost. And personal photo and image sharing sites are often blocked by corporate networks, which makes sense if you consider their intended purpose: <i>informally sharing personal photos</i>. S3 is a more professional image hosting choice; it offers tighter control along with a full set of developer APIs.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/using-amazon-s3-as-an-image-hosting-service/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Getting the Most Out of PNG ]]></title>
<link>https://blog.codinghorror.com/getting-the-most-out-of-png/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>When it comes to image formats on the internet, it's generally a three-way tie between <a href="http://en.wikipedia.org/wiki/JPEG">JPEG</a>, <a href="http://en.wikipedia.org/wiki/GIF">GIF</a>, and <a href="http://en.wikipedia.org/wiki/PNG">PNG</a>. Deciding which image format to use is relatively straightforward; you choose lossy JPEG when you're saving continuous-tone photographic images, and you choose between lossless GIF or lossless PNG when you're saving images with large blocks of the same or similar colors. <a href="http://blog.codinghorror.com/screenshots-jpeg-vs-gif/">See my comparison of GIF/PNG and JPEG</a> if you're not clear on what the difference is. But the choice between GIF and PNG is no contest. PNG is a more modern and vastly improved version of GIF that (almost) completely obsoletes it. <b>You should <i>always</i> choose PNG over GIF</b>, except in the following two circumstances:</p>
<ul>
<li>You want an animated graphic. PNG doesn't support animation. GIF does.</li>
<li>Your image is <em>extremely</em> small, on the order of a few hundred bytes. In my experience, GIF filesizes are smaller in this scenario.</li>
</ul>
<p>In every other way, PNG is the natural heir to GIF. It's copyright-free, it can store all bit depths, it can represent alpha channels, and it offers more efficient compression. But as great as PNG is, there are a few things you should know about PNG to get the most out of it.</p>
<p>Let's start with a representative image. I took a quick screenshot of this website, along with all the browser chrome, transparency, and shadows.  ClearType font rendering is on, and there's a nice mix of text, graphics, and UI. It's a perfect candidate for the lossless PNG file format, because there are large areas of the same colors and hard transitions between them. We want nice, crisp transitions between the white and dark areas of the screenshot.</p>
<img alt="image placeholder" >
<p>The actual size of the screenshot is 1233 x 946. When I save this file directly from Paint Shop Pro as a 24-bit PNG file, I get the following file sizes:</p>
<table width="300">
<tr>
<td>PNG, interlaced</td>
<td align="right">288 KB</td>
</tr>
<tr>
<td>PNG, non-interlaced</td>
<td align="right">212 KB</td>
</tr>
</table>
<p>So here's our first lesson: <b>never save interlaced PNG files</b>.</p>
<ul>
<li>Interlaced PNGs are 35% larger for the single purpose of <a href="http://blog.codinghorror.com/progressive-image-rendering/">progressive rendering</a>.</li>
<li>Progressive rendering is confusing; the image gets less and less blurry over time. As <a href="http://philip.greenspun.com/panda/images">Philip Greenspun so aptly pointed out</a>, readers can't tell when an image is "done".</li>
<li>Standard PNGs have a perfectly acceptable progressive rendering solution without interlacing. They render in obvious and simple fashion, from top to bottom.</li>
</ul>
<p>212 KB is an impressively small filesize for such a large and detailed image. It's a testament to the efficiency of the PNG image format. But we can do better. If we run <a href="http://advsys.net/ken/utils.htm#pngout">Ken Silverman's PNGOUT</a>* on the files, we can crunch them down even smaller:</p>
<table width="300">
<tr>
<td>PNG, interlaced</td>
<td align="right">190 KB</td>
</tr>
<tr>
<td>PNG, non-interlaced</td>
<td align="right">190 KB</td>
</tr>
</table>
<p>First, note that PNGOUT strips out any interlacing. If you have interlaced PNG images, you can expect a very substantial reduction in file size. But even without interlacing, PNGOUT reduces the file size by 22 KB, or nearly 10 percent. I know it doesn't sound like much, but PNG is by definition lossless compression. JPEG is lossy, so as file sizes decrease, <a href="http://blog.codinghorror.com/a-comparison-of-jpeg-compression-levels-and-recompression/">more and more of the image is lost</a>. With PNG, we haven't lost any detail in our images, we've just made them smaller. Folks, <b>this is free bandwidth!</b> It doesn't get much better than that.</p>
<p>To see how effective PNGOUT really is, I ran it on a subset of my /images folder. The trick here is that these images are <i>already</i> optimized; I run <a href="http://optipng.sourceforge.net/">OptiPNG</a> on every file in this folder periodically.</p>
<table width="350">
<tr>
<td></td>
<td align="right">OptiPNG</td>
<td align="right">PNGOUT</td>
</tr>
<tr>
<td>267 PNG files</td>
<td align="right">4.40 MB</td>
<td align="right">4.04 MB</td>
</tr>
</table>
<p>It took a while to run, but we get a further 9% reduction in PNG image size beyond what OptiPNG could do. How is this possible?</p>
<p>I thought the name <a href="http://en.wikipedia.org/wiki/Ken_Silverman">Ken Silverman</a> sounded familiar. Ken, the author of PNGOUT, is the wunderkind behind the original <a href="http://en.wikipedia.org/wiki/Duke_Nukem_3D">Duke Nukem 3D</a> build <a href="http://advsys.net/ken/build.htm">rendering engine</a>, which he wrote at the age of 18.</p>
<img alt="image placeholder" >
<p>Ken is so good, even <a href="http://en.wikipedia.org/wiki/John_Carmack">John Carmack</a> – the author of Doom and Quake, who is widely regarded as a programming god – <a href="http://advsys.net/ken/carmken.htm">respects him</a>. No wonder his little PNG optimizer decimates all the other ones. Always bet on Duke.</p>
<p><b>If you're running a website of any size, and you use PNG images in any quantity, you should <a href="http://advsys.net/ken/utils.htm">run them through PNGOUT</a> to reduce their size.</b> PNGOUT can also convert your existing GIF images to the superior PNG format along the way. And it's so easy to do; here's the Windows command prompt syntax to optimize all PNG images in a folder:</p>
<pre>
for %i in (*.png) do pngout "%i" /y
</pre>
<p>The PNGOUT optimization process isn't particularly speedy, but it hardly matters. This one-time optimization could reduce your image bandwidth usage from 10 to 30 percent. That's an offer I can't refuse.</p>
<p>(* thanks to Kevin Breitenstein for pointing this out to me)</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/getting-the-most-out-of-png/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Dude, Where's My 4 Gigabytes of RAM? ]]></title>
<link>https://blog.codinghorror.com/dude-wheres-my-4-gigabytes-of-ram/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Due to fallout from a recent computer catastrophe at work, I had the opportunity to salvage 2 GB of memory. I installed the memory in my work box, which brings it up to 4 gigabytes of RAM-- 4,096 megabytes in total. But that's not what I saw in System Information:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Only 3,454 megabytes. <i>Dude, where's my 4 gigabytes of RAM?</i>
</p>
<p>
The screenshot itself provides a fairly obvious hint why this is happening: <b>32-bit Operating System</b>.  In any 32-bit operating system, the virtual address space is limited, by definition, to the size of a 32-bit value:
</p>
<p>
</p>
<pre>
2<sup>32</sup> = 4,294,967,296<br>
4,294,967,296 / (1,024 x 1,024) = 4,096
</pre>
<p>
As far as 32-bit Vista is concerned, the world ends at 4,096 megabytes. That's it. That's all there is. No ms.
</p>
<p>
Addressing more than 4 GB of memory is <i>possible</i> in a 32-bit operating system, but it takes nasty hardware hacks like 36-bit <a href="http://en.wikipedia.org/wiki/Physical_Address_Extension">PAE</a> extensions in the CPU, together with nasty software hacks like the <a href="http://en.wikipedia.org/wiki/Address_Windowing_Extensions">AWE API</a>. Unless the application is specifically coded to be take advantage of these hacks, it's confined to 4 GB. Well, actually, <a href="http://www.brianmadden.com/content/content.asp?ID=69">it's stuck with even less-- 2 GB or 3 GB of virtual address space</a>, at least on Windows.
</p>
<p>
OK, so we're limited to 4,096 megabytes of virtual address space on a 32-bit operating system. Could be worse.* We could be back in 16-bit land, where the world ended at 64 <i>kilobytes</i>. Brr. I'm getting the shakes just thinking about segments, and pointers of the near and far variety. Let us never speak of this again.
</p>
<p>
But back to our mystery. Where, exactly, did the other 642 megabytes of my memory go? <a href="http://blogs.msdn.com/oldnewthing/archive/2006/08/14/699521.aspx">Raymond Chen provides this clue</a>:
</p>
<p>
</p>
<blockquote>
In the absence of the /PAE switch, the Windows memory manager is limited to a 4 GB physical address space. Most of that address space is filled with RAM, but not all of it. <b>Memory-mapped devices (such as your video card) will use some of that physical address space, as will the BIOS ROMs.</b> After all the non-memory devices have had their say, there will be less than 4GB of address space available for RAM below the 4GB physical address boundary.
</blockquote>
<p>
Ian Griffiths offers <a href="http://www.interact-sw.co.uk/iangblog/2005/08/05/is3gbenough">a more detailed explanation</a>:
</p>
<p>
</p>
<blockquote>
To address 4GB of memory you need 32 bits of address bus. (Assuming individual bytes are addressable.) This gives us a problem - the same problem that IBM faced when designing the original PC. You tend to want to have more than just memory in a computer - you need things like graphics cards and hard disks to be accessible to the computer in order for it to be able to use them. So just as the original PC had to carve up the 8086's 1MB addressing range into memory (640K) and 'other' (384K), the same problem exists today if you want to fit memory and devices into a 32-bit address range: not all of the available 4GB of address space can be given over to memory.
<p>
For a long time this wasn't a problem, because there was a whole 4GB of address space, so devices typically lurk up in the top 1GB of physical address space, leaving the bottom 3GB for memory. And 3GB should be enough for anyone, right?
</p>
<p>
So what actually happens if you go out and buy 4GB of memory for your PC? Well, it's just like the DOS days - there's a hole in your memory map for the IO. (Now it's only 25% of the total address space, but it's still a big hole.) So the bottom 3GB of your memory will be available, but there's an issue with that last 1GB.
</p>
</blockquote>
<p>
And if you think devices can't possibly need that much memory-mapped IO, I have some sobering news for you: by this summer, you'll be able to buy video cards with <i>1 GB of video memory</i>.
</p>
<p>
To be perfectly clear, this isn't a Windows problem-- <b>it's an x86 hardware problem</b>.  The memory hole is quite literally invisible to the CPU, no matter what 32-bit operating system you choose. The following diagram from Intel illustrates just where the memory hole is:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The proper solution to this whole conundrum is to use a 64-bit operating system. <font color="red">However, even with a 64-bit OS, you'll still be at the mercy of your motherboard's chipset and BIOS; make sure your motherboard supports using 4 GB or more of memory, as outlined in <a href="http://support.microsoft.com/kb/929605/en-us">this MSKB article</a>.</font>
</p>
<p>
</p>
<pre>
2<sup>64</sup> = 18,446,744,073,709,551,616<br>
18,446,744,073,709,551,616 / (1,024 x 1,024) / 8 = 2 exabytes
</pre>
<p>
In case you're wondering, the progression is <i>giga, tera, peta, exa</i>.
</p>
<p>
Although <a href="http://www.codinghorror.com/blog/archives/000435.html">the performance benefits of 64-bit are somewhat dubious on the desktop</a>, <b>a 64-bit OS absolutely essential if you run applications that need to use more than 2 GB of memory.</b> It's not common, but we're getting there.
</p>
<p>
The memory hole for IO still exists in the 64-bit world, but most modern BIOSes allow you to <a href="http://techfiles.de/dmelanchthon/files/memory_hole.pdf">banish the IO memory hole</a> (pdf) to some (for now) ridiculously high limit when you're running a 64-bit OS. Don't get too excited, though. The user-mode virtual address space in 64-bit Windows is <a href="http://msdn.microsoft.com/library/en-us/win64/win64/virtual_address_space.asp">a mere 8 terabytes</a>. Suffice it to say that we won't be running out of physical or virtual address space on 64-bit operating systems for the forseeable future. It's the final solution, at least for the lifetime of everyone reading this blog post today.
</p>
<p>
Here's one parting bit of advice: if, like me, you're planning to stick with a 32-bit operating system for the next few years, <b>don't waste your money on 4 GB of RAM. You won't be able to use it all. Buy 3 GB instead.</b> Every motherboard I'm aware of will happily accept 2 x 1 GB and 2 x 512 MB DIMMs.
</p>
<p>
* Could be <a href="http://imdb.com/title/tt0072431/quotes">raining</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dude-wheres-my-4-gigabytes-of-ram/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Internationalization, SIMS Style ]]></title>
<link>https://blog.codinghorror.com/software-internationalization-sims-style/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Internationalization of software is incredibly challenging. Consider <a href="http://ar.wikipedia.org/wiki/Sandbox">this Wikipedia sandbox page in Arabic</a>, which is a right-to-left (RTL) language:</p>
<img alt="image placeholder" >
<p>Compare that layout with the <a href="http://en.wikipedia.org/wiki/Internationalization_and_localization">Wikipedia page on internationalization and localization in English</a>. Now consider how you'd implement switching between English and Arabic in <a href="http://www.mediawiki.org/">MediaWiki</a>, the software that powers Wikipedia:</p>
<ul>
<li>Every bit of static text on the page has to come out of a unicode string resource file, indexed per-culture.
</li>
<li>Images that happen to contain text, or are otherwise culture-specific, must also be placed in a resource file and indexed per-culture.
</li>
<li>Numbers, currency, and dates must be displayed (and validated) differently depending on what country your audience lives in.
</li>
<li>You could detect the country your users are in, and automatically assume which language they're using. But this is obviously problematic in countries where multiple languages are spoken. Or, you can allow users to manually choose a language the first time they access your application. This is slightly easier in web applications, because you can absorb the ambient language setting from the browser's HTTP headers.
</li>
</ul>
<p>It's a lot of work.</p>
<p>Beyond the purely mechanical grunt work of translation, there are deeper cultural issues to consider, such as avoiding offensive images, colors, or concepts for certain cultures – and how the concepts you're trying to express in the software will map to a given culture. As <a href="http://blogs.msdn.com/larryosterman/archive/2005/01/26/361015.aspx">noted in a related Larry Osterman post</a>, these deeper cultural considerations are collectively known as <em>localization</em>:</p>
<blockquote>
<p>[localization] is a step past translation, taking the certain communication code associated with a certain culture.  There are so many aspects you have to think about such as their moral values, working styles, social structures, etc... in order to get desired (or non-desired) outputs.  This is one of the big reasons that automated translation tools leave so much to be desired - humans know about the cultural issues involved in a language, computers don't.</p>
</blockquote>
<p><a href="http://en.wikipedia.org/wiki/The_Sims">The Sims</a> has a unique solution that sidesteps the software internationalization problem. They invented an entirely new, completely artificial language: <a href="http://en.wikipedia.org/wiki/Simlish">Simlish</a>. <strong>Simlish renders your cultural background irrelevant. When you redefine language as gibberish, it's equally meaningless to everyone.</strong> Or is it? Somehow, The Sims is playable without a lick of translation or localization, without any comprehensible language of any sort.</p>
<blockquote>
Signs in The Sims games often do not contain text; they consist entirely of graphics. For instance, the stop sign in The Sims is a red octagon with a flat, white hand. In The Sims 2 it becomes a white bar instead. The sign for a grocery store depicts a cornucopia, and that of a restaurant shows a hamburger or a place setting.
<p>In The Sims, most text is only distinguishable at very close zooms. On book covers, newspapers and Nightlife's "Sims Must Wash Hands" sign, <strong>the lettering is all nonsense characters that bear about as much resemblance to Latin characters as they do to Cyrillic. Almost no actual characters from any known alphabet are used.</strong> The game uses the Simoleon sign (closely resembling ) as the currency symbol.</p>
<img alt="image placeholder" >
<p>When Sims are writing novels or term papers, dingbats from the Wingdings font appear as text on the screen. The notebooks used for homework contain writing composed of random lines.</p>
</blockquote>
<p>Characters in The SIMS don't just write in Simlish – they <a href="http://thesims2.ea.com/community/interview_04_22_04.php">speak it, too</a>:</p>
<blockquote>
<p>When The Sims was originally designed, <a href="http://en.wikipedia.org/wiki/Will_Wright">Will Wright</a> wanted the language the Sims spoke to be unrecognizable but full of emotion. That way, every player could construct their own story without being confined to a Maxis-written script (to say nothing of the mind-numbing repetition). We experimented with fractured Ukrainian, and the Tagalog language of The Philippines. Will even suggested that perhaps we base the sound on Navajo, inspired by the code talkers of WWII. None of those languages allowed us the sound we were looking for – so we opted for complete improvisation.</p>
</blockquote>
<p>Simlish is, by definition, meaningless. And yet it's surprisingly easy to figure out what a Sim is talking about, even without any visual point of reference or a facial expression to read. The intonation and context of the sounds is enough to extract meaning. Try these two Simlish MP3 samples (<a href="http://www.codinghorror.com/blog/files/sims2-1.mp3">one</a>, <a href="http://www.codinghorror.com/blog/files/sims2-2.mp3">two</a>) and hear for yourself.</p>
<p>Simlish even extends to music. Last year, Maxis <a href="http://www.gamespot.com/pc/strategy/thesims2/news_6119747.html">paid many original artists to re-record their songs with Simlish lyrics</a>:</p>
<blockquote>
<p>Each artist rerecorded one of their songs with new vocal tracks, <strong>replacing English lyrics with nonsensical Sim-speak</strong>. Simlish words don't have any real meaning, so the artists were free to come up with whatever sounded good, as long as English didn't seep in. The result isn't that different from what bands like the Cocteau Twins and Vas already do. The idea is to transcend words and use the human voice to express pure emotion.</p>
<p>Charlotte Martin, whose song "Beautiful Life" finds its way onto the University soundtrack, took things a step further than some of the other artists. She didn't just sing gobbledygook, she made sure all the Simlish words were consistent with their counterparts in the English version.  "It still had the same meaning, I just had to write it in an alien language," Martin said. In rewriting the song, Martin said it changed the way she thinks about lyrics, letting her come at her creation from a more technical standpoint, paying closer attention to syllables and rhythm.</p>
</blockquote>
<p>Probably the funniest example of this is the <a href="http://en.wikipedia.org/wiki/Pussycat_Dolls">Pussycat Dolls'</a> re-recording of "Don't Cha" in Simlish.</p>
<iframe width="480" height="360" src="//www.youtube.com/embed/Y0RDR44uURM" frameborder="0" allowfullscreen></iframe>
<p><a href="http://www.codinghorror.com/files/dont_cha___simlishnicolefancom.mp3">Listen to "Don't Cha" in Simlish</a> (mp3). Singing in gibberish almost makes a Pussycat Dolls song <em>more</em> intelligible. It's brilliant. Doba, baby, <em>doba!</em></p>
<p>Another example is Lily Allen's "Smile". Compare <a href="http://www.youtube.com/watch?v=0WxDrVUrSvI">the original version of "Smile"</a> with the <a href="http://www.youtube.com/watch?v=rJsZhiOhUVg">Simlish re-recording of "Smile"</a>. It works well for that cheeky little song, but it's a little weirder when a morose band like <a href="http://www.youtube.com/watch?v=rvXQhxKodo8">Depeche Mode re-records a song in Simlish</a>.</p>
<iframe width="480" height="360" src="//www.youtube.com/embed/rJsZhiOhUVg" frameborder="0" allowfullscreen></iframe>
<iframe width="640" height="360" src="//www.youtube.com/embed/0WxDrVUrSvI" frameborder="0" allowfullscreen></iframe>
<p>When you hear Simlish, you expect to hear meaningless gibberish. But instead, you hear something else, something unexpected. The absence of language isn't limiting; it's liberating. You move beyond language, from expressing with words to expressing visually, aurally, emotionally:</p>
<blockquote>
<p>For songstress Abra Moore, whose song "Big Sky" was used in the game, singing in Simlish gave her a new perspective on her music. "It's like jazz for me; I just take to it like a duck to water," Moore said. "It was very liberating creatively." The experience made such an impression on Moore that she said she'd consider recording a song in Sim-like scat on a future album. She perceives the emotional lyrics, divorced of a specific meaning, in almost a spiritual light. She's fascinated that fans try to interpret the nonsensical lyrics. It represents the essence of human nature, Moore said, to take meaning from something that has no meaning.</p>
</blockquote>
<p>Spoken words and music are dense with multiple levels of audible meaning. We probably can't take such Simlish liberties with applications and web sites, which are anchored on the flat, one-dimensional medium of text. The challenges of <a href="http://en.wikipedia.org/wiki/Internationalization_and_localization">i18n and l10n</a> are unavoidable for us. But as the Sims shows us, there's a lot to be said for following human conventions which work across all languages and cultures.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-internationalization-sims-style/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Building a Computer the Google Way ]]></title>
<link>https://blog.codinghorror.com/building-a-computer-the-google-way/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you're ever in Silicon Valley, I highly recommend checking out the <a href="http://www.computerhistory.org/">Computer History Museum</a>. Where else can you see a live demonstration of <a href="http://www.computerhistory.org/pdp-1/">the only known working PDP-1 in existence</a>, and actually get to <i>play the original <a href="http://en.wikipedia.org/wiki/Spacewar!">Spacewar</a> on it?</i> I did. It was incredible. I got chills. And my wife was bored beyond belief, but I love her all the more for soldiering through.
</p>
<p>
Beyond the special exhibits, the <a href="http://www.computerhistory.org/virtualvisiblestorage/home.html">Visible Storage area</a> is where the real action is at in the museum. It takes up the majority of the floor space, and it contains every computer I've ever heard of. Among the artifacts in visible storage is one of <b>Google's original servers from 1999</b>:
</p>
<p>
<a href="http://nomano.shiwaza.com/tnoma/blog/archives/002379.html"><img alt="image placeholder" >
 
<a href="http://nomano.shiwaza.com/tnoma/blog/archives/002379.html"><img alt="image placeholder" >
</p>
<p>
<a href="http://nomano.shiwaza.com/tnoma/blog/archives/002379.html"><img alt="image placeholder" >
</p>
<p>
If Google's first production server resembles a hastily cobbled together amalgam of off-the-shelf computer parts circa 1999, well, that's because <i>it is</i>. Just like <a href="http://www.codinghorror.com/blog/archives/000305.html">Google's original servers at Stanford</a>. If you think this rack is scary, you should see what it <i>replaced</i>.
</p>
<p>
Instead of buying whatever pre-built rack-mount servers Dell, Compaq, and IBM were selling at the time, <b>Google opted to hand-build their server infrastructure themselves</b>. The sagging motherboards and hard drives are literally propped in place on handmade plywood platforms. The power switches are crudely mounted in front, the network cables draped along each side. The poorly routed power connectors snake their way back to generic PC power supplies in the rear.
</p>
<p>
Some people might look at these early Google servers and see an amateurish fire hazard. Not me. I see a prescient understanding of <a href="http://www.codinghorror.com/blog/archives/000573.html">how inexpensive commodity hardware would shape today's internet</a>. I felt right at home when I saw this server; it's <i>exactly</i> what I would have done in the same circumstances. This rack is a perfect example of the commodity x86 market D.I.Y. ethic at work: if you want it done right, and done inexpensively, you build it yourself.
</p>
<p>
Even today, Google is serious about exerting total control over the servers in their now-massive server farms. They <a href="http://www.nytimes.com/2006/09/26/technology/26google.html?ex=1173931200&amp;en=372d524a3de3d515&amp;ei=5070">build their own high-efficiency power supplies</a>, and conduct <a href="http://labs.google.com/papers/disk_failures.pdf">fascinating, public research on disk failure</a> (pdf). Current estimates put <a href="http://en.wikipedia.org/wiki/Google_platform">Google's server farm at around 450,000 machines</a>-- and they're still custom built, commodity-class x86 PCs, just like they were in 1999.
</p>
<p>
<b>Like Google, I demand total control over every part of my PC.</b> I've always built my own. Building your own PC isn't for everyone, but if you're willing to add a little elbow grease, the D.I.Y. approach can result in a higher quality, better performing PC-- often at a substantial cost savings.
</p>
<p>
Here's a chart I put together based on my research for the <a href="http://www.hanselman.com/blog/TheCodingHorrorUltimateDeveloperRigThrowdownPart1.aspx">Scott Hanselman Ultimate Developer Rig Throwdown</a>:
</p>
<p>
</p>
<table width="900">
<tr>
<td style="width: 55px">
</td>
<td valign="top">
<strong>
D.I.Y.<br>
"Big Bang" </strong>
</td>
<td valign="top">
<strong>
D.I.Y.<br>
"Little Bang"</strong>
</td>
<td valign="top">
<strong><a href="http://store.apple.com/AppleStore/WebObjects/BizCustom?qprm=78313&amp;family=MacPro">
Mac  Pro</a></strong>
</td>
<td valign="top">
<strong><a href="http://www.dell.com/content/products/features.aspx/cto_xpsdt_410?c=us&amp;cs=19&amp;l=en&amp;s=dhs">
Dell XPS 710</a></strong>
</td>
<td valign="top">
<strong><a href="http://www.dell.com/content/products/features.aspx/cto_xpsdt_410?c=us&amp;cs=19&amp;l=en&amp;s=dhs">
Dell Dimension 410</a></strong>
</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
CPU</td>
<td valign="top">
Intel Core 2 Quad<br>
2.4 GHz </td>
<td valign="top">
Intel Core 2 Duo<br>
2.4 GHz</td>
<td valign="top">
2 x Intel Core 2 Duo<br>
2.66 GHz</td>
<td valign="top">
Intel Core 2 Duo<br>
2.4 GHz</td>
<td valign="top">
Intel Core 2 Duo<br>
2.4 GHz</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
Memory</td>
<td valign="top">
4 GB, DDR 800</td>
<td valign="top">
2 GB, DDR 800</td>
<td valign="top">
1 GB, DDR ECC 667</td>
<td valign="top">
2 GB, DDR 667</td>
<td valign="top">
2 GB, DDR 667</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
Mobo</td>
<td valign="top">
P965 premium</td>
<td valign="top">
P965 budget</td>
<td valign="top">
Intel 5000x</td>
<td valign="top">
unknown</td>
<td valign="top">
unknown</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
Drives</td>
<td valign="top">
2 x 150 GB 10k RPM (RAID 0)<br>
2 x 750 GB (RAID 1)</td>
<td valign="top">
500 GB</td>
<td valign="top">
250 GB</td>
<td valign="top">
500 GB</td>
<td valign="top">
500 GB</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
Video</td>
<td valign="top">
2 x 512 MB X1950 Pro</td>
<td valign="top">
256 MB X1950 Pro</td>
<td valign="top">
256 MB 7300 GT</td>
<td valign="top">
256 MB 7900 GS</td>
<td valign="top">
256 MB 7900 GS</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
Case</td>
<td valign="top">
<a href="http://www.antec.com/us/productDetails.php?ProdID=81800">Antec P180</a><br>
<img alt="image placeholder" >
</td>
<td valign="top">
<a href="http://www.antec.com/us/productDetails.php?ProdID=81800">Antec P180</a>
</td>
<td valign="top">
Apple<br>
<img alt="image placeholder" >
</td>
<td valign="top">
XPS<br>
<img alt="image placeholder" >
</td>
<td valign="top">
Dimension<br>
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
Other</td>
<td valign="top">
Premium PSU<br>
Premium heatsink</td>
<td valign="top">
Premium PSU<br>
Premium heatsink</td>
<td valign="top">
OS X<br>
Bundled software</td>
<td valign="top">
Windows Vista</td>
<td valign="top">
Windows Vista</td>
</tr>
<tr>
<td style="width: 55px; background-color: gainsboro;" valign="top">
Price</td>
<td style="color: red;" valign="top">
$3,500</td>
<td style="color: red;" valign="top">
$1,400</td>
<td style="color: red;" valign="top">
$2,499</td>
<td style="color: red;" valign="top">
$2,039</td>
<td style="color: red;" valign="top">
$1,400</td>
</tr>
</table>
<p>
If you're willing to factor out the cost of the operating system, the D.I.Y. "Little Bang" system offers more bang for the buck than any of its peers. And the "Big Bang" is off the charts, if you have the budget.
</p>
<p>
The lower-end Dell system looks quite similar, but closer inspection reveals otherwise:
</p>
<p>
</p>
<ul>
<li>Dell's use of non-standard case connectors and power supply connectors prevents future upgrades using standard commodity parts.
</li>
<li>The OEM parts used in Dell machines are generally of inferior quality to their retail equivalents. OEM parts are impressive on the surface, but cut corners to lower costs. For example, the use of slower DDR 667 memory; cut-down, featureless OEM motherboards; video cards with lower clocks and slower memory.
</li>
<li>Absolutely no overclocking potential.
</li>
<li>Limited internal case expansion for additional hard drives and video cards.
</li>
</ul>
<p>
The Mac Pro is a beautifully designed machine, but it has some quirks, too:
</p>
<p>
</p>
<ul>
<li>Quad-core in a single socket, ala the "Big Bang" system, makes more sense than this Dual-Dual arrangement. Obviously Apple will produce a Dual-Quad for a total of 8 CPUs any day now. But there is <a href="http://www.codinghorror.com/blog/archives/000655.html">a serious point of diminishing returns with additional CPUs</a> unless you're doing something highly specific and highly parallelizable like raytracing or rendering.
</li>
<li>Requires expensive DDR2 buffered ECC RAM, because it's a server motherboard.
</li>
<li>Zero overclocking options.
</li>
<li>667 MHz memory? Not that it matters very much to bottom-line performance, but support for different FSB speeds would be nice.
</li>
<li>The default video card and hard drive are totally pedestrian, and will limit overall performance unless replaced.
</li>
</ul>
<p>
If you don't have the time or inclination to build your own desktop PC, the Dells and the Mac Pro are perfectly valid choices. The prices are reasonable; the configurations flexible. There's absolutely nothing wrong with buying pre-built, as long as you spec carefully. But by the time I'm done setting up my D.I.Y. "Little Bang" system, it'll be faster, quieter, and more power efficient than any of the pre-built systems-- for the same money, or less. This is possible because the D.I.Y. system is uniquely mine; I choose exactly what goes in it, and exactly how it's configured.
</p>
<p>
Pre-built might work for typical users. But pre-built didn't work for Google. And pre-built doesn't work for me.
</p>
<p>
We aren't typical users. We're programmers. <b>The x86 commodity PC is the essential, ultimate tool of our craft.</b> It's the end product of 30 years of computer evolution. And it's still evolving today, with profound impact on the way we code. If you treat your PC like an appliance you plug into a wall, you've robbed yourself of a crucial lesson on the symbiotic relationship between software and hardware. The best way to truly <i>understand</i> the commodity PC is to gleefully dig in and <b>build one yourself</b>.  Get your hands dirty and experience the economics of computer hardware first hand-- the same economics that have shaped the software industry since the very first line of code was stored in memory.
</p>
<p>
Who knows, you might even enjoy it.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-12T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-computer-the-google-way/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ My Work PC, or, Taking Your Own Advice ]]></title>
<link>https://blog.codinghorror.com/my-work-pc-or-taking-your-own-advice/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I recently had the opportunity to rebuild my work PC. It strongly resembles the "Little Bang" D.I.Y. system I outlined in <a href="http://www.codinghorror.com/blog/archives/000814.html">my previous post on the philosophy of building your own computer</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
See, I <i>do</i> take my own advice.
</p>
<p>
Here's a quick breakdown of the components and the rationale behind each. Every aspect of this system has been a blog post at one point or another.
</p>
<p>
</p>
<ul>
<li>
<b>ASUS Vento 3600 case (green)</b>
<p>
Is there <a href="http://www.codinghorror.com/blog/archives/000218.html">anything more boring than a beige box?</a> The Vento is a little aggravating to work on, and it's a bit bulky. But it's unique, a total conversation starter, and the sparkly green model fits the Vertigo color scheme to a T. I even built my wife a PC using the red Vento. The 3600 has been discontinued in favor of <a href="http://www.directron.com/vento7700.html">the 7700</a>; the newest version is, sadly, much uglier.
</p>
<p>
</p>
</li>
<li>
<b>MSI P6N SLI, NVIDIA 650i chipset</b>
<p>
The 650i is a far more economic variation of the <a href="http://techreport.com/reviews/2006q4/nforce680i/index.x?pg=1">ridiculously expensive NVIDIA 680i chipset</a>, but offering the same excellent performance. Dual PCI express slots, for two video cards, is a must in <a href="http://www.codinghorror.com/blog/archives/000740.html">my three-monitor world</a>. It also has a fairly large, passive thin-fin northbridge cooler; quality of the motherboard chipset cooling is important, because modern motherboard chipsets can dissipate upwards of 20-30 watts all by themselves. And it still runs blazingly hot, even at idle.
</p>
<p>
</p>
</li>
<li>
<b>Intel Core 2 Duo E6600</b>
<p>
The Core 2 Duo is Intel's best processor in years. I opted for the E6600 because I have an unnatural love for large L2 caches, but even the cheapest Core Duo 2 runs rings around the competition. And <a href="http://www.codinghorror.com/blog/archives/000697.html">all the Core 2 Duos overclock like mad</a>. This one is running at 3 GHz with a <i>very</i> minor voltage bump for peace of mind.
</p>
<p>
</p>
</li>
<li>
<b>Antec NeoHE 380 watt power supply</b>
<p>
Great modular cable power supply, with around 80% efficiency at typical load levels. It's extremely quiet, <a href="http://www.silentpcreview.com/article273-page1.html">per the SPCR review</a>. It's <a href="http://www.codinghorror.com/blog/archives/000353.html">a myth that you "need" a 500 watt power supply</a>, but 380 W is about the lowest model you can buy these days. The <i>quality</i> of the power supply is far more important than any arbitrary watt number printed on its side.
</p>
<p>
</p>
</li>
<li>
<b>Scythe Ninja heatsink</b>
<p>
The Ninja, despite the goofy name, offers superlative performance. It is easily <a href="http://www.silentpcreview.com/article251-page1.html">one of the all-time greatest heatsinks ever made</a>, and still a top-rank performer. It's quite inexpensive these days, too. As you can see, I am running it fanless. The Ninja is particularly suited for passive operation because of the widely-spaced fins. It's easily cooled passively, even under overclocked, <a href="http://www.codinghorror.com/blog/archives/000657.html">dual prime 95 load</a>, by the 120 mm exhaust fan directly behind it. (Disclaimer: <a href="http://www.codinghorror.com/blog/archives/000707.html">I have a giant heatsink fetish</a>.)
</p>
<p>
</p>
</li>
<li>
<b>Dual passive GeForce 7600 GT 256 MB video cards</b>
<p>
The 7600 GT was the runaway champ in <a href="http://www.codinghorror.com/blog/archives/000662.html">the video card power/performance analysis</a> research I did last summer. The model I chose is a passively cooled, dual slot design from Gigabyte (<a href="http://www.xbitlabs.com/articles/video/display/gigabyte-7600gt.html">model NX76T256D</a>). It offers outstanding performance, it runs cool, it has dual DVI, and the design is clever. I liked this card so much, I bought two of them. Not for SLI (although that's now an option) but for more than two monitors. It's inexpensive, too, at around $115 per card.
</p>
<p>
</p>
</li>
<li>
<b>2 GB of generic PC800 DDR2</b>
<p>
I don't believe in buying expensive memory. It's not worth it, unless you're an extreme overclocker. I buy cheap, reasonable quality memory. Even the cheap stuff overclocks fairly well, at least for the moderate overclocks I'm shooting for.
</p>
<p>
</p>
</li>
<li>
<b>74 GB 10,000 RPM primary hard drive</b>; 300 GB 7,200 RPM secondary hard drive
<p>
I cannot emphasize enough <a href="http://www.codinghorror.com/blog/archives/000800.html">how big the performance difference is between 10,000 RPM drives and 7,200 RPM drives</a>. I know it's a little expensive, but the merits of the faster drive, plus the flexibility of having two spindles in your system, makes it well worth the investment.
</p>
<p>
</p>
</li>
</ul>
<p>
And <a href="http://www.codinghorror.com/blog/archives/000665.html">it's quiet, too</a>. The entire system is cooled by three fans: one 120mm exhaust, the 80mm fan in the power supply, and an optional 80 mm fan I installed in the front of the case to <a href="http://www.codinghorror.com/blog/archives/000748.html">keep hard drive temperatures down</a>. Airflow in the hard drive area is quite limited on the Vento.
</p>
<p>
One of the advantages of a D.I.Y. system is that <b>you can perform relatively inexpensive upgrades instead of buying an entirely new computer</b>. The most recent one was plopping in the new motherboard/cpu/memory/heatsink combo. With that upgrade, I now have a top of the line dual-core PC running at 3.0 GHz-- and it only cost me $650 to get there.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-13T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/my-work-pc-or-taking-your-own-advice/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Are Web Interfaces "Good Enough"? ]]></title>
<link>https://blog.codinghorror.com/are-web-interfaces-good-enough/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.utorrent.com/">Torrent</a>, my favorite BitTorrent client, now offers a web UI. See if you can spot the differences between the Web UI and the Windows UI:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
After spending about a year interacting with Torrent exclusively through Remote Desktop, I was pleasantly surprised to discover how good the web UI is. It aggressively exploits the latest Ajax techniques to replicate most of the rich GUI functionality of Torrent in a browser. But the web UI is still a pale shadow of the full-blown Windows UI. There are small but important details missing throughout, and part of the pleasure of using Torrent was luxuriating in its intense attention to detail, its wealth of well-designed data readouts. Using the web UI is like drinking watered-down beer. It doesn't satisfy.
</p>
<p>
<b>But <i>does it matter?</i></b> Despite my nitpicking, I can do everything I need to do remotely through the web UI.
</p>
<p>
I do sometimes miss the fit and finish of the complete Windows UI. But if the only way to achieve full fidelity is to log in to the machine as a user via Remote Desktop, it's hardly worth the effort. Remote GUI technology has never caught on, either in Windows (<a href="http://en.wikipedia.org/wiki/Terminal_Services">RDP</a>), in UNIX (<a href="http://en.wikipedia.org/wiki/X_Window_System">X11</a>), or even on the Mac (<a href="http://en.wikipedia.org/wiki/Apple_Remote_Desktop">ARD</a>). This approach has always felt like overkill, and it doesn't seem workable based on the historical evidence.
</p>
<p>
But maybe "good enough", via the eccentric and often unreliable combination of DHTML, JavaScript, and HTML, is all we need. That's <a href="http://www.joelonsoftware.com/articles/APIWar.html">what Joel Spolsky thinks</a>, anyway:
</p>
<p>
</p>
<blockquote>
So the Web user interface is about 80% there, and even without new web browsers we can probably get 95% there. This is Good Enough for most people and it's certainly good enough for developers, who have voted to develop almost every significant new application as a web application.
<p>
I'm actually a little bit sad about this, myself. To me the Web is great but Web-based applications with their sucky, high-latency, inconsistent user interfaces are a huge step backwards in daily usability. I love my rich client applications and would go nuts if I had to use web versions of the applications I use daily: Visual Studio, CityDesk, Outlook, Corel PhotoPaint, QuickBooks. But that's what developers are going to give us. Nobody (by which, again, I mean "fewer than 10,000,000 people") wants to develop for the Windows API any more. Venture Capitalists won't invest in Windows applications because they're so afraid of competition from Microsoft. And most users don't seem to care about crappy Web UIs as much as I do.
</p>
<p>
None of this bodes well for Microsoft and the profits it enjoyed thanks to its API power. The new API is HTML, and the new winners in the application development marketplace will be the people who can make HTML sing.
</p>
</blockquote>
<p>
Bruce Eckel read the same tea leaves as Joel Spolsky, and <a href="http://www.artima.com/weblogs/viewpost.jsp?thread=193593">concludes that the future of rich web applications lies not in HTML, but in Flash</a>:
</p>
<p>
</p>
<blockquote>
JavaScript has been around since, effectively, the beginning of the Web, but the browser wars made JavaScript inconsistent and thus painful to use. A key part of Ajax is that someone has gone to the trouble of figuring out cross-platform JavaScript issues so you can ignore the often radical inconsistencies between different browsers.
<p>
There are two problems with this approach. The first is that JavaScript is limited in what it can do. Although Ajax is an excellent hack that gets the last bit of mileage from JavaScript, it is nonetheless a hack, and the end is in sight. The second problem is that you are relying on Ajax libraries to handle cross-browser issues. If you want to write your own code, you must become an expert on those issues, and at that point much of the leverage of Ajax goes away. Ajax improves the experience a lot, but it has limits and I suspect we've already seen most of the tricks that Ajax is going to offer.
</p>
<p>
There's a very impressive Flash web app called Gliffy that imitates Visio (this was created with OpenLaszlo, which I'll mention later). No one could even think of creating something like that with Ajax, although someone did an imitation of the much simpler Microsoft Paint using HTML, CSS and JavaScript. Very impressive, but you get the sense that this is close to the limit of what those technologies can do, whereas Flash would just be getting started. Plus the Paint clone is a bit slow and clunky and the UI is inconsistent across browsers.
</p>
<p>
While amazing things have been accomplished within the confines of JavaScript with technologies like Ajax, JSON, GWT etc., these are nonetheless confines. We bump up against their limits every day, and those limits are not going away.
</p>
</blockquote>
<p>
I think Eckel is too quick to dismiss the utility of browser-based JavaScript applications. Yes, they're painful to create and debug, but they exploit the path of least resistance. And if I have learned anything in my entire life, it is this: <i>never bet against the path of least resistance.</i> You will lose. Every time. What Eckel neglects to consider is this:
</p>
<ul>
<li>The typical user only touches a fraction of the functionality in most applications. Switching to an online spreadsheet like <a href="http://www.editgrid.com">EditGrid</a> or WikiCalc is hardly a catastrophic loss when you only used 1 percent of Excel's functionality to begin with.
</li>
<li>Online applications may be awkward, but they do one key thing that local applications can never do: embed snippets of live content in a web page. <a href="http://instacalc.com/">Instacalc</a> may never be Excel, but so what? It's a completely different use case. Instacalc is ideal for embedding bite-sized, interactive nuggets of calculation next to a paragraph of text on a web page. It's the YouTube of spreadsheets.
</li>
<li>Eckel sees a world of JavaScript and DHTML that's inappropriate for large applications. I see a world of large applications that are inappropriate for most users. It's high time we scaled down and scaled back. If anything, this is a <i>beneficial</i> side-effect of the limitations inherent to the platform.
</li>
</ul>
<p>
Like Joel, I think the future of many-- but not all-- applications is in the browser. Web apps are good enough today for most tasks, and they're getting better every year. <b>The web browser is the giant black hole of the computing universe, and like it or not, your application is caught in its immense gravitational pull along with the rest of us.</b>
</p>
<p>
As useful and as clever as Torrent's web UI is, I'm still deeply disappointed.  I'm disappointed that, with all the technology at our disposal, we can't come up with some way to deliver a full-fidelity user interface over the wire for an application as nifty as Torrent. I'll belatedly agree that web interfaces are "good enough"-- but after all these years of progress, why should we have to <i>settle</i> for something that's merely "good enough"?  There <a href="http://msdn2.microsoft.com/en-us/architecture/bb288452.aspx">has to be a better way out there somewhere</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-14T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/are-web-interfaces-good-enough/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The "Works on My Machine" Certification Program ]]></title>
<link>https://blog.codinghorror.com/the-works-on-my-machine-certification-program/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Joseph Cooney had a brilliant idea for a new <a href="http://jcooney.net/archive/2007/02/01/42999.aspx">application certification program</a>. But Vista's bland white-on-gray badge, in my opinion, doesn't properly communicate the.. authoritative.. nature of said program. With the help of <a href="http://weblogs.asp.net/jgalloway/">Jon Galloway</a>, we zazzed things up a bit:
</p>
<p>
<img alt="image placeholder" >
 
</p>
<p>
You might think attaining such a prestigious, rigorous level of certification would be far too challenging. But fear not! Participating in this innovative new application certification program is as simple as pressing the F5 key on your keyboard. Just follow the <a href="http://jcooney.net/archive/2007/02/01/42999.aspx">four easy steps Joseph outlined</a>:
</p>
<p>
</p>
<ol>
<li>Compile your application code. Getting the latest version of any recent code changes from other developers is purely optional and not a requirement for certification.
</li>
<li>Launch the application or website that has just been compiled.
</li>
<li>Cause one code path in the code you're checking in to be executed. The preferred way to do this is with ad-hoc manual testing of the simplest possible case for the feature in question. Omit this step if the code change was less than five lines, or if, in the developer's professional opinion, the code change could not <i>possibly</i> result in an error.
</li>
<li>Check the code changes into your version control system.
</li>
</ol>
<p>
Congratulations! You're fully certified. Brand your app with your shiny new <b>Works on My Machine</b> badge. You'll certainly want to show it off to your fellow team members and key stakeholders. But please-- do try to keep your ego in check. Not everyone is capable of such an epic commitment to quality in software engineering.
</p>
<p>
(update: love the WOMM certification so much you want to proudly wear your certification for all to see? T-Shirts and stickers now available.)
</p>
<p>
</p>
<table cellpadding="8" cellspacing="8">
<tr>
<td align="center" valign="top">
<b>United States / Canada</b><br>
<a href="http://www.cafepress.com/codinghorror/"><img alt="image placeholder" >
<a href="http://www.cafepress.com/codinghorror/">Buy Works on My Machine shirts, stickers and mugs</a>
</td>
</tr>
</table>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-15T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-works-on-my-machine-certification-program/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Creating User Friendly 404 Pages ]]></title>
<link>https://blog.codinghorror.com/creating-user-friendly-404-pages/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We understand <a href="http://en.wikipedia.org/wiki/404_error">what 404 means</a>: Page Not Found. But the average internet user has no idea what 404 means or what to do about it. To them, it's yet another <a href="http://www.codinghorror.com/blog/archives/000114.html">unintelligible error message</a> from the computer. Most 404 pages are unvarnished geek-speak. Consider the default 404 page under IIS:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The default 404 page under Apache is no better:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Internet Explorer tries to shield the user from these poorly constructed 404 pages by automatically substituting friendlier error messages:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's not bad. It's certainly an improvement over the default 404 from Apache or IIS. But we can do better.
</p>
<p>
We can stop relying on the default behavior of our webservers and web browsers, and <b>create our own custom 404 page</b>. Unfortunately, many sites have custom 404 pages that are barely discernable from the generic webserver defaults. You wonder why they bother.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
So, what exactly should a user-friendly custom 404 page do? Although there's <a href="http://www.plinko.net/404/area404.asp">an entire website dedicated to documenting funny 404 pages</a>, funny isn't necessarily <i>helpful</i>. What can we do to help the user at this point? I have some ideas.
</p>
<p>
</p>
<ol>
<li>
<b>Drop the 404</b>
<p>Yes, the HTTP response code is 404, but there's absolutely no reason that ever needs to be shown on the actual page. <a href="http://www.codinghorror.com/blog/archives/000525.html">Error codes aren't helpful</a>. A simple explanation of the problem in plain English is all that's required. Any 404 page that has the characters "404" on it, if not already an outright failure, is already well on its way to becoming one.
</p>
<p>
</p>
</li>
<li>
<b>Automatically notify you of the 404</b>
<p>
Repeat after me: <i>it is not the user's job to inform you about problems with your website</i>. If you require the user to click a button to notify you about a 404, or if you require the user to fill out a broken link form, <i>you have utterly failed your users</i>. 404 notification should be automatic, and by that I do not mean "sit in my log files until I eventually have time to look for it". I suggest weekly or monthly 404 rollup reports, emailed automatically to the powers that be. I'd also recommend real-time email notification if there is a sudden spate of 404s, so you have an opportunity to fix the problem while it's still relevant-- before the world gives up on your seemingly nonexistent page.
</p>
<p>
</p>
</li>
<li>
<b>Try to find what the user was looking for and provide links to possible matches</b>
<p>
Don't just put a search box on the 404 page and force the user to perform a search. That's a cop-out. Instead, automatically perform a search on their behalf, using the erroneous URL as the search input, and display those results on the 404 page. You can also try to correct the URL, based on rules derived from the top ten or top fifty observed 404 errors. Does the URL end in .htm instead of .html? Is it spelled wrong? Are your URLs <a href="http://www.codinghorror.com/blog/archives/000458.html">case-sensitive</a>? Was the page moved, renamed, or reorganized somewhere else? It's sensible to have a search box on your 404 page for convenience's sake, but forcing the user to perform a search should always be the method of last resort.
</p>
<p>
</p>
</li>
<li>
<b>Present links to the most popular or most recent items</b>
<p>
If someone is visiting your website, statistically speaking, there's a good chance they are coming to see the same attraction everyone else is. Even if they aren't, your popular content is popular for a reason. Why not present links to your "greatest hits" on the 404 page? Similarly, if you run a periodic website like a blog, or a newspaper, display the last few articles or entries on the 404 page. And at the very least, you'll want a link back to the main website. Provide a filtered list of relevant links, and an errant user will never be more than one click away from escaping their current predicament.
</p>
<p>
</p>
</li>
<li>
<b>Keep the 404 page simple</b>
<p>
Your 404 page should be brief, concise, and to the point.* You're already dealing with confused users who can't find what they're looking for. Don't add insult to injury by spamming the user with a giant, complicated 404 page containing a complete sitemap of your website. For example, the <a href="http://www.apple.com/gimme-a-404">apple.com 404 page</a> makes this mistake.
</p>
<p>
</p>
</li>
</ol>
<p>
I found that <a href="http://www.useit.com/alertbox/404_improvement.html">Jakob Nielsen</a>, <a href="http://alistapart.com/articles/perfect404/">A List Apart</a>, and <a href="http://www.plinko.net/404/howto.asp?article=2">404 Research Lab</a> also had good advice on making 404 pages potentially <i>user friendly</i> instead of the geeky, incomprehensible dead end signs they usually are.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Unfortunately, I haven't had time to implement a better 404 page on my own website. Yet. If you're looking for live examples of 404 pages that get this right, I can recommend the <a href="http://www.1976design.com/gimme-a-404">1976 design 404 page</a>, as well as the <a href="http://www.useit.com/gimme-a-404">useit.com 404 page</a>. Sadly, this is an extremely short list because so few websites meet the criteria I outlined above. I sampled 404 pages from dozens of websites and most fail spectacularly, serving up 404 pages that are downright user <i>hostile</i>.
</p>
<p>
Whichever route you choose, <b>never settle for the default 404 page</b>. Replace it with a custom 404 page that is polite, illuminating, and most of all, <i>helpful</i>.
</p>
<p>
* But not <i>too</i> brief. You have to make your customized 404 page larger than 512 bytes, otherwise IE will assume it's a standard web server 404 message and replace it with its own friendly-ized version.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-16T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/creating-user-friendly-404-pages/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Primary Keys: IDs versus GUIDs ]]></title>
<link>https://blog.codinghorror.com/primary-keys-ids-versus-guids/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Long-time readers of this blog know that I have <a href="http://blog.codinghorror.com/mastering-guids-with-occams-razor/">an inordinate fondness for GUIDs</a>. Each <a href="http://en.wikipedia.org/wiki/Globally_Unique_Identifier">globally unique ID</a> is like a beautiful snowflake: every one a unique item waiting to be born.</p>
<p>Perhaps that's why I read with great interest recent accounts of people switching their database tables from traditional integer primary keys ...</p>
<pre>
ID  Value
--  -----
1   Apple
2   Orange
3   Pear
4   Mango
</pre>
<p>.. to GUID keys.</p>
<pre>
ID                                    Value
------------------------------------  -----
C87FC84A-EE47-47EE-842C-29E969AC5131  Apple
2A734AE4-E0EF-4D77-9F84-51A8365AC5A0  Orange
70E2E8DE-500E-4630-B3CB-166131D35C21  Pear
15ED815C-921C-4011-8667-7158982951EA  Mango
</pre>
<p>I know what you're thinking. <i>Using sixteen bytes instead of four bytes for a primary key? Have you lost your mind?</i> Those additional 12 bytes do come at a cost. But that cost may not be as great as you think:</p>
<ul>
<li>
<a href="http://www.informit.com/articles/printerfriendly.asp?p=25862&amp;rl=1">The Cost of GUIDs as Primary Keys</a> (SQL Server 2000)</li>
<li>
<a href="http://krow.livejournal.com/497839.html">Myths, GUID vs. Autoincrement</a> (MySQL 5)</li>
</ul>
<p>Using a GUID as a row identity value feels more natural-- and certainly more truly unique-- than a 32-bit integer. Database guru Joe Celko <a href="http://groups.google.com/group/microsoft.public.sqlserver.programming/msg/6d61dbf80d6f0fb6?hl=en&amp;lr=&amp;ie=UTF-8&amp;oe=UTF-8&amp;rnum=14">seems to agree</a>. GUID primary keys are a natural fit for many development scenarios, such as replication, or when you need to generate primary keys outside the database. But it's still a question of balancing the tradeoffs between traditional 4-byte integer IDs and 16-byte GUIDs:</p>
<table>
<tr>
<td valign="top">
<b>GUID Pros</b>
<li>Unique across every table, every database, every server
</li>
<li>Allows easy merging of records from different databases
</li>
<li>Allows easy distribution of databases across multiple servers
</li>
<li>You can generate IDs anywhere, instead of having to roundtrip to the database
</li>
<li>Most replication scenarios require GUID columns anyway
</li>
</td>
<td valign="top">
<b>GUID Cons</b>
<li>It is a whopping 4 times larger than the traditional 4-byte index value; this can have serious performance and storage implications if you're not careful
</li>
<li>Cumbersome to debug <code>where userid='{BAE7DF4-DDF-3RG-5TY3E3RF456AS10}'</code>
</li>
<li>The generated GUIDs should be partially sequential for best performance (eg, <code>newsequentialid()</code> on SQL 2005) and to enable use of clustered indexes
</li>
</td>
</tr>
</table>
<p>I'm not proposing that every database switch to GUID primary keys, but I do think it's important to know the option is out there. If you're still on the fence, <a href="http://web.archive.org/web/20150511162734/http://databases.aspfaq.com/database/what-should-i-choose-for-my-primary-key.html">what should I choose for my primary key?</a> has excellent advice and a solid analysis of the tradeoffs.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-19T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/primary-keys-ids-versus-guids/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Code Access Security and Bitfrost ]]></title>
<link>https://blog.codinghorror.com/code-access-security-and-bitfrost/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The <a href="http://www.laptop.org/">One Laptop Per Child</a> operating system features a new security model-- <a href="http://wiki.laptop.org/go/OLPC_Bitfrost">Bitfrost</a>. It's an interesting departure from the traditional UNIX and LINUX security model.
</p>
<p>
</p>
<blockquote>
The 1971 version of UNIX supported the following security permissions on user files:
<p>
</p>
<ul>
<li>non-owner can change file (write)
</li>
<li>non-owner can read file
</li>
<li>owner can change file (write)
</li>
<li>owner can read file
</li>
<li>file can be executed
</li>
<li>file is set-uid
</li>
</ul>
<p>
These permissions should look familiar, because they are very close to the same security permissions a user can set for her files today, in her operating system of choice. What's deeply troubling -- almost unbelievable -- about these permissions is that they've remained virtually the only real control mechanism that a user has over her personal documents today: a user can choose to protect her files from other people on the system, but has no control whatsoever over what her own programs are able to do with her files.
</p>
<p>
In 1971, this might have been acceptable: it was 20 years before the advent of the Web, and the threat model for most computer users was entirely different than the one that applies today. But how, then, is it a surprise that we can't stop viruses and malware now, when our defenses have remained largely unchanged from thirty-five years ago?
</p>
</blockquote>
<p>
BitFrost intends to address this problem by <b>adding a new level of permissions that applies to code</b>, not users: code access security.
</p>
<p>
</p>
<blockquote>
Consider the Solitaire game shipped with most versions of Microsoft Windows. This program needs:
<p>
</p>
<ul>
<li>no network access whatsoever
</li>
<li>no ability to read the user's documents
</li>
<li>no ability to utilize the built-in camera or microphone
</li>
<li>no ability to look at, or modify, other programs
</li>
</ul>
<p>
Yet if somehow compromised by an attacker, Solitaire is free to do whatever the attacker wishes, including:
</p>
<p>
</p>
<ul>
<li>read, corrupt or delete the user's documents, spreadsheets, music, photos and any other files
</li>
<li>eavesdrop on the user via the camera or microphone
</li>
<li>replace the user's wallpaper
</li>
<li>access the user's website passwords
</li>
<li>infect other programs on the hard drive with a virus
</li>
<li>download files to the user's machine
</li>
<li>receive or send e-mail on behalf of the user
</li>
<li>play loud or embarassing sounds on the speakers
</li>
</ul>
<p>
The critical observation here is not that Solitaire should never have the ability to do any of the above (which it clearly shouldn't), but that its creators know it should never do any of the above. If the system implemented a facility for Solitaire to indicate this at installation time, Solitaire could irreversibly shed various privileges the moment it's installed. This severely limits or destroys its usefulness to an attacker were it taken over.
</p>
</blockquote>
<p>
If I sound skeptical, that's because BitFrost sounds suspiciously similar to .NET framework code access security, as outlined in the <a href="http://msdn2.microsoft.com/en-us/library/system.security.permissions.aspx"><code>System.Security.Permissions</code></a> namespace. It's an enormous, complex list of explicit permissions you can grant or deny in your application's install manifest, exactly as described in the Solitaire example above. It sounds great in theory: establish a limited set of permissions your application needs up front, and let the .NET runtime worry about enforcing those permissions while your application is running.
</p>
<p>
But in practice, <a href="http://www.resolvecorp.com/blog/pierrenallet/PermaLink,guid,c4feb995-07bf-4087-a0cc-714d27505bc4.aspx">very few .NET developers make use of code access security</a>. It appears Microsoft noticed that, too:
</p>
<p>
</p>
<blockquote>
It seems Microsoft does not understand why nobody uses Code Access Security. In fact, Microsoft has <a href="http://blogs.msdn.com/brada/archive/2005/03/06/386172.aspx">a survey on the Internet</a>. You can go ahead and answer the survey but if you have followed this entry, you should know what I am getting at: <b>Code Access Security is too hard</b>. Don't get me wrong, I think Code Access Security is great. In particular, the stack walk mechanism is terrific. But the policy side is way too hard for most people.
</blockquote>
<p>
The CAS model was so profoundly unsuccessful in .NET 1.0 and 1.1 that <a href="http://www.leastprivilege.com/BewareBeAwareOfClickOnceDefaultSettings.aspx">ClickOnce in .NET 2.0 effectively does away with CAS</a>. You're now exactly one click away from running a full trust application that can do whatever it wants to on your machine, with no restrictions of any kind.
</p>
<p>
Perhaps the OLPC's BitFrost model will fare better than .NET Code Access Security did. But somehow I doubt it. <b>What good is a security model that's so cumbersome to use, nobody ever adopts it?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-20T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/code-access-security-and-bitfrost/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Race of Futuristic Supermen! ]]></title>
<link>https://blog.codinghorror.com/a-race-of-futuristic-supermen/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've seen a lot of <a href="http://www.userfriendly.org/">painfully bad IT web comics</a> in my day, but I'm happy to say that <a href="http://www.bugbash.net/">Bug Bash, by Hans Bjordahl</a>, is not one of them.
</p>
<p>
<a href="http://www.bugbash.net/comic/37.html"><img alt="image placeholder" >
</p>
<p>
This particular strip is one of my favorites because it hits so close to home. Software developers truly believe, in their heart of hearts, that <a href="http://www.codinghorror.com/blog/archives/000091.html">they are typical users</a>. Be sure to check out the sequel strip, <a href="http://www.bugbash.net/comic/44.html">How Good Software Goes Bad, Part II</a>, and while you're at it, <a href="http://www.bugbash.net/archives/comic">the rest of the bug bash archives</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-21T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-race-of-futuristic-supermen/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Top 6 List of Programming Top 10 Lists ]]></title>
<link>https://blog.codinghorror.com/top-6-list-of-programming-top-10-lists/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Presented, in no particular order, for your reading pleasure: my <b>top 6 list of programming top 10 lists</b>. To keep this entry concise, I've only quoted a brief summary of each item. If any of these sound interesting to you, I encourage you to click through and read the original author's thoughts in more detail.
</p>
<p>
<b>Jerry Weinberg: <a href="http://www.codinghorror.com/blog/archives/000584.html">The 10 Commandments of Egoless Programming</a></b>
</p>
<p>
</p>
<ol>
<li>Understand and accept that <a href="http://www.codinghorror.com/blog/archives/000300.html">you will make mistakes</a>.
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000586.html">You are not your code</a>.
</li>
<li>No matter how much "karate" you know, <a href="http://www.codinghorror.com/blog/archives/000051.html">someone else will always know more</a>.
</li>
<li>Don't <a href="http://www.codinghorror.com/blog/archives/000684.html">rewrite code</a> without consultation.
</li>
<li>Treat people who know less than you with respect, deference, and patience.
</li>
<li>The only constant in the world is <a href="http://www.codinghorror.com/blog/archives/000545.html">change</a>.
</li>
<li>The only true authority stems from knowledge, not from position.
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000752.html">Fight for what you believe</a>, but gracefully accept defeat.
</li>
<li>Don't be <a href="http://www.codinghorror.com/blog/archives/000080.html">"the guy in the room."</a>
</li>
<li>Critique code instead of people --  be kind to the coder, not to the code.
</li>
</ol>
<p>
<b>Dare Obasanjo: <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=a76eab63-70f0-48b4-8b75-66c366a651cd">Top 10 Signs Your Software Project is Doomed</a></b>
</p>
<p>
</p>
<ol>
<li>Trying to do too much in the first version.
</li>
<li>Taking a major dependency on unproven technology.
</li>
<li>Competing with an existing internal project that is either a cash cow or has powerful backers.
</li>
<li>The team is understaffed.
</li>
<li>"Complex problems require complex solutions".
</li>
<li>
<a href="http://www.stickyminds.com/se/S7923.asp">Schedule Chicken</a>
</li>
<li>
<a href="http://www.projectperfect.com.au/info_scope_creep_mgmt.php">Scope Creep</a>
</li>
<li>
<a href="http://www.answers.com/topic/second-system-syndrome">Second System Syndrome</a>
</li>
<li>No Entrance Strategy.
</li>
<li>Tackling a problem you don't know how to solve.
</li>
</ol>
<p>
<b>Omar Shahine: <a href="http://www.shahine.com/omar/TipsForWorkingAtMS.aspx">Top 10 Tips for Working at Microsoft (or Anywhere Else)</a></b>
</p>
<p>
</p>
<ol>
<li>Process is no substitute for thinking.
</li>
<li>Get out of your office.
</li>
<li>Use your product (the one your customers will).
</li>
<li>Fix things that are broken rather than complain about them being broken. Actions speak better than your complaining.
</li>
<li>Make hard problem look easy. Don't make easy problems look hard.
</li>
<li>Use the right communication tool for the job.
</li>
<li>Learn to make mistakes.
</li>
<li>Keep things simple.
</li>
<li>Add value all the time.
</li>
<li>Use their product.
</li>
</ol>
<p>
<b>Michael McDonough: <a href="http://www.designobserver.com/archives/000121.html">The Top 10 Things They Never Taught Me in Design School</a></b>
</p>
<p>
</p>
<ol>
<li>Talent is one-third of the success equation.
</li>
<li>95 percent of any creative profession is shit work.
</li>
<li>If everything is equally important, then nothing is very important.
</li>
<li>Don't over-think a problem.
</li>
<li>Start with what you know; then remove the unknowns.
</li>
<li>Don't forget your goal.
</li>
<li>When you throw your weight around, you usually fall off balance.
</li>
<li>The road to hell is paved with good intentions; or, no good deed goes unpunished.
</li>
<li>It all comes down to output.
</li>
<li>The rest of the world counts.
</li>
</ol>
<p>
<b>Andres Taylor: <a href="http://www.taylor.se/blog/2007/03/22/top-ten-things-ten-years-of-professional-software-development-has-taught-me/">Top 10 Things Ten Years of Professional Software Development Has Taught Me</a></b>
</p>
<p>
</p>
<ol>
<li>Object orientation is much harder than you think.
</li>
<li>The difficult part of software development is communication.
</li>
<li>Learn to say no.
</li>
<li>If everything is equally important, then nothing is important.
</li>
<li>Don't over-think a problem.
</li>
<li>Dive really deep into something, but don't get hung up.
</li>
<li>Learn about the other parts of the software development machine.
</li>
<li>Your colleagues are your best teachers.
</li>
<li>It all comes down to working software.
</li>
<li>Some people are assholes.
</li>
</ol>
<p>
<b>Steve Yegge: <a href="http://steve.yegge.googlepages.com/ten-great-books">10 Great Books</a></b>
</p>
<p>
</p>
<ol>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/020161622X/codihorr-20">The Pragmatic Programmer:  From Journeyman to Master</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201485672/codihorr-20">Refactoring: Improving the Design of Existing Code</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201633612/codihorr-20">Design Patterns</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201310090/codihorr-20">Concurrent Programming in Java(TM): Design Principles and Pattern (2nd Edition)</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0596528124/codihorr-20">Mastering Regular Expressions, 2nd Edition</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0387948600/codihorr-20">The Algorithm Design Manual</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0131103628/codihorr-20">The C Programming Language, Second Edition</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0262560992/codihorr-20">The Little Schemer</a>
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201100886/codihorr-20">Compilers</a>
</li>
<li>
<a href="http://c2.com/cgi/wiki">WikiWikiWeb</a>
</li>
</ol>
<p>
You may wonder why I included a top 10 list from someone who is clearly a designer and not a programmer. I agree <a href="http://globalnerdy.com/?p=477">with Joey deVilla</a>:
</p>
<p>
</p>
<blockquote>
Software development is a kissing cousin of engineering (if not an engineering discipline itself), and blends creativity with math and science. That's why I find that a lot of advice to creative types is also applicable to software developers.
</blockquote>
<p>
You may also want to contrast and compare <a href="http://www.codinghorror.com/blog/archives/000020.html">my recommended reading list</a> with Steve Yegge's. And yes, there is a reason <i>Refactoring</i> and <i>Design Patterns</i> aren't on my list, just as I'm sure there's a reason <i>Code Complete</i> is not on Steve's list.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-22T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/top-6-list-of-programming-top-10-lists/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Folding: The Death of the General Purpose CPU ]]></title>
<link>https://blog.codinghorror.com/folding-the-death-of-the-general-purpose-cpu/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A few recent articles have highlighted the <a href="http://gizmodo.com/gadgets/home-entertainment/breaking-ps3-folding-ps3-triples-folding-at-homes-computing-power-to-over-500-tflopspflops-in-spitting-range-246664.php">disproportionate contribution</a> Playstation 3 consoles are making to the <a href="http://fah-web.stanford.edu">Folding@Home</a> effort. The <a href="http://fah-web.stanford.edu/cgi-bin/main.py?qtype=osstats">OS statistics page for Folding@Home</a> tells the tale:
</p>
<p>
</p>
<table width="450">
<tr>
<td> </td>
<td align="right"><a href="http://en.wikipedia.org/wiki/FLOPS">TFLOPS</a></td>
<td align="right">Active CPUs</td>
<td align="right">Total CPUs
</td>
</tr>
<tr>
<td>Windows</td>
<td align="right">152</td>
<td align="right">160,173</td>
<td align="right">1,626,609
</td>
</tr>
<tr>
<td>Mac/PPC</td>
<td align="right">7</td>
<td align="right">8,776</td>
<td align="right">95,435
</td>
</tr>
<tr>
<td>Mac/Intel</td>
<td align="right">9</td>
<td align="right">2,864</td>
<td align="right">7,400
</td>
</tr>
<tr>
<td>Linux</td>
<td align="right">43</td>
<td align="right">25,239</td>
<td align="right">216,067
</td>
</tr>
<tr>
<td>GPU</td>
<td align="right">43</td>
<td align="right">733</td>
<td align="right">2,228
</td>
</tr>
<tr>
<td>PS3</td>
<td align="right"><font color="red">659</font></td>
<td align="right">26,911</td>
<td align="right">29,843
</td>
</tr>
</table>
<p>
There are a couple caveats to bear in mind when reading this chart:
</p>
<ol>
<li>The measurement of <a href="http://en.wikipedia.org/wiki/FLOPS">FLOPS</a> isn't an exact science. It would be more accurate to compare actual work units returned, but I don't see any way to do that from the folding statistics page.
</li>
<li>Current PC and Mac / PPC contributors span the entire gamut of CPUs released in the last seven years.
</li>
<li>Folding does cost money, in the form of electricity. Superior clients offer efficiency: bang per watt. You could make a compelling argument that certain clients with low efficiency aren't worth the cost of the electricity they're using. For reference, a <a href="http://www.hardcoreware.net/reviews/review-356-2.htm">PS3</a> and <a href="http://techreport.com/reviews/2006q3/core2/index.x?pg=16">a gaming-class PC</a> both use about 200 watts of power under load.
</li>
</ol>
<p>
The Playstation 3 is indeed dominating the charts; as of this writing, the PS3 is responsible for a whopping 72 percent of the computing power in the entire Folding@Home project.
</p>
<p>
<font color="red">UPDATE: as of 3/26/2007, the F@H network has arbitrarily halved the TFLOPS score for the PS3.</font>
</p>
<p>
<a href="http://folding.stanford.edu/FAQ-PS3.html"><img alt="image placeholder" >
</p>
<p>
<b>It's only a matter of time-- a few weeks at most-- before the PS3 constitutes more than 95 percent of the computing power in the entire Folding@Home network.</b> This doesn't surprise me in the least. The Playstation 3 can harness the considerable power of its <a href="http://en.wikipedia.org/wiki/Cell_microprocessor">specialized Cell CPU</a> to crunch work units far more efficiently than any general purpose CPU ever could.
</p>
<p>
If you look closely at the chart, you'll see even more powerful evidence of the dominance of specialized processors.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
GPU clients run on modern, high-end video cards. <a href="http://www.codinghorror.com/blog/archives/000732.html">The GPU on these video cards is even more specialized</a> than the Cell processor in the PS3.
</p>
<p>
The GPU client is limited to the current high-end ATI X1800 and X1900 video cards at the moment, which are already a generation behind NVIDIA's newest 8800 series. Even so, <b>the GPU clients are almost 2.5 times faster than the PS3</b>. Of course, this performance differential is more than balanced by the fact that PS3 is an easily obtainible (albeit somewhat expensive) consumer item; it's trivially easy to add one to the Folding@Home network, whereas the Folding@Home GPU client is quite immature, and few users have the necessary high-end ATI video cards to use it.
</p>
<p>
But the <i>real</i> lesson of this chart lies in the OS X / Intel data point. Intel-based Macs are, by definition, based on only the newest Intel processors-- Core Duo or better. Even so, it's an utter blowout:
</p>
<p>
</p>
<table width="300">
<tr>
<td>Intel Core Duo</td>
<td>1x
</td>
</tr>
<tr>
<td>PS3</td>
<td>
<font color="red">7.8x faster</font>
</td>
</tr>
<tr>
<td>GPU</td>
<td>
<font color="red">18.6x faster</font>
</td>
</tr>
</table>
<p>
With these kinds of performance ratios-- and I expect the performance gap to <i>widen</i> every year-- <b>there's almost no point in adding general purpose CPUs to the folding network any more.</b> It's a waste of time, effort, and electricity.
</p>
<p>
For folding and other distributed computing efforts, it's <b>the death of the general purpose CPU as we know it</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-23T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/folding-the-death-of-the-general-purpose-cpu/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's Wrong With The Daily WTF ]]></title>
<link>https://blog.codinghorror.com/whats-wrong-with-the-daily-wtf/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Alex Papadimoulis originally invited me to be a guest editor at The Daily WTF nearly six months ago. I was honored and accepted immediately. Since then, The Daily WTF has been rechristened <a href="http://www.worsethanfailure.com/">Worse Than Failure</a>.</p>
<p><img alt="image placeholder" >
<p>I'm a big fan of Alex and WTF; <a href="http://weblogs.asp.net/alex_papadimoulis/default.aspx">his blog</a> is fantastic, and WTF went from being a brilliant, hilarious germ of an idea to a staple of many developer's daily reading lists.</p>
<p>It's ironic, then, that <b><a href="http://worsethanfailure.com/Articles/Guest_Article_0x3a__Our_Dirty_Little_Secret.aspx">what I wrote</a> ended up being a direct criticism of The Daily WTF</b>. It's almost like I've fallen into the Spolsky rut; <a href="http://www.joelonsoftware.com/items/2006/03/05.html">invite me to speak</a> at your big important Java conference, and I'll create a session that tells you why <a href="http://blogs.law.harvard.edu/philg/2006/02/26/java-is-fading-as-a-web-development-tool-along-with-the-suv/">you're all idiots for using Java</a>. Or, perhaps I was <a href="http://www.quotationspage.com/quote/114.html">channeling Groucho Marx</a>. One of his most famous jokes goes something like this: <i>I sent the club a wire stating, please accept my resignation. I don't want to belong to any club that will accept me as a member.</i></p>
<img alt="image placeholder" >
<p>I give Alex tremendous credit for finally <a href="http://worsethanfailure.com/Articles/Guest_Article_0x3a__Our_Dirty_Little_Secret.aspx">posting my entry</a>, even though it never quite fit the WTF format. I hope it doesn't feel too much like a public service announcement, but it's something I absolutely had to get off my chest. It's <a href="http://www.yafla.com/dforbes/2006/09/08.html">a topic Dennis Forbes has struggled with as well</a>:</p>
<blockquote>
<p>This is a repeating theme: On the one side are the great programmers, and on the other are the people endlessly bound to give TheDailyWTF source material.</p>
<p>Do people really think such a schism exists? Is the impression that great developers are infallible, never creating any bad code at all, ever? Are bad programmers just stumbling from one WTF to another?</p>
<p>Of course not.</p>
<p>I fear the output of any developer who claimed that they've never written bad code. I would fear them because they're either bald-faced liars  –  believing that simply saying it repeatedly will somehow convince others into this fiction  –  or they're completely blind to their own weaknesses.</p>
<p>Every developer in the real world has had bad days, brain faults, or bad interpretations of new languages, environments or libraries. It's simply a given of the profession.</p>
</blockquote>
<p>I have no problem at all with the entertainment value of WTF. Laughing at <a href="http://www.codinghorror.com/blog/archives/000255.html">Rube Goldberg code</a> is therapeutic, even educational. But whether the code in question is catastrophically stupid or just plain ill-advised, we have to <i>do something about it</i>. Until we do, we are implicitly perpetuating the painful, costly cycle of bad coders writing bad code, ad infinitum. And that hurts all of us.</p>
<p>Reprogramming WTF code isn't enough. We need to reprogram the developers <i>producing</i> the WTF code. With my guest article, I was trying to <b>inspire readers to take on the burden of reprogramming bad developers</b>, rather than passively waiting for the bad developers to come to their senses on their own. That strategy <i>never</i> works.</p>
<p>I can absolutely guarantee that <b>the kinds of developers who could benefit most from reading WTF simply do not –  and never will –  read the WTF website</b>. Individually, personally, we have to do more to reach out to these developers: mentoring, apprenticeship, user groups, peer pressure, code reviews, etcetera. Do whatever you can, whatever makes sense to you, but <i>do something</i>. Pitch in so the next poor sap won't have to deal with WTF code, or at the very least, can benefit from slightly less crazy WTF code in the future.</p>
<p>I know it's asking a lot. It's tempting to get your daily fix of drive-by amusement and move on. But I believe it's our collective duty to leave the profession of software engineering better than we found it. There's so much we can do, and WTF is merely a starting point.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-wrong-with-the-daily-wtf/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Going Commando - Put Down The Mouse ]]></title>
<link>https://blog.codinghorror.com/going-commando-put-down-the-mouse/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>One of the quickest ways to increase your productivity on the computer is to <strong>go commando: stop using the mouse</strong>. When you stop relying on the mouse for everything, you're forced to learn the keyboard shortcuts. Jeremy Miller calls this <a href="http://codebetter.com/blogs/jeremy.miller/archive/2006/10/24/The-first-step-to-coding-faster.aspx">the first step to coding faster</a>. I agree.</p>
<p><img alt="image placeholder" >
<p>Keyboard shortcuts are almost always more efficient than using the mouse to point and click your way around the computer – but you'll never learn them if you keep leaning on your trusty mouse to do all the work. <strong>Stop for a moment, resist taking the easy way out with the mouse, and force yourself to learn at least one new keyboard shortcut per day</strong>. Yes, it's a tiny bit of extra work. But it will pay off down the road: you'll spend less time mousing around, and more time getting things done.</p>
<p>I'm not anti-mouse by any means. I remember when mice were new; I'd never want to go back to the bad old days of keyboard-only interfaces. But most people I've observed using the computer these days rely almost <em>exclusively</em> on the mouse, to the detriment of their overall computer experience. Here are a few examples of how even the simplest keyboard shortcuts can make your daily routine easier:</p>
<ol>
<li>
<a href="http://www.codinghorror.com/blog/archives/000754.html">Logging in with the keyboard</a>, using <kbd>Tab</kbd> and <kbd>Enter</kbd>
</li>
<li>
<a href="http://www.shahine.com/omar/GoingToAWebsiteWithControlenter.aspx">Going to a website</a> using <kbd>Alt</kbd>+<kbd>D</kbd> and <kbd>Ctrl</kbd>+<kbd>Enter</kbd> </li>
<li>Searching using <kbd>Ctrl</kbd>+<kbd>E</kbd> then <kbd>Enter</kbd>
</li>
<li>Editing text and moving your cursor with <a href="http://www.codinghorror.com/blog/archives/000563.html">basic textbox shortcuts</a>
</li>
</ol>
<p>That's just the tip of the iceberg. Most applications have tons of useful keyboard shortcuts; you just have to put down your mouse long enough to discover a few of them. It's a shame more applications don't go out of their way to <a href="http://www.codinghorror.com/blog/archives/000720.html">make keyboard shortcuts more discoverable</a>. At the very least, I'd like to see Office 2007 type behavior where, as you press the keyboard accelerator key, all the possible keyboard shortcuts "light up".</p>
<p><img alt="image placeholder" >
<p>Unfortunately, navigating through websites is nearly impossible without a mouse, due to the highly mouse-centric nature of HTML. I've given up on trying. But it is possible, if you're a die-hard. Unless you enjoy pressing the tab key umpteen million times, you'll definitely want to check out Jon Galloway's <a href="http://weblogs.asp.net/jgalloway/archive/2006/06/14/Mouseless-Computing.aspx">mouseless computing recommendations</a>, wherein he conquers the HTML keyboard challenge.</p>
<p>For best computing results, try to use your mouse <em>and</em> your keyboard to the fullest. But to do that, you've got to actively wean yourself off the mouse. <strong>Try going commando every now and then.</strong> It will be awkward and painful at first. You'll be sorely tempted to switch back to your old faithful mouse to get things done. Resist this urge! I guarantee whatever you're trying to do is possible – and ultimately quicker – if you persist with the keyboard.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/going-commando-put-down-the-mouse/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Learning on the Battlefield ]]></title>
<link>https://blog.codinghorror.com/learning-on-the-battlefield/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I occasionally get emails from people asking <strong>how to prepare for a career in software development</strong>. Some are students wondering what classes they should take; others have been bitten by the programming bug and are considering their next steps.</p>
<p>I always answer with the same advice. <a href="http://alistair.cockburn.us/index.php/Software_development_as_a_cooperative_game">There's no substitute for learning on the battlefield</a>.</p>
<blockquote>
<p>It appears to me that software development is happening in industry, not in the universities. Universities are great for problems that can be solved by sitting alone and thinking or experimenting for months on end. Universities were great for giving us automata theory, complexity analysis, compilers and the like. But universities are not at all well suited to understanding what is happening during software development.</p>
<p>Software development <em>at the moment</em> is much more like the early manufacture of samurai swords, shields, and battlefield tactics. You make a pile of swords or war tactics, send them onto the battlefield, and see which ones worked better. Then you make different swords and tactics, and so on. <strong>You have to be on the battlefield.</strong></p>
<img alt="image placeholder" >
I can't imagine learning the things I've learned while sitting peacefully in my office reflecting. Most of my original reflections and predictions were just wrong. So any one of you who is interested in this topic probably has to work as a developer or consultant, so you can see the moment-to-moment action and get raw data.
</blockquote>
<p>Of course, software development only teaches you how to talk to your computer. Higher education is still worthwhile because it teaches you how to talk to <em>people</em>. With a good educational background, you'll learn how to read effectively, how to write coherently, and how to think critically amongst your peers.</p>
<blockquote>
<p>If I were founding a university I would found first a smoking room; then when I had a little more money in hand I would found a dormitory; then after that, or more probably with it, a decent reading room and a library. After that, if I still had more money that I couldn't use, I would hire a professor and get some textbooks. (<a href="http://www.umuc.edu/resources/edit_styleguide/guide2-47.html">Stephen Leacock</a>)</p>
</blockquote>
<p>For a fast-moving field like computer science, <strong>the work you're doing is far more relevant than any classes you're taking.</strong> If you must choose between formal schooling and work experience, always choose work. If you're in school, aggressively pursue real-world experience that compliments your schoolwork.</p>
<p>Fortunately, this is a battle you can fight on multiple fronts:</p>
<ul>
<li>
<p>If you're a student, <strong>seek out internships like your life depends on it</strong>. Some of the best programmers I've ever met have been college interns. Intern somewhere that you can absorb and learn as much as possible. You won't make much money, but the experience will be priceless.<br>
 </p>
</li>
<li>
<p><strong>Participate in local user groups</strong>. User groups are an unbeatable resource for people just starting out in their careers; they're an excellent source of advice and mentorship.</p>
</li>
<li>
<p><strong>Contribute to an open-source project.</strong> There are thousands, so pick whatever strikes your fancy. But pick one and really dig in, become an active contributor. Absolutely nothing is more practical than working collaboratively with software developers all over the globe, from all walks of life.</p>
</li>
<li>
<p><strong>Publish articles</strong>. The cleverest code in the world won't help you if you can't clearly communicate how that code works, or what it's for. Try your hand at writing. <a href="http://www.codeproject.com">CodeProject</a> is an excellent sandbox to practice in. Publish an article and the large, active CodeProject community will let you know how you're doing with ratings and comments.<br>
 </p>
</li>
<li>
<p><strong>Start a blog</strong>. Pick a writing schedule and stick with it; I recommend once a week at minimum. Select a general theme for your blog and write on topics related (at least tangentially) to that theme. And <a href="http://web.archive.org/web/20070601225441/http://blogs.vertigosoftware.com/jatwood/archive/2006/09/05/3547.aspx">don't be an echo chamber</a>.</p>
</li>
</ul>
<p>You don't have to do all these things, but if you're serious about your career, pick at least two and follow through. For more detailed advice, I highly recommend <a href="http://www.softwarebyrob.com/2007/03/20/advice-on-how-to-become-a-programmer/">Rob's advice on how to become a programmer</a>.</p>
<p>In software development, you learn by doing. As long as you're <strong>out on the battlefield fighting the good fight</strong>, you're bound to improve.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/learning-on-the-battlefield/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Development as a Collaborative Game ]]></title>
<link>https://blog.codinghorror.com/software-development-as-a-collaborative-game/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Alistair Cockburn maintains that <a href="http://alistair.cockburn.us/index.php/Software_development_as_a_cooperative_game">software development is a cooperative game</a>:
</p>
<p>
</p>
<blockquote>
If software development was really a science, you could apply the scientific method to it. If it was really engineering, then you could apply known engineering techniques. If software development was a matter of producing models, then you could spend your money developing models.
<p>
However, it is none of those. <b>Software development is a "game", a game of speed and cooperation within your team, in competition against other teams.</b> It is a game against time, and a game for mind-share. You should spend your money to win that game.
</p>
<p>
Viewing software development as a game gives you better ideas on where to spend your money, how to structure your teams, and how they should allocate their efforts.
</p>
</blockquote>
<p>
It's a fascinating, thought-provoking article on the essential nature of software development. I can now see why <a href="http://www.dehora.net/journal/2007/03/cockburn_wins_jolt_award.html">Bill de hra calls Cockburn "the agile world's best kept secret."</a> I've only quoted the conclusion; I urge you read the complete article to get a full explanation of Cockburn's <a href="http://alistair.cockburn.us/index.php/Software_development_as_a_cooperative_game#---------------_4._Games">rationale behind the game analogy</a>.
</p>
<p>
</p>
<blockquote>
This game model of software development has stood me in good stead recently, as I evaluate military software projects and open-source software development. In some of the military software projects, what we see is predominance of the career and corporate-enhancing infinite games. It is quite clear that delivery of the software is a secondary concern, and growing the company, growing personal influence, or growing the career is what is many people's minds. The logic of the funny contractor behavior doesn't make sense until you realize they are playing a different game, in which different moves are called for. Then it suddenly all makes sense - even if you don't like it.
<p>
Open-source development is different because it is not a resource-limited game, nor is it finite and end-point directed. Linus Torvald did not say, "We'll make a shippable copy of Linux, and then we can all go home." No, Linus is around, and it will evolve. The game is interesting as long as it is interesting. Any number of players may show up, and they are not on a time-line. The game will abandoned as soon as it stops being interesting for the players. In that sense, it is much more like musicians playing together, or carpet-wrestling, or lego building. It is a cooperative game that is not directed toward "reaching the goal", and is not built around managing scant resources. And so the moves that make sense in open-source development naturally don't make the same sense for a standard resource-limited, goal-seeking software development project.
</p>
</blockquote>
<p>
The idea that games can inform real world design problems is not a new one; Damion Schubert's presentation <a href="http://www.zenofdesign.com/?p=500">What Vegas Can Teach MMO Designers</a> is full of similar insight. Casinos are the original MMORPG spaces, as outlined in <a href="http://www.zenofdesign.com/images/casinos.ppt">Damion's presentation</a> (ppt).
</p>
<p>
<a href="http://www.zenofdesign.com/images/casinos.ppt"><img alt="image placeholder" >
</p>
<p>
The concept of software development as a collaborative game appeals to me. It speaks to a deeper level of engagement in the process than "I get paid to do this." We play games because we derive some kind of essential satisfaction from playing them. You might even say it's fun-- either the <a href="http://www.codinghorror.com/blog/archives/000030.html">explicit kind</a>, or the <a href="http://www.codinghorror.com/blog/archives/000628.html">implicit kind</a>.
</p>
<p>
Fun may be more relevant than you think to your project. Raph Koster is a notable game designer and programmer who <a href="http://www.amazon.com/exec/obidos/ASIN/1932111972/codihorr-20">writes entire books on the theory of fun</a>.
</p>
<p>
<a href="http://www.theoryoffun.com/"><img alt="image placeholder" >
</p>
<p>
Take a minute to read Raph's classic <a href="http://www.theoryoffun.com/theoryoffun.pdf">theory of fun</a> (pdf) presentation. What you'll eventually realize is that <b>designing for fun isn't just important for game developers. It's important for <i>all</i> software developers.</b>
</p>
<p>
Do users <a href="http://www.codinghorror.com/blog/archives/000773.html">want to use your application</a>, or are they <i>forced</i> to use it?
</p>
<p>
In a <a href="http://www.raphkoster.com/gaming/etech07.shtml">recent ETech07 presentation</a> (also available <a href="http://www.raphkoster.com/gaming/etech07/TheCoreOfFun.pdf">as a PDF</a>), Raph connects the dots more explicitly. He deconstructs amazon.com, ebay.com, and linkedin.com for what they really are: massively distributed <i>games</i>. You'll want to read the <a href="http://www.wonderlandblog.com/wonderland/2007/03/etech_07_raph_k.html">transcript of the talk</a> along with the sides to dig a little deeper into the concepts:
</p>
<p>
</p>
<blockquote>
As you accomplish more, there need to be variant challenges. Connecting to a CEO on LinkedIn vs. connecting to the pr dude = different. What you want is for the game to acknowledge the fact that it's tougher to get on Reed Hoffman's linkedin rather than someone who sells ads.
<p>
Social media is about cooperation, but the core of games is competitive. As soon as you give people a ladder to climb, they'll climb it. Ratings. Metrics of contribution. Other people need to see it to measure against it.
</p>
</blockquote>
<p>
Software development is a collaborative game that you play, willingly or not, with your team and your users. You might say the secret of the game, then, is <b>learning how to play the game so that everyone is having fun</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-03-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-development-as-a-collaborative-game/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ All About My Cats! ]]></title>
<link>https://blog.codinghorror.com/all-about-my-cats/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<font color="red">Update 4/2/2007</font>: In case it wasn't clear, the topic of this post is part an <a href="http://en.wikipedia.org/wiki/April_Fools'_Day">April fool's joke</a>. Yes, those are our cats, and I love them to death, but I <i>hope</i> cat blogging is the last thing you'd expect from me. The other part was a wholesale switch to <b>the most obnoxious advertisements I could find</b> on the front page of this blog. If you didn't get to see it, check out <a href="https://blog.codinghorror.com/content/images/2014/Jun/codinghorrorapril12007cf2.png">a screenshot</a>. A static screenshot doesn't do the blinking, flashing, and live video (with sound!) justice, but it's nothing you haven't seen before elsewhere. Unfortunately.
</p>
<p>
My wife and I own two cats. Although they haven't <a href="http://ripley-the-cat.livejournal.com/">started their own blog</a>-- yet-- I'd like to introduce you to them today.
</p>
<p>
After my wife and I moved into our first home together, we started to consider pets. Up until that point we were renters, so pets were out of the question. My wife noticed Floyd in the weekly animal rescue ad in the local newspaper, and we were immediately smitten by his sweet face and his old-timey name. We adopted Floyd in summer 2001.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As promised in the ad, Floyd is very, very sweet. He's a docile, zen-like cat with the World's Loudest Purr. He loves to curl up next to my head after I get in bed, and once he gets his "motor" going, it's the equivalent of a diesel engine idling inches from your face. I affectionately refer to Floyd as Buddy, Domestic Shorthair California Puma, or just plain Puma. The puma reference is meant to be ironic because Floyd is scared of almost everything and everyone except us. But he's certainly come a long way from the mean streets of Durham, North Carolina where he was rescued as a stray.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If you're a cat owner and a computer user, you know how difficult it can be to get anything done with a cat around. Cats love nothing more than curling up <i>directly</i> in front of your keyboard for attention. Here's <a href="http://www.youtube.com/watch?v=-zud8OdKN6M">a short video I uploaded to YouTube of me petting Floyd</a> in front of my computer. It is safe for work, as long as you're comfortable with hot, sweet, man-on-cat action.
</p>
<p>
After about a year, we started thinking about adopting a second cat. We noticed that Floyd had little to do when we weren't around-- my wife and I both work-- and that he seemed to be retreating back into his shell after making so much progress in a year of living with us. We figured once you have the first cat, adding a second cat is hardly any additional work, and they can entertain each other when you're not around.
</p>
<p>
We visited our friend Diane, who rescued Floyd, and she introduced us to Elsie.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Elsie is definitely the Yin to Floyd's Yang. She's <i>nuts</i>. We had to install child locks on all of our cabinets because she would open them with her paw and get into whatever she could find. We bought a breadbox after finding a giant, ragged chunk ripped out of the wrapped loaf of bread we had left on the counter the day before.
</p>
<p>
Elsie can never get enough playtime, and delights in messing with Floyd and finding new cat hiding places. She demands attention, even when I'm working on the computer.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
We love Elsie, but I do slightly regret adopting a long-haired cat. The increase in the volume of cat hair was immediate and dramatic. After Elsie arrived, instead of vacuuming bi-weekly or monthly, we had to vacuum weekly. No surprise, then, that I typically refer to her by her nicknames: Fluffy or Big Ball o' Fluff. We often wonder what she really looks like under all that fur.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Now that Elsie's on the scene, I can definitively say that Floyd is no longer bored. Having two cats is far more entertaining for them-- and for us, too.
</p>
<p>
I'm not necessarily a "cat person" so much as I am an animal lover. I think the whole Dog vs. Cat war is ludicrous. (But I will say that cats are a far better match for lazy people like me.) Pets are amazing companions. I encourage you to visit your local animal rescue shelter and adopt a pet of your own.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/all-about-my-cats/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Projects as Rock Climbing ]]></title>
<link>https://blog.codinghorror.com/software-projects-as-rock-climbing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you accept the premise that <a href="http://www.codinghorror.com/blog/archives/000826.html">software development is a cooperative game</a>, then you might wonder: <b>what kind of game is it?</b>
</p>
<p>
Alistair Cockburn believes the closest analog to a software project is <a href="http://alistair.cockburn.us/index.php/Software_development_as_a_cooperative_game#---------------_4._Games">the cooperative game of rock climbing</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<ul>
<li>
<b>Technical.</b> The novice can only approach simple climbs. With practice, the climber can attack more and more difficult climbs. The more technically proficient rock climber can do things that the others cannot. Similarly, software development is technical and requires technical proficiency, and there is a frank difference in what a more skilled person can do compared with a less skilled person.
<p>
</p>
</li>
<li>
<b>Individual and Team.</b> Some people naturally climb better than others. Some people will never handle certain climbs. At each moment of the climb, each person is drawing on their own capabilities. They have to hold their own weight. And yet climbing is usually done in teams. There are solo climbers, but they are in the minority. Under normal circumstances, climbers form a team and the team has to work together to complete the climb. Similarly, software developers, while working on their individual assignments, must function as a team to get the software out.
<p>
</p>
</li>
<li>
<b>Tools.</b> Tools are a requirement for serious rock-climbing: chalk, chucks, harness, rope, carabiner, and so on. It is important to be able to reach for the right tool for the right moment. It is possible to climb very small distances with no tools. The longer the climb, the more critical the tool selection is. Software developers will recognize this. When you need a performance profiler, you really need it. You can't function without the compiler. The team gets stuck without the version control system. And so on.
<p>
</p>
</li>
<li>
<b>Planning and Improvising.</b> Whether bouldering, doing a single-rope climb, or a multi-day climb, the climbers always make a plan. The longer the climb, the more extensive the plan must be, even though the team knows that the plan will be insufficient, and wrong in places. Unforeseen, unforeseeable and purely chance obstacles are certain to show up on even the most meticulously planned climbing expeditions, unless the climb is short and the climbers have completed it several times before. Therefore, the climbers must be prepared to change their plans, to improvise, at a moment's notice. This dichotomy is part of what makes software development manages gnash their teeth. They want a plan, but have to deal with unforeseen difficulties. It is one of the reasons why incremental development is so critical to project success. It is why climbers climb in stages, and set various base camps.
<p>
</p>
</li>
<li>
<b>Fun.</b> Climbers climb because it is fun. Climbers experience a sense of flow while climbing, and this total occupation is part of what makes it fun. Similarly, programmers typically enjoy their work, and part of that enjoyment is getting into the flow of designing or programming.
<p>
</p>
</li>
<li>
<b>Challenging.</b> Climbers climb because there is a challenge. Can they really make it to the top? Most programmers crave this challenge, too. If programmers do not find their assignment challenging, they may quit, or start embellishing the system with design elements they find challenging.
<p>
</p>
</li>
<li>
<b>Resource-limited.</b> Rock climbing works against a time and energy budget. The climb needs to be completed before the team is too tired, before the food runs out, by nightfall or before the snows come.
<p>
</p>
</li>
<li>
<b>Dangerous.</b> If you fall wrong on a rock climb, you can be killed or maimed. This is probably the one aspect of rock climbing that does not transfer to software development. Rock climbers are fond of saying that climbing, done properly, is less dangerous than driving a car. However, I have never heard programmers compare the danger of programming with the danger of driving a car or even crossing the street.
</li>
</ul>
<p>
I'll admit I had never quite thought of software development in this way, but Alistair's rock climbing metaphor holds. It's certainly a far better metaphor than <a href="http://www.codinghorror.com/blog/archives/000298.html">the tired old bridge building chestnut</a>. I see further analogs in the way the natural environment itself-- and the difficult to predict, uncontrollable weather conditions-- can make or break a project.
</p>
<p>
The one unsatisfying aspect of the rock climbing metaphor is that <b>software tends to build upon itself in a way that rock climbing doesn't.</b> Each subsequent version of the software expands on the capabilities and the platform established in the previous version. So there are really <i>two</i> goals:
</p>
<p>
</p>
<ol>
<li>to reach the summit.
</li>
<li>to make it easier for subsequent teams to reach the summit.
</li>
</ol>
<p>
But these goals can be mutually exclusive. In a <a href="http://alistair.cockburn.us/index.php/The_end_of_software_engineering_and_the_start_of_economic-cooperative_gaming#Games.2C_Cooperative_Games.2C_Series.27_of_Games">followup article</a>, Alistair illustrates with an example he calls "The Swamp Game".
</p>
<p>
</p>
<blockquote>
Consider a race across an uncharted swampland in which some particular (unknown) artifact must be produced at some particular (unknown) place in the swamp. A team in this race would employ scouts and specialists of various sorts, and would create maps, route markings, bridges and so on. The racers would not, however, construct commercial quality maps, roads or bridges, since doing so would waste precious resources. Instead, they would estimate how much or little of a path must be cleared for themselves, how strong to build the bridge, how fancy of markings to make, how simple a map, in order to reach their goal in the shortest time.
<p>
If the race is run as part of a series, there will be new teammates coming after them to pick up the artifact and move it to a new place. The first team will therefore be well served to make slightly better paths, maps and bridges, always keeping in mind that doing this work competes with completing the current stage of the race. They also will be well served if they leave some people who understand the territory to be part of the next team. <b>Thus, the optimal strategies for a series of races are different than for a single race.</b>
</p>
<p>
There is no closed-form formula for winning the game. There are only strategies that are more useful in particular situations. That realization alone may be the strongest return for using the economic-cooperative game language: people on live projects see that they must constantly observe the characteristics of the changing situation, to collect known strategies, to invent new strategies on the fly; and that since a perfect outcome is not possible in an overconstrained situation, they much choose which outcome to prioritize at the expense of which others.
</p>
</blockquote>
<p>
I find Alistair's game theories fascinating and illuminating. Based on the strength of these two essays, I just picked up a copy of Alistair's book, <a href="http://www.amazon.com/exec/obidos/ASIN/0201699478/codihorr-20">Crystal Clear: A Human-Powered Methodology for Small Teams</a>. It's based on the same <a href="http://alistair.cockburn.us/index.php/Cooperative_game_manifesto_for_software_development">cooperative game manifesto</a> I've covered in my last two entries.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201699478/codihorr-20"><img alt="image placeholder" >
</p>
<p>
I've already run into one team using the Crystal method (no, not <a href="http://en.wikipedia.org/wiki/The_Crystal_Method">that crystal method</a>) at a customer site. I'll have to check in with them next week and see how close they are to the summit.
</p>
<p>
And the next time someone asks <i>you</i> why software projects are <a href="http://www.codinghorror.com/blog/archives/000588.html">so challenging</a>, <b>invite them to go rock climbing with you</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-projects-as-rock-climbing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Mouse DPI and USB Polling Rate ]]></title>
<link>https://blog.codinghorror.com/mouse-dpi-and-usb-polling-rate/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Despite my heavy computer use, <a href="http://www.codinghorror.com/blog/archives/000605.html">I rarely experience hand or wrist pain</a>. I consider myself fortunate. However, my mouse hand has been aching a bit lately. In light of my this, I decided it was time to change things up on the mouse front. I currently use the <a href="http://www.codinghorror.com/blog/archives/000286.html">Logitech MX518</a> mouse at work and the <a href="http://www.codinghorror.com/blog/archives/000362.html">Logitech G5</a> mouse at home. Both have the same roughly egg-like shape. I've never been completely satisfied with this shape, but it was the best of the available options at the time.
</p>
<p>
A little research turned up an excellent new alternative: the <a href="http://www.amazon.com/exec/obidos/ASIN/B000H16G3W/codihorr-20">Microsoft Habu mouse</a>. The Habu is roughly the same size and shape as <a href="http://www.amazon.com/exec/obidos/ASIN/B000GOUE7O/codihorr-20">the classic Intellimouse Explorer</a>, which is one of my all-time favorites.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000H16G3W/codihorr-20"><img alt="image placeholder" >
</p>
<p>
The Habu is a collaboration between Microsoft and <a href="http://www.razerzone.com/">Razer</a>. Razer is best known for their freakishly shaped high-end gaming mice, which I've never been a fan of. Fortunately, the Habu seems to have inherited the best traits from its parents: the classic <em>body</em> of the Intellimouse Explorer, with the sophisticated <em>brains</em> of a Razer gaming mouse. I thought I'd disable the blue LEDs straight away, but as a kid who grew up with the movie <a href="http://www.imdb.com/title/tt0084827/">TRON</a>, the retro blue outline look is growing on me.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The Habu has all the key features I personally look for in a mouse:
</p>
<ul>
<li>Wired
</li>
<li>High resolution LED or laser
</li>
<li>Conveniently placed forward and back thumb buttons
</li>
<li>On-the-fly adjustable DPI in hardware
</li>
</ul>
<p>
The Habu delivers resolution in spades; it offers four levels selectable via the small buttons behind the mouse wheel: 400, 800, 1600 or 2000 DPI. On top of that, the Habu has one truly unique feature: <strong>it stores all of its settings in onboard flash memory</strong>. It's the first mouse I've ever owned with firmware. Once you've configured the settings to taste, you can unplug the mouse, bring it to another computer, and those settings will be retained.
</p>
<p>
If, like me, you've invested in a high resolution mouse, there's one additional trick you should know to get the most out of it. The default USB polling rate is 125 Hz, which means the mouse cursor can only be updated every 8 milliseconds. But it is possible to <strong>increase the USB polling rate via software or hardware</strong>.
</p>
<table width="300">
<tbody>
<tr>
<td align="right">Polling rate</td>
<td align="right">Response time</td>
</tr>
<tr>
<td align="right">125 Hz</td>
<td align="right">8 ms</td>
</tr>
<tr>
<td align="right">250 Hz</td>
<td align="right">4 ms</td>
</tr>
<tr>
<td align="right">500 Hz</td>
<td align="right">2 ms</td>
</tr>
<tr>
<td align="right">1000 Hz</td>
<td align="right">1 ms</td>
</tr>
</tbody>
</table>
<p>
It's no coincidence that the Razer Habu and the latest Logitech mice automatically increase the USB polling rate in hardware. Whenever you plug them in, you'll benefit from the higher polling rate. Here's a screenshot of the Habu driver settings; you can select both your preferred DPI and polling rate, and write that into the mouse firmware permanently.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You can check your current mouse's USB polling rate via a utility like the <a href="http://www.codinghorror.com/blog/files/dx_mouse_timer_dialog.zip">Direct Input mouse rate tool</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Low-end mice and wireless interfaces may not be able to exceed the default 125 Hz USB polling rate, but you won't know until you try. To change your USB polling rate in software, refer to the following guides.
</p>
<ul>
<li>
<a href="http://forum.overclock3d.net/showthread.php?s=e327793189712e82bdacc9c4ffc99950&amp;t=8561">How to change the USB polling rate in Windows Vista</a>
</li>
<li>
<a href="http://www.overclock.net/faqs/73418-how-improve-mouse-response-accuracy-changing.html">How to change the USB polling rate in Windows XP or Windows 2003</a>
</li>
<li>
<a href="http://www.linux-gamers.net/modules/wiwimod/index.php?page=HOWTO+USBPolling">How to change the USB polling rate in Linux</a>
</li>
</ul>
<p>
If you own a reasonably nice mouse, and the mouse rate tool reports 125 Hz movement, I recommend bumping up the USB polling rate in software. Turning the polling rate all the way up to 1000 Hz probably isn't necessary. But <strong>if you're sensitive to cursor smoothness at all, I can practically guarantee you will feel the difference between 125 Hz and 500 Hz.</strong>
</p>
<p>
If you think all this talk of high DPI mice and USB polling rates is obsessive, trust me, it's merely the tip of the iceberg. <a href="http://www.esreality.com/?a=post&amp;id=1265679">ESReality developed an entire test rig for scientifically benchmarking mice</a>, and legions of twitch game players <a href="http://www.overclock.net/computer-peripherals/173255-cs-s-mouse-optimization-guide.html">pore over every minute detail of their mouse settings</a>.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/mouse-dpi-and-usb-polling-rate/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Pick a License, Any License ]]></title>
<link>https://blog.codinghorror.com/pick-a-license-any-license/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I hate software licenses. When I read a software license, what I see is a bunch of officious, mind-numbing lawyerly doublespeak. Blah, blah,   blah.. <em>kill me now.</em></p>
<p><img alt="image placeholder" >
<p>If I had my way, everything would be released under the <a href="http://sam.zoy.org/wtfpl/">WTFPL</a>. Over time, I've begrudgingly come to the conclusion   that, like lawyers, death, and taxes, choosing a software license is inevitable.     Of course, it doesn't matter if yours are the only human eyes that   will ever see the code. But <strong>a proper software license is a necessary evil for any code you plan to release to the public</strong>.</p>
<p>I definitely regret not choosing a software license for my CodeProject articles. I'll occasionally get friendly emails from people asking   permission to use the code from my articles in various projects, commercial and otherwise. It's thoughtful of people to ask first. I do appreciate it, and permission is   always granted with the single caveat that my name and URL remain in the comments.</p>
<p><span style="color: red;">Because I did not explicitly indicate a license, I declared an implicit copyright without explaining how others could use my code.</span> Since the code is unlicensed, I could theoretically assert copyright at any time and demand that people stop using my code. Experienced developers won't touch unlicensed code because <em>they have no legal right to use it</em>. That's ironic, considering the whole reason I posted the code in the first place was so other developers could benefit from that code.  I could have easily avoided this unfortunate situation if I had done the right thing and <strong>included a software license with my code</strong>.</p>
<p>Unfortunately, we love software licenses like we love standards – that's why <a href="http://www.opensource.org/licenses/alphabetical">there are so many of them</a>. And what, exactly, are the differences between all these licenses? How do you select the correct license for your software? I've attempted to succinctly capture the key differences between the most well-known software licenses in the following handy chart.</p>
<table cellspacing="3" cellpadding="3" width="720px" style="">
<tbody>
<tr>
<td width="100" valign="top" style="border-bottom:dotted 1px black"></td>
<td width="100" valign="top" style="border-bottom:dotted 1px black">Source</td>
<td width="170" valign="top" style="border-bottom:dotted 1px black">Type (Clauses)</td>
<td valign="top" style="border-bottom:dotted 1px black"></td>
</tr>
<tr>
<td valign="top"><b>None</b></td>
<td valign="top">Open</td>
<td valign="top">
<span style="color: red;">None</span> (0)</td>
<td valign="top">Without a license, the code is copyrighted by default. People can read the code, but they have no legal right to use it. To use the code, you must contact the author directly and ask permission.</td>
</tr>
<tr style="background-color:#eee">
<td valign="top"><a href="http://en.wikipedia.org/wiki/Public_domain"><b>Public domain</b></a></td>
<td valign="top">Open</td>
<td valign="top">Permissive (0)</td>
<td valign="top">If your code is in the   public domain, anyone may use your code for any purpose whatsoever. Nothing is in the public domain by default; you have to explicitly put your   work in the public domain if you want it there. Otherwise, you must be dead a long time before your work reverts to the public domain.</td>
</tr>
<tr>
<td valign="top"><a href="http://en.wikipedia.org/wiki/GNU_General_Public_License">GPL</a></td>
<td valign="top">Open</td>
<td valign="top">Copyleft (12)</td>
<td valign="top">The archetypal bearded, sandal-clad free software license. Your code can never be used in any proprietary program, ever! Take that, capitalism!</td>
</tr>
<tr style="background-color:#eee">
<td valign="top"><a href="http://en.wikipedia.org/wiki/GNU_Lesser_General_Public_License">LGPL</a></td>
<td valign="top">Open</td>
<td valign="top">Mostly Copyleft (16)</td>
<td valign="top">GPL with a cleverly-constructed pressure valve release. Your free software can be binary linked to proprietary programs under certain very specific circumstances.</td>
</tr>
<tr>
<td valign="top"><a href="http://en.wikipedia.org/wiki/MIT_License">MIT/X11</a></td>
<td valign="top">Open</td>
<td valign="top">Permissive (2)</td>
<td valign="top">Short and sweet.  Includes generic legal disclaimer of liability.</td>
</tr>
<tr style="background-color:#eee">
<td valign="top"><a href="http://en.wikipedia.org/wiki/BSD_license">BSD</a></td>
<td valign="top">Open</td>
<td valign="top">Permissive (2)</td>
<td valign="top">Short and sweet.  Includes legal disclaimer of liability with explicitly named organization.</td>
</tr>
<tr>
<td valign="top"><a href="http://en.wikipedia.org/wiki/Apache_License">Apache</a></td>
<td valign="top">Open</td>
<td valign="top">Permissive (9)</td>
<td valign="top">Requires derivative works to provide notification of any licensed or proprietary     code in a common location.</td>
</tr>
<tr style="background-color:#eee">
<td valign="top"><a href="http://en.wikipedia.org/wiki/Eclipse_Public_License">Eclipse</a></td>
<td valign="top">Open</td>
<td valign="top">Permissive (7)</td>
<td valign="top">Business friendly. Allows derivative works to choose their own license for their contributions.</td>
</tr>
<tr>
<td valign="top"><a href="http://en.wikipedia.org/wiki/Mozilla_Public_License">Mozilla</a></td>
<td valign="top">Open</td>
<td valign="top">Weak Copyleft (13)</td>
<td valign="top">Allows liberal mixing with proprietary software.</td>
</tr>
<tr style="background-color:#eee">
<td valign="top"><a href="http://www.microsoft.com/resources/sharedsource/licensingbasics/permissivelicense.mspx">MS Permissive</a></td>
<td valign="top">Open</td>
<td valign="top">Permissive (3)</td>
<td valign="top">Resembles the MIT and BSD licenses. Not formally accepted by OSI, and also offered in a "Windows-only" LPL   variant.</td>
</tr>
<tr>
<td valign="top"><a href="http://www.microsoft.com/resources/sharedsource/licensingbasics/communitylicense.mspx">MS Community</a></td>
<td valign="top">Open</td>
<td valign="top">Copyleft (3)</td>
<td valign="top">Resembles the GPL license. Requires all contributed code to be returned to the community. Not formally accepted by OSI, and also offered in a "Windows-only" LCL   version.</td>
</tr>
<tr style="background-color:#eee">
<td valign="top"><a href="http://www.microsoft.com/resources/sharedsource/licensingbasics/referencelicense.mspx">MS Reference</a></td>
<td valign="top">Proprietary</td>
<td valign="top">Read Only (3)</td>
<td valign="top">You can review the code, or make copies of it, but you can't use it or change it in any way. Allows a window (no pun intended) on formerly completely proprietary, secret code.</td>
</tr>
</tbody>
</table>
<p>After compiling this table, I've learned two things:</p>
<ol>
<li>My head hurts.</li>
<li>I still prefer the <a href="http://sam.zoy.org/wtfpl/">WTFPL</a>. </li>
</ol>
<p>I'm not even going to get into the many <a href="http://www.codinghorror.com/blog/archives/000247.html">religious issues</a> of software   licensing, such as...</p>
<ul>
<li>
<a href="http://en.wikipedia.org/wiki/Open_source">open-source software</a> vs.             <a href="http://en.wikipedia.org/wiki/Proprietary_software">proprietary software</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Copyleft">copyleft licensing</a> vs. <a href="http://en.wikipedia.org/wiki/Permissive_license">permissive licensing</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Tivoisation">Tivoization</a> in hardware</li>
<li>the   pernicious issue of <a href="http://en.wikipedia.org/wiki/Software_patent">software patents</a>. </li>
</ul>
<p>It's a minefield, people. All I'm saying is this: <strong>the next time you release code into the wild, do your fellow developers a favor and pick a license – any license</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/pick-a-license-any-license/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Firefox as an IDE ]]></title>
<link>https://blog.codinghorror.com/firefox-as-an-ide/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although <a href="http://www.codinghorror.com/blog/archives/000789.html">I prefer IE7's native speed and feel</a> for day-to-day browsing chores, there's no doubt that <b>Firefox is my primary web development IDE</b>.
</p>
<p>
Whenever I need to troubleshoot HTML, CSS, or JavaScript, I immediately reach for Firefox. That's primarily because of two incredibly powerful developer extensions for Firefox:
</p>
<p>
<b>1. <a href="http://chrispederick.com/work/webdeveloper/">Web Developer Extension</a></b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
WDE has lots of useful features, but the most wonderful thing about WDE is that <b>everything is editable in real-time</b>. Edit the CSS, edit the HTML, and watch your changes take effect as you type. It's like magic.
</p>
<p>
<b>2. <a href="http://www.getfirebug.com/">Firebug</a></b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://www.getfirebug.com/">Firebug</a> is a richer tool than WDE; it goes far beyond real-time editing of HTML and CSS, and delves deeply into profiling and debugging JavaScript. It also offers metrics on download time and download order over the wire. I highly recommend checking out <a href="http://ajaxian.com/archives/joe-hewitt-firebug-power-user-demo">the Joe Hewitt Firebug power user demo movie</a> to get a sense of its full feature set.
</p>
<p>
I can't imagine debugging a web app without these two essential tools, which <b>transform Firefox into the Visual Studio of browsers</b>. It'd be akin to <a href="http://www.codinghorror.com/blog/archives/000195.html">writing a .NET application in Notepad</a>. In fact, I feel so strongly about the utility of these extensions that I'm stopping to donate $10 to each project, right now. This is part of <a href="http://www.codinghorror.com/blog/archives/000735.html">my ongoing monthly contribution to small software vendors</a>.
</p>
<p>
If you haven't used these tools yet, I envy the experience you're about to have. Download them both and start experimenting. If you have used Firebug and WDE, I encourage you to share your favorite tips in the comments.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/firefox-as-an-ide/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ SEOs: the New Pornographers of the Web ]]></title>
<link>https://blog.codinghorror.com/seos-the-new-pornographers-of-the-web/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
There's something about the Search Engine Optimization (SEO) industry that I find highly distasteful. I've never quite been able to put my finger on it, until I read Rich Skrenta's <a href="http://www.skrenta.com/2007/04/early_adopter_pilotfish_pornog.html">pornographers vs. SEOs</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's all clear to me now.
</p>
<p>
<b>SEOs are the new pornographers of the web.</b>
</p>
<p>
Money is the most prurient interest of all. Just as pornographers sell sex, SEOs sell money. They trade in <b>get-rich-quick schemes via search traffic</b>.
</p>
<p>
Rich pointed out <a href="http://www.seomoz.org/blog/and-yet-the-diggs-keep-going-up">this SEOmoz post</a> as an example:
</p>
<p>
</p>
<blockquote>
My favourite Digg irony is the hatred the (a-HEM) Diggorati have for SEO, coupled with the fact that <i>they fall for linkbait All. The. Time.</i>
<p>
Every so often, one of our employees will roll into the office and announce, "I'm going to get on Digg today." Said employee will sit down, write something and then nervously monitor the server as predicted Digg occurs. I can only remember one instance in which this tactic has failed. The post does not always come from SEOmoz; in fact, it's often posted elsewhere. Sometimes, some Diggers will catch on to the fact that the submission came from someone affiliated with SEO and the comments will get nasty, but still the diggs keep going up.
</p>
</blockquote>
<p>
If that's not pure gaming of the system, I don't know what is. There are entire guides on how to properly linkbait, such as <a href="http://tropicalseo.com/2007/andy-hagans-ultimate-guide-to-link-baiting-and-social-media-marketing/">Andy Hagans' Ultimate Guide to Linkbaiting and Social Media Marketing</a>. Read it. I did, and now I feel like I just walked through a sewer.
</p>
<p>
Although SEOs pay lip service to the quality of the content, it's clear that the focus is on one thing, and one thing only: naked, <a href="http://www.shoemoney.com/2006/05/08/plentyoffish-marketing-101-when-all-else-fails-just-lie/">raw <i>greed</i></a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Jason Calacanis is probably <a href="http://www.calacanis.com/2007/02/07/why-people-hate-seo-and-why-smo-is-bulls-t/">the most prominent critic of SEO techniques</a>.
</p>
<p>
</p>
<blockquote>
The SEO folks got really pissed off at me <a href="http://www.calacanis.com/2006/12/06/black-hat-and-white-hat-seo-or-is-seo-b-s-or-not/">for saying "SEO is bulls@#t" last year</a>, but the truth is that 90% of the SEO market is made up of snake oil salesman. These are guys in really bad suits trying to get really naive people to sign long-term contracts. These clients typically make horrible products and don't deserve traffic. That's why they're not getting it organically. So they hire the slimebuckets to game the system for them.
<p>
There are some whitehat SEO firms out there, but frankly the whitehat SEO companies are simply doing solid web design. I don't consider them SEO at all. SEO is a tainted term and it means "gaming the system" to 90% of us.
</p>
</blockquote>
<p>
So much of what is optimistically termed Search Engine Optimization is basic web design 101. And yet the seedy SEO underground will still try to convince you their super-secret methods-- their magical snake oil-- is the only formula for success.
</p>
<p>
In fact, <b>the only difference between SEO "experts" and pornographers is that pornographers are more honest about what they're actually selling</b>. Hiring a SEO expert to increase the quality of your site's content is like renting a porn video for the plot and character development. Stop kidding yourselves.
</p>
<p>
What's most depressing about all of this is that reliance on SEO is <a href="http://www.scribd.com/doc/25132/Why-YCombinator-is-a-waste-of-time">ultimately self-defeating</a>.
</p>
<p>
</p>
<blockquote>
Let me tell you a story about my cousin, Steven. Steven wanted to become a musician. He had a rock band he diligently put together, and they recorded an album. When he played the album for me, he described it as a mixture of Green Day with some Linkin Park. He told me how he took the best of both bands and created his own sound.
<p>
The problem was, his music was boring, and his band sounded like hundreds of other indie bands.
</p>
<p>
Steven was just an average looking guy, his band was good but not brilliant, his music was solid, but not different. Steven believed in his band, and he was just good enough for everyone to encourage him to go on working on music, but never good enough to attract a fan base.
</p>
<p>
But Steven never even tried to build up fans. He never played his music for totally random people, and asked them for their opinion. All he did was try to get the people at the record labels interested in his music. He called and hounded, he stalked and staked out. He kept chasing those labels for years and years, and then suddenly gave up.
</p>
<p>
<b>Steven did not care about the music. Steven cared about the money. Steven did not concentrate on getting his music to the people, he concentrated on getting his music to the people who would guarantee him money and connections.</b>
</p>
</blockquote>
<p>
When you focus on SEO, you're focusing on money and connections. If that's your goal, then have at it. But don't be surprised when people see through you for what you really are.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/seos-the-new-pornographers-of-the-web/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ EA's Software Artists ]]></title>
<link>https://blog.codinghorror.com/eas-software-artists/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Electronic Arts is a lumbering corporate megalith today, pumping out yearly game franchise after yearly game franchise. It's easy to forget that EA was present at the very beginning of the computer game industry, innovating and blazing a trail for everyone to follow. Gamasutra's article <a href="http://gamasutra.com/features/20070216/fleming_01.shtml">We See Farther: A History of Electronic Arts</a> reminded me how instrumental EA was to the early history of computer gaming.
</p>
<p>
EA's infamous "We See Farther" ad promoted computer game programmers as artists if not rock stars. I distinctly remember seeing these ads as a dorky, computer-loving teenager. <b>I wondered, could being a computer programmer be.. <i>cool?</i></b>
</p>
<p>
<a href="http://www.codinghorror.com/blog/images/can-a-computer-make-you-cry.jpg">
<img alt="image placeholder" >
</p>
<p>
Okay, maybe not so much with the leather glove, but still. It was a glimmer of hope. According to Electronic Arts, computer programmers weren't just programmers; they could be <i>software artists</i>. And the earliest EA games even <i>looked</i> like rock album covers:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
EA also created the very concept of a sports game franchise, primarily with <a href="http://www.mobygames.com/game/pc-booter/dr-j-and-larry-bird-go-one-on-one">Dr. J and Larry Bird Go One on One</a>. This game was huge. The squeaking sneakers, the smashing backboard, the licensed marquee players. It was arguably <i>the</i> breakthrough sports game.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's impressive that Electronic Arts is still around after all these years. But I wonder what happened to the grandiose sentiments expressed in <a href="http://www.codinghorror.com/blog/images/can-a-computer-make-you-cry.jpg">the We See Farther ad</a>:
</p>
<p>
</p>
<blockquote>
These are wondrous machines we have created, and in them can be seen a bit of their makers. It is as if we had invested them with the image of our minds. And through them, we are learning more and more about ourselves. We learn, for instance, that we are more entertained by involvement of our imaginations than by passive viewing and listening. We learn that we are better taught by experience than by memorization. And we learn that the traditional distinctions-- the ones that are made between art and entertainment and education-- don't always apply.
<p>
We're providing a special environment for talented, independent software artists. It's a supportive environment, in which big ideas are given room to grow. And some of America's most respected software artists are beginning to take notice. We think our current work reflects this very special commitment. And though we are few in number today and apart from the mainstream of the mass software marketplace, we are confident that both time and vision are on our side.
</p>
</blockquote>
<p>
I sure wanted to believe in <i>software artistry</i> at the time. <a href="http://gamasutra.com/features/20070216/fleming_01.shtml">EA's history</a> proves that this is an <a href="http://www.codinghorror.com/blog/archives/000129.html">unusually difficult</a> vision statement to realize.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/eas-software-artists/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is Amazon's Mechanical Turk a Failure? ]]></title>
<link>https://blog.codinghorror.com/is-amazons-mechanical-turk-a-failure/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Amazon's <a href="http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Mechanical Turk Service</a> is a clever reference to the famous chess-playing hoax device, <a href="http://en.wikipedia.org/wiki/The_Turk">The Mechanical Turk</a>. The Mechanical Turk dates back to 1770, and has quite a storied history. Read through <a href="http://en.wikipedia.org/wiki/The_Turk">the Wikipedia article</a> if you have time; it's fascinating stuff.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The secret of the Turk, of course, was that it wasn't a chess-playing machine at all. There was a small person inside, controlling the machine.
</p>
<p>
Similarly, Amazon's Mechanical Turk is a machine that harnesses the work of hidden humans. It's a service that attempts to match people to small, bite-size units of work that are unsuitable for machines.
</p>
<p>
As of this writing, there are 128 Human Intelligence Tasks available via <a href="http://www.mturk.com/mturk/findhits?match=false">the Mechanical Turk task page</a>. The reward for these tasks ranges from $1.00 to $0.10, skewing heavily toward the bottom of that range. Almost 100 of the 128 tasks are $0.10 each. Here's a quick sampling of the available tasks:
</p>
<p>
</p>
<ul>
<li>Transcribe a 9 minute, 2 second podcast ($2.31 w/bonus)
</li>
<li>Write a review of a blog ($1.00)
</li>
<li>Make ten 2-3 sentence posts in a fansite forum ($0.50)
</li>
<li>Write a 2-3 paragraph blog entry ($0.50)
</li>
<li>Provide 3-D and 4-D ultrasound pictures of your baby ($0.40)
</li>
<li>Send unsolicited junk faxes from California companies ($0.25)
</li>
<li>Say 6 phrases in Turkish ($0.10)
</li>
<li>Write a short plot description of the movie "Black Snake Moan" ($0.10)
</li>
</ul>
<p>
Read through some of <a href="http://www.mturk.com/mturk/findhits?match=false">the available HITs</a> yourself. Be sure to click on the HIT to get the details on the job and any rules. You're at the mercy of the requester; it's up to them to judge your work worthy of payment.
</p>
<p>
Based on the quantity, quality, and type of tasks available, I think <b>Amazon's Mechanical Turk may be a failure</b>. It's been almost two years, and almost all the tasks have one or more of these problems:
</p>
<p>
</p>
<ol>
<li>obviously and suspiciously spammy
</li>
<li>require a lot of subjective human intervention and effort for "grading"
</li>
<li>the rates make working in a sweatshop seem lucrative
</li>
</ol>
<p>
What I find ironic about Amazon's Mechanical Turk service is that <b>Amazon built an entire business around the value of user reviews</b>. The strength of the user reviews is one of the main reasons I frequent Amazon. That's user-submitted content that people invested countless thousands of man-hours on. And <i>Amazon didn't pay anyone a dime to do it</i>.
</p>
<p>
I think the secret to running a viable Mechanical Turk service is, paradoxically, to do away with payment. Instead, they should have chosen a reward system based on intrinsic motivation. Intrinsic motivation is the reason why..
</p>
<p>
</p>
<ul>
<li>People willingly contribute millions upon millions of dollars worth of electricity to <a href="http://www.codinghorror.com/blog/archives/000823.html">efforts like Folding@Home</a> so they can show up on the leaderboards with their team.
</li>
<li>People spend hours submitting and rating articles on Digg and Reddit in the hopes that they will be promoted to the front page, and by proxy, increase their standing in the community.
</li>
<li>People actively convince others to join them on social networking sites like Linked In, MySpace, Classmates, and Facebook-- to increase the size and power of their networks.
</li>
</ul>
<p>
Nobody's paid to do any of the above. And yet each item I listed is easily equivalent to multiple Turk HITs. The best explanation I've found for this behavior is in Mary Poppendieck's <a href="http://www.poppendieck.com/pdfs/Compensation.pdf">Team Compensation</a> (pdf).
</p>
<p>
</p>
<blockquote>
There are two approaches to giving children allowances. Theory A says that children should earn their allowances; money is exchanged for work. Theory B says that children should contribute to the household without being paid, so allowances are not considered exchange for work. I know one father who was raised with Theory B but switched to Theory A for his children. He put a price on each job and paid the children weekly for the jobs they had done. This worked for a while, but then the kids discovered that they could choose among the jobs and avoid doing the ones they disliked. When the children were old enough to earn their own paychecks, they stopped doing household chores altogether, and the father found himself mowing the lawn alongside his neighbors' teenage children.
<p>
Were he to do it again, this father says he would not tie allowance to work.
</p>
<p>
In the same way, once employees get used to receiving financial rewards for
meeting goals, they begin to work for the rewards, not the intrinsic motivation that comes from doing a good job and helping their company be successful. <b>Many studies have shown that extrinsic rewards like grades and pay will, over time, destroy the intrinsic reward that comes from the work itself.</b>
</p>
</blockquote>
<p>
The theory of intrinsic motivation goes a long way toward explaining why Amazon's unpaid user reviews are so popular and effective, and yet the paid Mechanical Turk service appears to be withering on the vine.
</p>
<p>
Poppendieck notes that choosing a payment reward model can be an irreversible decision: <i>once you go down the path of monetary rewards, you may never be able to go back, even when they cease to be effective, as they inevitably will.</i> I think that's clearly the case for Amazon's Mechanical Turk.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-amazons-mechanical-turk-a-failure/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Usability Is Timeless ]]></title>
<link>https://blog.codinghorror.com/usability-is-timeless/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Jakob Nielsen's new book, <a href="http://www.amazon.com/exec/obidos/ASIN/0321350316/codihorr-20">Prioritizing Web Usability</a>, is a worthy companion to the previous two. Now it's a trilogy:
</p>
<ol>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/156205810X/codihorr-20">Designing Web Usability: The Practice of Simplicity</a> (2000)
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/073571102X/codihorr-20">Homepage Usability: 50 Websites Deconstructed</a> (2002)
</li>
<li>
<a href="http://www.amazon.com/exec/obidos/ASIN/0321350316/codihorr-20">Prioritizing Web Usability</a> (2006)
</li>
</ol>
<p>
You can tell Jakob and his co-authors are growing ever more skilled at <a href="http://www.codinghorror.com/blog/archives/000726.html">the practice of simplicity</a>; this book is the first in the series to drop the colon and subtitle.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0321350316/codihorr-20"><img alt="image placeholder" >
</p>
<p>
The very existence of the new, updated book hints that usability guidelines evolve over time. In one of the first chapters, Nielsen makes this explicit by revisiting earlier web usability issues to see how much they've improved in seven years. Each usability issue is rated from zero to three skulls to indicate how severe the problem is today:
</p>
<p>
<b>1. Usability issues that are still major problems today</b>
</p>
<p>
</p>
<table width="600">
<tr>
<td width="85">
<img alt="image placeholder" >
</td>
<td>Links that don't change color when visited</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Breaking the back button</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Opening new browser windows</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Pop-up windows</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Design elements that look like advertisements</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Violating web-wide conventions</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Vaporous content and empty hype</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Dense content and unscannable text</td>
</tr>
</table>
<p>
<b>2. Usability issues that are less important due to improvements in technology</b>
</p>
<p>
</p>
<table width="600">
<tr>
<td width="85"><img alt="image placeholder" >
<td>Slow download times</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Frames</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Adobe Flash content</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Low-relevancy search listings</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Multimedia and long videos</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Frozen layouts</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Cross-platform incompatibility</td>
</tr>
</table>
<p>
<b>3. Usability issues that are less important because users have adapted to the web</b>
</p>
<p>
</p>
<table width="600">
<tr>
<td width="85"><img alt="image placeholder" >
<td>Uncertain clickability</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Scrolling</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Registration</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Complex URLs</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Pull-down and cascading menus</td>
</tr>
</table>
<p>
<b>4. Usability issues that are less important because designers have learned restraint</b>
</p>
<p>
</p>
<table width="600">
<tr>
<td width="85"><img alt="image placeholder" >
<td>Plug-ins and bleeding edge technology</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>3D user interfaces</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Bloated design</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Splash pages</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Moving graphics and scrolling text</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Custom GUI widgets</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Not disclosing who's behind information</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Made-up words</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Outdated content</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Inconsistency within a web site</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Premature requests for personal information</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>Multiple sites</td>
</tr>
</table>
<p>
When comparing the severity of these 34 usability issues with their historical severity in 2000, Nielsen notes that <b>most of the progress can be attributed to designers learning restraint</b>:
</p>
<p>
</p>
<table width="275">
<tr>
<td width="225">Resolved by user adaptation</td>
<td>11%</td>
</tr>
<tr>
<td>Resolved by advances in technology</td>
<td>10%</td>
</tr>
<tr>
<td>Resolved by designer restraint</td>
<td>21%</td>
</tr>
<tr>
<td><font color="red">Still an issue</font></td>
<td><font color="red">58%</font></td>
</tr>
</table>
<p>
Relying on user education or technology fixes to address usability issues means you'll be waiting a long time. Most of the <i>immediate</i> benefits are realized by designers who learn to follow usability guidelines. But designers are fallible, too, so there's no guarantee these problems won't crop up again later, or in slightly different forms.
</p>
<p>
The data presented in Prioritizing Web Usability shows that usability guidelines do evolve over time, but <i>slowly</i>. It also illustrates how <b>the core principles of usability are timeless</b>:
</p>
<p>
</p>
<blockquote>
From 1984 to 1986, the U.S. Air Force compiled existing usability knowledge into a single, well-organized set of guidelines for its user interface designers called <a href="http://www.hcibib.org/sam/">Guidelines for Desigining User Interface Software, ESD-TR-86-278</a> (also <a href="http://www.dfki.de/~jameson/hcida/papers/smith-mosier.pdf">available as a pdf</a>). Jakob Nielsen was one of several people who advised the undertaking. The project identified 944 guidelines, most of them related to military command and control systems built in the 1970s and early 1980s, which used mainframe technology.
<p>
You might think that these old findings would be irrelevant to today's designers. If so, you'd be wrong. As an experiment, we retested 60 of the 1986 guidelines in 2005. Of these, 54 continue to be valid today. Of the total 944 guidelines, we deduced that 10 percent are no longer valid and 20 percent are irrelevant because they relate to rarely used interface technologies. <b>But nearly 70 percent of the orginal guidelines continue to be both correct and relevant 20 years later.</b>
</p>
</blockquote>
<p>
This is one of the reasons I urge software developers to study and understand the principles of usability. It's one of the precious few bodies of knowledge in a developer's toolkit that will still be useful twenty years from now.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/usability-is-timeless/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Pernicious Issue of Software Patents ]]></title>
<link>https://blog.codinghorror.com/the-pernicious-issue-of-software-patents/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A reddit user recently invoked link necromancy on <a href="http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html">a 1994 Donald Knuth letter</a> to the U.S. Patent Office:
</p>
<p>
</p>
<blockquote>
When I think of the computer programs I require daily to get my own work
done, <b>I cannot help but realize that none of them would exist today if
software patents had been prevalent in the 1960s and 1970s</b>.  Changing the
rules now will have the effect of freezing progress at essentially its
current level.  If present trends continue, the only recourse available to
the majority of America's brilliant software developers will be to give up
software or to emigrate.  The U.S.A.  will soon lose its dominant position.
<p>
Please do what you can to reverse this alarming trend.  There are far
better ways to protect the intellectual property rights of software
developers than to take away their right to use fundamental building
blocks.
</p>
</blockquote>
<p>
You have to respect the opinion of <a href="http://en.wikipedia.org/wiki/Donald_Knuth">Donald Knuth</a>, because he's our homeboy.
</p>
<p>
<a href="http://geekz.co.uk/shop/store/show/knuth-tshirt"><img alt="image placeholder" >
</p>
<p>
Still, opinions vary. The software patent debate <a href="http://en.wikipedia.org/wiki/Software_patent_debate">merits an entire Wikipedia article</a>, and the <a href="http://programming.reddit.com/info/1h2u0/comments">ensuing comment debate on Reddit</a> represents plenty of opposing viewpoints.
</p>
<p>
Paul Graham, surprisingly, <a href="http://paulgraham.com/softwarepatents.html">thinks software patents don't matter</a>:
</p>
<p>
</p>
<blockquote>
I'm not saying secrecy would be worse than patents, just that we couldn't discard patents for free. Businesses would become more secretive to compensate, and in some fields this might get ugly. Nor am I defending the current patent system. There is clearly a lot that's broken about it. But the breakage seems to affect software less than most other fields.
<p>
In the software business I know from experience whether patents encourage or discourage innovation, and the answer is the type that people who like to argue about public policy least like to hear: they don't affect innovation much, one way or the other. Most innovation in the software business happens in startups, and startups should simply ignore other companies' patents. At least, that's what we advise, and we bet money on that advice.
</p>
</blockquote>
<p>
Paul Heckel goes so far as to say <a href="http://www-swiss.ai.mit.edu/6805/articles/int-prop/heckel-debunking.html">responsible, rational use of software patents may actually <i>encourage</i> innovation</a>:
</p>
<p>
</p>
<blockquote>
In brief, what superficially looks like another problem to be dealt with in the increasingly competitive, commodities oriented software business, will prove to be what makes products less price competitive. Many industries have worked on this basis all along: patents make industries more diverse in their offerings, more profitable, more innovative, and ultimately will make the U.S. more competitive.
<p>
The essence of this article is simple: Software intellectual property issues are not inherently different in substance from other technologies; what motivates people is not inherently different; industry life cycle is not inherently different; marketing and business strategies and tactics are not inherently different; the law and policy issues are not inherently different. The technology is not even new. Software has been around for 40 years. The issues may be new to those who had no experience of them, but the only thing that is different is that software is a mass market industry for the first time and real money is at stake.
</p>
</blockquote>
<p>
As much as I respect Knuth, I have to agree that the problem with software patents isn't the patents themselves. It's the sloppy, haphazard way the patents are granted and enforced. If anything needs reforming, it's the U.S. Patent Office.
</p>
<p>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-pernicious-issue-of-software-patents/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Twitter: Service vs. Platform ]]></title>
<link>https://blog.codinghorror.com/twitter-service-vs-platform/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://twitter.com/">Twitter</a> is a victim of its own success. The site has massive scaling problems, to the tune of 11,000 pageviews per second. According to this <a href="http://www.radicalbehavior.com/5-question-interview-with-twitter-developer-alex-payne/">interview with a Twitter developer</a>, a lot of the scaling problems are attributable to Twitter's choice of platform:
</p>
<p>
</p>
<blockquote>
By various metrics Twitter is the biggest <a href="http://www.rubyonrails.org/">Rails</a> site on the net right
now. Running on Rails has forced us to deal with scaling issues -
issues that any growing site eventually contends with - far sooner
than I think we would on another framework.
<p>
The common wisdom in the Rails community at this time is that scaling
Rails is a matter of cost: just throw more CPUs at it. The problem
is that more instances of Rails (running as part of a Mongrel
cluster, in our case) means more requests to your database. At this
point in time there's no facility in Rails to talk to more than one
database at a time. The solutions to this are caching the hell out
of everything and setting up multiple read-only slave databases,
neither of which are quick fixes to implement. So it's not just
cost, it's time, and time is that much more precious when people can['t]
reach your site.
</p>
<p>
None of these scaling approaches are as fun and easy as developing
for Rails. All the convenience methods and syntactical sugar that
makes Rails such a pleasure for coders ends up being absolutely
punishing, performance-wise. Once you hit a certain threshold of
traffic, either you need to strip out all the costly neat stuff that
Rails does for you (RJS, ActiveRecord, ActiveSupport, etc.) or move
the slow parts of your application out of Rails, or both.
</p>
<p>
It's also worth mentioning that there shouldn't be doubt in anybody's
mind at this point that Ruby itself is slow. It's great that people
are hard at work on faster implementations of the language, but right
now, it's tough. If you're looking to deploy a big web application
and you're language-agnostic, realize that the same operation in Ruby
will take less time in Python. All of us working on Twitter are big
Ruby fans, but I think it's worth being frank that this isn't one of
those relativistic language issues. Ruby is slow.
</p>
</blockquote>
<p>
I've often said that <a href="http://www.codinghorror.com/blog/archives/000509.html">performance doesn't always matter</a>. But if, like Twitter, your business model is predicated on how fast your users can press the Refresh button in their browser, you could be in serious trouble if your service becomes popular.
</p>
<p>
What I find particularly amusing is the performance comparison with Python. It's hard to believe that Python is that much faster than Ruby. Python, like Ruby, is an interpreted language, and <b>interpreted languages are so slow that if you have to ask how much performance you're giving up, you can't afford it</b>. Consider this chart from Code Complete 2.0:
</p>
<p>
</p>
<table width="500">
<tr>
<td>
<strong>Language</strong>
</td>
<td>
<strong>Type of Language</strong>
</td>
<td>
<strong>Execution Time Relative to C++</strong>
</td>
</tr>
<tr>
<td>
C++</td>
<td>
Compiled</td>
<td>
1:1</td>
</tr>
<tr>
<td>
Visual Basic</td>
<td>
Compiled</td>
<td>
1:1</td>
</tr>
<tr>
<td>
C#</td>
<td>
Compiled</td>
<td>
1:1</td>
</tr>
<tr>
<td>
Java</td>
<td>
Byte code</td>
<td>
1.5:1</td>
</tr>
<tr>
<td style="color: red">
PHP</td>
<td style="color: red">
Interpreted</td>
<td style="color: red">
&gt; 100:1</td>
</tr>
<tr>
<td style="color: red">
Python</td>
<td style="color: red">
Interpreted</td>
<td style="color: red">
&gt; 100:1</td>
</tr>
</table>
<p>
I realize that Web 2.0 is built <a href="http://www.codinghorror.com/blog/archives/000573.html">on the back of the cheap "whatever box" server</a>. Twitter is probably the perfect storm of refresh-heavy design coupled with exponential growth. Most websites wish they were so lucky.
</p>
<p>
To be fair, it sounds like <a href="http://www.loudthinking.com/arc/000608.html">most of Twitter's problems are database problems</a>, so maybe it doesn't matter what language they use. But it does make you wonder: <b>what's more important-- the service, or the platform you deliver that service on?</b>
</p>
<p>
In the case where the latter is jeopardizing the former, I think it's pretty clear where your allegiances should lie. Your users don't care how cool the Rails platform is-- but they sure do care about consistent availability of your service.
</p>
<p>
<font color="red">Update:</font> This entry isn't as clear as it could be. See my <a href="http://www.codinghorror.com/blog/archives/000839.html">followup to this post</a> for a better explanation of my position.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/twitter-service-vs-platform/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Reddit: Language vs. Platform ]]></title>
<link>https://blog.codinghorror.com/reddit-language-vs-platform/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
My previous entry, <a href="http://www.codinghorror.com/blog/archives/000838.html">Twitter: Service vs. Platform</a>, was widely misunderstood. I suppose I only have myself to blame, so I'll try to clarify with another example.
</p>
<p>
Consider Reddit. The Reddit development team <a href="http://blog.reddit.com/2005/12/on-lisp.html">switched from Lisp to Python</a> late in 2005:
</p>
<p>
</p>
<blockquote>
If Lisp is so great, why did we stop using it? One of the biggest issues was the <b>lack of widely used and tested libraries</b>. Sure, there is a CL library for basically any task, but there is rarely more than one, and often the libraries are not widely used or well documented. Since we're building a site largely by standing on the shoulders of others, this made things a little tougher. There just aren't as many shoulders on which to stand.
<p>
On that note, if you have been considering writing a web application in Lisp, go for it. It will be tough if you're not already a Lisper, but you will learn a lot along the way, and it will be worth it I am sure. Lisp is especially great for projects where the end goal is unknown because it's so easy to steer in different directions. <b>Lisp will never get in your way, although sometimes the environment will.</b>
</p>
</blockquote>
<p>
Language performance is a red herring. That's especially true when we're comparing dynamic languages like Ruby, Lisp, and Python that will never be known for their high octane, nitro burnin' performance levels. I assumed Alex Payne knew that when <a href="http://www.radicalbehavior.com/5-question-interview-with-twitter-developer-alex-payne/">he chose to specifically call out Ruby language performance</a>, but maybe I assumed wrong.
</p>
<p>
When you choose a language, like it or not, you've chosen a <i>platform</i>. And as Steve so patiently and calmly explained to all the <a href="http://damienkatz.net/2007/01/the_volkswagen.html">Lisp enthusiasts</a>, the <i>platform around the language</i>, more than the language itself, sets the tone for your development experience. The availability of common, popular libraries and the maturity of the development environment end up trumping any particular significance the language holds.
</p>
<p>
That's why the Reddit switch makes good business sense: <b>they didn't change languages; they changed platforms</b>. At the point which your choice of platform starts to jeopardize your service, <i>you switch platforms</i>, exactly as Reddit did. Your users don't give a damn what framework and language you're using. The only people who care about that stuff are other software developers. And God help you if your users <i>are</i> software developers; then you're really in trouble.
</p>
<p>
But things aren't all roses in Python-land either. The Reddit developers initially used a Rails-like web application framework, with <a href="http://www.aaronsw.com/weblog/rewritingreddit">decidedly mixed results</a>:
</p>
<p>
</p>
<blockquote>
The framework that seems most promising is <a href="http://www.djangoproject.com/">Django</a> and indeed the authors of reddit initially attempted to rewrite their site in it. I was curious about their experience, so I carefully followed them along, trying to help them out.
<p>
Django seemed great from the outside: a nice-looking website, intelligent and talented developers, and a seeming surplus of nice features. The developers and community are extremely helpful and responsive to patches and suggestions. And all the right goals are espoused in their philosophy documents and FAQs. Unfortunately, however, they seem completely incapable of living up to them.
</p>
<p>
While Django claims that it's "loosely coupled", using it pretty much requires fitting your code into Django's worldview. Django insists on executing your code itself, either through its command-line utility or a specialized server handler called with the appropriate environment variables and Python path. When you start a project, by default Django creates folders nested four levels deep for your code and while you can move around some files, I had trouble figuring out which ones and how.
</p>
<p>
Django's philosophy says "Explicit is better than implicit", but Django has all sorts of magic. Database models you create in one file magically appear someplace else deep inside the Django module with a different name. When your model function is called, new things have been added to its variable-space and old ones removed. (I'm told they're currently working on fixing both of these, though.)
</p>
</blockquote>
<p>
Note that any analogies I'm drawing between Rails and Django here are purely intentional.
</p>
<p>
Not that there's anything wrong with adopting a web application framework. But <b>at least in Python you have a <i>choice</i> of web application frameworks</b>. Instead of investing in the Django worldview, the Reddit team decided that the lighter weight <a href="http://webpy.org/">web.py</a> better suited their needs. Similarly, some ASP.NET developers reject the entire page lifecycle model, preferring to write their own HttpHandlers and HttpModules for finer-grained control over what's happening on their website. And that's fine; the ASP.NET platform accommodates both camps of developers.
</p>
<p>
It's true that Twitter represents an extreme case, but it sure looks like the Twitter developers could <a href="http://www.codinghorror.com/blog/archives/000838.html">benefit from a choice of web application frameworks</a>, too. In the end, it's about choice and flexibility. Not just in the language, but in the platform that inevitably comes along with any language.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/reddit-language-vs-platform/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ When In Doubt, Make It Public ]]></title>
<link>https://blog.codinghorror.com/when-in-doubt-make-it-public/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Marc Hedlund offered some <a href="http://radar.oreilly.com/archives/2007/03/sfearthquakes_o.html">unique advice</a> to web entrepreneurs last month:
</p>
<p>
</p>
<blockquote>
One of my favorite business model suggestions for [web] entrepreneurs is to <b>find an old UNIX command that hasn't yet been implemented on the web, and fix that</b>.
</blockquote>
<p>
To illustrate, Marc provides a list of UNIX commands with their corresponding web implementations:
</p>
<p>
</p>
<table>
<tr>
<td width="120">
<a href="http://en.wikipedia.org/wiki/Talk_%28Unix%29"><code>talk</code></a>, <a href="http://en.wikipedia.org/wiki/Finger_protocol"><code>finger</code></a>
</td>
<td><a href="http://www.icq.com/">ICQ</a></td>
</tr>
<tr>
<td><a href="http://en.wikipedia.org/wiki/LISTSERV"><code>LISTSERV</code></a></td>
<td><a href="http://www.deja.com">DejaNews</a></td>
</tr>
<tr>
<td><a href="http://en.wikipedia.org/wiki/Ls"><code>ls</code></a></td>
<td><a href="http://dir.yahoo.com/">Yahoo! directory</a></td>
</tr>
<tr>
<td>
<a href="http://en.wikipedia.org/wiki/Find"><code>find</code></a>, <a href="http://en.wikipedia.org/wiki/Grep"><code>grep</code></a>
</td>
<td><a href="http://www.google.com">Google</a></td>
</tr>
<tr>
<td><a href="http://en.wikipedia.org/wiki/Rn_(newsreader)"><code>rn</code></a></td>
<td><a href="http://www.bloglines.com/">Bloglines</a></td>
</tr>
<tr>
<td><a href="http://en.wikipedia.org/wiki/Pine_%28e-mail_client%29"><code>pine</code></a></td>
<td><a href="http://gmail.google.com/">Google Mail</a></td>
</tr>
<tr>
<td><a href="http://en.wikipedia.org/wiki/Mount_(computing)"><code>mount</code></a></td>
<td><a href="http://aws.amazon.com/s3">Amazon S3</a></td>
</tr>
<tr>
<td><a href="http://en.wikipedia.org/wiki/Bash"><code>bash</code></a></td>
<td><a href="http://pipes.yahoo.com/">Yahoo! Pipes</a></td>
</tr>
<tr>
<td><a href="http://en.wikipedia.org/wiki/Wall_%28Unix%29"><code>wall</code></a></td>
<td><a href="http://www.twitter.com">Twitter</a></td>
</tr>
</table>
<p>
Jason Kottke noted that most successful "new" business models on the web <a href="http://www.kottke.org/07/03/public-and-permanent/%0A">aren't new at all</a>-- they're simply <b>taking what was once private and making it public and permanent</b>:
</p>
<p>
</p>
<blockquote>
<b><a href="http://www.blogger.com/">Blogger</a> = public email messages.</b> (1999) Instead of "Dear Bob, Check out this movie." it's "Dear People I May or May Not Know Who Are Interested in Film Noir, check out this movie. If you like it, maybe we can be friends."
<p>
<b><a href="http://www.flickr.com/">Flickr</a> = public photo sharing.</b> (2004) Flickr co-founder Caterina Fake said in a recent interview: "When we started the company, there were dozens of other photosharing companies such as Shutterfly, but on those sites there was no such thing as a public photograph -- it didn't even exist as a concept -- so the idea of something 'public' changed the whole idea of Flickr."
</p>
<p>
<b><a href="http://www.youtube.com/">YouTube</a> = public home videos.</b> (2005) Bob Saget was onto something.
</p>
<p>
<b><a href="http://www.twitter.com">Twitter</a> = public IM.</b> (2006) I don't think it's any coincidence that one of the people responsible for Blogger is also responsible for Twitter.
</p>
</blockquote>
<p>
But you don't have to found a new Web 2.0 company to benefit from the power of public information. Even brick and mortar companies are finally <a href="http://www.wired.com/wired/archive/15.04/wired40_ceo.html">realizing that the age-old principle of "secret by default" may not be the best policy today</a>:
</p>
<p>
</p>
<blockquote>
Companies used to assume that details about their internal workings were valuable precisely because they were secret. If you were cagey about your plans, you had the upper hand; if you kept your next big idea to yourself, people couldn't steal it. Now, billion- dollar ideas come to CEOs who give them away; corporations that publicize their failings grow stronger. Power comes not from your Rolodex but from how many bloggers link to you - and everyone trembles before search engine rankings.
</blockquote>
<p>
Power, it seems, comes from <i>public</i> information. Secrets are only a source of powerlessness. Just ask Brad Abrams, who poses <a href="http://blogs.msdn.com/brada/archive/2006/04/10/InformationIsTheCurrency.aspx%0A">this rhetorical question</a>:
</p>
<p>
</p>
<blockquote>
If no one knows you did X, did you really get all the benefits for doing X?
</blockquote>
<p>
I think Brad is being a bit too cautious here. I'll go one step further. Until you've..
</p>
<p>
</p>
<ul>
<li>Written a blog entry about X
</li>
<li>Posted Flickr photos of X
</li>
<li>Uploaded a video of X to YouTube
</li>
<li>Typed a Twitter message about X
</li>
</ul>
<p>
.. <i>did X really happen at all?</i>
</p>
<p>
This is not to say we should fill the world with noise on every mundane aspect of our existence. But who decides what is mundane? Who decides what is interesting? Everything's interesting to <i>someone</i>, even if that someone is only you and a few other people in the world.
</p>
<p>
It's my firm belief that <a href="http://www.codinghorror.com/blog/archives/000567.html">the inclusionists are winning</a>. We live in a world of infinitely searchable micro-content, and every contribution, however small, enriches all of us. But more selfishly, if you're interested in deriving maximum benefit from your work, there's no substitute for making it public and findable. Obscurity sucks. But obscurity by choice is irrational. <b>When in doubt, make it public</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/when-in-doubt-make-it-public/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Sins of Software Security ]]></title>
<link>https://blog.codinghorror.com/sins-of-software-security/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I picked up a free copy of <a href="http://www.amazon.com/exec/obidos/ASIN/0072260858/codihorr-20">19 Deadly Sins of Software Security</a> at a conference last year. I didn't expect the book to be good because it was a free giveaway item from one of the the vendor booths. But I paged through it on the flight home, and I was pleasantly surprised. It's actually quite good.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0072260858/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Software security isn't exactly my favorite topic, so holding my interest is no mean feat. It helps that the book is mercifully brief and to the point, and filled with practical examples and citations. It's an excellent cross-platform, language-agnostic checksheet of common software security risks.
</p>
<p>
Here's a brief summary of each of the 19 sins, along with a count of the number of vulnerabilities I found in the <a href="http://cve.mitre.org/cve/">Common Vulnerabilities and Exposures database</a> for each one.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="720">
<tr>
<td width="150">
</td>
<td width="100">
<b>Affected Languages</b>
</td>
<td>
</td>
<td align="right" width="50">
<b>Exploit count</b>
</td>
</tr>
<tr>
<td valign="top">
Buffer Overflows</td>
<td valign="top">
C, C++</td>
<td style="width: 427px">
A buffer overrun occurs when a program allows input to write beyond the end of the
allocated buffer. Results in anything from a crash to the attacker gaining complete
control of the operating system. Many famous exploits are based on buffer overflows,
such as <a href="http://en.wikipedia.org/wiki/Morris_worm">the Morris worm</a>.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=buffer+overflow">3,326</a>
</td>
</tr>
<tr>
<td valign="top">
Format String Problems</td>
<td valign="top">
C, C++</td>
<td>
The standard format string libraries in C/C++ include some potentially dangerous
commands (particularly %n). If you allow untrusted user input to pass through a
format string, this can result in anything from arbitrary code execution to spoofing
user output.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=format+string">411</a>
</td>
</tr>
<tr>
<td valign="top">
Integer Overflows</td>
<td valign="top">
C, C++, others</td>
<td>
Failure to range check on integer types. This can cause integer overflow crashes
and logic errors. In C/C++, integer overflows can be turned into a buffer overrun
and arbitrary code execution, but all languages are prone to denial of service and
logic errors.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=integer+overflow">288</a>
</td>
</tr>
<tr>
<td valign="top">
SQL Injection</td>
<td valign="top">
All</td>
<td>
Forming SQL statements with untrusted user input means users can "inject" their
own commands into your SQL statements. This puts your data at risk, and can even lead to complete
server and network compromise.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=sql+injection">2,225</a>
</td>
</tr>
<tr>
<td valign="top">
Command Injection</td>
<td valign="top">
All</td>
<td>
Occurs when untrusted user input is passed to a compiler or interpreter, or worse,
a command line shell. Potential risk depends on the context.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=execute+arbitrary+code">193</a>
</td>
</tr>
<tr>
<td valign="top">
Failing to Handle Errors</td>
<td valign="top">
Most</td>
<td>
A broad category of problems related to a program's error handling strategy; anything
that leads to the program crashing, aborting, or restarting is potentially a denial
of service issue and therefore can be a security problem, particularly on servers.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=errors">80</a>
</td>
</tr>
<tr>
<td valign="top">
Cross-Site Scripting (XSS)</td>
<td valign="top">
Any web-facing</td>
<td>
A web application takes some input from the user, fails to validate it, and echoes
that input directly back to the web page. Because this code is running in the context
of your web site, it can do anything your website could do, including retrieving
cookies, modifying the HTML DOM, and so forth.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=xss">2,996</a>
</td>
</tr>
<tr>
<td valign="top">
Failing to Protect Network Traffic</td>
<td valign="top">
All</td>
<td>
Most programmers understimate the risk of transmitting data over the network, even
if that data is not private. Attackers can eavesdrop, replay, spoof, tamper with,
or otherwise hijack any unprotected data sent over the wire.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=replay">26</a>
</td>
</tr>
<tr>
<td valign="top">
Use of Magic URLs and Hidden Form Fields</td>
<td valign="top">
Any web-facing</td>
<td>
Passing sensitive or secure information via the URL querystring or hidden HTML form
fields, sometimes with lousy or ineffectual "encryption" schemes. Attackers can
use these fields to hijack or manipulate a browser session.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=hidden+form">33</a>
</td>
</tr>
<tr>
<td valign="top">
Improper use of SSL and TLS</td>
<td valign="top">
All</td>
<td>
Using most SSL and TLS APIs requires writing a lot of error-prone code. If programmers
aren't careful, they will have an illusion of security in place of the actual security
promised by SSL. Attackers can use certificates from lax authorities, subtly invalid
certificates, or stolen/revoked certificates, and it's up to the developer to write
the code to check for that.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=ssl">123</a>
</td>
</tr>
<tr>
<td valign="top">
Use of Weak Password-Based Systems</td>
<td valign="top">
All</td>
<td>
Anywhere you are using passwords, you need to seriously consider the risks inherent
to all password-based systems. Risks like phishing, social engineering, eavesdropping,
keyloggers, brute force attacks, and so on. And then you have to worry about how
users choose passwords, and where to store them securely on the server. Passwords
are a necessary evil, but tread carefully.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=password">1,235</a>
</td>
</tr>
<tr>
<td valign="top">
Failing to Store and Protect Data Securely</td>
<td valign="top">
All</td>
<td>
Information spends more time stored on disk than in transit. Consider filesystem
permissions and encryption for any data you're storing. And try to avoid hardcoding
"secrets" into your code or configuration files.
</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=encrypted">56</a>
</td>
</tr>
<tr>
<td valign="top">
Information Leakage</td>
<td valign="top">
All</td>
<td>
The classic trade-off between giving the user helpful information, and preventing
attackers from learning about the internal details of your system. Was the password
invalid, or the username?</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=leakage">26</a>
</td>
</tr>
<tr>
<td valign="top">
Improper File Access</td>
<td valign="top">
All</td>
<td>
1) There is often a window of vulnerability between time of check and time of use
(TOCTOU) in the filesystem, so an attacker can slip changes in, particularly if
the files are accessed over the network.<br>
2) The "it isn't really a file problem"; you may think you have a file, but attackers
may substitute a link to another file, or a device name, or a pipe.<br>
3) Allowing users control over the complete filename and path of files used by the program; this can lead to
directory traversal attacks.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=toctou">5</a>, <a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=traversal">
58</a>
</td>
</tr>
<tr>
<td valign="top">
Trusting Network Name Resolution</td>
<td valign="top">
All</td>
<td>
It's simple to override and subvert DNS on a server or workstation with a local
HOSTS file. How do you really know you're talking to the real "secureserver.com"
when you make a HTTP request?</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=dns+name">20</a>
</td>
</tr>
<tr>
<td valign="top">
Race Conditions</td>
<td valign="top">
All</td>
<td>
A race condition is when two different execution contexts are able to change a resource
and interfere with each other. If attackers can force a race condition, they can
execute a denial of service attack. Unfortunately, writing properly concurrent code
is incredibly difficult.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=race+condition">139</a>
</td>
</tr>
<tr>
<td valign="top">
Unauthenticated Key Exchange</td>
<td valign="top">
All</td>
<td>
Exchanging a private key without properly authenticating the entity/machine/service
that you're exchanging the key with. To have a secure session, both parties need
to agree on the identity of the opposing party. You'd be shocked how often this
doesn't happen.
</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2002-1623">1</a>
</td>
</tr>
<tr>
<td valign="top">
Cryptographically Strong Random Numbers</td>
<td valign="top">
All</td>
<td>
Imagine you're playing poker online. The computer shuffles and deals the cards.
You get your cards, and then another program tells you what's in everybody else's
hands. Random numbers are similarly fundamental to cryptography; they're used to
generate things like keys and session identifiers. An attacker who can predict numbers--
even with only a slight probability of success-- can often leverage this information
to breach the security of a system.</td>
<td align="right" valign="top">
<a href="http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=insufficiently+random">5</a>
</td>
</tr>
<tr>
<td valign="top">
Poor Usability</td>
<td valign="top">
All</td>
<td>
Security is always extra complexity and pain for the user. It's up to us software
developers to go out of our way to make it as painless as it can reasonably be.
<em>Security only works if the secure way also happens to be the easy way.</em>
</td>
<td align="right" valign="top">
All</td>
</tr>
</table>
<p>
It's true that C and C++ have a heavy cross to bear. But only 3 of the 19 sins can be completely lumped on the plate of K&amp;R. The other 16 apply almost everywhere, to any developer writing code on any platform. It's a sobering thought.
</p>
<p>
The usability sin is the one that's most interesting to me. <b>Usability is tough under the best of conditions-- and security is the <i>worst</i> of conditions, at least from the user's perspective.</b> It's quite a challenge. There are a few great links in the book on the topic of security usability:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.microsoft.com/technet/archive/community/columns/security/essays/10imlaws.mspx?mfr=true">10 Immutable Laws of Security</a>
</li>
<li>
<a href="http://www.microsoft.com/technet/archive/community/columns/security/essays/10salaws.mspx?mfr=true">The 10 Immutable Laws of Security Administration</a>
</li>
<li>
<a href="http://msdn2.microsoft.com/en-us/library/ms995351.aspx">Writing Error Messages for Security Features</a>
</li>
<li>
<a href="http://www.gaudior.net/alma/johnny.pdf">Why Johnny Can't Encrypt: A Usability Evaluation of PGP 5.0</a> (pdf)
</li>
<li>
<a href="http://reports-archive.adm.cs.cmu.edu/anon/1998/CMU-CS-98-155.pdf">Usability of Security: A Case Study</a> (pdf)
</li>
<li>
<a href="http://rozinov.sfs.poly.edu/papers/security_vs_usability.pdf">Are Usability and Security Two Opposite Directions in Computer Systems?</a> (pdf)
</li>
</ul>
<p>
You can certainly find other books that go much deeper on particular aspects of software security. But if you're looking for an excellent primer on the entire gamut of security problems that could potentially afflict your project, <a href="http://www.amazon.com/exec/obidos/ASIN/0072260858/codihorr-20">19 Deadly Sins of Software Security</a> is an excellent starting point.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/sins-of-software-security/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Apparently Bloggers Aren't Journalists ]]></title>
<link>https://blog.codinghorror.com/apparently-bloggers-arent-journalists/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I ran across <a href="http://mxdj.sys-con.com/read/363083.htm">this blog entry</a> while researching Microsoft's new <a href="http://www.microsoft.com/silverlight/">Silverlight</a> Flash competitor. It makes some disturbing complaints about the limitations of Silverlight, in bold all-caps to boot:
</p>
<p>
</p>
<blockquote>
This is where I threw my hands up in disgust. What in the holy name of Scooby-Doo are those people thinking?!?! After poring through the [Silverlight] API, I thought "I must be mistaken. Surely this is a mistake." But then I asked a colleague and he confirmed it for me. Let me skip a couple lines and highlight this so you all can see it clearly.
<p>
<b>WPF/E (Silverlight) HAS NO SUPPORT FOR BINDING TO MODELS, BINDING TO DATA, OR EVEN CONNECTING TO NETWORK RESOURCES TO OBTAIN DATA.</b>
</p>
<p>
So, I will summarize Microsoft's efforts to date around Silverlight. They have created a declarative programming model that uses XAML as an instantiation language for rich 2D (not 3D) content and animations, as well as extended JavaScript to support this model. Using this model, you can create embedded mini-apps that have access to rich animations, graphics, audio, and video objects. However, these mini applications cannot communicate with the outside world, they cannot consume web services, and they cannot bind UI elements to data. In addition, this model doesn't even have support for things that should be considered a stock part of any library such as buttons, checkboxes, list boxes, list views, grids, etc.
</p>
</blockquote>
<p>
Those are serious problems indeed. I found this blog entry because it's referenced by <a href="http://vistasmalltalk.wordpress.com/2007/04/18/thoughts-on-microsofts-silverlight/#comment-5636">another blog entry on the limitations of Silverlight</a>:
</p>
<p>
</p>
<blockquote>
But what are the capabilities of Silverlight itself? I came across this blog entry of someone who has downloaded the SDK, read the documentation, and looked at the code. Microsoft seems to be waiting for the Orcas release cycle before adding data binding, controls, and .Net runtime support to Silverlight - and Orcas could be delayed until 2008.
</blockquote>
<p>
But before I clicked through to <i>that</i> blog entry, I started by reading <a href="http://and-another-thing.typepad.com/weblog/2007/04/fancy_guis.html">this blog post on the limitations of Silverlight</a>:
</p>
<p>
</p>
<blockquote>
Although I just found this post about it which points out that [Silverlight] has a lot of pretty major shortcomings.
</blockquote>
<p>
The idea that Microsoft's new Flash-alike <b>can't even download data via HTTP</b> seemed impossibly wrong to me. Couldn't be. Can't be. Like any large company, Microsoft certainly makes their share of dumb mistakes. But an epic mistake like that stretches the bounds of credibility even for Microsoft.
</p>
<p>
In short, I didn't believe it. So I downloaded the <a href="http://www.microsoft.com/silverlight/asp/tools.aspx">Silverlight SDK</a> to take a look for myself. Guess what I found in the Silverlight SDK documentation, not five minutes after downloading it?
</p>
<p>
</p>
<blockquote>
The <b>Downloader</b> object is a special-purpose WPF/E object that provides the ability to download content, such as XAML content, JavaScript content, or media assets, such as images. By using the <b>Downloader</b> object you do not have to provide all application content when the WPF/E control is instantiated. Rather, you can download content on demand in response to application needs. The <b>Downloader</b> object provides functionality for initiating the data transfer, monitoring the progress of the data transfer, and retrieving the downloaded content.
<p>
The properties and methods of the Downloader object are modeled after the XMLHttpRequest (XHR) set of APIs. <a href="http://msdn2.microsoft.com/en-us/library/ms535874.aspx">XMLHttpRequest</a> provides JavaScript and other web browser scripting languages the ability to transfer and manipulate XML data to and from a web server using HTTP.
</p>
</blockquote>
<p>
I'm not out to defend Silverlight here.
</p>
<p>
It's clear that blogger A posted <i>completely erroneous information</i>; I'm not sure how he could have missed the obviously named and prominently featured Downloader object in the SDK. It really calls into question whether or not he actually used the SDK at all. But let's assume, for the moment, that he did, and it was a simple oversight on his part. The strident tone of his post makes me think otherwise, but let's give him the benefit of the doubt.
</p>
<p>
The real problem is that this erroneous information was echoed by blogger B, and then echoed <i>again</i> by blogger C. <b>At no point did anyone stop to actually verify the claims of blogger A, even in the most rudimentary, basic of ways.</b> All they had to do was download the SDK and look for themselves to confirm that his complaints were true. I'm talking five minutes, maximum.
</p>
<p>
But they didn't.
</p>
<p>
Instead, they blindly parroted blogger A, assumed that all of his claims were valid, and perpetuated his mistake across the internet.
</p>
<p>
Let's compare that behavior with the <a href="http://www.spj.org/ethicscode.asp">Society of Professional Journalists Code of Ethics</a>, which includes the following guidelines:
</p>
<p>
</p>
<ul>
<li>Test the accuracy of information from all sources and exercise care to avoid inadvertent error. Deliberate distortion is never permissible.
</li>
<li>Diligently seek out subjects of news stories to give them the opportunity to respond to allegations of wrongdoing.
</li>
<li>Identify sources whenever feasible. The public is entitled to as much information as possible on sources' reliability.
</li>
</ul>
<p>
I realize that it's unrealistic to hold every blogger on planet Earth to <a href="http://en.wikipedia.org/wiki/Journalism_ethics_and_standards#Standards_and_reputation">the same standards as professionally trained journalists</a>. Bloggers, after all, aren't professionals.
</p>
<p>
But I do believe blog readers have a right to expect that amateur bloggers will:
</p>
<p>
</p>
<ol>
<li>Do their homework before writing.
</li>
<li>Do some basic investigation of other bloggers' claims <i>before</i> linking to their posts or quoting them.
</li>
</ol>
<p>
None of these bloggers did any of the above. Don't let their mistakes delude you into thinking this is typical or acceptable behavior. It isn't. We may not be professional journalists-- but we are still accountable for the words we write. It pains me that I even have to say this in 2007, but don't assume everything you read on the internet is true. <b>Check the facts <i>yourself</i>.</b> Putting in that extra bit of effort won't transform you into a journalist, but I can <i>guarantee</i> it'll make you a better blogger.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/apparently-bloggers-arent-journalists/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Welcome to Dot-Com Bubble 2.0 ]]></title>
<link>https://blog.codinghorror.com/welcome-to-dot-com-bubble-20/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The <a href="http://en.wikipedia.org/wiki/Dot-com_bubble">dot-com bubble</a> was a watershed event for software developers. You simply couldn't work in the field without having something miraculous or catastrophic happen to you. Or both at once.</p>
<blockquote>
The "dot-com bubble" was a speculative bubble covering roughly 1995 — 2001 during which stock markets in Western nations saw their value increase rapidly from growth in the new Internet sector and related fields. The period was marked by the founding (and in many cases, spectacular failure) of a group of new Internet-based companies commonly referred to as dot-coms. A combination of rapidly increasing stock prices, individual speculation in stocks, and widely available venture capital created an exuberant environment in which many of these businesses dismissed standard business models, focusing on increasing market share at the expense of the bottom line. The bursting of the dot-com bubble marked the beginning of a relatively mild yet rather lengthy early 2000s recession in the developed world.
</blockquote>
<p>Like many others, I saw warning signs all over the place in late 2000:</p>
<ul>
<li>Skyrocketing salaries resulted in a rash of neophytes entering the software development field with giant dollar signs in their eyes.</li>
<li>Internet companies with irrational, unsustainible business strategies built to cash in and hiring at a frenetic pace.</li>
<li>You were never more than two degrees of separation away from a tale of some programmer who became an overnight millionaire.</li>
</ul>
<p>Despite all the warning signs, it never occurred to me that <b>I was working in a bubble</b>. Until it popped.  I don't want to make that mistake again. The three years after the bubble burst were dark, dark times for software developers. Everyone had to scramble to find a place to weather the worst of the storm. And the backlash was severe: rampant offshoring, devaluation of the IT industry as a whole, and diminished salaries and opportunies for everyone.</p>
<p><img alt="image placeholder" >
<p><b>Seven years later, we're now clearly in the throes of another dot-com bubble.</b> You might argue that the new bubble has been in effect since mid-2006, but the signs are absolutely <em>unmistakable</em> now. The job market for software developers is every bit as hyper-competitive as it was in 1999. The idea that you can found a company on the internet-- and make money-- is taken seriously now. There's a new one <a href="http://www.techcrunch.com">every week</a>.</p>
<p>We've had seven long years to think about what the dot-com bubble meant, and where things went wrong. Here's what I think the original bubble got wrong, and what's different in today's bubble:</p>
<ol>
<li>
<b>Most people have an always-on broadband connection to the internet.</b> Broadband penetration was a mere 5 percent in 2000; <a href="https://blog.codinghorror.com/do-modems-still-matter/">as of early 2007 it's now over 50 percent</a>. So many dot-com business models were predicated on the mass market of dialup users, conveniently forgetting how <i>brutally</i> painful it was to use the internet on a modem.</li>
<li>
<b>The emergence of viable ad networks.</b> Few dot-com companies had revenue models that made any sense. Now there are dozens of potential advertising networks that you can plop on a web page to guarantee income proportionate to the pageviews. This <a href="http://web.archive.org/web/20080220023417/http://www.micropersuasion.com/2005/12/2006_trends_to__3.html">advertising-supported model pioneered on the web</a> is even trickling over into desktop applications.</li>
<li>
<b>Moore's law and open source.</b> An internet startup can now scale to thousands of concurrent users on a few <a href="https://blog.codinghorror.com/web-2-0-and-the-whatever-box-server/">cheap, commodity server boxes</a>, running proven open-source solutions like Linux and MySQL. All of this was possible in 2000, but the "whitebox" software and hardware was unproven, and tended to be far behind the expensive, proprietary solutions. Now it's assumed, mature, a known quantity — and the cost for that hardware and software is precipitously close to $0.</li>
</ol>
<p>But the original bubble wasn't <em>all</em> greed and stupidity — I recommend reading through Paul Graham's <a href="http://www.paulgraham.com/bubble.html">What the Bubble Got Right</a> for the upside.</p>
<p>This new bubble does appear to be <a href="http://web.archive.org/web/20080220023656/http://www.micropersuasion.com/2007/04/irrational_exub.html">a bit more sane than the last one</a>, at least initially. The greasy odor of get-rich-quick isn't quite as overpowering as it was in 1999. So far, people seem more interested in building sustainible, useful businesses than rapid market capitalizations.</p>
<p>Bubbles are exciting times. Fortunes are made and lost; careers built and destroyed. It's great while it lasts. So here's my question to you: <strong>what will you do differently in <em>this</em> bubble?</strong></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/welcome-to-dot-com-bubble-20/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Where Are All the Open Source Billionaires? ]]></title>
<link>https://blog.codinghorror.com/where-are-all-the-open-source-billionaires/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Hugh MacLeod asks, if open source is so great, <a href="https://www.gapingvoid.com/blog/2007/04/16/how-well-does-open-source-currently-meet-the-needs-of-shareholders-and-ceos/">where are all the open source billionaires?</a></p>
<blockquote>
<p>If Open Source software is free, then why bother spending money on <a href="https://partner.microsoft.com/global/program">Microsoft Partner</a> stuff? I already know what Microsoft's detractors will say: "There's no reason whatsoever. $40 billion per year is totally wasted."</p>
<p>This, however is not a very satisfying answer, simply because it doesn't quite ring true. <b>Otherwise there'd be a lot more famous Open Source billionaires out there</b>, being written up in Forbes Magazine or wherever. And Bill Gates would've been ousted years ago.</p>
</blockquote>
<p>I can immediately think of one reason there aren't any open-source billionaires:</p>
<p><a href="http://kde-files.org/CONTENT/content-files/44218-linuxdistrotimeline-7.2.png"><img alt="image placeholder" >
<p>Most competition for open source software comes from other open source software. It's far more cutthroat than the commercial software market could ever be.</p>
<p>Rajesh Setty responded to Hugh's question with a few additional reasons why <a href="https://rajeshsetty.com/2007/04/15/why-are-the-open-source-business-people-not-ultra-rich-yet/">it's difficult for open source businesses to make money</a>:</p>
<blockquote>
<p>If open source is license free, the costs have to be low to work with open source. If cost is one of the reasons for a customer to embrace open source, he or she will pay less than what they would have paid to a comparable enterprise software to do the same job. An open source company would have to therefore work twice as hard to a comparable enterprise software company to make the same or less amount of money. This means that they have to have a lot more resources than the competing enterprise software company. How can you have a smaller pie but feed a lot more people and still keep everyone happy?</p>
</blockquote>
<p>But I think MacLeod is asking the wrong question, so Setty's answers, although well reasoned, are irrelevant. <b>There probably won't ever be any open source billionaires.</b> Just <a href="https://developer.jboss.org/blogs/marcf/2005/05/27/is-open-source-financially-viable?_sscc=t">ask JBoss founder Marc Fleury</a>:</p>
<blockquote>
<p>To do [open source software] seriously, professionally, in a sustainable fashion you need to make a living. What is clearly compromised is the "instant billionaire" club. I remember the first time I saw Torvalds on a panel and someone asked "why isn't there an open source billionaire", and I immediately thought "because you are distributing FREE SOFTWARE, dummy." And there still isn't an open source billionaire today. There are very few billionaires period. Your average MSFT developer certainly isn't one.</p>
<p><b>I for one don't believe there will ever be an open source billionaires club.</b> There are and will be many multi-millionaires though. If we execute on our plan without screwing up, we will create a large batch of OS millionaires. We care about the developers and people who create real value in companies getting rewarded.</p>
</blockquote>
<p>The lack of open source software billionaires is <i>by design</i>. It's part of the intent of open source software -- to <b>balance the scales by devaluing the <a href="https://seekingalpha.com/article/10166-chart-software-companies-gross-profit-margins">obscene profit margins</a> that exist in the commercial software business</b>. Duplicating software is about as close to legally printing money as a company can get; profit margins <a href="http://www.nytimes.com/financialtimes/business/FT1035873352050.html">regularly exceed 80 percent</a>.</p>
<p>To ask where the open source billionaires are is to demonstrate a profound misunderstanding of how open source software works. If you wanted to become obscenely rich by starting an open source software company, I'm sorry, but you picked the wrong industry. You'll make a living, perhaps even a lucrative one. But you won't become Bill Gates rich, or Paul Allen rich, by siphoning away the exorbitant profit margins commercial software vendors have enjoyed for so many years.</p>
<p>But there is a silver lining.</p>
<p><b>There are real millionaires – even billionaires – who built companies on open source software.</b> Just ask Larry Page and Sergey Brin. Or the YouTube founders. The real money isn't in the software. It's in the service you build with that software.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/where-are-all-the-open-source-billionaires/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Not To Write a Technical Book ]]></title>
<link>https://blog.codinghorror.com/how-not-to-write-a-technical-book/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If I told you to choose between two technical books, one by <a href="http://en.wikipedia.org/wiki/Charles_Petzold">renowned Windows author Charles Petzold</a>, and another by some guy you've probably never heard of, which one would you pick?
</p>
<p>
That's what I thought too. Until I sat down to read both of them. Take a look for yourself:
</p>
<p>
<b>Charles Petzold's <a href="http://www.amazon.com/exec/obidos/ASIN/0735619573/codihorr-20">Applications = Code + Markup</a>:</b>
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
<b>Adam Nathan's <a href="http://www.amazon.com/exec/obidos/ASIN/0672328917/codihorr-20">Windows Presentation Foundation Unleashed</a>:</b>
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
Beyond the obvious benefit of full color printing, which <a href="http://www.codinghorror.com/blog/archives/000518.html">adds another dimension to any text</a>, it's not even close. The Nathan book is the clear winner:
</p>
<p>
</p>
<ul>
<li>It's full of diagrams, screenshots, and illustrations <i>showing</i> the meaning of the code.
</li>
<li>The text is frequently broken up by helpful color-coded sidebars such as "digging deeper", "FAQ", and "warning".
</li>
<li>The code/markup snippets are smaller and easier to digest; they don't dominate page upon page of the text.
</li>
<li>Liberal use of bullets, tables, subheadings, and other textual elements provides excellent <a href="http://www.useit.com/alertbox/9710a.html">scannability</a>.
</li>
<li>The book has a sense of humor without being obnoxious or cloying.
</li>
<li>Did I mention it's in <font color="red">color</font>?
</li>
</ul>
<p>
The Nathan book is brilliant. It reads like a blog and competes toe-to-toe with anything you'd find on the web. Petzold's book, in contrast, is a greyscale sea of endless text and interminable code. There are so few diagrams in the book that you get a little thrill every time you encounter one. It also artificially segregates code and markup: the first half is all C# code; it's not until the second half that you see any XAML markup whatsoever, even though XAML is one of the most important new features of WPF, and the one developers will be least familiar with.
</p>
<p>
I suppose this sort of old-school treatment is typical Petzold. What do you expect from a guy who thinks <a href="http://www.codinghorror.com/blog/archives/000427.html">Visual Studio rots the minds of software developers</a>? The difference in approach is immediately obvious to anyone who opens both books. One looks compelling, fun, and inviting; the other looks like a painful, textbook slog that's the equivalent of writing code in <a href="http://www.notepad.org">Notepad</a>. <b>Petzold's an excellent writer, but writing alone can't make up for the massive layout deficiencies of his book</b>.
</p>
<p>
It's too bad, because I loved Petzold's earlier book Code, which was <a href="http://www.codinghorror.com/blog/archives/000761.html">a love letter to the personal computer</a> filled with wonderful illustrations. As much as I respect Petzold, you should avoid his WPF book. <a href="http://www.amazon.com/exec/obidos/ASIN/0672328917/codihorr-20">Get the Nathan book instead</a>-- you'll love it. Publishers, take note: I'd sure be buying a heck of a lot more technical books if more of them were like this one.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-not-to-write-a-technical-book/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Coding Horror on .NET Rocks ]]></title>
<link>https://blog.codinghorror.com/coding-horror-on-net-rocks/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It was my great honor to participate in <a href="http://www.dotnetrocks.com/default.aspx?showNum=232">this week's epsiode of .NET Rocks!</a>
</p>
<p>
<a href="http://www.dotnetrocks.com/">.NET Rocks!</a> is a long running internet radio talk show for software developers that goes all the way back to 2002. I've listened to their shows off and on for years. They've interviewed some very notable software developers along the way, <a href="http://www.dotnetrocks.com/default.aspx?showNum=215">including Steve McConnell</a>, and many other people far more interesting than myself. One of the earliest interviews (#11, to be precise) was <a href="http://www.dotnetrocks.com/default.aspx?showNum=11">with our CEO, Scott Stanfield</a>.
</p>
<p>
My interview is 64 minutes long, and explores some common themes I've covered here in my blog. It's available in the following formats:
</p>
<p>
</p>
<ul>
<li>
<a href="http://perseus.franklins.net/dotnetrocks_0232_jeff_atwood.mp3">MP3</a>
</li>
<li>
<a href="http://perseus.franklins.net/dotnetrocks_0232_jeff_atwood.wma">WMA</a> (<a href="http://perseus.franklins.net/dotnetrocks_0232_jeff_atwood_lo.wma">lo-fi WMA</a>)
</li>
<li>
<a href="http://perseus.franklins.net/dotnetrocks_0232_jeff_atwood.m4b">AAC</a>
</li>
</ul>
<p>
For some reason, I had trouble opening these links by directly clicking, so you may want to right click and do a "save as". More download options are available on <a href="http://www.dotnetrocks.com/default.aspx?showNum=232">the interview page</a>.
</p>
<p>
Thanks to Carl Franklin and Richard Campbell for a great interview!
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/coding-horror-on-net-rocks/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ JavaScript and HTML: Forgiveness by Default ]]></title>
<link>https://blog.codinghorror.com/javascript-and-html-forgiveness-by-default/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I've been troubleshooting a bit of JavaScript lately, so I've <a href="http://blogs.msdn.com/ie/archive/2004/10/26/247912.aspx">enabled script debugging</a> in IE7. Whenever the browser encounters a JavaScript error on a web page, instead of the default, unobtrusive little status bar notification..</p>
<p>
<img alt="image placeholder" >
</p>
<p>
.. I now get one of these glaring, modal error debug notification dialogs:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I left this setting enabled out of pure forgetfulness. Browsing the web this way, I quickly realized that <b>the web is full of JavaScript errors.</b> You can barely click through three links before encountering a JavaScript error of one kind or another. Often they come in pairs, triplets, sometimes dozens of them. It's nearly impossible to navigate the web with JavaScript error notification enabled.
</p>
<p>
JavaScript errors are so pervasive, in fact, that it's easy to understand why IE demotes them to nearly invisible statusbar elements. If they didn't, nobody would be able to browse the web without getting notified to death. Firefox goes even further: there's <i>no visible UI whatsoever</i> for any JavaScript errors on the current web page. You have to open the Tools | Error Console dialog to see them.
</p>
<p>
The upshot of this is that JavaScript errors, unless they result in obvious functional problems, tend to go unnoticed. <b>Things that would cause showstopping compiler errors in any other language are at worst minor inconveniences in JavaScript.</b> When errors are ignored by default, what you end up with is an incredibly tolerant, extremely permissive programming ecosystem.  If it works, it works, errors be damned.
</p>
<p>
But this unparallelled flexibility has its price. Just ask Dave Murdock, who <a href="http://www.innerexception.com/2007/04/tip-make-sure-you-declare-javascript.html">found out the hard way</a> how flexible JavaScript can be.
</p>
<p>
</p>
<blockquote>
So I dug into the code, which I hadn't written, and I saw JavaScript similar to this in the execution path that was causing Firefox to hang:
<p>
</p>
<pre>
var startIndex = 0;
for (i = startIndex; i &lt; endIndex; i++) {
// do some stuff here
}
</pre>
<p>
This works fine in Internet Explorer 7. What happens in Firefox? i is reinitialized to startIndex after every run of the loop. You have to declare the loop like this for it to work:
</p>
<p>
</p>
<pre>
var startIndex = 0;
for (var i = startIndex; i &lt; endIndex; i++) {
// do some stuff here
}
</pre>
<p>
Putting the var before i is the way it ought to be as far as I can tell, but both Internet Explorer and Firefox do the wrong thing by developers here. Both browsers should be sticklers about requiring var in a loop variable declaration and produce a clear JavaScript interpreter error before the code has the chance to run.
</p>
</blockquote>
<p>
It's not just JavaScript. HTML and CSS are incredibly forgiving of errors as well. Ned Batchelder <a href="http://www.nedbatchelder.com/blog/200701.html#e20070118T062812">observed bizarrely tolerant behavor</a> when specifying named colors that don't exist. Consider this small snippet of HTML:
</p>
<p>
</p>
<pre>&lt;font color='red'&gt;█ This is RED&lt;/font&gt;</pre>
<p>
As you vary the named color, you don't get the error you might expect. What you do get is weird colors:
</p>
<p>
</p>
<table cellpadding="5">
<tr>
<th align="left"></th>
<th align="left">Firefox</th>
<th align="left">IE7</th>
<th align="left">Opera</th>
</tr>
<tr>
<td>red</td>
<td>
<font color="#ff0000">█ #ff0000</font>
</td>
<td>
<font color="#ff0000">█ #ff0000</font>
</td>
<td>
<font color="#ff0000">█ #ff0000</font>
</td>
</tr>
<tr>
<td>seagreen</td>
<td>
<font color="#2e8b57">█ #2e8b57</font>
</td>
<td>
<font color="#2e8b57">█ #2e8b57</font>
</td>
<td>
<font color="#2e8b57">█ #2e8b57</font>
</td>
</tr>
<tr>
<td>sea green</td>
<td>
<font color="#0e00ee">█ #0e00ee</font>
</td>
<td>
<font color="#0e00ee">█ #0e00ee</font>
</td>
<td>
<font color="#0ea00e">█ #0ea00e</font>
</td>
</tr>
<tr>
<td>sxbxxsreen</td>
<td>
<font color="#0000e0">█ #0000e0</font>
</td>
<td>
<font color="#0000e0">█ #0000e0</font>
</td>
<td>
<font color="#00b000">█ #00b000</font>
</td>
</tr>
<tr>
<td>sxbxxsree</td>
<td>
<font color="#00000e">█ #00000e</font>
</td>
<td>
<font color="#0b00ee">█ #0b00ee</font>
</td>
<td>
<font color="#00b000">█ #00b000</font>
</td>
</tr>
<tr>
<td>sxbxxsrn</td>
<td>
<font color="#000000">█ #000000</font>
</td>
<td>
<font color="#0b0000">█ #0b0000</font>
</td>
<td>
<font color="#00b000">█ #00b000</font>
</td>
</tr>
<tr>
<td>sxbxeen</td>
<td>
<font color="#000e00">█ #000e00</font>
</td>
<td>
<font color="#0bee00">█ #0bee00</font>
</td>
<td>
<font color="#00b0ee">█ #00b0ee</font>
</td>
</tr>
<tr>
<td>sreen</td>
<td>
<font color="#00ee00">█ #00ee00</font>
</td>
<td>
<font color="#00ee00">█ #00ee00</font>
</td>
<td>
<font color="#00ee00">█ #00ee00</font>
</td>
</tr>
<tr>
<td>ffff00</td>
<td>
<font color="#ffff00">█ #ffff00</font>
</td>
<td>
<font color="#ffff00">█ #ffff00</font>
</td>
<td>
<font color="#ffff00">█ #ffff00</font>
</td>
</tr>
<tr>
<td>xf8000</td>
<td>
<font color="#0f8000">█ #0f8000</font>
</td>
<td>
<font color="#0f8000">█ #0f8000</font>
</td>
<td>
<font color="#0f8000">█ #0f8000</font>
</td>
</tr>
</table>
<p>
(If you're curious how "sea green" can possibly equate to blue, the answers are <a href="http://www.nedbatchelder.com/reactor/comment.php?entryid=e20070118T062812&amp;title=Color%20parsing%20brainteaser">in the comments to Ned's post</a>.)
</p>
<p>
I can't think of any other programming environment that goes to such lengths to avoid presenting error messages, that tries so hard to make broken code work, at least a little. Although there was a push to tighten up HTML into the much more strictly enforced XHTML, it's <a href="http://www.hixie.ch/advocacy/xhtml">an utter failure</a>. If you're not convinced, read <a href="http://diveintomark.org/archives/2004/01/14/thought_experiment">Mark Pilgrim's thought experiment</a>:
</p>
<p>
</p>
<blockquote>
Imagine that you posted <a href="http://nick.typepad.com/blog/2004/01/feeddemon_and_w.html">a long rant about how [strict XHTML validation] is the way the world should work</a>, that clients should be the gatekeepers of wellformedness, and strictly reject any invalid XML that comes their way. You click 'Publish', you double-check that your page validates, and you merrily close your laptop and get on with your life.
<p>
A few hours later, you start getting email from your readers that your site is broken. Some of them are nice enough to include a URL, others simply scream at you incoherently and tell you that you suck. (This part of the thought experiment should not be terribly difficult to imagine either, for anyone who has ever dealt with end-user bug reports.) You test the page, and lo and behold, they are correct: the page that you so happily and validly authored is now not well-formed, and it not showing up at all in any browser. You try validating the page with a third-party validator service, only to discover that it gives you an error message you've never seen before and that you don't understand.
</p>
</blockquote>
<p>
Unfortunately, <a href="http://www.tbray.org/ongoing/When/200x/2004/01/16/DraconianHistory">the Draconians won</a>: when rendering as strict XHTML, any error in your page results in a page that not only doesn't render, but also presents a nasty error message to users.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
They may not have realized it at the time, but the Draconians inadvertently destroyed the future of XHTML with this single, irrevocable decision.
</p>
<p>
The lesson here, it seems to me, is that <b>forgiveness by default is absolutely <i>required</i> for the kind of large-scale, worldwide adoption that the web enjoys</b>.
</p>
<p>
The permissive, flexible tolerance designed into HTML and JavaScript is alien to programmers who grew up being regularly flagellated by their compiler for the tiniest of mistakes. Some of us were punished so much so that we actually started to <i>like</i> it. We point and laugh at the all the awful HTML and JavaScript on the web that barely functions. We scratch our heads and wonder why the browser can't give us the punishment we so richly deserve for our terrible, terrible mistakes.
</p>
<p>
Even though programmers have learned to like draconian strictness, <b>forgiveness by default is what works</b>. It's here to stay. We should learn to love our <a href="http://www.crummy.com/software/BeautifulSoup/">beautiful soup</a> instead.
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2007-04-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/javascript-and-html-forgiveness-by-default/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ See You At MIX07 ]]></title>
<link>https://blog.codinghorror.com/see-you-at-mix07/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm heading off to <a href="http://www.visitmix.com/">MIX07</a> today.
</p>
<p>
<a href="http://www.visitmix.com/"><img alt="image placeholder" >
</p>
<p>
MIX is by far my favorite Microsoft conference, because it "mixes" in a liberal dose of <a href="https://content.visitmix.com/public/sessions.aspx">traditionally non-Microsoft folks</a> for a <b>broader range of perspectives</b>. It's probably the only Microsoft conference I'll be attending this year.
</p>
<p>
<a href="http://www.vertigo.com/">Vertigo</a> is also presenting something special at MIX: our new <a href="http://www.vertigo.com/familyshow.aspx">Family.Show WPF reference app</a>.
</p>
<p>
<a href="http://www.vertigo.com/familyshow.aspx"><img alt="image placeholder" >
</p>
<p>
If you're attending MIX this year and you're interested in meeting up, <a href="mailto:jatwood@codinghorror.com">shoot me an email</a>. I'll definitely bring lots of stickers.
</p>
<p>
I also set up <a href="http://twitter.com/codinghorror">a Coding Horror Twitter stream</a> for MIX related activities, and I'll try to keep it updated throughout the conference, barring any <a href="http://www.codinghorror.com/blog/archives/000838.html">performance meltdowns</a> -- for example, right now Twitter's static asset server appears to be down, so no images or stylesheets appear.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/see-you-at-mix07/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ An Initiate of the Bayesian Conspiracy ]]></title>
<link>https://blog.codinghorror.com/an-initiate-of-the-bayesian-conspiracy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.yudkowsky.net/bayes/bayes.html">An Intuitive Explanation of Bayesian Reasoning</a> is an extraordinary piece on Bayes' theorem that starts with this simple puzzle:
</p>
<p>
</p>
<blockquote>
1% of women at age forty who participate in routine screening have breast cancer.  80% of women with breast cancer will get positive mammographies.  9.6% of women without breast cancer will also get positive mammographies.  A woman in this age group had a positive mammography in a routine screening.  <font color="red">What is the probability that she actually has breast cancer?</font>
</blockquote>
<p>
This simple puzzle is not all that simple in practice. Only 15% of doctors, when presented with this situation, come up with the correct answer.
</p>
<p>
<b>Can you come up with the correct answer -- <i>without</i> resorting to Google, the comments to this post, or reading the answer provided in the article?</b>
</p>
<p>
If so, congratulations. You're a natural initiate of the Bayesian Conspiracy. For the rest of us, Bayes' Theorem is a bit more difficult to grasp:
</p>
<p>
</p>
<blockquote>
While there are a few existing <a href="http://www.cs.ubc.ca/~murphyk/Bayes/bayesrule.html">online explanations of Bayes' Theorem</a>, my experience with trying to introduce people to Bayesian reasoning is that the existing online explanations are too abstract.  Bayesian reasoning is very counterintuitive.  People do not employ Bayesian reasoning intuitively, find it very difficult to learn Bayesian reasoning when tutored, and rapidly forget Bayesian methods once the tutoring is over.  This holds equally true for novice students and highly trained professionals in a field.  Bayesian reasoning is apparently one of those things which, like <a href="http://en.wikipedia.org/wiki/Quantum_mechanics">quantum mechanics</a> or the <a href="http://en.wikipedia.org/wiki/Wason_selection_task">Wason Selection Test</a>, is inherently difficult for humans to grasp with our built-in mental faculties.
</blockquote>
<p>
In computer science, <b>it's easy to demonstrate the immense power of Bayes' theorem: it's the basis for almost all spam filters in use today</b>. Bayesian email filtering was first publicized by Paul Graham's <a href="http://www.codinghorror.com/blog/archives/000086.html">A Plan for Spam</a> in mid-2002. Most programmers know about Bayesian filtering now; it's the primary weapon in any modern Spam fighting toolkit.
</p>
<p>
What you may not know, however, is that there's something even more effective than Bayesian spam filtering. It's eloquently described in William Yerazunis' presentation <a href="http://crm114.sourceforge.net/docs/Plateau99/img0.html">The Spam Filtering Plateau at 99.9% Accuracy and How to Get Past It</a> (also available in <a href="http://www.merl.com/reports/docs/TR2004-091.pdf">pdf paper form</a>). And it's been implemented as the <a href="http://crm114.sourceforge.net/wiki/doku.php">CRM114 Discriminator</a> for years. That technique is <a href="http://www.codinghorror.com/blog/archives/000423.html">Markovian spam filtering</a>:
</p>
<p>
</p>
<blockquote>
How to change a Bayesian spam filter to a Markovian spam filter:
<ol>
<li>Change the feature generator from single words to spanning multiple words </li>
<li>Change the weighting so that longer features have more weight (ie, longer features generate local probabilities closer to 0.0 and 1.0)
</li>
<li>The 2^2n weighting means that the weights are 1, 4, 16, 64, 256, ... for span lengths of 1, 2, 3, 4, 5 ... words
</li>
</ol>
</blockquote>
<p>
In other words, where Bayesian filters examine the relationship between individual words, Markovian filters expand the scope to examine the relationship between words and phrases. It's a tweak, but a significant one that amplifies the accuracy of the already uncannily accurate Bayes' theorem.
</p>
<p>
But the true power of Bayes' theorem extends far beyond merely discriminating between spam and non-spam. As the <a href="http://crm114.sourceforge.net/wiki/doku.php">CR114 documentation</a> notes, you can use these powerful statistical models to discriminate between.. well, just about anything:
</p>
<p>
</p>
<blockquote>
Spam is the big target with CRM114, but it's not a specialized Email-only tool. CRM114 has been used to sort web pages, resumes, blog entries, log files, and lots of other things. Accuracy can be as high as 99.9 %. In other words, CRM114 learns, and it learns fast.
</blockquote>
<p>
Now perhaps you can understand why some people are so excited about Bayes' theorem.
</p>
<p>
</p>
<blockquote>
Maybe you see Bayes' theorem, and you understand the theorem, and you can use the theorem, but you can't understand why your friends and/or research colleagues seem to think it's the secret of the universe.  Maybe your friends are all wearing Bayes' theorem T-shirts, and you're feeling left out.  Maybe you're a girl looking for a boyfriend, but the boy you're interested in refuses to date anyone who "isn't Bayesian".  What matters is that Bayes is cool, and if you don't know Bayes, you aren't cool.
<p>
Why does a mathematical concept generate this strange enthusiasm in its students?  What is the so-called Bayesian Revolution now sweeping through the sciences, which claims to subsume even the experimental method itself as a special case?  What is the secret that the adherents of Bayes know?  What is the light that they have seen?
</p>
</blockquote>
<p>
It's not intuitive for most people, but look <a href="http://www.yudkowsky.net/bayes/bayes.html">a little more closely</a>, and I think you, too, will become <b>an initiate of the Bayesian conspiracy</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-04-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/an-initiate-of-the-bayesian-conspiracy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Programming Tip: Learn a Graphics Editor ]]></title>
<link>https://blog.codinghorror.com/programming-tip-learn-a-graphics-editor/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One lesson I took from <a href="http://www.visitmix.com/">MIX</a> is that software development and graphic design are increasingly interrelated disciplines. Although they are very different skillsets, it's important for developers to have some rudimentary design skills, and vice-versa. There's a lot of useful cross-pollination going on between developers and designers.
</p>
<p>
You can't reinvent yourself as a designer overnight. And <a href="http://www.codinghorror.com/blog/archives/000734.html">nor should you try to</a>. But developers <i>should</i> understand the essentials of graphics editing, such as <a href="http://www.codinghorror.com/blog/archives/000464.html">the difference between JPG and PNG</a>, or vector graphics as represented in the <a href="http://developer.mozilla.org/en/docs/Canvas_tutorial">Canvas tag</a>, <a href="http://en.wikipedia.org/wiki/Scalable_Vector_Graphics">SVG</a>, and <a href="http://www.xaml.net/">XAML</a>. Most of all, <b>I believe every software developer should have basic competence in a common graphics editor</b>.
</p>
<p>
<a href="http://www.getpaint.net/screenshots/pdn26_seattle.jpg"><img alt="image placeholder" >
</p>
<p>
Pick your poison:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.gimp.org/">The GIMP</a> (free, all platforms)
</li>
<li>
<a href="http://www.getpaint.net/">Paint.NET</a> (free, Windows)
</li>
<li>
<a href="http://www.adobe.com/products/photoshop/index.html">Photoshop CS3</a> ($500+)
</li>
<li>
<a href="http://www.adobe.com/products/photoshopelwin/">Photoshop Elements</a> ($70)
</li>
<li>
<a href="http://www.corel.com/servlet/Satellite/us/en/Product/1152105040688">Paint Shop Pro</a> ($99)
</li>
</ul>
<p>
No, I won't include Microsoft Paint in this list. And I will add this one warning: although GIMP is both free and powerful, the interface is so excruciatingly difficult to use that by the time you become proficient, you'll be able to handle any graphics editor on the market with ease. I'm a Paint Shop Pro man myself, but there's a broad equivalency between these programs for the type of basic graphic work that most programmers would need. Any of them will do.
</p>
<p>
Once you've selected a graphics editor, the real challenge is learning how to use it. To get a taste of how complex graphics can be, browse through Ars Technica's <a href="http://arstechnica.com/reviews/apps/photoshop-cs3.ars/9">Photoshop CS3 review</a>. Fortunately, you'll typically only need to use a fraction of the functionality of these programs. For tips on getting started, browse through this <a href="http://graphicssoft.about.com/od/softwaretutorials/Graphics_Software_Tutorials_and_User_Resources.htm">list of graphics software tutorials</a>. Whatever you do, <b>try to wean yourself off crappy graphics tools like Paint</b>. It'll be painful at first, but spend the time to work past the learning curve. Expand your skillset by getting comfortable with a real graphics editor. Get some experience under your belt with the same tools that designers use.
</p>
<p>
Technically, this has nothing to do with writing code. But competence in a real graphics editor means you'll have a much easier time working with designers because you now share a common toolset. Given enough practice with the tools, you might even be able to <a href="http://www.codinghorror.com/blog/archives/000152.html">copy a good design</a> yourself in a pinch.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/programming-tip-learn-a-graphics-editor/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Basic Design Principles for Software Developers ]]></title>
<link>https://blog.codinghorror.com/basic-design-principles-for-software-developers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In my previous post, I urged developers to <a href="http://www.codinghorror.com/blog/archives/000849.html">learn a mainstream graphics editing program</a>. This is purely a mechanical skill, so it seemed reasonable for developers to give it a shot. If we can absorb extremely complex development environments, compilers, and databases, why not a graphics editor? But as a few commenters pointed out, competence in a graphics editor isn't enough; you also have to <b>learn some basic design principles to use the tool effectively</b>. Turn the tables for a moment: would it be reasonable to expect designers to learn our favorite development IDE, purely as a tool, without any guidance on how to write code, too?</p>
<p>Probably not. That's why I'm so glad Graham Stewart reminded me to mention <a href="http://www.amazon.com/exec/obidos/ASIN/0321193857/codihorr-20">The Non-Designer's Design Book</a>.</p>
<p><a href="http://www.amazon.com/exec/obidos/ASIN/0321193857/codihorr-20"><img alt="image placeholder" >
<p>I bought my copy of this book way back in 1996, when I was a software developer with zero design skills, looking for a little guidance. I'm not a designer now by any means –  but when you start at zero, there's nowhere to go but up. I love the opening quote from the book, which touches on a theme I <a href="http://www.codinghorror.com/blog/archives/000846.html">discussed</a> recently that <a href="http://www.google.com/search?q=atwood+petzold+nathan+book">got a lot of press</a>:</p>
<blockquote>
<p>More matter is being printed and published today than ever before, and every publisher of an advertisement, pamphlet, or book expects his material to be read. Publishers, and even more so, readers want what is important to be clearly laid out. They will not read anything that is troublesome to read, but are pleased with what looks clear and well arranged, for it will make their task of understanding easier. For this reason, the important must stand out and the unimportant be subdued...</p>
<p>The technique of modern typography must also adapt itself to the speed of our times. Today, we cannot spend as much time on a letter heading or other piece of jobbing as was possible even in the nineties.</p>
</blockquote>
<p>In the above quote by <a href="http://en.wikipedia.org/wiki/Jan_Tschichold">Jan Tschichold</a>, he's referring to the <i>eighteen-nineties</i>. The quote dates back to 1935, but it's as true today as it ever was.</p>
<p>The book does look suspiciously amateurish, with its garish purple and yellow cover and odd font choices. Nonetheless, I found <a href="http://www.amazon.com/exec/obidos/ASIN/0321193857/codihorr-20">The Non-Designer's Design Book</a> to be a tremendously helpful introduction to practical, real world design principles for a neophyte. Paging through it today, it's still as useful and interesting as ever. It outlines the first baby step towards a lifelong design education in clear, simple terms:</p>
<blockquote>
<p>Many years ago I received a tree identification book for Christmas. I was at my parents' home, and after all the gifts had been opened I decided to go out and identify the trees in the neighborhood. Before I went out, I read through part of the book. The first tree in the book was the Joshua tree because it only took two clues to identify it. Now the Joshua tree is a really weird-looking tree and I looked at that picture and said to myself, "Oh, we don't have that kind of tree in Northern California. That is a weird-looking tree, and I've never seen one before."</p>
<p>So I took my book and went outside. My parents lived in a cul-de-sac of six homes. Four of those homes had Joshua trees in the front yard. I had lived in that house for thirteen years, and I had never seen a Joshua tree. I took a walk around the block, and there must have been a sale at the nursery when everyone was landscaping their new homes–  at least 80 percent of the homes had Joshua trees in the front yards. <b>And I had never seen one before!</b> Once I was conscious of the tree –  once I could name it –  I saw it everywhere.</p>
</blockquote>
<p>You begin at the beginning: <b>by learning to see the design all around you</b>. All it takes to distinguish yourself is a little judicious application of the design guidelines in this book–  guidelines so universal they apply to web sites as easily as they do to traditional client GUI applications. And once you do, you'll begin to see how these rules apply everywhere.</p>
<p>I'm sure there are other good introductory design books out there. I can personally vouch that this one stands the test of time. The author produced <a href="http://www.amazon.com/s/ref=sr_nr_n_12/002-2138923-6224802?ie=UTF8&amp;rh=n%3A1000%2Cp%5F27%3ARobin%20Williams%2Cn%3A5">a number of related books</a>, but the reviews on those are mixed at best; most point back to this classic. And here's one clever little feature of this book that I just noticed after all these years–  instead of <a href="http://www.lipsum.com/">Lorem Ipsum</a> dummy text, the author uses <a href="http://www.crockford.com/wrrrld/anguish.html">Anguish Languish</a>, which is way more fun.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/basic-design-principles-for-software-developers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Maximizing The Value of Your Keystrokes ]]></title>
<link>https://blog.codinghorror.com/maximizing-the-value-of-your-keystrokes/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I met <a href="http://en.wikipedia.org/wiki/Jon_Udell">Jon Udell</a> this year at MIX. I was reading through his <a href="http://blog.jonudell.net/">excellent blog</a> to flesh out some of the topics we talked about, when I was struck by the powerful message of <a href="http://blog.jonudell.net/2007/04/10/too-busy-to-blog-count-your-keystrokes/">this particular entry</a>:
</p>
<p>
</p>
<blockquote>
When people tell me they're too busy to blog, I ask them to count up their output of keystrokes. How many of those keystrokes flow into email messages? Most. How many people receive those email messages? Few. How many people could usefully benefit from those messages, now or later? More than a few, maybe a lot more.
<p>
From this perspective, blogging is a communication pattern that optimizes for the amount of awareness and influence that each keystroke can possibly yield. Some topics, of course, are necessarily private and interpersonal. But a surprising amount of business communication is potentially broader in scope. If your choice is to invest keystrokes in an email to three people, or in a blog entry that could be read by those same three people plus more -- maybe many more -- why not choose the latter? Why not make each keystroke work as hard as it can?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
[converting an email to a blog entry] can have powerful network effects. To exploit them, you have to realize that the delivery of a message, and the notification of delivery, do not necessarily coincide. Most of the time, in email, they do. The message is both notification and payload. But a message can also notify and point to a payload which is available to the recipient but also to other people and processes in other contexts. That arrangement costs hardly any extra keystrokes, and hardly any extra time. But it's an optimization that can radically expand influence and awareness.
</p>
</blockquote>
<p>
I covered similar ground in <a href="http://www.codinghorror.com/blog/archives/000840.html">When In Doubt, Make It Public</a>, but Jon's entry is even more compelling. It's a specific example of how you can adapt your behavior to have a much broader impact. What Jon's describing happens to me all the time. I'll be in the middle of composing an email when I suddenly realize that <b>there's no reason to silo this information in a private email exchange</b>. I convert that email into a blog entry. Now, anyone who is interested in the topic can find it and have a public conversation with me-- and everyone else-- about it.
</p>
<p>
The next time you find yourself typing more than a few sentences on your keyboard, stop and ask: <b>are you maximizing the value of your keystrokes?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/maximizing-the-value-of-your-keystrokes/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Phishing: The Forever Hack ]]></title>
<link>https://blog.codinghorror.com/phishing-the-forever-hack/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Most of the hacking techniques described in the 1994 book <a href="http://www.amazon.com/exec/obidos/ASIN/1559501065/codihorr-20">Secrets of a Super-Hacker</a> are now laughably out of date. But not all of them. A few are not only still effective, but <i>far more</i> effective in the current era of ubiquitous internet access. As the author notes early in the book, some attacks are timeless:
</p>
<p>
</p>
<blockquote>
Hacking may seem harder than before, but it really isn't. The <i>culture</i> may have become more aware of security, but the individual user still lives in a world of benign indifference, vanity, user-friendliness, and friendly-userness. Users who are in-the-know will always want to help the less fortunate ones who are not. Those who aren't will seek the advice of the gurus. And so social engineering and reverse social engineering live on, as you shall discover in these pages.
<p>
Ease of use will always rule. The "dumb" password will be a good guess for a long time to come. People just don't choose "6Fk%810(@vbM-34trwX51" for their passwords.
</p>
<p>
Add to this milieu the immense number of computer systems operating today, and the staggering multitudes of inept users who run them. In the past, computers were used by the techno-literate few. Now they are bought, installed, used, managed, and even programmed by folks who have a hard time getting their bread to toast light brown. I'm not denigrating them -- I applaud their willingness to step into unfamiliar waters. I just wish (sort of) that they would <i>realize</i> what danger they put themselves in every time they act without security in mind.
</p>
</blockquote>
<p>
I don't think there's any better illustration of the timelessness of social engineering hacks-- and the vulnerability of unsophisticated mainstream users-- than <a href="http://en.wikipedia.org/wiki/Phishing">phishing</a>. The results of a 2006 phishing study, <a href="http://www.freakonomics.com/pdf/Why%20Phishing%20Works-1.pdf">Why Phishing Works</a> (pdf), are truly sobering:
</p>
<p>
</p>
<ul>
<li>Good phishing websites fooled 90% of participants.
</li>
<li>23% of participants in the study did not look at the address bar, status bar, or the security indicators.
</li>
<li>On average, the participants incorrectly judged whether a website was real or a spoof 40% of the time.
</li>
<li>15 out of  22 participants  proceeded without hesitation when presented with popup warnings about fraudulent certificates.
</li>
<li>Neither  education, age, sex, previous experience, nor hours of computer use showed a statistically significant correlation with vulnerability to phishing. Everyone was vulnerable.
</li>
</ul>
<p>
Phishing is remarkably effective. Bear in mind that the users in this study were told in advance to <b>expect a mixture of real and fake websites</b>, so these results may actually be <i>better</i> than real world performance, as hard as that is to believe. Here's a detailed breakdown of the test sites used in the study, along with the percent of users who were unable to correctly identify whether the site was real or a spoof:
</p>
<p>
</p>
<table cellpadding="4" width="650">
<tr>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
<strong>
% Wrong</strong>
</td>
</tr>
<tr>
<td valign="top">Bank of the West</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (bankofthevvest.com), padlock in content, Verisign logo and certificate validation seal, consumer alert warning</td>
<td valign="top">
<strong>91</strong>
</td>
</tr>
<tr>
<td valign="top">PayPal</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">Uses Mozilla XML User Interface Language (XUL) to simulate browser chrome w/ fake address bar, status bar and SSL indicators</td>
<td valign="top">
<strong>81</strong>
</td>
</tr>
<tr>
<td valign="top">Etrade</td>
<td valign="top">
<font color="green">Real</font>
</td>
<td valign="top">3rd party URL (etrade.everypath.com), SSL, simple design, no graphics for mobile users</td>
<td valign="top">
<strong>77</strong>
</td>
</tr>
<tr>
<td valign="top">PayPal</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (paypal-signin03.com), padlock in content</td>
<td valign="top">
<strong>59</strong>
</td>
</tr>
<tr>
<td valign="top">PayPal</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (IP address), padlock in content</td>
<td valign="top">
<strong>59</strong>
</td>
</tr>
<tr>
<td valign="top">Capital One</td>
<td valign="top">
<font color="green">Real</font>
</td>
<td valign="top">3rd party URL (cib.ibanking-services.com), SSL, dedicated login page, simple design</td>
<td valign="top">
<strong>50</strong>
</td>
</tr>
<tr>
<td valign="top">PayPal</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">Screenshot of legitimate SSL protected Paypal page within a rogue web page</td>
<td valign="top">
<strong>50</strong>
</td>
</tr>
<tr>
<td valign="top">Ameritrade</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (ameritrading.net)</td>
<td valign="top">
<strong>50</strong>
</td>
</tr>
<tr>
<td valign="top">Bank of America</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">Rogue popup window on top of legitimate BOFA homepage, padlock in content</td>
<td valign="top">
<strong>36</strong>
</td>
</tr>
<tr>
<td valign="top">Bank of the West</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (IP address), urgent anti-fraud warnings (requests large amount of personal data)</td>
<td valign="top">
<strong>32</strong>
</td>
</tr>
<tr>
<td valign="top">USBank</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (IP address), padlock in content, security warnings, identity verification (requests large amount of personal data)</td>
<td valign="top">
<strong>32</strong>
</td>
</tr>
<tr>
<td valign="top">Ebay</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (IP address), account verification (requests large amount of personal data)</td>
<td valign="top">
<strong>32</strong>
</td>
</tr>
<tr>
<td valign="top">Yahoo</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (center.yahoo-security.net), account verification (requests large amount of personal data)</td>
<td valign="top">
<strong>23</strong>
</td>
</tr>
<tr>
<td valign="top">NCUA</td>
<td valign="top">
<font color="red">Spoof</font>
</td>
<td valign="top">URL (IP address), padlock in content, account verification (requests large amount of personal data)</td>
<td valign="top">
<strong>18</strong>
</td>
</tr>
<tr>
<td valign="top">Ebay</td>
<td valign="top">
<font color="green">Real</font>
</td>
<td valign="top">SSL protected login page, TRUSTe logo</td>
<td valign="top">
<strong>14</strong>
</td>
</tr>
<tr>
<td valign="top">Bank Of America</td>
<td valign="top">
<font color="green">Real</font>
</td>
<td valign="top">Login page on non-SSL homepage, padlock in content</td>
<td valign="top">
<strong>14</strong>
</td>
</tr>
<tr>
<td valign="top">Tele-Bears (Student Accounts)</td>
<td valign="top">
<font color="green">Real</font>
</td>
<td valign="top">SSL protected login page</td>
<td valign="top">
<strong>9</strong>
</td>
</tr>
<tr>
<td valign="top">PayPal</td>
<td valign="top">
<font color="green">Real</font>
</td>
<td valign="top">Login page on non-SSL homepage, padlock in content</td>
<td valign="top">
<strong>9</strong>
</td>
</tr>
<tr>
<td valign="top">Bank One</td>
<td valign="top">
<font color="green">Real</font>
</td>
<td valign="top">Login page on non-SSL homepage, padlock in content</td>
<td valign="top">
<strong>0</strong>
</td>
</tr>
</table>
<p>
There's only one conclusion you can draw from <a href="http://www.freakonomics.com/pdf/Why%20Phishing%20Works-1.pdf">the study's results</a>: <b>when presented with a spoofed web page, a large percentage of users will <i>always</i> fall for it.</b> Forever.
</p>
<p>
Once that spoofed page is up, even if we use the extraordinarily optimistic estimate that only 15 percent of users will fall for it, that's still a tremendous number of users at risk. Given the poor statistics, the only mitigation strategy that makes sense is to somehow <b>prevent showing the spoofed page to the user</b>. The good news is that the latest versions of <a href="http://www.mozilla.com/en-US/firefox/phishing-protection/">Firefox</a> and <a href="http://www.microsoft.com/athome/security/online/phishing_filter.mspx">Internet Explorer</a> have anti-phishing capabilities which do exactly that: they use real-time, distributed blacklists to prevent showing known spoof sites to users. I visited the <a href="http://www.phishtank.com/index.php">PhishTank</a> site to gather a set of known phishing URLs to see how well these browsers perform.
</p>
<p>
Firefox may be using PhishTank as a source; every URL I visited showed the most severe warning, blocking the phishing site from the user behind a sort of smoked glass effect. Unfortunately, it's all too easy to click the little red X and use the page. I don't think it's a good idea for this dialog to be so easily dismissable, like any other run of the mill dialog box.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
IE7 opened some of the recent phishing sites with no warnings at all. But a few triggered the heuristic check for "suspicious", with a dropdown warning obscuring part of the site:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Others made the IE7 blacklist and were blocked completely behind a gateway page. I prefer this to the Firefox approach; once the URL is reported as a phishing site, there's absolutely no reason to show <i>any</i> of its content to the user.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I'm <a href="http://www.codinghorror.com/blog/archives/000715.html">no fan of distributed blacklists</a>, but I think they're a necessary evil in this case. Throughout the last ten years of incremental browser security improvements, users have <i>always</i> been susceptible to spoof attacks. It doesn't matter how many security warnings we present, or how much security browser chrome we wrap websites in. <b>Phishing is the forever hack.</b> If the phishing page is displayed at all, it invariably reels a large percentage of users in hook, line, and sinker. The <i>only</i> security technique that can protect users from phishing scams, it seems, is the one that prevents them from ever seeing the phishing page in the first place.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/phishing-the-forever-hack/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Your Favorite Programming Quote ]]></title>
<link>https://blog.codinghorror.com/your-favorite-programming-quote/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
My all-time favorite programming quote has to be this <a href="http://en.wikipedia.org/wiki/Nathaniel_Borenstein">Nathaniel Borenstein</a> bon mot:
</p>
<p>
</p>
<blockquote>
It should be noted that no ethically-trained software engineer would ever consent to write a  DestroyBaghdad procedure. Basic professional ethics would instead require him to write a DestroyCity procedure, to which Baghdad could be given as a parameter.
</blockquote>
<p>
It's too perfect. Never have programmers been more neatly summarized.
</p>
<p>
There are a few great collections of programming quotes on the web which are fun to browse through:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.sysprog.net/quotlang.html">Programming Quotations</a>
</li>
<li>
<a href="http://www.eskimo.com/~hottub/software/programming_quotes.html">Quotes about Computer Languages</a>
</li>
<li>
<a href="http://www.sysprog.net/quotpgmr.html">Quotes about Programmers</a>
</li>
<li>
<a href="http://www.gdargaud.net/Humor/QuotesProgramming.html">Computer Programming Quotes</a> (good, but many unsourced)
</li>
<li>
<a href="http://en.wikiquote.org/wiki/Programming">Programming - Wikiquote</a>
</li>
</ul>
<p>
If I find a quote that resonates with me, I research the person behind the quote. <a href="http://en.wikipedia.org/wiki/Larry_Wall">Larry Wall</a> is a good example:
</p>
<p>
</p>
<blockquote>
I think that the biggest mistake people make is latching onto the first idea that comes to them and trying to do that. It really comes to a thing that my folks taught me about money. Don't buy something unless <a href="http://www.codinghorror.com/blog/archives/000084.html">you've wanted it three times</a>. Similarly, don't throw in a feature when you first think of it. Think if there's a way to generalize it, think if it should be generalized. Sometimes you can generalize things too much. I think like the things in Scheme were generalized too much. There is a level of abstraction beyond which people don't want to go. Take a good look at what you want to do, and try to come up with the long-term lazy way, not the short-term lazy way.
</blockquote>
<p>
Jason Kottke did most of the work for me by putting together a <a href="http://www.kottke.org/remainder/07/05/13365.html">great Larry Wall reading list</a>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.wall.org/~larry/natural.html">Natural Language Principles in Perl</a>
</li>
<li>
<a href="http://www.wall.org/~larry/pm.html">Perl, the first postmodern computer language</a>
</li>
<li>
<a href="http://www.ddj.com/dept/windows/184410483">A Conversation with Larry Wall</a>
</li>
<li>
<a href="http://groups.google.com/group/comp.lang.perl.misc/msg/4ea8ddd4dfcf8a9b">Linguistics and Perl</a>
</li>
</ul>
<p>
If that's too much rah-rah Perl action for you, read <a href="http://avatraxiom.livejournal.com/58084.html">this article questioning the future of Perl in Bugzilla</a> to get some equal time. But <b>I don't have to dogmatically accept Perl to respect Larry Wall</b>. I doubt Larry would want me to, anyway. It's not about the language; it's about learning to understand <a href="http://www.codinghorror.com/blog/archives/000541.html">programmers as human beings</a>.
</p>
<p>
You can't know every notable personality in the field of computer science. But reading through some of their quotes is as good a place as any to start. It's one way to find out, at least peripherally, who the giants are in the industry, and what they're most famous for. Browsing through quotes also lets you figure out who your influences are-- or should be. Personally, I'd cite <a href="http://en.wikiquote.org/wiki/Jef_Raskin">Jef Raskin</a> and <a href="http://www.softwarequotes.com/ShowQuotes.asp?ID=554&amp;Name=McConnell,_Steve_C&amp;Type=Q">Steve McConnell</a> as my two greatest influences.
</p>
<p>
Who are the greatest influences on your work as a software developer? And more importantly, <b>what's your favorite quote from your influences?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/your-favorite-programming-quote/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Giving Up on Microsoft ]]></title>
<link>https://blog.codinghorror.com/giving-up-on-microsoft/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although I am generally platform agnostic, I make no secret of the fact that <b>I am primarily a Microsoft developer</b>. In a way, I grew up with Microsoft-- as a teenager, I cut my programming teeth on the <a href="http://en.wikipedia.org/wiki/TI_BASIC_%28TI_99/4A%29">early</a> <a href="http://en.wikipedia.org/wiki/Applesoft_BASIC">microcomputer</a> <a href="http://en.wikipedia.org/wiki/AmigaBASIC">implementations</a> of <a href="http://en.wikipedia.org/wiki/Microsoft_BASIC">Microsoft BASIC</a>. And I spent much of my professional life writing Visual Basic code. When Microsoft rebooted their programming franchise with .NET in 2003, I was thrilled and reinvigorated, glad to finally have a <a href="http://www.codinghorror.com/blog/archives/000039.html">viable exit strategy</a> from the glass house that was Visual Basic.
</p>
<p>
As a developer who grew up on a steady diet of Microsoft tools, I never understood the pockets of rabid anti-Microsoft sentiment in the programming community. To me, Microsoft was the least of all possible commercial evils, a generally benevolent dictatorship. Humor me for a moment and imagine replacing Microsoft with one of its competitors: Sun, IBM, Oracle, or Apple. I don't know about you, but those alternate histories send a chill up my spine. Yes, Microsoft is a near-monopoly, but as giant, evil monopolistic corporations go, you could do a lot worse. Microsoft is far from perfect, but they generally do the right thing as far as I'm concerned.
</p>
<p>
Microsoft has always been a developer-centric company to their very core. From Steve Ballmer's <a href="http://www.codinghorror.com/blog/archives/000350.html">developers, developers, developers</a>, to Bill Gates' centerfold shot, it's always been abundantly clear that Microsoft is a company which prides itself on taking care of its core constituency: developers.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Although I'm still satisfied with my place in the Microsoft development universe, some developers desperately want off the Microsoft treadmill. Mike Gunderloy is <a href="http://www.afreshcup.com/2006/12/9/what-s-going-on-here">a notable example</a>:
</p>
<p>
</p>
<blockquote>
I've spent the bulk of the last fifteen years developing some amount of reputation and expertise in the Microsoft universe, having published dozens of books and hundreds of articles, worked as an editor and consultant, written (as a subcontractor) parts of various Microsoft products, and so on. I'm also the editor of the Larkware site, which tracks news in the Microsoft software world for developers.
<p>
Unfortunately, over that time I've also come to the conclusion that, even though it is staffed largely by smart and ethical people, Microsoft itself represents a grave threat to the future of software development through its increasing inclination to stifle competition through legal shenanigans. Its recent attempt to claim that no one can implement a user interface that looks anything like the Office 2007 ribbon without licensing some nebulous piece of intellectual property represents a new low in this regard.
</p>
<p>
I'm in a bit of a bind. Unlike fifteen years ago, I've got a family, including four kids, and I can't afford to just walk out on a career that brings in good money. But I rather desperately want to find an alternative. This blog will record some of my explorations as I hunt around in other corners of the software world, trying to decide if there's a viable business plan for me that can include <b>weaning myself off of Microsoft software</b>.
</p>
</blockquote>
<p>
Mike started a new blog, <a href="http://afreshcup.com">A Fresh Cup</a>, where he's <a href="http://afreshcup.com/tags/reinventing">reinventing himself</a> as an open-source developer. If you were wondering why the content at <a href="http://www.larkware.com/">Larkware's Daily Grind</a> has degenerated so much recently (and boy, has it ever), now you know. His heart's just not in it any more.
</p>
<p>
I can understand where Mike is coming from. Microsoft releases new technology at a blistering pace, and keeping up-- not to mention dealing with all the obsolete baggage you're carrying around-- is half the challenge. Just take a look at the stack I have to install on my development machine to do development work in .NET 3.0:
</p>
<p>
</p>
<ul>
<li>Windows Vista
</li>
<li>Visual Studio 2005
</li>
<li>Visual Studio 2005 Team Explorer (source control)
</li>
<li>Orcas Extensions for Visual Studio 2005 (WPF &amp; WCF project templates)
</li>
<li>SQL Server Express SP2
</li>
<li>Visual Studio 2005 SP1
</li>
<li>Visual Studio 2005 SP1 Update for Vista
</li>
<li>ASP.NET 2.0 AJAX Extensions 1.0
</li>
<li>Expression Blend
</li>
</ul>
<p>
Historically, I've used Microsoft development environments because they made my life easier. It's hard to look at this list and see how it's any easier than the open source alternatives. I also begin to look longingly at the open source developers who have been plugging away productively in Perl or Python over the last five years. Sometimes, you wonder if choosing an environment where things change more slowly isn't a better long term evolutionary decision. Perhaps there's a kernel of truth in Paul Graham's sensationalist <a href="http://www.paulgraham.com/microsoft.html">Microsoft is Dead</a> article: can you even <i>name</i> any startups that use Microsoft development tools?
</p>
<p>
So part of me agrees with Mike. To <a href="http://www.ojar.com/view_23493.htm">paraphrase Chris Rock</a>: <b>I'm not saying he should have given up on Microsoft. <i>But I understand</i>.</b>
</p>
<p>
Mike's certainly entitled to take whatever steps he deems necessary for his professional development. Still, his attitude frustrates me, because it falls so egregiously into <a href="http://www.codinghorror.com/blog/archives/000602.html">the stereotypical, religious love/hate dichotomy</a> that I've observed again and again in software developers. You either love Microsoft and use exclusively Microsoft products, or you hate Microsoft, and you vow never to use any of their products ever again. There's nothing in between. No middle ground. Why does it have to be an all or nothing proposition? As far as I'm concerned, every software developer, regardless of what's on their tool belt, has the same goal: to craft useful computer software that delights users. <b>We're allies, not enemies.</b> Friendly rivalry I can understand. But the rabid partisanship that I typically see-- on <i>both</i> sides of the fence-- isn't helping us.
</p>
<p>
I also find that <b>both the Microsoft community and the open-source communities are far too insular and provincial</b>. I had the great pleasure of meeting <a href="http://tirania.org/blog/">Miguel de Icaza</a> at MIX this year. Miguel is one of <a href="http://www.codinghorror.com/blog/archives/000037.html">my heroes</a>, as he was instrumental in bringing .NET to the world of open source with the <a href="http://www.mono-project.com/Main_Page">Mono project</a>. What truly surprised me, though, was how few MIX attendees knew who Miguel was, despite his groundbreaking contribution to the .NET programming ecosystem. To me, he's famous. A celebrity. But because Miguel has roots in the open-source community, he barely exists to the majority of Microsoft-centric developers. They didn't even know who he was! And those who did recognize him had about a 50/50 chance of disliking him on principle. As Miguel pointed out during the open source panel, he's disliked by <i>both</i> camps: open-source zealots think he's sold out to Microsoft, and Microsoft zealots think he's destroying the value of the .NET platform.
</p>
<p>
This is wrong. This is not the way things should be.
</p>
<p>
As a software developer, you're doing yourself a disservice by pledging allegiance to anything other than yourself and your craft-- whether it's Microsoft or the principle of <a href="http://www.fsf.org/">free software</a>. Stop with the us vs. them mentality. Let go of the partisanship. We're all in this thing together.
</p>
<p>
I'm a pragmatist. For now, I choose to live in the Microsoft universe. But that doesn't mean I'm ignorant of how the other half lives. There's always more than one way to do it, and just because I chose one particular way doesn't make it the right way-- or even a particularly good way. Choosing to be provincial and insular is a sure-fire path to ignorance. <a href="http://weblogs.asp.net/jgalloway/archive/2007/05/02/are-you-alt-net.aspx">Learn how the other half lives</a>. Get to know some developers who don't live in the exact same world you do. Find out what tools they're using, and why. If, after getting your feet wet on both sides of the fence, you decide the other half is living better and you want to join them, then I bid you a fond farewell.
</p>
<p>
But either way, we're still friends.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/giving-up-on-microsoft/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Zoomable Interfaces ]]></title>
<link>https://blog.codinghorror.com/zoomable-interfaces/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Asa Raskin, the son of the late <a href="http://en.wikipedia.org/wiki/Jef_Raskin">Jef Raskin</a>, recently <a href="http://video.google.com/videoplay?docid=-6856727143023456694">gave a presentation at Google</a> on the work his company, <a href="http://www.humanized.com/">Humanized</a>, is doing. It's largely a continuation of the work of his father. One of the most interesting aspects of Jef's work was <b>zoomable user interfaces</b>. Asa's demo of zoomable interfaces starts at 1:05 in the <a href="http://video.google.com/videoplay?docid=-6856727143023456694">video</a>. You can interact with the very same flash demo on <a href="http://rchi.raskincenter.org/index.php?title=Demos">this page</a>; scroll down to "Launch the Zoom Demo", and be prepared to wait a bit, as it's an 8 megabyte Flash file.
</p>
<p>
Although popularized by Jef Raskin, Humanized isn't the only company working on zoomable user interfaces; Microsoft has <a href="http://labs.live.com/Seadragon.aspx">Seadragon</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You can experience the Seadragon technology in <a href="http://labs.live.com/photosynth/SystemCheck.htm">Photosynth</a>, which is also being ported to Microsoft's <a href="http://www.microsoft.com/silverlight/">Silverlight</a>. According to Microsoft, <b>zoomable UI has these advantages</b>:
</p>
<p>
</p>
<ol>
<li>Speed of navigation is independent of the size or number of objects.
</li>
<li>Performance depends only on the ratio of bandwidth to pixels on the screen.
</li>
<li>Transitions are smooth as butter.
</li>
<li>Scaling is near perfect and rapid for screens of any resolution.
</li>
</ol>
<p>
<a href="http://en.wikipedia.org/wiki/Zooming_User_Interface">Zooming user interfaces</a> are rare in current operating systems and applications, but there are a few. You're probably already using at least one zoomable user interface without thinking much about it.
</p>
<p>
</p>
<ul>
<li>Most modern mapping sites (<a href="http://maps.google.com">Google Maps</a>, <a href="http://maps.live.com/">Live Maps</a>) allow zooming in and out, with varying degrees of smoothness and fidelity.
</li>
<li>
<a href="http://www.apple.com/macosx/features/expose/">The Expose feature in OS X</a> is a limited form of zooming in and out of the desktop. Vista's Flip3D is a far less useful imitation, but fortunately there is <a href="http://insentient.net/index.html">an excellent clone available</a>.
</li>
<li>Ole Eichhorn's company Aperio implemented similar zoom techniques to allow the viewing of terapixel images in the browser. You can <a href="http://w-uh.com/posts/070504-BigTIFF.html">dynamically zoom in and out of a 3 terabyte image</a> compressed into 144 gigabytes of data.
</li>
<li>The <a href="http://www.codinghorror.com/blog/archives/000762.html">OLPC Sugar UI</a> heavily leverages the <a href="http://wiki.laptop.org/go/OLPC_Human_Interface_Guidelines/The_Laptop_Experience/Zoom_Metaphor">Zoom metaphor</a> in its design.
</li>
<li>Many mobile web browsers, due to their tiny screens, implement zoomable interfaces for navigating the web. The Apple iPhone, the Nintendo DS, and <a href="http://labs.live.com/deepfish/">DeepFish</a> for Windows Mobile all use this technique to render web pages.
</li>
</ul>
<p>
What really struck me about zoomable UI is <b>how intuitive and usable it is in the right situation</b>. The zooming metaphor is central to the new real-time strategy game <a href="http://en.wikipedia.org/wiki/Supreme_Commander">Supreme Commander</a>; you're constantly zooming into the battle to take control of individual units, then zooming back out to get a larger, strategic view of what's happening on the battlefield. It's totally natural and completely intuitive. You <a href="http://www.codinghorror.com/blog/archives/000377.html">don't have to think</a>; it just works the way you'd expect it to.
</p>
<p>
<a href="http://img150.imageshack.us/img150/5814/supcomzoomlargecz2.jpg"><img alt="image placeholder" >
</p>
<p>
I'm not sure when the <a href="http://en.wikipedia.org/wiki/Scroll_wheel">mouse scroll wheel</a> became standard equipment on computer mice, exactly, but I'm awfully glad that it did. <b>Zooming is a natural metaphor that people adapt to as easily as they do to scrolling</b>. Zoomable UI is woefully underused today, but I think it should be an integral part of our desktop operating systems in the future.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/zoomable-interfaces/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ This Site May Harm Your Computer ]]></title>
<link>https://blog.codinghorror.com/this-site-may-harm-your-computer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.usenix.org/events/hotbots07/tech/full_papers/provos/provos.pdf">The Ghost In The Browser: Analysis of Web-based Malware</a> (pdf) describes <b>how Google is leveraging their overwhelming search dominance to combat browser malware installations</b>. In <a href="http://www.mattcutts.com/blog/siteadvisor-study/">a blog entry last summer</a>, Matt Cutts said:
</p>
<p>
</p>
<blockquote>
Given how much I hate web pages that install malicious software or abuse browser security holes, I'd like it if we did even more to protect our users.
</blockquote>
<p>
Apparently, they've <a href="http://www.mattcutts.com/blog/how-google-handles-malware-a-historical-overview/">done even more to protect users</a> since then. Here's a Google search result tagged with the ominous warning "This site may harm your computer":
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Clicking <a href="http://www.google.com/support/bin/answer.py?answer=45449&amp;topic=360&amp;hl=en&amp;sa=X&amp;oi=malwarewarninglink&amp;resnum=1&amp;ct=help">"This site may harm your computer"</a> leads to a Google support page. Attempting to click through to the actual website results in an interstitial warning, offering no way to click through:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I think this is a fairly effective method of warning away most rational users from a clearly evil website. Of course, users who desire whatever media, software, or pornography the site is hawking can still type the URL in their address bar. Users will <a href="http://www.codinghorror.com/blog/archives/000347.html">find a way to see the dancing bunnies</a> if they really, <i>really</i> want to, no matter how many warnings and barriers you blast in front of them.
</p>
<p>
If you want to see what's behind that URL, fair warning: in addition to being outright dangerous for a machine that's not patched to the gills, it's NSFW in a big way. A little investigation showed that it's doing the following:
</p>
<p>
</p>
<ul>
<li>Attempts to use the remote data services ActiveX control.
</li>
<li>Shows a spoof HTML page with the text "windows media player cannot play video file; Click here to download missing Video ActiveX object". The download runs setup.exe.
</li>
<li>Runs Javascript with exploit sniffing code.
</li>
</ul>
<p>
If you accept that Google wields the immense power of being <a href="http://www.codinghorror.com/blog/archives/000767.html">the de-facto start page for the internet</a>, then maybe this kind of policing effort comes with the territory. <b>To do nothing-- to let these purely evil sites show up in Google results with no warning whatsoever-- would be irresponsible.</b> Although a person might be performing questionable searches to get this page in their results, it's irrelevant. Despite the individual ethics of the person using that one computer, a compromised computer will be used for attacks and spam against everyone.
</p>
<p>
Still, I'm a little curious. Why does Google <a href="http://www.codinghorror.com/blog/archives/000767.html">deploy the ultimate weapon of search delisting</a> on sites using black-hat SEO techniques to game search rankings, while known evil malware sites get stern warning interstitials instead? I brought up the Google result by doing a direct search on the domain name. The very same search <b>produces no results on live.com or ask.com</b>. Clearly that site has been delisted by everyone except Google. The domain still has a PageRank of four. I applaud the effort, but what value does keeping a site like that in your search index have for users?
</p>
<p>
Even if your web site is <i>not</i> evil, it's possible for others to inject malicious code into your page if you're not careful. The <a href="http://www.usenix.org/events/hotbots07/tech/full_papers/provos/provos.pdf">Google whitepaper</a> provides three external vectors that can turn a good web page to the dark side:
</p>
<p>
</p>
<ul>
<li>Compromised webservers can insert malicious code into all HTML pages served
</li>
<li>Pages which allow user-contributed HTML, where the HTML hasn't been properly sanitized
</li>
<li>The use of questionable advertising content, or compromised ad servers
</li>
</ul>
<p>
It's scary how many ways this can happen. I strongly urge you to <a href="http://www.usenix.org/events/hotbots07/tech/full_papers/provos/provos.pdf">read the whitepaper</a> to get all the gory details.
</p>
<p>
Google's paper says <b>one in ten webpages contains malicious code</b>. The most direct way to address malware delivered via web pages is to increase the security of the operating system and the browser, so "drive-by downloads" cannot happen without the user's explicit consent. But a problem as large as malware should be attacked on multiple fronts. Search engines are in a unique position to help index and identify malicious webpages, and prevent them from being accessible in search results. It's encouraging to read about Google's architecture for automatically identifying malicious URLs. I don't think it's fair to call this <a href="http://www.roughtype.com/archives/2007/05/driveby_malware.php">Google policing the web</a>; it's just good, ethical business to <b>filter out the evil</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/this-site-may-harm-your-computer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ C# and the Compilation Tax ]]></title>
<link>https://blog.codinghorror.com/c-and-the-compilation-tax/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Over the last four years, I've basically given up on the idea that .NET is a multiple language runtime.
</p>
<p>
</p>
<ul>
<li>The so-called choice between the two most popular languages, C# and VB.NET, is <a href="http://www.codinghorror.com/blog/archives/000519.html">no more meaningful than the choice between Coke and Pepsi</a>. Yes, IronPython and IronRuby are meaningfully different dynamic languages, but they're somewhere on the horizon and far from first-class IDE citizens.
<p>
</p>
</li>
<li>There's simply <b>too much cognitive friction</b> when translating back and forth between these two very, very similar languages. Semicolons or underscores? Case sensitivity or case insensitivity? Parens or brackets? Arrays that begin at one, or arrays that begin at zero? To-may-to or to-mah-to? It's just not worth the mental effort it costs to keep track of all these nitpicky little differences that can bite you so easily.
<p>
</p>
</li>
<li>Mixing source code in different languages is awkward at best. You have to segregate each language into its own compilable project. Separate-- but equal. Sort of. Well, mostly.
<p>
</p>
</li>
<li>Most of the community has settled on C# as the de-facto standard, so you're in for a rough slog of code translation if you want to stick with VB and cleanly integrate commonly available source code libraries into your codebase. And if you want to <i>understand</i> the code you're absorbing into your application (note: this isn't really optional in my experience), you better learn how to read it without a bunch of mental translation gymnastics. And once you've learned how to read and write the language well enough to integrate it, you've come full circle. Like me, you'll be left wondering why you didn't just cut out the translation penalty entirely and stick with one language in the first place.
<p>
</p>
</li>
</ul>
<p>
This is not to say that you can't do multiple language development in .NET. But most of the time, it isn't worth the hassle. It's less painful to move with the herd and <a href="http://www.codinghorror.com/blog/archives/000235.html">choose C# like everyone else does</a>. For the most part, <b>I've learned to suck it up and pretend C# is the only .NET language</b>. I'll even grudgingly admit that explicitly ending lines with semicolons is way better than the mish-mash of carriage returns and underscores we have in VB.NET. But there are still two things that drive me nuts about C#.
</p>
<p>
The first is the <a href="http://www.codinghorror.com/blog/archives/000458.html">evil of case sensitivity</a>. As an advocate for people over machines, I have to go on record stating that case sensitivity in a programming language is wrong, and will <i>always</i> be wrong. I know the decision is written in stone at this point, and it's never going to change, so I'll leave it at that. It's <a href="http://www.codinghorror.com/blog/archives/000247.html">a religious issue</a>, and we software developers are <a href="http://www.codinghorror.com/blog/archives/000699.html">nothing if not religious</a>. Let's move on.
</p>
<p>
The second is <b>the C# compilation tax</b>. When working in C#, I'm constantly compiling the solution to ensure that I haven't broken anything. It's a ridiculous productivity tax in an endless loop: Write some code. Compile. Write a little more code. Compile. Change a function. Compile. Rename a variable. Compile. Refactor some methods. Compile. Then compile again, just to be sure. Wait a second.. did I compile this yet? Compile!
</p>
<p>
Notice a pattern here? I'm going to prematurely wear out my CTRL, SHIFT, and B keys. When coding in C#, I feel like a monkey in a cage that dispenses food pellets when I press CTRL+SHIFT+B. It's a complete waste of time, but you're compelled to do it through perverse incentives in the IDE.
</p>
<p>
What's particularly sad about this is that, in my experience, most C# developers think manually compiling all the time is a natural state of affairs. Well, it isn't. In VB.NET we have this <a href="http://www.panopticoncentral.net/articles/947.aspx">clever little technology</a> we call <b>background compilation</b>. Background compilation saves you the effort of all that meaningless, repetitive, mind-numbing manual compilation. It's very simple: as you type, imagine all that CTRL+SHIFT+B-ing happening automagically in the background for you.
</p>
<p>
With background compilation, <i>I know immediately when I've made a mistake</i>. I don't have to wait until the next time I manually invoke the compiler. Let's say I was to type in the following C# code:
</p>
<p>
</p>
<pre>
string s;
s = 1;
</pre>
<p>
Well, that code looks fine in the editor. Until I compile. Contrast that with the VB.NET equivalent:
</p>
<p>
</p>
<pre>
Dim s As String
s = 1
</pre>
<p>
The second I finish typing the assignment (e.g., move my cursor off the second line), the statement is flagged as an invalid assignment. No compilation necessary; it automatically appears as an ambient squiggly underline in the background.
</p>
<p>
This is an admittedly trivial example, but background compilation makes my life so much easier in VB.NET. It reduces the turnaround time between mistake and fix to virtually nothing. And you can do other clever things with it, such as quickly renaming a function or variable to get an idea of where it's being referenced via the stack of compiler errors that appear. If nothing else, it's one less thing I have to remember to do: oh yeah, the C# IDE shows me basic syntax problems, but I gotta compile my C# to see what's <i>really</i> broken. Doesn't that seem like <a href="http://www.codinghorror.com/blog/archives/000377.html">unnecessary work</a> to you? It sure does to me.
</p>
<p>
Background compilation is something that, unlike case sensitivity, is <i>not</i> written in stone, and possibly <i>could</i> be fixed. It's an IDE feature, not a language feature. Here's hoping the C# team eventually <b>recognizes the massive productivity drain of the C# compilation tax for the average developer</b>. If some developers are masochists who hate productivity, then make background compilation a configurable option they can turn off. They can march off in lockstep, back to their wheel of never-ending CTRL+SHIFT+B pain. More power to 'em.
</p>
<p>
Personally, I'd rather let the computer do the grunt work of compiling in the background. Freed from the onerous compilation tax, no longer compulsively invoking the compiler every few minutes, I can spend more time concentrating on my code.
</p>
<p>
I may have accepted the C# penance, but I wish the saints at Microsoft would see fit to grant this one small wish to a converted VB.NET sinner.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/c-and-the-compilation-tax/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Bill Gates and DONKEY.BAS ]]></title>
<link>https://blog.codinghorror.com/bill-gates-and-donkey-bas/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>It's hard to imagine now, but in the early days of Microsoft, Bill Gates was an <a href="http://blog.codinghorror.com/how-to-become-a-better-programmer-by-not-programming/">actual programmer</a>. One bit of hard evidence is the BASIC program <a href="http://en.wikipedia.org/wiki/DONKEY.BAS">DONKEY.BAS</a> included with original IBM PCs running IBM DOS 1.10. The history of this weird little program is covered <a href="https://web.archive.org/web/20070704104845/http://www.microsoft.com/presspass/exec/billg/speeches/2001/06-19teched.aspx">in a 2001 TechEd keynote</a> by Gates himself:</p>
<blockquote>
<p><strong>ARI BIXHORN</strong>: Well, I am thrilled to be here today, because this week we are celebrating the ten-year birthday of the world's most powerful, productive and popular developer tool. And of course I'm talking about Visual Basic.</p>
<p>Now, to help set the context for just how far Visual Basic has come and really how far the Basic language has come, I'd like to take a step back just a few years and look at an application that was written in Basic. This application, called Donkey.bas was actually written by none other than the gentleman standing to the left of me. Bill, how long ago was it that you wrote Donkey.bas?</p>
<p><strong>BILL GATES</strong>: Actually, it was myself and <a href="http://en.wikipedia.org/wiki/Neil_Konzen">Neil Konzen</a> at four in the morning with this prototype IBM PC sitting in this small room. IBM insisted that we had to have a lock on the door and we only had this closet that had a lock on it, so we had to do all our development in there and it was always over 100 degrees, but we wrote late at night a little application to show what the Basic built into the IBM PC could do. And so that was Donkey.bas. It was at the time very thrilling. So go ahead and show them what that looks like.</p>
</blockquote>
<p>Here's a small animation I captured of DONKEY.BAS running in a virtual machine:</p>
<img alt="image placeholder" >
<p>Thrilling indeed. The Macintosh folks were <a href="http://folklore.org/StoryView.py?project=Macintosh&amp;story=Donkey.txt">suitably unimpressed</a>:</p>
<blockquote>
<p>[PC-DOS] came with some games written in BASIC that were especially embarrassing. The most embarrassing game was a lo-res graphics driving game called "Donkey". The player was supposed to be driving a car down a slowly scrolling, poorly rendered "road", and could hit the space bar to toggle the jerky motion. Every once in a while, a brown blob would fill the screen, which was supposed to be a donkey manifesting in the middle of the road. If you didn't hit the space bar in time, you would crash into the donkey and lose the game.</p>
<p>We thought the concept of the game was as bad the crude graphics that it used. Since the game was written in BASIC, you could list it out and see how it was written. We were surprised to see that the comments at the top of the game proudly proclaimed the authors: Bill Gates and Neil Konzen. Neil was a bright teenage hacker who I knew from his work on the Apple II (who would later become Microsoft's technical lead on the Mac project) but we were amazed that such a thoroughly bad game could be co-authored by Microsoft's co-founder, and that he would actually want to take credit for it in the comments.</p>
</blockquote>
<p>It's funny to think that DONKEY.BAS is part of Gates' legacy as a programmer. If nothing else, at least he has a healthy sense of humor about his past. The only copy of <a href="http://drivey.com/DONKEYQB.BAS.html">the source code for DONKEY.BAS</a> I can find has been stripped of any credits by Gates or Konzen. It's a fairly short program, but it's also a painful reminder of how awkward programming was in 1981. <font color="red">Update:</font> Leon was kind enough to send in <a href="https://github.com/coding-horror/donkey.bas/blob/master/donkey.bas">an original copy of DONKEY.BAS</a> from the DOS 1.1 disks.</p>
<p>During the TechEd 2001 keynote, Microsoft demonstrated a tongue-in-cheek, fully 3D update of Donkey written in the then-beta VB.NET language, to illustrate just how far BASIC had come in the intervening 20 years.</p>
<img alt="image placeholder" >
<p>You <s>can still</s> can no longer <a href="http://web.archive.org/web/20080327123446/http://www.microsoft.com/downloads/details.aspx?FamilyID=990d0ec1-23ea-4408-898d-1fd5727a8890&amp;displaylang=en">download the VB.NET version of Donkey</a> from Microsoft. I downloaded it and converted it to Visual Studio 2005 and .NET 2.0 fine. But I couldn't get it to run because of its oddball dependency on DirectX 8.</p>
<blockquote>
<p>Donkey .NET is a three-dimensional driving simulator game that demonstrates the new features available to Microsoft® Visual Basic® developers. Written in Visual Basic .NET RTM, this sample uses XML Web services, multithreading, structured exception handling, shaped Windows Forms, and custom-drawn controls. The sample includes the setups for both the game application and an optional XML Web service used with the game. The setups will also install the source code.</p>
<p><img alt="image placeholder" >
</blockquote>
<p>I suppose that's another enduring lesson of DONKEY.BAS; the various BASIC implementations have never been known for their stellar compatibility.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/bill-gates-and-donkey-bas/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Designing Interactions at IDEO ]]></title>
<link>https://blog.codinghorror.com/designing-interactions-at-ideo/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Recently, <a href="http://jcooney.net/">Joseph Cooney</a> and a coworker both recommended the book <a href="http://www.amazon.com/exec/obidos/ASIN/0262134748/codihorr-20">Designing Interactions</a> to me at the same time. A strange confluence of events that's got to be some sort of sign. I immediately ordered the book.</p>
<p><a href="http://www.amazon.com/exec/obidos/ASIN/0262134748/codihorr-20"><img alt="image placeholder" >
<p>And I'm so glad I did. It's a wonderful, beautiful book about the history of digital technology design, filled with stunning full-color photographs and illustrations, frequently interspersed with interviews from key industry figures. You can browse the table of contents and download a sample chapter from <a href="http://www.designinginteractions.com/">the book's website</a>. I recommend it without reservation.</p>
<p>I didn't realize it at the time, but the author, <a href="http://en.wikipedia.org/wiki/Bill_Moggridge%20">Bill Moggridge</a>, is one of the co-founders of the iconic design firm <a href="http://en.wikipedia.org/wiki/IDEO">IDEO</a>. His other claim to fame is designing what many consider to be the world's first laptop computer in 1979, the <a href="http://oldcomputers.net/grid1101.html">GRiD Compass</a>. Nobody could afford it, of course, but it was an evolutionary milestone in computer history.</p>
<p>IDEO is a true giant in the field of design; just <a href="http://www.ideo.com/work/">browse through their portfolio</a> and I can practically guarantee you've used more than one product they've designed. IDEO is so influential they've packaged their message into products, too. I already own a few IDEO artifacts. I ordered the <a href="http://www.ideo.com/work/method-cards">IDEO Method Cards</a> back in 2005. I still occasionally flip through them; they're great little nudges to get you thinking about all the different ways design should influence what you're working on.</p>
<p><a href="http://www.ideo.com/work/method-cards"><img alt="image placeholder" >
<p>Last Christmas, without any coaching from me, my wife bought me another IDEO book, <a href="http://www.amazon.com/exec/obidos/ASIN/0385499841/codihorr-20">The Art of Innovation: Lessons in Creativity</a>. It's a decent read as well. I have yet to obtain a copy of their latest book, <a href="http://www.amazon.com/exec/obidos/ASIN/0385512074/codihorr-20">The Ten Faces of Innovation: IDEO's Strategies for Defeating the Devil's Advocate and Driving Creativity Throughout Your Organization</a>, but if the length of the title is any indication, I'm sure it's a doozy.</p>
<p>I think IDEO and Moggridge are on the right track: <strong>strictly framing technology in service to people</strong>. I know it seems obvious, but it's one of those things that bears reminding every so often. Perhaps that's why reading <a href="http://www.amazon.com/exec/obidos/ASIN/0262134748/codihorr-20">Designing Interactions</a> is so inspiring.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/designing-interactions-at-ideo/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Meet The Inventor of the Mouse Wheel ]]></title>
<link>https://blog.codinghorror.com/meet-the-inventor-of-the-mouse-wheel/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The mouse wheel is so integral to my mousing experience now that it's difficult to imagine using a GUI without one. Although I clearly remember using mice without scroll wheels, I can't recall exactly <i>when</i> the transition occurred-- when mouse wheels became a standard, expected feature on every mouse as they are today.
</p>
<p>
The first reference to a mouse with a wheel I can find is the Genius EasyScroll mouse, which was released in 1995.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
With those terrible aesthetics, it's not surprising that mouse wheels weren't truly popularized until the first Microsoft Intellimouse was released in 1996.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I would argue that <b>the mouse wheel is the first true mouse innovation <a href="http://www.codinghorror.com/blog/archives/000286.html">since the invention of the mouse itself</a></b>. Given its importance, I've often wondered exactly how the mouse wheel was invented, but I could never find a source of any kind.
</p>
<p>
Matt Young was kind enough to forward me a link <b>finally revealing who invented the mouse wheel: Microsoft's Eric Michelman</b>, as described in his article <a href="http://www.ericmic.com/history%20of%20the%20scroll%20wheel.htm">The History of the Scroll Wheel</a>:
</p>
<p>
</p>
<blockquote>
Back in 1993, as I was watching many Excel users do their work, I noticed the difficulty they had moving around large spreadsheets.  Finding and jumping to different sections was often difficult.  I had the idea that perhaps a richer input device would help.
<p>
My original idea was the zoom lever.  This was simply a lever, presumably for your non-mouse hand (i.e. on the left side of your keyboard if you're right-handed).  When you push it away from you the spreadsheet zooms out.  When you pull it towards you, it zooms back in.
</p>
<p>
I prototyped this by hooking a joystick up to my computer and using DDE to connect it to Excel for zooming.  Using a joystick button along with the stick, I also had it do "data zooming", which was drilling in and out through Excel outlines.
</p>
<p>
This all seemed useful, so I showed it to the Hardware division at Microsoft.  They were initially cool to the idea, which I presented as a zoom lever, and it didn't go anywhere at that point.
</p>
<p>
At this point most people thought it was kind of wacky.  Focusing on zooming was a very Excel-centric approach.  More specifically, it was a very 2-D centric approach.  That is, using an application that presents 2-dimensional data, like a spreadsheet or graphics, it's very useful to zoom in and out.  But the other main style of application is a linear flow application like Word, and there it's not as useful.  You could do zooming with Word, where zooming out shows you a multi-page view and then you click on a desired page and zoom into it, but that's not as natural as with a spreadsheet or graphics and images.
</p>
<p>
A number of people suggested adding panning and scrolling functionality.  In particular I remember Chris Graham saying zooming was just too limiting and it should pan as well.  In response to this feedback, I added panning to the prototype, so moving the joystick side-to-side and back-and-forth scrolled Excel in the corresponding direction.
</p>
<p>
Around this time, the hardware guys came back and said that they had considered adding a wheel to the mouse, but they didn't know what it would be used for.  Document navigation answered that question, so they said that if I could get Office to support it, they would build it.  This really meant Excel and Word since they were the "800 lb gorillas" -- if Excel and Word supported something, then the other Office apps would follow, and if Office as a whole supported something, then everyone else would follow too (this was the early 1993 when Office was the heart of most people's computer usage).
</p>
</blockquote>
<p>
Eric was completely fixated on the idea that the wheel should be for zooming by default, but finally relented when he met resistance from legendary technology journalist <a href="http://walt.allthingsd.com/">Walt Mossberg</a>. Before they shipped it, they added a button under the wheel, and made the default wheel action "scroll".
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The rest, as they say, is history.
</p>
<p>
After that, mouse wheels-- and the third mouse button <i>under</i> the wheel-- quickly became popular, standard features on every mouse. Although work started on this feature in 1993, and the hardware didn't ship until 1996, the first
<a href="http://www.google.com/patents?vid=USPAT5912661&amp;id=jb4WAAAAEBAJ&amp;dq=5,912,661">mouse wheel patent filing</a> from Microsoft is dated 1999.
</p>
<p>
So here's to you, mouse wheel. Whether you're <a href="http://www.codinghorror.com/blog/archives/000858.html">zooming</a> or <a href="http://www.codinghorror.com/blog/archives/000376.html">scrolling</a>, we owe you-- and Eric Michelman-- a debt of gratitude.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/meet-the-inventor-of-the-mouse-wheel/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Reducing User Interface Friction ]]></title>
<link>https://blog.codinghorror.com/reducing-user-interface-friction/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Tantek elik recently wrote a great entry on <a href="http://tantek.com/log/2007/02.html#d19t1813">cognitive load in user interface</a>, comparing instant messaging and email:
</p>
<p>
</p>
<blockquote>
To instant message (IM) someone, you merely:
<p>
</p>
<ol>
<li>switch to your IM client
</li>
<li>double click their name
</li>
<li>type your message
</li>
<li>press return
</li>
</ol>
<p>
To email someone, you have to:
</p>
<p>
</p>
<ol>
<li>switch to your email client
</li>
<li>choose "New/Compose Message" from the interface
</li>
<li>type the recipient's name (autocomplete in most email programs typically helps to reduce this to 3-4 keystrokes)
</li>
<li>type tab or return to go to the next field (typically another to or cc field)
</li>
<li>type tab or return again to go to the subject field
</li>
<li>think up a subject (or ideally skip it)
</li>
<li>type a subject (or ideally skip it)
</li>
<li>type tab or return again to go to the message body field
</li>
<li>type in your message
</li>
<li>click send
</li>
</ol>
<p>
Ideally, assuming no subject (which is atypical), and only typing 3 letters to autocomplete the recipients name, that's ten steps-- more than 3x the interface overhead of IM.
</p>
</blockquote>
<p>
Jan Miksovsky covers similar ground when enumerating <a href="http://miksovsky.blogs.com/flowstate/2007/05/hurdles_in_the_.html">the hurdles at the entrance to a website</a>:
</p>
<p>
</p>
<blockquote>
<ol>
<li>Figure out what the service does, and whether it meets your needs.
</li>
<li>Find the entry point for signing up.
</li>
<li>Pick a user ID.
</li>
<li>If the user ID isn't an email address, enter their email address.
</li>
<li>Pick a password.
</li>
<li>Enter the password again to confirm it.
</li>
<li>Pick the password several more times to comply with arbitrary security requirements.
</li>
<li>Write down the password somewhere before you forget the new variation of your usual password that finally made it past the arbitrary security requirements.
</li>
<li>Enter personal data used to configure the service to your needs.
Comply with (or carefully turn down) requests for demographic data for marketing purposes. This may include opting out of requests to be added to email newsletters.
</li>
<li>Agree to terms of use and other legal agreements.
</li>
<li>Activate their account. The user might need to switch to a completely different application-- their email client-- and look for a message from the service.
</li>
<li>Download software. If the service entails client software or browser plug-ins, the user has an additional dozen hurdles to jump through: the browser's save dialog, progress dialog, "Are you sure you want to run this?" dialog, an elevate-to-administrator security dialog, and probably a firewall dialog-- not to mention the software's own overly long sequence of setup questions.
</li>
</ol>
</blockquote>
<p>
John Gruber offers another example <a href="http://daringfireball.net/2007/03/deal_with_it">comparing calendar entry overhead</a>:
</p>
<p>
</p>
<blockquote>
My typical usage [in <a href="http://www.apple.com/macosx/features/ical/">iCal</a>]:
<p>
</p>
<ol>
<li>Double-click on the date of the event in month view.
</li>
<li>Type the event name.
</li>
<li>Tab past Location.
</li>
<li>Tab past "all-day" checkbox.
</li>
<li>Tab past Month.
</li>
<li>Tab past Day.
</li>
<li>Tab past Year.
</li>
<li>Enter the hour.
</li>
<li>Enter the minutes.
</li>
<li>Swap the AM/PM.
</li>
</ol>
<p>
Compare and contrast to the event entry UI for the calendar feature in <a href="http://www.backpackit.com/">Backpack</a>:
</p>
<p>
</p>
<ol>
<li>Double-click on the date of the event in month view.
</li>
<li>Type the time and name of the event.
</li>
</ol>
</blockquote>
<p>
Whether you call it cognitive load, a sequence of hurdles, interface overhead, or just plain excise, it all adds up to the same thing: <b>interface friction for the user</b>. Sand in the gears of their mind. One more unnecessary thing they have to <a href="http://www.codinghorror.com/blog/archives/000377.html">think about</a> before using your application.
</p>
<p>
<b>How many steps does it take to do something in <i>your</i> application?</b> Have you counted? Have you thought about ways to reduce or eliminate those steps for your users? If not, you absolutely should be. Fire up your application and start counting as you click and type through the most common user scenarios. I think you'll be unpleasantly surprised.
</p>
<p>
Some interface friction is inevitable. But it is possible to reduce interface friction to an absolute minimum. One of the best "frictionless" sign-up user interfaces I've ever seen is at <a href="http://reddit.com">reddit</a>. If you click any element that requires login, you're presented with an overlay &lt;div&gt; that allows you to sign up in a single step and also complete the action you originally clicked on, in one fell swoop:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Reduced interface friction goes a long way toward explaining the popularity of services like <a href="http://www.twitter.com/">twitter</a> and <a href="http://www.tumblr.com/">tumbr</a>. What's the minimum amount of effort a user can expend to produce something? The answer could be a key competitive advantage.
</p>
<p>
That single input box on the Google homepage starts to look more and more like <a href="http://www.codinghorror.com/blog/archives/000595.html">an optimal user experience</a>. It might be unrealistic to reduce your application's UI to a single text box-- but you should <b>continually strive to reduce the friction of your user interface</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/reducing-user-interface-friction/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Productivity Tip: Upgrade Your Pentium 4 ]]></title>
<link>https://blog.codinghorror.com/productivity-tip-upgrade-your-pentium-4/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/000860.html">C# and the Compilation Tax</a>, several commenters noted that they have "fast dual-core computers", and yet background compilation performance was unsatisfactory for them on large projects. It's entirely possible that this is Visual Studio's fault. However, I'd like to point out that <b>not all dual core computers are created equal</b>. Not by a long shot.
</p>
<p>
Take a look at this <a href="http://www.digit-life.com/articles2/cpu/intel-core2-duo-e6600.html">Visual C++ compilation benchmark</a>. Details of the benchmark methodology are available on <a href="http://www.digit-life.com/articles2/cpu/method-2006-2-0-rc.html">this page</a>, but for now let's assume this is typical compilation performance in a typical IDE. <b>The baseline score of 100 represents a 2.6 GHz Pentium D 805 CPU</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Clearly the <a href="http://www.codinghorror.com/blog/archives/000285.html">multiple core future</a> has already arrived-- every CPU you see here is a dual-core model. Many Pentium 4 models come in dual-core flavor.
</p>
<p>
The CPU at the bottom of the benchmark results isn't just any garden variety Pentium 4, though. It's the <a href="http://techreport.com/reviews/2006q1/pentium-xe-965/index.x?pg=1">Pentium 965 "Extreme Edition"</a>, the absolute pinnacle of the Pentium 4 CPU family. It's a 3.73 GHz dual-core, dual-hyperthreaded CPU that originally retailed for almost a thousand dollars. <b>The <i>fastest possible</i> Pentium 4 is nearly 50 percent slower at compilation than a midrange Athlon 64 or Core 2 Duo CPU</b>. But wait! It gets worse!
</p>
<p>
Consider <a href="http://techreport.com/reviews/2006q3/core2/index.x?pg=11">WorldBench - Mozilla 1.4 results</a>. The times shown are in seconds; lower scores are better.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Bringing up the rear, by a large margin, are two members of the Pentium 4 CPU family. The 3.6 GHz Pentium D 960 is <b>almost twice as slow</b> as the 2.6 GHz Core 2 Duo E6700 in Mozilla.
</p>
<p>
Perhaps this is why Tech Report called the Pentium 4 "[a] CPU based on a lame-duck microarchitecture."
</p>
<p>
If you're running a Pentium 4 CPU-- even a "fast" 3.4 GHz+ dual-core model-- you could <b>more than double your performance</b> by upgrading to a middle-of-the-road Core 2 Duo CPU. And I'm not talking about meaningless synthetic performance benchmark numbers; I'm talking about performance in real world apps that software developers use every day, meat and potatoes stuff like web browsers and compilers.
</p>
<p>
If you're using a Pentium 4 CPU of any kind, consider upgrading at the earliest possible opportunity. Given how much software developers are paid, it makes no economic sense to hobble them with old, slow PCs based on the underperforming Pentium 4 CPU. <a href="http://www.codinghorror.com/blog/archives/000666.html">Demand your rights</a>.  You can pick up a midrange Core 2 Duo system, sans monitor, for under a thousand dollars. Isn't the value of your time worth at least that?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/productivity-tip-upgrade-your-pentium-4/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ JavaScript: The Lingua Franca of the Web ]]></title>
<link>https://blog.codinghorror.com/javascript-the-lingua-franca-of-the-web/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Mike Shaver, a founding member of the Mozilla team, has <a href="http://shaver.off.net/diary/2007/05/10/the-high-cost-of-some-free-tools/">strong feelings</a> about how the web became popular:
</p>
<p>
</p>
<blockquote>
If you choose a platform that needs tools, <b>if you give up the viral soft collaboration of View Source and copy-and-paste mashups</b> and being able to jam jQuery in the hole that used to have Prototype in it, you lose what gave the web its distributed evolution and incrementalism. You lose what made the web great, and what made the web win.
</blockquote>
<p>
The <a href="http://www.codinghorror.com/blog/archives/000661.html">radically open source, viral nature of the View Source menu</a> is certainly a key part of the web's success. But that's only part of the story. The increasing maturity of the JavaScript implementation in modern browsers is <a href="http://www.paulgraham.com/web20.html">the foundation of the web's present and future</a>:
</p>
<p>
</p>
<blockquote>
One ingredient of [Web 2.0] is certainly Ajax, which I can still only just bear to use without scare quotes. Basically, <b>what "Ajax" means is "Javascript now works."</b> And that in turn means that web-based applications can now be made to work much more like desktop ones.
</blockquote>
<p>
Like many programmers, I initially wrote off JavaScript as a toy language. Even Douglas "my middle name is JavaScript" Crockford was <a href="http://javascript.crockford.com/survey.html">guilty of this misconception</a>:
</p>
<p>
</p>
<blockquote>
When JavaScript was first introduced, I dismissed it as being not worth my attention. Much later, I took another look at it and discovered that hidden in the browser was an excellent programming language. My initial attitudes were based on the initial positioning of JavaScript by Sun and Netscape. They made many misstatements about JavaScript in order to avoid positioning JavaScript as a competitor to Java. Those misstatements continue to echo in the scores of badly written JavaScript books aimed at the dummies and amateurs market.
</blockquote>
<p>
Regardless of your original feelings towards the language, JavaScript has <a href="http://www.oreillynet.com/pub/a/javascript/2001/04/06/js_history.html">come a long way</a> since the bad old days of 1995. We've got CPU power to burn on the client; so much power, in fact, that even an interpreted, dynamic language like JavaScript <a href="http://www.codinghorror.com/blog/archives/000509.html">can be a credible client-side development environment</a>. The language has been <a href="http://en.wikipedia.org/wiki/ECMAScript">standardized as ECMA-262, edition 3</a> since 1999, so there's now a reasonable expectation of compatibility across browsers.
</p>
<p>
More and more websites leverage JavaScript to stretch the boundaries of what the browser can do. The idea of browsing today's web with JavaScript disabled is almost quaint. With the success of so many startups based on nothing but JavaScript, HTML, and the server-side language of their choice, you'd think JavaScript would enjoy some hard-won respect by now. But I still see a lot of angst and ennui towards JavaScript from developers, even today. Scott Koon had <a href="http://blog.jonudell.net/2007/04/30/a-conversation-with-john-lam-about-the-dynamic-language-runtime-silverlight-and-ruby/#comment-12862">a clever way of putting it</a>:
</p>
<p>
</p>
<blockquote>
[JavaScript won] by default. People wanted to build better web applications. Programming against Flash movies sucked. Javascript was already in all the browsers. If you're the last man left on earth, it doesn't matter how ugly you are when the women come to re-populate the planet.
</blockquote>
<p>
Some programmers will do almost anything to avoid getting their feet dirty in the highly imperfect world of JavaScript. Vendors are all too willing to offer up their alternatives:
</p>
<p>
</p>
<ul>
<li>
<a href="http://en.wikipedia.org/wiki/Microsoft_Silverlight">Microsoft Silverlight 1.1</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Adobe_Flex">Adobe Flex</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/JavaFX">Sun's JavaFX</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Macromedia_Flash">Adobe Flash</a>
</li>
</ul>
<p>
Despite all the pretenders to the throne, JavaScript isn't going away any time soon. <b>JavaScript is the world's most ubiquitous computing runtime.</b> It's time we learned to accept and embrace JavaScript rather than blindly fighting it. That doesn't mean we can't explore alternatives-- but the best way to transcend the limitations of JavaScript is to immerse yourself in those limitations. At least that way you know what you're fighting for, and what the alternatives really mean.
</p>
<p>
Is JavaScript annoying at times? Sure. Is it aggravating to deal with all the cross-browser issues you'll inevitably run into? Absolutely. Is debugging in the browser a pain in the butt? You bet it is, although <a href="http://www.codinghorror.com/blog/archives/000780.html">FireBug helps</a>. But JavaScript, in its way, is <a href="http://javascript.crockford.com/javascript.html">as groundbreaking as it is infuriating</a>:
</p>
<p>
</p>
<blockquote>
JavaScript's C-like syntax, including curly braces and the clunky for statement, makes it appear to be an ordinary procedural language. This is misleading because JavaScript has more in common with functional languages like Lisp or Scheme than with C or Java. It has arrays instead of lists and objects instead of property lists. Functions are first class. It has closures. You get lambdas without having to balance all those parens.
</blockquote>
<p>
<b>JavaScript is the <a href="http://en.wikipedia.org/wiki/Lingua_franca">lingua franca</a> of the web. Ignore it at your peril.</b>
</p>
<p>
If you're looking to get reacquainted with JavaScript, the best single resource on the web is still <a href="http://javascript.crockford.com/">Douglas Crockford's site</a>. I can also recommend Douglas Crockford's series of Yahoo videos, which provide an excellent overview of modern thinking in JavaScript.
</p>
<p>
</p>
<ul>
<li>
<a href="http://video.yahoo.com/video/search?p=the+javascript+programming+language+crockford">The JavaScript Programming Language</a>
</li>
<li>
<a href="http://video.yahoo.com/video/search?p=advanced+javascript+crockford">Advanced JavaScript</a>
</li>
<li>
<a href="http://video.yahoo.com/video/search?p=theory+of+the+dom+crockford">An Inconvenient API: The Theory of the DOM</a>
</li>
</ul>
<p>
You can <a href="http://yuiblog.com/assets/crockford/">download the companion slides</a> for these presentations from the excellent <a href="http://yuiblog.com/">Yahoo User Interface Blog</a>.
</p>
<p>
There are some exciting JavaScript alternatives on the horizon. Some will be successful; some won't. In all the hubbub over new tools and new choices, don't forget that <b>JavaScript remains an excellent choice for rich internet application development</b> -- and as the existing lingua franca of the web, its success is <i>guaranteed</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/javascript-the-lingua-franca-of-the-web/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ When Hardware is Free, Power is Expensive ]]></title>
<link>https://blog.codinghorror.com/when-hardware-is-free-power-is-expensive/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Bill Gates has often said that <b>over time, the cost of computer hardware approaches zero</b>. Here's <a href="https://www.wired.com/2004/03/gates-hardware-will-be-free/">one such example</a>:</p>
<blockquote>
Ten years out, in terms of actual hardware costs you can almost think of hardware as being free.
</blockquote>
<p>History has proven him right. Computer hardware isn't literally free, of course. But it's <i>effectively</i> free relative to the level of computing power you're getting for your dollar. <b>What does it mean when computer hardware is effectively free, and getting even more free every day?</b></p>
<p>For one thing, <a href="http://www.codinghorror.com/blog/archives/000011.html">computer software starts to look incredibly expensive</a>. But let's put aside the ratio of software cost to hardware cost for now.</p>
<p>If you're Google, or any other company building out massive datacenter farms, cheap hardware is a strategic advantage. It means you can build larger and larger datacenters for less money.  Computers may be smaller and cheaper than ever, but they <a href="https://www.cnet.com/news/power-could-cost-more-than-servers-google-warns/">still require electricity to operate.</a> You now have a new problem. The electrical power used to drive all that free hardware you've amassed becomes your greatest expense:</p>
<blockquote>
Over the last three generations of Google's computing infrastructure, performance has nearly doubled, Barroso said. But because performance per watt remained nearly unchanged, that means electricity consumption has also almost doubled.
<p><b>If server power consumption grows 20 percent per year, the four-year cost of a server's electricity bill will be larger than the $3,000 initial price of a typical low-end server with x86 processors.</b> Google's data center is populated chiefly with such machines. But if power consumption grows at 50 percent per year, "power costs by the end of the decade would dwarf server prices," even without power increasing beyond its current 9 cents per kilowatt-hour cost, Barroso said.</p>
</blockquote>
<p>Computer hardware costs may be approaching zero, but power costs are fixed – or rising. The thirst for power in the face of increasingly large datacenters has driven Google to <a href="http://www.infoworld.com/article/2662029/operating-systems/it-confronts-the-datacenter-power-crisis.html">build datacenters in out-of-the-way places where power costs are low</a>:</p>
<blockquote>
Google, for example, has watched its energy consumption almost double during the past three generations of upgrades to its sprawling computing infrastructure. <b>It recently unveiled a major new datacenter site in a remote part of Oregon, where power costs are a fraction of those at Google's home base in Silicon Valley.</b> But cheap power may not be enough. Last year, Google engineer Luiz Andr Barroso predicted that energy costs would dwarf equipment costs  – "possibly by a large margin"  – if power-hungry datacenters didn't mend their ways. Barroso went on to warn that datacenters' growing appetite for power "could have serious consequences for the overall affordability of computing, not to mention the overall health of the planet."
</blockquote>
<p>Google doesn't just <a href="https://blog.codinghorror.com/building-a-computer-the-google-way/">build their own servers</a>. They <a href="http://www.networkworld.com/article/2304459/data-center/google-builds-own-servers-for-efficiency.html">build their own power supplies</a>, too:</p>
<blockquote>
The power supply to servers is one place that energy is unnecessarily lost. One-third of the electricity running through a typical power supply leaks out as heat, [Urs Hlzle] said. That's a waste of energy and also creates additional costs in the cooling necessary because of the heat added to a building.
<p><b>Rather than waste the electricity and incur the additional costs for cooling, Google has power supplies specially made that are 90% efficient.</b> "It's not hard to do. That's why to me it's personally offensive" that standard power supplies aren't as efficient, he said.</p>
<p>While he admits that ordering specially made power supplies is more expensive than buying standard products, Google still saves money ultimately by conserving energy and cooling, he said.</p>
</blockquote>
<p>Google wants to extend that same efficiency outside their datacenter to your home PC. The three page Google whitepaper <a href="http://static.googleusercontent.com/media/services.google.com/en//blog_resources/PSU_white_paper.pdf">High-efficiency power supplies for home computers and servers</a> (pdf) outlines how and why:</p>
<blockquote>
At Google, we run many computers in our data centers to serve your queries, so energy conservation and efficiency are important to us. For several years we've been developing more efficient power supplies to eliminate waste from power supplies. Instead of the typical efficiencies of 60-70%, our servers' power supplies now run at 90% efficiency or better, cutting down the energy losses by a factor of four.
<p>We believe this energy-saving power supply technology can be applied to home<br>
computers, too. So we've been working with Intel and other partners to propose a new power supply standard. The opportunity for savings is immense   –  we estimate that if deployed in 100 million PCs running for an average of eight hours per day, this new standard would save 40 billion kilowatt-hours over three years, or more than $5 billion at California's energy rates.</p>
</blockquote>
<p>I can vouch for this: power is <i>incredibly</i> expensive in California, to the point that <a href="https://blog.codinghorror.com/the-cost-of-leaving-your-pc-on/">running even a single PC 24/7 can have a noticeable impact on your power bill</a>.</p>
<p>Google's proposal to increase the efficiency of PC power supplies mirrors a push for efficiency that's been going on for a while in the PC enthusiast space. It's partly a reflection of <a href="https://blog.codinghorror.com/building-a-quiet-pc/">the quiet PC movement</a>: less heat always equal less noise. But it can also have a bottom-line impact on how much you pay the power company each month.</p>
<p>I'm not aware of any standard PC power supplies that reach the lofty 90% efficiency goal Google claims. What Google's proposing is a deeper, more fundamental change to the way the PC power supply is built – simplifying from multiple voltages (+12v, -12v, 5v, and 3.3v) to a single voltage (12v).  But <b>a standard PC power supply of sufficient quality <i>can</i> reach up to 85% efficiency</b>. Consider the following graph comparing the efficiency of two PC power supplies:</p>
<img alt="image placeholder" >
<p>The graph shows <b>the difference between a typical PC power supply and one of the most energy efficient power supplies currently on the market</b>. The data table tells the story in raw watts:</p>
<table border="0" cellpadding="4" cellspacing="4">
<tr>
<td colspan="9">
<strong><a href="http://www.silentpcreview.com/article177-page4.html">NeoPower 480 Power Supply</a></strong>
</td>
</tr>
<tr>
<td>
AC Input</td>
<td align="right">
110</td>
<td align="right">
142</td>
<td align="right">
220</td>
<td align="right">
276</td>
<td align="right">
336</td>
<td align="right">
390</td>
<td align="right">
515</td>
<td align="right">
596</td>
</tr>
<tr>
<td>
DC Output</td>
<td align="right">
65</td>
<td align="right">
90</td>
<td align="right">
150</td>
<td align="right">
200</td>
<td align="right">
250</td>
<td align="right">
300</td>
<td align="right">
400</td>
<td align="right">
460</td>
</tr>
<tr>
<td>
Efficiency</td>
<td align="right">
59%</td>
<td align="right">
63%</td>
<td align="right">
68%</td>
<td align="right">
72%</td>
<td align="right">
74%</td>
<td align="right">
77%</td>
<td align="right">
78%</td>
<td align="right">
77%</td>
</tr>
<tr>
<td>
Waste</td>
<td align="right">
45</td>
<td align="right">
52</td>
<td align="right">
70</td>
<td align="right">
76</td>
<td align="right">
86</td>
<td align="right">
90</td>
<td align="right">
115</td>
<td align="right">
136</td>
</tr>
</table>
<br>
<table border="0" cellpadding="4" cellspacing="4">
<tr>
<td colspan="10">
<strong><a href="http://www.silentpcreview.com/article692-page4.html">Corsair HX520W Power Supply</a></strong>
</td>
</tr>
<tr>
<td>
AC Input</td>
<td align="right">
64</td>
<td align="right">
88</td>
<td align="right">
115</td>
<td align="right">
183</td>
<td align="right">
236</td>
<td align="right">
295</td>
<td align="right">
350</td>
<td align="right">
486</td>
<td align="right">
638</td>
</tr>
<tr>
<td>
DC Output</td>
<td align="right">
43</td>
<td align="right">
63</td>
<td align="right">
89</td>
<td align="right">
148</td>
<td align="right">
199</td>
<td align="right">
251</td>
<td align="right">
298</td>
<td align="right">
407</td>
<td align="right">
519</td>
</tr>
<tr>
<td>
Efficiency</td>
<td align="right">
68%</td>
<td align="right">
72%</td>
<td align="right">
77%</td>
<td align="right">
81%</td>
<td align="right">
84%</td>
<td align="right">
85%</td>
<td align="right">
85%</td>
<td align="right">
84%</td>
<td align="right">
81%</td>
</tr>
<tr>
<td>
Waste</td>
<td align="right">
21</td>
<td align="right">
24</td>
<td align="right">
26</td>
<td align="right">
35</td>
<td align="right">
37</td>
<td align="right">
44</td>
<td align="right">
52</td>
<td align="right">
79</td>
<td align="right">
119</td>
</tr>
</table>
<p>It's a decent result; efficiency increases by more than 10 percent across the board. But there's a catch: <b>the power supply efficiency curve peaks at around 250 watts</b>.</p>
<p><a href="http://www.codinghorror.com/blog/archives/000353.html">Most desktop PCs barely use 200 watts of power</a>. It's extremely difficult to build a desktop computer that uses 250 watts of power without <a href="http://www.codinghorror.com/blog/archives/000662.html">adding a high-powered $300+ gaming class video card to the mix</a>  – or even two of them in SLI mode. Furthermore, you'll only reach that level of power usage under extreme load – with the video card and CPU both operating at near 100% usage. In other words, <i>only when you're playing a video game</i>. The <a href="http://techreport.com/review/12458/amd-radeon-hd-2900-xt-graphics-processor/15">difference between idle and gaming load power usage</a> can be more than 100w.</p>
<p>Unless you're a gamer, you won't even come <i>close</i> to 200 watts of power usage, even under full load. And how often is your PC operating at full load? If you're like most users, almost never. Your PC is statistically idle 99% of the time it is turned on. Idle power consumption for a typical desktop PC <a href="http://techreport.com/review/10351/intel-core-2-duo-and-extreme-processors/16">ranges between 120 and 150 watts</a>. Thus, <b>the real challenge is to deliver 90%+ efficiency at typical idle power consumption levels – 120-150 watts.</b></p>
<p>The savings from upgrading to an efficient power supply on a single PC are rarely worth it. I'll demonstrate using <a href="https://blog.codinghorror.com/the-cost-of-leaving-your-pc-on/">my old server</a> as an example. It draws 160 watts of power at idle, and is turned on 24/7, 365 days a year. If I was to hypothetically install a power supply in this server that was 15 percent more efficient  – a <i>best-case</i> scenario  – how much power would I save per year?</p>
<pre>
160 watts * (8,760 hours per year) / 1000 = 1401.6 kilowatt-hours
136 watts * (8,760 hours per year) / 1000 = 1191.4 kilowatt-hours
</pre>
<p>At the insanely expensive California power rates in my area, that equates to the following dollar amount per year:</p>
<pre>
1401.6 kilowatt-hours * 14.28 cents / 100 = $200.15
1191.4 kilowatt-hours * 14.28 cents / 100 = $170.13
</pre>
<p>I'd save a whopping <i>thirty bucks per year</i>. That's not even enough to cover the cost of the energy-efficient power supply! I'd have to amortize the cost of the power supply over three years to justify the expense.</p>
<p>All this tells us is that Google's problems aren't necessarily our personal problems. Not exactly news. But if you multiply that result by <a href="https://en.wikipedia.org/wiki/Google_Data_Centers">the tens of thousands of servers in Google's server farm</a>, all operating at near 100% load, it's a whole different ballgame. Efficiency is a strategic business decision for Google. Considering the millions upon millions of computers in the world, <b>more efficient PC power supplies are also part of the greater public good</b>. Do no evil, indeed.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/when-hardware-is-free-power-is-expensive/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The End of the "Microsoft Tax" ]]></title>
<link>https://blog.codinghorror.com/the-end-of-the-microsoft-tax/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Today, bowing to <a href="http://www.ideastorm.com/">customer demand</a>, Dell launched <a href="http://www.dell.com/ubuntu">a new series of desktops</a> featuring the free, open-source <a href="http://www.ubuntu.com/">Ubuntu</a> operating system.
</p>
<p>
To my knowledge, <b>this is the first time Dell has <i>ever</i> offered any non-Microsoft operating system on their desktops</b>. Until today, it was quite literally impossible to decline the Windows license when you bought a desktop from Dell. If you bought a desktop PC from Dell, you got -- and paid for -- a copy of Windows, whether you wanted it or not. This is <a href="http://www.freesoftwaremagazine.com/blogs/the_microsoft_tax_revisited">commonly referred to as "The Microsoft Tax"</a>. Offering a free desktop operating system is <b>effectively the same thing as selling hardware without <i>any</i> operating system</b>.
</p>
<p>
Whether you're a fan of the latest open source operating systems, or just a fan of plain old-fashioned consumer choice, the end of the Microsoft tax is a win for customers. I was a little worried that Dell would charge extra for the privilege, but it looks like they played fair and square:
</p>
<p>
</p>
<table padding="4" spacing="4" width="500">
<tr>
<td style="width: 80px">
</td>
<td valign="top">
<a href="http://configure.us.dell.com/dellstore/config.aspx?c=us&amp;cs=19&amp;l=en&amp;oc=DDCWAA3&amp;s=dhs">
Dell Dimension E520</a>
</td>
<td valign="top">
<a href="http://configure.us.dell.com/dellstore/config.aspx?c=us&amp;cs=19&amp;kc=6V440&amp;l=en&amp;oc=DDCWAV3&amp;s=dhs">
Dell Dimension E520N</a>
</td>
</tr>
<tr>
<td style="width: 80px">
CPU</td>
<td valign="top">
Core 2 Duo E4300 1.86 GHz</td>
<td valign="top">
Core 2 Duo E4300 1.86 GHz</td>
</tr>
<tr>
<td style="width: 80px">
RAM</td>
<td valign="top">
1 GB DDR2</td>
<td valign="top">
1 GB DDR2</td>
</tr>
<tr>
<td style="width: 80px">
Hard Drive</td>
<td valign="top">
250 GB</td>
<td valign="top">
250 GB</td>
</tr>
<tr>
<td style="width: 80px">
Media</td>
<td valign="top">
CD-RW/DVD</td>
<td valign="top">
CD-RW/DVD</td>
</tr>
<tr>
<td style="width: 80px">
Video</td>
<td valign="top">
Integrated Intel GMA X3000</td>
<td valign="top">
Integrated Intel GMA 950</td>
</tr>
<tr>
<td style="width: 80px">
OS</td>
<td valign="top">
<b>Windows Vista Home Premium</b>
</td>
<td valign="top">
<b>Ubuntu Desktop Edition 7.04</b>
</td>
</tr>
<tr>
<td style="width: 80px">
</td>
<td valign="top">
<span style="color: red">$679</span>
</td>
<td valign="top">
<span style="color: red">$599</span>
</td>
</tr>
</table>
<p>
The hardware is essentially identical. We can infer that Dell's price for a Windows Vista Home Premium license is $80. An <a href="http://www.google.com/products?q=vista+home+premium+oem">OEM copy of Home Premium runs about $129</a>, so it's cheaper to buy the license from Dell than it is to buy one yourself. But if you have no intention of running Windows, you just saved eighty bucks.
</p>
<p>
Kudos to Dell for doing the right thing and <b>ending the Microsoft Tax</b>. It's also quite possible today will be looked back on as an important turning point in the history of desktop computing.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-end-of-the-microsoft-tax/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Upgrading to a High Efficiency Power Supply ]]></title>
<link>https://blog.codinghorror.com/upgrading-to-a-high-efficiency-power-supply/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In <a href="https://blog.codinghorror.com/when-hardware-is-free-power-is-expensive/">When Hardware is Free, Power is Expensive</a>, I referenced a <a href="http://static.googleusercontent.com/media/services.google.com/en//blog_resources/PSU_white_paper.pdf">Google whitepaper</a> (pdf) that explained why typical PC power supplies are not particularly efficient:</p>
<blockquote>
<p><strong>Most likely, the computer you're using wastes 30-40% of the electrical power it<br>
consumes because it is using an inefficient power supply.</strong> It's difficult to believe that something as basic as a power supply could be responsible for that amount of waste, but it's true. The problem with power supplies is that they generate heat, which saps away energy meant to power the computer. That happens when the power supply converts AC current into the DC current needed by computers</p>
</blockquote>
<p>Google's solution for their datacenter computers is a radical makeover – switching wholesale to single-voltage 12 volt power supplies.</p>
<blockquote>
<p>The net result of [the switch to a single-voltage 12v power supply] is a dramatic improvement in efficiency (including the power supply and the regulators) to about 85%, at virtually no cost. In other words, <b>you won't have to pay more for a higher-efficiency PC, because the power supply is actually getting simpler, not more complicated</b>. By spending another $20 or so extra, it is possible to use higher-quality components and achieve efficiencies well over 90%.</p>
<p>You won't be able to buy such computers for a while, and Google isn't planning on selling you any. But we're working with industry partners such as Intel to make this technology an open standard that everyone can use, and that all vendors hopefully will adopt. It's the right solution technically, and the right thing to do for the environment.</p>
</blockquote>
<p>Who knows when these hypothetical single-voltage systems will arrive on the market in the form of desktop PCs and laptops we can actually buy. In the meantime, <strong>it is possible to upgrade your computer with a high efficiency multiple-voltage power supply</strong>. Unfortunately, existing high efficiency power supplies aren't available "at virtually no cost"; they tend to be quite a bit more expensive than their less efficient cousins. I just upgraded my home PC to a high efficiency power supply:<br></p>
<ul>
<li>Core 2 Duo 3.2 GHz CPU (overclocked, overvolted)</li>
<li>Radeon X1900 XTX primary video card</li>
<li>Radeon X1550 secondary video card</li>
<li>Western Digital Raptor 150 GB primary hard drive</li>
<li>Seagate 750 GB secondary hard drive</li>
<li>Creative X-Fi sound card</li>
</ul>
<p>Note that this is a fairly power hungry system by current desktop standards. The <a href="http://www.codinghorror.com/blog/archives/000662.html">gaming-class video card</a> and overclocked/overvolted CPU are the primary culprits. I used my <a href="https://blog.codinghorror.com/why-estimate-when-you-can-measure/">trusty kill-a-watt to measure the power usage</a> before and after the power supply upgrade. The power supply was the <em>only</em> component that changed.</p>
<table cellpadding="4" cellspacing="4" width="425px">
<tr>
<td style="width: 100px">
</td>
<td align="right" style="width: 65px">
Typical PSU</td>
<td align="right" style="width: 65px">
Efficient PSU</td>
<td style="width: 65px">
</td>
<td style="width: 65px">
</td>
</tr>
<tr>
<td style="width: 65px">
Off</td>
<td align="right" style="width: 65px">
5 w</td>
<td align="right" style="width: 65px">
5 w</td>
<td align="right" style="width: 65px">
</td>
<td align="right" style="width: 65px"></td>
</tr>
<tr>
<td style="width: 65px">
Boot (peak)</td>
<td align="right" style="width: 65px">
237 w</td>
<td align="right" style="width: 65px">
215 w</td>
<td align="right" style="width: 65px">
-22 w</td>
<td align="right" style="width: 65px">
9.3%</td>
</tr>
<tr>
<td style="width: 65px">
Desktop</td>
<td align="right" style="width: 65px">
205 w</td>
<td align="right" style="width: 65px">
185 w</td>
<td align="right" style="width: 65px">
-20 w</td>
<td align="right" style="width: 65px">
9.8%</td>
</tr>
<tr>
<td style="width: 65px">
1 × <a href="http://www.mersenne.org/freesoft.htm">Prime95</a>
</td>
<td align="right" style="width: 65px">
236 w</td>
<td align="right" style="width: 65px">
217 w</td>
<td align="right" style="width: 65px">
-19 w</td>
<td align="right" style="width: 65px">
8.1%</td>
</tr>
<tr>
<td style="width: 65px">
2 × Prime95</td>
<td align="right" style="width: 65px">
257 w</td>
<td align="right" style="width: 65px">
237 w</td>
<td align="right" style="width: 65px">
-20 w</td>
<td align="right" style="width: 65px">
7.8%</td>
</tr>
<tr>
<td style="width: 65px">
<a href="http://www.gamershell.com/download_19282.shtml">DiRT demo</a> peak</td>
<td align="right" style="width: 65px">
270 w</td>
<td align="right" style="width: 65px">
247 w</td>
<td align="right" style="width: 65px">
-23 w</td>
<td align="right" style="width: 65px">
8.5%</td>
</tr>
</table>
<p><strong>Most typical desktop PC power supplies are only 60 to 75 percent efficient; high efficiency models offer 80+ percent, all the way up to 85 percent depending on the load</strong>. And that's exactly what we're seeing in these results. With the new high-efficiency power supply installed, I gained about 10 percent efficiency at each load level. To get an idea of where this system stands in terms of overall power usage, you can compare with a few different systems shown on <a href="http://www.silentpcreview.com/article28-page4.html">page 4 of the Silent PC Review Power Supply Fundamentals</a>.</p>
<p>I was surprised to find that <strong>my PC uses 5 watts of power <em>even when it's powered off</em></strong>. This is what's known as <a href="http://www.berkeley.edu/news/media/releases/2001/02/09_energ.html">"standby" electricity loss</a>, and at least <a href="http://www.berkeley.edu/news/media/releases/2001/02/09_energ.html">one study</a> showed it accounts for 6 to 16 percent of all energy use in homes, and <a href="http://china.lbl.gov/publications/china_standby_sino1102.pdf">another</a> (pdf) estimates that standby power use is now responsible for 1% of total carbon emissions on earth. The only way to reduce your computer's power use to zero watts is to unplug it from the wall, or flip the power switch on the back of the power supply.</p>
<p>If you're interested in upgrading to a high-efficiency power supply, look for models tagged with <a href="http://www.80plus.org/">the 80 PLUS designation</a>, which are guaranteed 80% efficient at 20%, 50% and 100% of their rated load. Many vendors cut corners by stating their power supplies offer "up to" 80 percent efficiency, but what they don't tell you is that you'll only reach that level of efficiency under extreme power loads that are unrealistic for most desktops. Seasonic is a popular choice, as they have aggressively enforced the 80 PLUS certification on almost their entire product line. But fair warning: you will pay a premium.<br></p>
<p>You can use <a href="http://www.80plus.org/80sav.htm">the handy calculator provided by the 80 PLUS website</a> to determine how much money you could potentially save on your power bill by switching to a more efficient power supply. It's usually not much, <a href="https://blog.codinghorror.com/when-hardware-is-free-power-is-expensive/">unless you happen to run a server farm</a>. But every little bit helps, and until Google and Intel offer up their single-voltage 12 volt system designs – which supposedly offer greater than 90 percent efficiency – it's the best we can do.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/upgrading-to-a-high-efficiency-power-supply/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How to Get Rich Programming ]]></title>
<link>https://blog.codinghorror.com/how-to-get-rich-programming/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I originally discovered the <b>fiendishly addictive Tower Defense</b> as a multiplayer game modification for <a href="http://www.blizzard.com/war3/">Warcraft III</a>. It's a cooperative game mode where you, and a few other players, are presented with a simple maze. A group of monsters appear at the entrance and trudge methodically toward the exit. Your goal is to destroy the monsters before they reach the exit by constructing attack towers along the borders of the maze. As you kill monsters, you gain cash, which you use to purchase more powerful attack towers and upgrades for your existing towers. The monsters keep increasing in power each wave, but if you're clever, you might be able to survive all the waves and reach the end.
</p>
<p>
I can't explain exactly what makes Tower Defense so addictive, but man, is it ever. Perhaps it's the collaborative gameplay, along with the "just one more time" element of different tower arrangements and greater income to build ever more powerful towers. Remember, <b>this is a game mode not created by Blizzard, but invented by multiplayer game modders using the tools provided with Warcraft III</b>. It was completely unique-- I had never played anything like it. After about six months, I completely stopped playing traditional multiplayer games of Warcraft III in favor of user modifications like Tower Defense.  As a hat tip to the community, Blizzard included their take on tower defense as a hidden mission in the <a href="http://www.blizzard.com/war3x/">Frozen Throne expansion</a>.
</p>
<p>
I suppose it was inevitable that this new, addictive Tower Defense game mode would jump from the select audience of gamers with gaming-class PCs to simpler Flash implementations everyone can enjoy. The low-intensity, puzzle-like gameplay of Tower Defense translates well to the broad audience of casual gamers. And the most popular version, by far, is <a href="http://www.handdrawngames.com/DesktopTD/">Desktop Tower Defense</a>.
</p>
<p>
<a href="http://www.handdrawngames.com/DesktopTD/"><img alt="image placeholder" >
</p>
<p>
Warning: before clicking on that link, allow me to reiterate: <i>tower defense is addictive!</i> Don't blame me if you lose an hour or more of productivity. But if you, like me, just have to make it through all 50 levels (or 100 levels in challenge mode), I refer you to this collection of <a href="http://www.neatorama.com/2007/04/14/desktop-tower-defense-strategies/">Desktop Tower Defense strategies</a>. And a word of advice: upgrade a few towers to the maximum; don't spread your upgrades across a fleet of towers.
</p>
<p>
You'd be surprised how much money you can make by creating a flash game and giving it away for free on the internet. The Tower Defense game mode is <b>a business opportunity for an enterprising programmer</b>. According to <a href="http://gigaom.com/2007/05/27/desktop-tower-defense/">a recent interview</a>, Paul Preese, the author of Desktop Tower Defense, is making <font color="red">around $8,000 <i>per month</i></font>.
</p>
<p>
</p>
<blockquote>
So here's a couple ways to a create successful game online:
<p>
</p>
<ol type="a">
<li>Find an investor who's crazy enough to give you millions of dollars
</li>
<li>Put it on a distribution network and hope you get enough customers willing to buy it as a download
</li>
<li>Make a Flash mini-game, let people play it for free, and watch the ad revenue pour in when the site gets 20 million pageviews a month.
</li>
</ol>
<p>
That's the option Paul Preece took with his phenomenally popular Desktop Tower Defense, and though he has no professional experience with game development, <b>the Visual Basic programmer is now making, by his estimate, high four figures monthly for his ferociously viral little game</b>.
</p>
<p>
DTD's main revenue source is AdSense, but with its avalanche of popularity, advertisers have approached Preece directly, leading to "Affiliate deals, sponsorship, custom versions for other companies etc. The last two are in the pipeline but I thought I'd add them in at a low level."
</p>
<p>
Preece's main expense is running the server. "Hosting fees are negligible," he says, "at $130 per month. But I am getting very close to the 1200GB bandwidth allocation!" That plus "the continuous supply of late night Red Bull" comprise the bulk of Desktop's budget.
</p>
</blockquote>
<p>
So minus the time he spent programming, and his nominal hosting fees, Paul Preese is clearing almost $100,000 "salary" per year with Desktop Tower Defense. And he did it all on his own: he wrote the game, placed it on a public web server, hooked up AdSense, and then submitted it to a few social bookmark sites. No selling his soul to a publisher, no middlemen, just pure income, controlled directly by him.
</p>
<p>
What's truly exciting about this is how <b>the internet has created economic opportunity for a single programmer working alone</b>. You might not get rich, exactly, but $100k/year is an impressive salary in most areas of the United States. <a href="http://en.wikipedia.org/wiki/Roller_Coaster_Tycoon">Roller Coaster Tycoon</a> was the last traditionally published game created by a single programmer working alone. The author, Chris Sawyer, cleared <b>$30 million</b> for all the various version of the game released since 1999, <a href="http://www.next-gen.biz/index.php?option=com_content&amp;task=view&amp;id=1546&amp;Itemid=2">according to financial documents released by the publisher</a>. And just to put things in perspective, the publisher cleared $180 million. That's the "selling your soul" part.
</p>
<p>
Granted, $4 million per year is a heck of a lot more than $100,000 per year. But the odds of you and I getting a publishing deal-- or <a href="http://en.wikipedia.org/wiki/Roller_Coaster_Tycoon#History">writing a game in assembly language</a>-- are pretty slim. Paul's success, on the other hand, is something that any programmer, with sufficient motivation and a little bit of luck, could potentially duplicate.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-get-rich-programming/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Is The System Idle Process Hogging All The Resources? ]]></title>
<link>https://blog.codinghorror.com/why-is-the-system-idle-process-hogging-all-the-resources/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
From the "you can't make this stuff up department", <a href="http://www.pcmag.com/article2/0,1759,1304348,00.asp">this 2003 gem</a> from <a href="http://www.codinghorror.com/blog/archives/000302.html">blogging O.G. John Dvorak</a>:
</p>
<p>
</p>
<blockquote>
IDLE-TIME PROCESS. Once in a while the system will go into an idle mode, requiring from five minutes to half an hour to unwind. It's weird, and I almost always have to reboot. <b>When I hit Ctrl-Alt-Delete, I see that the System Idle Process is hogging all the resources and chewing up 95 percent of the processor's cycles.</b> Doing what? Doing nothing? Once in a while, after you've clicked all over the screen trying to get the system to do something other than idle, all your clicks suddenly ignite and the screen goes crazy with activity. This is not right.
</blockquote>
<p>
I remember <a href="http://www.pcmag.com/article2/0,1759,1304348,00.asp">reading Dvorak's PC Magazine column</a> at the time and doing a double-take. Dvoraksayswhat?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In John's defense, it sounds like he was having some kind of strange, unrelated problem which he wrongly attributed to the idle task. But his profound misunderstanding of how this fundamental bit of computer science works is a wee bit disturbing for <a href="http://en.wikipedia.org/wiki/John_C._Dvorak">a computer journalist of his tenure and stature</a>.
</p>
<p>
In case there's anyone reading this who <i>doesn't</i> understand how the <a href="http://en.wikipedia.org/wiki/System_Idle_Process">System Idle Process</a> works (Hi Mr. Dvorak!), the Wikipedia entry for <a href="http://en.wikipedia.org/wiki/Idle_task">Idle task</a> is unusually succinct, so I'll just quote it in its entirety:
</p>
<p>
</p>
<blockquote>
In computing, an idle task is a special task loaded by the OS scheduler only when there is nothing for the computer to do. The idle task can be hard-coded into the scheduler, or it can be implemented as a separate task with the lowest possible priority. An advantage of the latter approach is that programs monitoring the system status can see the idle task along with all other tasks; an example is Windows NT's System idle process.
<p>
On modern processors, where a HLT (halt) instruction saves significant amounts of power and heat, the idle task almost always consists of a loop which repeatedly executes HLT instructions. However, on older computers, where temperature dissipation was almost constant with CPU load, the program would often do useless things, like blink the front panel lights in an amusing or recognizable pattern.
</p>
<p>
Often, this had the effect on timeshared systems that if one was lucky enough to have access to the computer room, one could glance at the front panel lights to see how busy the machine was. If the idle pattern very rarely showed up, the machine was heavily loaded, and one might go for lunch before waiting for a job to finish; on the other hand, if it was clearly blinking the idle pattern, one might run the job immediately.
</p>
<p>
In Unix-like operating systems such as Linux, the idle task has process ID zero, and never exits. Another specially distinguished task on Unix-like operating systems is the init process, which does little more than wait around for its child processes to die.
</p>
</blockquote>
<p>
In other words, if the idle task is "chewing up 95 percent of the processor's cycles", that's normal: it simply means your CPU isn't working very hard on anything at the moment.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-is-the-system-idle-process-hogging-all-the-resources/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Computer Hardware Pornography ]]></title>
<link>https://blog.codinghorror.com/computer-hardware-pornography/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've never understood programmers who loved the craft of programming, but were disinterested in the underlying hardware -- the very tool that allows them to practice their craft. I have an unabashed love for computer hardware that borders on inappropriate. I'm not ashamed to admit it.
</p>
<p>
<font color="red">Warning: this post appeals to prurient interests-- <i>in computer hardware</i></font>.
</p>
<p>
If, like me, you love the hardware as much as the software, you're in for a rare treat. I have three books you'll definitely want to have delivered in an unmarked brown wrapper.
</p>
<p>
In collaboration with the <a href="http://www.computerhistory.org/">Computer History Museum</a> in Mountain View, California, the book <a href="http://www.amazon.com/exec/obidos/ASIN/0811854426/codihorr-20">Core Memory: A Visual Survey of Vintage Computers</a> was recently released. I picked up a signed copy at the <a href="http://makerfaire.com/">Maker Faire</a> a week ago.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0811854426/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Core Memory is a virtual tour of the <a href="http://www.computerhistory.org/virtualvisiblestorage/">amazing visual storage area</a> of the Computer History Museum. If you live <a href="http://www.computerhistory.org/about/directions/">in the area</a>, and have any interest whatsoever in computers, <i>visit this museum</i>. It's awe inspiring-- any computer you can think of is probably represented there. Some of them have been painstakingly refurbished to functioning status, and they do demonstrations periodically. That's how I had the privilege of playing <a href="http://en.wikipedia.org/wiki/Spacewar!">Spacewar</a> on the original vector display of <a href="http://www.computerhistory.org/pdp-1/">the only known functioning PDP-1 in the world</a>. If you can't make it to the museum, this book is the next best thing to being there.
</p>
<p>
Robert Scoble <a href="http://scobleizer.com/2007/05/15/cool-photo-book-of-computer-history/">recorded a short video</a> of the photographer, Mark Richards, touring the visual storage area and talking about the two year gestation of the book. You can get a preview of the magnificent photography in the book at <a href="http://www.markrichardsphotography.com/main.php">Mark Richards' website</a>. Boing Boing called them <i>magnificent portraits of the machines' pretty faces and equally beautiful guts, a stunning series of "glamour shots" for nerds.</i> Unfortunately, I can't link directly to the photo section; you'll have to manually <a href="http://www.markrichardsphotography.com/main.php">navigate to the main menu</a> and select Book: "Core Memory".
</p>
<p>
Along the same lines, Mark Frauenfelder's book <a href="http://www.amazon.com/exec/obidos/ASIN/1847320139/codihorr-20">The Computer: An Illustrated History</a> explores the complete history of computing in pictorial style, beginning with the abacus and going all the way to the Aibo and iPod.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/1847320139/codihorr-20"><img alt="image placeholder" >
</p>
<p>
It's a broader overview of the computer as a fixture of human culture, filled with similarly amazing photographs. It's a fine companion that fills the gaps in Core Memory nicely. This <a href="http://www.arsgeek.com/?p=1320">book review at ArsGeek</a> provides a chapter summary and some additional commentary.
</p>
<p>
Both of these books focus on computers, although there's a brief chapter on game consoles in The Computer. If you're more interested in the entertainment side of computer hardware, you'll definitely want the German import <a href="http://www.amazon.com/exec/obidos/ASIN/3000153594/codihorr-20">The Encyclopedia of Game Machines</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/3000153594/codihorr-20"><img alt="image placeholder" >
</p>
<p>
It's an absurdly exhaustive reference of every game console-- and every computer that was used for gaming-- ever released. Although the book has a slightly European bent, it truly justifies the title "encyclopedia". If you played games on it, know anyone who played games on it, or just read about other people playing games on it, it's featured in this excellent book along with relevant statistics, a summary, and of course a rich set of high resolution photographs. You can view sample pages in the <a href="http://www.retroblast.com/reviews/gameplanencyclopedia.html">retroblast review</a>.
</p>
<p>
As for me, I own all three books, and I recommend them highly. It's the only way to satisfy my insatiable hardware lust, short of the world's largest bank account. Now if you'll excuse me, I need some "alone time" to go read through them.. again. I'm sure you understand.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/computer-hardware-pornography/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Let's Build a Grid ]]></title>
<link>https://blog.codinghorror.com/lets-build-a-grid/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Khoi Vinh, the design director for the New York Times, <b>explains how essential grids are to web design</b> in his SXSW presentation with Mark Boulton, <a href="http://www.subtraction.com/archives/2007/0318_oh_yeeaahh.php">Grids Are Good (Right?)</a>.
</p>
<p>
So much web design work relies on establishing a grid and the constraints on that grid: ad sizes, display size, browser display area minus chrome, and so forth. Grids are, quite literally, everywhere. But learning how to effectively utilize grids-- without becoming a slave to them-- can make the difference between a competent layout and a great layout.
</p>
<p>
The case study in <a href="http://www.subtraction.com/pics/0703/grids_are_good.pdf">the presentation</a> (pdf) is Yahoo!, which offers <i>"rudimentary but unimaginative use of grid"</i>. The redesign, Yeeaahh!, offers a more flexible and interesting grid alignment that feels less like a &lt;table&gt; tag writ large.
</p>
<p>
</p>
<table>
<tr>
<td valign="top"><a href="http://www.yahoo.com"><img alt="image placeholder" >
<td valign="top">
<a href="http://yeeaahh.subtraction.com/"><img alt="image placeholder" >
</td>
</tr>
</table>
<p>
The point wasn't to improve on Yahoo's design. The idea was to <b>use the redesign to illustrate the various methods and principles that experienced designers use in grid layouts</b>. Can you see the grid at work on this redesigned page?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
How about now?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Learning to <i>see</i> the grids is the first step. The presentation slides are quite instructive; you can <a href="http://www.subtraction.com/pics/0703/grids_are_good.pdf">download the slides</a> (8mb pdf) directly from Khoi's site.
</p>
<p>
The grid pictured above is an advanced scenario, created by and for expert designers. But <a href="http://intensivstation.ch/en/templates/">basic CSS grid layouts</a> are a fairly <a href="http://www.codinghorror.com/blog/archives/000474.html">well understood science by now</a>. They offer a cookbook of layouts for neophyte designers to choose from.
</p>
<p>
<a href="http://intensivstation.ch/en/templates/"><img alt="image placeholder" >
</p>
<p>
When you're not sure where to begin with your UI design, <b>start by building a grid</b>. But grids don't have to be a straitjacket. Approached with the proper mindset, they can be liberating. Embracing the constraints of a grid in your design-- and knowing when to break those constraints-- is a crucial skill for designers, both neophyte and expert.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/lets-build-a-grid/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Best Code is No Code At All ]]></title>
<link>https://blog.codinghorror.com/the-best-code-is-no-code-at-all/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Rich Skrenta writes that <a href="http://www.skrenta.com/2007/05/code_is_our_enemy.html">code is our enemy</a>.
</p>
<p>
</p>
<blockquote>
Code is bad. It rots. It requires periodic maintenance. It has bugs that need to be found. New features mean old code has to be adapted. The more code you have, the more places there are for bugs to hide. The longer checkouts or compiles take. The longer it takes a new employee to make sense of your system. If you have to refactor there’s more stuff to move around.
<p>
Code is produced by engineers. To make more code requires more engineers. Engineers have n^2 communication costs, and all that code they add to the system, while expanding its capability, also increases a whole basket of costs. You should do whatever possible to increase the productivity of individual programmers in terms of the expressive power of the code they write. Less code to do the same thing (and possibly better). Less programmers to hire. Less organizational communication costs.
</p>
</blockquote>
<p>
Rich hints at it here, but the real problem isn’t the code. The code, like a newborn babe, is blameless and innocent the minute it is written into the world. Code isn’t our enemy. You want to see the real enemy? Go look in the mirror. There’s your problem, right there.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>As a software developer, you are your own worst enemy. The sooner you realize that, the better off you’ll be.</b>
</p>
<p>
I know you have the best of intentions. We all do. We’re software developers; we love writing code. It’s what we do. We never met a problem we couldn’t solve with some duct tape, a jury-rigged coat hanger, and a pinch of code. But Wil Shipley argues that we should <a href="http://wilshipley.com/blog/2007/05/pimp-my-code-part-14-be-inflexible.html">rein in our natural tendencies to write lots of code</a>:
</p>
<p>
</p>
<blockquote>
The fundamental nature of coding is that our task, as programmers, is to recognize that every decision we make is a trade-off. To be a master programmer is to understand the nature of these trade-offs, and be conscious of them in everything we write.
<p>
In coding, you have many dimensions in which you can rate code:
</p>
<p>
</p>
<ul>
<li>Brevity of code</li>
<li>Featurefulness</li>
<li>Speed of execution</li>
<li>Time spent coding</li>
<li>Robustness</li>
<li>Flexibility</li>
</ul>
<p>
Now, remember, these dimensions are all in opposition to one another. You can spend three days writing a routine which is really beautiful <i>and</i> fast, so you’ve gotten two of your dimensions up, but you’ve spent <i>three days</i>, so the "time spent coding" dimension is <i>way</i> down.
</p>
<p>
So, when is this worth it? How do we make these decisions? The answer turns out to be very sane, very simple, and also the one nobody, ever, listens to: <b>Start with brevity. Increase the other dimensions as required by testing.</b>
</p>
</blockquote>
<p>
I couldn’t agree more. I’ve given similar advice when I <a href="https://blog.codinghorror.com/code-smaller/">exhorted developers to Code Smaller</a>. And I’m not talking about a <a href="http://en.wikipedia.org/wiki/Reductio_ad_absurdum">reductio ad absurdum</a> contest where we use up all the clever tricks in our books to make the code fit into less physical space. <b>I’m talking about practical, sensible strategies to reduce the volume of code an individual programmer has to read to understand how a program works.</b> Here’s a trivial little example of what I’m talking about:
</p>
<p>
</p>
<pre>
if (s == String.Empty)
if (s == "")
</pre>
<p>
It seems obvious to me that the latter case is better because it’s just plain <i>smaller</i>. And yet I’m virtually guaranteed to encounter developers who will fight me, almost <a href="https://blog.codinghorror.com/are-you-there-god-its-me-microsoft/">literally to the death</a>, because they’re absolutely convinced that the verbosity of <code>String.Empty</code> is somehow friendlier to the compiler. As if I care about that. As if <i>anyone</i> cared about that!
</p>
<p>
It’s painful for most software developers to acknowledge this, because they love code so much, but <b>the best code is no code at all</b>. Every new line of code you willingly bring into the world is code that has to be debugged, code that has to be read and understood, code that has to be supported. Every time you write new code, you should do so reluctantly, under duress, because you completely exhausted all your other options. Code is only our enemy because there are so many of us programmers writing so damn much of it. If you <i>can’t</i> get away with no code, the next best thing is to <b>start with brevity</b>.
</p>
<p>
If you love writing code — really, truly <i>love to write code</i> — you’ll love it enough to write as little of it as possible.
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2007-05-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-best-code-is-no-code-at-all/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Gates and Jobs, Then and Now ]]></title>
<link>https://blog.codinghorror.com/gates-and-jobs-then-and-now/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you didn't get a chance to watch <a href="http://www.msnbc.msn.com/id/18970439/site/newsweek/">today's historic interview between Bill Gates and Steve Jobs</a>, you should. Finally seeing these two computer industry giants on stage interacting with each other was fascinating and at times even a little touching.
</p>
<p>
</p>
<ul>
<li><a href="http://d5.allthingsd.com/20070530/video-steve-jobs-and-bill-gates-prologue/">Steve Jobs and Bill Gates Prologue</a></li>
<li><a href="http://d5.allthingsd.com/20070530/steve-jobs-and-bill-gates-together-part-1-of-7/">Steve Jobs and Bill Gates Part 1</a></li>
<li><a href="http://d5.allthingsd.com/20070531/video-steve-jobs-and-bill-gates-together-part-2-of-7/">Steve Jobs and Bill Gates Part 2</a></li>
<li><a href="http://d5.allthingsd.com/20070531/video-steve-jobs-and-bill-gates-together-part-3-of-7/">Steve Jobs and Bill Gates Part 3</a></li>
<li><a href="http://d5.allthingsd.com/20070531/video-steve-jobs-and-bill-gates-together-part-4-of-7/">Steve Jobs and Bill Gates Part 4</a></li>
<li><a href="http://d5.allthingsd.com/20070531/video-steve-jobs-and-bill-gates-together-part-5-of-7/">Steve Jobs and Bill Gates Part 5</a></li>
<li><a href="http://d5.allthingsd.com/20070531/video-steve-jobs-and-bill-gates-together-part-6-of-7/">Steve Jobs and Bill Gates Part 6</a></li>
<li><a href="http://d5.allthingsd.com/20070531/video-steve-jobs-and-bill-gates-together-part-7-of-7/">Steve Jobs and Bill Gates Part 7</a></li>
<li><a href="http://d5.allthingsd.com/20070531/video-steve-jobs-and-bill-gates-highlight-reel/">Steve Jobs and Bill Gates Highlight Reel</a></li>
<li><a href="http://d5.allthingsd.com/20070531/d5-gates-jobs-transcript/">Steve Jobs and Bill Gates Session Transcript</a></li>
</ul>
<p>
To put some context on today's meeting, watch this highlight reel of <a href="http://d5.allthingsd.com/20070530/video-steve-jobs-and-bill-gates-prologue/">Steve Jobs and Bill Gates in 1983 and 1997</a>. It's hard to believe, but <b>the last time these two guys were on stage together was in 1983 for the "Macintosh Dating Game".</b> That's why today's interview was so notable-- historic, even.
</p>
<p>
It's clear that these two long-term rivals have a lot of respect for each other. They might even be <i>friends</i>. They've certainly been through a lot together in the last thirty years.
</p>
<p>
</p>
<blockquote>
<b>Bill Gates</b>: It's been fun to work together. I actually kind of miss some of the people who aren't around anymore. You know, people come and go in this industry. It's nice when somebody sticks around and they have some context of all the things that have worked and not worked. The industry gets all crazy about some new thing, you know, like, there's always this paradigm of the company that's successful is going to go away and stuff like that. It's nice to have people seeing the waves and waves of that and yet, when it counted, to take the risk to bring in something new.
<p>
<b>Steve Jobs</b>: You know, when Bill and I first met each other and worked together in the early days, generally, we were both the youngest guys in the room, right? Individually or together. I'm about six months older than he is, but roughly the same age. And now when we're working at our respective companies, I don't know about you, but I'm the oldest guy in the room most of the time. And that's why I love being here. And, you know, I think of most things in life as either a Bob Dylan or a Beatles song, but there's that one line in that one Beatles song, "you and I have memories longer than the road that stretches out ahead." And that's clearly true here.
</p>
</blockquote>
<p>
In a way, I feel like I've been tagging along with Gates and Jobs throughout their storied history, through the ups and downs, through the ebb and flow of the computer industry. Their history feels like <i>our</i> history, <i>my</i> history. These two guys have been my role models since the day I first booted a computer. Everyone I know has owned an Apple computer, or run Microsoft software-- or both-- at some point in their lives. It's unavoidable. I <a href="http://www.codinghorror.com/blog/archives/000718.html">grew up with the microcomputer</a>, and <b>the microcomputer as we know it today is largely due to the influence of both Jobs and Gates</b>.
</p>
<p>
Respect.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-05-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/gates-and-jobs-then-and-now/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Background Compilation and Background Spell Checking ]]></title>
<link>https://blog.codinghorror.com/background-compilation-and-background-spell-checking/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Dennis Forbes took issue with my recent post on <a href="http://www.codinghorror.com/blog/archives/000860.html">C# and the Compilation Tax</a>, offering this criticism, pointedly titled <a href="http://www.yafla.com/dforbes/2007/05/16.html">"Beginners and Hacks"</a>:
</p>
<p>
</p>
<blockquote>
Sometimes [background compilation and edit and continue] are there to coddle a beginner, carefully keeping them within the painted lines and away from the dangerous electrical sockets along the wall. That would explain why it was a more important feature in VB.NET than C#...not that VB.NET is any more trivial -- it's just a syntactic variant -- but it is the language that beginner programmers are generally guided into.
<p>
My experience has been that the best developers naturally start using less and less "helpers", to the extreme where you have incontestably great developers like <a href="http://www.xml.com/ldd/chapter/book/ch04.html">Linus Torvalds arguing against fundamental helpers like interactive debuggers</a>.
</p>
<p>
<b>I don't buy the infinite monkeys on an infinite number of keyboards model of software development</b>. I can only envision tools like continuous compilation and edit and continue as the hand-holding of beginners, and the crutch of hacks.
</p>
</blockquote>
<p>
Regardless of whether or not Dennis is buying it, <b>the infinite monkey software development model is what we're stuck with</b>. I'm an advocate of designing practical systems that accommodate <a href="http://www.newtechusa.com/ppi/talent.asp">what actually happens in the real world</a>-- rather than the way we <i>wish</i> things worked. The present model of software development is clearly <a href="http://en.wikipedia.org/wiki/Turtles_all_the_way_down">monkeys all the way down</a>. And if you're offended to be lumped in with the infinite monkey brigade, I'd say that's <i>incontestable</i> proof that you're one of us.
</p>
<p>
For every one Linus Torvalds, there are <a href="http://www.codinghorror.com/blog/archives/000072.html">ten thousand programmers who aren't Linus Torvalds</a>. I don't expect this ratio to change any time soon, so any effort directed at helping typical developers with better tooling is a significant advancement in the state of software development. Yes, you could throw <a href="http://en.wikipedia.org/wiki/Emacs">emacs</a> and volumes 1-5 of <a href="http://www-cs-faculty.stanford.edu/~knuth/taocp.html">The Art of Programming</a> at your development team. Or you can buy them the best, most advanced development tools on the market. Which approach do you think will be more effective?
</p>
<p>
Ian Griffiths expressed his discontent with background compilation in <a href="http://www.interact-sw.co.uk/iangblog/2007/05/15/language-choice">a completely different way</a>:
</p>
<p>
</p>
<blockquote>
I hate VB.NET's continuous bloody interference. I HADN'T FINISHED TYPING YET YOU STUPID COMPILER! CAN'T YOU SEE THAT? DOES IT LOOK TO YOU LIKE I'M DONE TYPING? DID IT NOT OCCUR TO YOU THAT THE REASON YOU'VE FOUND ALL THOSE ERRORS IS BECAUSE I'M NOT FINISHED YET?!! I'LL TELL YOU WHEN I WANT YOU TO CHECK MY WORK, AND NOT BEFORE!
<p>
There. I feel better now.
</p>
<p>
Yes, I'm sure rebuilding my C# applications every other keystroke, as Jeff apparently feels compelled to do, would have a negative effect on my productivity. How could it be otherwise when VB.NET's less than helpful attempts to do that automatically are so very distracting? <a href="http://www.codinghorror.com/blog/archives/000424.html">"It looks like you're writing a program. Would you like help?"</a> Oddly enough, I don't feel the need to disrupt my train of thought continuously. So I would prefer it if VB.NET didn't disrupt me automatically.
</p>
</blockquote>
<p>
I respect the opinions of Dennis and Ian greatly. If you don't have their blogs in your aggregator yet, you should. But I also respectfully disagree with both of them on this topic. If you find background compilation naggy-- or if you think it's strictly for beginners and hacks-- then <b>you must really, <i>really</i> hate background spell checking</b>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
People absolutely <i>adore</i> background spell checking. It's one of those rare "you'll get it from me when you pry it out of my dead, cold hands" features that users will switch applications over. Automatic background red-squiggly-underline spell checking in HTML forms is one of the marquee features of Firefox 2.0. In fact, it's <a href="http://www.mozilla.com/en-US/firefox/features.html#experience">feature number two on the feature page</a>, right under tabbed browsing.
</p>
<p>
<b>I see very little difference between background spell checking and background compilation.</b> To me, they're no-brainers for the same reasons. I'm actually an excellent speller, to the point that I can (and do) work without a spell checker and rarely make mistakes. But having subtle background underlining effects when I've potentially made a spelling mistake is undeniably helpful to me, a self-professed excellent speller. I can ignore it when I know it's wrong and keep on plowing ahead. But more often than not, I've actually made a typo, and I no longer have to methodically read through my writing several times to find it. With background spell checking, all I need to do is quickly scan through the red squiggly underlined text.
</p>
<p>
Mike Pope, a professional writer for Microsoft, also <a href="http://www.mikepope.com/blog/DisplayBlog.aspx?permalink=1753">defends background spelling and grammar checking</a>:
</p>
<p>
</p>
<blockquote>
I use the spell checker and grammar checker in Word all the time. These things are tools for me, ways to help somewhat with the gruntwork of examining every letter of every word of every sentence in all the documents I edit. The spell checker finds words all the time that have been fumbled (often by me as I edit), although it finds many, many more that it thinks are errors but are just fine in context (e.g. lots of technical names). The grammar checker doesn't have as much opportunity to be helpful, but it's good at finding problems like subject-verb agreement when the subject of sentence has been edited but the verb has not.
<p>
But these tools are often looked at askance. As I've noted before (I think), professional editors can be snotty about the grammar checker in particularly, focusing on errors that the checker doesn't find, or constructions that confuse the grammar checker and make it believe it's found an error when there is none. Similarly, virtually everyone has examples where the spell checker has missed words. The spell checker is helpless in the face of their-they're-there confusion, for example.
</p>
</blockquote>
<p>
The funny thing about this debate is that I've lived the zero-tooling lifestyle. It sucks. Here's how I've composed every single blog entry I've ever written: <b>in a fixed-size HTML textbox</b>. In fact, I'm writing in it <i>right now</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Despite my spelling prowess, I've posted many spelling mistakes to this blog. Using the most primitive of tools to compose these blog posts isn't a glorious, sweeping validation of my expertise as a writer. If anything, it's an indication of my idiocy, or at least <b>my unwillingness to let better tools help me be a better writer</b>. It's absolutely nothing to be proud of. In fact, I'm a little ashamed to admit how neanderthal my blog tooling really is.
</p>
<p>
Neither background compilation nor background spell checking are <i>meant</i> to be crutches. Any reasonably competent person knows that tools are never substitutes for critical thinking about what you're writing or coding--  as Mike <a href="http://www.mikepope.com/blog/DisplayBlog.aspx?permalink=1753">so aptly points out</a>:
</p>
<p>
</p>
<blockquote>
Considering all this, the tools are pretty good at what they do. <b>But no matter how good they are, people need to understand the tools' limitations, or for perhaps more fundamentally, the tools are just tools, and they should never have the last say.</b> Don't let that computer boss you around.
</blockquote>
<p>
Intentionally choosing not to use better tools because you're afraid they will become a crutch is, at best, cruel and patronizing. And it's usually a bad business decision to boot. Turn off background compilation-- or background spell checking-- if you must, but <b>background spell checking is on by default in Word and Firefox 2.0</b>. Is it a perfect solution to the spelling problem? No. Far from it. But for the average user, it's an easy, automatic, unobtrusive way to see and correct common spelling errors. And background compilation, as in VB.NET, offers the same benefit for common coding errors.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/background-compilation-and-background-spell-checking/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Removing The Login Barrier ]]></title>
<link>https://blog.codinghorror.com/removing-the-login-barrier/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Dare Obasanjo's May 26th <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=3689274c-91e5-4ab9-bea8-630719932304">thoughts on the facebook platform</a> contained a number of links to the Facebook API documentation. At the time, clicking through to any of the Facebook API links resulted in a login dialog:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It struck me as incredibly odd that I had to login just to look at API documentation. <b>When presented with the login barrier, I did what 99% of all the people who encounter a login barrier do: I turned back.</b> Dare seemed excited about the Facebook API, but I lost interest when confronted with this login screen.
</p>
<p>
Wouldn't you want information about your API disseminated as widely as possible, to as many people as possible? To be fair, Facebook has since rectified this problem. Clicking on the link now takes you <a href="http://developer.facebook.com/">directly to the Facebook API documentation</a> with no login barrier. I'm not so sure the Facebook folks are "brilliant on several levels" if their API documentation was placed behind a login barrier, even if for only a few days.
</p>
<p>
I previously referenced Jan Miksovsky's <a href="http://www.codinghorror.com/blog/archives/000866.html">enumeration of login steps as a type of user interface friction</a>. But in reality, login barriers are far worse than friction-- <b>they're a <i>brick wall</i></b>. Login barriers are a no-win situation for users. What's in it for them? And without sneaking behind the barrier, if only for a moment, how can the user possibly know if your site is worth the hassle of signing up? If you're the <a href="http://www.nytimes.com/">New York Times</a>, maybe you can get away with forcing users to deal with the login barrier before getting to the meat of your website. But <a href="http://www.codinghorror.com/blog/archives/000127.html">most of us will never have that much cheese</a>.
</p>
<p>
Even if you can't avoid an eventual login, it <i>is</i> possible to make the user's login process nearly seamless. Too many sites take a ham-handed, completely traditional approach to logins. <b>You can do much, much better than the abysmal login barrier status quo.</b> Jan doesn't mince any words when he says <a href="http://www.geni.com">Geni</a> has <a href="http://miksovsky.blogs.com/flowstate/2007/06/geni_slickest_t.html">the most inviting initial user experience he's ever seen</a>:
</p>
<p>
</p>
<blockquote>
Right off the bat, you're cleverly dropped into a family tree that's already partially started: there's a place for you, and obvious points to add your parents. No fanfare is needed to introduce the site or explain what it's for. The very nature of the task's UI makes it obvious that you're building a family tree.
<p>
You're asked for an email address, and in the most compact text imaginable, they define the key points of their privacy policy ("never spammed, never shared").
</p>
<p>
It's not advertised to the user at this point that the email address they enter for themselves will become their user ID on the site. This is revealed the first time the user tries to return to the site. At that point -- the second visit -- the user is asked to sign in with their email address and a temporary password that was emailed separately to that address.
</p>
</blockquote>
<p>
It's obvious that Jan has been thinking a lot about this topic; he has a followup post describing <a href="http://miksovsky.blogs.com/flowstate/2007/05/easing_visitors.html">how Netvibes and Pageflakes ease visitors into sites with anonymous accounts</a>:
</p>
<p>
</p>
<blockquote>
<b>These sites both use cookies to establish a tentative, anonymous relationship between you and the site.</b> You can even enter personal data to customize the various widgets, but until you've established an account, you're generally using the service anonymously. (Of course, even without a user ID, each additional piece of data you enter to customize the site can be used to more precisely identify you.)
<p>
You can use your anonymous account for as long as you want to, provided you use the same browser on the same machine to do so. Whenever you reach that point -- maybe even months after starting to use the service -- you can sign up for an account. The basis of your relationship with the site transfers from your anonymous browser cookie to a real account secured with a user ID and a password. (Both these sites use your email address as a user ID, to eliminate the signup hurdle of picking a user ID.)
</p>
<p>
The deep principle at work is that a site doesn't need to rush to secure a relationship with a visitor. Inevitable interest in getting more out of the site (in these cases, the desire to use your customized home page from another location) slowly pushes you, the casual anonymous visitor, to finally forge a permanent relationship with the site as an identified user. The site knows a relationship with you will develop in its own time.
</p>
</blockquote>
<p>
If your application requires users to log in, <b>don't underestimate the impact of the login barrier you're presenting to users</b>. Consider utilizing anonymous, cookie-based accounts to give users a complete experience that more closely resembles the experience that named users get. By removing the login barrier and blurring the line between anonymous users and named users, you're likely to gain a lot more of the latter.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/removing-the-login-barrier/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Ask -- Observe ]]></title>
<link>https://blog.codinghorror.com/dont-ask-observe/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
James Surowiecki, author of <a href="http://www.amazon.com/exec/obidos/ASIN/0385721706/codihorr-20">The Wisdom of Crowds</a>, writes about <a href="http://www.newyorker.com/talk/financial/2007/05/28/070528ta_talk_surowiecki">the paradox of complexity and consumer choice</a> in a recent New Yorker column:
</p>
<p>
</p>
<blockquote>
A recent study by a trio of marketing academics found that when consumers were given a choice of three models, of varying complexity, of a digital device, more than sixty per cent chose the one with the most features. Then, when the subjects were given the chance to customize their product, choosing from twenty-five features, they behaved like kids in a candy store. (Twenty features was the average.) <b>But, when they were asked to use the digital device, so-called "feature fatigue" set in. They became frustrated with the plethora of options they had created, and ended up happier with a simpler product.</b>
</blockquote>
<p>
It's impossible to see that you're creating a frankenstein's monster of a product-- until you attempt to use it. It's what I call <b>the all-you-can-eat buffet problem</b>. There's so much delicious food to choose from at the buffet, and you're so very hungry. Naturally you load up your plate with wild abandon. But after sitting down at the table, you belatedly realize <i>there's no way you could possibly eat all that food</i>.
</p>
<p>
In all fairness, sometimes people do, in fact, want complexity. The <a href="http://blog.outer-court.com/archive/2007-06-04.html#n60">newly redesigned Google Korea homepage</a> is intentionally complex. Google's Marissa Mayer noted <i>"It was important where our classic minimalism wasn't working that we adapt."</i>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This echoes an <a href="http://www.jnd.org/dn.mss/simplicity_is_highly.html">earlier blog post by Donald Norman</a> describing the way South Koreans seek out complexity in luxury goods:
</p>
<p>
</p>
<blockquote>
I recently toured a department store in South Korea. Visiting department stores and the local markets is one of my favorite pastimes whenever I visit a country new to me, the better to get to know the local culture. Foods differ, clothes differ, and in the past, appliances differed: appliances, kitchen utensils, gardening tools, and shop tools.
<p>
I found the traditional "white goods" most interesting: Refrigerators and washing machines. The store obviously had the Korean companies LG and Samsung, but also GE, Braun, and Philips. The Korean products seemed more complex than the non-Korean ones, even though the specifications and prices were essentially identical. "Why?" I asked my two guides, both of whom were usability professionals. "Because Koreans like things to look complex," they responded. It is a symbol: it shows their status.
</p>
</blockquote>
<p>
What's particularly telling in the study Surowiecki cites is the disconnect between what people <i>say</i> they want and what they <i>actually</i> want. You'll find this theme echoed over and over again in usability circles: <b>what users say they will do, and what they actually do, are often two very different things.</b> That's why asking users what they want is nearly useless from a usability perspective; <b>you have to <i>observe what users actually do</i></b>. That's what <a href="http://www.codinghorror.com/blog/archives/000779.html">usability testing</a> is. Instead of asking consumers what features they wanted in a digital camera, the study should have presented them with a few digital camera prototypes and then observed how they were used. Consumers' success or failure interacting with the prototypes tells us more than a thousand surveys, questionnaires, or focus groups ever could. Unfortunately, creating physical prototypes of digital cameras is prohibitively expensive, so it doesn't happen.
</p>
<p>
Prototyping software, which is <a href="http://www.codinghorror.com/blog/archives/000566.html">built out of pure thought-stuff</a>, is a much easier proposition. <a href="http://www.25hoursaday.com/weblog/">Dare Obasanjo</a> recently pointed out a great paper, <a href="http://exp-platform.com/Documents/GuideControlledExperiments.pdf">Practical Guide to Controlled Experiments on the Web</a> (pdf), which makes a strong case for frequent observational A/B usability tests:
</p>
<p>
</p>
<blockquote>
Greg Linden at Amazon created a prototype to show personalized recommendations based on items in a shopping cart. You add an item, recommendations show up; add another item, different recommendations show up. Linden notes that while the prototype looked promising, a marketing senior vice-president was dead set against it, claiming it would distract people from checking out. Greg was forbidden to work on this any further. Nonetheless, Greg ran a controlled experiment, and the feature won by such a wide margin that not having it live was costing Amazon a noticeable chunk of change. With new urgency, shopping cart recommendations launched. Since then, multiple sites have copied cart recommendations.
<p>
The culture of experimentation at Amazon, where data trumps intuition, and a system that made running experiments easy, allowed Amazon to innovate quickly and effectively.
</p>
</blockquote>
<p>
Why <i>ask</i> users if they'd like recommendations in their shopping carts when you can simply deploy the feature to half your users, then <i>observe</i> what happens? Web sites are particularly amenable to this kind of observational testing, because it's easy to collect the user action data on the server as a series of HTTP requests. You don't even have to be physically present to "observe" users this way. However, you can perform the same kind of data analysis, with a little care, even if you're deploying a traditional desktop application. Jensen Harris <a href="http://blogs.msdn.com/jensenh/archive/2005/10/31/487247.aspx">describes how Microsoft collects user action data in Office 2003</a>:
</p>
<p>
</p>
<blockquote>
Suppose you wanted to know what [Office 2000] features people use the most.  Well, you start by asking a "guru" who has worked in the product for a long time.  "Everyone uses AutoText a lot," the guru says.  The louder the "experts" are, the more their opinions count.  Then you move on to the anecdotal evidence: "I was home over Christmas, and I saw my mom using Normal View... that's probably what most beginners use."  And mix in advice from the helpful expert: "most people run multi-monitor, I heard that from the guy at Best Buy."
<p>
SQM, which stands for "Service Quality Monitoring" is our internal name for what became known externally as the <a href="http://www.microsoft.com/products/ceip/en-us/default.mspx">Customer Experience Improvement Program</a>.  It works like this: Office 2003 users have the opportunity to opt-in to the program.  From these people, we collect anonymous, non-traceable data points detailing how the software is used and and on what kind of hardware.  (Of course, no personally identifiable data is collected whatsoever.)
</p>
<p>
As designers, we define data points we're interested in learning about and the software is instrumented to collect that data.  All of the incoming data is then aggregated together on a huge server where people like me use it to help drive decisions.
</p>
<p>
What kind of data do we collect?  We know everything from the frequency of which commands are used to the number of Outlook mail folders you have.  We know which keyboard shortcuts you use.  We know how much time you spend in the Calendar, and we know if you customize your toolbars.  In short, we collect anything we think might be interesting and useful as long as it doesn't compromise a user's privacy.
</p>
</blockquote>
<p>
This may sound eerily like Big Brother, but the SQM merely extends the same level of reporting enjoyed in every single web application ever created to desktop applications.
</p>
<p>
The true power of this data is that you can remotely, silently, automatically "observe" what users actually do in your software. Now you can answer questions like <a href="http://blogs.msdn.com/jensenh/archive/2005/11/07/489864.aspx">what are the top 5 most used commands in Microsoft Word 2003?</a> The answer may surprise you. Do you know what the top 5 most frequently used functions in <i>your</i> application are?
</p>
<p>
Don't get me wrong. I love users. Some of my best friends are users. But like all of us humans, they're unreliable at best. <b>In order to move beyond usability guesswork, there's no substitute for observing customers using your product.</b> Wouldn't it be liberating to be able to make design decisions based on the way your customers actually use your software, rather than the way they tell you they use it? Or the way you <i>think</i> they use it? Whether you're observing users in <a href="http://www.codinghorror.com/blog/archives/000779.html">low-fi usability tests</a>, or collecting user action data so you can observe users virtually, the goal is the same: <b>don't ask -- observe</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-ask-observe/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Designing for Informavores, or, Why Users Behave Like Animals Online ]]></title>
<link>https://blog.codinghorror.com/designing-for-informavores-or-why-users-behave-like-animals-online/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm currently reading through <a href="http://findability.org/">Peter Morville's</a> excellent book <a href="http://www.amazon.com/exec/obidos/ASIN/0596007655/codihorr-20">Ambient Findability</a>. It cites some papers that attempt to explain the search behavior of web users, starting with <b>the berrypicking model</b>:
</p>
<p>
</p>
<blockquote>
In a 1989 article entitled <a href="http://www.gseis.ucla.edu/faculty/bates/berrypicking.html">"The Design of Browsing and Berrypicking Techniques for the Online Search Interface,"</a> Marcia Bates exposed the inadequacy of the classic information retrieval model characterized by a single query.
<p>
Instead, she proposed <b>a berrypicking model that recognizes the iterative and interactive nature of the information seeking process</b>. Bates understood that the query and the information need itself evolve as users interact with documents and search systems. She also recognized that since relevant documents (like berries) tend to be scattered, users move fluidly between search and browse modes, relying on a rich variety of strategies including footnote chasing, area scanning, and citation, subject, and author searching.
</p>
<p>
In short, Bates described information seeking behavior on today's Web, back in 1989. Google relies on the citations we call "inbound links." Blogs support "backward chaining" through trackbacks. Flickr and del.icio.us allow us to pivot on subject or author. The Web allows our information seeking to grow more iterative and interactive with each innovation. The berrypicking model is more relevant today than ever.
</p>
</blockquote>
<p>
Bates' research was picked up by Peter Pirolli and Stuart Card and folded into their 1995 paper titled <a href="http://acm.org/sigchi/chi95/proceedings/papers/ppp_bdy.htm">Information Foraging in Information Access Environments</a>:
</p>
<p>
</p>
<blockquote>
We use the term <b>Information Foraging</b> both to conjure up the metaphor of organisms browsing for sustenance and to indicate a connection to the more technical optimal foraging theory found in biology and anthropology. Animals adapt their behavior and their structure through evolution to survive and reproduce to their circumstance. Animals adapt, among other reasons, to increase their rate of energy intake. To do this they evolve different methods: a wolf hunts ("forages") for prey, but a spider builds a web and allows the prey to come to it. Humans seeking information also adopt different strategies, sometimes with striking parallels to those of animal foragers. The wolf-prey strategy bears some resemblance to classic information retrieval, and the spider-web strategy is like information filtering.
</blockquote>
<p>
So if you've ever wondered why users behave like animals online, now you know. There's real science behind it in <a href="http://en.wikipedia.org/wiki/Information_foraging">information foraging</a>. Instead of hunting for food, users hunt for information, ruthlessly, and without compunction.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In practice, what this means is that users pursue "information scent". <b>Users will click the back button nearly instantly when they don't catch a whiff of the right information from the current page</b>. Jakob Nielsen <a href="http://www.useit.com/alertbox/20030630.html">explains</a>:
</p>
<p>
</p>
<blockquote>
Information foraging's most famous concept is <a href="http://www.useit.com/alertbox/20040802.html">information scent</a>: users estimate a given hunt's likely success from the spoor: assessing whether their path exhibits cues related to the desired outcome. Informavores will keep clicking as long as they sense (to mix metaphors) that they're "getting warmer" -- the scent must keep getting stronger and stronger, or people give up. Progress must seem rapid enough to be worth the predicted effort required to reach the destination.
</blockquote>
<p>
If you think this is all a bunch of trumped-up academic terminology for the basic principle of human laziness, well.. <a href="http://www.useit.com/alertbox/20030630.html">you're right</a>.
</p>
<p>
</p>
<blockquote>
Humans are under less evolutionary pressure to improve their Web use, but basic laziness is a human characteristic that might be survival-related (don't exert yourself unless you have to). <b>In any case, people like to get maximum benefit for minimum effort.</b> That's what makes information foraging a useful tool for analyzing online media.
</blockquote>
<p>
Whether you call it "information foraging" or the rather more honest "maximum benefit for minimum effort", <b>it's a powerful model of the way people actually work online</b>. There are billions of web pages, and only a tiny fraction are worth the users' time. That's why <b>informavores are unforgiving</b>. They will..
</p>
<ul>
<li>Demand to see what you have to offer in <a href="http://news.bbc.co.uk/1/hi/technology/6131668.stm">under four seconds</a>.
</li>
<li>Form a first impression of your site in <a href="http://www.bioedonline.org/news/news.cfm?art=2268">just 50 milliseconds</a>.
</li>
<li>Give up on your site entirely within two minutes of arriving.
</li>
</ul>
<p>
The last point is noted by Nielsen in his new book <a href="http://www.amazon.com/exec/obidos/ASIN/0321350316/codihorr-20">Prioritizing Web Usability</a>:
</p>
<p>
</p>
<blockquote>
In recent years, <a href="http://www.useit.com/alertbox/20040816.html">highly improved search engines have reversed [the idea of "sticky" web sites] by emphasizing quality in their sorting of search results</a>. It is now extremely easy for users to find other good sites. Information foraging predicts that the easier it is to find good patches [of information], the quicker users will leave a patch. Thus, the better search engines get at highlighting quality sites, the less time users will spend on any one site. This theoretical prediction was amply confirmed by the empirical data we collected for this book: <b>People left the sites they found useless within less than two minutes.</b>
</blockquote>
<p>
Frankly, I'm surprised it's a whole two minutes. You better hope the information scent is strong on your page, because Informavores' fingers are always hovering over the back button. And they have <i>very</i> itchy trigger fingers.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/designing-for-informavores-or-why-users-behave-like-animals-online/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Who Killed the Desktop Application? ]]></title>
<link>https://blog.codinghorror.com/who-killed-the-desktop-application/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've sworn by <a href="http://www.microsoft.com/streets/default.mspx">Microsoft Streets and Trips</a> for years, since the late 90's. I make a point of installing the latest version of Microsoft's mapping application all our desktop PCs for all our desktop mapping needs. It's also great on laptop PCs; combined with a USB GPS receiver and a laptop, Streets and Trips is a fine navigational aid on trips. Well, assuming you were going to take the laptop on your trip anyway, which I always do.
</p>
<p>
So I was taken aback when I noticed my wife was using Google Maps on her PC to map something. I asked her why she was using Google Maps instead of our old pal Streets and Trips, and she said, quite matter of factly, "Because it's faster."
</p>
<p>
<i>Because it's faster?</i>
</p>
<p>
I tested it myself, and she's right. It takes about 9 seconds to launch Streets and Trips 2007 on my (very fast) desktop PC, compared to about 3 seconds to load <a href="http://maps.google.com">maps.google.com</a> in the browser. It's a mixed-up, topsy-turvy world we live in when <b>web mapping applications are now faster and more convenient to use than their desktop equivalents</b>. But it's a fact.
</p>
<p>
What's worse, <b>Google maps is easier to use than Streets and Trips, too</b>. Here's the location of the <a href="http://www.dnalounge.com/">DNA Lounge</a>, a club <a href="http://www.wired.com/culture/lifestyle/news/2001/07/45264">owned by old-school Netscape engineer Jamie Zawinski</a>, mapped in Streets and Trips.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's how I get directions to the club using Streets and Trips:
</p>
<p>
</p>
<ol>
<li>Right-click the pushpin
</li>
<li>Click Route, add as End
</li>
<li>Navigate to the address entry bar on the toolbar
</li>
<li>Type my home address and press Enter
</li>
<li>Right-click the new pushpin
</li>
<li>Select Route, add as Beginning
</li>
<li>Click the car icon on the toolbar to bring up the route planner sidebar
</li>
<li>Click the Get Directions button
</li>
</ol>
<p>
It's an incredible amount of work for what is probably one of the most frequent use cases for mapping software-- getting directions from point A to point B. Let's compare the same task in Google Maps. We're already up 6 seconds since the browser-based app loads in 1/3 the time of the desktop application.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Here's how I get directions to the club using Google Maps:
</p>
<p>
</p>
<ol>
<li>Click the "To here" link
</li>
<li>Type my home address and press Enter
</li>
</ol>
<p>
There's no reason Streets and Trips couldn't adopt the same conventions as Google Maps. But Streets and Trips seems to be completely stuck in the old world mentality of toolbars, menus, and right-clicking. <b>All the innovation in user interface seems to be taking place on the web, and desktop applications just aren't keeping up.</b> Web applications are evolving online at a frenetic pace, while most desktop applications are mired in circa-1999 desktop user interface conventions, plopping out yearly releases with barely noticeable new features.
</p>
<p>
This should be an unfair comparison. Streets and Trips is free to harness the complete power of the desktop PC, whereas Google Maps is limited to web browser scripting and HTTP calls to the server. Google Maps turns all those browser-based application weaknesses into strengths, by offering a bunch of online-enabled features that Streets and Trips doesn't: satellite view, real-time traffic data, and the new street view. Plus it's always up to date; we're guaranteed to be using the latest version with the newest features. And unlike Streets and Trips, it's free-- or at least ad-subsidized.
</p>
<p>
Streets and Trips will still be helpful in one very specific situation: disconnected use with a laptop and/or a GPS. But in every other case, Google Maps is superior. It's faster, it's simpler to use, and it has more features. It's hard not to look at the facts and <b>conclude that desktop applications-- at least desktop <i>mapping</i> applications-- are dead.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/who-killed-the-desktop-application/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's Wrong With Apple's Font Rendering? ]]></title>
<link>https://blog.codinghorror.com/whats-wrong-with-apples-font-rendering/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I had read a few complaints that <a href="http://www.agileprogrammer.com/dotnetguy/archive/2006/06/03/15617.aspx">OS X font rendering was a little wonky</a>, even from <a href="http://www.joelonsoftware.com/items/2006/09/11.html">Joel Spolsky himself</a>:</p>
<blockquote>OS X antialiasing, especially, it seems, with the monospaced fonts, just isn't as good as Windows ClearType. Apple has some room to improve in this area; the fonts were blurry on the edges.</blockquote>
<p>I didn't believe it until I downloaded the first beta of Safari 3 for Windows and saw it for myself.</p>
<p>Font rendering in <a href="http://www.apple.com/safari/">Safari 3 Beta</a>:</p>
<p><img alt="image placeholder" >
<p>Font rendering in <a href="http://www.microsoft.com/windows/ie/default.asp">Internet Explorer 7</a>:</p>
<p><img alt="image placeholder" >
<p>All of these screenshots were taken under Windows Vista. It's easier to see what's happening if we zoom in a bit. These images are zoomed 200% with exact per-pixel resizing. Safari on the top, IE7 on the bottom:</p>
<p>
<img alt="image placeholder" >
<br>
<img alt="image placeholder" >
</p>
<p>At first I wasn't even sure if Apple was using <a href="http://www.microsoft.com/typography/ClearTypeInfo.mspx">ClearType</a>-alike RGB anti-aliasing, but it's clear from the zoomed image that they are. <strong>It looks like they've skewed the contrast of the fonts to an absurdly low level.</strong> The <a href="http://www.microsoft.com/typography/ClearTypePowerToy.mspx">ClearType Tuner PowerToy</a> allows you to manually adjust the RGB font aliasing contrast level, as I <a href="http://www.codinghorror.com/blog/archives/000651.html">documented in an earlier blog post</a>, but I don't think it can go as low as Apple has it set.</p>
<p><strong>I am absolutely not trying to start an <a href="http://www.codinghorror.com/blog/archives/000796.html">OS X versus Windows flame war</a> here</strong>. I used the quote above for a reason: there really is no single best way to render fonts; results depend on your display, the particular font you're using, and many other factors. That said, I'm curious why Apple's default font rendering strategies, <em>to my eye</em> -- and to the eyes of at least two other people -- are visibly inferior to Microsoft's on typical LCD displays. This is exactly the kind of graphic designer-ish detail I'd expect Cupertino to get right, so it's all the more surprising to me that they apparently haven't.</p>
<p><strong><span style="color: red;">Update:</span></strong> I have a <a href="http://www.codinghorror.com/blog/archives/000885.html">followup post</a> that explains the font rendering difference. It looks like neither Apple or Microsoft is wrong; it's a question of whether you <a href="http://www.codinghorror.com/blog/archives/000885.html">respect the pixel grid</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-wrong-with-apples-font-rendering/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Font Rendering: Respecting The Pixel Grid ]]></title>
<link>https://blog.codinghorror.com/font-rendering-respecting-the-pixel-grid/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've finally determined <a href="http://www.codinghorror.com/blog/archives/000884.html">What's Wrong With Apple's Font Rendering</a>. As it turns out, there actually <i>wasn't</i> anything wrong with Apple's font rendering, per se. Apple simply chose a different font rendering philosophy, <a href="http://www.joelonsoftware.com/items/2007/06/12.html">as Joel Spolsky explains</a>:
</p>
<p>
</p>
<blockquote>
<b>Apple</b> generally believes that the goal of the algorithm should be to preserve the design of the typeface as much as possible, even at the cost of a little bit of blurriness.
<p>
<b>Microsoft</b> generally believes that the shape of each letter should be hammered into pixel boundaries to prevent blur and improve readability, even at the cost of not being true to the typeface.
</p>
</blockquote>
<p>
So we answer the question with another question. <b>What do you respect more: the pixel grid, or the font designer?</b> It's not surprising that Apple would side with the font designer, because <a href="http://www.codinghorror.com/blog/archives/000769.html">Steve Jobs thinks Microsoft has no taste</a>. But me, I'm a pragmatist. Given the ubiquity of relatively low DPI displays, <a href="http://mezzoblue.com/archives/2007/06/12/a_subpixel_s/">I'm with Dave Shea</a>. I side with the pixel grid.
</p>
<p>
</p>
<blockquote>
Joel talks about the pixel grid, and how Microsoft's type rendering pays more attention to it. Speaking as someone who <a href="http://www.mezzoblue.com/icons/chalkwork/">thinks a lot</a> about <a href="http://mezzoblue.com/archives/2007/02/21/icon_design/">the pixel grid</a>, I have to say I think I'm coming around to the idea that Microsoft's ClearType simply works better.
<p>
Alright, I'd better qualify that quickly. Think about it this way – as a designer, you don't just set type in Photoshop and let it go, right? You tweak. You kern. You attempt to <a href="http://www.mezzoblue.com/archives/2004/01/18/type_the_ex/">match the letters to the pixel grid</a> as closely as possible to reduce the blurriness. Sometimes spacing suffers, and you have to choose between a slightly blurry letter with perfect spacing, or a more precise fit within the pixel grid with just slightly off spacing. I can't be the only one that leans toward the latter most times.
</p>
<p>
And that's the difference here. ClearType is a closer match to what I do manually already. Yes, I prefer the way type on OS X looks; ClearType seems too sharp and overly blocky, the subtleties of the curves are lost and it's overly chunky. But, for the medium in which it's being rendered, it seems like a more ideal solution.
</p>
</blockquote>
<p>
Dave's opinion carries a lot of weight here, not just because he's <a href="http://mezzoblue.com">a well-known designer</a>, but because the three citations he provides demonstrate just how common it is for designers to do exactly the kind of manual, per-pixel tweaks that ClearType does for us automatically. And it's not just an aesthetic choice, either – there's plenty of hard data to support the assertion that <a href="http://blogs.msdn.com/fontblog/archive/2005/12/13/503236.aspx">snapping fonts to the pixel grid improves reading accuracy</a>.
</p>
<p>
A fascinating greyscale-only variant of this rendering techique, <a href="http://web.archive.org/web/20070706034446/http://artofcode.com/fontfocus/">FontFocus</a>, illustrates beautifully how subtle tweaks can "snap" fonts to the pixel grid for better readability:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Typography, if you haven't figured this out by now, is really complicated. It's one of the few areas of "computer science" that actually <a href="http://www.microsoft.com/typography/ctfonts/WordRecognition.aspx">justifies the title</a>. I highly recommend reading <a href="http://web.archive.org/web/20070706034446/http://artofcode.com/fontfocus/">the entire FontFocus article</a>, as it's very instructive.
</p>
<p>
Dave Shea thinks <b>the pixel grid will be moot once high resolution displays become ubiquitious</b>. I wholeheartedly agree, although I'm unsure when exactly that will be. The history of display resolution increases have been quite modest so far. Ten years ago I was using a single 17" 1024x768 display; now I'm using three 20" 1600x1200 displays. So you'll forgive me if I'm not overly optimistic about this theoretical jump from 100 DPI to 200 DPI.
</p>
<p>
I don't understand why Apple is asking us to sacrifice the present at the altar of the future. <b>Can't we have hinting at low resolutions, and accuracy at high resolutions, too?</b> Snapping fonts to a pixel grid may very well be irrelevant when everyone is luxuriating in the glow of their 200 DPI monitors. Until that glorious day arrives, respecting the pixel grid certainly makes text a lot more readable for those of us stuck in the here and now.
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2007-06-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/font-rendering-respecting-the-pixel-grid/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Where Are The High Resolution Displays? ]]></title>
<link>https://blog.codinghorror.com/where-are-the-high-resolution-displays/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In a recent post, Dave Shea documented <a href="http://mezzoblue.com/archives/2007/06/12/a_subpixel_s/">his love/hate relationship with the pixel grid</a>:
</p>
<p>
</p>
<blockquote>
Here's the caveat though -- high resolution displays. At 100dpi, ClearType wins out, but we're not going to be stuck here much longer. Give it a few years, let's do this comparison again when 200dpi is standard. I suspect the pixel grid won't matter nearly so much then.
</blockquote>
<p>
I was somewhat curious about Dave's claim that in "a few years" displays with 200 <a href="http://en.wikipedia.org/wiki/Dots_per_inch">DPI</a> will be standard fare. So I did some research to document how far we've come in display resolution over the last twenty years.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td>
<strong>
Year</strong>
</td>
<td>
<strong>
Model</strong>
</td>
<td style="text-align: right">
<strong>
Resolution</strong>
</td>
<td style="text-align: right">
<strong>Size</strong>
</td>
<td style="text-align: right">
<strong>DPI</strong>
</td>
</tr>
<tr>
<td>
1984</td>
<td>
<a href="http://lowendmac.com/compact/128k.shtml">
Original Macintosh</a>
</td>
<td style="text-align: right">
512 x 342</td>
<td style="text-align: right">
9" (8.5")
</td>
<td style="text-align: right">
72</td>
</tr>
<tr>
<td>
1984</td>
<td>
<a href="http://www.old-computers.com/museum/computer.asp?st=1&amp;c=185">IBM PC AT</a>
</td>
<td style="text-align: right">
640 x 350</td>
<td style="text-align: right">
13" (12.3")</td>
<td style="text-align: right">
60</td>
</tr>
<tr>
<td>
1994</td>
<td>
<a href="http://docs.info.apple.com/article.html?artnum=112530">
Apple Multiple Scan 17 Display</a>
</td>
<td style="text-align: right">
1024 x 768</td>
<td style="text-align: right">
17" (16.1")</td>
<td style="text-align: right">
80</td>
</tr>
<tr>
<td>
2004</td>
<td>
<a href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;articleId=94187">
Apple Cinema HD display</a>
</td>
<td style="text-align: right">
2560 x 1600</td>
<td style="text-align: right">
30"</td>
<td style="text-align: right">
100</td>
</tr>
</table>
<p>
I used the <a href="http://www.raydreams.com/prog/dpi.aspx">Tag studios Monitor DPI calculator</a> to arrive at the DPI numbers in the above table. I couldn't quite figure out what the actual displayable area of those early CRT monitors were, so I estimated about 5% non-displayable area based on the diagonal measurement.
</p>
<p>
Regardless, it's sobering to consider that <b>the resolution of computer displays has increased by less than a factor of two over the last <i>twenty years</i>.</b> Sure, displays have gotten larger-- <i>much</i> larger-- but actual <a href="http://en.wikipedia.org/wiki/Display_resolution">display resolution</a> in terms of pixels per inch has only gone up by a factor of about 1.6.
</p>
<p>
I can't think of any other piece of computer hardware that has improved so little since 1984.
</p>
<p>
Some manufacturers do make high resolution displays, but they're far from common, and very few get anywhere close to 200 DPI. Here's one model <a href="http://www.extremetech.com/article2/0,3973,525370,00.asp">ViewSonic was demonstrating in 2002</a>:
</p>
<p>
</p>
<blockquote>
This 22.2-inch LCD panel being sold by Viewsonic uses the same panel developed and marketed by IBM last year (<a href="http://en.wikipedia.org/wiki/IBM_T220/T221_LCD_monitors">T220/T221</a>). The difference is that IBM charged nearly $20,000 for its version; Viewsonic plans on selling this one for around $8,000. That's still pretty pricey -- what makes this panel so special?
<p>
Try 9.2 million pixels, for one thing. This 16x9 aspect panel has a native resolution of 3840x2400 pixels. That translates to roughly 200 dots per inch. In fact, you have to put your nose up to the screen to really notice the pixels. Scanned topographical maps could be easily read, even down to the smallest typeface. The monitor is targeted towards specialized image processing and CAD applications, and offers a 400:1 contrast ratio. Driving 9.2 megapixels requires a graphics card with twin TMDS transmitters.
</p>
</blockquote>
<p>
High pixel density monitors are far outside the mainstream. The large versions are prohibitively expensive; the small versions can't justify their price premium over the lower-resolution competition with larger physical size. It's telling that today, in 2007, the Apple store doesn't even sell a <a href="http://store.apple.com/1-800-MY-APPLE/WebObjects/AppleStore.woa/wa/RSLID?s=priceHL&amp;nnmm=browse&amp;node=home%2Fmac_accessories%2Fdisplays">single standalone LCD</a> offering over 100 DPI. Nor can I find a single high resolution LCD of any type <a href="http://www.newegg.com/Store/SubCategory.aspx?SubCategory=20&amp;name=LCD-Monitors">on newegg</a>. I have no doubt that if I had $10,000 burning a hole in my pocket, I could buy a 200 DPI display <i>somewhere</i>, but at consumer prices and through consumer outlets, high resolution displays simply <i>don't exist</i>.
</p>
<p>
Most of the time, you see high resolution display options on laptops, where <b>the notebook form factor physically precludes the display from getting any larger</b>. Manufacturers are forced to <a href="http://www.raydreams.com/docs/dpi.html">pack more and more pixels into a LCD panel of a fixed size</a>:
</p>
<p>
</p>
<blockquote>
When I purchased my notebook I had a choice of three monitor resolutions - the standard 1200 x 800, 1680 x 1050, and 1920 x 1200. The diagonal screen size is 15.4" giving me the three corresponding pixel densities of 98, 129, and a whopping 147 ppi!
</blockquote>
<p>
It's hard to see this choice of display resolutions as anything other than a side-effect of laptop size restrictions. If notebook vendors could somehow fit a folding 30" LCD panel into a laptop, they absolutely would. But even at 147 DPI, we're only halfway to our goal. <b>To reach 200 DPI, that same 15.4" laptop display would have to pack in 2560 x 1600 pixels</b>. Imagine a 30" Apple Cinema HD display shrunken by half, and you'll get the idea.
</p>
<p>
Short of some kind of miraculous technological breakthrough, <b>I can't see computer displays reaching 200 DPI in "a few years".</b> It's unlikely we'll even get there in <i>ten</i> years. I'd love to be proven wrong, but all the evidence of history-- not to mention typical consumer "bigger is better" behavior-- is overwhelming.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/where-are-the-high-resolution-displays/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Incremental Feature Search in Applications ]]></title>
<link>https://blog.codinghorror.com/incremental-feature-search-in-applications/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm a big fan of <a href="http://www.codinghorror.com/blog/archives/000432.html">incremental search</a>. But incremental search isn't just for navigating large text documents. <b>As applications get larger and more complicated, incremental search is also useful for navigating the sea of features that modern applications offer</b>.
</p>
<p>
Office 2007's design overhaul is arguably one of <a href="http://www.codinghorror.com/blog/archives/000724.html">the most significant innovations in GUI applications since the invention of menus and toolbars</a>:
</p>
<p>
</p>
<blockquote>
Of course, as you know if you've read <a href="http://blogs.msdn.com/jensenh/archive/2006/03/28/563007.aspx">Part 1 of the story</a>, many of today's UI paradigms attributed to Apple were introduced well before the Lisa or the Macintosh. Regardless of who gets credit for them, they're good paradigms. There's nothing wrong with menus and toolbars-based UI for certain applications. Truth be told, these paradigms served Office well for a number of releases.
<p>
It's not that menus and toolbars are bad or that the people who created them weren't smart. The problem is that Office has outgrown them. <b>There's a point beyond which menus and toolbars cease to scale well. A flat menu with 8 well-organized commands on it works just great; a three-level hierarchical menu containing 35 loosely-related commands can be a bit of a disaster.</b>
</p>
<p>
In short, we're not trying to destroy anything. Our goal is to create a new standard user interface for full-featured productivity applications. The original team who built Word or Excel couldn't have imagined how much their products would be able to do today. I want us to step back, to think through the question: "what kind of interface would they have built knowing how Word turned out?"
</p>
</blockquote>
<p>
It's absolutely true that <a href="http://www.codinghorror.com/blog/archives/000558.html">menus and toolbars don't scale</a>. The Office 2007 ribbon takes cues from web design to make navigating the thousands of features in Word, Excel, and Powerpoint much easier. But the ribbon, although it's a <i>major</i> improvement over menus and toolbars, isn't perfect, either:
</p>
<p>
</p>
<blockquote>
I was working with Excel all day yesterday, trying to find a command I know existed in Excel 2003 and can be found quite easily. I was clicking every tab and hovering over all the buttons. I must have gone through the Ribbon at least 5 times. In the end, the stupid command wasn't even in the ribbon to begin with. You had to manually add it to the "Quick Access Toolbar". If I had "Scout", I could have saved at least the frustration of not being able to find a tool that I know is there, not to mention the time and effort wasted.
</blockquote>
<p>
I know a <a href="http://blogs.vertigo.com/personal/swarren/Blog/default.aspx">star developer</a> who is expert at Word, and the same exact thing happened to her. <b>How do you find what isn't in the ribbon?</b> Well, you could use incremental search to find it. Microsoft has an experimental beta of <a href="http://www.istartedsomething.com/20070124/scout-office-2007/">an incremental ribbon search feature for Office 2007, codenamed "Scout"</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Unfortunately, it looks like <a href="http://www.istartedsomething.com/20070203/saving-scout/">internal politics at Microsoft may have killed the ribbon search add-in</a>, which is a shame. A search feature doesn't take anything away from the ribbon. They serve two different audiences, and complement each other perfectly. I'm with Long Zheng: <a href="http://www.istartedsomething.com/20070203/saving-scout/">the ribbon search feature should be shipped as a PowerToy</a>.
</p>
<p>
The first time I saw an application use an incremental feature searching technique was back in 2004. The <a href="http://www.codinghorror.com/blog/archives/000467.html">options dialog for Quest's Toad database utility</a> became so complex that it required a search function to find anything in it. At the time, I wasn't too keen on the idea of an options dialog that complicated, but I have since bowed to its inevitability. Applications get more feature-rich over time, and navigation methods have to evolve to keep up.
</p>
<p>
You probably already know that <a href="http://www.codinghorror.com/blog/archives/000766.html">Vista's revamped start menu</a> takes advantage of incremental searching. But other Microsoft applications are starting to adopt this paradigm as well. Take <a href="http://www.microsoft.com/expression/">Microsoft's new Expression design tools</a>, for example. In most development tools, you're facing down enormous lists of properties all the time. How do you find the particular property you're looking for? You guessed it: <b>incremental search</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In the above screenshot, I'm filtering the properties for a Windows Presentation Foundation button by typing "ind" in the properties search field. Note how the interface dynamically filters, showing only button properties that match what I've typed as I type it. Isn't that much faster than scrolling through a list?
</p>
<p>
If the evolution of the web has taught us anything, it's that <a href="http://www.codinghorror.com/blog/archives/000595.html">search inevitably becomes the dominant navigation metaphor</a>. Simple applications may be able to get away with menus and toolbars, or better yet, a ribbon. But as the application grows larger and more complex, <b>it's faster to incrementally search for the feature we need</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/incremental-feature-search-in-applications/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How to Clean Up a Windows Spyware Infestation ]]></title>
<link>https://blog.codinghorror.com/how-to-clean-up-a-windows-spyware-infestation/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I recently upgraded my <a href="http://blogs.vertigosoftware.com/jatwood/search.aspx?q=vertikart&amp;p=1">dedicated racing simulation PC</a>, so I was forced to re-install Windows XP SP2, along with all the games. As I was downloading the no-cd patches for the <a href="http://www.codinghorror.com/blog/archives/000476.html">various racing sims</a> I own, I was suddenly and inexplicably deluged with popups, icons, and unwanted software installations. I got that sinking feeling: I had become the unfortunate victim of a <b>spyware infestation</b>.
</p>
<p>
Of course, this is <i>completely my own fault</i> for browsing the web using the 2004-era web browser included with a default install of Windows XP Service Pack 2. If I was thinking rationally, I would have downloaded <a href="http://www.mozilla.com/en-US/firefox/">Firefox</a> first, or at least connected to Windows Update to get the latest patches, <i>before</i> venturing on to the open internet. But I figured I'd save myself that work, and just pop into a few specific web sites for a few quick downloads. Couldn't hurt, right? Let my mistake be a lesson to everyone reading this: <b><i>never</i> browse the web without the very latest version of your preferred web browser</b>. Intentionally choosing to browse the web with a three year old browser, as I did, is an incredibly dangerous thing to do.
</p>
<p>
The consequences in this case are fairly minimal since this isn't even my secondary machine-- it's a special-purpose PC dedicated to gaming. Reinstalling the operating system is no big deal. But it's still an inconvenient timesink, and in any case, the spyware infestation has to be dealt with because it causes serious performance problems and will even interrupt gameplay with incessant popups.
</p>
<p>
The two most common sites for no-cd patches are <a href="http://www.megagames.com">MegaGames</a> and GameCopyWorld. In case you're wondering, yes, I do own all my games. I download no-cd patches for convenience's sake; I consider them a privilege of ownership for knowledgeable, ethical PC gamers. I figured the infection came from one of these sites. So I set up a <a href="http://en.wikipedia.org/wiki/Honeypot_%28computing%29">honeypot virtual machine</a> under <a href="http://www.microsoft.com/windows/products/winfamily/virtualpc/default.mspx">Virtual PC 2007</a>, using the ancient, original 2001 release of Windows XP and the classic <a href="http://www.everything2.com/index.pl?node_id=1374161">Devil's Own key</a>, and began testing.
</p>
<p>
Here's a shot of Task Manager at the desktop, after installing the necessary virtual machine additions. This is a completely plain vanilla, clean Windows XP installation: no service packs, no updates, no nothing. This system is connected to the internet, but it's not as dangerous as it sounds. Because it's behind a NAT router that blocks all incoming connections, there's no way it can get <i>passively</i> infected. I let it connect to the internet and quiesce at the desktop for about an hour, just to prove my point. <b>No passive infections occurred behind a NAT router</b>, even for this woefully out of date September 2001 era install of Windows XP.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Now we're leaving passivity behind, and unwisely <b>browsing the open internet with the unpatched, six year old original version of Internet Explorer 6.0</b>. <a href="http://en.wikipedia.org/wiki/Danger,_Will_Robinson">Danger, Will Robinson!</a> I left Task Manager running as I browsed to MegaGames, downloaded a no-cd patch, and... nothing. I then visited GameCopyWorld, downloaded a no-cd patch, and... all of a sudden, it's crystal clear who the culprit is. Check out Task Manager now:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This comes as a shock to me, because GameCopyWorld is recommended often in gaming forums. I consider(ed) it a reputable web site. I've never had a problem with the site before, because I usually surf with the latest updates. But the unpatched browser spyware infestation from visiting GCW-- <b>just from visiting the web pages, even if you don't download a single thing</b>-- is nearly immediate and completely devastating. The virtual machine desktop, after a few scant minutes, tells the story:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It isn't pretty, and let me tell you, <b>I have a new degree of sympathy for the poor users who become the unfortunate victims of spyware infestations</b>. The machine becomes borderline unusable, between...
</p>
<p>
</p>
<ul>
<li>new icons that magically appear on your desktop
</li>
<li>full-screen popups that occur every two minutes
</li>
<li>dialog boxes that offer to "install antivirus software" with only an OK button
</li>
<li>system performance degradation from all those spyware background processes
</li>
</ul>
<p>
... it's a wonder people don't just give up on computing altogether. Once the door is open, it seems the entire neighborhood of malware, spyware, and adware vendors take up residence in your machine. There should be a special circle of hell reserved for companies who make money doing this to people.
</p>
<p>
At first, I was mad at myself for letting this happen. I should know better, and I <i>do</i> know better. Then I channeled that anger into action: <b>this is my machine, and I'll be damned if I will stand for any slimy, unwanted malware, adware, or spyware that takes up residence on it.</b> I resolved to clean up my own machine and fix the mess I made. It's easier than you might think, and I'll show you exactly how I did it.
</p>
<p>
Our first order of business is to <b>stop any spyware that's currently running</b>. You'll need something a bit more heavy-duty than mere Task Manager-- get Sysinternals' <a href="http://www.microsoft.com/technet/sysinternals/utilities/ProcessExplorer.mspx">Process Explorer</a>. Download it, run it, and sort the process list by Company Name.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Kill any processes that don't have a Company Name</b> (with the exception of DPCs, Interrupts, System, and System Idle Process). Right-click the processes and select Kill, or select them and press the Delete key. You can use my initial screenshot of Task Manager, at the top of this post, as a reference for what <i>should</i> be running in a clean Windows XP installation. But there's usually no need to be that specific; unless it has a Company Name you recognize, it's highly likely to be a rogue application and should be terminated.
</p>
<p>
Stopping the running spyware is only half the battle. Now we need to <b>stop the spyware from restarting the next time we boot the system</b>. <a href="http://www.netsquirrel.com/msconfig/">Msconfig</a> is a partial solution, but again we need something more powerful than what is provided out of the box. Namely, SysInternals' <a href="http://www.microsoft.com/technet/sysinternals/Utilities/Autoruns.mspx">AutoRuns utility</a>. Download it, run it, and start browsing through the list that appears:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As you can see, there's a bunch of spyware, malware, adware, and god knows what else gunking up the works-- all from visiting a <i>single</i> website! <b>Scroll through the list, all the way to the bottom, scanning for blank Publishers, or any Publisher you don't recognize. If you see anything that's suspect, delete it!</b> In a default Windows install, 99.5% of the entries will have "Microsoft Corporation" as the Publisher. Any <i>reputable</i> vendor will have no problem attaching their name to their work, so it's generally only the blank entries you need to worry about.
</p>
<p>
Now <b>reboot the system</b>. We've removed most of the spyware infestation, but there's a certain much more virulent class of spyware that can survive this treatment. We'll deal with them next.
</p>
<p>
After rebooting, check Process Explorer and Autoruns for anything suspicious, exactly as we did before. The first thing I noticed that "came back" in Autoruns was a suspicious driver, core.sys, that didn't have a Publisher. I used <b>the powerful Find | Find Handle or DLL menu in Process Explorer</b> to locate any active references to this file.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Unfortunately I didn't capture the right screenshot at the time, so I'm showing a generic search result above. Anyway, there was exactly one open handle to the core.sys file. I selected the result, which highlights the corresponding handle in the lower pane of the Process Explorer view. Right-click the handle entry in the lower pane and click "Close Handle".
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
After I closed the handle, I could physically delete the rogue core.sys file from the filesystem, along with the Autoruns entry for it. Problem solved!
</p>
<p>
The other item that reappeared in Autoruns after the reboot was an <b>oddly named DLL file with hooks into Winlogon and Explorer</b>. In addition to the suspicious name, each entry carries the tell-tale sign of the missing Publisher value:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Delete the entries in Autoruns all you want; they'll keep coming back when you press F5 to refresh. This rogue, randomly named DLL continually monitors to make sure its ugly little hooks are in place. The nasty thing about processes attached to <a href="http://en.wikipedia.org/wiki/Winlogon">Winlogon</a> is that they're very difficult to kill or remove. We can kill Explorer, but <b>killing Winlogon is not an option</b>; it's the root process of Windows, so shutting it down causes the OS to restart. It's a difficult <a href="http://en.wikipedia.org/wiki/Catch-22_(logic)">catch-22</a>.
</p>
<p>
But we're smarter than the malware vendors. Fire up Process Explorer and use the Find | Find Handle or DLL menu to locate all the instances of this DLL by name. (See, I told you this option was powerful.) Kill any open handles to this file that you find, exactly as we did before. But you'll need to go one step further. We know from the Autoruns that this DLL is likely to be attached to the Explorer and Winlogon processes, but let the find results be your guide. Double-click on any processes you found that reference this DLL.  <b>In the process properties dialog, select the Threads tab. Scroll through the threads and kill every one that has the rogue DLL loaded.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Once you've killed all the threads, you can finally delete the entries in Autoruns without them coming back. Reboot, and your machine is now completely free of spyware. <b>I count 17 entries in Task Manager, exactly the same number as when I originally started.</b>
</p>
<p>
Of course, the smartest thing to do is <b>not to get infected with spyware, malware, or adware in the first place</b>. I can't emphasize this enough: <i>always browse with the latest patches for your preferred web browser</i>. But if you do happen to get infected, at least now you have the tools and knowledge to banish these evildoers from your machine forever.
</p>
<p>
<font color="red">Update: If you're worried about spyware, malware, and adware, you should strongly consider <a href="http://www.codinghorror.com/blog/archives/000891.html">not running as an Administrator</a>.</font>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-clean-up-a-windows-spyware-infestation/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Escaping From Gilligan's Island ]]></title>
<link>https://blog.codinghorror.com/escaping-from-gilligans-island/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I find it helpful to revisit Steve McConnell's <a href="http://www.stevemcconnell.com/rdenum.htm">list of classic development process mistakes</a>, and the <a href="http://www.stevemcconnell.com/rdmistak.htm">accompanying case study</a>, at least once every year. Stop me if you've heard this one before:</p>
<blockquote>
<p>"Look, Mike," Tomas said. "I can hand off my code today and call it 'feature complete', but I've probably got three weeks of cleanup work to do once I hand it off." Mike asked what Tomas meant by "cleanup." "I haven't gotten the company logo to show up on every page, and I haven't gotten the agent's name and phone number to print on the bottom of every page. It's little stuff like that. All of the important stuff works fine. I'm 99-percent done."</p>
</blockquote>
<p>As that old software proverb goes, <i>the first ninety percent of the task takes ninety percent of the time, and the last ten percent takes the other ninety percent.</i></p>
<p>The <a href="http://www.stevemcconnell.com/rdmistak.htm">Classic Mistakes case study</a> is unnerving to read; it's like those staged re-enactments you see on <a href="http://www.amw.com/">America's Most Wanted</a>. It's an exaggerated but strangely accurate summary of every pathological software project I've ever participated in, which is to say almost all of them.</p>
<p>This is the phenomenon McConnell likens to <a href="http://www.tvtome.com/GilligansIsland/">Gilligan's Island</a>. <b>Every week there's some new, crazy scheme to escape the island, but at the end of the episode, the castaways always end up stuck on the island for yet another week.</b></p>
<img alt="image placeholder" >
<p>If you don't immediately see the parallels with software development, allow me to reacquaint you with <a href="http://blog.codinghorror.com/the-long-dismal-history-of-software-project-failure/">the long, dismal history of software project failure</a>. <b>Classic mistakes are classic because they're so seductive.</b> You have to actively recognize when you're falling into one of these traps. As Steve once said in <a href="http://technetcast.ddj.com/hz-show-980417.html">an interview</a>:</p>
<blockquote>
<p>Actually succeeding in a software project depends a whole lot less on not doing a few things wrong but on doing almost everything right.</p>
</blockquote>
<p>Which is why you should have every single one of <a href="http://www.stevemcconnell.com/rdenum.htm">the 36 classic mistakes</a> outlined in McConnell's <a href="http://www.amazon.com/exec/obidos/ASIN/1556159005/codihorr-20">Rapid Development</a> committed to memory by now:</p>
<table cellpadding="2" cellspacing="2" width="700">
<tr>
<td><b>People Mistakes</b></td>
<td><b>Process Mistakes</b></td>
</tr>
<tr>
<td valign="top">
Undermined motivation<br>
Weak personnel<br>
Uncontrolled problem employees<br>
Heroics<br>
Adding people to a late project<br>
Noisy, crowded offices<br>
Friction between developers and customers<br>
Unrealistic expectations<br>
Lack of effective project sponsorship<br>
Lack of stakeholder buy-in<br>
Lack of user input<br>
Politics placed over substance<br>
Wishful thinking<br>
</td>
<td valign="top">
Overly optimistic schedules<br>
Insufficient risk management<br>
Contractor failure<br>
Insufficient planning<br>
Abandonment of planning under pressure<br>
Wasted time during the fuzzy front end<br>
Shortchanged upstream activities<br>
Inadequate design<br>
Shortchanged quality assurance<br>
Insufficient management controls<br>
Premature or too frequent convergence<br>
Omitting necessary tasks from estimates<br>
Planning to catch up later<br>
Code-like-hell programming<br>
</td>
</tr>
<tr>
<td>
<br><b>Product Mistakes</b>
</td>
<td>
<br><b>Technology Mistakes</b>
</td>
</tr>
<tr>
<td valign="top">
Requirements gold-plating<br>
Feature creep<br>
Developer gold-plating<br>
Push me, pull me negotiation<br>
Research-oriented development<br>
</td>
<td valign="top">
Silver-bullet syndrome<br>
Overestimated savings from new tools or methods<br>
Switching tools in the middle of a project<br>
Lack of automated source control<br>
</td>
</tr>
</table>
<p>I've increasingly come to believe the only difference between experienced and inexperienced software developers is that the experienced ones <a href="http://blog.codinghorror.com/fail-early-fail-often/">realize when they're making mistakes</a>. The same rule applies to software projects and project managers. <b>If you're not actively scanning through the list of Classic Software Development Mistakes as you run your software project, you have no idea how likely it is you're making one of these mistakes <i>right now</i>.</b></p>
<p>Making mistakes is inevitable, but repeating the same ones over and over doesn't have to be. You should endeavor to make all-new, spectacular, never-seen-before mistakes. To that end, Steve McConnell highlighted <a href="http://forums.construx.com/blogs/stevemcc/archive/2007/06/15/Classic-Mistakes-Updated.aspx">a few new classic mistakes in his blog</a> that he's about to add to the canon, 10 years later:</p>
<ul>
<li>Confusing estimates with targets</li>
<li>Excessive multi-tasking</li>
<li>Assuming global development has a negligible impact on total effort</li>
<li>Unclear project vision</li>
<li>Trusting the map more than the terrain</li>
<li>Outsourcing to reduce cost</li>
<li>Letting a team go dark (replaces the previous "lack of management controls")</li>
</ul>
<p>Steve is also looking for our feedback. He published a <a href="https://vovici.com/wsb.dll/s/10431g2996e">Classic Mistakes Survey</a> and invited everyone to participate. If you have any kind of software project experience under your belt, <a href="https://vovici.com/wsb.dll/s/10431g2996e">please do</a>.</p>
<p>It's true, <a href="http://blog.codinghorror.com/the-long-dismal-history-of-software-project-failure/">the odds are against you</a>. But it's a good idea to periodically remind yourself that maybe, just maybe –  <b>if you can avoid making the same classic mistakes as so many other software projects before you</b> –  you might actually manage to escape from the island one of these days.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/escaping-from-gilligans-island/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ In Programming, One Is The Loneliest Number ]]></title>
<link>https://blog.codinghorror.com/in-programming-one-is-the-loneliest-number/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Is software development <b>an activity preferred by anti-social, misanthropic individuals who'd rather deal with computers than other people?</b> If so, does it then follow that all software projects are best performed by a single person, working alone?</p>
<img alt="image placeholder" >
<p>The answer to the first question may be a reluctant yes, but the answer to the second question is a resounding and definitive <i>no</i>. I was struck by <a href="http://web.archive.org/web/20071026082303/http://eddiesguy.blogspot.com/2007/06/creating-my-own-personal-hell.html">this beautifully written piece</a> which explains <b>the dangers of programming alone</b>:</p>
<blockquote>
<p>Some folks have claimed that [working alone] presents a great opportunity to establish your own process. In my experience, <i>there is no process in a team of one</i>. There's nothing in place to hold off the torrents of work that come your way. There's no one to correct you when the urge to gold-plate the code comes along. There's no one to review your code. There's no one to ensure that your code is checked in on time, labeled properly, unit tested regularly. There's no one to ensure that you're following a coding standard. There's no one to monitor your timeliness on defect correction. There's no one to verify that you're not just marking defects as "not reproducible" when, in fact, they are. There's no one to double-check your estimates, and call you on it when you're just yanking something out of your ass.</p>
<p>There's no one to pick up the slack when you're sick, or away on a business trip. There's no one to help out when you're overworked, sidetracked with phone calls, pointless meetings, and menial tasks that someone springs on you at the last minute and absolutely must be done right now. There's no one to bounce ideas off of, no one to help you figure your way out of a bind, no one to collaborate with on designs, architectures or technologies. You're working in a vacuum. And in a vacuum, no one can hear you scream.</p>
<p>If anyone's reading this, let this be a lesson to you. Think hard before you accept a job as the sole developer at a company. It's a whole new kind of hell. If given the chance, take the job working with other developers, where you can at least work with others who can mentor you and help you develop your skill set, and keep you abreast of current technology.</p>
</blockquote>
<p>Working alone is a temptation for many desperate software developers who feel trapped, surrounded by incompetence and mismanagement in the desert of the real. Working alone means complete control over a software project, wielding ultimate power over every decision. But working on a software project all by yourself, instead of being empowering, is paradoxically <i>debilitating</i>. It's a shifting mirage that offers the tantalizing promise of relief, while somehow leaving you thirstier and weaker than you started.</p>
<p>Like many programmers, I was drawn to computers as a child because I was an introvert. The world of computers –  that calm, rational oasis of ones and zeros –  seemed so much more inviting than the irrational, unexplainable world of people and social interactions with no clear right and wrong. Computers weren't <i>better</i> than people, exactly, but they were sure one heck of a lot easier to understand.</p>
<p>Computing in the early, pre-internet era was the very definition of a solitary activity. Dani Berry, the author of M.U.L.E., <a href="http://blog.codinghorror.com/gee-i-wish-i-had-spent-more-time-alone-with-my-computer/">sums up with this famous quote:</a> <i>"No one ever said on their deathbed, 'Gee, I wish I had spent more time alone with my computer.'"</i> But we've long since left the days of solitary 8-bit programming behind. The internet, and the increasing scope and complexity of software, have made sure of that. I can barely program these days <a href="http://blog.codinghorror.com/does-offline-mode-still-matter/">without an active internet connection</a>; I feel crippled when I'm not networked into the vast hive mind of programming knowledge on the internet.</p>
<p>What good are nifty coding tricks if you can't show them off to anyone? How can you possibly learn the craft without being exposed to other programmers with different ideas, different approaches, and different skillsets? Who will review your code and tell you when there's an easier approach you didn't see? <b>If you're serious about programming, you should <i>demand</i> to work with your peers</b>.</p>
<p>There's only so far you can go in this field by yourself. Seek out other smart programmers. Work with them. Endeavor to be <a href="http://web.archive.org/web/20071018050405/http://markeseremet.blogspot.com/2006/12/dumbest-guy-in-room.html">the dumbest guy in the room</a>, and you'll quickly discover that software development is a far more social activity than most people realize. There's a lot you can learn from your fellow introverts.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/in-programming-one-is-the-loneliest-number/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Windows Security Epidemic: Don't Run as an Administrator ]]></title>
<link>https://blog.codinghorror.com/the-windows-security-epidemic-dont-run-as-an-administrator/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/000888.html">How to Clean Up a Windows Spyware Infestation</a>, I documented how <b>spyware can do a drive-by infection of your machine through your web browser</b>. To be absolutely clear, <font color="red">I never clicked on any advertisements, or downloaded and executed any files</font>. All I did was open a GameCopyWorld web page in an unpatched, original circa-2001 version of Internet Explorer 6.0.
</p>
<p>
Yes, I know this is a spectacularly stupid thing to do. But I'm glad I did it. I got a small taste of the experience awaiting casual users when they browse the web without the latest patches and updates. I think <i>every</i> technical computer user should have this experience, so they can see first hand, on their own machine, the profound evil that we're up against. Sure, we can recover, but we do this stuff for a living. I'm trying to imagine what my mother or father would do if this happened to them. They'd probably have to <a href="http://www.nytimes.com/2005/07/17/technology/17spy.html?ex=1279252800&amp;en=5b2b6783f66a7422&amp;ei=5090">buy a new computer</a>.
</p>
<p>
When the only viable solution to sickness is to <i>kill the patient</i>, you have a problem of epidemic proportions.
</p>
<p>
Adam McNeil, of <a href="http://www.webroot.com/">Webroot Software</a>, was kind enough to lend an investigative hand and duplicate the GameCopyWorld scenario. His findings are exhaustive and eye-opening:
</p>
<p>
</p>
<blockquote>
After researching the GameCopyWorld.com website I can confirm that the site is utilizing 3rd party exploits in order to deliver malware. The exploits in question appear to be delivered through a series of advertisements within the gamecopyworld.com website.
<p>
GameCopyWorld displays a "Find Your Love at Bride.Ru" advertisement.  That advertisement "refers" to linktarget.com in order to display an advertisement for the DVD software produced by Slysoft.com.  That advertisement "refers" to 39m.net which in turn creates an &lt;iframe&gt; to buyhitscheap.com.  Buyhitscheap.com in turn calls fkdomain.info who attempts to deliver a series of exploits to a users system in hopes of installing a trojan dropper.  The fkdomain.info site attempts to exploit the following: (there could be more but these were the exploits I picked out of the code)
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.us-cert.gov/cas/techalerts/TA07-005A.html">Apple QuickTime with an RTSP Buffer Overflow error</a>
</li>
<li>
<a href="http://marc.info/?l=bugtraq&amp;m=116767279710088&amp;w=2">WinZip FileView ActiveX CreateNewFolderFromName Method</a>
</li>
<li>
<a href="http://secunia.com/advisories/22159/">Microsoft Windows Shell Code Execution Vulnerability</a>
</li>
<li>
<a href="http://www.microsoft.com/technet/security/Bulletin/MS03-011.mspx">Byte Verify Exploit</a>
</li>
</ul>
<p>
The dropper creates files that in turn download additional files as well as create threads within the Internet Explorer browser.
</p>
<p>
<a href="http://www.webroot.com/consumer/products/spysweeper/">Webroot SpySweeper</a> detected the following spies after allowing the installer to run over night.
</p>
<p>
</p>
<ul>
<li>Virtumonde
</li>
<li>Visfx
</li>
<li>ZenoSearchAssistant
</li>
<li>PurityScan
</li>
<li>Trojan Downloader Matcash
</li>
<li>Trojan-Downloader-Zlob
</li>
<li>BookedSpace
</li>
<li>Trojan-Downloader-WaveRevenue
</li>
<li>Trojan.Gen
</li>
<li>Trojan-Downloader-Prez
</li>
<li>MaxiFiles
</li>
<li>TargetSaver
</li>
<li>Trojan-Poolsv
</li>
<li>Trojan-Dropper-Zomavis
</li>
<li>Webhancer
</li>
<li>Web Buying
</li>
<li>Command
</li>
<li>Core Adware (CoreAdware is known to use Rootkits {core.sys} to mask its presence.)
</li>
</ul>
<p>
In addition to the above listed spies, I have also recorded a large number of unclassified (not for long) files and registry entires that were added to the box as well.
</p>
<p>
Seeing as how these exploit files were delivered via 3rd party advertisements I'm not sure it is entirely accurate to place all of the blame for this Drive-by with GameCopyWorld.com.  It's possible that they allowed a third party to attempt exploits on a users machine, but then again it's also entirely possible that one of these advertisers has slipped in these exploits without their knowledge or consent.  It's impossible to know if this exploit was delivered intentionally or accidentally.
</p>
</blockquote>
<p>
I've never used any Webroot products, but when an employee takes his own personal time to investigate a public scenario so thoroughly, that speaks very highly of the company. They're clearly one of the good guys. But the fact that I <i>have</i> to maintain a mental "safe list" of software companies-- these are OK, these are questionable-- is itself disturbing and unhealthy. It's symptomatic of just how sick the Windows software ecosystem has become. <b>It's nearly impossible to tell the good guys from the bad guys</b>. Do a web search for "spyware" and you'll get dozens of results, some of which are for companies that installed the spyware in the first place. Can you tell them apart? Could your parents?
</p>
<p>
Tracing this massive security epidemic all the way back to <a href="http://en.wikipedia.org/wiki/Patient_Zero">patient zero</a> doesn't take much detective work. It originates with Windows NT 3.0, when <b>Microsoft chose to set up default users as Administrators</b>.
</p>
<p>
This infection was <b>only possible because I was logged in as an administrator</b>. Choosing <i>not</i> to run as an Administrator is easily the single most important security tip for a Windows machine, whether you're running XP or Vista. Worried about your parents getting infected? Need to create an account for a teenager? <b>Set them up as regular users</b>. It's not a panacea, but it goes an awful long way towards solving the problem. As a test, I logged in as a normal user, and I was unable to duplicate the GameCopyWorld infection in any way-- even with a completely unpatched, circa 2001 version of Windows XP. Running as a normal user <i>really works</i>.
</p>
<p>
<a href="http://blogs.msdn.com/aaron_margosis/archive/2004/06/17/157962.aspx">Aaron Margosis' blog</a> is the best source of information on running as a non-administrator. His list of <a href="http://blogs.msdn.com/aaron_margosis/archive/2004/06/17/157962.aspx">reasons why you shouldn't run as an Administrator</a> is hair-raising stuff:
</p>
<p>
</p>
<blockquote>
If you're running as admin, an exploit can:
<p>
</p>
<ul>
<li>install kernel-mode rootkits and/or keyloggers (which can be close to impossible to detect)
</li>
<li>install and start services
</li>
<li>install ActiveX controls, including IE and shell add-ins (common with spyware and adware)
</li>
<li>access data belonging to other users
</li>
<li>cause code to run whenever anybody else logs on (including capturing passwords entered into the Ctrl-Alt-Del logon dialog)
</li>
<li>replace OS and other program files with trojan horses
</li>
<li>access LSA Secrets, including other sensitive account information, possibly including account info for domain accounts
</li>
<li>disable/uninstall anti-virus
</li>
<li>cover its tracks in the event log
</li>
<li>render your machine unbootable
</li>
<li>if your account is an administrator on other computers on the network, the malware gains admin control over those computers as well
</li>
</ul>
..and lots more
</blockquote>
<p>
I'll admit I am not the best role model on this count. Personally, I lost my enthusiasm for limited user accounts when <b>Microsoft didn't have the guts to make standard users the default-- as they absolutely should have-- in Windows Vista</b>. I <a href="http://www.codinghorror.com/blog/archives/000347.html">swore they would</a>. Instead, we got got hybrid administrator weirdness and "Cancel or Allow" oddities.
</p>
<p>
I guess that's yet another thing we can sacrifice at <a href="http://www.joelonsoftware.com/articles/APIWar.html">the dark altar of backwards compatibility</a>.
</p>
<p>
I understand the pressure to be backwards compatible. There's no end of Vista blowback based on minor driver compatibility issues. The <i>"if it doesn't work, it's automatically Microsoft's fault, even if the software or hardware vendor is clearly to blame"</i> mentality is sadly all too common. But given the <b>massive ongoing Windows security epidemic</b>, was defaulting regular users to Administrator accounts-- exactly like Windows XP, Windows 2000, and Windows NT before it-- <i>really</i> the right decision to make?
</p>
<p>
I'm not so sure.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-windows-security-epidemic-dont-run-as-an-administrator/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Does Anyone Actually Read Software EULAs? ]]></title>
<link>https://blog.codinghorror.com/does-anyone-actually-read-software-eulas/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>If you've used a computer for any length of time, you've probably clicked through hundreds of <b>End User License Agreement (EULA) dialogs</b>. And if you're like me, you haven't read a single word of any of them.</p>
<img alt="image placeholder" >
<p>Who can blame you? They're mind-numbing legalese. As a software developer, I understand that <a href="http://blog.codinghorror.com/pick-a-license-any-license/">choosing a software license for my code is helpful to my fellow developers</a>. But who, exactly, benefits from an <i>end-user</i> license agreement?</p>
<img alt="image placeholder" >
<p>I'm an end user, and I don't recall anything good ever coming from clicking that "I accept" option. It's just another meaningless hoop I have to jump through before I can actually use the software. For all I know, the EULA could specify that the software is going to install a keylogger, steal all my passwords and financial information, send incriminating emails threatening the president, format my hard drive, and then sleep with my wife. How would I know? I blindly clicked that big, fat accept button, same as I always have.</p>
<p>Short of <a href="http://www.javacoolsoftware.com/eulalyzer.html">writing software to read the EULA and automatically flag such problems</a> – a conceptually brilliant solution to an intractable problem – what's a poor "end user" to do?</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/F1C4gWyW1Ng" frameborder="0" allowfullscreen></iframe>
<p>The EFF points out <a href="https://www.eff.org/wp/dangerous-terms-users-guide-eulas">a few common problems with EULA agreements</a> you might want to watch out for:</p>
<ol>
<li>
<b>"Do not criticize this product publicly."</b><br>
<p>Hidden within the terms of many EULAs are often serious demands asking consumers to sign away fundamental rights. Many agreements on database and middleware programs forbid the consumer from comparing his or her product with another and publicly criticizing the product. This obviously curtails free speech, and makes it more difficult for consumers to get accurate information about what they're buying by inhibiting professional watchdog groups like Consumer Reports from conducting independent reviews.</p>
</li>
<li>
<b>"Using this product means you will be monitored."</b><br>
<p>Many products come with EULAs with terms that force users to agree to automatic updates – usually by having the computer or networked device contact a third party without notifying the consumer, thus potentially compromising privacy and security.</p>
</li>
<li>
<b>"Do not reverse-engineer this product."</b><br>
<p>Some EULA terms harm people who want to customize their technology, as well as inventors who want to create new products that work with the technology they've bought. "Reverse-engineering," which is often forbidden in EULAs, is a term for taking a machine or piece of software apart in order to see how it works. This kind of tinkering is explicitly permitted by federal law – it is considered a "fair use" of a copyrighted item. Courts have held that the fair use provisions of the US Copyright Act allow for reverse-engineering of software when the purpose is to create a non-infringing interoperable program.</p>
</li>
<li>
<b>"Do not use this product with other vendor's products."</b><br>
<p>Vendors use EULAs to make consumers agree that they won't use products that evaluate the performance of the software they've bought, or that can be used to uninstall all or part of the program. Essentially, clicking "I Agree" to such a EULA means that you're not supposed to reconfigure your computer to touch or remove the software you've just installed. These kinds of EULA terms have become popular lately because many vendors support free versions of their products by packaging them with third-party programs that serve ads or gather information about consumer habits for marketing companies. If users uninstalled such ride-along programs at will, the vendors might lose revenue. For example, Claria (formerly Gator) is a company that delivers pop-up ads and pays to have its GAIN software bundled in free versions of popular file-sharing program Kazaa.</p>
</li>
<li>
<b>"By signing this contract, you also agree to every change in future versions of it. Oh yes, and EULAs are subject to change without notice."</b><br>
<p>Put simply, this means that when you install iTunes, you are not only agreeing to all the onerous terms in the box, but you are also agreeing to future terms that may appear in the iTunes Terms of Service months or years from now. These terms are subject to change without notice, and you don't even get a chance to click through this future "contract" and agree. Mere "continued use of the iTunes Music Store" constitutes your agreement to contractual terms that you may not be aware exist. These kinds of terms are ubiquitous in EULAs and in Terms of Service for countless products.</p>
</li>
<li>
<b>"We are not responsible if this product messes up your computer."</b><br>
<p>The disclaimer of liability for faulty software is perhaps the most important function of a EULA from the manufacturer's perspective. And it's bad news for the consumer. This term purports to supplant traditional consumer protection and products liability law. Clicking yes on EULAs containing this common clause means that the consumer cannot file class-action lawsuits against the vendor for faulty products, or for products that do not do all the things that the company advertised they would.</p>
</li>
</ol>
<p>I've presented only the summary highlights; I highly recommend reading <a href="https://www.eff.org/wp/dangerous-terms-users-guide-eulas">the rest of the EFF article</a> for much more detail. Unfortunately, following any of the EFF's advice requires reading the EULA in minute detail, a time commitment that few are willing to make.</p>
<p>What I've pictured above are known as <a href="http://en.wikipedia.org/wiki/EULA#Shrink-wrap_and_click-wrap_licenses">click-wrap licenses</a>. Clicking through indicates assent to the license. But did you know that <b>the physical act of opening some software can subject you to shrink-wrap license terms</b>? Cory Doctorow calls shrinkwrap licenses <a href="http://www.informationweek.com/shrinkwrap-licenses-an-epidemic-of-lawsuits-waiting-to-happen/d/d-id/1051535">an epidemic of lawsuits waiting to happen</a>. I'm not sure about the lawsuit epidemic, but the jury is definitely still out on whether or not clickwrap and shrinkwrap EULAs are enforceable – or even meaningful.</p>
<blockquote>
<p>Clickwrap and shrinkwrap agreements all start with the phrase <a href="http://reasonableagreement.org/">READ CAREFULLY</a>, in caps. The phrase means, "IGNORE THIS." That's because the small print is unchangeable and outrageous.</p>
<p>Why read the "agreement" if you know that:</p>
<ul>
<li>No sane person would agree to its text, and</li>
<li>Even if you disagree, no one will negotiate a better agreement with you?</li>
</ul>
</blockquote>
<p>Given the insanity of our current predicament, <i>not</i> reading the EULA could very well be the most rational course of action.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/does-anyone-actually-read-software-eulas/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How To Advertise on Your Blog Without (Completely) Selling Out ]]></title>
<link>https://blog.codinghorror.com/how-to-advertise-on-your-blog-without-completely-selling-out/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was saddened to read this blurb from <a href="http://globalnerdy.com/2007/06/25/notes-from-danah-boyds-myfriends-myspace/">danah boyd's outstanding "MyFriends, MySpace"</a> presentation at Harvard:
</p>
<p>
</p>
<blockquote>
My activist self wanted to believe that the users are aware of [ads], but sadly, that's not the case. To them, seeing ads means that the service is free. <b>Kids are so used to being blasted with ads that they don't notice them.</b>
</blockquote>
<p>
I am no fan of advertising. I <i>hate</i> the fact that <a href="http://www.codinghorror.com/blog/archives/000772.html">most websites are plastered with obnoxious, barely relevant ads</a>. I've <a href="http://www.codinghorror.com/blog/archives/000700.html">considered advertising before</a>, but I rejected it. I don't want to be part of the problem. Even as a hypothetical, I couldn't come up with any tangible advertising benefits for anyone but myself-- and even then, not without taking on significant risks:
</p>
<p>
</p>
<ul>
<li>
<b>Loss of credibility</b>. Do you advocate the products your ads are hawking? Are you pandering to drive page views or writing what you feel? Who <i>are</i> you writing for, exactly? Your advertisers? Your audience? Yourself?
<p>
</p>
</li>
<li>
<b>Design Suffers</b>. Ads are eyesores, virtual billboards cluttering the digital landscape of a website. Got whitespace? Fill it with another ad, naturally. Maximize that revenue stream, layout be damned!
<p>
</p>
</li>
<li>
<b>Lack of Professionalism</b>. In traditional journalism, there's strictly enforced separation between the writers and the marketers selling ads. In a one-man blog shop, this isn't possible, so questions of impartiality are unavoidable.
</li>
</ul>
<p>
But there's a certain.. inevitability.. to online advertising, <a href="http://www.shirky.com/writings/paying_attention.html">as Clay Shirky wrote</a>:
</p>
<p>
</p>
<blockquote>
This model, which generates income by making content widely available over open networks without charging user fees, is usually called 'ad-supported content', and it is currently very much in disfavor on the Internet. I believe however, that not only can ad-supported content work on the Internet, I believe it can't not work. Its success is guaranteed by the net's very makeup - the net is simply too good at gathering communities of interest, too good at freely distributing content, and too lousy at keeping anything locked inside subscription networks, for it to fail. Like TV, the net is better at getting people to pay attention than anything else.
</blockquote>
<p>
That was a few years ago. Now the battle is long over. Advertising has won so completely and decisively that it's hard to imagine any other revenue model working online. A handful of websites can <a href="http://blogs.smugmug.com/baldy/2006/09/25/the-curious-decline-of-free-photo-sharing/">pull off pay-only services</a>, but it isn't even on the radar for most.
</p>
<p>
Advertising sucks. But you know what else sucks? When people point out how stupid you are to <a href="http://www.calacanis.com/2007/01/09/am-i-throwing-away-100k/">throw away five figures worth of potential income</a>. Repeatedly. At length. So the question becomes this:
</p>
<p>
<b>Is it possible to advertise responsibly, with respect for your audience-- and yourself?</b> I think it is, if you're careful.
</p>
<p>
One of my favorite references on responsible online advertising is the <a href="http://www.modernlifeisrubbish.co.uk">Modern Life blog</a>. Like so many of my favorite blogs, it's not updated nearly often enough. But Stuart Brown's piece on <a href="http://www.modernlifeisrubbish.co.uk/article/balancing-adsense-with-user-experience">balancing AdSense with user experience</a> offers the best advice I've seen so far:
</p>
<p>
</p>
<ol>
<li>Use the <a href="https://www.google.com/adsense/support/bin/answer.py?answer=17954">AdSense heat map</a> to judiciously select one or two places for ads, rather than blasting them across your page.
<p>
</p>
</li>
<li>As a courtesy, turn off ads for Digg, Reddit, and other popular referring URLs. This audience doesn't appreciate ads, and they're the least likely to click them anyway.
<p>
</p>
</li>
<li>Reward frequent readers by keeping your new content free of ads. Use time-delayed ads that only display on articles <i>after</i> they've aged for a week.
<p>
</p>
</li>
<li>Always offer full content in your RSS feed. Don't force people to click through to your site and see your advertisements.
</li>
</ol>
<p>
It's sensible, original advice that's respectful of readers. The advertising section of <a href="http://www.modernlifeisrubbish.co.uk/article/ethical-blogging-101">Ethical Blogging 101</a> is also spot-on as well. Heck, read his entire blog while you're there. It's all great.
</p>
<p>
Stuart only talks about AdSense in his posts. <b>AdSense is easy enough to plug in to your website, but is generic AdSense really the right choice?</b> In <a href="http://www.advertisespace.com/2007/05/25/the-7-levels-of-revenue-for-your-blog/">The 7 Levels of Revenue for your Blog</a>, Google AdSense is the absolute bottom of the barrel, a choice of last resort. There are other options:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="700px">
<tr>
<td>
</td>
<td>
</td>
<td style="border-bottom: silver 1px dotted">
Sold Through</td>
<td style="border-bottom: silver 1px dotted">
Revenue</td>
</tr>
<tr>
<td>
<strong>Level 1</strong>
</td>
<td>
AdSense</td>
<td>
Google</td>
<td>
$1 CPM</td>
</tr>
<tr>
<td>
<strong>Level 2</strong>
</td>
<td>
Affiliate Programs</td>
<td>
Amazon, Buy.com, etc</td>
<td>
1-2% sales</td>
</tr>
<tr>
<td>
<strong>Level 3</strong>
</td>
<td>
Traditional
Ad Networks</td>
<td>
ContextWeb, ValueClick, AdOn, etc</td>
<td>
$1-$2 CPM</td>
</tr>
<tr>
<td>
<strong>Level 4</strong>
</td>
<td>
Automated Text Link Ads</td>
<td>
TextLinkAds</td>
<td>
$25/link</td>
</tr>
<tr>
<td>
<strong>Level 5</strong>
</td>
<td>
Fixed Text Link Ads</td>
<td>
(direct)</td>
<td>
$50/link</td>
</tr>
<tr>
<td>
<strong>Level 6</strong>
</td>
<td>
Graphical Banner Ads</td>
<td>
(direct)</td>
<td>
$5-$20 CPM</td>
</tr>
<tr>
<td>
<strong>Level 7</strong>
</td>
<td>
Fixed Monthly Sponsors</td>
<td>
(direct)</td>
<td>
(negotiated)</td>
</tr>
</table>
<p>
Notice that the top 3 tiers of the advertising pyramid are <b>all sold directly</b>. I prefer this approach. You retain maximum control over exactly what is advertised on your website. Instead of an ad network deciding what gets displayed, <i>you</i> decide. It's a relationship you control.
</p>
<p>
If you're going to clutter up your website with advertising in the first place, why not do it as effectively as possible? Don't use the Ronco spray-on advertising approach -- e.g., indiscriminately placing low-value Google AdSense units in every nook and cranny of your page. It's a better experience for you, and your readers, to be much more selective. I'll never understand bloggers who place their own personal desire for an additional few grand of income over <a href="http://www.slideshare.net/garr/kathy-sierra-on-building-a-global-microbrand-from-sxswi/15">basic respect for their readers</a>.
</p>
<p>
By now, you may be wondering if this is a rather tedious, long-winded way of saying that <i>I'm about to start advertising on this blog</i>. You're right. It is. But I have one more bit of advice to offer before I do, and it's arguably the most important one of all.
</p>
<p>
<b>I will be donating a significant percentage of my ad revenue back to the programming community.</b> The programming community is the reason I started this blog in the first place. The programming community is what makes this blog possible. It's an open secret amongst bloggers that the blog comments are often better than the original blog post, and it's because the community collectively knows far more than you or I will ever know.
</p>
<p>
So, what's <i>significant</i>? Let's start with <b>$5,000</b>.
</p>
<p>
I've personally benefited most from the .NET open source community, which I feel is radically under-served by Microsoft, so I'll be contributing this money to one or more .NET open source projects to maximize its impact. And what's even <i>more</i> exciting is that I have a verbal commitment from <a href="http://blogs.msdn.com/aniyer/">Anand Iyer</a>, a MS Developer Evangelist, for Microsoft to match my contribution. <b>That makes a cool $10,000 we will be contributing to support open-source .NET projects!</b>
</p>
<p>
<font color="red">Update:</font> My $5,000 was <a href="http://www.codinghorror.com/blog/archives/001098.html">awarded to the ScrewTurn Wiki project</a> in April 2008. Sorry it took so long.
</p>
<p>
As much as I abhor advertising, I'm tremendously excited to have the opportunity to share my advertising revenue with the larger .NET programming community. For me, that's the tipping point. Giving back to the community is what makes the pain of advertising worthwhile.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-advertise-on-your-blog-without-completely-selling-out/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Supporting Open Source Projects in the Microsoft Ecosystem ]]></title>
<link>https://blog.codinghorror.com/supporting-open-source-projects-in-the-microsoft-ecosystem/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As part of my <a href="http://www.codinghorror.com/blog/archives/000893.html">new advertising initiative</a>, Microsoft and I are teaming up to <b>donate $10,000 in support of open source .NET projects</b>.
</p>
<p>
Why am I focusing on .NET open source projects? In short, because <b>open source projects are treated as second-class citizens in the Microsoft ecosystem</b>. Many highly popular open source projects have contributed so much to the .NET community, and they've gotten virtually no support at all from Microsoft in return. I'd like to see that change. In fact, I'll go even further-- I think it <i>must</i> change if Microsoft wants to survive as a vendor of development tools.
</p>
<p>
Of course, I'm not the first person to make this observation:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.hanselman.com/blog/SandcastleMicrosoftCTPOfAHelpCHMFileGeneratorOnTheTailsOfTheDeathOfNDoc.aspx">Scott Hanselman</a>
<p>
It's a shame that Microsoft can't put together an organization like INETA (who already gives small stipends to folks to speak at User Groups) and gave away grants/stipends to the 20 or so .NET Open Source Projects that TRULY make a difference in measurable ways. The whole thing could be managed out of the existing INETA organization and wouldn't cost more than a few hundred grand - the price of maybe 3-4 Microsoft Engineers.
</p>
<p>
</p>
</li>
<li>
<a href="http://www.ayende.com/Blog/archive/7043.aspx">Ayende Rahien</a>
<p>
The open source community in .NET is big, but it is only a fraction of the size of the open source community in other environments (Java, for instance). This disparity can be explained by looking at the basic facts of the .NET community: there's one central vendor, Microsoft. This puts Microsoft in a position where they have the ear of every .NET developer, team lead and architect. And Microsoft isn't doing anything to foster a healthy OSS community around .NET.
</p>
<p>
</p>
</li>
<li>
<a href="http://blog.davestechshop.net/archive/2006/09/16/MicrosoftShouldSupportOpenSource.aspx">Dave</a>
<p>
In my company's commercial application we depend upon DotNetNuke, Nant, log4net, NUnit and other open source tools. Those open source projects help support us. In fact, without DNN, we would probably be out of business because our developments costs would be too high. In turn, my company helps support Microsoft through the purchase of licenses and MSDN subscriptions. Yet Microsoft does not complete the circle by financially supporting any of those open source projects.
</p>
<p>
</p>
</li>
<li>
<a href="http://www.dotnetnuke.com/Default.aspx?tabid=825&amp;EntryID=1129">Joe Brinkman</a>
<p>
I believe it is in Microsoft's best interests to identify a handful of open source projects to support, especially where those projects fill a void in the Microsoft product line, or where the project promotes the adoption of Microsoft products.  However, I think the project bears even more responsibility to identify how they can benefit a potential corporate sponsor, and then actively pitch the idea to the corporation whose sponsorship is being sought.  The project should care more about developing and growing this relationship than the corporate sponsor, since the project could well die without the support, while the corporation only loses one of many potential opportunities.
</p>
<p>
</p>
</li>
</ul>
Open source software is at its best when <a href="http://www.codinghorror.com/blog/archives/000649.html">you aren't obligated to do anything at all other than use it</a>. But given the disappointing lack of official support for open source projects in the Microsoft .NET ecosystem, it's time for us to band together and <i>do something</i> about it. When <a href="http://blogs.msdn.com/aniyer/">Anand</a> mentioned that he could match my $5,000 donation with funds from Microsoft, I was thrilled. This is a fantastic opportunity for Microsoft to step up to the plate and make their support for open source .NET projects explicit in a very public way.
<p>
Here are my initial thoughts on splitting up the $10,000:
</p>
<p>
</p>
<ul>
<li>
<b>Three donations of $2,500</b> for the most worthy <i>established</i> .NET open source projects.
</li>
<li>
<b>Five donations of $500</b> for <i>new, up and coming</i> .NET open source projects.
</li>
</ul>
<p>
I'd also like to see this become a yearly event. As long as my advertising revenues hold up, I'm certainly willing to contribute a percentage back to the community every year.
</p>
<p>
All of this will be determined by popular vote, of course. Let's start by getting together a list of candidates. I'm soliciting nominations. <b>Which .NET open source projects do you find most useful?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/supporting-open-source-projects-in-the-microsoft-ecosystem/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Learning, or, Learning How To Learn ]]></title>
<link>https://blog.codinghorror.com/learning-or-learning-how-to-learn/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of my most eye-opening early experiences was a tour of a local manufacturing plant during high school. One of our tour guides was a MIT trained engineer who accompanied us, explaining how everything worked. At the end of the tour, he gave each of us a picture of a spider he had taken under one of the electron microscopes they had at the facility. He labelled it <a href="http://thewho.net:16080/discography/songs/BoristheSpider.html">"Boris the Spider"</a> after the Who song. I kept that photo in my school locker for months.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As a college-bound high school junior, I was impressed. I thought my Apple II was the neatest tool ever, but this guy had a freaking <i>electron microscope</i>. He was articulate, intelligent, and on top of that, one of the coolest people I had ever met. And he graduated from <a href="http://web.mit.edu/">MIT</a>, one of the best engineering schools in the country. During lunch, I asked him how much of his schoolwork applied to his current engineering job. His response?
</p>
<p>
<i>I can't think of a single thing from my MIT classes I've used on the job.</i>
</p>
<p>
This blew my mind. What's the value of a marquee college degree if none of the skills you learn are useful on the job?
</p>
<p>
At first, I was incredulous. But after considering my own high school educational experience, it started to make more sense. And certainly after attending college for a year, I knew exactly what he meant. <b>The value of education isn't in the specific material you learn-- it's in learning how to learn</b>. In <a href="http://www.zephoria.org/thoughts/archives/2007/06/27/knowledge_acces.html">Knowledge Access as a Public Good</a>, danah boyd presents Wikipedia as a perfect example of the latter:
</p>
<p>
</p>
<blockquote>
Why are we telling our students not to use Wikipedia rather than educating them about how Wikipedia works? Sitting in front of us is an ideal opportunity to talk about how knowledge is produced, how information is disseminated, how ideas are shared. Imagine if we taught the "history" feature so that students would have the ability to track how a Wikipedia entry is produced and assess for themselves what the authority of the author is. You can't do this with an encyclopedia. Imagine if we taught students how to fact check claims in Wikipedia and, better yet, to add valuable sources to a Wikipedia entry so that their work becomes part of the public good.
</blockquote>
<p>
Passively reading the material in an encyclopedia or textbook is learning, in a sense. But learning how to research and question the material you read-- and, as in Wikipedia, how to update it so <i>you're</i> adding to the communal wealth of knowledge-- is a <i>far</i> more valuable skill. This kind of participatory, hands-on experience outstrips any kind of traditional classroom textbook. Why read textbooks when you can help write one? There's <a href="http://www.codinghorror.com/blog/archives/000827.html">no substitute for learning on the battlefield</a>.
</p>
<p>
Nowhere is <b>the importance of learning how to learn</b> more critical than in the field of software development. Programming is, almost by definition, continuously learning: your entire career will be one long, unbroken string of learning one new bit of technology after another. Every ten years the software development field reinvents itself, and it's our job to keep up.
</p>
<p>
If you don't like learning new things, you will <i>despise</i> software engineering. It's all we do. That's why <b>learning how to learn is such an important skill for software engineers</b>. In our field, <a href="http://www.codinghorror.com/blog/archives/000220.html">how only lasts about five years, but why is forever</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/learning-or-learning-how-to-learn/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why You Don't Want an iPhone -- Yet ]]></title>
<link>https://blog.codinghorror.com/why-you-dont-want-an-iphone-yet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Let me start by saying up front that <b>I am a fan of the iPhone</b>.
</p>
<p>
The mobile phone market is a sad, pathetic wasteland in desperate need of improvement. I'm hoping iPhone will the collective kick in the pants the smartphone market needs to <i>finally stop making user hostile products</i>.
</p>
<p>
But before you rush out this Friday, June 29th to be an early adopter and buy a shiny new <a href="http://www.apple.com/iphone/">iPhone</a>, I have a cautionary tale for you.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
My work generously provides me with a <a href="http://www.samsungblackjack.com/">Samsung Blackjack</a> smartphone. I wasn't thrilled about the idea of owning a smartphone. My mobile phone needs are modest, and I thought the <a href="http://www.microsoft.com/windowsmobile/default.mspx">Windows Mobile</a> 5.0 based Blackjack would be overkill for what I do. But I was pleasantly surprised. The hardware is wonderful; smartphone design has really come into its own in the latest generation. The software, well... not so much. Windows Mobile 5.0 has a huge number of rough edges, real head-slapping "what were they thinking" moments. You'd think they would have figured this mobile stuff out by now, after five full versions. But Windows Mobile is servicable, if not great. And I found two specific features incredibly addictive:
</p>
<p>
</p>
<ol>
<li>Mobile access to my email
</li>
<li>Mobile access to the internet
</li>
</ol>
<p>
It's gotten to the point now where I get the shakes if I can't bust out my Blackjack and look up something on Wikipedia, any time, any place. It's like <b>having the sum of the entire world's knowledge in the palm of your hand, wherever you happen to be.</b> I can't overstate how powerful this is. It completely and utterly spoils you.
</p>
<p>
A lot of the fancy things Apple is showing in the iPhone ads I was already doing with the Blackjack. For example, when I was on vacation in Chicago recently, this scenario played out:
</p>
<ul>
<li>We were walking down <a href="http://www.themagnificentmile.com/">the Magnificent Mile</a> when we realized we should try to get Second City tickets.
</li>
<li>I grabbed my Blackjack, navigated to the <a href="http://www.secondcity.com/">Second City website</a>, and saw that there were seats available for the 8pm show in about an hour.
</li>
<li>I clicked through to automatically dial the number for the Second City box office. I was told to come down and get on the standby list because the last few tickets had just been snapped up.
</li>
<li>I then launched the <a href="http://mobile.search.live.com/about/download/default.aspx">Windows Live mapping application</a> and quickly mapped a route to the nearest <a href="http://www.chicago-l.org/">L station</a>.
</li>
</ul>
<p>
Could I have done all this more smoothly on the iPhone? I'm sure of it. The Windows Mobile web browser is pretty crappy, and unlikely to render websites that aren't at least a <i>little</i> mobile frendly. It's hardly Safari. But still, we got into that 8pm Second City show on standby, thanks to my phone and judicious use of the internet. It's no <a href="http://www.youtube.com/results?search_query=iphone+calamari">"calamari"</a>, but it'll do, pig. <a href="http://www.imdb.com/title/tt0112431/">It'll do</a>.
</p>
<p>
The Blackjack supports both 3G and EDGE data connections. 3G data connections are amazing. When you're connected via that little "3G" icon in the upper-right hand corner of your mobile phone screen, it's like a beautiful, golden river of bytes flowing into your cell phone. Web sites <i>blast</i> on to your mobile screen. <b>3G is darn near a cable modem experience.</b> It makes using the internet on the go an absolute pleasure.
</p>
<p>
EDGE data connections, on the other hand, are none of those things. When my Samsung Blackjack is using an EDGE connection, it's like downloading the internet through an overclocked dialup modem. It's, in a word, <b>unbelievably painful</b>. It's the difference between "hey, let me whip out my phone and look this up really quick on wikipedia" and "eh, isn't worth the time investment." For reference, when downloading files, I see data rates of around 10 kb/sec with EDGE, and easily five times that (or more!) with 3G. Every time I see my phone displaying that little "E" icon that denotes an EDGE connection, I frown. It's a warning sign that using the internet will now be an unsatisfying, tedious, dialup era chore, instead of the fun, tiny-little-cable-modem experience it <i>could</i> be with 3G.
</p>
<p>
So you might be more than a little concerned, as I am, that <b>the iPhone only supports EDGE data connections</b>-- and doesn't support 3G data connections at all! It's a cruel oversight for a phone that has such an outstanding web browser. Jobs' answer to this criticism is that the iPhone supports WiFi, and iPhone users should seek out WiFi connections instead of suffering through EDGE cellular connections.
</p>
<p>
If you think <b>reliance on WiFi</b> is an <i>advantage</i> of the iPhone, check your <a href="http://cache.gizmodo.com/gadgets/images/iProduct.gif">reality distortion field</a>. I've lived the WiFi lifestyle when I've travelled, and it's not pleasant. Free, public WiFi points are a dying breed. Most WiFi points these days are locked down tight with passwords and encryption. And if they're not locked down, they want to charge you exorbitant rates for a few measly hours of WiFi access. It's like this at every single airport I've been at in the last year. And every Starbucks. And pretty much every other commercial venue. The only places I've had luck at are smaller non-chain coffee shops, public libraries, and so forth. If you're counting on the availability of free WiFi for reasonable data speeds on your iPhone, you're in for a rude awakening.
</p>
<p>
I've found that <i>not</i> being tied down to WiFi access is an incredible blessing when I travel. One of my favorite features of Windows Mobile is that you can tether via USB and <a href="http://blogs.vertigo.com/personal/jatwood/Blog/Lists/Posts/Post.aspx?ID=27">use it as a cellular modem for your PC</a>. The 3G cellular data network <b>frees me from dependency on expensive, unreliable, hard to find WiFi hotspots</b>. It's saved me at least fifty bucks on WiFi access fees in the last two months alone-- and I could do it from anywhere I had cell coverage, not just in a small hotspot huddled around the altar of WiFi.
</p>
<p>
I'm no <a href="http://solution.allthingsd.com/20070626/the-iphone-is-breakthrough-handheld-computer/">Walt Mossberg</a>. It's not my goal to crush anyone's dreams of owning their first iPhone. I know you've heard this a million times, but never, <i>never</i> has it been more true for any technology product: <b>wait for version 2.0 before buying.</b>
</p>
<p>
<a href="http://twitter.com/hotdogsladies/statuses/116192932"><img alt="image placeholder" >
</p>
<p>
Consider the fate of the original iPod, which was a far less ambitious product. This isn't just yet another small hard drive strapped to a tiny LCD display-- it's Apple's <i>first cell phone ever</i>. Maybe you remember <a href="http://www.engadget.com/2006/05/26/jobs-you-have-to-buy-a-new-ipod-at-least-once-a-year/">this choice Jobs quote</a>:
</p>
<p>
</p>
<blockquote>
"You keep on innovating, you keep on making better stuff," Jobs said, in response to a question from Williams about why a new iPod might seem outdated as soon as you take it out of the box. Then Jobs offered a bit of advice to consumers: "If you always want the latest and greatest, then you have to buy a new iPod at least once a year."
</blockquote>
<p>
If we use history as our guide, we can expect that <b>Apple will introduce a new iPhone within 12 months</b>. It's likely to address the most glaring flaws with the original: it'll probably have 3G, more storage, longer battery life, and so on.
</p>
<p>
I'm all for competition. I'm even what you might call an early adopter. But I think buying the very first iPhone model is a terrible idea unless you're the type of person who has a $500/month discretionary fund set aside solely for gadgets. The lack of 3G alone should be enough for serious pause, as it's such an obvious, painful omission from a phone with such powerful internet capabilities. I know I'd rarely use my Blackjack to access the internet if I was limited to brutally slow EDGE connection speeds, and I fear the same of the iPhone.
</p>
<p>
That said, not all buying decisions have to be rational. It is fun to own the latest gadgets, and as gadgets go, there's no doubt that the iPhone is a doozy. If you're willing to live with the crippling WiFi and EDGE limitations, then have at it. But at least go in knowing what you're getting into. And mark your calendar, because <b>you'll probably be upgrading to the second generation iPhone within 12 months</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-you-dont-want-an-iphone-yet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Three Faces of About Face ]]></title>
<link>https://blog.codinghorror.com/the-three-faces-of-about-face/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I bought my copy of <a href="http://en.wikipedia.org/wiki/Alan_Cooper">Alan Cooper's</a> classic <b>About Face</b> in 1995. I remember poring over it, studying its excellent advice, reveling in its focus on the hot new UI paradigms standardized in Windows 95-- toolbars, menus with icons, tabbed dialogs, and so forth. Seems quaint now, if not <a href="http://www.codinghorror.com/blog/archives/000724.html">borderline obsolete</a>, but this <i>was</i> 12 whole years ago. That's almost a lifetime in computer dog-years.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4">
<tr>
<td valign="top">
<a href="http://www.amazon.com/exec/obidos/ASIN/1568843224/codihorr-20"><img alt="image placeholder" >
</td>
<td valign="top">
<a href="http://www.amazon.com/exec/obidos/ASIN/0764526413/codihorr-20"><img alt="image placeholder" >
</td>
<td valign="top">
<a href="http://www.amazon.com/exec/obidos/ASIN/0470084111/codihorr-20"><img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="top">
<b><a href="http://www.amazon.com/exec/obidos/ASIN/1568843224/codihorr-20">About Face</a></b><br>
1995<br>
Alan Cooper
</td>
<td valign="top">
<b><a href="http://www.amazon.com/exec/obidos/ASIN/0764526413/codihorr-20">About Face 2.0</a></b><br>
2003<br>
Alan Cooper, Robert Reimann
</td>
<td valign="top">
<b><a href="http://www.amazon.com/exec/obidos/ASIN/0470084111/codihorr-20">About Face 3</a></b><br>
2007<br>
Alan Cooper, Robert Reimann, David Cronin
</td>
</tr>
</table>
<p>
I had no idea that there was a new edition of About Face until late 2003, when I saw the new cover sitting on a coworker's desk. I rushed out to get my own copy, and I found the book much improved over the original. I love Cooper, but he can be awfully bombastic at times. Having a second author dilutes Cooper's natural bombast and adds another viewpoint for a broader perspective. The new version was better and more up to date. My old copy was officially obsolete.
</p>
<p>
I was surprised to see a comment on my <a href="http://www.codinghorror.com/blog/archives/000020.html">recommended reading</a> post about yet <i>another</i> new edition of About Face released this year. Again, I rushed out to get my own copy. Cooper is obsoleting his own books at a frantic pace; it's almost as bad as software. If, like me, you're wondering <b>what's new in About Face 3</b>, there's a summary in the introduction:
</p>
<p>
</p>
<ul>
<li>The book has been reorganized to present its ideas in a more easy-to-use reference structure. The book is divided into three parts: the first deals with process and high-level ideas about users and design, the second deals with high-level interaction design principles, and the third deals with lower-level interface design principles
</li>
<li>The first part describes the <a href="http://media.wiley.com/product_data/excerpt/13/07645264/0764526413.pdf">Goal-Directed Design process</a> (pdf) in much greater detail than in the second edition, and more accurately reflects current practices at <a href="http://www.cooper.com/">Cooper</a>, including research techniques, the creation of personas, and how to use personas and scenarios to synthesize interaction design solutions.
</li>
<li>Throughout the book, we attempt to more explicitly discuss visual interface design concepts, methods and issues, as well as issues related to a number of platforms beyond the desktop.
</li>
<li>Terminology and examples in the book have been updated to reflect the current state of the art in the industry, and the text as a whole has been thoroughly edited to improve clarity and readability.
</li>
</ul>
<p>
I'll vouch for the readability improvement in text and layout -- this is a much better designed book overall. Adding the third author has improved the book even more, definitively obsoleting the previous version. <b>About Face 3 is the best edition of this classic yet</b>. If you've never owned a copy, consider yourself lucky on two counts:
</p>
<p>
</p>
<ol>
<li>You don't have to waste money on old editions; you can start with the latest and best edition.
</li>
<li>You're about to read one of the best books ever written on interaction design. Enjoy.
</li>
</ol>
<p>
I envy the experience you're about to have. For the rest of us, time to pony up the upgrade fee. Again.
</p>
<p>
If you like About Face, you'll also enjoy Cooper's <a href="http://www.amazon.com/exec/obidos/ASIN/0672326140/codihorr-20">The Inmates Are Running The Asylum</a>. Originally released in 1999, it was similarly refreshed with a second edition in 2004. I own the first edition, so it looks like I'll be upgrading, too.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-three-faces-of-about-face/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Avoiding Walled Gardens on the Internet ]]></title>
<link>https://blog.codinghorror.com/avoiding-walled-gardens-on-the-internet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I occasionally get requests to join private social networking sites, like LinkedIn or Facebook. I always politely decline. I understand the appeal of private social networking, and I mean no disrespect to the people who send invites. But it's just <a href="http://www.codinghorror.com/blog/archives/000703.html">not for me</a>.
</p>
<p>
I feel very strongly that we already have the world's best public social networking tool right in front of us: <b>it's called the internet</b>. Public services on the web, such as blogs, twitter, flickr, and so forth, are what we should invest our time in. And <a href="http://www.codinghorror.com/blog/archives/000840.html">because it's public</a>, we can leverage the immense power of internet search to tie it all-- and each other-- together.
</p>
<p>
In comparison, adding content to a private, walled garden on the internet <a href="http://scott.heiferman.com/notes/2007/05/walled.html">smacks of the old-world America Online ideology</a>:
</p>
<p>
</p>
<blockquote>
While at Sony in 1994, I was sent to Virginia to learn how to build a Sony "app" on AOL (the #3 online service, behind Compuserve &amp; Prodigy at the time) using AOL's proprietary "rainman" platform. Fast forward to Facebook 2007 and see similarities: If you want access to their big base of users, <b>develop something in their proprietary language for their people who live in their walled garden</b>.
</blockquote>
<p>
It was so clear to me back in 1999 that AOL was doomed. But at the time, any criticism of AOL was heresy. For a lot of companies, AOL <i>was</i> the internet. You had to accommodate AOL users in your web design and business decisions because of their immense user base and perceived power. Ten years later, is AOL is even relevant? Does anyone care?
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon">
<img alt="image placeholder" >
</p>
<p>
The lesson I take from this is that <b>no matter how wonderful your walled garden is, it can't compete with the public, open internet</b>. Jason Kottke <a href="http://www.kottke.org/07/06/facebook-is-the-new-aol">explains</a>:
</p>
<p>
</p>
<blockquote>
As it happens, we already have a platform on which anyone can communicate and collaborate with anyone else, individuals and companies can develop applications which can interoperate with one another through open and freely available tools, protocols, and interfaces. It's called the internet and it's more compelling than AOL was in 1994 and Facebook in 2007. Eventually, someone will come along and turn Facebook inside-out, so that instead of custom applications running on a platform in a walled garden, applications run on the internet, out in the open, and people can tie their social network into it if they want, with privacy controls, access levels, and alter-egos galore.
</blockquote>
<p>
Jason Kottke's equating of Facebook to AOL is intended to provoke. You might even say it's incendiary. But it's absolutely true, and a much-needed wakeup call. Have we really <a href="http://www.kottke.org/07/07/facebook-vs-aol-redux">forgotten the lesson of AOL's walled garden so soon?</a>
</p>
<p>
</p>
<blockquote>
Faced with competition from this open web, AOL lost. Running a closed service with custom content and interfaces was no match for the wild frontier of the web. Maybe if they'd done some things differently, they would have fared better, but they still would have lost. In competitive markets, open and messy trumps closed and controlled in the long run. Everything you can do on Facebook is possible using a loose coalition of blogging software, IM clients, email, Twitter, Flickr, Google Reader, etc. Sure, it's not as automatic or easy, but <b>anyone can participate</b>. The number of things to see and do on the web outnumbers the number of things you can see and do on Facebook by several orders of magnitude -- and always will.
<p>
Facebook is an intranet for you and your friends that just happens to be accessible without a VPN. If you're not a Facebook user, you can't do anything with the site. Nearly everything published by their users is private. Google doesn't index any user-created information on Facebook. All of the significant information and, more importantly, interaction still happens in private. <b>Maybe we shouldn't be so excited about the web's future moving onto an intranet.</b>
</p>
</blockquote>
<p>
If you want to join my friends list, let's do it in public. Post a link to one of my blog entries. Enter a comment right here. Reply to one of <a href="http://twitter.com/codinghorror">my tweets</a>. Send me <a href="mailto:jatwood@codinghorror.com">an email</a> or an instant message. I'll even collaborate with you, as long as it results in <a href="http://www.codinghorror.com/blog/archives/000847.html">a public artifact of some kind</a>.
</p>
<p>
Just <b>don't ask me to enter your private walled garden</b>. There's no future in it.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-06-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/avoiding-walled-gardens-on-the-internet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Rethinking Design Patterns ]]></title>
<link>https://blog.codinghorror.com/rethinking-design-patterns/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Many developers consider the book <a href="http://www.amazon.com/exec/obidos/ASIN/0201633612/codihorr-20">Design Patterns</a> a classic.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201633612/codihorr-20"><img alt="image placeholder" >
</p>
<p>
So what's a design pattern?
</p>
<p>
</p>
<blockquote>
A design pattern systematically names, motivates, and explains <b>a general design that addresses a recurring design problem</b> in object-oriented systems. It describes the problem, the solution, when to apply the solution, and its consequences. It also gives implementation hints and examples. The solution is a <b>general arrangement of objects and classes</b> that solve the problem. The solution is customized and implemented to solve the problem in a particular context.
</blockquote>
<p>
It's certainly worthwhile for every programmer to read Design Patterns at least once, if only to learn <a href="http://www.developer.com/design/article.php/1502691">the shared vocabulary of common patterns</a>. But I have two specific issues with the book:
</p>
<p>
</p>
<ol>
<li>Design patterns are a form of complexity. As with all complexity, I'd rather see developers focus on simpler solutions <i>before</i> <a href="http://www.codinghorror.com/blog/archives/000380.html">going straight to a complex recipe of design patterns</a>.
</li>
<li>If you find yourself frequently writing a bunch of boilerplate design pattern code to deal with a "recurring design problem", that's <i>not</i> good engineering-- <a href="http://www.codinghorror.com/blog/archives/000308.html">it's a sign that your language is fundamentally broken</a>.
</li>
</ol>
<p>
In his presentation <a href="http://perl.plover.com/yak/design/samples/slide001.html">"Design Patterns" Aren't</a>, Mark Dominus says <b>the "Design Patterns" solution is to turn the programmer into a fancy macro processor</b>. I don't want to put words in Mark's mouth, but I think he agrees with at least one of my criticisms.
</p>
<p>
But Dominus also digs deeper into the source material than most. He cites Christopher Alexander's book <a href="http://www.amazon.com/exec/obidos/ASIN/0195019199/codihorr-20">A Pattern Language</a>, which was the inspiration for Design Patterns.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0195019199/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Dominus summarizes the book thusly:
</p>
<p>
</p>
<blockquote>
Suppose you want to design a college campus. You must delegate some of the design to the students and professors, otherwise the Physics building won't work well for the physics people. No architect knows enough about about what physics people need to do it all themselves. But you can't delegate the design of <i>every</i> room to its occupants, because then you'll get a giant pile of rubble.
<p>
How can you distribute responsibility for design through all levels of a large hierarchy, while still maintaining consistency and harmony of overall design? This is the architectural design problem Alexander is trying to solve, but it's also a fundamental problem of computer systems development.
</p>
</blockquote>
<p>
That's the key insight that drives both books. Unfortunately, Dominus believes that <a href="http://perl.plover.com/yak/design/samples/note.html">the Gang-of-Four version obstructs Alexander's message</a>, replacing actual thought and insight with a plodding, mindless, cut-and-paste code generation template mentality:
</p>
<p>
</p>
<blockquote>
The point of <a href="http://perl.plover.com/yak/design/">the talk</a> is this: The "design patterns" you get from the Gang-of-Four book are not the same as the idea of "design patterns" that are put forward in Alexander's books. People say they are, but they aren't the same thing. Alexander's idea is a really good one, one that programmers might find useful. But very few programmers are going to find out about it, because they think they already know what it is. But they actually know this other idea which happens to go by the same name.
<p>
<b>So (once again) we need to take a fresh look at Christopher Alexander</b>. Forget what I said about the damn iterator pattern, already.
</p>
</blockquote>
<p>
I know it's not technically a software development book, but consider <a href="http://www.docuverse.com/blog/donpark/2007/07/01/eclipse-as-a-city">this advice from Don Park</a>:
</p>
<p>
</p>
<blockquote>
If <a href="http://www.eclipse.org/">Eclipse</a> is a boomtown which countless developers and companies continue to pour into, it now looks like LA, tiny downtown surrounded by endless expanse of suburban neighborhoods indistinguishable from each other other than by their names. Although one of the key pioneers behind Eclipse is Eric Gamma, one of the four authors of the infamous Design Patterns book, I feel that not enough attention is being paid to the original concepts that inspired the book, concepts captured in books by Christopher Alexander.
</blockquote>
<p>
You could read <a href="http://www.amazon.com/exec/obidos/ASIN/0201633612/codihorr-20">Design Patterns</a> like any number of other software developers before you. But I humbly suggest that you should go deeper and read <a href="http://www.amazon.com/exec/obidos/ASIN/0195019199/codihorr-20">A Pattern Language</a>, too, because <a href="http://www.codinghorror.com/blog/archives/000189.html">ideas are more important than code</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/rethinking-design-patterns/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Technology Backlash ]]></title>
<link>https://blog.codinghorror.com/the-technology-backlash/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Riding the waves of technology in the computer industry is exhilarating when you're twenty, but there's a certain emptiness that begins to creep in around the edges by the time you're forty. When you've spent the last twenty years doing nothing but frantically hanging ten on the latest, biggest, coolest waves of technology, fatigue inevitably begins to set in. There's an increasing sense of Dj vu - of doing the same thing over and over, with only small improvements to show for it each time. On a bad day, you can feel like you're living the movie <a href="http://www.imdb.com/title/tt0107048/">Groundhog Day</a>, and you've just woken up to the melodic strains of Sonny and Cher singing "I've Got You, Babe". Again.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Don't get me wrong. As a child, I believed that computers would change the world for the better. I still believe computers <i>are</i> changing the world for the better. But that doesn't mean we should accept them unquestioningly into our lives, either. Software developers are almost by definition technologists. So we love this stuff. To us, technology is its own reward. But sometimes it's healthy, even for us technologists, to push back and ask hard questions about whether a particular technology is making our lives better-- or worse. For every single Tivo or iPod, there are hundreds of also-ran <a href="http://en.wikipedia.org/wiki/Microsoft_Bob">Microsoft Bobs</a> and <a href="http://www.howstuffworks.com/internet-odor1.htm">iSmells</a>. People found entire careers on the shifting sands of technology, often on <a href="http://www.computerworld.com/action/article.do?command=printArticleBasic&amp;articleId=9020942">technologies that become utterly obsolete</a>. It's easy to make the wrong choice, and devilishly hard to predict what will still matter ten years from now.
</p>
<p>
Instead of investing so much time in technology, <a href="http://www.west-wind.com/weblog/posts/106053.aspx">as Rick Strahl points out</a>, why not invest in the one technology <i>guaranteed</i> to pay dividends -- ourselves?
</p>
<p>
</p>
<blockquote>
Is your quality of life really better because of the gadgetry? Cell phones are bringing connectivity to us anywhere and everywhere. Good because you can be in contact whenever necessary. But bad because you can in fact be in contact anywhere and everywhere. It takes all sorts of self-constraint to implement the 'just say NO' policy on cell phones and turn them off. Always on, always connected, always surrounded by the constant media buzzsaw. When's the last time you connected with -- oh I don't know -- yourself? Or nature?
</blockquote>
<p>
A similar sentiment is echoed by a technology worker in this <a href="http://sfgate.com/cgi-bin/article.cgi?file=/c/a/2007/06/30/MNGSCQOVND1.DTL">recent San Francisco Chronicle article</a>; don't neglect the human beings behind all these computers.
</p>
<p>
</p>
<blockquote>
Ray Carlson, 46, of Hayward worked as a help desk analyst for software companies and found that "technology for its own sake" was the unquestioned workplace edict. "There was always a constant learning curve that could only be fully ascended by those whose first love was technology," he said. "One had to be willing to allow one's career to run roughshod over any sane boundaries between work and home. People bragged about how many hours they worked and that they had no life outside of work."
<p>
In retrospect, he said, "The dot-com bust was the best thing that ever happened to me up to that point. It caused me to recognize that people, not machines, are my passion.
</p>
</blockquote>
<p>
Perhaps the original purveyor of this "tune in, turn off, and drop out" policy is <a href="http://en.wikipedia.org/wiki/Clifford_Stoll">Cliff Stoll</a>. His book <a href="http://www.amazon.com/exec/obidos/ASIN/0385419945/codihorr-20">Silicon Snake Oil</a> dates back to 1996, the veritable dark ages of the internet. He followed it up in 1999 with <a href="http://www.amazon.com/exec/obidos/ASIN/0385489757/codihorr-20">High Tech Heretic: Why Computers Don't Belong in the Classroom and Other Reflections by a Computer Contrarian</a>. Lest you think Mr. Stoll is some kind of computer hating luddite, consider that he's an astronomer and a hard-core UNIX hacker from <i>way</i> back. I remember reading excerpts from his book <a href="http://www.amazon.com/exec/obidos/ASIN/1416507787/codihorr-20">The Cuckoo's Egg</a> in Byte. It's a gripping narrative of Mr. Stoll tracking a wily KGB hacker who infiltrated the Lawrence Berkeley Labs systems-- along with hundreds of other military and education sites-- in the mid 1980s.
</p>
<p>
Mr. Stoll's reservations are based on extensive use of the internet, all the way back to its formative years; he's been online since 1976. Familiarity, in this case, breeds contempt. You can get a sense of Stoll's position in <a href="http://findarticles.com/p/articles/mi_m4422/is_n6_v13/ai_18515699/pg_1">this 1996 interview</a>:
</p>
<p>
</p>
<blockquote>
One of the lies of the Internet is that it is an information superhighway and that we need lots more information. But I have never met anyone standing on a street corner, sign in hand, saying we need more information. Just the opposite, many of us, especially those of us working in technical fields, say, "I've got all the information I need. Give me less, but give me higher quality information." And that's what's missing from the Internet, quality. When it doesn't cost anything to post the stuff, people naturally post anything they wish. As a result, when I need quality information, I turn to that which is published on paper for the obvious reason that it costs money to publish on paper. Because of that, there is a built-in filter. They are called editors. Because it costs money, they will only allow that which has quality content. So when I want quality, I look on a piece of paper. I look at that which has been edited. And that's what is grossly and desperately missing from the World Wide Web: editors, critics, reviewers, reporters.
<p>
The answer to me is self-evident. It's economic. You get what you pay for. When it's cheap or free to publish something on the World Wide Web, you will naturally publish that which costs the least, has the least and has the least economic value. If you have a catalog or parts list, you put it online. When you have something you want people to study and think hard about, you'll put it on paper. Quality writing takes time. Somebody who puts time and money and effort into it... are they going to give it away for free? Maybe, but I doubt it.
</p>
</blockquote>
<p>
Some of his criticisms are prescient. Still, I don't think the internet is anywhere near as destructive and devoid of value today as Mr. Stoll imagined it would be ten years ago. If anything, quite the opposite. But it's not the specific criticisms that matter; it's his spirit of healthy skepticism that I admire most:
</p>
<p>
</p>
<blockquote>
This much is certain: Unless we debate these questions in public, we move blindly. We listen to some cyberguru who says this is the way the future is, close your eyes and trust me. I don't believe in gurus. I believe in skepticism, in discussion, in public debate. <b>It's our responsibility as citizens, as technologists, to debate where this stuff is likely to go and to ask difficult questions.</b>
</blockquote>
<p>
Too often, we get so heads-down in the digital rat race that we forget to get off the treadmill for a moment and ask those hard questions. We lose perspective and don't bother questioning our assumptions. We forget to take time out to <i>be analog</i> for a little while. As a person who all-too-willingly spends nearly all his waking life in front of a computer* It might be a little disingenuous for me to talk about <b>using technology in moderation</b>. But I think that's exactly what the doctor ordered: <i>moderation in all things, including moderation.</i> The analog world is an essential part of a balanced digital information diet.
</p>
<p>
Now if you'll excuse me, I have to go check my email.
</p>
<p>
* I spend the remaining time <i>dreaming</i> about computers.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-technology-backlash/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Game Development Postmortems ]]></title>
<link>https://blog.codinghorror.com/game-development-postmortems/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've written about <a href="http://www.codinghorror.com/blog/archives/000736.html">the value of project postmortems before</a>. Still, getting a project postmortem going (or, if you prefer your terminology a bit less morbid, a project retrospective) can be a daunting proposition. <a href="http://www.gdmag.com/postmort.htm">Game Developer Magazine's postmortem objectives</a> offers a helpful template for conducting a postmortem yourself:
</p>
<p>
</p>
<blockquote>
The bulk of the [postmortem] should revolve around the "5 wrongs, 5 rights" concept:
<p>
<b>Explain what 5 goals, features or aspects of the project went off without a hitch or better than planned.</b> Were there any phases of development that you thought would be much harder than you had planned? Did a new programmer come on the team and inject great ideas or brilliant programming ability into the effort? Did a new technology become widely adopted by consumers that solved a particularly thorny development problem? Did new development tools become available that let you add better graphics or sound? Did you save money in certain ways you hadn't expected? Cut days/weeks/months off the schedule in some way you hadn't expected to? Did the marketing or PR team get some outstanding preview coverage in a consumer magazine?
</p>
<p>
<b>Explain what 5 goals, features or aspects of the project were problematic or failed completely.</b> Did the lead programmer leave the company halfway throughout the project? Did adapting to new technologies (for example, MMX, DirectX, a new graphics library or AI algorithm) create unanticipated problems for the developers? Did your development tools let you down in some way or not live up to expectations? Did hidden costs creep into the project, and if so, where did they come from? Did the schedule slip for some reason? Was the configuration testing or beta testing cycle problematic for some reason? Did features get axed because of scheduling pressures? Did the lead programmer quit? Did the marketing or PR team misrepresent the game to the public, causing false hopes? Be specific in this regard -- postmortems that accentuate the "what went right" and sugar coat the "what went wrong" sections are dismissed by readers and won't be accepted by our edit staff. Be honest, that's all we are asking.
</p>
</blockquote>
<p>
These postmortems are deemed <b>so significant to other game developers that they're often the cover story on the magazine</b>. I think that's <i>exactly</i> the priority level postmortems should have; if you're not <a href="http://www.codinghorror.com/blog/archives/000889.html">learning from your mistakes</a>, or even better, learning from other people's mistakes, then your next project will have a rocky future at best.
</p>
<p>
<a href="http://www.gdmag.com/archive/feb06.htm"><img alt="image placeholder" >
</p>
<p>
Game Developer Magazine isn't available online without subscribing, but many of the postmortems from the magazine are compiled in the book <a href="http://www.amazon.com/exec/obidos/ASIN/1578202140/codihorr-20">Postmortems from Game Developer: Insights from the Developers of Unreal Tournament, Black and White, Age of Empires, and Other Top-Selling Games</a>.
</p>
<p>
However, <a href="http://gamasutra.com">Gamasutra</a>, another magazine for game developers, does <a href="http://gamasutra.com/php-bin/article_display.php?category=5">post its postmortems online</a>. As I've mentioned before, <a href="http://www.codinghorror.com/blog/archives/000456.html">one of my very favorite postmortems is for Trespasser</a>, one of the most notorious failures in PC gaming history. But it's instructive to soak in the successes as well as gawk at the trainwrecks. Here are a few Gamasutra postmortems I recommend (registration required):
</p>
<p>
</p>
<ul>
<li>Bungie's <a href="http://www.gamasutra.com/features/19980731/regier_01.htm">Myth: The Fallen Lords</a>
</li>
<li>Looking Glass Studio's <a href="http://www.gamasutra.com/features/19990709/thief_01.htm">Thief: The Dark Project</a>
</li>
<li>Sierra's <a href="http://www.gamasutra.com/features/20000609/reinhart_01.htm">SWAT3 Close Quarters Battle</a>
</li>
<li>Ion Storm's <a href="http://www.gamasutra.com/features/20001206/spector_01.htm">Deus Ex</a>
</li>
<li>Lionhead Studios' <a href="http://www.gamasutra.com/features/20010613/molyneux_01.htm">Black &amp; White</a>
</li>
<li>Bohemia Interactive's <a href="http://www.gamasutra.com/features/20011219/spanel_01.htm">Operation Flashpoint</a>
</li>
<li>Stardock's <a href="http://www.gamasutra.com/features/20030507/wardell_01.shtml">Galactic Civilizations</a>
</li>
<li>Peter Stock's <a href="http://gamasutra.com/features/20060619/stock_01.shtml">Armadillo Run</a>
</li>
</ul>
<p>
All the postmortems are worthwhile, and you'll surely recognize a lot of the pitfalls and triumphs they describe. Even if you don't care a whit about gaming, it's instructive to read game development postmortems because <b>game development is such a pressure cooker</b>. It's incredibly challenging software engineering, with unclear goals (eg, "fun") under intense deadlines. Every project pathology you're likely to see on your software project has probably already materialized on one or more of these games.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/game-development-postmortems/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Better Image Resizing ]]></title>
<link>https://blog.codinghorror.com/better-image-resizing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In a previous post, I <a href="http://www.codinghorror.com/blog/archives/000367.html">examined the difference between bilinear and bicubic image resizing techniques</a>. Those are the two options available in most graphics programs for resizing an image.</p>
<p><img alt="image placeholder" >
<p>After some experimentation, I came up with these rules of thumb:</p>
<ul>
<li>When making an image <strong>smaller, use bicubic</strong>, which has a natural <em>sharpening</em> effect. You want to emphasize the data that remains in the new, smaller image after discarding all that extra detail from the original image. </li>
<li>When making an image <strong>larger, use bilinear</strong>, which has a natural <em>smoothing</em> effect. You want to blend over the interpolated fake detail in the new, larger image that never existed in the original image. </li>
</ul>
<p>Of course, there are plenty of conditions that might make you want to choose one method over the other, but I think these are reasonable guidelines to start with.</p>
<p>What I didn't realize when I wrote the original article is that <strong>there are other, more advanced resizing algorithms available</strong>.  Some are specific to particular kinds of images, such as the <a href="http://en.wikipedia.org/wiki/2xSaI">2xSAI</a> algorithm which works on pixel art. Compare this shot of <a href="http://www.codinghorror.com/blog/images/mario_wario_pixel.gif">Mario vs. Wario using pixel resizing</a>, and <a href="http://www.codinghorror.com/blog/images/mario_wario_2xsal.png">the same shot using 2xSAI resizing</a>. It's a dramatic difference, especially since traditional bilinear and bicubic upsizing methods degenerate into a giant blur on pixel art.</p>
<p>Supposedly, one of the best image resizing algorithms on the market is <a href="http://www.ononesoftware.com/detail.php?prodLine_id=2">Genuine Fractals</a>. The web site boasts that you can use its <strong>fractal-based resizing algorithm</strong> to <em>"enlarge your images over 1000% with no loss in image quality"</em>. It's probably pure marketing hyperbole, but I was still intrigued. Bilinear and Bicubic are decent, but there has to be room for improvement in there somewhere. I downloaded a trial version of the tool (which requires Photoshop Elements, or Photoshop CS) and gave it a shot.</p>
<p>I took the <a href="http://en.wikipedia.org/wiki/Lenna">the reference Lena image</a> and blew it up 500%.</p>
<p>Here's a closeup of the results using <strong>Bicubic Sharper</strong>:</p>
<p><img alt="image placeholder" >
<p>Here's the same closeup using <strong>Genuine Fractals</strong>:</p>
<p><img alt="image placeholder" >
<p>Bicubic wouldn't normally be my choice here, but I chose it because it's technically the most advanced method, and it produces the results closest to the effect that the fractal resizing delivers. Still, <strong>the fractal algorithm comes out way ahead</strong>; you can't see any pixel resize artifacts in the enlarged image, and the edges are sharp and well defined. It does start to bear an unfortunate resemblance to a watercolor drawing filter, but arbitrarily resizing images to 5 times their original size will always involve tradeoffs of some kind.</p>
<p>Bicubic and bilinear are well understood image resizing algorithms, and they're "good enough" for most image resizing chores. That's why they are provided out of the box in almost all graphics applications and graphics libraries. There's an <a href="http://www.codeproject.com/csharp/imgresizoutperfgdiplus.asp">outstanding article on CodeProject</a> which digs into advanced image resizing algorithms with actual C# code for some spline and fractal resizing algorithms. But before you begin resizing images, consider whether you <em>need</em> those advanced algorithms.</p>
<p><strong>Reducing images</strong> is a completely safe and rational operation. You're simply reducing precision and resolution by discarding information. Make the image as small as you want, and you have complete fidelity-- within the bounds of the number of pixels you've allowed. You'll get good results no matter which algorithm you pick. (Well, unless you pick the naive Pixel Resize or Nearest Neighbor algorithms.)</p>
<p><strong>Enlarging images</strong> is risky. Beyond a certain point, enlarging images is a fool's errand; you can't magically synthesize an infinite number of new pixels out of thin air. And interpolated pixels are never as good as real pixels. That's why it's more than a little artificial to upsize the 512x512 Lena image by 500%. It'd be smarter to find a higher resolution scan or picture of whatever you need* than it would be to upsize it in software.</p>
<p>But <strong>when you can't avoid enlarging an image</strong>, that's when it pays to know the tradeoffs between bicubic, bilinear, and more advanced resizing algorithms. At least arm yourself with enough knowledge to pick the best of the bad options you have.</p>
<p>* e.g., if I really needed the Lena image that large, I'm better off hunting down old copies of Playboy and scanning them myself. Or at least that's what I tell my wife...</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2007-07-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/better-image-resizing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Defining Open Source ]]></title>
<link>https://blog.codinghorror.com/defining-open-source/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>As I mentioned two weeks ago, my plan is to <a href="http://www.codinghorror.com/blog/archives/000894.html">contribute $10,000 to the .NET open source ecosystem</a>. $5,000 from me, and a matching donation of $5,000 from Microsoft.</p>
<p>There's only two ground rules so far:</p>
<ol>
<li>The project must be written in <strong>.NET managed code</strong>. </li>
<li>The project must be <strong>open source</strong>. </li>
</ol>
<p>The first rule is simple enough; although mono and subversion are great open source projects, they aren't written in .NET managed code, and are therefore totally ineligible. But number two is where I hit a roadblock: <strong>how do you tell if something that calls itself "open source" is <em>really</em> open source?</strong> Many projects think they are-- or at least some users may <em>think</em> they are-- but they really aren't.</p>
<p>NDoc is an example of exactly this kind of tricky misunderstanding, per a comment <a href="http://www.kynosarges.de/">Chris Nahr</a> left on <a href="http://www.codinghorror.com/blog/archives/000649.html">a related post</a>:</p>
<p> </p>
<blockquote>If [other people contributing] was his wish he kept it to himself. The source code for NDoc 2.0 was never released -- Kevin claimed licensing issues as the reason. No one else could contribute, except by mailing him bug reports on his (binary-only) alpha builds.
<p>Kevin is now supposedly passing on the Sourceforge administration of the project to two other guys; I hope we'll finally see a public source code release again so that willing engineers actually <em>can</em> contribute once again.</p>
</blockquote>
<p>I want to avoid these kinds of problems.</p>
<p>To that end, here are a few criteria we need to evaluate for each nominated project, to ensure that they're not just paying lip service to "open source":</p>
<p> </p>
<ol>
<li>
<strong>The project must use <a href="http://en.wikipedia.org/wiki/Open-source_license">an OSI approved license</a>,</strong> or the permissive or reciprocal <a href="http://www.microsoft.com/resources/sharedsource/licensingbasics/sharedsourcelicenses.mspx">shared source licenses</a> from Microsoft. (I have to include that rider because part of the OSI's pissing match with Microsoft is not formally recognizing Microsoft's licenses, even though they're absolutely in the spirit of open source.) <a href="http://www.codinghorror.com/blog/archives/000833.html">Pick a license, any license!</a> If your project does not have a license, or if you fail to make it stupid easy for us to determine what license your project uses... your project is ineligible.
<p> </p>
</li>
<li>
<strong>The project must use a commonly available method of public source control</strong>. SourceForge, CodePlex, Google Code, whatever. Other developers should be able to retrieve the read-only public code using a source control tool, and potentially check in changes to the codebase if granted appropriate permissions. If the only way to get to the source code is via HTTP download of a ZIP file... your project is ineligible.
<p> </p>
</li>
<li>
<strong>The project must provide public evidence that it accepts and encourages code contributions from the outside world</strong>. Is a project truly open source if it only has <em>one</em> developer? Is a project truly open source if it has a cabal of three developers who summarily ignore all outside suggestions and contributions? All I'm looking for here is evidence of some kind of community. It doesn't have to be a large one, necessarily, but it has to be there. The spirit of open source is active community development. If you can't show a decent history of checkins from a reasonable variety of contributors... your project is ineligible. </li>
<p> </p>
<p> </p>
</ol>
<p>This maps fairly well to <a href="http://www.gnu.org/philosophy/free-sw.html">the "four freedoms" of the Free Software Foundation</a>:</p>
<p> </p>
<ul>
<li>The freedom to run the program, for any purpose. </li>
<li>The freedom to study how the program works, and adapt it to your needs. </li>
<li>The freedom to redistribute copies so you can help your neighbor. </li>
<li>The freedom to improve the program, and release your improvements to the public, so that the whole community benefits. </li>
</ul>
<p>So now the vetting process begins.</p>
<p><strong>I need your help to figure out how many of the projects nominated in the comments actually meet the criteria I've outlined</strong>. I've put <a href="http://spreadsheets.google.com/pub?key=pKxDW35algYebfs8nssTjIQ">a read-only spreadsheet online via Google documents</a> which contains all the projects people nominated <a href="http://www.codinghorror.com/blog/archives/000894.html">in the comments to my original post</a>. But I can't seem to make it editable by the world. I can only invite people in as "collaborators". Supposedly <a href="http://spreadsheets.google.com/ccc?key=pKxDW35algYebfs8nssTjIQ&amp;inv=everyone@everywhere.com&amp;t=6408456595839589032&amp;guest">this link allows anyone with a Google account to be a collaborator</a>. Try that first.</p>
<p>Alternately, if there's a better way to collaboratively edit a spreadsheet-like list, I'm open to suggestions!</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2007-07-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/defining-open-source/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
</channel>
</rss>
