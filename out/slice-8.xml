<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title><![CDATA[ Top 25 Most Dangerous Programming Mistakes ]]></title>
<link>https://blog.codinghorror.com/top-25-most-dangerous-programming-mistakes/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I don't usually do news and current events here, but I'm making an exception for the <a href="http://cwe.mitre.org/top25/#Brief">CWE/SANS Top 25 Most Dangerous Programming Errors</a> list. This one is important, and deserves a wide audience, so I'm repeating it here -- along with a brief hand-edited summary of each error.
</p>
<p>
<b>If you work on software in any capacity, at least skim this list.</b> I encourage you to click through for greater detail on anything you're not familiar with, or that piques your interest.
</p>
<p>
</p>
<ol>
<li>
<a href="http://cwe.mitre.org/data/definitions/20.html">Improper Input Validation</a>
<blockquote>
Ensure that your input is valid. If you're expecting a number, it shouldn't contain letters. Nor should the price of a new car be allowed to be a dollar. Incorrect input validation can lead to vulnerabilities when attackers can modify their inputs in unexpected ways. Many of today's most common vulnerabilities can be eliminated, or at least reduced, with strict input validation.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/116.html">Improper Encoding or Escaping of Output</a>
<blockquote>
Insufficient output encoding is at the root of most injection-based attacks. An attacker can modify the commands that you intend to send to other components, possibly leading to a complete compromise of your application - not to mention exposing the other components to exploits that the attacker would not be able to launch directly. When your program generates outputs to other components in the form of structured messages such as queries or requests, be sure to separate control information and metadata from the actual data.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/89.html">Failure to Preserve SQL Query Structure</a> (aka 'SQL Injection')
<blockquote>
If attackers can influence the SQL that you send to your database, they can modify the queries to steal, corrupt, or otherwise change your underlying data. If you use SQL queries in security controls such as authentication, attackers could alter the logic of those queries to bypass security.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/79.html">Failure to Preserve Web Page Structure</a> (aka 'Cross-site Scripting')
<blockquote>
Cross-site scripting (XSS) is a result of combining the stateless nature of HTTP, the mixture of data and script in HTML, lots of data passing between web sites, diverse encoding schemes, and feature-rich web browsers. If you're not careful, attackers can inject Javascript or other browser-executable content into a web page that your application generates. Your web page is then accessed by other users, whose browsers execute that malicious script as if it came from you -- because, after all, it <i>did</i> come from you! Suddenly, your web site is serving code that you didn't write. The attacker can use a variety of techniques to get the input directly into your server, or use an unwitting victim as the middle man.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/78.html">Failure to Preserve OS Command Structure</a> (aka 'OS Command Injection')
<blockquote>
Your software acts as a bridge between an outsider on the network and the internals of your operating system. When you invoke another program on the operating system, and you allow untrusted inputs to be fed into the command string, you are inviting attackers into your operating system.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/319.html">Cleartext Transmission of Sensitive Information</a>
<blockquote>
Information sent across a network crosses many different nodes in transit to its final destination. If your software sends sensitive, private data or authentication credentials, beware: attackers could sniff them right off the wire. All they need to do is control one node along the path to the final destination, any node within the same networks of those transit nodes, or plug into an available interface. Obfuscating traffic using schemes like Base64 and URL encoding offers no protection.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/352.html">Cross-Site Request Forgery (CSRF)</a>
<blockquote>
Cross-site request forgery is like accepting a package from a stranger -- except the attacker tricks a user into activating a HTTP request "package" that goes to your site. The user might not even be aware that the request is being sent, but once the request gets to your server, it looks as if it came from the user -- not the attacker. The attacker has masqueraded as a legitimate user and gained all the potential access that the user has. This is especially handy when the user has administrator privileges, resulting in a complete compromise of your application's functionality.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/362.html">Race Condition</a>
<blockquote>
A race condition involves multiple processes in which the attacker has full control over one process; the attacker exploits the process to create chaos, collisions, or errors. Data corruption and denial of service are the norm. The impact can be local or global, depending on what the race condition affects - such as state variables or security logic - and whether it occurs within multiple threads, processes, or systems.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/209.html">Error Message Information Leak</a>
<blockquote>
Chatty error messages can disclose secrets to any attacker who misuses your software. The secrets could cover a wide range of valuable data, including personally identifiable information (PII), authentication credentials, and server configuration. They might seem like harmless secrets useful to your users and admins, such as the full installation path of your software -- but even these little secrets can greatly simplify a more concerted attack.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/119.html">Failure to Constrain Operations within the Bounds of a Memory Buffer</a>
<blockquote>
The scourge of C applications for decades, buffer overflows have been remarkably resistant to elimination. Attack and detection techniques continue to improve, and today's buffer overflow variants aren't always obvious at first or even second glance. You may think that you're completely immune to buffer overflows because you write your code in higher-level languages instead of C. But what is your favorite "safe" language's interpreter written in? What about the native code you call? What languages are the operating system API's written in? How about the software that runs Internet infrastructure?
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/642.html">External Control of Critical State Data</a>
<blockquote>
If you store user state data in a place where an attacker can modify it, this reduces the overhead for a successful compromise. Data could be stored in configuration files, profiles, cookies, hidden form fields, environment variables, registry keys, or other locations, all of which can be modified by an attacker. In stateless protocols such as HTTP, some form of user state information must be captured in each request, so it is exposed to an attacker out of necessity. If you perform any security-critical operations based on this data (such as stating that the user is an administrator), then you can bet that somebody will modify the data in order to trick your application.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/73.html">External Control of File Name or Path</a>
<blockquote>
When you use an outsider's input while constructing a filename, the resulting path could point outside of the intended directory. An attacker could combine multiple ".." or similar sequences to cause the operating system to navigate out of the restricted directory. Other file-related attacks are simplified by external control of a filename, such as symbolic link following, which causes your application to read or modify files that the attacker can't access directly. The same applies if your program is running with raised privileges and it accepts filenames as input. Similar rules apply to URLs and allowing an outsider to specify arbitrary URLs.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/426.html">Untrusted Search Path</a>
<blockquote>
Your software depends on you, or its environment, to provide a search path (or working path) to find critical resources like code libraries or configuration files. If the search path is under attacker control, then the attacker can modify it to point to resources of the attacker's choosing.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/94.html">Failure to Control Generation of Code</a> (aka 'Code Injection')
<blockquote>
While it's tough to deny the sexiness of dynamically-generated code, attackers find it equally appealing. It becomes a serious vulnerability when your code is directly callable by unauthorized parties, if external inputs can affect which code gets executed, or if those inputs are fed directly into the code itself.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/494.html">Download of Code Without Integrity Check</a>
<blockquote>
If you download code and execute it, you're trusting that the source of that code isn't malicious. But attackers can modify that code before it reaches you. They can hack the download site, impersonate it with DNS spoofing or cache poisoning, convince the system to redirect to a different site, or even modify the code in transit as it crosses the network. This scenario even applies to cases in which your <i>own</i> product downloads and installs updates.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/404.html">Improper Resource Shutdown or Release</a>
<blockquote>
When your system resources have reached their end-of-life, you dispose of them: memory, files, cookies, data structures, sessions, communication pipes, and so on. Attackers can exploit improper shutdown to maintain control over those resources well after you thought you got rid of them. Attackers may sift through the disposted items, looking for sensitive data. They could also potentially reuse those resources.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/665.html">Improper Initialization</a>
<blockquote>
If you don't properly initialize your data and variables, an attacker might be able to do the initialization for you, or extract sensitive information that remains from previous sessions. If those variables are used in security-critical operations, such as making an authentication decision, they could be modified to bypass your security. This is most prevalent in obscure errors or conditions that cause your code to inadvertently skip initialization.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/682.html">Incorrect Calculation</a>
<blockquote>
When attackers have control over inputs to numeric calculations, math errors can have security consequences. It might cause you to allocate far more resources than you intended - or far fewer. It could violate business logic (a calculation that produces a negative price), or cause denial of service (a divide-by-zero that triggers a program crash).
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/285.html">Improper Access Control</a> (Authorization)
<blockquote>
If you don't ensure that your software's users are only doing what they're allowed to, then attackers will try to exploit your improper authorization and exercise that unauthorized functionality.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/327.html">Use of a Broken or Risky Cryptographic Algorithm</a>
<blockquote>
Grow-your-own cryptography is a welcome sight to attackers. Cryptography is hard. If brilliant mathematicians and computer scientists worldwide can't get it right -- and they're regularly obsoleting their own techniques -- then neither can you.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/259.html">Hard-Coded Password</a>
<blockquote>
Hard-coding a secret account and password into your software is extremely convenient -- for skilled reverse engineers. If the password is the same across all your software, then every customer becomes vulnerable when that password inevitably becomes known. And because it's hard-coded, it's a huge pain to fix.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/732.html">Insecure Permission Assignment for Critical Resource</a>
<blockquote>
Beware critical programs, data stores, or configuration files with default world-readable permissions. While this issue might not be considered during implementation or design, it should be. Don't require your customers to secure your software for you! Try to be secure by default, out of the box.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/330.html">Use of Insufficiently Random Values</a>
<blockquote>
You may depend on randomness without even knowing it, such as when generating session IDs or temporary filenames. Pseudo-Random Number Generators (PRNG) are commonly used, but a variety of things can go wrong. Once an attacker can determine which algorithm is being used, he can guess the next random number often enough to launch a successful attack after a relatively small number of tries.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/250.html">Execution with Unnecessary Privileges</a>
<blockquote>
Your software may need special privileges to perform certain operations; wielding those privileges longer than necessary is risky. When running with extra privileges, your application has access to resources that the application's user can't directly reach. Whenever you launch a separate program with elevated privileges, attackers can potentially exploit those privileges.
</blockquote>
</li>
<li>
<a href="http://cwe.mitre.org/data/definitions/602.html">Client-Side Enforcement of Server-Side Security</a>
<blockquote>
Don't trust the client to perform security checks on behalf of your server. Attackers can reverse engineer your client and write their own custom clients. The consequences will vary depending on what your security checks are protecting, but some of the more common targets are authentication, authorization, and input validation.
</blockquote>
</li>
</ol>
<p>
Of course there's nothing truly <i>new</i> here; I essentially went over the same basic list in <a href="http://www.codinghorror.com/blog/archives/000841.html">Sins of Software Security</a> almost two years ago. The only difference is the relative priorities, as web applications start to dominate mainstream computing.
</p>
<p>
This list of software security mistakes serves the same purpose as McConnell's <a href="http://www.codinghorror.com/blog/archives/000889.html">list of classic development mistakes</a>: to raise awareness. A surprisingly large part of success is recognizing the most common mistakes and failure modes. So you can -- at least in theory -- realize when your project is slipping into one of them. <b>Ignorance is the biggest software project killer of them all.</b>
</p>
<p>
Heck, even if you <i>are</i> aware of these security mistakes, you might end up committing them anyway. I know <a href="http://www.codinghorror.com/blog/archives/001167.html">I have</a>.
</p>
<p>
Have you?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/top-25-most-dangerous-programming-mistakes/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Die, You Gravy Sucking Pig Dog! ]]></title>
<link>https://blog.codinghorror.com/die-you-gravy-sucking-pig-dog/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In the C programming language, you're regularly forced to deal with the painful, dangerous concepts of pointers and explicit memory allocation.
</p>
<p>
</p>
<pre>
b1 = (double *)malloc(m*sizeof(double));
</pre>
<p>
In modern garbage collected programming languages, life is much simpler; you simply new up whatever object or variable you need.
</p>
<p>
</p>
<pre>
Double[] b1 = new Double[m];
</pre>
<p>
Use your objects, and just walk away when you're done. The garbage collector will cruise by periodically, and when he sees stuff you're not using any more, he'll clean up behind you and deal with all that nasty pointer and memory allocation stuff on your behalf. It's totally automatic.
</p>
<p>
Pretty awesome, right? I'd wager the majority of programmers alive today have never once worried about <code>malloc()</code>. I call this progress, <a href="http://www.jwz.org/doc/gc.html">as does Jamie Zawinski</a>:
</p>
<p>
</p>
<blockquote>
Based on my experience using both kinds of languages, for years at a stretch, I claim that a good garbage collector always beats doing explicit malloc/free in both computational efficiency and programmer time.
<p>
However, I also claim that, because of the amount of programmer time that is saved by using GC rather than explicit malloc/free, as well as the dramatic reduction in hard-to-debug storage-management problems, even using a mediocre garbage collector will still result in your ending up with better software faster.
</p>
<p>
Most of the time, throwing memory and CPU at the problem is still <a href="http://www.codinghorror.com/blog/archives/001198.html">cheaper than throwing programmer time at the problem</a>, even when you multiply the CPUs/memory by the number of users. This isn't true all the time, but it's probably true more often than you think, because <a href="http://www.codinghorror.com/blog/archives/001046.html">Worse is Better</a>.
</p>
</blockquote>
<p>
But even for programmers who have enjoyed automatic garbage collection their whole careers, there are still some.. oddities. See if you can spot one here:
</p>
<p>
</p>
<pre>
sqlConnection.Close();
sqlConnection.Dispose();
sqlConnection = null;
</pre>
<p>
That is one hellaciously <i>closed</i> database connection. Why don't you take it out back and shoot it, while you're at it?
</p>
<p>
Even with your friendly neighborhood garbage collector making regular rounds on commodity desktops/servers where many gigabytes of main memory are commonplace, there are still times when you need to release precious resources <i>right now</i>. Not at some unspecified point in the future, whenever the GC gets around to it. Like, say, a database connection. Sure, your database server may be powerful, but it doesn't support an infinitely large number of concurrent connections, either.
</p>
<p>
The confusing choice between setting an object to <code>null</code> and calling the <code>Dispose</code> method doesn't help matters any. Is it even clear what state the connection is in after <code>Close</code> is called? Could the connection be reused at that point?
</p>
<p>
Personally, <b>I view explicit disposal as more of an optimization than anything else</b>, but it can be a pretty important optimization on a heavily loaded webserver, or a performance intensive desktop application plowing through gigabytes of data.
</p>
<p>
Of course, your average obsessive-compulsive developer sees that he's dealing with a semi-precious system resource, and immediately takes matters into his own hands, because <a href="http://www.codinghorror.com/blog/archives/000031.html">he can do a better job than the garbage collector</a>. K. Scott Allen proposes a solution that might mollify both camps in <a href="http://odetocode.com/Blogs/scott/archive/2004/11/07/605.aspx">Disposal Anxiety</a>:
</p>
<p>
</p>
<blockquote>
What the IDisposable interface needs is a method that promotes self-efficacy in a developer. A method name that can stir up primal urges as the developer types. What we need is a method like the one in BSD's <a href="http://www.freebsd.org/cgi/cvsweb.cgi/~checkout~/src/sbin/shutdown/shutdown.c?rev=1.26&amp;content-type=text/plain">shutdown.c</a> module.
<p>
</p>
<pre>
die_you_gravy_sucking_pig_dog()
{
char *empty_environ[] = { NULL };
syslog(LOG_NOTICE, "%s by %s: %s",
doreboot ? "reboot" : dohalt ? "halt" : dopower ? "power-down" :
"shutdown", whom, mbuf);
(void)sleep(2);
(void)printf("rnSystem shutdown time has arrived�07�07rn");
if (killflg) {
(void)printf("rbut you'll have to do it yourselfrn");
exit(0);
}
</pre>
<p>
Now, I know this function was written back in the days when steam engines still ruled the world, but we could modernize the function by applying some .NET naming standards.
</p>
<p>
</p>
<pre>sqlConnection.<b>DieYouGravySuckingPigDog()</b>;</pre>
<p>
Can you feel the passion behind this statement? This statement carries the emotion that is hard to find in today's code. I hope you'll support this proposal. Good people will be able to sleep at night once again.
</p>
</blockquote>
<p>
So the next time <i>you</i> feel anxious about letting objects fall out of scope, remember: <b>you could always terminate them with extreme prejudice</b>, if you feel it's necessary.
</p>
<p>
But it probably isn't.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/die-you-gravy-sucking-pig-dog/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Two Types of Browser Zoom ]]></title>
<link>https://blog.codinghorror.com/the-two-types-of-browser-zoom/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>From the dawn of the web – at least since Netscape Navigator 4.x – it has been possible to resize the text on a web page. This is typically done through the View menu.</p>
<p><img alt="image placeholder" >
<p>This was fine in the early, primitive days of the web, when page layouts were simple and unsophisticated. Want the font to be three times larger? No problem! Pump it up until your eyes bleed; you're unlikely to break the design, because there's precious little <em>design</em> at all.</p>
<p><img alt="image placeholder" >
<p>But this was a time long before the web had become a platform for <a href="http://www.codinghorror.com/blog/archives/000883.html">full-blown applications</a>, with complex, dense, almost GUI-like designs.</p>
<p>The accepted web design guidance is that you should generally produce web page layouts that work at:</p>
<ol>
<li>the default font size (obviously) </li>
<li>one size <em>below</em> the default font size </li>
<li>one size <em>above</em> the default font size </li>
</ol>
<p>I agree, and you should be testing for this on your own websites. The handy keyboard equivalents in most browsers are:</p>
<p><kbd>Ctrl</kbd> + <kbd>0</kbd>   Reset font size to default</p>
<p><kbd>Ctrl</kbd> + <kbd>+</kbd>   Make font one size larger</p>
<p><kbd>Ctrl</kbd> + <kbd>-</kbd>   Make font one size smaller</p>
<p>(yes, holding down the <kbd>Ctrl</kbd> key and then scrolling your mouse scroll wheel works, too, but <a href="http://www.codinghorror.com/blog/2007/03/going-commando---put-down-the-mouse.html">no real programmer would use that</a>.)</p>
<p>It is important to let the user control their browsing experience. But I think that <strong>the traditional method of font-only browser sizing is a solution whose time has come and gone</strong>. There's a better way. Opera was the first browser to introduce <strong>full page zoom</strong> as an alternative to traditional font sizing, but Firefox 3 is where most people actually experience it. In fact, in Firefox 3, it's the <em>default</em> page sizing mode.</p>
<p><img alt="image placeholder" >
<p>Note that "Zoom Text Only" is unchecked. And for good reason. Compare for yourself. Here's the Digg homepage using old-school Netscape 4.x style font scaling.</p>
<p><strong>Browser Font Scaling: Default</strong></p>
<p><img alt="image placeholder" >
<p><strong>Browser Font Scaling: <span style="color: red;">Size +1</span></strong></p>
<p><img alt="image placeholder" >
<p><strong>Browser Font Scaling: <span style="color: red;">Size +2</span></strong></p>
<p><img alt="image placeholder" >
<p>Digg follows the design rule of thumb I suggested above: it scales to font size +1, but beyond that, all bets are off. With the fonts at +2, the top menu is scrunched, the search box clipped, and the digg numbers are spilling out over the boxes. The "most recent" navigation element has completely disappeared! Now compare this with the newer method of full page zooming:</p>
<p><strong>Browser Full Page Zoom Scaling: Default</strong></p>
<p><img alt="image placeholder" >
<p><strong>Browser Full Page Zoom Scaling: <span style="color: red;">Size +1</span></strong></p>
<p><img alt="image placeholder" >
<p><strong>Browser Full Page Zoom Scaling: <span style="color: red;">Size +2</span></strong></p>
<p><img alt="image placeholder" >
<p>While the page does get wider, the full page zoom method has tremendous advantages:</p>
<ol>
<li>Full page zoom works on almost every web page in the world, with no changes whatsoever by the web designers </li>
<li>Full page zoom scales far, <em>far</em> beyond the +1/-1 sizes that you can reasonably expect from traditional browser font sizing approaches. </li>
</ol>
<p>To prove that full page zoom scales like nobody's business, here's a screenshot I captured of the <a href="http://www.codinghorror.com/blog/images/digg-page-zoom-max-256.png">Digg homepage scaled to fit the entire width of my 1920 x 1080 monitor</a>. In comparison, increasing the fonts beyond +2 results in a jumbled, unreadable mess.</p>
<p>Honestly, I can't see much use for traditional browser font sizing. It's increasingly fragile on today's web. I wish more browsers would take the lead from Firefox 3, and <strong>adopt full page zoom as the new default page sizing method</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-two-types-of-browser-zoom/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Visit With Alan Kay ]]></title>
<link>https://blog.codinghorror.com/a-visit-with-alan-kay/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://en.wikipedia.org/wiki/Alan_Kay">Alan Kay</a> is one of my computing heroes. All this stuff we do every day as programmers? Kay had a hand in inventing a huge swath of it:
</p>
<p>
</p>
<blockquote>
Computer scientist Kay was the leader of the group that invented object-oriented programming, the graphical user interface, 3D computer graphics, and ARPANET, the predecessor of the Internet
</blockquote>
<p>
So as you might imagine, I was pretty thrilled to see he was <a href="http://blog.stackoverflow.com/2009/01/welcome-our-newest-member-alan-kay/">dabbling a little in Stack Overflow</a>. It's difficult to fathom the participation of a legend like Alan in a site for regular programmers. Maybe we should add a <a href="http://en.wikipedia.org/wiki/Turing_Award">Turing Award</a> badge. At least people can't complain that it is unobtainable.
</p>
<p>
Jeff Moser, an avid Stack Overflow user with a an <a href="http://www.moserware.com/">outstanding blog</a> of his own, had the opportunity to meet Alan recently and ask him about it. Jeff gave me permission to reprint his field report here.
</p>
<p>
</p>
<blockquote>
Since I knew I'd be seeing Alan Kay at <a href="http://www.rebootingcomputing.org">Rebooting Computing</a>, I decided to verify his Stack Overflow usage in person. According to Alan, he found the original question using an automated search alert just like Atwood had guessed.
<p>
We then proceeded to discuss how it's sad that identity is still hard online. For example, it's hard to prove if I'm telling the truth here. As for that, the best I can offer is to look at my picture on <a href="http://www.moserware.com/">my blog</a> and compare with this picture from the Summit:
</p>
<p>
<a href="http://www.flickr.com/photos/cglusky/3195351350/in/set-72157612501297914"><img alt="image placeholder" >
</p>
<p>
(Alan is on my right)
</p>
<p>
Alan is a great person to talk to because of his huge experience in the computing field.
</p>
<p>
He's currently working at the <a href="http://vpri.org">Viewpoints Research Institute</a> where they're doing some classic PARC style research of trying to do for software what Moore's Law did for hardware. A decent explanation by Alan Kay himself is <a href="http://irbseminars.intel-research.net/AlanKay.wmv">available here</a> (wmv). For specifics, you might want to check out the recent <a href="http://www.vpri.org/pdf/tr2008003_experimenting.pdf">PhD thesis of Alessandro Warth</a>, one of Alan's students.
</p>
<p>
One of the greatest lessons I've personally learned from Alan is just how important computing history is in order to understand the context of inventions. One of Alan's greatest heroes is J.C.R. Licklider (a.k.a. "Lick"). Our discussions a few months ago led me to read "The Dream Machine" and <a href="http://www.moserware.com/2008/05/who-is-this-licklider-guy.html">write a post about it</a>.
</p>
<p>
A consequence of studying history well is that you'll notice that a ton of the really cool and interesting stuff was developed in the ARPA-&gt;<a href="http://en.wikipedia.org/wiki/Xerox_PARC">PARC</a> days and it's slowed down since. I'd assume that's why he's curious about anything post-PARC's peak days (e.g. 1980+).
</p>
<p>
I'd say that Alan firmly believes that the "Computer Revolution Hasn't Happened Yet" (still) even though he's been talking about it for decades.
</p>
<p>
For example:
</p>
<p>
</p>
<ul>
<li>see his <a href="http://video.google.com/videoplay?docid=-2950949730059754521">'97 talk at OOPSLA</a>.
</li>
<li>and this <a href="http://www.sri.com/engvideos/kay.html">video from last month</a> at the 40 Year Anniversary of Engelbart's <a href="http://www.codinghorror.com/blog/archives/001182.html">"Mother of all Demos"</a>.
</li>
</ul>
<p>
Speculating from discussions, I'd say that the problem he sees is that computers should help us become better thinkers rather than "distracting/entertaining ourselves to death." Alan likes to use the example that our "pop culture" is more concerned with "air guitar" and "Guitar Hero" rather than appreciating genuine beauty and expressiveness of real instruments (even though it takes a bit longer to master). Check out 1:03:40 of <a href="https://admin.adobe.acrobat.com/_a295153/p99875217/">this video from program for the Future</a>. In effect, we're selling our potential short.
</p>
<p>
I think that's my biggest take away from Alan about computing: computers can do so much more than we're using them for now (e.g. provide "a teacher for every learner").
</p>
<p>
Hope this helps provide some context.
</p>
</blockquote>
<p>
Indeed it does, Jeff. If you'd like to get a sense of what Alan is about and the things he's working on, I recommend this <a href="http://queue.acm.org/detail.cfm?id=1039523">Conversation with Alan Kay</a> from the ACM.
</p>
<p>
</p>
<blockquote>
It's not that people are completely stupid, but if there's a big idea and you have deadlines and you have expedience and you have competitors, very likely what you'll do is take a low-pass filter on that idea and implement one part of it and miss what has to be done next. This happens over and over again. If you're using early-binding languages as most people do, rather than late-binding languages, then you really start getting locked in to stuff that you've already done. You can't reformulate things that easily.
<p>
Let's say the adoption of programming languages has very often been somewhat accidental, and the emphasis has very often been on how easy it is to implement the programming language rather than on its actual merits and features. For instance, Basic would never have surfaced because there was always a language better than Basic for that purpose. That language was Joss, which predated Basic and was beautiful. But Basic happened to be on a GE timesharing system that was done by Dartmouth, and when GE decided to franchise that, <b>it started spreading Basic around just because it was there, not because it had any intrinsic merits whatsoever</b>.
</p>
<p>
This happens over and over again. The languages of Niklaus Wirth have spread wildly and widely because he has been one of the most conscientious documenters of languages and one of the earlier ones to do algorithmic languages using p-codes (pseudocodes) -- the same kinds of things that we use. The idea of using those things has a common origin in the hardware of a machine called the Burroughs B5000 from the early 1960s, which the establishment hated.
</p>
</blockquote>
<p>
Any similarity between the above and PHP is, I'm sure, <a href="http://www.codinghorror.com/blog/archives/001119.html">completely coincidental</a>. That sound you're hearing is just <a href="http://www.youtube.com/watch?v=sTUIHK7gHRE">a little bit of history repeating</a>.
</p>
<p>
To me, the quintessential Alan Kay presentation is <a href="http://video.google.com/googleplayer.swf?docId=-533537336174204822">Doing with Images Makes Symbols: Communicating With Computers</a>.
</p>
<p>
<object data="http://video.google.com/googleplayer.swf?docId=-533537336174204822" height="330" type="application/x-shockwave-flash" width="400"><param name="allowScriptAccess" value="never">
<param name="movie" value="http://video.google.com/googleplayer.swf?docId=-533537336174204822">
<param name="quality" value="best">
<param name="bgcolor" value="#ffffff">
<param name="scale" value="noScale">
<param name="wmode" value="window"></object>
</p>
<p>
As the video illustrates, computers are almost secondary to most of Alan's work; that's the true brilliance of it. The real goal is <a href="http://dailykibitz.blogspot.com/2008/08/alan-kay-on-research-into-learning-and.html">teaching and learning</a>. I'm reminded of a comment Andrew Stuart, a veteran software development recruiter, once sent me in email:
</p>
<p>
</p>
<blockquote>
One subtle but interesting observation that I would make - <a href="http://www.codinghorror.com/blog/archives/001054.html">your article</a> points out that <b>"what software developers do best is <i>learn</i>"</b> - this is close to the mark, though I would rearrange the words slightly to <b>"what the best software developers do is <i>learn</i>."</b> Not all software developers learn, but the best ones certainly do.
</blockquote>
<p>
And this, I think, lies at the heart of everything Alan does -- computing not as an end in itself, but as a vehicle for <a href="http://www.codinghorror.com/blog/archives/000895.html">learning how to learn</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-visit-with-alan-kay/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The One Thing Programmers and Musicians Have In Common ]]></title>
<link>https://blog.codinghorror.com/the-one-thing-programmers-and-musicians-have-in-common/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In my <a href="http://www.codinghorror.com/blog/archives/001213.html">previous post</a>, a commenter asked this question:
</p>
<p>
</p>
<blockquote>
So many of the best minds I have met in computing have a love for music. Is it something to do with being able to see beauty in complex numerical systems?
</blockquote>
<p>
I adore music. I have a vast music collection and I love listening to music and exploring new bands and genres I haven't heard. But I have <i>zero</i> musical ability. So it's not really appropriate for me to comment on this. I've read the same observation expressed in many different places. Enough so that <b>I do wonder if there's some kind of relationship between being a musician and being a programmer.</b>
</p>
<p>
For informed opinions, let's turn to programmers who are actually musicians. I thought Rob Birdwell, who left <a href="http://weblogs.asp.net/rbirdwell/archive/2003/11/14/37643.aspx">a single plaintive 2003 blog entry</a> on his programming blog, summarized it well:
</p>
<p>
</p>
<blockquote style="margin-left:0px;">
<ul>
<li>Let's be practical:  musicians become programmers, generally not the other way around, simply because those gigs actually pay the bills.
</li>
<li>Creating music and software are simultaneously collaborative and individualistic undertakings.
</li>
<li>Musicians, regardless of era, are generally technically engaged. The instruments themselves (the hardware) often interface with other devices (amps, mixers, mutes) to achieve different sounds.  Composers often deal with an array of technologies to get their music written, performed and/or produced.
</li>
<li>Music is an abstract medium - the printed note requires interpretation and execution.  Like the written line of code, there is often much more than meets the eye.
</li>
<li>Music is a form of self-expression.  Many programmers, often to the dismay of corporate managers, try to express themselves through code.
</li>
<li>One famous music educator, Dick Grove, once said that composers/musicians often like to solve puzzles.  (Dick Grove was very computer saavy - although I'm not sure he wrote code, I wouldn't doubt his ability to do so.)
</li>
</ul>
</blockquote>
<p>
Rob is clearly a guy with feet in both worlds, although music is obviously winning. Rob <a href="http://www.birdwellmusic.com/Blogger/">has an active music blog</a> with way more than one entry. There are even some programming tidbits mixed in here and there.
</p>
<p>
I noticed one comment on Rob's programming blog entry from <a href="http://www.franklins.net/carl.aspx">Carl Franklin</a>, who <i>also</i> happens to be an amazing musician. He can prove it, too: <a href="http://www.youtube.com/watch?v=-yUHV9hGAdg&amp;fmt=18">here's Carl performing the song Jungle Love as a one man band</a>. Incredible! Carl also sees parallels between musicians and programmers:
</p>
<p>
</p>
<blockquote>
Instrumentalists in particular (guitar players for example) make great programmers. It's not just about math and music being similar, or the fundamentals vs the art. Instrumentalists have to zoom in to work with very repetitive technical details, and so become very focused - like a guitar player practicing a piece of music at a slow speed. But, the best programmers are able to then zoom out and see the big picture, and where their coding fits into the whole project, much like an artist has to step back from a painting and see the whole of it, or an instrumentalists has to produce something that communicates a complete work, not just the scales and technical aspects of it.
</blockquote>
<p>
Carl is something of a fixture in the .NET programming community from the very earliest days. He now runs a little <a href="http://www.pwop.com/podcasts.aspx">media empire</a>; I participated peripherally in that empire when I <a href="http://www.codinghorror.com/blog/archives/000847.html">recorded a .NET Rocks podcast</a> with him and Richard Campbell about two years ago.
</p>
<p>
While I certainly appreciate Carl and Rob's first hand opinions as both programmers and musicians, <b>I worry that this is just another convenient, self-fulfilling analogy we programmers use to puff ourselves up</b>. Sort of like Paul Graham <a href="http://www.codinghorror.com/blog/archives/000261.html">comparing programmers to painters</a>. Or when Alistair Cockburn said <a href="http://www.codinghorror.com/blog/archives/000826.html">software development was a collaborative game</a>, and <a href="http://www.codinghorror.com/blog/archives/000830.html">software projects are like rock climbing</a>.
</p>
<p>
We're the programmers; <b>programming is whatever we say it is</b>.
</p>
<p>
There is a feeling I get from being "in the zone" when listening to music that strongly resembles the feeling of being immersed in an enjoyable bit of programming. There are rhythms and cadences of algorithmic flow. But I'm hesitant to draw any deeper parallels.
</p>
<p>
I've been a software developer in a (theoretically) professional capacity for 15 years now. And every year of coding that goes by, I find myself agreeing more and more with a particular Frank Zappa lyric from the song <a href="http://lyricwiki.org/Frank_Zappa:A_Little_Green_Rosetta">A Little Green Rosetta</a>.
</p>
<p>
</p>
<blockquote>
<p>
<a href="http://www.amazon.com/dp/B0000009SY/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
<i>They're pretty good musicians<br>
But it don't make no difference<br>
If they're good musicians<br>
Because anybody who would buy this record<br>
Doesn't give a f**k if there's good musicians</i>
</p>
</blockquote>
<p>
Now that's the one thing programmers and musicians <i>really</i> have in common.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-one-thing-programmers-and-musicians-have-in-common/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Open Source Software, Self Service Software ]]></title>
<link>https://blog.codinghorror.com/open-source-software-self-service-software/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Have you ever used those self-service checkout machines at a grocery store or supermarket?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
What fascinates me about self-service checkout devices is that <b>the store is making you do work they would normally pay their employees to do.</b> Think about this for a minute. You're playing the role of the paying customer <i>and</i> the cashier employee. Under the watchful eyes of security cameras and at least one human monitor, naturally, but still. We continue to check ourselves out. Not only willingly, but enthusiastically. For that one brief moment, we're working for the supermarket at the lowest possible pay scale: none.
</p>
<p>
That's the paradox of self-checkout. But to me it's no riddle at all: <b>nobody else in that store cares about getting Jeff Atwood checked out <i>nearly</i> as much as Jeff Atwood does.</b> I always choose self-service checkout, except in extraordinary cases. The people with the most vested interest in the outcome of the checkout process are the very same people that self-checkout puts in charge: me! How could it not work? It's the perfect alignment of self-interest.
</p>
<p>
I don't mean this as a dig against supermarket employees. They're (usually) competent and friendly enough. I should know; I worked my way through high school and part of college as a Safeway checker. I tried my level best to be good at my job, and move customers through my line as quickly as possible. I'm sure I could check someone out faster than they could do it themselves. But there's only one me, and at most a half-dozen other checkers working the store, compared to the multitudes of customers. It doesn't scale.
</p>
<p>
If you combine the self-interest angle and the scaling issue, self-service checkout seems obvious, a win for everyone. But self-service is not without issues of its own:
</p>
<p>
</p>
<ul>
<li>What if the item you're scanning isn't found, or can't be scanned?
</li>
<li>Some of the self-service machines have fairly elaborate and non-obvious rules in place, to prevent fraud and theft. Also, the user interface can sometimes be less than ideal on the machines.
</li>
<li>How do you handle coupons? Loyalty cards? Buying 20 of the same item? Scanning the wrong item?
</li>
<li>The self-service stations are lightly manned. The ratio between employee monitors and self-checkout machines runs about 1:4 in my experience. If you have a problem, you might end up waiting longer than a traditional manned checkout.
</li>
<li>How do you ring up items like fruit and vegetables which don't have UPC codes, and have to be weighed?
</li>
<li>What about unusual, awkwardly shaped items or oversize items?
</li>
<li>Customers who have trouble during self-checkout may feel they're stupid, or that they did something wrong. Guess where they're going to lay the blame for those feelings?
</li>
</ul>
<p>
There are certain rituals to using the self-service checkout machines. And we know that. <b>We programmers fundamentally grok the hoops that the self-service checkout machines make customers jump through.</b> They are, after all, devices designed by our fellow programmers. Every item has to be scanned, then carefully and individually placed in the bagging area which doubles as a scale to verify the item was moved there. One at time. In strict sequence. Repeated exactly the same every time. We live this system every day; it's completely natural for a programmer. But it isn't natural for average people. I've seen plenty of customers in front of me struggle with self-service checkout machines, puzzled by the workings of this mysterious device that seems so painfully <i>obvious</i> to a programmer. I get frustrated to the point that I almost want to rush over and help them myself. Which would defeat the purpose of a.. self-service device.
</p>
<p>
I was thinking about this while reading Michael Meeks' article, <a href="http://www.gnome.org/~michael/blog/ooo-commit-stats-2008.html">Measuring the true success of OpenOffice.org</a>. He reaches some depressing conclusions about the current state of <a href="http://www.openoffice.org/">OpenOffice</a>, a high profile open source competitor to Microsoft Office:
</p>
<p>
</p>
<blockquote>
Crude as they are, the <a href="http://www.gnome.org/~michael/blog/ooo-commit-stats-2008.html">statistics</a> show a picture of slow disengagement by Sun, combined with a spectacular lack of growth in the developer community. In a healthy project we would expect to see a large number of volunteer developers involved, in addition - we would expect to see a large number of peer companies contributing to the common code pool; we do not see this in OpenOffice.org. Indeed, quite the opposite. We appear to have the lowest number of active developers on OO.o since records began: 24, this contrasts negatively with Linux's recent low of 160+. Even spun in the most positive way, OpenOffice.org is at best stagnating from a development perspective.
</blockquote>
<p>
This is troubling, because <b>open source software development is the ultimate self-service industry</b>. As Michael notes, the project is sadly undermining itself:
</p>
<p>
</p>
<blockquote>
Kill the ossified, paralysed and gerrymandered political system in OpenOffice.org. Instead put the developers (all of them), and those actively contributing, into the driving seat. This in turn should help to kill the many horribly demotivating and dysfunctional process steps currently used to stop code from getting included, and should help to attract volunteers. Once they are attracted and active, listen to them without patronizing.
</blockquote>
<p>
Indeed, once you destroy the twin intrinsic motivators of self-determination and autonomy on an open source project, I'd argue you're no better off than you were with traditional closed source software. <b>You've created a self-service checkout machine so painful to use, so awkward to operate, that it gives the self-service concept a bad name.</b> And that's heartbreaking, because self-service is the soul of open source:
</p>
<p>
</p>
<blockquote>
Why is my bug not fixed? Why is the UI still so unpleasant? Why is performance still poor? Why does it consume more memory than necessary? Why is it getting slower to start? Why? Why? The answer lies with developers: <a href="http://contributing.openoffice.org/">Will you help us make OpenOffice.org better?</a>
</blockquote>
<p>
In order for open source software projects to survive, they must ensure that they present as few barriers to self-service software development as possible. And any barriers they do present must be very low -- <i>radically</i> low. Asking your customers to <a href="http://contributing.openoffice.org/programming.html">learn C++ programming</a> to improve their Open Office experience is a pretty far cry indeed from asking them to operate a scanner and touchscreen to improve their checkout experience. And if you can't convince an audience of programmers, who are inclined to understand and love this stuff, who exactly <i>are</i> you expecting to convince?
</p>
<p>
So, if you're having difficulty getting software developers to participate in your open source project, I'd say the community isn't failing your project. <i>Your project is failing the community</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/open-source-software-self-service-software/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Scripter at Heart ]]></title>
<link>https://blog.codinghorror.com/a-scripter-at-heart/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>What's the difference between <strong>a programming language and a scripting language</strong>? Is there even a difference at all? Larry Wall's epic <a href="http://www.perl.com/pub/a/2007/12/06/soto-11.html?page=1">Programming is Hard, Let's Go Scripting</a> attempts to survey the scripting landscape and identify commonalities.</p>
<blockquote>When you go out to so-called primitive tribes and analyze their languages, you find that structurally they're just about as complex as any other human language. Basically, you can say pretty much anything in any human language, if you work at it long enough. Human languages are Turing complete, as it were.
<p>Human languages therefore differ not so much in what you can say but in what you must say. In English, you are forced to differentiate singular from plural. In Japanese, you don't have to distinguish singular from plural, but you do have to pick a specific level of politeness, taking into account not only your degree of respect for the person you're talking to, but also your degree of respect for the person or thing you're talking about.</p>
<p>So languages differ in what you're forced to say. Obviously, if your language forces you to say something, you can't be concise in that particular dimension using your language. Which brings us back to scripting.</p>
<p>How many ways are there for different scripting languages to be concise?</p>
<p>How many recipes for borscht are there in Russia?</p>
</blockquote>
<p>Larry highlights the following axes of language design in his survey:</p>
<ol>
<li>Binding: Early or Late? </li>
<li>Dispatch: Single or Multiple? </li>
<li>Evaluation: Eager or Lazy? </li>
<li>Typology: Eager or Lazy? </li>
<li>Structures: Limited or Rich? </li>
<li>Symbolic or Wordy? </li>
<li>Compile Time or Run Time? </li>
<li>Declarational or Operational? </li>
<li>Classes: Immutable or Mutable? </li>
<li>Class-based or Prototype-based? </li>
<li>Passive data, global consistency or Active data, local consistency? </li>
<li>Encapsulatation: by class? by time? by OS constructs? by GUI elements? </li>
<li>Scoping: Syntactic, Semantic, or Pragmatic? </li>
</ol>
<p>It's difficult to talk about Larry Wall without pointing out that <a href="http://en.wikipedia.org/wiki/Perl_6">Perl 6</a> has been missing in action for a very long time. In this 2002 <a href="http://interviews.slashdot.org/article.pl?sid=02/09/06/1343222&amp;mode=thread&amp;tid=145">Slashdot interview with Larry</a>, he talks about Perl 6 casually, like it's just around the corner. Sadly, it has yet to be released. That's not quite <a href="http://en.wikipedia.org/wiki/Duke_Nukem_Forever">Duke Nukem Forever</a> vaporware territory, but it's darn close.</p>
<p>While interesting, I have to admit that I have a problem with all this pontificating about the nature of scripting languages, and the endlessly delayed release of Perl 6. <strong>Aren't Mr. Wall's actions, on some level, contrary to the spirit of the very thing he's discussing?</strong> The essence of a scripting language is <em>immediate gratification</em>. They're <a href="http://www.codinghorror.com/blog/archives/000346.html">Show, Don't Tell</a> in action.</p>
<p>In fact, my first programming experiences didn't begin with a compile and link cycle. They began <a href="http://www.codinghorror.com/blog/archives/001104.html">something like this</a>:</p>
<p><img alt="image placeholder" >
<p><img alt="image placeholder" >
<p><img alt="image placeholder" >
<p>As soon as you booted the computer, the first thing you were greeted with is that pesky blinking cursor. It's right there, inviting you.</p>
<p><em>C'mon. Type something. See what happens</em>.</p>
<p>That's the ineffable, undeniable beauty of a scripting language. You don't need to read a giant Larry Wall article, or wait 8 years for Perl 6 to figure that out. It's right there in front of you. Literally. Try entering this in your browser's address bar:</p>
<pre>javascript:alert('hello world');
</pre>
<p>But it's not <em>real</em> programming, right?</p>
<p>My first experience with <em>real</em> programming was in high school. Armed with a purchased copy of the <a href="http://www.amazon.com/dp/0131103628/?tag=codihorr-20">the classic K&amp;R book</a> and a pirated C compiler for my <a href="http://en.wikipedia.org/wiki/Amiga_1000">Amiga 1000</a>, I knew it was finally time to <strong>put my childish AmigaBASIC programs aside</strong>.</p>
<p><a href="http://www.amazon.com/dp/0131103628/?tag=codihorr-20"><img alt="image placeholder" >
<p>I remember that evening only vaguely (in my defense: I am old). My mom was throwing some kind of party downstairs, and one of the guests tried to draw me out of my room and be social. She was a very nice lady, with the best of intentions. I brandished my K&amp;R book as a shield, holding it up and explaining to her: "No. You don't understand. This is important. I need to learn what's in this book." Tonight, <em>I become a real programmer</em>. And so I began.</p>
<p>What happened next was <strong>the eight unhappiest hours of my computing life</strong>. Between the painfully slow compile cycles and the torturous, unforgiving dance of pointers and memory allocation, I was almost ready to give up programming altogether. C wasn't for me, certainly. But I couldn't shake the nagging feeling that there was something altogether <em>wrong</em> with this type of programming. How could C suck all the carefree joy out of my stupid little AmigaBASIC adventures? This language took what I had known as programming and contorted it beyond recognition, into something stark and <a href="http://www.codinghorror.com/blog/archives/001046.html">cruel</a>.</p>
<p>I didn't know it then, but I sure do now. <strong>I hadn't been programming at all. I had been scripting.</strong></p>
<p>I don't think my revulsion for C is something I need to apologize for. In fact, I think it's the other way around. I've just been waiting for the rest of the world to catch up to <a href="http://www.oreillynet.com/pub/wlg/3190">what I always knew</a>.</p>
<blockquote>The reason why dynamic languages like Perl, Python, and PHP are so important is key to understanding the paradigm shift. Unlike applications from the previous paradigm, web applications are not released in one to three year cycles. They are updated every day, sometimes every hour. Rather than being finished paintings, they are sketches, continually being redrawn in response to new data.
<p>In my talk, I compared web applications to Von Kempelen's famous hoax, the mechanical Turk, a 1770 mechanical chess playing machine with a man hidden inside. <strong>Web applications aren't a hoax, but like the mechanical Turk, they do have a programmer inside. And that programmer is sketching away madly.</strong></p>
</blockquote>
<p>Now, I do appreciate and admire the seminal influence of C. In the right hands, it's an incredibly powerful tool. Every language has its place, and every programmer should choose the language that best fits their skillset and the task at hand.</p>
<p>I know, I know, <a href="http://www.ericsink.com/entries/c_morse_code.html">I'll never be a real programmer</a>. But I've come to terms with my limitations, because <strong>I'm a scripter at heart</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-scripter-at-heart/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Ultimate Dogfooding Story ]]></title>
<link>https://blog.codinghorror.com/the-ultimate-dogfooding-story/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In software circles, dogfooding refers to the practice of <b>using your own products</b>. It was apparently <a href="http://en.wikipedia.org/wiki/Eating_your_own_dog_food">popularized by Microsoft</a>:</p>
<blockquote>
The idea originated in television commercials for Alpo brand dog food; actor Lorne Greene would tout the benefits of the dog food, and then would say it's so good that he feeds it to his own dogs. In 1988, Microsoft manager Paul Maritz sent Brian Valentine, test manager for Microsoft LAN Manager, an email titled "Eating our own Dogfood" challenging him to increase internal usage of the product.
</blockquote>
<p>Buried deep in Eric Sink's post <a href="http://www.ericsink.com/articles/Yours_Mine_Ours.html">Yours, Mine and Ours</a> is perhaps the ultimate example of <a href="http://blog.codinghorror.com/the-difficulty-of-dogfooding/">the power of dogfooding</a>.</p>
<blockquote>
<p>The primary machine tool in any well-equipped woodshop is a<br>
table saw.  Basically, it's a polished cast iron table with a slot through which protrudes a circular saw blade, ten inches in diameter.  Wood is cut by sliding it across the table into the spinning blade.</p>
<p>A table saw is an extremely dangerous tool.  My saw can cut<br>
a 2-inch thick piece of hard maple with no effort at all.  Frankly, it's a tool which should only be used by someone who is a little bit afraid of it.  It should be obvious what would happen if a finger ever came in contact with the spinning blade.  Over 3,000 people each year lose a finger in an accident with<br>
a table saw.</p>
<p>A guy named Stephen Gass has come up with an amazing solution to this problem.  He is a woodworker, but he also has a PhD in physics.  His technology is called <a href="http://www.sawstop.com/">Sawstop</a>.<br>
It consists of two basic inventions:</p>
<ul>
<li>He has a sensor which can detect the difference in<br>
capacitance between a finger and a piece of wood.</li>
<li>He has a way to stop a spinning table saw blade within<br>
1/100 of a second, less than a quarter turn of rotation.</li>
</ul>
<p>The videos of this product are amazing.  Slide a piece of<br>
wood into the spinning blade, and it cuts the board just like it should.  Slide a hot dog into the spinning blade, and it stops instantly, leaving the frankfurter with nothing more than a nick.</p>
<p>Here's the spooky part: <b>Stephen Gass tested his product on<br>
his own finger!</b>  This is a guy who really wanted to close the distance between him and his customers. No matter how much I believed in my product, I think I<br>
would find it incredibly difficult to stick my finger in a spinning table saw<br>
blade.</p>
</blockquote>
<p>The creator actually did stick his own finger in a SawStop on camera, <a href="http://www.sawstopreview.com/sawstop-videos/stephen-gass-sticks-his-own-finger-into-a-sawstop/">apparently on the Discovery Channel show Time Warp</a> – and now thanks to eagle-eyed reader Andy Bassit, here it is! The action starts at around 4 minutes in.</p>
<iframe width="480" height="360" src="//www.youtube.com/embed/eiYoBbEZwlk" frameborder="0" allowfullscreen></iframe>
<p>There's also a video of the sawstop in action on YouTube, using a hotdog in place of an errant digit. Personally, I find this demonstration no less effective than an actual finger.</p>
<iframe width="480" height="360" src="//www.youtube.com/embed/esnQwVZOrUU" frameborder="0" allowfullscreen></iframe>
<p>Does it work? Yes, but it still has unavoidable limitations <a href="http://www.just4fun.org/woodworking/tool_reviews/sawstop/">based on the laws of physics</a>:</p>
<blockquote>
<p>The bottom line is that <b>this saw cuts you about 1/16" for every foot per second that you're moving.</b>  If you hit the blade while feeding the wood you're likely to get cut about 1/16" or less. If you hit the blade while you're falling you'll likely get a 3/16" deep cut instead of multiple finger amputation.  If you hit it while pitching a baseball for the major leagues the injury will be even worse.</p>
</blockquote>
<p>Dogfooding your own code <a href="http://blog.codinghorror.com/the-difficulty-of-dogfooding/">isn't always possible</a>, but it's worth looking very closely at any ways you <i>can</i> use your own software internally. As Mr. Gass proves, nothing exudes confidence like <b>software developers willing to stick their own extremities into the spinning blades of software they've written.</b></p>
<p><font color="red">Update:</font> I found this <a href="http://log.ometer.com/2008-04.html#13">quote from Havoc Pennington</a> rather illustrative.</p>
<blockquote>
<p>It would be wonderful discipline for any software dev team serious about Linux 'on the desktop' (whatever that means) to ban their own use of terminals. Of course, none of us have ever done this, and that explains a lot about the resulting products.</p>
</blockquote>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-ultimate-dogfooding-story/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Sad Tragedy of Micro-Optimization Theater ]]></title>
<link>https://blog.codinghorror.com/the-sad-tragedy-of-micro-optimization-theater/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'll just come right out and say it: <a href="http://www.codinghorror.com/blog/archives/000634.html">I love strings</a>. As far as I'm concerned, there isn't a problem that I can't solve with a string and <a href="http://www.codinghorror.com/blog/archives/000245.html">perhaps a regular expression or two</a>. But maybe that's just my <a href="http://steve-yegge.blogspot.com/2006/03/math-for-programmers.html">lack of math skills</a> talking.
</p>
<p>
In all seriousness, though, the type of programming we do on <a href="http://stackoverflow.com">Stack Overflow</a> is intimately tied to strings. We're constantly building them, merging them, processing them, or dumping them out to a HTTP stream. Sometimes I even give them relaxing massages. Now, if you've worked with strings at all, you know that this is code you desperately want to avoid writing:
</p>
<p>
</p>
<pre>
static string Shlemiel()
{
string result = "";
for (int i = 0; i &lt; 314159; i++)
{
result += getStringData(i);
}
return result;
}
</pre>
<p>
In most garbage collected languages, strings are immutable: when you add two strings, the contents of both are copied. As you keep adding to <code>result</code> in this loop, more and more memory is allocated each time. This leads directly to <a href="http://www.yafla.com/dforbes/String_Concatenation_and_Immutable_Strings_Speeding_Spidermonkey/">awful quadradic n<sup>2</sup> performance</a>, or as Joel likes to call it, <a href="http://www.joelonsoftware.com/articles/fog0000000319.html">Shlemiel the painter performance</a>.
</p>
<p>
</p>
<blockquote>
Who is Shlemiel? He's the guy in this joke:
<p>
Shlemiel gets a job as a street painter, painting the dotted lines down the middle of the road. On the first day he takes a can of paint out to the road and finishes 300 yards of the road. "That's pretty good!" says his boss, "you're a fast worker!" and pays him a kopeck.
</p>
<p>
The next day Shlemiel only gets 150 yards done. "Well, that's not nearly as good as yesterday, but you're still a fast worker. 150 yards is respectable," and pays him a kopeck.
</p>
<p>
The next day Shlemiel paints 30 yards of the road. "Only 30!" shouts his boss. "That's unacceptable! On the first day you did ten times that much work! What's going on?"
</p>
<p>
"I can't help it," says Shlemiel. "Every day I get farther and farther away from the paint can!"
</p>
</blockquote>
<p>
This is a softball question. You all knew that. <b><i>Every</i> decent programmer knows that string concatenation, while fine in small doses, is deadly poison in loops.</b>
</p>
<p>
But what if you're doing nothing but small bits of string concatenation, dozens to hundreds of times -- as in most web apps? Then you might develop a nagging doubt, as I did, that lots of little Shlemiels could possibly be as bad as one <i>giant</i> Shlemiel.
</p>
<p>
Let's say we wanted to build this HTML fragment:
</p>
<p>
</p>
<pre>
&lt;div class="user-action-time"&gt;stuff&lt;/div&gt;
&lt;div class="user-gravatar32"&gt;stuff&lt;/div&gt;
&lt;div class="user-details"&gt;stuff&lt;br/&gt;stuff&lt;/div&gt;
</pre>
<p>
Which might appear on a given Stack Overflow page anywhere from one to sixty times. And we're serving up hundreds of thousands of these pages per day.
</p>
<p>
Not so clear-cut, now, is it?
</p>
<p>
So, which of these methods of forming the above string do you think is fastest over a hundred thousand iterations?
</p>
<p>
<b>1: Simple Concatenation</b>
</p>
<p>
</p>
<pre>
string s =
@"&lt;div class=""user-action-time""&gt;" <font color="red">+ st() + st()</font> + @"&lt;/div&gt;
&lt;div class=""user-gravatar32""&gt;" + st() + @"&lt;/div&gt;
&lt;div class=""user-details""&gt;" + st() + "&lt;br/&gt;" + st() + "&lt;/div&gt;";
return s;
</pre>
<p>
<b>2: String.Format</b>
</p>
<p>
</p>
<pre>
string s =
@"&lt;div class=""user-action-time""&gt;{0}{1}&lt;/div&gt;
&lt;div class=""user-gravatar32""&gt;{2}&lt;/div&gt;
&lt;div class=""user-details""&gt;{3}&lt;br/&gt;{4}&lt;/div&gt;";
return String.<font color="red">Format</font>(s, st(), st(), st(), st(), st());
</pre>
<p>
<b>3: string.Concat</b>
</p>
<p>
</p>
<pre>
string s =
string.<font color="red">Concat</font>(@"&lt;div class=""user-action-time""&gt;", st(), st(),
@"&lt;/div&gt;&lt;div class=""user-gravatar32""&gt;", st(),
@"&lt;/div&gt;&lt;div class=""user-details""&gt;", st(), "&lt;br/&gt;",
st(), "&lt;/div&gt;");
return s;
</pre>
<p>
<b>4: String.Replace</b>
</p>
<pre>
string s =
@"&lt;div class=""user-action-time""&gt;{s1}{s2}&lt;/div&gt;
&lt;div class=""user-gravatar32""&gt;{s3}&lt;/div&gt;
&lt;div class=""user-details""&gt;{s4}&lt;br/&gt;{s5}&lt;/div&gt;";
s = s.<font color="red">Replace</font>("{s1}", st()).Replace("{s2}", st()).
Replace("{s3}", st()).Replace("{s4}", st()).
Replace("{s5}", st());
return s;
</pre>
<p>
<b>5: StringBuilder</b>
</p>
<p>
</p>
<pre>
var sb = new <font color="red">StringBuilder(256)</font>;
sb.Append(@"&lt;div class=""user-action-time""&gt;");
sb.Append(st());
sb.Append(st());
sb.Append(@"&lt;/div&gt;&lt;div class=""user-gravatar32""&gt;");
sb.Append(st());
sb.Append(@"&lt;/div&gt;&lt;div class=""user-details""&gt;");
sb.Append(st());
sb.Append("&lt;br/&gt;");
sb.Append(st());
sb.Append("&lt;/div&gt;");
return sb.ToString();
</pre>
<p>
Take your itchy little trigger finger off that compile key and <i>think</i> about this for a minute. Which one of these methods will be faster?
</p>
<p>
Got an answer? Great!
</p>
<p>
And.. drumroll please.. the correct answer:
</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<h1>It. Just. Doesn't. Matter!</h1>
<p>
We already know none of these operations will be performed in a loop, so we can rule out brutally poor performance characteristics of naive string concatenation. All that's left is micro-optimization, and the minute you begin worrying about tiny little optimizations, <a href="http://www.codinghorror.com/blog/archives/000185.html">you've already gone down the wrong path</a>.
</p>
<p>
Oh, you don't believe me? Sadly, I didn't believe it myself, which is why I got drawn into this in the first place. Here are my results -- for 100,000 iterations, on a dual core 3.5 GHz Core 2 Duo.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="350">
<tr>
<td><b>1: Simple Concatenation</b></td>
<td>606 ms</td>
</tr>
<tr>
<td><b>2: String.Format</b></td>
<td>665 ms</td>
</tr>
<tr>
<td><b>3: string.Concat</b></td>
<td>587 ms</td>
</tr>
<tr>
<td><b>4: String.Replace</b></td>
<td>979 ms</td>
</tr>
<tr>
<td><b>5: StringBuilder</b></td>
<td>588 ms</td>
</tr>
</table>
<p>
Even if we went from the <i>worst</i> performing technique to the best one, we would have saved a lousy 391 milliseconds over a hundred thousand iterations. Not the sort of thing that I'd throw a victory party over. I guess I figured out that using <code>.Replace</code> is best avoided, but even that has some readability benefits that might outweigh the miniscule cost.
</p>
<p>
Now, you might very well ask which of these techniques has the lowest <b>memory usage</b>, <a href="http://blogs.msdn.com/ricom/archive/2004/03/12/88715.aspx">as Rico Mariani did</a>. I didn't get a chance to run these against <code>CLRProfiler</code> to see if there was a clear winner in that regard. It's a valid point, but I doubt the results would change much. In my experience, techniques that abuse memory also tend to take a lot of clock time. Memory allocations are fast on modern PCs, but they're far from free.
</p>
<p>
Opinions vary on just <a href="http://blog.briandicroce.com/2008/02/04/stringbuilder-vs-string-performance-in-net/">how many strings you have to concatenate</a> before you should start worrying about performance. The general consensus is <b>around 10</b>. But you'll also read crazy stuff, like this:
</p>
<p>
</p>
<blockquote>
<b>Don't use += concatenating ever.</b> Too many changes are taking place behind the scene, which aren't obvious from my code in the first place. I advise you to use String.Concat() explicitly with any overload (2 strings, 3 strings, string array). This will clearly show what your code does without any surprises, while allowing yourself to keep a check on the efficiency.
</blockquote>
<p>
Never? Ever? Never ever ever? Not even once? Not even if <i>it doesn't matter?</i> Any time you see "don't ever do X", alarm bells should be going off. Like they hopefully are right now.
</p>
<p>
Yes, you should avoid the obvious beginner mistakes of string concatenation, the stuff every programmer learns their first year on the job. But after that, you should be more worried about the maintainability and readability of your code than its performance. And that is perhaps the most tragic thing about letting yourself get sucked into micro-optimization theater  -- <b>it distracts you from your real goal: writing better code.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-01-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-sad-tragedy-of-micro-optimization-theater/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Have Keyboard, Will Program ]]></title>
<link>https://blog.codinghorror.com/have-keyboard-will-program/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
My beloved <a href="http://www.amazon.com/dp/B000A6PPOK/?tag=codihorr-20">Microsoft Natural Keyboard 4000</a> has succumbed to the relentless pounding of my fingers.
</p>
<p>
A moment of silence, please.
</p>
<p>
OK, it still works, technically, but certain keys have become.. <i>unreliable</i>. In particular, the semicolon key is now infuriatingly difficult to use. I don't know if this is God's way of punishing lapsed Visual Basic programmers, or what, but it's incredibly annoying. Yes, I've tried cleaning it repeatedly with compressed air (although I didn't <a href="http://www.codinghorror.com/blog/archives/001115.html">get to the dishwasher</a> quite yet), but no dice. I blame <a href="http://en.wikipedia.org/wiki/Brian_Kernighan">Kernighan</a>, <a href="http://en.wikipedia.org/wiki/Dennis_Ritchie">Ritchie</a>, and <a href="http://en.wikipedia.org/wiki/Anders_Hejlsberg">Anders</a>, in that order. Also, Canada.
</p>
<p>
Or maybe my keyboard is just worn out. It is <a href="http://www.codinghorror.com/blog/archives/000400.html">three years old</a>. Some of the home row keys and the arrows are worn to a shiny blankness. Perhaps it's time to reinvest in my keyboard.
</p>
<p>
And why not? As a corollary to <a href="http://www.codinghorror.com/blog/archives/001188.html">We Are Typists First, Programmers Second</a>, <b>a quality keyboard is one of the best (and cheapest) investments you can make in your career.</b> So what makes a good <i>programming</i> keyboard? Well, I can point to a few things that <a href="http://www.codinghorror.com/blog/archives/000209.html">make for a very bad one</a>:
</p>
<p>
<b>1. Thou Shalt Not Mangle <font color="red">The Home Key Cluster</font></b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>2. Thou Shalt Not Use a <font color="red">Non-Standard Arrow Key Cluster</font></b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>3. Thou Shalt Not <font color="red">Remap the Function Keys</font></b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>These areas are sacrosanct for programmers</b>. Unlike the average home or office user, we depend on our function keys, the home key cluster, and the arrow keys. We use the <i>crap</i> out of these keys. Move those around and you might as well cut our fingers off while you're at it.
</p>
<p>
I think all programmers can agree on these three. Beyond that, it rapidly becomes a matter of personal preference. Do you like your keyboards ...
</p>
<p>
</p>
<ul>
<li>Ergonomic or standard?
</li>
<li>Clicky or quiet?
</li>
<li>Low-profile or normal?
</li>
<li>Minimalistic or extra function keys?
</li>
<li>With backlights and LEDs or plain?
</li>
</ul>
<p>
There are many small subtleties to key position and size that could also heavily influence your choice. Pick whatever keyboard you like, as long as it's <b>of reasonable quality, and you're comfortable typing on it for long periods</b>. That's the important thing. With that in mind, I'll survey a few popular programming keyboard choices.
</p>
<p>
I mentioned my beloved <a href="http://www.amazon.com/dp/B000A6PPOK/?tag=codihorr-20">Microsoft Natural Keyboard 4000</a>, which is pretty much <b>the holy grail of keyboards</b> to me.
</p>
<p>
</p>
<p>
<a href="http://www.amazon.com/dp/B000A6PPOK/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
Some people don't care for the non-split spacebar, and the way the keys have a fair bit of resistance -- but that's never bothered me. If you're into the whole ergonomic split layout thing, as I obviously am, it's difficult to go wrong with the Natural 4000. That's why I'm replacing my old keyboard with the very same model. If you hate wires, the wireless equivalent is available -- but only with the <a href="http://www.amazon.com/dp/B000Q6UZBM/?tag=codihorr-20">Microsoft Natural Ergonomic Desktop 7000</a> bundle.
</p>
<p>
If you're into classic keyboards, the <a href="http://www.amazon.com/dp/B001CZC0QO/?tag=codihorr-20">DAS Keyboard Professional</a> is another popular choice. Here it is next to the classic <a href="http://en.wikipedia.org/wiki/Model_M_keyboard">IBM Model M</a>, the granddaddy of all PC keyboards.
</p>
<p>
<a href="http://techreport.com/articles.x/16138"><img alt="image placeholder" >
</p>
<p>
These are both buckling spring keyboards, part of a long line of <a href="http://www.dansdata.com/clickykeyboards.htm">venerable keyboard designs going back to 1980</a>. Dan waxes poetic:
</p>
<p>
</p>
<blockquote>
These mainstream 'boards, all with one or another variant of the simple and quiet rubber dome switch idea, are perfectly OK for people who don't type much. They may drop dead with or without the assistance of a spilled beverage, but that's no big deal; if your computer's essential to your happiness, buy a spare cheap keyboard in case your main cheap keyboard dies, and use your nasty mushy input devices with my blessing.
<p>
If you do type a lot, though, you owe it to yourself to get a good keyboard of one kind or another, for the same reason that people who use the mouse a lot shouldn't settle for some ancient crusty serial-port optomechanical artifact.
</p>
<p>
Old mouses aren't nice to use, but old keyboards can be, because mouse technology's advanced a lot over the last 20 years, but <b>keyswitch technology was quite mature in 1980. Modern keyboard tech advances have mainly had to do with wireless interfaces, snazzy looks, and making cheap crud cheaper.</b>
</p>
</blockquote>
<p>
The Das got a <a href="http://techreport.com/articles.x/16138">very favorable review at Tech Report</a>. And it also comes in a super-hardcore <a href="http://store.daskeyboard.net/das2usbult.html">blank keycaps edition</a>, if you really want to prove to yourself (and your coworkers) that you can actually touch type. It is a bit spendy, though, particularly when <a href="http://pckeyboards.stores.yahoo.net/customizer.html">excellent Model M clones</a> can be had for fifty bucks less.
</p>
<p>
If you're more into laptop-style ultra low profile keyboards, you might prefer the <a href="http://www.amazon.com/dp/B000V07N9U/?tag=codihorr-20">Apple Keyboard</a>.
</p>
<p>
<a href="http://www.amazon.com/dp/B000V07N9U/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
Haven't tried this one myself, but I've heard good things; the layout seems solid and the quality superb, as you would expect from Apple.
</p>
<p>
I read <a href="http://stackoverflow.com/questions/687/keyboard-for-programmers">recommendations for each of these keyboards</a> almost daily. But of course I'm only touching the tip of the iceberg in this post. There are at least a dozen other popular contenders, along with a seemingly neverending parade of oddities and curiosities. Such as the <a href="http://en.wikipedia.org/wiki/Space-cadet_keyboard">Space cadet keyboard</a>.
</p>
<p>
Whatever your choice, <b>give your keyboard the consideration it deserves; it is the one essential tool of our craft</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/have-keyboard-will-program/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Mixing Oil and Water: Authorship in a Wiki World ]]></title>
<link>https://blog.codinghorror.com/mixing-oil-and-water-authorship-in-a-wiki-world/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>When you visit Wikipedia's <a href="http://en.wikipedia.org/wiki/Asphalt">entry on asphalt</a>, you get some reasonably reliable information about asphalt. What you don't get, however, is any indication of <em>who the author is</em>. That's because the author is irrelevant. Wikipedia is a community effort, the result of tiny slices of effort contributed by millions of people around the world. The focus is on the value of the aggregated information, not who the individual authors are.</p>
<p>But who is that community? According to Jimmy Wales, <a href="http://www.aaronsw.com/weblog/whowriteswikipedia">most of the work on Wikipedia is done by a tightly knit Gang of 500</a>:</p>
<blockquote>Wales decided to run a simple study to find out: he counted who made the most edits to the site. “I expected to find something like an 80-20 rule: 80% of the work being done by 20% of the users, just because that seems to come up a lot. But it’s actually much, much tighter than that: it turns out over 50% of all the edits are done by just .7% of the users … 524 people. … And in fact the most active 2%, which is 1400 people, have done 73.4% of all the edits.” The remaining 25% of edits, he said, were from “people who [are] contributing … a minor change of a fact or a minor spelling fix … or something like that.”
</blockquote>
<p>Stack Overflow has some wiki-like aspects, and even my limited experience with the genre tells me this claim is implausible. Aaron Swartz ran his own study and <a href="http://www.aaronsw.com/weblog/whowriteswikipedia">came to a very different conclusion</a>:</p>
<blockquote>I wrote a little program to go through each edit and count how much of it remained in the latest version. Instead of counting edits, as Wales did, I counted the number of letters a user actually contributed to the present article.
<p>
If you just count edits, it appears the biggest contributors to the Alan Alda article (7 of the top 10) are registered users who (all but 2) have made thousands of edits to the site. Indeed, #4 has made over 7,000 edits while #7 has over 25,000. In other words, if you use Wales’s methods, you get Wales’s results: most of the content seems to be written by heavy editors.
</p>
<p>
But when you count letters, the picture dramatically changes: few of the contributors (2 out of the top 10) are even registered and most (6 out of the top 10) have made less than 25 edits to the entire site. In fact, #9 has made exactly one edit — this one! With the more reasonable metric — indeed, the one Wales himself said he planned to use in the next revision of his study — the result completely reverses.
</p>
</blockquote>
<p><strong>Insiders account for the vast majority of the edits. But it's the outsiders who provide nearly all of the content.</strong></p>
<p>Satisfying the needs of these two radically different audiences – the insiders and the outsiders – is the art of wiki design. That's why, on Stack Overflow, we mix oil and water:</p>
<ol>
<li>There's a strong sense of <a href="http://www.hms.harvard.edu/integrity/authorship.html">authorship</a>, with a reputation system and a signature block attached to every post, like traditional blogs and forums. </li>
<li>Once the system learns to trust you, you can edit anything – and we sometimes switch into a mode where authorship is de-emphasized to focus on the resulting content, like a <a href="http://en.wikipedia.org/wiki/Wiki">wiki</a>. </li>
</ol>
<p>I'm not sure mixing these opposing elements would work for a project on the scale of Wikipedia. But I think it works for us (and when I say <em>us</em>, I mean programmers) because it's analogous to the version control system baked into the DNA of every programmer. Communal ownership is all well and good, but sometimes you still need to know <a href="http://www.codinghorror.com/blog/archives/000992.html">Who Wrote This Crap</a>. Authorship matters, ownership matters – and yet there's still something bigger, a larger goal we're all working toward, that trumps any individual contribution we might make. Both elements are in play.</p>
<p>Still, we absorbed a lot of tension with this design choice, because <strong>authorship and wiki are fundamentally opposing goals</strong>. How do you balance self-interest (vote for me) with selfnessness (vote for this content)? Sometimes it breaks down. There's a rough area around the edges where these two systems meet. For example, consider the Stack Overflow question titled <strong>Significant new inventions in computing since 1980</strong>.</p>
<p><img alt="image placeholder" >
<p>If you knew this question was from <a href="http://www.codinghorror.com/blog/archives/001213.html">Turing Award winning computer scientist Alan Kay</a>, would it change the way you reacted to it? <em>Of course it would!</em></p>
<p>But you'd never know that, because our wiki signature block only tells you:</p>
<ol>
<li>The last editor (Out Into Space) </li>
<li>How many revisions there have been to this question so far (5) </li>
<li>How many users have created those revisions (4) </li>
</ol>
<p>It's a lot of information, by typical wiki standards. Who cares who wrote the question, as long as it's a good question, right?</p>
<p>But that doesn't entirely work; <strong>we <em>also</em> need to know who the primary author is</strong>, because that information will color and influence our responses to the question. I'll grant you this is an extreme example; no disrespect to my fellow programmers, but you haven't won a turing award. Even in more typical cases, attaching authorship <em>matters</em>. It lets us know who we're talking to, what their background is, what their skills are, and so forth. Furthermore, how can you possibly form a community when everyone is a random, anonymous contributor?</p>
<p>So the challenge, then, is tracking authorship – strictly for informational purposes – across a series of edit revisions. Jimbo erred in tracking only edit counts. Aaron used Python's <code>difflib.SequenceMatcher.find_longest_match</code> to establish ownership across revisions. This is the basic technique visualized in <a href="http://www.research.ibm.com/visual/projects/history_flow/explanation.htm">IBM's History Flow</a>.</p>
<blockquote>Imagine a scenario where three people will make contributions to a Wiki page at different points in time. Each person edits the page and then saves their changes to what becomes the latest version of that page.
<p><img alt="image placeholder" >
<p>History Flow connects text that has been kept the same between consecutive versions. Pieces of text that do not have correspondence in the next (or previous) version are not connected and the user sees a resulting "gap" in the visualization; this happens for deletions and insertions.</p>
</blockquote>
<p>It's very cool when applied to larger inputs; see <a href="http://www.research.ibm.com/visual/images/discover_mag.jpg">history flow visualization of the Wikipedia entry on evolution</a>.</p>
<p>Now, <strong>the differencing of text is, in itself, not exactly a trivial problem.</strong> I started by examining the <a href="http://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein Distance</a>, but this algorithm is truly brute force. See if you can tell why, in this visualization of the Levenshtein distance between "puzzle" and "pzzel":</p>
<p><img alt="image placeholder" >
<p>The levenshtein distance is a measure of how many insertions, deletions, or substitutions are required to transform string A into string B. The larger the number, the more different the strings are. We're comparing two strings essentially letter-by-letter, which means the typical cost is O(mn), where m and n are the lengths of the two strings we're comparing. That's why you typically see Levenshtein used for comparing <em>words</em>, nothing on the order of paragraphs or pages.</p>
<p>I played around with Levenshtein for a while, but even optimized implementations are brutally slow as the size of the input increases. I quickly realized that a <strong>line-based comparison</strong> was the only workable one. We used this <a href="http://www.mathertel.de/Diff/DiffDoku.aspx">C# implementation</a> of <a href="http://xmailserver.org/diff2.pdf">An O(ND) Difference Algorithm and its Variations</a> (pdf).</p>
<p>What I ended up implementing was nowhere near as thorough as IBM's history flow, although it's probably similar to the rough metrics Aaron used. I simply sum the total size of all line contributions (insertions or deletions) from any given author in a revision, with a small bonus multiplier of 2x for the original author. We report the highest percentage of authorship in the final revision.</p>
<p><img alt="image placeholder" >
<p>The line-based diff approach for determining authorship is far from perfect; it'd be more accurate if it was per-word or per-sentence. But it's a fairly good approximation in my testing.</p>
<p>And most importantly, <strong>wiki posts by Alan Kay look like they're from Alan Kay.</strong></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/mixing-oil-and-water-authorship-in-a-wiki-world/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ You're Doing It Wrong ]]></title>
<link>https://blog.codinghorror.com/youre-doing-it-wrong/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/001218.html">The Sad Tragedy of Micro-Optimization Theater</a> we discussed the performance considerations of building a fragment of HTML.
</p>
<p>
</p>
<pre>
string s =
@"&lt;div class=""action-time""&gt;{0}{1}&lt;/div&gt;
&lt;div class=""gravatar32""&gt;{2}&lt;/div&gt;
&lt;div class=""details""&gt;{3}&lt;br/&gt;{4}&lt;/div&gt;";
return String.<font color="red">Format</font>(s, st(), st(), st(), st());
</pre>
<p>
The second act of this particular theater was foreshadowed by <a href="http://www.workingwithrails.com/person/14560-stephen-touset">Stephen Touset's</a> comment:
</p>
<p>
</p>
<blockquote>
The correct answer is that <b>if you're concatenating HTML, you're doing it wrong in the first place. Use an HTML templating language.</b> The people maintaining your code after you will thank you (currently, you risk anything from open mockery to significant property damage).
</blockquote>
<p>
The performance characteristics of building small string fragments isn't just a red herring -- no, it's far, far worse. The <i>entire question is wrong</i>. This is one of my favorite <a href="http://www.codinghorror.com/blog/archives/000103.html">lessons from The Pragmatic Programmer</a>.
</p>
<p>
</p>
<blockquote>
When faced with an impossible problem, identify the real constraints. Ask yourself: "Does it have to be done this way? Does it have to be done at all?"
</blockquote>
<p>
If our ultimate conclusion was that performance is secondary to readability of code, that's exactly what we should have asked, before doing anything else.
</p>
<p>
Let's express the same code sample using the standard <a href="http://www.asp.net/mvc/">ASP.NET MVC</a> templating engine. And yes, we render stuff like this all over the place in Stack Overflow. It's the default method of rendering for a reason.
</p>
<p>
</p>
<pre>
&lt;div class="action-time"&gt;&lt;%= User.ActionTime %&gt;&lt;/div&gt;
&lt;div class="gravatar32"&gt;&lt;%= User.Gravatar %&gt;&lt;/div&gt;
&lt;div class="details"&gt;&lt;%= User.Details %&gt;&lt;br/&gt;&lt;%= User.Stuff %&gt;&lt;/div&gt;
</pre>
<p>
We have a HTML file, through which we poke some holes and insert the data. Simple enough, and conceptually similar to the <code>String.Replace</code> version. Templating works reasonably well in the trivial cases when you have an object with obvious, basic data types in fields that you spit out.
</p>
<p>
But beyond those simple cases, it's shocking how hairy HTML templating gets. What if you need do to a bit of formatting or processing to get that data into shape before displaying it? What if you need to make decisions and display things differently depending on the contents of those fields? Your once-simple page templates get progressively more and more complex.
</p>
<p>
</p>
<pre>
&lt;%foreach (var User in Users) { %&gt;
&lt;div class="action-time"&gt;&lt;%= ActionSpan(User)%&gt;&lt;/div&gt;
&lt;% if (User.IsAnonymous) { %&gt;
&lt;div class="gravatar32"&gt;&lt;%= RenderGravatar(User)%&gt;&lt;/div&gt;
&lt;div class="details"&gt;&lt;%= RepSpan(User)%&gt;&lt;br/&gt;&lt;%= Flair(User)%&gt;&lt;/div&gt;
&lt;% } else { %&gt;
&lt;div class="anon"&gt;anonymous&lt;/div&gt;
&lt;% } %&gt;
&lt;% } %&gt;
</pre>
<p>
This is a fairly mild case, but you can see where templating naturally tends toward a frantic, unreadable mish-mash of code and template -- <a href="http://www.codinghorror.com/blog/archives/001155.html">Web Development as Tag Soup</a>. If your HTML templates can't be kept simple, they're not a heck of a lot better than the procedural string building code they're replacing. And this is not an easy thing to stay on top of, in my experience. The daily grind of struggling to keep the templates from devolving into tag soup starts to feel every bit as grotty as all that nasty string work we were theoretically replacing.
</p>
<p>
Now it's my turn to ask -- <i>why?</i>
</p>
<p>
I think existing templating solutions are going about this completely backwards. <b>Rather than poking holes in HTML to insert code, we should simply treat HTML <i>as</i> code.</b>
</p>
<p>
Like so:
</p>
<p>
</p>
<pre>
foreach (var User in Users)
{
&lt;div class="action-time"&gt;[ActionSpan(User)]&lt;/div&gt;
if (User.IsAnonymous)
{
&lt;div class="gravatar32"&gt;[RenderGravatar(User)]&lt;/div&gt;
&lt;div class="details"&gt;[UserRepSpan(User)]&lt;br/&gt;[UserFlairSpan(User)]&lt;/div&gt;
}
else
{
&lt;div class="anon"&gt;anonymous&lt;/div&gt;
}
}</pre>
<p>
Seamlessly mixing code and HTML, using a minumum of those headache-inducing escape characters. Is this a programming language for <a href="http://www.codinghorror.com/blog/archives/000821.html">a race of futuristic supermen?</a> No. There are languages that can do this right now, today -- where you can <b>stick HTML in the middle of your code</b>. It's already possible <a href="http://blogs.msdn.com/dmitryr/archive/2008/12/29/asp-net-mvc-view-engine-using-vb-net-xml-literals.aspx">using Visual Basic XML Literals</a>, for example.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Even the <a href="http://www.reddit.com/r/programming/comments/7rc5v/x_xml_oriented_programming_language_i_cant/c076grx">hilariously maligned X#</a> has the right core idea. Templating tends to break down because <b>it forces you to treat code and markup as two different and fundamentally incompatible things.</b> We spend all our time awkwardly switching between markup-land and code-land using escape sequences. They're always fighting each other -- and us.
</p>
<p>
Seeing HTML and code get equal treatment in my IDE makes me realize one thing:
</p>
<p>
We've <i>all</i> been doing it wrong.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/youre-doing-it-wrong/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Reinvent The Wheel, Unless You Plan on Learning More About Wheels ]]></title>
<link>https://blog.codinghorror.com/dont-reinvent-the-wheel-unless-you-plan-on-learning-more-about-wheels/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The introduction to <a href="http://www.codinghorror.com/blog/archives/000380.html">Head First Design Patterns</a> exhorts us <strong>not to reinvent the wheel</strong>:</p>
<blockquote>You're not alone. At any given moment, somewhere in the world someone struggles with the same software design problems you have. You know you don't want to reinvent the wheel (or worse, a flat tire), so you look to Design Patterns – the lessons learned by those who've faced the same problems. With Design Patterns, you get to take advantage of the best practices and experience of others, so that you can spend your time on … something else. Something more challenging. Something more complex. Something more fun.</blockquote>
<p>Avoiding the reinvention of the proverbial wheel is a <a href="http://sourcemaking.com/antipatterns/reinvent-the-wheel">standard bit of received wisdom</a> in software development circles. There's certainly truth there, but I think it's a bit dangerous if taken too literally – if you <strong>categorically deny all attempts to solve a problem with code once any existing library is in place</strong>.</p>
<p><img alt="image placeholder" >
<p>I'm not so sure. I think reinventing the wheel, if done properly, can be useful. For example, <a href="http://blogs.ipona.com/james/archive/2008/03/17/Reinventing-Linq.aspx">James Hart reinvented the wheel</a>. And he liked it:</p>
<blockquote>I reinvented the wheel last week. I sat down and deliberately coded something that I knew already existed, and had probably also been done by many many other people. In conventional programming terms, I wasted my time. But it was worthwhile, and what's more I would recommend almost any serious programmer do precisely the same thing.</blockquote>
<p>But who's James Hart? Just another programmer. If that doesn't carry enough weight for you, how does it sound coming <a href="http://www.forth.com/resources/evolution/evolve_1.html">from Charles Moore, the creator of FORTH?</a></p>
<blockquote>A second corollary was even more heretical: "Do it yourself!"
<p><em>The conventional approach, enforced to a greater or lesser extent, is that you shall use a standard subroutine. I say that you should write your own subroutines.</em></p>
<p><em>Before you can write your own subroutines, you have to know how. This means, to be practical, that you have written it before; which makes it difficult to get started. But give it a try. After writing the same subroutine a dozen times on as many computers and languages, you'll be pretty good at it.</em></p>
<p>Moore followed this to an astounding extent. Throughout the 70's, as he implemented Forth on 18 different CPUs, he invariably wrote for each his own assembler, his own disk and terminal drivers, even his own multiply and divide subroutines (on machines that required them, as many did). When there were manufacturer-supplied routines for these functions, he read them for ideas, but never used them verbatim. By knowing exactly how Forth would use these resources, by omitting hooks and generalities, and by sheer skill and experience (he speculated that most multiply/divide subroutines were written by someone who had never done one before and never would again), his versions were invariably smaller and faster, usually significantly so.</p>
<p>Moreover, he was never satisfied with his own solutions to problems. Revisiting a computer or an application after a few years, he often re-wrote key code routines. He never re-used his own code without re-examining it for possible improvements. This later became a source of frustration to Rather, who, as the marketing arm of FORTH, Inc., often bid jobs on the assumption that since Moore had just done a similar project this one would be easy – only to watch helplessly as he tore up all his past code and started over.</p>
</blockquote>
<p>And then there's <a href="http://crazybob.org/2007/09/why-reinvent-wheel.html">Bob Lee</a>, who leads the core library development on <a href="http://android.com/">Android</a>.</p>
<blockquote>Depending on the context, you can almost always replace "Why reinvent the wheel?" with "Please don't compete with me," or "Please don't make me learn something new." Either way, the opponent doesn't have a real argument against building something newer and better, but they also don't want to admit their unhealthy motivations for trying to stop you.
<p>More seeds, more blooms, I say. Don't build houses on kitchen sinks. Reinvent away. <strong>Most of our current technology sucks, and even if it didn't, who am I to try and stop you?</strong></p>
</blockquote>
<p>Indeed. If anything, "Don't Reinvent The Wheel" should be used as a call to arms for deeply educating yourself about all the existing solutions – not as a bludgeoning tool to undermine those who legitimately want to build something better or improve on what's already out there. In my experience, sadly, it's much more the latter than the former.</p>
<p>So, no, you shouldn't reinvent the wheel. <strong>Unless you plan on learning more about wheels</strong>, that is.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-reinvent-the-wheel-unless-you-plan-on-learning-more-about-wheels/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Elephant in the Room: Google Monoculture ]]></title>
<link>https://blog.codinghorror.com/the-elephant-in-the-room-google-monoculture/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was browsing the sessions at an upcoming <a href="http://en.oreilly.com/found">Search Conference</a>, which describes itself thusly:
</p>
<p>
</p>
<blockquote>
The way to online success is through being easily found in search engines such as Google, Yahoo!, and Microsoft Live Search. While developers have historically thought of search as a marketing activity, technical architecture has now become critical for search success.
</blockquote>
<p>
Anyone else see the <b>elephant in the room</b>, there? No?
</p>
<p>
<a href="http://www.newyorker.com/online/2007/05/14/slideshow_070514_banksy?viewall=true"><img alt="image placeholder" >
</p>
<p>
Just two weeks after we launched Stack Overflow, I mentioned that <a href="http://www.codinghorror.com/blog/archives/001174.html">search engines already made up 50% of our traffic</a>. Well, not so much search engine<u><b>s</b></u> as search engin<u><b>e</b></u>:
</p>
<p>
</p>
<blockquote>
I try to be politically correct in discussing web search, avoiding the g-word whenever possible, desperately attempting to preserve the illusion that web search is actually a competitive market. But it's becoming a transparent and cruel joke at this point. <b>When we say "web search" we mean one thing, and one thing only: Google</b>. <a href="http://www.skrenta.com/2006/12/googles_true_search_market_sha.html">Rich Skrenta explains</a>:
</blockquote>
<p>
</p>
<blockquote>
I'm not a professional analyst, and my approach here is pretty back-of-the-napkin. Still, it confirms what those of us in the search industry have known for a long time.
<p>
The New York Times, for instance, gets nearly 6 times as much traffic from Google as it does from Yahoo. Tripadvisor gets 8 times as much traffic from Google vs. Yahoo.
</p>
<p>
Even Yahoo's own sites are no different. While it receives a greater fraction of Yahoo search traffic than average, Yahoo's own flickr service gets 2.4 times as much traffic from Google as it does from Yahoo.
</p>
<p>
My favorite example: According to Hitwise, [ex] Yahoo blogger Jeremy Zawodny gets 92% of his inbound search traffic from Google, and only 2.7% from Yahoo.
</p>
</blockquote>
<p>
That was written almost two years ago. Guess which way those numbers have gone since then?
</p>
<p>
Now that <a href="http://stackoverflow.com/">Stack Overflow</a> has been chugging right along for almost six months, allow me to share the last month of our own data. <b>Currently, 83% of our total traffic is from search engines</b>, or rather, one <i>particular</i> search engine:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="300">
<tr>
<td style="border-bottom:1px dotted black;">Search Engine</td>
<td align="right" style="border-bottom:1px dotted black;">Visits</td>
</tr>
<tr>
<td>Google</td>
<td align="right">3,417,919</td>
</tr>
<tr>
<td>Yahoo</td>
<td align="right">9,779</td>
</tr>
<tr>
<td>Live</td>
<td align="right">5,638</td>
</tr>
<tr>
<td>Search</td>
<td align="right">2,961</td>
</tr>
<tr>
<td>AOL</td>
<td align="right">1,274</td>
</tr>
<tr>
<td>Ask</td>
<td align="right">1,186</td>
</tr>
<tr>
<td>MSN</td>
<td align="right">1,177</td>
</tr>
<tr>
<td>Altavista</td>
<td align="right">202</td>
</tr>
<tr>
<td>Yandex</td>
<td align="right">191</td>
</tr>
<tr>
<td>Seznam</td>
<td align="right">103</td>
</tr>
</table>
<p>
Those 6x and 8x numbers that Rich quoted two years ago seem awfully quaint now. Google delivers <b>350x</b> the traffic to Stack Overflow that the next best so-called "search engine" does. <i>Three hundred and fifty times!</i>
</p>
<p>
Now, I don't claim that Stack Overflow is representative of every site on the internet -- obviously it isn't. It's a site for programmers. And let me be absolutely crystal clear that I have no problem at all with Google. That said, I find it profoundly disturbing that <b>if every other search engine in the world shut down <i>tomorrow</i>, our website's traffic would be effectively unchanged</b>. That's downright <i>scary</i>.
</p>
<p>
Yes, I like Google. Yes, Google works great and has been my homepage for about eight years now. Google nailed search, and they deserve the leadership position they've earned. But where's the healthy competition? Where's the incentive for Google to improve? All I see is a large and growing monoculture that acts as the <a href="http://www.skrenta.com/2007/01/winnertakeall_google_and_the_t.html">start page for the internet</a>.
</p>
<p>
I'm a little surprised all the people who were so <a href="http://en.wikipedia.org/wiki/United_States_v._Microsoft">up in arms about the Microsoft "monopoly" ten years ago</a> aren't out in the streets today lighting torches and sharpening their pitchforks to go after Google. Does the fact that Google's products are mostly free and ad-supported somehow exempt it from the same scrutiny? Isn't anyone else concerned that Google, even with the best of "don't be evil" intentions, has become <a href="http://whimsley.typepad.com/whimsley/2008/03/mr-googles-guid.html">more master than servant</a>?
</p>
<p>
Calling the current state of search engine competition a horse race is an insult to horse races. No, what we have here is a one horse race where all the other horses were shipped off to glue factories years ago. <b>Forget "search conference", you should be throwing a "Google conference", because there's no difference.</b>
</p>
<p>
I don't know. Maybe that's OK. But it does mean that if Google, for whatever reason, decided to remove you from its search results, <a href="http://www.codinghorror.com/blog/archives/000767.html">your website no longer exists</a>. At least not as a viable business, anyway.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-elephant-in-the-room-google-monoculture/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Ferengi Programmer ]]></title>
<link>https://blog.codinghorror.com/the-ferengi-programmer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
There was a little <a href="http://blog.objectmentor.com/articles/2009/01/31/quality-doesnt-matter-that-much-jeff-and-joel">brouhaha</a> recently about <a href="http://www.joelonsoftware.com/items/2009/01/31.html">some comments Joel Spolsky made</a> on our podcast:
</p>
<p>
</p>
<blockquote>
Last week I was listening to a <a href="http://www.hanselminutes.com/default.aspx?showID=163">podcast on Hanselminutes</a>, with Robert Martin talking about the <a href="http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod">SOLID principles</a>. (That's a real easy-to-Google term!) It's object-oriented design, and they're calling it agile design, which it really, really isn't. It's principles for how to design your classes, and how they should work. And, when I was listening to them, they all sounded to me like extremely bureaucratic programming that came from the mind of somebody that has not written a lot of code, frankly.
</blockquote>
<p>
There's nothing really objectionable about <a href="http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod">Bob's object-oriented design principles</a>, on the face of it. (Note that all links in the below table are PDFs, so click accordingly.)
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="600">
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/srp.pdf">The Single Responsibility Principle</a></td>
<td>A class should have one, and only one, reason to change.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/ocp.pdf">The Open Closed Principle</a></td>
<td>You should be able to extend a classes behavior, without modifying it.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/lsp.pdf">The Liskov Substitution Principle</a></td>
<td>Derived classes must be substitutable for their base classes.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/dip.pdf">The Dependency Inversion Principle</a></td>
<td>Depend on abstractions, not on concretions.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/isp.pdf">The Interface Segregation Principle</a></td>
<td>Make fine grained interfaces that are client specific.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/granularity.pdf">The Release Reuse Equivalency Principle</a></td>
<td>The granule of reuse is the granule of release.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/granularity.pdf">The Common Closure Principle</a></td>
<td>Classes that change together are packaged together.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/granularity.pdf">The Common Reuse Principle</a></td>
<td>Classes that are used together are packaged together.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/granularity.pdf">The Acyclic Dependencies Principle</a></td>
<td>The dependency graph of packages must have no cycles.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/stability.pdf">The Stable Dependencies Principle</a></td>
<td>Depend in the direction of stability.</td>
</tr>
<tr>
<td><a href="http://www.objectmentor.com/resources/articles/stability.pdf">The Stable Abstractions Principle</a></td>
<td>Abstractness increases with stability.</td>
</tr>
</table>
<p>
While I do believe every software development team should endeavor to <a href="http://www.codinghorror.com/blog/archives/000568.html">follow the instructions on the paint can</a>, there's a limit to what you can fit on a paint can. It's the most basic, most critical information you need to proceed and not make a giant mess of the process. As brief as the instructions on a paint can are, they do represent the upper limit of what most people will realistically read, comprehend, and derive immediate benefit from.
</p>
<p>
<b>Expanding from a few guidelines on a paint can into a detailed painting manual is far riskier.</b> The bigger and more grandiose the set of rules you come up with, the more severe the danger. A few broad guidelines on a paint can begets thirty rules for painting, which begets a hundred detailed principles of painting..
</p>
<p>
Pretty soon you'll find yourself believing that every possible situation in software development can be prescribed, <i>if only you could come up with a sufficiently detailed set of rules!</i> And, of course, a critical mass of programmers patient enough to read Volumes I - XV of said rules. You'll also want to set up a few messageboards for these programmers to argue endlessly amongst themselves about the meaning and interpretation of the rules.
</p>
<p>
This strikes me as <b>a bit like Ferengi programming</b>.
</p>
<p>
<a href="http://www.amazon.com/dp/0671529366/?tag=codihorr-20">
<img alt="image placeholder" >
</p>
<p>
The <a href="http://en.wikipedia.org/wiki/Ferengi">Ferengi</a> are a part of the Star Trek universe, primarily in <a href="http://en.wikipedia.org/wiki/Star_Trek:_Deep_Space_Nine">Deep Space Nine</a>. They're a race of ultra-capitalists whose every business transaction is governed by <a href="http://memory-alpha.org/en/wiki/Rules_of_Acquisition">the 285 Rules of Acquisition</a>. There's a rule for every possible business situation -- and, inevitably, an interpretation of those rules that gives the Ferengi license to cheat, steal, and bend the truth to suit their needs.
</p>
<p>
At what point do you stop having a set of basic, reasonable programming guidelines -- and start being <b>a Ferengi programmer, an imperfect manifestation of the ruleset?</b>
</p>
<p>
Like James Bach, I've found <a href="http://www.satisfice.com/blog/archives/174">less and less use for rules</a> in my career. Not because I'm a <a href="http://www.codinghorror.com/blog/archives/001080.html">self-made genius who plays by my own rules</a>, mind you, but because I value the skills, experience, and judgment of my team far more than any static set of rules.
</p>
<p>
</p>
<blockquote>
When <a href="http://xprogramming.com/blog/2009/01/30/context-my-foot">Ron says there is an "absolute minimum of practice"</a> that must be in for an agile project to succeed, I want to reply that I believe there is an absolute minimum of practice needed to have a competent opinion about things that are needed -- and that in his post he does not achieve that minimum. I think part of that minimum is to understand what words like "practice" and "agile" and "success" can mean (recognizing they are malleable ideas). Part of it is to recognize that people can and have behaved in agile ways without any concept of agile or ability to explain what they do.
<p>
My style of development and testing is highly agile. I am agile in that I am prepared to question and rethink anything. I change and develop my methods. I may learn from packaged ideas like Extreme Programming, but I never <i>follow</i> them. <i>Following is for novices who are under active supervision</i>. Instead, I craft methods on a project by project basis, and I encourage other people to do that, as well. <b>I take responsibility for my choices. That's engineering for adults like us.</b>
</p>
</blockquote>
<p>
Guidelines, particularly in the absence of experts and mentors, <a href="http://www.codinghorror.com/blog/archives/000578.html">are useful</a>. But there's also a very real danger of <b>hewing too slavishly to rulesets</b>. Programmers are already quite systematic by disposition, so the idea that you can come up with a detailed enough set of rules, and sub-rules, and sub-sub-rules, that you can literally <i>program yourself</i> for success with a "system" of sufficient sophistication -- this, unfortunately, comes naturally to most software developers. If you're not careful, you might even slip and <a href="http://www.codinghorror.com/blog/archives/000203.html">fall into a Methodology</a>. Then you're in <i>real</i> trouble.
</p>
<p>
<b>Don't become a Ferengi Programmer.</b> Rules, guidelines, and principles are gems of distilled experience that should be studied and respected. But they're never a substute for thinking critically about your work.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-ferengi-programmer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Real Ultimate Programming Power ]]></title>
<link>https://blog.codinghorror.com/real-ultimate-programming-power/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>A common response to <a href="http://blog.codinghorror.com/the-ferengi-programmer/">The Ferengi Programmer</a>:</p>
<blockquote>
<p>From what I can see, the problem of "overly-rule-bound developers" is nowhere near the magnitude of the problem of "developers who don't really have a clue."<br>
The majority of developers do not suffer from too much design patterns, or too much SOLID, or agile, or waterfall for that matter. They suffer from whipping out cowboy code in a pure chaos environment, using simplistic drag &amp; drop, data driven, vb-like techniques.</p>
</blockquote>
<p>Absolutely.</p>
<p>But here's the paradox: the types of programmers who would most benefit from these guidelines, rules, principles, and checklists are the least likely to read and follow them. <strong>Throwing a book of rules at a terrible programmer just creates a terrible programmer with a bruise on their head where the book bounced off.</strong> This is something I discussed previously in <a href="http://www.codinghorror.com/blog/archives/001004.html">Mort, Elvis, Einstein, and You</a>:</p>
<blockquote>
<p>Thus, if you read the article, you are most assuredly in the twenty percent category. The other eighty percent are not actively thinking about the craft of software development. They would never find that piece, much less <em>read</em> it. They simply don't read programming blogs – other than as the result of web searches to find quick-fix answers to a specific problem they're having. Nor have they read any of the books in my <a href="http://blog.codinghorror.com/recommended-reading-for-developers/">recommended reading list</a>. The defining characteristic of the vast majority of these so-called "vocational" programmers is that <em>they are unreachable</em>. It doesn't matter what you, I or anyone else writes here – they'll never see it.</p>
</blockquote>
<p>In the absence of mentoring and <a href="http://blog.codinghorror.com/software-apprenticeship/">apprenticeship</a>, the dissemination of better programming practices is often conveniently packaged into <a href="http://en.wikipedia.org/wiki/Software_engineering_methodology#Specific_software_development_methodologies">processes and methodologies</a>. How many of these do you know? How many have you practiced?</p>
<table cellspacing="4" cellpadding="4" width="600">
<tbody>
<tr>
<td>1969</td>
<td><a href="http://en.wikipedia.org/wiki/Structured_programming">Structured programming</a></td>
</tr>
<tr>
<td>1975</td>
<td><a href="http://en.wikipedia.org/wiki/Jackson_Structured_Programming">Jackson Structured Programming </a></td>
</tr>
<tr>
<td>1980</td>
<td><a href="http://en.wikipedia.org/wiki/Structured_Systems_Analysis_and_Design_Methodology">Structured Systems Analysis and Design Methodology</a></td>
</tr>
<tr>
<td>1980</td>
<td><a href="http://en.wikipedia.org/wiki/Structured_Analysis_and_Design_Technique">Structured Analysis and Design Technique</a></td>
</tr>
<tr>
<td>1981</td>
<td><a href="http://en.wikipedia.org/wiki/Information_Engineering">Information Engineering</a></td>
</tr>
<tr>
<td>1990</td>
<td><a href="http://en.wikipedia.org/wiki/Object-oriented_programming">Object-oriented programming</a></td>
</tr>
<tr>
<td>1991</td>
<td><a href="http://en.wikipedia.org/wiki/Rapid_application_development">Rapid Application Development</a></td>
</tr>
<tr>
<td>1990</td>
<td><a href="http://en.wikipedia.org/wiki/Virtual_finite_state_machine">Virtual finite state machine </a></td>
</tr>
<tr>
<td>1995</td>
<td><a href="http://en.wikipedia.org/wiki/Dynamic_Systems_Development_Method">Dynamic Systems Development Method</a></td>
</tr>
<tr>
<td>1998</td>
<td><a href="http://en.wikipedia.org/wiki/Scrum_(development)">Scrum</a></td>
</tr>
<tr>
<td>1999</td>
<td><a href="http://en.wikipedia.org/wiki/Extreme_Programming">Extreme Programming</a></td>
</tr>
<tr>
<td>2002</td>
<td><a href="http://en.wikipedia.org/wiki/Enterprise_Unified_Process">Enterprise Unified Process</a></td>
</tr>
<tr>
<td>2003</td>
<td><a href="http://en.wikipedia.org/wiki/Rational_Unified_Process">Rational Unified Process</a></td>
</tr>
<tr>
<td>2004</td>
<td><a href="http://en.wikipedia.org/wiki/Constructionist_design_methodology">Constructionist Design Methodology</a></td>
</tr>
<tr>
<td>2005</td>
<td><a href="http://en.wikipedia.org/wiki/Agile_Unified_Process">Agile Unified Process</a></td>
</tr>
</tbody>
</table>
<p>And how do we expect the average developer to find out about these? In a word, <strong>marketing</strong>. (I could have <a href="http://blog.codinghorror.com/software-development-its-a-religion/">substituted religion</a> here without much change in meaning.)  It's no coincidence that a lot of the proponents of these methodologies make their living consulting and teaching about them. And they have their work cut out for them, too, because <a href="http://www.ericsink.com/entries/Note_to_self.html">most programmers are unreachable</a>:</p>
<blockquote>
<p>I was sitting in my office chatting with my coworker Jeremy Sheeley.  Jeremy leads the dev team for Vault and Fortress.  In the course of our discussion, I suddenly realized that none of our marketing efforts would reach Jeremy.  He doesn't go to trade shows or conferences.  He doesn't read magazines.  He doesn't read blogs.  He doesn't go to user group meetings.<br>
Jeremy is a decision-maker for the version control tool used by his team, and nothing we are doing would make him aware of our product.  How many more Jeremies are out there?</p>
</blockquote>
<p>Millions! As Seth Godin notes, the <a href="http://sethgodin.typepad.com/seths_blog/2007/05/reaching_the_un.html">unreachable are now truly unreachable</a> – at least not through marketing.</p>
<p>So, if we know the programmers who would benefit most from these rules and principles and guidelines are:</p>
<ul>
<li>highly unlikely to ever read them of their own volition</li>
<li>almost impossible to reach through traditional <s>religion</s> marketing</li>
</ul>
<p>Remind me again – <strong>who, exactly, are we writing these principles, rules, guidelines, and methodologies for?</strong> If we're only reaching the programmers who are thoughtful enough to care about their work in the first place, what have we truly accomplished? I agree with Jeff R., who left this comment:</p>
<blockquote>
<p>There's nothing wrong with the <a href="http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod">SOLID principles</a>; they make sense to me. But I've been programming since the days of card readers and teletypes. They <em>won't</em> make sense to those with little experience. They don't know when or how to apply them appropriately. They get bogged down in the attempt.</p>
<p>So trying to follow them changes the focus from result to process. And that's deadly.</p>
</blockquote>
<blockquote>
<p>It's the job of the lead programmer or manager to see that good principles are followed, perhaps by guiding others invisibly, without explicitly mandating or even mentioning those principles.</p>
</blockquote>
<p>In my effort to <a href="http://blog.codinghorror.com/sucking-less-every-year/">suck less every year</a>, I've read hundreds of programming books. I've researched every modern programming methodology. I'm even a Certified Scrum Master<sup>tm</sup>. All of it, to me, seems like endlessly restated versions of four core fundamentals. But "four core fundamentals?" that's awful marketing. Nobody will listen in rapt, adoring attention to me as I pontificate, nor will they pay the exorbitant consulting fees I demand to support the lifestyle I have become accustomed to. It simply won't do. Not at all. So, I dub this:</p>
<h3>The Atwood System of Real Ultimate Programming Power</h3>
<ul>
<li><a href="http://blog.codinghorror.com/curlys-law-do-one-thing/">DRY</a></li>
<li><a href="http://blog.codinghorror.com/kiss-and-yagni/">KISS</a></li>
<li><a href="http://blog.codinghorror.com/were-building-the-space-shuttle/">YAGNI</a></li>
<li><a href="http://www.youtube.com/watch?v=nMupwUD8vzk">NAMBLA</a></li>
</ul>
<p>All those incredibly detailed rules, guidelines, methodologies, and principles? YAGNI. If it can't be explained on a single double-spaced sheet of paper, it's a waste of your time. Go read and write some code! And if you can't grok these fundamentals in the <a href="http://blog.codinghorror.com/how-to-become-a-better-programmer-by-not-programming/">first three or four years</a> of your programming career, well – <a href="http://discourse.codinghorror.com/t/mastering-guids-with-occams-razor/1004/2">this slightly modified R. Lee Ermey quote</a> comes to mind.</p>
<p><em>My name is Jeff, and I can't stop thinking about programming.</em> And <a href="http://blog.codinghorror.com/programming-love-it-or-leave-it/">neither should you</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/real-ultimate-programming-power/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Are You An Expert? ]]></title>
<link>https://blog.codinghorror.com/are-you-an-expert/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I think I have a problem with authority. Starting with <a href="http://www.codinghorror.com/blog/archives/001124.html">my own</a>.
</p>
<blockquote>
<p>
It troubles me greatly to hear that people see me as an expert or an authority, and not a fellow amateur.
</p>
<p>
If I've learned anything in my career, it is that approaching software development as an expert, as someone who has already discovered everything there is to know about a given topic, is the one surest way to fail.
</p>
<p>
Experts are, if anything, more suspect than the amateurs, because they're less honest. You <em>should</em> question everything I write here, in the same way you question everything you've ever read online – or anywhere else for that matter. Your own research and data should trump any claims you read from anyone, no matter how much of an authority or expert you, I, Google, or the general community at large may believe them to be.
</p>
</blockquote>
<p>
Have you ever worked with software developers who <a href="http://it.toolbox.com/blogs/alexexmachina/horror-stories-for-programmers-beware-the-bogus-experts-14999">thought of themselves as experts</a>, with almost universally painful results? I certainly have. You might say I've developed <strong>an anti-expert bias</strong>. Apparently, so has Wikipedia; a section titled <a href="http://en.wikipedia.org/wiki/Wikipedia:Expert_editors#Warnings_to_expert_editors">warnings to expert editors</a> explains:
</p>
<ol>
<li>Experts can identify themselves on their user page and list whatever credentials and experience they wish to publicly divulge. It is difficult to maintain a claim of expertise while being anonymous. In practice, there is no advantage (and considerable disadvantage) in divulging one's expertise in this way.<br><br>
</li>
<li>Experts do not have any other privileges in resolving edit conflicts in their favor: in a content dispute between a (supposed) expert and a non-expert, it is not permissible for the expert to "pull rank" and declare victory. In short, "Because I say so" is never an acceptable justification for a claim in Wikipedia, regardless of expertise. Likewise, expert contributions are not protected from subsequent revisions from non-experts, nor is there any mechanism to do so. Ideally, if not always in practice, it is the quality of the edits that counts.<br><br>
</li>
<li>There is <strong>a strong undercurrent of anti-expert bias in Wikipedia</strong>. Thus, if you become recognized as an expert you will be held to higher standards of conduct than non-experts.
</li>
</ol>
<p>
Let's stop for a moment to savor the paradox of a free and open encyclopedia written by people who <a href="http://www.kuro5hin.org/story/2004/12/30/142458/25">view the contributions of experts with healthy skepticism</a>. How could that possibly work?
</p>
<p>
I'd argue that's the only way it <em>could</em> work – when all contributions are viewed critically, regardless of source. This is a radical inversion of power. But a radical inversion of power is exactly what is required. There are only a handful of experts, but untold million amateurs. And the <a href="http://www.codinghorror.com/blog/archives/001222.html">contributions of these amateurs is absolutely essential</a> when you're trying to generate a website that contains a page for.. well, everything. The world is a fractal place, filled with infinite detail. Nobody knows this better than software developers. The programmers in the trenches, spending every day struggling with the details, are the people who often have the most local knowledge about narrow programming topics. There just aren't enough experts to go around.
</p>
<p>
So what does it mean to be an expert, then, when <strong>expertise is perceived as impractical at best, and a liability at worst?</strong> In a <a href="http://www.youtube.com/watch?v=3FTwaojNkXw">recent Google talk</a>, James Bach presented the quintessential postmodern image of an expert performing – <a href="http://www.imdb.com/name/nm0000537/">Steve McQueen</a> in <a href="http://www.imdb.com/title/tt0072308/">The Towering Inferno</a>:
</p>
<blockquote>
<strong>[turns to fire commissioner] What do we got here, Kappy?</strong><br>
Fire started, 81st floor, storage room. It's bad. Smoke's so thick, we can't tell how far it's spread.<br>
<strong>Exhaust system?</strong><br>
Should've reversed automatically. It must be a motor burnout.<br>
<strong>Sprinklers?</strong><br>
They're not working on 81.<br>
<strong>Why not?</strong><br>
I don't know.<br>
<p>
<img alt="image placeholder" >
</p>
<p>
<strong>[turns to architect] Jim? Give us a quick refresher on your standpipe system.</strong><br>
Floors have 3 and 1.5 inch outlets.<br>
<strong>GPM?</strong><br>
Fifteen hundred from ground to 68, and 1,000 from 68 to 100, and 500 from there to the roof.<br>
<strong>Are these elevators programmed for emergencies?</strong><br>
Yes.<br>
<strong>What floor are your plans on?</strong><br>
79. My office.<br>
<strong>That's two floors below the fire. It'll be our Forward Command. Men, take up the equipment. I want to see all floor plans, 81 through 85.</strong><br>
Gotcha.<br>
<strong>[turns to security chief] Give me a list of your tenants.</strong><br>
Don't worry, we're moving them out now.<br>
<strong>Not live-ins. Businesses.</strong><br>
We lucked out. Most of them haven't moved in yet. Those that have are off at night.<br>
<strong>I want to know who they are, not where.</strong><br>
What's that got to do with anything? Who they are?<br>
<strong>Any wool or silk manufacturers? In a fire, wool and silk give off cyanide gas. Any sporting good manufacturers, like table-tennis balls? They give off toxic gases. Now do you want me to keep going?</strong><br>
One tenant list, coming up.<br>
<strong>[turns to crew leader] What do we got?</strong><br>
Elevator bank, central core. Service elevators here. Air conditioning ducts, 6 inches.<br>
<strong>Pipe alleys here?</strong><br>
One, two, three, four, five.<br>
<strong>Have you got any construction on 81? Anything that can blow up, like gasoline, fabric cleaner?</strong><br>
I don't think so.
</p>
</blockquote>
<p>
What does this tell us? I mean, other than … Steve McQueen is a badass? <strong>Being an expert isn't telling other people what you know.</strong> It's understanding what questions to ask, and flexibly applying your knowledge to the specific situation at hand. Being an expert means providing sensible, highly contextual direction.
</p>
<p>
What I love about <a href="http://www.youtube.com/watch?v=3FTwaojNkXw">James Bach's presentation</a> is how he spends the entire first half of it questioning and deconstructing everything – his field, his expertise, his own reputation and credentials, even! And then, <em>only</em> then, he cautiously, slowly builds it back up through a process of continual learning.
</p>
<blockquote>
<strong>Level 0</strong>: I overcame <em>obliviousness</em><br>
I now realize there is something here to learn.
<p>
<strong>Level 1</strong>: I overcame <em>intimidation</em><br>
I feel I can learn this subject or skill. I know enough about it so that I am not
intimidated by people who know more than me.
</p>
<p>
<strong>Level 2</strong>: I overcame <em>incoherence</em><br>
I no longer feel that I'm pretending or hand-waving. I feel reasonably
competent to discuss or practice. What I say sounds like what I think I know.
</p>
<p>
<strong>Level 3</strong>: I overcame <em>competence</em>.<br>
Now I feel productively self-critical, rather than complacently good enough.
I want to take risks, invent, teach, and push myself. I want to be with other
enthusiastic students.
</p>
</blockquote>
<p>
Insight like this is why Mr. Bach is <a href="http://www.buccaneerscholar.com/blog/archives/3">my favorite Buccaneer-Scholar</a>. He leaves us with this bit of advice to New Experts:
</p>
<blockquote>
<ul>
<li>Practice, practice, practice!
</li>
<li>Don't confuse experience with expertise.
</li>
<li>Don't trust folklore – but learn it anyway.
</li>
<li>Take nothing on faith. Own your methodology.
</li>
<li>Drive your own education – no one else will.
</li>
<li>Reputation = Money. <strong>Build and protect your reputation.</strong>
</li>
<li>Relentlessly gather resources, materials, and tools.
</li>
<li>Establish your standards and ethics.
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000771.html">Avoid certifications</a> that trivialize the craft.
</li>
<li>Associate with demanding colleagues.
</li>
<li>Write, speak, and <em>always tell the truth as you see it</em>.
</li>
</ul>
</blockquote>
<p>
Of course, Mr. Bach is talking about testing here, but I believe his advice applies equally well to developing expertise in programming, or anything else you might do in a professional capacity. It starts with questioning <em>everything</em>, most of all yourself.
</p>
<iframe width="480" height="360" src="//www.youtube.com/embed/3FTwaojNkXw" frameborder="0" allowfullscreen></iframe>
<p>
So if you want to be an expert in practice rather than in name only, take a page from Steve McQueen's book. Don't be the guy telling everyone what to do. <em>Be the guy asking all the questions.</em>
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/are-you-an-expert/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Bad Apple: Group Poison ]]></title>
<link>https://blog.codinghorror.com/the-bad-apple-group-poison/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>A recent episode of <a href="http://www.thisamericanlife.org/radio-archives/episode/370/ruining-it-for-the-rest-of-us">This American Life</a> interviewed Will Felps, a professor who conducted a sociological experiment demonstrating the <a href="http://www.thisamericanlife.org/radio-archives/episode/370/ruining-it-for-the-rest-of-us">surprisingly powerful effect of bad apples</a>.</p>
<p>Groups of four college students were organized into teams and given a task to complete some basic management decisions in 45 minutes. To motivate the teams, they're told that whichever team performs best will be awarded $100 per person. What they don't know, however, is that in some of the groups, the fourth member of their team isn't a student. He's an actor hired to play a bad apple, one of these personality types:</p>
<ul>
<li>
<strong>The Depressive Pessimist</strong> will complain that the task that they're doing isn't enjoyable, and make statements doubting the group's ability to succeed.</li>
<li>
<strong>The Jerk</strong> will say that other people's ideas are not adequate, but will offer no alternatives himself. He'll say "you guys need to listen to the expert: me."</li>
<li>
<strong>The Slacker</strong> will say "whatever", and "I really don't care."</li>
</ul>
<blockquote>
<p>The conventional wisdom in the research on this sort of thing is that none of this should have had much effect on the group at all. Groups are powerful. Group dynamics are powerful. And so groups dominate individuals, not the other way around. There's tons of research, going back decades, demonstrating that people conform to group values and norms.</p>
</blockquote>
<p>But Will found the opposite.</p>
<p><strong>Invariably, groups that had the bad apple would perform worse.</strong> And this despite the fact that were people in some groups that were very talented, very smart, very likeable. Felps found that the bad apple's behavior had a profound effect – groups with bad apples performed 30 to 40 percent worse than other groups. On teams with the bad apple, people would argue and fight, they didn't share relevant information, they communicated less.</p>
<p>Even worse, <strong>other team members began to take on the bad apple's characteristics</strong>. When the bad apple was a jerk, other team members would begin acting like a jerk. When he was a slacker, they began to slack, too. And they wouldn't act this way just in response to the bad apple. They'd act this way to each other, in sort of a spillover effect.</p>
<p>What they found, in short, is that <strong>the worst team member is the best predictor of how any team performs</strong>. It doesn't seem to matter how great the best member is, or what the average member of the group is like. It all comes down to what your worst team member is like. The teams with the worst person performed the poorest.</p>
<p>The actual <a href="http://liberalorder.typepad.com/the_liberal_order/files/bad_apples_rob.pdf">text of the study</a> (pdf) is available if you're interested. However, I highly recommend <a href="http://www.thisamericanlife.org/radio-archives/episode/370/ruining-it-for-the-rest-of-us">listening to the first 11 minutes of the This American Life show</a>. It's a fascinating, highly compelling recap of the study results. I've summarized, but I can't really do it justice without transcribing it all here.</p>
<p>Ira Glass, the host of This American Life, found Felps' results so striking that he began to question his <i>own</i> teamwork:</p>
<blockquote>
<p>I've really been struck at how common bad apples are. Truthfully, I've been kind of haunted by my conversation with Will Felps. Hearing about his research, you realize <strong>just how easy it is to poison any group</strong> [...] each of us have had moments this week where we wonder if we, unwittingly, have become the bad apples in our group.</p>
</blockquote>
<p>As always, self-awareness is the first step. If you can't tell who the bad apple is in your group, <i>it might be you</i>. Consider your own behavior on your own team – are you slipping into any of these negative bad apple behavior patterns, even in a small way?</p>
<p>But there was a solitary glimmer of hope in the study, one particular group that bucked the trend:</p>
<blockquote>
There was one group that performed really well, despite the bad apple. There was just one guy, who was a particularly good leader. And what he would do is ask questions, he would engage all the team members, and diffuse conflicts. I found out later that he's actually the son of a diplomat. His father is a diplomat from some South American country. He had this amazing diplomatic ability to diffuse the conflict that normally would emerge when our actor, Nick, would display all this jerk behavior.
</blockquote>
<p>This apparently led Will to his next research project: can a group leader change the dynamics and performance of a group by <a href="http://blog.codinghorror.com/are-you-an-expert/">going around and asking questions</a>, soliciting everyone's opinions, and making sure everyone is heard?</p>
<p>While it's depressing to learn that a group can be so powerfully affected by the worst tendencies of a single member, it's heartening to know that a skilled leader, if you're lucky enough to have one, can intervene and potentially control the situation.</p>
<p>Still, the obvious solution is to address the problem at its source: <strong>get rid of the bad apple</strong>.</p>
<p>Even if it's you.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-bad-apple-group-poison/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Rate Limiting and Velocity Checking ]]></title>
<link>https://blog.codinghorror.com/rate-limiting-and-velocity-checking/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Lately, I've been seeing these <b>odd little signs</b> pop up in storefronts around town.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
All the signs have various forms of this printed on them:
</p>
<p>
</p>
<blockquote>
Only <u>3</u> students at a time in the store please
</blockquote>
<p>
We took that picture at a 7-11 convenience store which happens to be near a high school, so maybe the problem is particularly acute there. But even farther into town, the same signs appear with disturbing regularity. I'm guessing the store owners must consider these rules necessary because:
</p>
<p>
</p>
<ul>
<li>teenage students are more likely to shoplift than most customers
</li>
<li>with many teenage students in the store, it's difficult for the owners to keep an eye on everyone, which further increases the likelihood of shoplifting.
</li>
</ul>
<p>
I'm just guessing; I don't own a store. But like the "no elephants" sign, it must be there to <a href="http://www.joelonsoftware.com/uibook/chapters/fog0000000059.html">address a real problem</a>.
</p>
<p>
</p>
<blockquote>
When you go into a restaurant and see a sign that says "No Dogs Allowed," you might think that sign is purely proscriptive: Mr. Restaurant doesn't like dogs around, so when he built the restaurant he put up that sign. If that was all that was going on, there would also be a "No Snakes" sign; after all, nobody likes snakes. And a "No Elephants" sign, because they break the chairs when they sit down. The real reason that sign is there is historical: it is a historical marker that indicates that people used to try to bring their dogs into the restaurant
</blockquote>
<p>
All these signs are enough to make me <b>question the ethics of high school students in groups of 3 or more</b>. Although, to be fair, I've seen some really shifty looking graduate students in my day.
</p>
<p>
In truth, these kinds of limits are <i>everywhere</i>; they're just not as obvious because there's often no signage trail to follow.
</p>
<p>
</p>
<ul>
<li>Most ATMs only allow you to withdraw $300 cash maximum in one day.
</li>
<li>Free email accounts typically limit how many emails can be sent per day.
</li>
<li>Internet providers limit individual download and upload speeds to ensure they aren't overselling their bandwidth.
</li>
<li>There's a maximum on how many Xbox Live Points you can add to your account per day. (<a href="http://en.wikipedia.org/wiki/Downloadable_content_in_Rock_Band">All 500+ Rock Band songs</a> aren't going to download themselves, after all.)
</li>
</ul>
<p>
I'm sure you can think of lots of other real world examples. They're all around you.
</p>
<p>
There are people who act like groups of rampaging teenage students online, too, and we deal with them in the same way: by <b>imposing rate limits!</b> Consider how <a href="http://googleonlinesecurity.blogspot.com/2007/07/reason-behind-were-sorry-message.html">Google limits any IP address that's submitting "too many" search requests</a>:
</p>
<p>
</p>
<blockquote>
Several things can trigger the sorry message.
<p>
<img alt="image placeholder" >
</p>
<p>
Often it's due to infected computers or DSL routers that proxy search traffic through your network - this may be at home or even at a workplace where one or more computers might be infected. Overly aggressive SEO ranking tools may trigger this message, too. In other cases, we have seen self-propagating worms that use Google search to identify vulnerable web servers on the Internet and then exploit them. The exploited systems in turn then search Google for more vulnerable web servers and so on.  This can lead to a noticeable increase in search queries and <i>sorry</i> is one of our mechanisms to deal with this.
</p>
</blockquote>
<p>
I did <a href="http://www.codinghorror.com/blog/archives/001186.html">a bit of Google scraping</a> once for a small research project, but I never ran into the CAPTCHA limiter. I think that entry predates its appearance. But it does make you wonder what typical search volumes are, and how they're calculated. <b>Determining how much is "too much" -- that's the art of rate limiting</b>. It's a tricky thing, even for the store owner:
</p>
<p>
</p>
<ul>
<li>Couldn't three morally bankrupt students shoplift just as effectively as four?
</li>
<li>How do you tell who is a student? Is it based purely on perception of age?
</li>
<li>Do we expect this rule to be self-enforcing? Will the fourth student walk into the store, identify three other students, and then decide to leave?
</li>
</ul>
<p>
Rate limiting isn't always a precise science. But it's <i>necessary</i>, even with the false positives -- consider <a href="http://www.codinghorror.com/blog/archives/001206.html">how dangerous a login entry with no limits on failed attempts</a> could be. This is especially true once your code is connected to the internet. Human students can be a problem, but there's a practical limit to how many students can fit in a store, and how fast they can physically shoplift your inventory. But <b>what if those "students" were an infinite number of computer programs, capable of stealing items from your web store at a rate only limited by network bandwidth?</b> Your store would be picked clean in a matter of minutes. Maybe even seconds!
</p>
<p>
Not having any sort of rate limiting in your web application is an open invitation to abuse. Even the most innocuous of user actions, if done rapidly enough and by enough users, could have potentially disastrous effects.
</p>
<p>
Even after you've instituted a rate limit, you can still get in trouble. On Stack Overflow, we <a href="http://www.codinghorror.com/blog/archives/001123.html">designed for evil</a>. We have a Google-style rate limiting CAPTCHA in place, along with a variety of other bot defeating techniques. They'be been working well so far. But what we failed to consider was that a determined (and apparently ultra-bored) <i>human</i> user could sit there and <a href="http://blog.stackoverflow.com/2009/02/new-question-answer-rate-limits/">solve CAPTCHAs as fast as possible to spam the site</a>.
</p>
<p>
And thus was born a new user based limit. I suppose we could create a little sign and hang it outside our virtual storefront:
</p>
<p>
</p>
<blockquote>
Only 1 question per new user every 10 minutes, please.
</blockquote>
<p>
There are a few classes of rate limiting or velocity checking you can do:
</p>
<p>
</p>
<ol>
<li>
<b>Per user or API key</b>. Ensure that any given user account or API account key holder can only perform (n) actions per minute. This is usally fairly safe, though it won't protect you from a user who automates the creation of 100 puppet accounts to do their bidding. It all depends how strictly you tie identity to the API key or user; you can easily ban, or in the worst case, track down the culprits and ask them to desist.
<br><br>
</li>
<li>
<b>Per IP address</b>. Ensure that any given IP address can only perform (n) actions per minute. This works well in the typical case, but can cause problems for multiple users who happen to be behind a proxy that makes them appear to you as the "same" IP address. This is the only method possible on mostly anonymous sites like Craigslist, and it definitely works, because <a href="http://www.codinghorror.com/craigslist/">I've been on the receiving end of it</a>. Example implementations are <a href="http://www.zdziarski.com/projects/mod_evasive/">mod_evasive</a> for Apache, or the <a href="http://learn.iis.net/page.aspx/548/using-dynamic-ip-restrictions/">IIS7 Dynamic IP Restriction module</a>.
<br><br>
</li>
<li>
<b>Per global action</b>. Ensure that a particular action can only happen (n) times per minute. Kind of the nuclear option, so obviously must be used with care. Can make sense for the "big red launch button" administrator functions which should be extraordinarily rare -- until a malicious user happens to gain administrator rights and starts pushing that big red button over and over.
</li>
</ol>
<p>
I was shocked how little comprehensive information was out there on rate limiting and velocity checking for software developers, because <b>they are your first and most important line of defense against a broad spectrum of possible attacks</b>. It's amazing how many attacks you can mitigate or even <i>defeat</i> by instituting basic rate limiting.
</p>
<p>
Take a long, hard look your own website -- how would it deal with a roving band of bored, morally ambiguous schoolkids?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/rate-limiting-and-velocity-checking/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Who's Your Coding Buddy? ]]></title>
<link>https://blog.codinghorror.com/whos-your-coding-buddy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I am continually amazed how much better my code becomes after I've had a peer look at it. I don't mean a formal review in a meeting room, or making my code open to anonymous public scrutiny on the internet, or some kind of onerous <a href="http://en.wikipedia.org/wiki/Pair_programming">pair programming</a> regime. Just <strong>one brief attempt at explaining and showing my code to a fellow programmer</strong> – that's usually all it takes.</p>
<p>This is, of course, nothing new. Karl Wiegers' excellent book <a href="http://www.amazon.com/dp/0201734850/?tag=codihorr-20">Peer Reviews in Software: A Practical Guide</a> has been the definitive guide since 2002.</p>
<p><a href="http://www.amazon.com/dp/0201734850/?tag=codihorr-20"><img alt="image placeholder" >
<p>I don't think anyone disputes the value of <a href="http://blog.codinghorror.com/pair-programming-vs-code-reviews/">having another pair of eyes on your code</a>, but there's a sort of institutional inertia that prevents it from happening in a lot of shops. In the chapter titled <a href="http://www.processimpact.com/reviews_book/reviews_book_toc.shtml">A Little Help from Your Friends</a>, Karl explains:</p>
<blockquote>
<p>Busy practitioners are sometimes reluctant to spend time examining a colleague's work. You might be leery of a coworker who asks you to review his code. Does he lack confidence? Does he want you to do his thinking for him? "Anyone who needs his code reviewed shouldn't be getting paid as a software developer," scoff some review resisters.</p>
<p>In a healthy software engineering culture, team members engage their peers to improve the quality of their work and increase their productivity. They understand that the time they spend looking at a colleague's work product is repaid when other team members examine their own deliverables. <strong>The best software engineers I have known actively sought out reviewers.</strong> Indeed, the input from many reviewers over their careers was part of what made these developers the best.</p>
</blockquote>
<p>In addition to the above chapter, you can sample <a href="http://www.processimpact.com/reviews_book/chapter_3.pdf">Chapter 3</a> (pdf) courtesy of the author's own <a href="http://processimpact.com/">Process Impact</a> website. This isn't just feel-good hand waving. There's actual data behind it. Multiple studies show <a href="http://blog.codinghorror.com/code-reviews-just-do-it/">code inspections are startlingly effective</a>.</p>
<blockquote>
<p>the average defect detection rate is only 25 percent for unit testing, 35 percent for function testing, and 45 percent for integration testing. In contrast, <strong>the average effectiveness of design and code inspections are 55 and 60 percent</strong>.</p>
</blockquote>
<p>So why aren't you doing code reviews? Maybe it's because <em>you haven't picked out a coding buddy yet!</em></p>
<p>Remember those school trips, where everyone was admonished to pick a buddy and stick with them? This was as much to keep everyone out of trouble as safe. Well, the same rule applies when you're building software. Before you check code in, <strong>give it a quick once-over with your buddy</strong>. Can you explain it? Does it make sense? Is there anything you forgot?</p>
<p>I am now required by law to link to <a href="http://www.osnews.com/story/19266/WTFs_m">this cartoon</a>.</p>
<p><a href="http://www.osnews.com/story/19266/WTFs_m"><img alt="image placeholder" >
<p>Thank you, I'll be here all week.</p>
<p>But seriously, this cartoon illustrates exactly the kind of broad reality check we're looking for. It doesn't have to be complicated to be effective. WTFs/minute is a perfectly acceptable unit of measurement to use with your coding buddy. The XP community has promoted <a href="http://www.extremeprogramming.org/rules/pair.html">pair programming</a> for years, but I think the buddy system is a far more practical way to achieve the same results.</p>
<p>Besides, who wouldn't want to be <strong>half of an awesome part-time coding dynamic duo?</strong><br>
<img alt="image placeholder" >
<p>That's way more exciting than the prospect of being shackled to the same computer with another person. Think about all the <em>other</em> classic dynamic duos out there:</p>
<ul>
<li>Batman and Robin</li>
<li><a href="http://www.imdb.com/title/tt0098439/">Tango and Cash</a></li>
<li>Lennon and McCartney</li>
<li>Cagney and Lacey</li>
<li>Mario and Luigi</li>
<li>Starsky and Hutch</li>
<li>Siegfried and Roy</li>
<li><a href="http://www.imdb.com/title/tt0098536/">Turner and Hooch</a></li>
<li>Abbott and Costello</li>
<li><a href="http://en.wikipedia.org/wiki/Miami_Vice">Crockett and Tubbs</a></li>
<li>Jobs and Wozniak</li>
<li>Thelma and Louise</li>
<li>Bert and Ernie</li>
<li><a href="http://en.wikipedia.org/wiki/CHiPs">Ponch and Jon</a></li>
<li>Hall and Oates</li>
<li>Cheech and Chong</li>
</ul>
<p>Individuals can do great things, but two highly motivated peers can accomplish even more when they work together. Surely there's at least <em>one</em> programmer you work with who you admire or at least respect enough to adopt the buddy system with. (And if not, you might consider <a href="http://blog.codinghorror.com/changing-your-organization-for-peons/">changing your company</a>.)</p>
<p>One of the great joys of programming is <a href="http://www.codinghorror.com/blog/archives/000890.html">not having to do it alone</a>. <strong>So who's <em>your</em> coding buddy?</strong></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whos-your-coding-buddy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Paying Down Your Technical Debt ]]></title>
<link>https://blog.codinghorror.com/paying-down-your-technical-debt/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Every software project I've ever worked on has <a href="http://martinfowler.com/bliki/TechnicalDebt.html">accrued technical debt</a> over time:</p>
<blockquote>
<p>Technical Debt is a wonderful metaphor <a href="http://www.c2.com/cgi/wiki?TechnicalDebt">developed by Ward Cunningham</a> to help us think about this problem. In this metaphor, doing things the quick and dirty way sets us up with a technical debt, which is similar to a financial debt. Like a financial debt, the technical debt incurs interest payments, which come in the form of the extra effort that we have to do in future development because of the quick and dirty design choice. We can choose to continue paying the interest, or we can pay down the principal by refactoring the quick and dirty design into the better design. Although it costs to pay down the principal, we gain by reduced interest payments in the future.</p>
<p>The metaphor also explains why it may be sensible to do the quick and dirty approach. Just as a business incurs some debt to take advantage of a market opportunity developers may incur technical debt to hit an important deadline. The all too common problem is that development organizations let their debt get out of control and spend most of their future development effort paying crippling interest payments.</p>
</blockquote>
<p>No matter how talented and smart the software developers, all these tiny deferments begin to add up and cumulatively weigh on the project, dragging it down. My latest project is no different. After six solid months working on the Stack Overflow codebase, this is <i>exactly</i> where we are. We're digging in our heels and retrenching for a major refactoring of our database.  We have to <b>stop working on new features for a while and pay down some of our technical debt</b>.</p>
<img alt="image placeholder" >
<p>I believe that accruing technical debt is unavoidable on any real software project. Sure, you <a href="http://c2.com/cgi/wiki?RefactorAsYouGo">refactor as you go</a>, and incorporate improvements when you can – but it's impossible to predict exactly how those key decisions you made early on in the project are going to play out. All you can do is roll with the punches, and budget some time into the schedule to <b>periodically pay down your technical debt.</b></p>
<p>The time you take out of the schedule to make technical debt payments typically doesn't result in anything the customers or users will see. This can sometimes be hard to justify. In fact, I had to defend our decision with Joel, my business partner. He'd prefer we work on some crazy thing he calls <i>revenue generation</i>, whatever that is.</p>
<p>Steve McConnell has a <a href="https://web.archive.org/web/20080119115611/http://blogs.construx.com/blogs/stevemcc/archive/2007/11/01/technical-debt-2.aspx">lengthy blog entry examining technical debt</a>. The perils of not ackowledging your debt are clear:</p>
<blockquote>
<p>One of the important implications of technical debt is that it must be <i>serviced</i>, i.e., once you incur a debt there will be interest charges. <b>If the debt grows large enough, eventually the company will spend more on servicing its debt than it invests in increasing the value of its other assets.</b> A common example is a legacy code base in which so much work goes into keeping a production system running (i.e., "servicing the debt") that there is little time left over to add new capabilities to the system. With financial debt, analysts talk about the "debt ratio," which is equal to total debt divided by total assets. Higher debt ratios are seen as more risky, which seems true for technical debt, too.</p>
</blockquote>
<p>Beyond what Steve describes here, I'd also argue that <b>accumulated technical debt becomes a major disincentive to work on a project.</b> It's a collection of small but annoying things that you have to deal with every time you sit down to write code. But it's exactly these small annoyances, this sand grinding away in the gears of your workday, that eventually causes you to stop enjoying the project. <a href="http://blog.codinghorror.com/revisiting-the-xml-angle-bracket-tax/">These small things matter</a>.</p>
<p>It can be scary to go in and <b>rebuild a lot of working code that has become crufty over time.</b> But <a href="http://en.wikipedia.org/wiki/Bene_Gesserit#Litany_against_fear">don't succumb to fear</a>.</p>
<blockquote>
<p><em>I must not fear.</em><br>
Fear is the mind-killer.<br>
Fear is the little-death that brings total obliteration.<br>
I will face my fear.<br>
I will permit it to pass over me and through me.<br>
And when it has gone past I will turn the inner eye to see its path.<br>
Where the fear has gone there will be nothing.<br>
Only I will remain.</p>
</blockquote>
<p>When it comes time to pay down your technical debt, <a href="http://blog.codinghorror.com/dont-be-afraid-to-break-stuff/">don't be afraid to break stuff</a>. It's liberating, even energizing to tear down code in order to build it up stronger and better than it was before. Be brave, and realize that paying your technical debt every so often is a normal, necessary part of the software development cycle to avert massive interest payments later. After all, <a href="http://blog.codinghorror.com/how-to-stop-sucking-and-be-awesome-instead/">who wants to live forever?</a></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/paying-down-your-technical-debt/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ File Compression in the Multi-Core Era ]]></title>
<link>https://blog.codinghorror.com/file-compression-in-the-multi-core-era/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've been playing around a bit with file compression again, as we generate some very large backup files daily on <a href="http://stackoverflow.com">Stack Overflow</a>.
</p>
<p>
We're using the latest 64-bit version of <a href="http://www.7-zip.org/">7zip</a> (4.64) on our database server. I'm <a href="http://www.codinghorror.com/blog/archives/000942.html">not a big fan of more than dual core on the desktop</a>, but it's a no brainer for servers. The more CPU cores the merrier! This server has two quad-core CPUs, a total of 8 cores, and I was a little disheartened to discover that neither RAR nor 7zip seemed to make much use of more than 2.
</p>
<p>
Still, even if it does only use 2 cores to compress, the 7zip algorithm is amazingly effective, and has <a href="http://www.codinghorror.com/blog/archives/000799.html">evolved over the last few years to be respectably fast</a>. I used to <a href="http://www.codinghorror.com/blog/archives/000798.html">recommend RAR over Zip</a>, but given the increased efficiency of 7zip and the fact that it's free and RAR isn't, it's the logical choice now.
</p>
<p>
Here are some quick tests I performed <b>compressing a single 4.76 GB database backup file</b>. This was run on a server with dual quad-core 2.5 GHz Xeon E5420 CPUs.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="500">
<tr>
<td>7zip</td>
<td>fastest</td>
<td align="right">5 min</td>
<td align="right">14 MB/sec</td>
<td align="right">973 MB</td>
</tr>
<tr>
<td>7zip</td>
<td>fast</td>
<td align="right">7 min</td>
<td align="right">11 MB/sec</td>
<td align="right">926 MB</td>
</tr>
<tr>
<td>7zip</td>
<td>normal</td>
<td align="right">34 min</td>
<td align="right">2.5 MB/sec</td>
<td align="right">752 MB</td>
</tr>
<tr>
<td>7zip</td>
<td>maximum</td>
<td align="right">41 min</td>
<td align="right">2.0 MB/sec</td>
<td align="right">714 MB</td>
</tr>
<tr>
<td>7zip</td>
<td>ultra</td>
<td align="right">48 min</td>
<td align="right">1.7 MB/sec</td>
<td align="right">698 MB</td>
</tr>
</table>
<p>
For those of you who are now wondering, <i>wow, if 7zip does this well on maximum and ultra, imagine how it'd do on ultra-plus</i>, don't count on it. <b>There's a reason most compression programs default to certain settings as "normal".</b> Above these settings, <a href="http://www.codinghorror.com/blog/archives/000313.html">results tend to fall off a cliff</a>; beyond that sweet spot, you tend to get absurdly tiny increases in compression ratio in exchange for huge order of magnitude increases in compression time.
</p>
<p>
Now watch what happens when I switch 7zip to use the <a href="http://en.wikipedia.org/wiki/Bzip2">bzip2 compression algorithm</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
We'll compress that same 4.76 GB file, on the same machine:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="500">
<tr>
<td>bzip2</td>
<td>fastest</td>
<td align="right">2 min</td>
<td align="right">36 MB/sec</td>
<td align="right">1092 MB</td>
</tr>
<tr>
<td>bzip2</td>
<td>fast</td>
<td align="right">2.5 min</td>
<td align="right">29 MB/sec</td>
<td align="right">1011 MB</td>
</tr>
<tr>
<td>bzip2</td>
<td>normal</td>
<td align="right">3.5 min</td>
<td align="right">22 MB/sec</td>
<td align="right">989 MB</td>
</tr>
<tr>
<td>bzip2</td>
<td>maximum</td>
<td align="right">7 min</td>
<td align="right">12 MB/sec</td>
<td align="right">987 MB</td>
</tr>
<tr>
<td>bzip2</td>
<td>ultra</td>
<td align="right">21 min</td>
<td align="right">4 MB/sec</td>
<td align="right">986 MB</td>
</tr>
</table>
<p>
Why is bzip2 able to work so much <i>faster</i> than 7zip? Simple:
</p>
<p>
<b>7zip algorithm CPU usage</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>bzip2 algorithm CPU usage</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Bzip2 uses more than 2 CPU cores to parallelize its work</b>. I'm not sure what the limit is, but the drop-down selector in the 7zip GUI allows up to 16 when the bzip2 algorithm is chosen. I used 8 for the above tests, since that's how many CPU cores we have on the server.
</p>
<p>
Unfortunately, bzip2's increased speed is sort of moot at high compression levels. The difference between normal, maximum, and ultra compression is a meaningless 0.06 percent. It scales beautifully in time, but hardly at all in space. That's a shame, because that's exactly where you'd like to spend the speed increase of paralellization. Eking out a percent of size improvement <a href="http://users.elis.ugent.be/~wheirman/compression/index.php#ranking">could still make sense</a>, depending on the circumstances:
</p>
<p>
</p>
<blockquote>
<i>total time = compression time + n * (compressed file size / network speed + decompression time)</i>
<p>
For instance, if you compress a file to send it over a network once, <i>n</i> equals one and compression time will have a big influence. If you want to post a file to be downloaded many times, <i>n</i> is big so long compression times will weigh less in the final decision. Finally, slow networks will do best with a slow but efficient algorithm, while for fast networks a speedy, possibly less efficient algorithm is needed.
</p>
</blockquote>
<p>
On the other hand, the ability to <b>compress a 5 GB source file to a fifth of its size in two minutes flat</b> is pretty darn impressive. Still, I can't help wondering how fast the 7zip algorithm would be if it was rewritten and parallelized to take advantage of more than 2 CPU cores, too.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-02-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/file-compression-in-the-multi-core-era/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Promise and Peril of Jumbo Frames ]]></title>
<link>https://blog.codinghorror.com/the-promise-and-peril-of-jumbo-frames/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We sit at the intersection of two trends:
</p>
<p>
</p>
<ol>
<li>Most home networking gear, including routers, has safely <b>transitioned to gigabit ethernet</b>.
</li>
<li>The generation, storage, and transmission of large high definition video files is <a href="http://www.codinghorror.com/blog/archives/001197.html">becoming commonplace</a>.
</li>
</ol>
<p>
If that sounds like you, or someone you know, there's one tweak you should know about that can potentally improve your local network throughput quite a bit -- enabling <a href="http://en.wikipedia.org/wiki/Jumbo_frame">Jumbo Frames</a>.
</p>
<p>
The typical UDP packet looks something like this:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But the default size of that data payload was established years ago. In the context of gigabit ethernet and the amount of data we transfer today, it does seem a bit.. anemic.
</p>
<p>
</p>
<blockquote>
The original 1,518-byte MTU for Ethernet was chosen because of the high error rates and low speed of communications. If a corrupted packet is sent, only 1,518 bytes must be re-sent to correct the error. However, each frame requires that the network hardware and software process it. If the frame size is increased, the same amount of data can be transferred with less effort. This reduces CPU utilization (mostly due to interrupt reduction) and increases throughput by allowing the system to concentrate on the data in the frames, instead of the frames around the data.
</blockquote>
<p>
I use <a href="http://www.codinghorror.com/blog/archives/001107.html">my beloved energy efficient home theater PC</a> as an always-on media server, and I'm constantly transferring gigabytes of video, music, and photos to it. Let's try enabling jumbo frames for my little network.
</p>
<p>
The first thing you'll need to do is <b>update your network hardware drivers to the latest versions</b>. I <a href="http://blog.stackoverflow.com/2009/02/server-speed-tests/">learned this the hard way</a>, but if you want to play with advanced networking features like Jumbo Frames, you need the latest and greatest network hardware drivers. What was included with the OS is unlikely to cut it. Check on the network chipset manufacturer's website.
</p>
<p>
Once you've got those drivers up to date, look for <b>the Jumbo Frames setting in the advanced properties of the network card</b>. Here's what it looks like on two different ethernet chipsets:
</p>
<p>
<img alt="image placeholder" >
 
<img alt="image placeholder" >
</p>
<p>
That's my computer, and the HTPC, respectively. I was a little disturbed to notice that neither driver recognizes exactly the same data payload size. It's named "Jumbo Frame" with 2KB - 9KB settings in 1KB increments on the Realtek, and "Jumbo Packet" with 4088 or 9014 settings on the Marvell. I know that <b>technically, for jumbo frames to work, all the networking devices on the subnet have to agree on the data payload size</b>. I couldn't tell quite <i>what</i> to do, so I set them as you see above.
</p>
<p>
(I didn't change anything on my router / switch, which at the moment is the <a href="http://www.codinghorror.com/blog/archives/001010.html">D-Link DGL-4500</a>; note that <i>most</i> gigabit switches support jumbo frames, but you should always verify with the manufacturer's website to be sure.)
</p>
<p>
I then ran a few tests to see if there was any difference. I started with a simple file copy.
</p>
<p>
<b>Default network settings</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Jumbo Frames enabled</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
My file copy went from 47.6 MB/sec to 60.0 MB/sec. Not too shabby! But this is a very ad hoc sort of testing. Let's see what the <a href="http://www.passmark.com/products/pt_advnet.htm">PassMark Network Benchmark</a> has to say.
</p>
<p>
<b>Default network settings</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Jumbo Frames enabled</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This confirms what I saw with the file copy. With jumbo frames enabled, we go from <b>390,638 kilobits/sec to 477,927 kilobits/sec average</b>. A solid 20% improvement.
</p>
<p>
Now, jumbo frames aren't a silver bullet. <b>There's a reason jumbo frames are never enabled by default</b>: some networking equipment can't deal with the non-standard frame sizes. Like all deviations from default settings, it is absolutely possible to make your networking <i>worse</i> by enabling jumbo frames, so proceed with caution. This SmallNetBuilder article <a href="http://www.smallnetbuilder.com/content/view/30201/54/1/2/">outlines some of the pitfalls</a>:
</p>
<p>
</p>
<blockquote>
<b>1) For a large frame to be transmitted intact from end to end, every component on the path must support that frame size. </b>
<p>
The switch(es), router(s), and NIC(s) from one end to the other must <i>all</i> support the same size of jumbo frame transmission for a successful jumbo frame communication session.
</p>
<p>
<b>2) Switches that don't support jumbo frames will <i>drop</i> jumbo frames.</b>
</p>
<p>
In the event that both ends agree to jumbo frame transmission, there still needs to be end-to-end support for jumbo frames, meaning all the switches and routers must be jumbo frame enabled. At Layer 2, not all gigabit switches support jumbo frames. Those that do will forward the jumbo frames. Those that don't will drop the frames.
</p>
<p>
<b>3) For a jumbo packet to pass through a router, both the ingress and egress interfaces must support the larger packet size. Otherwise, the packets will be dropped or fragmented.</b>
</p>
<p>
If the size of the data payload can't be negotiated (this is known as <a href="http://en.wikipedia.org/wiki/Pmtud">PMTUD</a>, packet MTU discovery) due to firewalls, the data will be dropped with no warning, or "blackholed". And if the MTU isn't supported, the data will have to be fragmented to a supported size and retransmitted, reducing throughput.
</p>
</blockquote>
<p>
In addition to these issues, large packets can also hurt latency for gaming and voice-over-IP applications. Bigger isn't always better.
</p>
<p>
Still, if you regularly transfer large files, jumbo frames are <a href="http://www.smallnetbuilder.com/content/view/30201/54/1/3/">definitely worth looking into</a>. My tests showed a solid 20% gain in throughput, and for the type of activity on my little network, I can't think of any downside.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-promise-and-peril-of-jumbo-frames/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Procrastination and the Bikeshed Effect ]]></title>
<link>https://blog.codinghorror.com/procrastination-and-the-bikeshed-effect/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The book <a href="http://www.amazon.com/dp/0596007590/?tag=codihorr-20">Producing Open Source Software: How to Run a Successful Free Software Project</a> is a <b>fantastic reference for anyone involved in a software project</b> – whether you're running the show or not.</p>
<p><a href="http://www.amazon.com/dp/0596007590/?tag=codihorr-20"><img alt="image placeholder" >
<p>In addition to the dead-tree edition, the book is available in an appropriately open source free format at <a href="http://producingoss.com/">the official website</a>. The entire book is great, and worth a thorough read, even if you think open source <a href="http://www.flickr.com/photos/daviderickson/718933691/">is communism</a>.</p>
<p>My favorite chapter is <a href="http://producingoss.com/en/communications.html">the one on communication</a>. While important on any software project, communication is especially vital on open source projects, which are "bewilderingly diverse both in audiences and communication mechanisms." One particular pitfall of open source projects is that, if you don't manage the project carefully, you can tend to attract developers who <a href="https://blog.codinghorror.com/the-code-first-dictum/">are more interested in discussion than writing code</a>. It's a subtle but pernicious problem – communication gone wrong.</p>
<blockquote>
<p>Although discussion can meander in any topic, the probability of meandering goes up as the technical difficulty of the topic goes down. After all, the greater the technical difficulty, the fewer participants can really follow what's going on. Those who can are likely to be the most experienced developers, who have already taken part in such discussions thousands of times before, and know what sort of behavior is likely to lead to a consensus everyone can live with.</p>
<p>Thus, consensus is hardest to achieve in technical questions that are simple to understand and easy to have an opinion about, and in "soft" topics such as organization, publicity, funding, etc. People can participate in those arguments forever, because there are no qualifications necessary for doing so, no clear ways to decide (even afterward) if a decision was right or wrong, and because simply outwaiting other discussants is sometimes a successful tactic.</p>
<p>The principle that the amount of discussion is inversely proportional to the complexity of the topic has been around for a long time, and is known informally as <a href="http://bikeshed.com/">the Bikeshed Effect</a>.</p>
</blockquote>
<p>We've struggled with this on <a href="http://stackoverflow.com/">Stack Overflow</a>, too. The broad soft questions tend to get much more interest and attention than the narrow, technical coding questions that we originally intended the site for. We've made adjustments, but it's an unavoidable aspect of group dynamics. Who are we kidding? It's <i>fun</i> to discuss what color the bikeshed should be painted. Everyone has an opinion about their favorite color scheme.</p>
<img alt="image placeholder" >
<p>What many people don't realize is that the bikeshed effect is, in fact, <a href="http://esciencenews.com/articles/2009/01/12/why.we.procrastinate.and.how.stop">a form of procrastination</a>. And it can suck in highly technical developers, along with everyone else.</p>
<blockquote>
<p>The psychologists handed out questionnaires to a group of students and asked them to respond by e-mail within three weeks. All the questions had to do with rather mundane tasks like opening a bank account and keeping a diary, but different students were given different instructions for answering the questions. Some thought and wrote about what each activity implied about personal traits: what kind of person has a bank account, for example. Others wrote simply about the nuts and bolts of doing each activity: speaking to a bank officer, filling out forms, making an initial deposit, and so forth. The idea was to <b>get some students thinking abstractly and others concretely</b>. Then the psychologists waited. And in some cases, waited and waited. They recorded all the response times to see if there was a difference between the two groups, and indeed there was a significant difference.</p>
<p>The findings, reported in Psychological Science, a journal of the Association for Psychological Science, were very clear. Even though all of the students were being paid upon completion, <b>those who thought about the questions abstractly were much more likely to procrastinate – and in fact some never got around to the assignment at all.</b> By contrast, those who were focused on the how, when and where of doing the task e-mailed their responses much sooner, suggesting that they hopped right on the assignment rather than delaying it.</p>
</blockquote>
<p>This is one reason why <a href="https://blog.codinghorror.com/it-came-from-planet-architecture/">I'm so down on architecture astronauts</a>. I find that <b>the amount of discussion on a software feature is inversely proportional to its value</b>. Sure, have some initial discussion to figure out your direction, but the sooner you can get away from airy abstractions, and down to the nuts and bolts of <i>building the damn thing</i>, the better off you – and your project – will be.</p>
<p>Put another way, what's <a href="http://jeremy.zawodny.com/blog/archives/008581.html">the hardest thing you have to do every day?</a> Deciding what to ignore, so you can stop procrastinating and <i>get stuff done</i>. The next time you feel yourself getting drawn into a protracted bikeshed discussion, consider: shouldn't you be <a href="https://blog.codinghorror.com/yes-but-what-have-you-done/">building something instead?</a></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/procrastination-and-the-bikeshed-effect/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ HTML Validation: Does It Matter? ]]></title>
<link>https://blog.codinghorror.com/html-validation-does-it-matter/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The web is, to put it charitably, <a href="http://www.codinghorror.com/blog/archives/000848.html">a rather forgiving place</a>. You can feed web browsers almost <i>any</i> sort of HTML markup or JavaScript code and they'll gamely try to make sense of what you've provided, and render it the best they can. In comparison, most programming languages are almost cruelly unforgiving. If there's a single character out of place, your program probably won't compile, much less run. This makes the HTML + JavaScript environment a rather unique -- and often frustrating -- software development platform.
</p>
<p>
But it doesn't have to be this way. There are provisions and mechanisms for <b>validating your HTML markup</b> through the official <a href="http://validator.w3.org/">W3C Validator</a>. Playing with the validator underscores how deep that <a href="http://www.codinghorror.com/blog/archives/000848.html">forgiveness by default</a> policy has permeated the greater web. Dennis Forbes recently ran a number of websites through the validator, including this one, with predictably bad results:
</p>
<p>
</p>
<blockquote>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.reddit.com">http://www.reddit.com</a> - 36 errors as XHTML 1.0 Transitional. <strong>EDIT:</strong> Rechecked Reddit, and now it's a <span style="color:green;font-weight:bold;">PASS</span><br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.slashdot.org">http://www.slashdot.org</a> - 167 errors as HTML 4.01 Strict<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.digg.com">http://www.digg.com</a> - 32 errors as XHTML 1.0 Transitional<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.cnn.com">http://www.cnn.com</a> - 40 errors as HTML 4.01 Transitional (inferred as no doctype was specified)<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.microsoft.com">http://www.microsoft.com</a> - 193 errors as XHTML 1.0 Transitional<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.google.com">http://www.google.com</a> - 58 errors as HTML 4.01 Transitional<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.flickr.com">http://www.flickr.com</a> - 34 errors as HTML 4.01 Transitional<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://ca.yahoo.com">http://ca.yahoo.com</a> - 276 errors as HTML 4.01 Strict<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.sourceforge.net">http://www.sourceforge.net</a> - 65 errors as XHTML 1.0 Transitional<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.joelonsoftware.com">http://www.joelonsoftware.com</a> - 33 errors as XHTML 1.0 Strict<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.stackoverflow.com">http://www.stackoverflow.com</a> - 58 errors as HTML 4.01 Strict<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.dzone.com">http://www.dzone.com</a> - 165 errors as XHTML 1.0 Transitional<br>
<span style="color:red;font-weight:bold;">FAIL</span> - <a href="http://www.codinghorror.com/blog/">http://www.codinghorror.com/blog/</a> - 51 errors as HTML 4.01 Transitional<br>
<span style="color:green;font-weight:bold;">PASS</span> - <a href="http://www.w3c.org">http://www.w3c.org</a> - no errors as XHTML 1.0 Strict<br>
<span style="color:green;font-weight:bold;">PASS</span> - <a href="http://www.linux.com">http://www.linux.com</a> - no errors as XHTML 1.0 Strict<br>
<span style="color:green;font-weight:bold;">PASS</span> - <a href="http://www.wordpress.com">http://www.wordpress.com</a> - no errors as XHTML 1.0 Transitional<br>
</blockquote>
<p>
In short, <a href="http://www.codinghorror.com/blog/archives/000723.html">we live in malformed world</a>. So much so that <b>you begin to question whether validation matters at all</b>. If you see this logo on a site, what does it mean to you? How will it affect your experience on that website? As a developer? As a user?
</p>
<p>
<a href="http://validator.w3.org/"><img alt="image placeholder" >
</p>
<p>
We just went through the exercise of validating Stack Overflow's HTML. I almost immediately ruled out the idea of validating as XHTML, because I <a href="http://www.b-list.org/weblog/2008/jun/18/html/">vehemently agree with James Bennett</a>:
</p>
<p>
</p>
<blockquote>
The short and sweet reason is simply this: <b>XHTML offers no compelling advantage -- to me -- over HTML</b>, but even if it did it would also offer increased complexity and uncertainty that make it unappealing to me.
</blockquote>
<p>
The whole HTML validation exercise is questionable, but <a href="http://www.webdevout.net/articles/beware-of-xhtml">validating as XHTML is flat-out masochism</a>. Only recommended for those that enjoy pain. Or programmers. I can't always tell the difference.
</p>
<p>
Anyway, we validated as the <b>much saner HTML 4.01 strict</b>, and even then I'm not sure it was worth the time we spent. So many of these validation rules feel arbitrary and meaningless. And, what's worse, some of them are actively <i>harmful</i>. For example, this is not allowed in HTML strict:
</p>
<p>
</p>
<pre>
&lt;a href="http://www.example.com/" <font color="red">target="_blank"</font>&gt;foo&lt;/a&gt;
</pre>
<p>
That's right, <code>target</code>, a perfectly harmless attribute for links that you want to open in a different browser tab/window, is somehow verboten in HTML 4.01 strict. There's <a href="http://krijnhoetmer.nl/stuff/html/strict-doctype-target/">an officially supported workaround</a>, but it's <a href="http://www.quirksmode.org/bugreports/archives/2005/02/custom_dtds_int_1.html">only implemented by Opera</a>, so in effect .. there is no workaround.
</p>
<p>
In order to comply with the HTML 4.01 strict validator, you need to remove that <code>target</code> attribute and replace it with JavaScript that does the same thing. So, immediately I began to wonder: Is anybody validating our JavaScript? What about our CSS? Is anyone validating the DOM manipulations that JavaScript performs on our HTML? Who validates the validator? Why can't I stop thinking about zebras?
</p>
<p>
Does it <i>really</i> matter if we render stuff this way..
</p>
<p>
</p>
<pre>
&lt;td width="80"&gt;
&lt;br/&gt;
</pre>
<p>
.. versus this way?
</p>
<p>
</p>
<pre>
&lt;td style="width:80px"&gt;
&lt;br&gt;
</pre>
<p>
I mean, who makes up these rules? And for what reason?
</p>
<p>
I couldn't help feeling that validating as HTML 4.01 strict, at least in our case, was <b>a giant exercise in to-may-to versus to-mah-to</b>, punctuated by aggravating changes that we were forced to make for no practical benefit. (Also, if you have a ton of user-generated content like we do, you can pretty much throw any fantasies of 100% perfect validation <a href="http://diveintomark.org/archives/2004/01/14/thought_experiment">right out the window</a>.)
</p>
<p>
That said, <b>validation does have its charms</b>. There were a few things that the validation process exposed in our HTML markup that were clearly wrong -- an orphaned tag here, and a few inconsistencies in the way we applied tags there. Mark Pilgrim <a href="http://diveintomark.org/archives/2003/05/05/why_we_wont_help_you">makes the case for validation</a>:
</p>
<p>
</p>
<blockquote>
I am not claiming that your page, once validated, will automatically render flawlessly in every browser; it may not. I am also not claiming that there aren't talented designers who can create old-style "Tag Soup" pages that do work flawlessly in every browser; there certainly are. But the validator is an automated tool that can highlight small but important errors that are difficult to track down by hand. If you create valid markup most of the time, you can take advantage of this automation to catch your occasional mistakes. But if your markup is nowhere near valid, you'll be flying blind when something goes wrong. The validator will spit out dozens or even hundreds of errors on your page, and finding the one that is actually causing your problem will be like finding a needle in a haystack.
</blockquote>
<p>
There is some truth to this. <b>Learning the rules of the validator, even if you don't agree with them, teaches you what the official definition of "valid" is.</b> It grounds your markup in reality. It's sort of like passing your source code through an ultra-strict <a href="http://en.wikipedia.org/wiki/Lint_programming_tool">lint</a> validation program, or setting your compiler to the strictest possible warning level. Knowing the rules and boundaries helps you define what you're doing, and gives you legitimate ammunition for agreeing or disagreeing. You can make an informed choice, instead of a random "I just do this and it works" one.
</p>
<p>
After jumping through the HTML validation hoops ourselves, here's my advice:
</p>
<p>
</p>
<ol>
<li>
<b>Validate your HTML</b>. Know what it means to have valid HTML markup. Understand the tooling. More information is always better than less information. Why fly blind?
</li>
<li>
<b>Nobody cares if your HTML is valid</b>. Except you. If you want to. Don't think for a second that producing perfectly valid HTML is more important than running your website, delivering features that delight your users, or getting the job done.
</li>
</ol>
<p>
But the question remains: does HTML Validation really matter? Yes. No. Maybe. It depends. I'll tell you the same thing my father told me: <i>take my advice and do as you please</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/html-validation-does-it-matter/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Computer Performance Shell Game ]]></title>
<link>https://blog.codinghorror.com/the-computer-performance-shell-game/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The performance of any computer is akin to a <a href="http://en.wikipedia.org/wiki/Shell_game">shell game</a>.</p>
<img alt="image placeholder" >
<p>The <b>computer performance shell game</b>, also known as "find the bottleneck", is always played between these four resources:</p>
<ul>
<li>CPU</li>
<li>Disk</li>
<li>Network</li>
<li>Memory</li>
</ul>
<p>At any given moment, your computer is waiting for some operation to complete on one of these resources. <b>But which one: CPU, memory, disk, or network?</b> If you're interested in performance, the absolute first thing you have to do is determine which of these bottlenecks is currently impeding performance – and <i>eliminate it</i>. At which point the bottleneck often shifts to some other part of the system, far too rapidly for your eye to see. Just like a real shell game.</p>
<p>So the art of performance monitoring is, first and foremost, getting your computer to tell you what's going on in each of these areas – so you can make your best guess where the pea is right now.</p>
<p>My previous performance drug of choice was <a href="http://www.codinghorror.com/blog/archives/000393.html">Task Manager</a>, or its vastly more sophisticated bigger brother, <a href="http://www.codinghorror.com/blog/archives/000162.html">Process Explorer</a>. But now that I've discovered the <a href="http://www.winsupersite.com/showcase/winvista_ff_rmon.asp">Reliability and Performance Monitor</a>, I <i>can't stop watching it</i>. It is my crystal meth. While the previous tools were solid enough, they both had one glaring flaw. <b>They only showed CPU load and memory usage.</b> Those are frequently performance bottlenecks, to be sure, but they're only part of the story.</p>
<p>The <b>Reliability and Performance Monitoring tool</b>, while continuing the fine Microsoft product tradition of absolutely freaking horrible names, is new to Windows Vista and Windows Server 2008. And it rocks.</p>
<img alt="image placeholder" >
<p>Right off the bat you get a nice summary of what's going on in your computer performance shell game, with an overview graph and high water marks for CPU, Disk, Network, and Memory, along with scaled numbers. Eyeball this one key set of graphs and you can usually get a pretty good idea which part of your computer is working overtime.</p>
<p>There are also collapsible detail sections for each graph. On these detail sections, bear in mind the numbers are all live, and the default sort orders tend to bring the most active things to the top. And they <i>stay</i> at the top until they're no longer using that resource, at which point they disappear. The detail sections are a quick way to drill down into each resource and see what programs and processes are monopolizing it at any given time.</p>
<p>The <b>CPU detail section</b> gives you a moving average of CPU usage, which is much saner than Task Manager's always shifting numbers. Admittedly, this section isn't radically different than taskman – and it's functionally identical to <a href="http://en.wikipedia.org/wiki/Top_(Unix)">the Unix <code>top</code> command</a>. But the moving average alone is surprisingly helpful in avoiding obsessing over rapid peaks and valleys.</p>
<img alt="image placeholder" >
<p>The <b>Disk detail section</b> shows which processes are reading and writing to disk, for what filenames/paths, and how long it's taking to service those requests – in real time. I generally alternate between read and write sort order here, although sometimes response time can be informative as well.</p>
<img alt="image placeholder" >
<p>The <b>Network detail section</b> shows which processes are sending the most data over the network right now. On a public website, this gives you an at-a-glance breakdown of which IP addresses are hitting you the hardest. In fact, while checking this, I just laid down another IP ban for some random IP that was scraping the heck out of our site.</p>
<img alt="image placeholder" >
<p>The <b>Memory detail section</b> shows the five most essential metrics for memory usage in real time. Hard Faults are, of course, forced reads from disk into memory – something you want to keep a close eye on. And Working Set is the best general indicator of how much memory a process is actively using to do its thing.</p>
<img alt="image placeholder" >
<p>The computer performance shell game is nothing new; it is as old as computing itself. And it is a deeply satisfying game for <a href="http://www.codinghorror.com/blog/archives/000761.html">those of us who love this stuff</a>.</p>
<p>I <i>thought</i> I knew how to play it, until I discovered the Reliability and Performance Monitor. Now that I have a utility like this to let me suss out exactly where that performance pea is, I realize how much I was missing.</p>
<p>Now, on to <a href="http://en.wikipedia.org/wiki/Three-card_Monte">three card monte</a>. Watch my hands closely!</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-09T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-computer-performance-shell-game/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Can't Error Messages Be Fun? ]]></title>
<link>https://blog.codinghorror.com/why-cant-error-messages-be-fun/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I haven't had the opportunity to talk at all about <a href="http://www.google.com/chrome">Google's new Chrome browser</a> yet. Which is a shame, because it's <b>easily the best web browser I've ever used</b>. If it wasn't for the complete and utter lack of an add-in ecosystem, I'd switch away from Firefox in a heartbeat. If you're curious about Chrome, check out <a href="http://www.google.com/googlebooks/chrome/">the Scott McCloud comic</a> Google commissioned to explain it. Or, heck, <a href="http://www.google.com/chrome/eula.html">just try it yourself!</a>
</p>
<p>
Chrome is a joy to use, and in my opinion at least, it's the first <i>true</i> advance in web browser technology since the heady days of Internet Explorer 4.0. Chrome is filled with so many thoughtful details, so many reimaginings of web browser functionality as a true application platform, it's hard to even list them all.
</p>
<p>
In fact, the best way to explain how great Chrome is might arguably be one of the silliest, tiniest things about it -- <b>even Chrome's error messages are fun!</b> Here's an error I experienced last night while trying to clean up my GMail contacts list.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The tab is <i>frozen</i>, you see? With the snowflakes, its little scarf and teeth chattering in the cold? Rather than being annoyed with GMail, and blaming Chrome, I am completely disarmed by this error. It makes me laugh! It reminds me that the developers working on this software, rather than just taking the path of least resistance and spitting out a generic message box with a <a href="http://www.codinghorror.com/blog/archives/000525.html">cryptic error code</a>, took time to make their error messages not only user friendly, but <i>fun</i>.
</p>
<p>
I'm reminded of the <a href="http://www.codinghorror.com/blog/archives/000030.html">Beagle Brothers statement of quality</a>:
</p>
<p>
</p>
<blockquote>
Our programs are FUN to use. Our instructions are CLEAR and complete.
</blockquote>
<p>
And what happens if there's a serious rendering error on a Chrome tab, resulting in a per-tab process crash? <b>Aw, Snap!</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
These errors are subtle homages to the classic Macintosh <a href="http://www.sadmac.org/">Sad Mac</a>. Which is a tad ironic, as Chrome is very much Windows only, at least for now.
</p>
<p>
Now, none of this means that you shouldn't take errors seriously. As a competent and professional software developer, <a href="http://www.codinghorror.com/blog/archives/001118.html">you <i>will</i> crash responsibly</a>. Every time.  Humor alone is not the goal here.
</p>
<p>
Errors aren't the most glamorous part of software development. In fact, they're sort of a downer. But <b>the way you handle errors speaks volumes about how much you respect your users, and ultimately, your own project.</b> <a href="http://www.codinghorror.com/blog/archives/000979.html">Remember, this stuff is supposed to be fun!</a> Why not share some of that joy, that fun you had building your application, with your users? We certainly did this on Stack Overflow with our CAPTCHA and Error pages. It's a major drag for your users to end up on a human verification page, or a big fat honking server error. So why not ease the tension a bit by spending a little extra time on your errors and using them to illustrate the lighter side of software development?
</p>
<p>
Don't get me wrong. Your error messages should <a href="http://www.codinghorror.com/blog/archives/001118.html"><i>always</i> be informative and helpful</a>. That's not optional. But as Google Chrome shows us, it is possible to do that while <i>also</i> being fun. And that's even better.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-10T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-cant-error-messages-be-fun/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Sharpening the Saw ]]></title>
<link>https://blog.codinghorror.com/sharpening-the-saw/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As a software developer, how do you <b>sharpen your saw</b>?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Sharpening the saw is shorthand for anything you do that isn't <i>programming</i>, necessarily, but (theoretically) makes you a better programmer. It's derived from the Covey book <a href="http://www.amazon.com/dp/0743269519/?tag=codihorr-20">The 7 Habits of Highly Effective People</a>.
</p>
<p>
</p>
<blockquote>
There's a guy who stumbled into a lumberjack in the mountains. The man stops to observe the lumberjack, watching him feverishly sawing at this very large tree. He noticed that the lumberjack was working up a sweat, sawing and sawing, yet going nowhere. The bystander noticed that the saw the lumberjack was using was about as sharp as a butter knife. So, he says to the lumberjack, "Excuse me Mr. Lumberjack, but I couldn't help noticing how hard you are working on that tree, but going nowhere." The lumberjack replies with sweat dripping off of his brow, "Yes... I know. This tree seems to be giving me some trouble." The bystander replies and says, "But Mr. Lumberjack, your saw is so dull that it couldn't possibly cut through anything." "I know", says the lumberjack, "but I am too busy sawing to take time to sharpen my saw."
</blockquote>
<p>
Of course, the best way to improve at something is to <a href="http://www.codinghorror.com/blog/archives/001138.html"><b>do it as often as possible</b></a>. But if you're so heads down coding that you have no time for discussion, introspection, or study, you aren't really moving forward. You have to strike a mindful balance between practicing your craft and thinking about how you practice your craft.
</p>
<p>
Scott Hanselman has some solid ideas on ways to <a href="http://www.hanselman.com/blog/SharpenTheSawForDevelopers.aspx">encourage members of your development team to sharpen their saws</a>. And then there's the obvious way, the thing you're doing right now: <b>reading programming blogs</b>. I don't mean this blog, but ones of actual <i>worth</i>. If you keep an open mind, you can sharpen your saw that way, <a href="http://weblog.raganwald.com/2007/10/how-to-use-blunt-instrument-to-sharpen.html">as Reginald Braithwaite notes</a>:
</p>
<p>
</p>
<blockquote>
What we do is this: we read a blog post, reading thing after thing we agree with, and if just one thing in there doesn't fit our personal world view, we demand a correction. If the thesis of the post clashes with our prejudices, we accuse the author of being an idiot. Honestly, we would suck as salespeople. We would quit the first time someone disagreed with us.
<p>
What I suggest we do is mimic these salespeople. When we read a post, or a book, or look at a new language, let's assume that some or even most of it will not be new. Let's assume that we'll positively detest some of it. But let's also look at it in terms of our own profit: <b>we win if we can find just one thing in there that makes us better programmers</b>.
</p>
<p>
That's all we need from a blog post, you know. It's a huge win if there's one thing in a post. Heck, it's a huge win if we read one hundred posts and learn one new valuable thing.
</p>
</blockquote>
<p>
If you're looking for good programming blogs to sharpen your saw (or at least pique your intellectual curiosity), I know of two <b>excellent programming specific link aggregation sites</b> that can help you find them.
</p>
<p>
The first is <a href="http://news.ycombinator.com/news">Hacker News</a>, which I recommend highly.
</p>
<p>
<a href="http://news.ycombinator.com/news"><img alt="image placeholder" >
</p>
<p>
<a href="http://news.ycombinator.com/news">Hacker News</a> is the brainchild of <a href="http://www.paulgraham.com/">Paul Graham</a>, so it partially reflects his interests in <a href="http://ycombinator.com/">Y Combinator</a> and entrepreneurial stuff like startups. Paul is serious about moderation on the site, so in addition to the typical Digg-style voting, there's a secret cabal (I like to think of it as <a href="http://www.youtube.com/watch?v=yfY1wa8oVN0">The Octagon</a>, "no one will admit they still exist!") of hand-picked editors who remove flagged posts. More importantly, the conversation on the site about the articles is quite rational, with very little noise and trolling.
</p>
<p>
The other site is <a href="http://www.reddit.com/r/programming/">programming reddit</a>. The conversation there is more chaotic, with a wild-west anything goes sensibility, gated only by the up and down votes of the community. But it is quite reliable for digging up a great variety of links that are of particular interest to programmers.
</p>
<p>
Of course, too much saw sharpening, or random, aimless saw sharpening, can become <a href="http://www.codinghorror.com/blog/archives/000922.html">another form of procrastination</a>. But a developer who seems completely disinterested in it at all is a huge red flag. As Peter Bregman explains, <a href="http://blogs.harvardbusiness.org/cs/2009/01/the_interview_question_you_sho.html">obsession can be a good thing</a>:
</p>
<p>
</p>
<blockquote>
People are often successful not despite their dysfunctions but because of them. <b>Obsessions are one of the greatest telltale signs of success.</b> Understand a person's obsessions and you will understand her natural motivation. The thing for which she would walk to the end of the earth.
</blockquote>
<p>
It's OK to be a <i>little</i> obsessed with sharpening your saw, if it means actively <b>submitting and discussing programming articles on, say, <a href="http://news.ycombinator.com/">Hacker News</a></b>.
</p>
<p>
What do you recommend for sharpening <i>your</i> saw as a programmer?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-10T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/sharpening-the-saw/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Spawned a New Process ]]></title>
<link>https://blog.codinghorror.com/spawned-a-new-process/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Back in September 2008, I mentioned that we were <a href="http://www.codinghorror.com/blog/archives/001168.html">spawning a new process</a>. Well, that process arrived today, and its id is <b>Henry Burton Atwood</b>.
</p>
<p>
We're starting him off right with a little light reading.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You may recognize this book from Apple's Mac vs PC ad series, specifically, <a href="http://www.youtube.com/watch?v=zSgIb0xBQhk&amp;fmt=18">the "Gift Exchange" Mac vs PC ad</a>.
</p>
<p>
<a href="http://www.youtube.com/watch?v=zSgIb0xBQhk&amp;fmt=18"><img alt="image placeholder" >
</p>
<p>
Because, truly, what better gift is there for a newborn than <b>the C++ GUI Programming Guide</b>?  <a href="http://www.youtube.com/watch?v=zSgIb0xBQhk&amp;fmt=18">Watch the ad</a> to see what I mean. <i>"I've been eyeing that myself."</i>
</p>
<p>
All credit for creation of this new process of course goes to my wife Betsy who did the <i>real</i> work. I now truly understand the meaning of <a href="http://www.youtube.com/watch?v=_w-AG_yF1Uw">the classic Bill Cosby skit on childbirth</a>.
</p>
<p>
Helping my wife walk the pain scale, going from pain level 7/10, 8/10 and then seeing the maw of darkness that lies at pain scale 10/10 and beyond, was quite an experience. How much pain? Well, imagine the worst pain you've ever experienced. Now imagine taking that pain, packing it in to a rickety Oldsmobile, setting it on fire, then driving it off the edge of a cliff at maximum speed. Into a valley filled with white-hot molten lava.
</p>
<p>
It's a little bit worse than that.
</p>
<p>
You may have heard that childbirth is a mystical, spiritual process. The thing that ties every human being together as one long continuous string of life, extending all the way back to the beginning of time. To a point, it is. As my friend <a href="http://haacked.com">Phil</a> said, it's all ponies and butterflies. Until the ponies and butterflies start spontaneously screaming. But, it was all worth it to get Henry, who is genetically engineered to be <i>awesome</i>. Being a geek from birth, Henry has <a href="http://twitter.com/rockhardawesome">his own Twitter account</a>, which was opened with exactly the first message you'd expect:
</p>
<p>
<a href="http://twitter.com/rockhardawesome/status/1314984401"><img alt="image placeholder" >
</a>
</p>
<p>
Hello World. Literally.
</p>
<p>
If you've been reading my blog for a while, I'm sure you know <b>I will approach our new parenting adventure the same way I do programming</b> -- with absolutely no freaking idea what I'm doing. And often hilarious results.
</p>
<p>
Here's to you, little guy, and every other little programmer being born around the world.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-12T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/spawned-a-new-process/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The World's Largest MMORPG: You're Playing it Right Now ]]></title>
<link>https://blog.codinghorror.com/the-worlds-largest-mmorpg-youre-playing-it-right-now/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was struck by the conclusion of Andy Oram's <a href="http://radar.oreilly.com/archives/2008/02/developing-an-i.html">thoughtful piece on the next generation of online forums</a>.
</p>
<p>
</p>
<blockquote>
People who want to learn more about computer technology and solve problems they encounter on their systems currently have a wealth of forums to turn to: mailing lists and newsgroups, official and unofficial documentation (which may be distributed on the Web, on their systems, or in printed form) and the more collaborative media of IRC channels, wikis, and virtual worlds.
<p>
Why tamper with this set of resources? Because they are not as easy to find or to use as they should be. Each medium was invented for purposes other than the specific task of educating computer users, and have never been tailored to the tasks of generating and searching for information about computer systems. If relevant material was served through more specialized and helpful tools, people might create better information and it might be used more.
</p>
<p>
[..]
</p>
<p>
Done well, this system would make it <b>fun and rewarding to contribute information to user communities</b>.
</p>
</blockquote>
<p>
The key word here is "fun".
</p>
<p>
When you interact with other people online ..
</p>
<p>
</p>
<ul>
<li>sending an email to a mailing list
</li>
<li>posting on a discussion forum
</li>
<li>chatting on IRC
</li>
<li>revising a Wiki entry
</li>
<li>entering a blog comment
</li>
</ul>
<p>
.. like it or not, you're participating in <b>the world's largest MMORPG</b>. Lurking is always free. Those that choose to go beyond lurking, to add some tiny bit of content to the web, do it because they find it enjoyable. On some level, <i>they're having fun</i>. If you want to a cultivate a community of participants instead of passive, zombie-like TV viewers who contribute nothing, <b>you should be designing to maximize this fun</b>. As Andy discovered, not designing game-like aspects into community websites is the bigger long term mistake.
</p>
<p>
In the fantastic presentation <a href="http://lostgarden.com/2008/10/princess-rescuing-application-slides.html">Mixing Games and Applications</a>, Dan C.  explores the example of Mario Brothers, which we know as a game. But what if it was a traditional desktop application: <b>Rescue Princess Enterprise 2008</b>?
</p>
<p>
<a href="http://www.codinghorror.com/blog/images/mario-princess-rescue.png"><img alt="image placeholder" >
</p>
<p>
Or a web 2.0 website, <b>Princesszr</b>?
</p>
<p>
<a href="http://www.codinghorror.com/blog/images/mario-princess-rescue.png"><img alt="image placeholder" >
</p>
<p>
How easy are the above two applications to learn? To use? The desktop application has a steep learning curve, but offers lots of power and flexibility. The web 2.0 version has almost no learning curve, but it only does one simple (and boring) thing.
</p>
<p>
Now consider it <b>as a game</b>.
</p>
<p>
<a href="http://www.codinghorror.com/blog/images/mario-princess-rescue.png"><img alt="image placeholder" >
</p>
<p>
</p>
<blockquote>
<p>
The player is handed a new tool called Mario the first time they see this screen.  They don't know how to use him.  The screen gives them a playground where they can try different things:
</p>
<p>
</p>
<ul>
<li>Blocks that reward jumping by giving out coins.
</li>
<li>Goomba that rewards successfully learning how to attack.  It also teaches the players to avoid Goombas on pain of death.
</li>
<li>Blocks that teach the player how to collect powerups.
</li>
</ul>
There are a couple interesting points to note:
<p>
</p>
<ol>
<li>The awarding of a new tool is almost always paired with a simple level that lets the player learn the tool in a somewhat safe environment.
</li>
<li>The player cannot pass this section without mastering at least one critical skill, in this case moving and jumping.  This sort of gating ensures that the designer can rely upon the user having the jumping skill available at later points in the game.
</li>
</ol>
This is different than most apps.  In many apps, you sort through the options and turn on a new feature. There is nothing that is the equivalent of a 'level' or learning context to help you build skills associated with the tool.
</blockquote>
<p>
Recasting the experience as a game means <b>it can be simultaneously complex and easily learnable</b>. That's something we couldn't accomplish through traditional applications, which are designed to be <i>usable but not necessarily fun</i>. They've failed to design for fun. And in an era of ubiquitious web community , that's a big mistake.
</p>
<p>
Let's not trivialize this. Just because your application is fun <a href="http://bokardo.com/archives/game-mechanics-for-interaction-design-an-interview-with-amy-jo-kim/">doesn't mean you've turned it into a game</a>. You've adopted game mechanics in order to build community:
</p>
<p>
</p>
<blockquote>
I see game mechanics working well on sites like YouTube, Yelp, Twitter, and Flickr. <b>These sites have added game mechanics like points, leaderboards, level-ups, social exchanges, and customization</b> to a strong core experience. In particular, YouTube has done a brilliant job of making the overall experience feel game-like, without turning the site into a traditional game.
<p>
Why is this happening in so many places? I think game design principles have become common knowledge for young Web designers. Many of the people who are designing and building these sites grew up playing games, and are familiar with game design principles - even if they're not "officially" game designers themselves. It's a testament to how pervasive and mainstream gaming has become.
</p>
</blockquote>
<p>
I recommend paging through <a href="http://bokardo.com/archives/game-mechanics-for-interaction-design-an-interview-with-amy-jo-kim/">Amy's presentations</a> for a more detailed explanation with lots of great examples:
</p>
<p>
</p>
<ol>
<li>
<a href="http://www.slideshare.net/amyjokim/putting-the-fun-in-functiona?type=powerpoint">Putting the Fun in Functional</a>
</li>
<li>
<a href="http://www.slideshare.net/amyjokim/power-to-the-players?type=powerpoint">Power to the Players</a>
</li>
</ol>
<p>
If you're looking for a lower-level design compendium of game mechanics, suitable for implementation on your own site, check out the Yahoo Developer Network <a href="http://developer.yahoo.com/ypatterns/parent.php?pattern=reputation">social design patterns library</a>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://developer.yahoo.com/ypatterns/parent.php?pattern=ratingsreviews">Ratings &amp; Reviews</a>
</li>
<li>
<a href="http://developer.yahoo.com/ypatterns/parent.php?pattern=reputation">Reputation</a>
</li>
<li>
<a href="http://developer.yahoo.com/ypatterns/parent.php?pattern=ranking">Ranking</a>
</li>
</ul>
<p>
<a href="http://lostgarden.com/2008/06/what-actitivies-that-can-be-turned-into.html">Not every activity can be turned into a game</a>. And perhaps not every activity <i>should</i> be a game.
</p>
<p>
But when it comes to community websites -- sites that get better for everyone the more users actively participate -- these are already so close to being de-facto games that it'd be downright negligent to ignore this aspect of the design. You should shape and define your community by <b>explicitly acknowledging and embracing the game-like aspects you want to encourage</b>, rather than pretending they don't exist.
</p>
<p>
After all, the first step in breaking our addiction to the world's largest MMORPG is to admit that we have a problem.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-15T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-worlds-largest-mmorpg-youre-playing-it-right-now/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Hardest Interview Puzzle Question Ever ]]></title>
<link>https://blog.codinghorror.com/the-hardest-interview-puzzle-question-ever/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Have you ever been to an interview for a programming job where they <b>asked you one of those interview puzzle questions?</b> I have. The one I got was:
</p>
<p>
</p>
<blockquote>
How much of your favorite brand of soda is consumed in this state?
</blockquote>
<p>
And no, the correct answer is not <i>who cares</i>, unless the thing you don't care about is getting the job you're interviewing for. I didn't know it at the time, but this is a Fermi Question. (To prevent spoilers, the answer can be found in <a href="http://www.codinghorror.com/blog/archives/000627.html">a previous blog post</a>.)
</p>
<p>
Puzzle questions were all the rage in programming interviews in the 90s and early aughts. This is documented in the book <a href="http://www.amazon.com/dp/0316919160/?tag=codihorr-20">How Would You Move Mount Fuji?</a> with a specific emphasis on Microsoft's hiring practices.
</p>
<p>
<a href="http://www.amazon.com/dp/0316919160/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
It is prudent to <a href="http://www.techinterview.org/">study common interview puzzle questions</a> if you know you'll be interviewing at a company that asks these sorts of questions. And if you think you're ace at programming puzzle questions, then I challenge you to point your massive brain at this, <a href="http://www.cartalk.com/content/read-on/2008/08.23.2.html">the hardest interview puzzle question ever</a>:
</p>
<p>
</p>
<blockquote>
A hundred prisoners are each locked in a room with three pirates, one of whom will walk the plank in the morning. Each prisoner has 10 bottles of wine, one of which has been poisoned; and each pirate has 12 coins, one of which is counterfeit and weighs either more or less than a genuine coin. In the room is a single switch, which the prisoner may either leave as it is, or flip. Before being led into the rooms, the prisoners are all made to wear either a red hat or a blue hat; they can see all the other prisoners' hats, but not their own. Meanwhile, a six-digit prime number of monkeys multiply until their digits reverse, then all have to get across a river using a canoe that can hold at most two monkeys at a time. But half the monkeys always lie and the other half always tell the truth. Given that the Nth prisoner knows that one of the monkeys doesn't know that a pirate doesn't know the product of two numbers between 1 and 100 without knowing that the N+1th prisoner has flipped the switch in his room or not after having determined which bottle of wine was poisoned and what color his hat is, what is the solution to this puzzle?
</blockquote>
<p>
In other words, <a href="http://www.codinghorror.com/blog/archives/000226.html">I hate puzzle questions</a>.*
</p>
<p>
</p>
<blockquote>
I'm also not a huge fan of those abstract impossible questions, eg, "how many optometrists are there in Seattle?", but I suppose that's a matter of taste. If you absolutely must, at least ask an impossible question that has some relevance to a problem your very real customers might encounter. <b>I just can't muster any enthusiasm for completely random arbitrary puzzles in the face of so many actual, real world problems.</b>
</blockquote>
<p>
And yes, I totally failed that interview. Which was disappointing, because it was kind of a cool job.
</p>
<p>
Not that <a href="http://www.codinghorror.com/blog/archives/000226.html">my proposal for interviewing programmers</a> was any more popular, though I do think it's much better.
</p>
<p>
</p>
<blockquote>
I have my own theory about the ideal way to interview developers: <b>have the candidate give a 10 minute watercooler presentation to your team on something they've worked on</b>. I think this is a far better indicator of success than a traditional interview. You'll quickly ascertain:
<p>
</p>
<ul>
<li>Is this person passionate about what they are doing?
</li>
<li>Can they communicate effectively to a small group?
</li>
<li>Do they have a good handle on their area of expertise?
</li>
<li>Would your team enjoy working with this person?
</li>
</ul>
</blockquote>
<p>
You'd certainly want to complement this type of interview with some actual hands on programming, to make sure the applicant isn't full of crap -- although I'm pretty sure that you can't B.S. your way through a technical presentation to a handful of your peers if you truly have no idea what you're talking about. (And if you can, you should be CEO of a startup by now.)
</p>
<p>
<b>What I'm optimizing for here is the ability to communicate</b>. Most programmers, once they <a href="http://www.codinghorror.com/blog/archives/000781.html">pass the FizzBuzz level of competency</a>, are decent enough. But coding chops aren't enough. To go from good to great, you must be able to communicate effectively: with your teammates, your manager, the users, and ultimately the world.
</p>
<p>
My wife and I just finished a five day hospital stay for <a href="http://www.codinghorror.com/blog/archives/001242.html">the birth of our first child</a>. During our stay, we were assisted by a parade of different nurses, at least two different nurses every day, sometimes more as we progressed to different areas of the hospital and through daily shift changes. The quality of care at this particular hospital is generally quite high, but we were flummoxed by the disparity in care between the <i>worst</i> nurses and the <i>best</i> nurses. After a few days, I finally figured out the common characteristic -- <b>the worst nurses were invariably the worst communicators!</b> The fact that these nurses couldn't effectively <i>communicate</i> with us:
</p>
<p>
</p>
<ul>
<li>why they needed to do something
</li>
<li>what the options were
</li>
<li>offer advice
</li>
<li>troubleshoot our problems
</li>
</ul>
Meant they ended up feeling like rigid, inflexible proceduralists who didn't care or constantly had to appeal to authority. Of course, this wasn't true. I'm sure they were perfectly competent registered nurses. But in the absence of reasonable communication, it sure <i>seemed</i> that way. To be fair, these nurses were frequently (but not always!) non-native English speakers.
<p>
Hiring is difficult under the best of conditions. But an interview process that relies too heavily on puzzle questions is risky. Sure, you may end up with programmers who can solve (or memorize, I guess) the absolute gnarliest puzzle questions you throw at them. But isn't <b>effectively communicating those solutions to the rest of the team</b> important, too? For many programmers, <i>that's</i> the hardest part of the puzzle.
</p>
<p>
*  although I expect aficionados of the style should be able to identify all the classic interview puzzle questions represented here.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-16T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-hardest-interview-puzzle-question-ever/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Five Dollar Programming Words ]]></title>
<link>https://blog.codinghorror.com/five-dollar-programming-words/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've been a longtime <a href="http://www.codinghorror.com/blog/archives/000750.html">fan of Eric Lippert's blog</a>. And one of my favorite (albeit short-lived) post series was his <b>Five Dollar Words for Programmers</b>. Although I've sometimes been <a href="http://gandolf.homelinux.org/blog/index.php?id=52">accused of being too wordy</a>, I find that learning the right word to describe something you're doing is a small step on the road towards <a href="http://www.codinghorror.com/blog/archives/001236.html">understanding and eventual mastery</a>.
</p>
<p>
Why are these words worth five dollars? They're <b>uncommon words that have a unique and specialized meaning in software development</b>. They are a bit off the beaten path. Words you don't hear often, but also words that provide the thrill of discovery, that "aha" moment as you realize a certain programming concept you knew only through experimentation and intuition has a <i>name</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Eric provides examples of a few great five dollar programming words on his blog.
</p>
<p>
1. <b><a href="http://blogs.msdn.com/ericlippert/archive/2005/10/26/483900.aspx">Idempotent</a></b>
</p>
<p>
</p>
<blockquote>
There are two closely related definitions for idempotent. A value is "idempotent under function foo" if the result of doing foo to the value results in the value right back again.
<p>
A function is "idempotent" if the result of doing it twice (feeding the output of the first call into the second call) is exactly the same as the result of doing it once. (Or, in other words, every output of the function is idempotent under it.)
</p>
</blockquote>
<p>
This isn't just academic. Eric notes that idempotence is used all the time in caching functions that create the object being requested. Calling the function two or a thousand times returns the same result as calling it once.
</p>
<p>
<b>2. <a href="http://blogs.msdn.com/ericlippert/archive/2005/10/28/483905.aspx">Orthogonality</a></b>
</p>
<p>
</p>
<blockquote>
Imagine for instance that you were trying to describe how to get from one point in an empty room to another. A perfectly valid way to do so would be to say how many steps to go north or south, and then how many steps to go northeast or southwest.  This hockey-stick navigation system is totally workable, but it feels weird because north and northeast are not orthogonal -- you can't change your position by moving northeast without also at the same time changing how far north you are.  With an orthogonal system -- say, the traditional north-south/east-west system -- you can specify how far north to go without worrying about taking the east-west movement into account at all.
<p>
Nonorthogonal systems are hard to manipulate because it's hard to tweak isolated parts. Consider my fish tank for example. The pH, hardness, oxidation potential, dissolved oxygen content, salinity and conductivity of the water are very nonorthogonal; changing one tends to have an effect on the others, making it sometimes tricky to get the right balance. Even things like changing the light levels can change the bacteria and algae growth cycles causing chemical changes in the water.
</p>
</blockquote>
<p>
Orthogonality is a powerful concept that <a href="http://brandonbyars.com/blog/articles/2008/07/21/orthogonality">applies at every level of coding</a>, from the architecture astronaut to the lowest level code monkey. If modifying item #1 results in unexpected behavior in item #2, you have a major problem -- that's a form of unwanted coupling. Dave Thomas illustrates with a <a href="http://www.artima.com/intv/dry3.html">clever helicopter analogy</a>:
</p>
<p>
</p>
<blockquote>
It sounds fairly simple. You can use the pedals to point the helicopter where you want it to go. You can use the collective to move up and down. Unfortunately, though, because of the aerodynamics and gyroscopic effects of the blades, all these controls are related. So one small change, such as lowering the collective, causes the helicopter to dip and turn to one side. You have to counteract every change you make with corresponding opposing forces on the other controls. However, by doing that, you introduce more changes to the original control. So you're constantly dancing on all the controls to keep the helicopter stable.
<p>
That's kind of similar to code. We've all worked on systems where you make one small change over here, and another problem pops out over there. So you go over there and fix it, but two more problems pop out somewhere else. You constantly push them back -- like that Whack-a-Mole game -- and you just never finish. If the system is not orthogonal, if the pieces interact with each other more than necessary, then you'll always get that kind of distributed bug fixing.
</p>
</blockquote>
<p>
3. <a href="http://blogs.msdn.com/ericlippert/archive/2007/11/13/immutability-in-c-part-one-kinds-of-immutability.aspx"><b>Immutability</b></a>
</p>
<p>
Immutability is a bit more broad, but the commonly accepted definition is based on the fact that <code>String</code> objects in Java, C#, and Python <a href="http://en.wikipedia.org/wiki/Immutable_object">are immutable</a>.
</p>
<p>
</p>
<blockquote>
There's nothing you can do to the number one that changes it. You cannot paint it purple, make it even or get it angry. It's the number one, it is eternal, implacable and unchanging. Attempting to do something to it -- say, adding three to it -- doesn't change the number one at all. Rather, it produces an entirely different and also immutable number. If you cast it to a double, you don't change the integer one; rather, you get a brand new double.
<p>
Strings, numbers and the null value are all truly immutable.
</p>
</blockquote>
<p>
Try to imagine your strings painstakingly carved out of enormous blocks of granite. Because they are -- they're immutable! It may seem illogical that every time you modify a <code>string</code>, the original is kept as-is and an entirely new <code>string</code> is created. But this is done for <a href="http://stackoverflow.com/questions/93091/why-cant-string-be-not-immutable-in-java-and-net">two very good technical reasons</a>. Understanding immutability is <a href="http://www.codinghorror.com/blog/archives/001218.html">essential to grok string performance</a> in those languages.
</p>
<p>
I don't pretend that these three words are particularly unique or new, just a tiny bit off the beaten path. They were, however, new <i>to me</i> at one time, and discovering them marked a small milestone in my own evolution as a programmer.
</p>
<p>
<b>What's <i>your</i> favorite five dollar programming word?</b> And how did it help you reach that particular "aha" moment in <i>your</i> code? (Links to references / definitions greatly appreciated in comments -- perhaps we can all discover at least <i>one</i> new five dollar programming word today. Remember, learn four and you'll earn a cool twenty bucks worth of knowledge!)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-19T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/five-dollar-programming-words/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ See You at EclipseCon! ]]></title>
<link>https://blog.codinghorror.com/see-you-at-eclipsecon/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I have the very great honor of <a href="http://www.eclipsecon.org/2009/sessions?id=751">speaking at this year's EclipseCon</a> with one of my heroes, <a href="http://www.shirky.com/">Clay Shirky</a>.
</p>
<p>
<a href="http://www.eclipsecon.org/2009/"><img alt="image placeholder" >
</p>
<p>
The theme of this year's EclipseCon is collaboration -- so all the talks are presented by two speakers. Our talk, <a href="http://www.eclipsecon.org/2009/sessions?id=751"><b>The Social Mind: Designing Like Groups Matter</b></a>, will alternate between the theory (Clay) and practice (Jeff) of online community. Hopefully in a coherent way.
</p>
<p>
This is an easy talk for me to deliver, because I quite literally used Clay Shirky's book, <a href="http://www.amazon.com/exec/obidos/ASIN/1594201536/codihorr-20">Here Comes Everybody: The Power of Organizing Without Organizations</a>, as a blueprint for <a href="http://www.codinghorror.com/blog/archives/001169.html">building Stack Overflow</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/1594201536/codihorr-20"><img alt="image placeholder" >
</p>
<p>
I wasn't kidding when I said <a href="http://www.codinghorror.com/blog/archives/001122.html">It's Clay Shirky's Internet, We Just Live In It</a>.
</p>
<p>
I can't emphasize enough how deeply I respect Clay. I've read everything he's written to a degree that you might even say I <i>studied</i> it. Clay continues to be one of the most perceptive and insightful technical writers in the world on the topic of internet culture and community. His <a href="http://www.shirky.com/weblog/2009/03/newspapers-and-thinking-the-unthinkable/">latest missive on the demise of newspapers</a> is not to be missed. It's thrilling to have this opportunity to speak side by side with such a vital, important figure in internet history.
</p>
<p>
It is also extremely gratifying to me that <b>I am giving this talk to a group of non Windows-centric developers</b>. Despite my personal background, we always intended Stack Overflow to be a tribute to the greater craft of programming, a place where you could rub shoulders with fellow programmers from all sorts of different backgrounds and professional interests -- a bit like the old, classic computer programming magazines like <a href="http://en.wikipedia.org/wiki/Byte_(magazine)">Byte</a> and <a href="http://en.wikipedia.org/wiki/Dr._Dobb%27s_Journal">Dr. Dobb's Journal</a>.
</p>
<p>
</p>
<table>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
It pains me to see developers who let themselves get locked into some particular toolchain ghetto, without at least peripheral awareness of what else is going on in the programming world around them.
</p>
<p>
Good programmers are interested in <i>everything</i> -- and that's exactly the kind of talk Clay and I intend to deliver.
</p>
<p>
<font color="red">Update:</font> I'm not sure the event was recorded, but <a href="http://ztrek.blogspot.com/2009/03/secrets-of-social-site-success.html">Alan Zeichick's summary of our talk</a> is outstanding. I also <a href="http://www.slideshare.net/codinghorror/eclipsecon-2009-keynote-the-social-mind-designing-like-groups-matter">put the slides up on SlideShare for viewing or download</a>, though it's tough without audio.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-21T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/see-you-at-eclipsecon/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Who's Your Arch-Enemy? ]]></title>
<link>https://blog.codinghorror.com/whos-your-arch-enemy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I didn't fully understand 37 Signals' advice to <a href="http://gettingreal.37signals.com/ch02_Have_an_Enemy.php">Have an Enemy</a> until recently.
</p>
<p>
</p>
<blockquote>
Sometimes the best way to know what your app should be is to know what it shouldn't be. Figure out your app's enemy and you'll shine a light on where you need to go.
<p>
When we decided to create project management software, we knew Microsoft Project was the gorilla in the room. Instead of fearing the gorilla, we used it as a motivator. <b>We decided Basecamp would be something completely different, the anti-Project.</b>
</p>
<p>
One bonus you get from having an enemy is a very clear marketing message. People are stoked by conflict. And they also understand a product by comparing it to others. With a chosen enemy, you're feeding people a story they want to hear. Not only will they understand your product better and faster, they'll take sides. And that's a sure-fire way to get attention and ignite passion.
</p>
</blockquote>
<p>
I've explained <a href="http://stackoverflow.com">Stack Overflow</a> to hundreds of people, and by <i>far</i> the most effective way to explain what we do -- the way that causes people to visibly "get it" almost instantly, with a giant cartoon lightbulb practically appearing over their head -- is this:
</p>
<p>
</p>
<blockquote>
We're like experts-exchange, but without all the evil.
</blockquote>
<p>
<b>I never appreciated how easy Experts-Exchange makes it for us.</b> They are almost <a href="http://www.google.com/search?q=experts-exchange+sucks">universally loathed</a>. We don't just have a rival, we have a larger than life moustache-twirling, cape-wearing villain to contrast ourselves with.
</p>
<p>
<a href="http://www.threadless.com/product/1107/The_League_of_Cliche_Evil_Super_Villains%0A"><img alt="image placeholder" >
</p>
<p>
No matter how much we may suck (and we try very, very hard <i>not</i> to suck), we can simply point to the experts-exchange website and we instantly become the hero. The good guy. The underdog.
</p>
<p>
I have absolutely nothing against Experts-Exchange. Realize that I've been a fan of the <a href="http://www.codinghorror.com/blog/archives/000630.html">smackdown learning model</a> for a long time; it's like <a href="http://en.wikipedia.org/wiki/Kayfabe">kayfabe</a> in professional wrestling. There are no hard feelings; <b>this "rivalry" is mostly useful as a way to explain what it is we do</b>. This internet is certainly big enough for the both of us -- big enough, in fact, for hundreds of Q&amp;A websites.
</p>
<p>
That said, if you have an arch-enemy -- the more horrible and evil and larger-than-life the better -- consider yourself lucky. They're doing you a <i>huge</i> favor.
</p>
<p>
So, who's your arch-enemy?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-22T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whos-your-arch-enemy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Don't Like It? Code it Yourself! ]]></title>
<link>https://blog.codinghorror.com/dont-like-it-code-it-yourself/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Have you ever considered paying for, or sponsoring, a
</p>
<p>
</p>
<ul>
<li>bug fix
</li>
<li>new feature
</li>
<li>plugin
</li>
<li>small tweak to existing functionality
</li>
</ul>
<p>
... for software that you use?
</p>
<p>
I don't mean waiting for a new release of the software, which will contain a bunch of new features you may or may not care about, along with all new bugs. I'm talking about <b>making a very specific request for <i>existing</i> software happen through financial sponsorship</b>.
</p>
<p>
Sure, if the software you're using happens to be open source, you can <i>theoretically</i> download the source code, roll up your sleeves, and <a href="http://forum.handbrake.fr/viewtopic.php?t=501">code it yourself</a>.
</p>
<p>
</p>
<blockquote>
If you have a very strong desire to see a particular feature implemented, your odds of success of ultimately having it become a part of the tool are dramatically increased if instead of asking for it to be implemented, you check out a copy of the latest source code tree, code it yourself (even if slightly incomplete or somewhat buggy), and submit it for peer review by the existing developer pool. Other technical parties are far more likely to help you complete a worthwhile code enhancement that you've clearly put time and thought into than they are to remotely consider doing what you want from scratch just because you want it.
<p>
Of course, not all end-users have the technical acumen or programming experience to bring such things to reality. You have three options: a) find a programming friend that you can get excited about your idea and have him follow the above paragraph, b) live without the feature and enjoy the software you have been provided free and proves useful to many others, or c) find a different software package that does do what you want.
</p>
</blockquote>
<p>
But how realistic is this for the average user? Heck, how realistic is this for the average <i>programmer</i>? Even if you're the type of macho, gung-ho programmer who can master an alien code base just to get some small pet feature or bugfix in -- do you honestly have the kind of time it would take to do that?
</p>
<p>
Sometimes, when people say this:
</p>
<p>
</p>
<blockquote>
The source code is freely available. If you feel so strongly about this bugfix/tweak/feature/plugin, <b>why don't you code it yourself?</b>
</blockquote>
<p>
They're really saying this:
</p>
<p>
</p>
<blockquote>
F**k you.
</blockquote>
<p>
That seems a bit harsh to me. Surely there's <i>something</i> between the extremes of "give up" and "code it yourself."
</p>
<p>
Why isn't there a service to aggregate and pool funds to <a href="http://ideaforge.linux.com/story.php?title=sponsor-programming-of-featuressoftware">sponsor programming particular features or bugfixes in open source software?</a>
</p>
<p>
</p>
<blockquote>
There are many end-users willing to pay for improvements to free software and writing new programs. There are also many talented programmers wanting to get paid to work on free software. Allow end-users to escrow payments that are pooled together to pay developers for implementing features / writing software. A panel of well-known free software experts is needed to vet new ideas before payment is escrowed for them, and to review programmer work having met the target.
</blockquote>
<p>
I realize that using financial incentives on open source projects can have <a href="http://www.codinghorror.com/blog/archives/001158.html">some unintended consequences</a>. But a sort of attention and interest aggregation service for existing projects -- one backed by real money, so you know the interested parties are serious -- seems like a worthwhile cause. It might even attract the interest of other programmers if the pool got large enough.
</p>
<p>
To me, at least, <b>sponsorship seems like a constructive way for people who are unable or unwilling to write code to affect the direction of a project</b>. For example, I've sponsored several bugfixes in a key .NET open source library that we use for Stack Overflow. These are bugfixes they considered low priority, but were serious issues for our site. I was happy to give back to the project, and it was certainly a more realistic option than us carving out a chunk of our own development time to contribute the bugfixes ourselves.
</p>
<p>
That said, I am concerned that this sort of aggregated sponsorship system hasn't naturally evolved on its own by now. Is it not sustainible, or incompatible with the kind of intrinsic motivations that <a href="http://www.scribd.com/doc/10280604/Intrinsic-Motivation-in-Open-Source-Software">drive most open source development</a>?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-26T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/dont-like-it-code-it-yourself/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Ugly American Programmer ]]></title>
<link>https://blog.codinghorror.com/the-ugly-american-programmer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
On the internet, you can pretend the world is flat. Whatever country you live in, whatever language you speak, you have the same access to the accumulated knowledge of the world as every other citizen of the planet Earth. And a growing percentage of that knowledge can and <i>should</i> be available in your native language.
</p>
<p>
But I believe the rules are different for programmers. So much so that I'm going to ask the unthinkable: <b>shouldn't every software developer understand English?</b>
</p>
<p>
<a href="http://www.eastendbrewing.com/node/129"><img alt="image placeholder" >
</p>
<p>
A wildly disproportionate amount of programming information is available in English. The overwhelming majority of programming languages <a href="http://en.wikipedia.org/wiki/Non-English-based_programming_languages">use English keywords</a>. By any metric you can possibly measure, English is the <a href="http://dictionary.reference.com/browse/lingua%20franca">lingua franca</a> of programming.
</p>
<p>
Now, In terms of cultural literacy and travel, presuming that everyone should speak English is a totally unacceptable attitude, the epitome of the <a href="http://en.wikipedia.org/wiki/The_Ugly_American">ugly american</a>.
</p>
<p>
<a href="http://catandgirl.com/?p=1544"><img alt="image placeholder" >
</p>
<p>
But those rules don't apply to us.
</p>
<p>
We're not talking about normal everyday people. We're talking about programmers. Citizens of the internet. People who swear allegiance not to a country, but a <i>compiler</i>. <b>Hackers have their own culture, their own norms and standards for literacy.</b> Eric Raymond notes that <a href="http://www.catb.org/~esr/faqs/hacker-howto.html#skills4">functional English is <i>required</i> for true hackers</a>:
</p>
<p>
</p>
<blockquote>
As an American and native English-speaker myself, I have previously been reluctant to suggest this, lest it be taken as a sort of cultural imperialism. But several native speakers of other languages have urged me to point out that English is the working language of the hacker culture and the Internet, and that you will need to know it to function in the hacker community.
<p>
Back around 1991 I learned that many hackers who have English as a second language use it in technical discussions even when they share a birth tongue; it was reported to me at the time that English has a richer technical vocabulary than any other language and is therefore simply a better tool for the job. For similar reasons, translations of technical books written in English are often unsatisfactory (when they get done at all).
</p>
<p>
Linus Torvalds, a Finn, comments his code in English (it apparently never occurred to him to do otherwise). His fluency in English has been an important factor in his ability to recruit a worldwide community of developers for Linux. It's an example worth following.
</p>
<p>
Being a native English-speaker does not guarantee that you have language skills good enough to function as a hacker. If your writing is semi-literate, ungrammatical, and riddled with misspellings, many hackers (including myself) will tend to ignore you. While sloppy writing does not invariably mean sloppy thinking, we've generally found the correlation to be strong -- and we have no use for sloppy thinkers. If you can't yet write competently, learn to.
</p>
</blockquote>
<p>
It's difficult to communicate this idea without feeling like <b>an ugly American programmer</b>. But it doesn't come from a nationality, or a desire to dominate the world. It's nothing more than great hackers collectively realizing that sticking to English for technical discussion makes it easier to <i>get stuff done</i>. <b>It's a meritocracy of code</b>, not language, and nobody (or at least nobody who is sane, anyway) localizes programming languages.
</p>
<p>
I received this email from Slawomir, a Polish programmer, a few months ago. He confirmed what I've always suspected and secretly believed -- but have been hesitant to say:
</p>
<p>
</p>
<blockquote>
I just listened to <a href="http://blog.stackoverflow.com/2008/11/podcast-29/">Stack Overflow podcast episode 29</a> where you discuss localization of developer tools.
<p>
In my opinion there is no reason to translate developer tools and documentation.
</p>
<p>
I know many developers in Poland who prefer (as Joel mentioned) to get English documentation rather than Polish translation and the reason for that is that translations were not always accurate. Even Microsoft developer documentation was translated partially or with errors, so reading original English document was easier than English-Polish soup.
</p>
<p>
<b>If everybody blogs and develops in English - our global repository of solutions and blog posts is much bigger and you have better chances of finding an answer to your problem.</b>
</p>
</blockquote>
<p>
Consciously choosing to switch from Polish to English reminds me why I gave up Visual Basic for C#, as painful as that was. These languages do exactly the same things -- and the friction of choosing the minority language was severe. I found reams of code and answers in C# whenever I searched, and almost nothing at all in VB.NET. I spent so much time converting code into VB.NET and introducing new bugs and errors in the process, along with countless language-only forks. This eventually stopped making sense to me -- as it would to any good programmer.
</p>
<p>
Advocating the adoption of <b>English as the de-facto standard language of software development</b> is simple pragmatism, the most virtuous of all hacker traits. If that makes me an ugly American programmer, so be it.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-03-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-ugly-american-programmer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Should Competent Programmers be &quot;Mathematically Inclined&quot;? ]]></title>
<link>https://blog.codinghorror.com/should-competent-programmers-be-mathematically-inclined/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the more famous <a href="http://en.wikipedia.org/wiki/Edsger_W._Dijkstra">Edsger Dijkstra</a> quotes is from his 1972 Turing award lecture, <a href="http://www.cs.utexas.edu/users/EWD/transcriptions/EWD04xx/EWD498.html">How do we tell truths that might hurt?</a>
</p>
<p>
</p>
<blockquote>
<b>Besides a mathematical inclination</b>, an exceptionally good mastery of one's native tongue is the most vital asset of a competent programmer.
</blockquote>
<p>
Note that he specifically says <a href="http://www.codinghorror.com/blog/archives/001248.html">native tongue, not English</a>. Which makes me wonder why all of Dijkstra's most important writings were in English, not his native Dutch.
</p>
<p>
But I digress. Let's consider the first part of the Dijkstra quote. <b>Should competent programmers be "mathematically inclined"?</b> It might be instructive to think of programming as a form of mathematics, at least for one reason: to resist localization. Although there have been attempts to <a href="http://en.wikipedia.org/wiki/Non-English-based_programming_languages">create localized programming languages</a>, as far as I know, nobody has ever tried to localize Ãâ‚¬ or the number 3. They're universal. So in that sense, programming languages bear a vague, passing resemblance to mathematics. Learn the symbols once and use them everywhere in the world, no matter what your native tongue is.
</p>
<p>
On the other hand, <b>I have not found <i>in practice</i> that programmers need to be mathematically inclined to become great software developers</b>.  Quite the opposite, in fact. This does depend heavily on what kind of code you're writing, but the vast bulk of code that <i>I've</i> seen consists mostly of the "balancing your checkbook" sort of math, nothing remotely like what you'd find in the average college calculus textbook, even.
</p>
<p>
</p>
<pre>
{
i = j++ / (x + v);
}
</pre>
<p>
Not exactly the stuff mathletes are made of.
</p>
<p>
I never understood the desire to formally equate skill at mathematics with skill at programming. While being a math wonk certainly won't <i>hurt</i> you as a programmer, it's very hard for me to draw a direct line from "good at math" to "good at programming". Like Rory, I believe that <a href="http://neopoleon.com/blog/posts/13166.aspx">software development requires some markedly right-brained sensibilities</a>.
</p>
<p>
</p>
<blockquote>
When I was growing up, I remember hearing people say things like, "If you like computer programming, then you'll love math." I always thought that these people were absolutely nuts. While there is something intrinsically similar about certain types of math and computer programming, the two are different in many more ways than they are similar.
<p>
With math, and I'm not talking about the crazy number-theory math philosophy "Do numbers really exist?" side of things, but with the applied stuff, there are correct answers. You're either correct or you're incorrect.
</p>
<p>
With coding, the best you can hope for is to do something well. With so many different ways to effect a single outcome, it's up to some very right-brained sensibilities to determine if you've met your goal, as there isn't anybody (except [another more experienced developer]) who can tell you if you're right or not.
</p>
<p>
If you ignore your right brain, and I'm talking generally about abstraction and aesthetics, then you can slap some code together that might work, but it also might be one hell of a maintenance nightmare. If you focus only on the right brain, you might have something that works, but is so utterly inefficient and personalized that you're the only person on Earth who could make sense of the code and maintain it.
</p>
</blockquote>
<p>
All those caveats aside, people still advocate the idea that math alone has the power to make you a better programmer. Steve Yegge makes <a href="http://steve-yegge.blogspot.com/2006/03/math-for-programmers.html">the best case I've read for the programmer-mathematician</a>, with his five points:
</p>
<p>
</p>
<blockquote>
<ol>
<li>Math is a lot easier to pick up after you know how to program.  In fact, if you're a halfway decent programmer, you'll find it's almost a snap. </li>
<br>
<li>They teach math all wrong in school.  Way, WAY wrong.  If you teach yourself math the right way, you'll learn faster, remember it longer, and it'll be much more valuable to you as a programmer. </li>
<br>
<li> Knowing even a <em>little</em> of the right kinds of math can enable you do write some pretty interesting programs that would otherwise be too hard.  In other words, math is something you can pick up a little at a time, whenever you have free time. </li>
<br>
<li>Nobody knows all of math, not even the best mathematicians.  The field is constantly expanding, as people invent new formalisms to solve their own problems.  And with any given math problem, just like in programming, there's more than one way to do it.  You can pick the one you like best. </li>
<br><li>  Math is... ummm, please don't tell anyone I said this; I'll never get invited to another party as long as I live.  But math, well...  I'd better whisper this, so listen up: <font size="-2"><em>(it's actually kinda fun.)</em></font>
</li>
</ol>
</blockquote>
<p>
To me, this reads like a broad recipe for becoming intellectually curious and building skill at solving abstract problems. Important programming skills, to be sure, but not necessarily exclusive to the study of math. If math is your preferred way to <a href="http://www.codinghorror.com/blog/archives/001236.html">sharpen your saw</a>, then have at it -- but it's hardly the <i>only</i> way.
</p>
<p>
I recently received this email:
</p>
<p>
</p>
<blockquote>
I run a small (4 people) web dev shop and I'm finding that younger coders haven't had the pleasure of writing assembler or managing without library functions. I've always found strong math skills to be one of the most useful skills for coding, and when one has Google and a massive library of functions, one doesn't have to be good at math to get things working, until it either breaks, has edge cases, or brings out OS or library bugs.
<p>
Some quick examples: simplifying tricky equations to determine array indicies or memory offsets; trigonometry to help with physical calculations; mental hex/bin/dec conversion; logic equalities such as DeMorgan's theorem.
</p>
</blockquote>
<p>
He's got the right idea; if we're going to talk about math, let's get out of the abstract and into the specific. Let's talk details. Examples. What could be more math-y than that?
</p>
<p>
<b>What code have you personally written where a detailed knowledge of math made your work easier?</b> I can think of some broad categories. Writing a 3D game. Or a physics simulation. Or low-level image filters. Or compression algorithms. The list goes on and on. But if you're in those situations, you'll know it.
</p>
<p>
Maybe I'm a hopeless optimist, but I think most programmers are smart enough to learn whatever math they need <a href="http://www.codinghorror.com/blog/archives/000575.html">just in time</a> to attack the problem at hand.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/should-competent-programmers-be-mathematically-inclined/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Eight Levels of Programmers ]]></title>
<link>https://blog.codinghorror.com/the-eight-levels-of-programmers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Have you ever gotten that classic job interview question, <strong>"where do you see yourself in five years?"</strong> When asked, I'm always mentally transported back to <a href="http://www.youtube.com/watch?v=SRwrg0db_zY#t=1m13">a certain Twisted Sister video from 1984</a>.</p>
<blockquote>I want you to tell me – no, better yet, stand up and <em>tell the class</em> –
<p><a href="http://www.youtube.com/watch?v=SRwrg0db_zY#t=1m13"><img alt="image placeholder" >
<p><strong>what do you wanna do with your life?</strong></p>
</blockquote>
<p>You want to rock, naturally! Or at least be a <a href="http://www.codinghorror.com/blog/archives/000552.html">rockstar programmer</a>. It's not a question that typically gets a serious answer – sort of like that other old groan-inducing interview chestnut, "what's your greatest weakness?" It's that you sometimes rock <em>too hard</em>, right? Innocent bystanders could get hurt.</p>
<p>But I think this is a different and more serious class of question, one that deserves real consideration. Not for the interviewer's benefit, but for your <em>own</em> benefit.</p>
<p>The "where do you see yourself in five years" question is sort of glib, and most people have a pat answer they give to interviewers. But it does raise some deeper concerns: what <em>is</em> the potential career path for a software developer? Sure, <a href="http://www.codinghorror.com/blog/archives/001202.html">we do this stuff because we love it</a>, and we're <a href="http://www.codinghorror.com/blog/archives/000979.html">very fortunate in that regard</a>. But will you be sitting in front of your computer programming when you're 50? When you're 60? What is the best possible career outcome for a programmer who aspires to be.. well, a programmer?</p>
<p>What if I told you, with <a href="http://www.kenrockwell.com/tech/7art.htm">tongue firmly planted in cheek</a>, that there were <strong>Eight Levels of Programmers?</strong></p>
<ol>
<li>
<strong>Dead Programmer</strong>
<p>This is the highest level. Your code has survived and transcended your death. You are a part of the permanent historical record of computing. Other programmers study your work and writing. You may have won a Turing Award, or written influential papers, or invented one or more pieces of fundamental technology that have affected the course of programming as we know it. You don't just have a wikipedia entry – there are entire websites dedicated to studying your life and work.</p>
<p>Very few programmers ever achieve this level in their own lifetimes.</p>
<p>Examples: <a href="http://en.wikipedia.org/wiki/Edsger_W._Dijkstra">Dijkstra</a>, <a href="http://en.wikipedia.org/wiki/Donald_Knuth">Knuth</a>, <a href="http://en.wikipedia.org/wiki/Alan_Kay">Kay</a></p>
</li>
<li>
<strong>Successful Programmer</strong>
<p>Programmers who are both well known and have created entire businesses – perhaps even whole industries – around their code. These programmers have given themselves <a href="http://e-texteditor.com/blog/2009/opencompany">the real freedom zero</a>: the freedom to decide for themselves what they want to work on. And to share that freedom with their fellow programmers.</p>
<p>This is the level to which most programmers should aspire. Getting to this level often depends more on business skills than programming.</p>
<p>Examples: <a href="http://en.wikipedia.org/wiki/Bill_Gates">Gates</a>, <a href="http://en.wikipedia.org/wiki/John_D._Carmack">Carmack</a>, <a href="http://en.wikipedia.org/wiki/David_Heinemeier_Hansson">DHH</a></p>
</li>
<li>
<strong>Famous Programmer</strong>
<p>This is also a good place to be, but not unless you also have a day job.</p>
<p>You're famous in programming circles. But being famous doesn't necessarily mean you can turn a profit and support yourself. Famous is good, but <em>successful</em> is better. You probably work for a large, well known technology company, an influential small company, or you're a part of a modest startup team. Either way, other programmers have heard of you, and you're having a positive impact on the field.</p>
</li>
<li>
<strong>Working Programmer</strong>
<p>You have a successful career as a software developer. Your skills are always in demand and you never have to look very long or hard to find a great job. Your peers respect you. Every company you work with is improved and enriched in some way by your presence.</p>
<p>But where do you go from there?</p>
</li>
<li>
<strong>Average Programmer</strong>
<p>At this level you are a good enough programmer to realize that you're not a <em>great</em> programmer. And you might never be.</p>
<p>Talent often has little do do with success. You can be very successful if you have business and people skills. If you are an average programmer but manage to make a living at it then you <em>are</em> talented, just not necessarily at coding.</p>
<p>Don't knock the value of self-awareness. It's more rare than you realize. There's nothing wrong with lacking talent. Be bold. Figure out what you're good at, and pursue it. Aggressively.</p>
</li>
<li>
<strong>Amateur Programmer</strong>
<p>An amateur programmer loves to code, and it shows: they might be a promising student or intern, or perhaps they're contributing to open source projects, or building interesting "just for fun" applications or websites in their spare time. Their code and ideas show promise and enthusiasm.</p>
<p>Being an amateur is a good thing; from this level one can rapidly rise to become a working programmer.</p>
</li>
<li>
<strong>Unknown Programmer</strong>
<p>The proverbial typical programmer. Joe Coder. Competent (usually) but unremarkable. Probably works for a large, anonymous MegaCorp. It's just a job, not their entire life. Nothing wrong with that, either.</p>
</li>
<li>
<strong>Bad Programmer</strong>
<p>People who somehow fell into the programmer role without an iota of skill or ability. Everything they touch <a href="http://www.codinghorror.com/blog/archives/000824.html">turns into pain and suffering</a> for their fellow programmers – with the possible exception of <em>other</em> Bad Programmers, who lack even the rudimentary skill required to tell that they're working with another Bad Programmer.</p>
<p>Which is, perhaps, the hallmark of all Bad Programmers. These people have no business writing code of any kind – but they do, anyway.</p>
</li>
</ol>
<p>These levels aren't entirely serious. Not every programmer aspires to the same things in their career. But it's illuminating to consider what a programmer <em>could</em> accomplish in ten years, twenty years, or thirty years – perhaps even a lifetime. Which <a href="http://en.wikipedia.org/wiki/List_of_programmers">notable programmers</a> do you admire the most? What did they accomplish to earn your admiration?</p>
<p>In short, <strong>what do you wanna do with your life?</strong></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-eight-levels-of-programmers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I Happen to Like Heroic Coding ]]></title>
<link>https://blog.codinghorror.com/i-happen-to-like-heroic-coding/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've been following Michael Abrash for more than 10 years now; he's one of <a href="http://www.codinghorror.com/blog/archives/001061.html">my programming heroes</a>. So I was fascinated to discover that Mr. Abrash wrote an article <a href="http://www.ddj.com/hpc-high-performance-computing/216402188?pgno=1">extolling the virtures of Intel's upcoming Larrabee</a>. What's Larrabee? It's a weird little unreleased beast that sits somewhere in the vague no man's land <a href="http://www.anandtech.com/cpuchipsets/intel/showdoc.aspx?i=3367">between CPU and GPU</a>:
</p>
<p>
</p>
<blockquote>
[Larrabee] is first and foremost NOT a GPU. It's a CPU. A many-core CPU that is optimized for data-parallel processing. What's the difference? Well, there is very little fixed function hardware, and the hardware is targeted to run general purpose code as easily as possible. The bottom lines is that Intel can make this very wide many-core CPU look like a GPU by implementing software libraries to handle DirectX and OpenGL.
</blockquote>
<p>
We know that GPUs generally deliver one or two more orders of magnitude more performance than a general purpose CPUs <a href="http://www.codinghorror.com/blog/archives/000732.html">at the things they are good at</a>. That's what I would expect for dedicated hardware devoted to a specific and highly parallizable task.
</p>
<p>
Michael Abrash has already attempted what most people said was impossible -- to build <b>a full software 3D renderer that runs modern games at reasonable framerates</b>. In other words, to make a general purpose CPU compete in a completely unfair fight against a highly specialized GPU. He's effectively accomplished that, and his company sells it as a product called <a href="http://www.radgametools.com/pixomain.htm">Pixomatic</a>:
</p>
<p>
</p>
<blockquote>
In this <a href="http://www.google.com/search?q=Optimizing+Pixomatic+for+x86+Processors">three-part article</a>, I discuss the process of optimizing <a href="http://www.radgametools.com/pixomain.htm">Pixomatic</a>, an x86 3D software rasterizer for Windows and Linux written by Mike Sartain and myself. Pixomatic was <b>perhaps the greatest performance challenge I've ever encountered</b>, certainly right up there with <a href="http://en.wikipedia.org/wiki/Quake">Quake</a>. When we started on Pixomatic, we weren't even sure we'd be able to get DirectX 6 features and performance, the minimum for a viable rasterizer. I'm pleased to report that we succeeded. On a 3 GHz Pentium 4, Pixomatic can run Unreal Tournament 2004 at 640Ã¢â€”Å 480, with bilinear filtering enabled. On slower processors, performance is of course lower, but by rendering at 320Ã¢â€”Å 240 and stretching up to 640Ã¢â€”Å 480, Unreal Tournament 2004 runs adequately well -- even on a 733-MHz Pentium III.
</blockquote>
<p>
Pixomatic is documented in <a href="http://www.google.com/search?q=Optimizing+Pixomatic+for+x86+Processors">an excellent series of Dr. Dobbs articles</a>. It's fascinating reading; even though I know zero about assembly language, Michael's language of choice, he's a fantastic writer. That old adage about the subject not mattering when you have a great teacher has never been truer.
</p>
<p>
I remember <a href="http://www.codinghorror.com/blog/archives/000234.html">trying out Pixomatic</a> briefly four years ago. Those CPUs he's talking about seem awfully quaint now, and that made me curious: how fast is the Pixomatic software renderer on <i>today's</i> CPUs? My current box is a <b>Core 2 Duo (wolfdale) running at 3.8 GHz</b>. So I downloaded the <a href="http://download.cnet.com/Unreal-Tournament-2004-demo/3000-7441_4-10262824.html">Unreal Tournament 2004 demo</a> (still fun, by the way!), and followed the brief, easy instructions provided to <a href="http://www.radgametools.com/pixo/PixoWithUnreal2004.txt">enable the Pixomatic software renderer</a>. It's not complicated:
</p>
<p>
</p>
<pre>
ut2004.exe -software
</pre>
<p>
One word of warning. Be sure you have an appropriate resolution set before doing this! I was playing at 1920x1200 initially, and that's what the software renderer defaulted to. And here's the shocker: <i>it was actually playable!</i> I couldn't believe it. It wasn't great, mind you, but it was hardly a slideshow. I tweaked the resolution down to something I felt was realistic: 1024x768. I turned on framerate display by pressing ...
</p>
<p>
</p>
<pre>
~
stat fps
</pre>
<p>
... from within the game. <b>This Pixomatic software rendered version of the game delivered a solid 40-60 fps experience in capture the flag mode</b>. It ran so well, in fact, that I decided to bump up the detail -- I enabled 32-bit color and bilinear filtering by editing the <code>ut2004.ini</code> file:
</p>
<p>
</p>
<pre>
[PixoDrv.PixoRenderDevice]
FogEnabled=True
Zoom2X=False
SimpleMaterials=True
LimitTextureSize=True
<font color="red">LowQualityTerrain=False</font>
TerrainLOD=10
SkyboxHack=True
<font color="red">FilterQuality3D=3</font>
FilterQualityHUD=1
HighDetailActors=False
SuperHighDetailActors=False
ReduceMouseLag=True
DesiredRefreshRate=0
DetailTexMipBias=0.000000
Use16bitTextures=False
<font color="red">Use16bit=False</font>
UseStencil=False
UseCompressedLightmaps=False
DetailTextures=False
UsePrecaching=True
</pre>
<p>
Once I did this, the game looked totally respectable. Eerily reminiscent in visuals and performance to the classic, early Voodoo and Voodoo 2 cards, actually.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
(If you think this looks bad, check out <a href="http://www.firingsquad.com/media/gallery_index.asp/244">Doom 3 running on an ancient Voodoo 2 setup</a>. It's certainly better than that!)
</p>
<p>
The frame rate took a big hit, <b>dropping to 30fps</b>, but I found it was an uncannily <i>stable</i> 30fps. The only achilles heel of the Pixomatic software renderer is places with lots of alpha blending, such as when you fire a sniper rifle, obscuring the entire screen with a puff of muzzle smoke, or if you're standing near a teleportation portal.
</p>
<p>
Pretty amazing, right? It is!
</p>
<p>
</p>
<h2>And <b>utterly pointless</b>.</h2>
<p>
My <a href="http://www.codinghorror.com/blog/archives/001185.html">current video card</a> renders Unreal Tournament 2004 at the highest possible resolution with every possible quality option set to maximum, at somewhere between <b>200 and 300 frames per second</b>. Despite the miraculously efficient assembly Abrash and Sartain created to make this possible <i>at all</i>, it's at best a carnival oddity; even the crappiest onboard laptop 3D (assuming a laptop of recent vintage) could outperform Pixomatic <a href="http://www.anandtech.com/video/showdoc.aspx?i=2427&amp;p=5">without even breaking a sweat</a>.
</p>
<p>
We know that the game is far more enjoyable to play with a real GPU, on a real video card. And we're hip deep in real GPUs on every platform; even the <a href="http://forum.beyond3d.com/showthread.php?t=42496">iPhone has one</a>. Perhaps Pixomatic made some business sense back in 2003, but it didn't take a genius analyst back then to see that it would make no business sense at <i>all</i> today. At the same time, I can't help admiring the engineering effort that went into building a viable 3D software renderer, something that seemed virtually <i>impossible</i> bordering on foolish.
</p>
<p>
</p>
<blockquote>
In short, it will be possible to get major speedups from [Larrabee] without heroic programming, and that surely is A Good Thing. Of course, nothing's ever that easy; as with any new technology, only time will tell exactly how well automatic vectorization will work, and at the least it will take time for the tools to come fully up to speed. Regardless, it will equally surely be possible to get even greater speedups by getting your hands dirty with intrinsics and assembly language; besides, <b>I happen to like heroic coding</b>.
</blockquote>
<p>
Ditto.
</p>
<p>
We'll have to wait and see if Intel's efforts to push GPU functionality into their x86 architecture makes any of this heroic coding more relevant in the future. Either way, it remains impressive.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/i-happen-to-like-heroic-coding/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Almost Perfect ]]></title>
<link>https://blog.codinghorror.com/almost-perfect/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'll always remember <a href="http://en.wikipedia.org/wiki/WordPerfect">WordPerfect</a> as the quintessential white text on blue screen application.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/WordPerfect"><img alt="image placeholder" >
</p>
<p>
For a period from about 1985 to 1992, <b>WordPerfect was the most popular word processing program in the world on virtually every computing platform</b>. I remember it well; the very <i>concept</i> of word processing was synonymous with WordPerfect.
</p>
<p>
And now I can't even recall the last time I encountered a WordPerfect document, much less anyone who still uses WordPerfect. The software is still limping along, barely, under the auspices of Corel corporation, as <a href="http://www.corel.com/servlet/Satellite/us/en/Product/1207676528492">WordPerfect Office X4</a>. I guess it's a testament to how quickly things change in the world of software; you can dominate the world for years, only to be relegated to little more than a dimly remembered footnote in computing history a decade later.
</p>
<p>
Perhaps that's why the online book <a href="http://www.wordplace.com/ap/index.shtml">Almost Perfect</a>, which documents the rise and fall of WordPerfect, is such a gripping read. I clicked through, read the first chapter, read the second chapter, and ... I <i>couldn't stop reading it!</i>
</p>
<p>
Some of the story is predictable. WordPerfect, like many other companies at the time, <b>never really made the transition from DOS to Windows</b>. They didn't just bet on the wrong horse, they institutionalized a software culture that lived and died on character mode assumptions. That, plus an almost fanatical dedication to cross-platform parity -- even when the platforms they supported made little business sense -- makes the final outcome almost inevitable.
</p>
<p>
Still, there's something intriguing about the fledgling SSI corporation. For one thing, the entire business was run in an agile, almost by-the-seat-of-their-pants way. It's a bit of a David and Goliath story, how they clawed their way to success over so many formidable opponents by simply <b>dedicating themselves to creating an excellent product</b>, and cultivating a vibrant community around that product both inside <i>and</i> outside the company. But perhaps the best part is that the company was <a href="http://www.wordplace.com/ap/ap_chap08.shtml">run by programmers</a>:
</p>
<p>
</p>
<blockquote>
We spent a lot of time in meetings going over what had to be in the product and how things should work. These decisions were made by the programmers, who sometimes had very heated discussions about what was needed. At times the three of us on the Board had to assume the role of referee. Some of the issues were very complicated, so by the time the arguments were finished and a decision was made, I usually had a headache.
<p>
<b>It was somewhat unusual for a software company to let the programmers decide the future of its products</b>. We were, however, a company founded and owned by programmers, where programmers were treated with an extra measure of respect. The marketing department was used primarily to sell products once they were developed, and only rarely did it get involved early enough to perform the traditional marketing role of identifying a need and defining a product to fill that need. At times this put us in the position of developing solutions before we identified problems, but it was hard to be too critical of the programmers when the company was so successful. To their credit, the programmers tried very hard to listen to our customers and to those of us in the marketing department. The programmers were smart and thoughtful and very good at protecting the best interests of the company. At times, however, they were prone to manipulate some of the data they received to fit what it was they wanted to do.
</p>
</blockquote>
<p>
The story sort of fizzles out toward the end, as the author, W. E. Pete Peterson, is unceremoniously kicked out of the company just as WordPerfect Corporation <a href="http://www.businessweek.com/archives/1993/b331955.arc.htm">begins to lose its hold on the market</a>. Perhaps this is fitting: like WordPerfect itself, he doesn't go out with a bang, but a whimper.
</p>
<p>
At any rate, <a href="http://www.wordplace.com/ap/index.shtml">Almost Perfect</a> is fantastic reading. Long out of print, it finds its own audience when self-published on the web. It's reminiscent of the very best early computer industry tales from one of my favorite books, <a href="http://www.amazon.com/exec/obidos/ASIN/0887308554/codihorr-20">Accidental Empires</a>.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0887308554/codihorr-20"><img alt="image placeholder" >
</p>
<p>
I was paging through the book again after I was reminded of it, and I found this passage:
</p>
<p>
</p>
<blockquote>
Of course, companies don't have to grow. <a href="http://en.wikipedia.org/wiki/Electric_Pencil">Electric Pencil</a>, the first word processing program for the Apple II, was the archetype for all word processing packages that followed, but its developer, a former Hollywood screenwriter, just got tired of all the support hassles and finally shut his company down. In 1978, Electric Pencil had 250,000 users. By 1981, it was forgotten.
</blockquote>
<p>
The book was also <a href="http://www.codinghorror.com/blog/archives/000718.html">made into a documentary, Triumph of the Nerds</a>. I recommend both highly.
</p>
<p>
I'm not sure if all the lessons from <a href="http://www.wordplace.com/ap/index.shtml">Almost Perfect</a> are relevant today -- but some failure patterns are timeless, and I certainly admired the way SSI bootstrapped itself while letting the employees (and more specifically, the <i>programmers</i>) run the company.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/almost-perfect/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Sex, Lies, and Software Development ]]></title>
<link>https://blog.codinghorror.com/sex-lies-and-software-development/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Are there any programming jobs you wouldn't take? Not because the jobs didn't pay enough, had poor benefits, or limited upside -- but because the work itself made you uncomfortable? Consider the tale of <a href="http://freshmeat.net/articles/excessive-code-and-excessive-nudity-what-gives">one freshmeat.net writer</a>:
</p>
<p>
</p>
<blockquote>
Back in the old days (let's say 1996), I was just another Perl coder writing CGI scripts for a living. Well, pocket money's more like it, but okay. I wrote scripts for fun, I wrote them to make some cash, and I wrote them because I'm a geek and I love programming. Then, one day, I got a phone call from this company. A friend of mine had referred them to me, and they wanted me to write a CGI script. The gentleman I spoke with was very well mannered, very well educated -- the typical likeable manager.
<p>
After some talking, he came to the point. The CGI script I was to create was supposed to take an archive of images and make them searchable by topic. In itself nothing amazing, but when I asked, out of curiosity, what kind of images we were talking about, I was surprised to find out it was porn. Yes, <b>porn</b>.
</p>
<p>
I accepted the job, and life changed dramatically. Instead of friends saying "cool" or some coders I knew saying "nice script", they shied away, refused to talk to me, refused to look at the script. For a long time, I wondered why. This year, I went to a convention. I was just out there looking for new cool stuff, not much else. Everyone I talked to was friendly, and downright nice, right up until the point when I told them what I did for a living. Then they suddenly remembered they had something better to do.
</p>
<p>
And why? Does working on the adult part of the net mean I'm a scumbag? Does it mean I'm sleazy? Does it mean I'm untrustworthy? Does it mean my code is bad?
</p>
</blockquote>
<p>
That was eight years ago. I wonder how the now over-thirty author of the original article is getting on in his career. <b>Does he still write code for the adult industry?</b> Somehow, I doubt it.
</p>
<p>
This isn't just random noodling on my part. I've almost been in the same situation. About ten years ago, I had an interview for a programming position with a prominent North Carolina based purveyor of adult products. After the interview, I asked my girlfriend (now my wife) how she would feel if I took a job that was, more or less, in the adult industry. Although she's flexible on almost every topic, this is one area where she had serious reservations. I think the operative words were "what will we tell our parents?" It's a fair question. For that matter, what do you tell your friends when they ask where you work? Your peers? It was enough to keep me from taking the job.
</p>
<p>
Years later, I encountered one of my previous coworkers who <i>had</i> taken a programming job there. It turns out I made the right choice, but not for the reasons you might think. There were technical and managerial problems on the job that far outstripped any effects from the unusual choice of industry. That said, when I asked him what the environment was like, working daily with adult products, he had a one word response: <i>weird</i>.
</p>
<p>
The adult industry does present interesting technical and scaling challenges, perhaps more interesting than building yet another line of business <a href="http://en.wikipedia.org/wiki/Create,_read,_update_and_delete">CRUD</a> application for Yet Another MegaCorp. A recent Reddit discussion thread which asked <a href="http://www.reddit.com/r/programming/comments/844pj/if_you_designed_a_porn_site_would_you_put_it_on/">if you designed a porn site, would you put it on your resume?</a> had some excellent examples.
</p>
<p>
</p>
<blockquote>
[Adult] sites have oodles of top-quality attributes to them; payment processing, secured content, username and password maintenance (especially self-service maintenance) rapid updates and, if your site was successful, some interesting scaling problems to engineer around.
<p>
I work for an [adult] site. It's going on my resume. Anybody I've told in a professional or semi-professional setting has been impressed and wanted to know the technical details about our server setup and bandwidth. I have yet to meet anybody, friend or prospective employer who was turned off by the thought of my serving up [adult content]. And I'm willing to say that I wouldn't work for someone who would judge me negatively because of it. I got into it because of the interesting scaling problems and potential for wisdom-of-crowds filtering and selection. And you know what, it's kinda fun.
</p>
<p>
I've worked in the [adult] industry for over 8 years. If I were to apply for a new job, you bet I would include it on my resume. I don't think I'd want to work for a company that couldn't see the benefit of having someone onboard that's worked with systems that must always work, have a known cost-per-minute of downtime, and are on a permanently continuous release cycle.
</p>
</blockquote>
<p>
The general tone of the advice is that, if you choose to work in the adult industry, <b>you have to tell white lies about your work</b> -- small evasions about what your work is, and who it is for, depending on the audience. Invoke vague NDAs. Describe things in broad, general terms.
</p>
<p>
What if you saw this programming job listing:
</p>
<p>
</p>
<ul>
<li>Work from home on a large, high-traffic website with lots of challenging scaling problems.
</li>
<li>Use the latest frameworks and technologies.
</li>
<li>Set your own hours.
</li>
<li>Excellent pay through wire transfer from an offshore account, with full benefits.
</li>
</ul>
<p>
(I am not making any of this up, I'm actually summarizing a real job listing.) Seems like a <i>fantastic</i> programming job, right? But what if I told you this job listing was for an <b>adult website?</b> Would you still consider it?
</p>
<p>
I bring this up because I recently read a great <a href="http://timothyfitz.wordpress.com/2009/02/10/continuous-deployment-at-imvu-doing-the-impossible-fifty-times-a-day/">in the trenches story about continuous deployment</a>.
</p>
<p>
</p>
<blockquote>
Our tests suite takes nine minutes to run (distributed across 30-40 machines). Our code pushes take another six minutes. Since these two steps are pipelined that means at peak we're pushing a new revision of the code to the website every nine minutes. That's 6 deploys an hour. Even at that pace we're often batching multiple commits into a single test/push cycle. On average we deploy new code fifty times a day.
</blockquote>
<p>
My enthusiasm for this supreme feat of software engineering was tempered by the fact that, when I clicked through to find out more about the company that was doing such sophisticated software engineering, I learned that it's a 3D chat avatar system. A very.. <i>sexy</i>..  3D chat avatar system. Just look at their ads to see what I mean:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
What is being sold here? I've even seen similar "sexy" IMVU ads with female 3D avatars in skimpy lingerie come up organically on my <a href="http://www.fakeplasticrock.com">Fake Plastic Rock</a> blog, of all places. I'm not the first person to <a href="http://www.shamusyoung.com/twentysidedtale/?p=955">make this connection</a>, either.
</p>
<p>
</p>
<blockquote>
A reader expressed their irritation with the IMVU ads that have been running in the sidebar recently. I was actually glad to see I wasn't the only one. They have a trashy, lowest-common-denominator feel to them. Kind of a "Welcome to Hoochie World" vibe. The ad has been running for over a month, and I've never seen a picture of a single male avatar. It's either the quasi-jailbait in a bikini, or a couple of skanks in a pseudosapphic embrace. Using a pretty girl to sell your stuff is perfectly reasonable, but doing it with such a lack of class gets on my nerves. I've never used the software, but the ads make me think their chat software is a world inhabited by l337-speaking teenage boys that would make the average FARK thread sound like the Mclaughlin Group by comparison.
</blockquote>
<p>
The <a href="http://avatars.imvu.com/hottiepie4life">profile for IMVU user "hottiepie4life"</a> makes it abundantly clear that IMVU, while not <i>quite</i> part of the adult industry per se, skirts awfully close to the edge of it. Enough to make me, personally, uncomfortable about working there, or talking to anyone who worked there. And it certainly colors and devalues my impression of the technical work going on there.
</p>
<p>
Maybe this is my problem. Does the subject matter dilute the excellent technical work the IMVU team might be doing? No. But at the same time, <b>I can't help questioning the ultimate value of that work.</b> I'm no prude. And I don't expect every programmer to be doing noble, selfless work for the good of humanity. All the same, it's difficult for me to respect software engineering in the service of such least common denominator interests.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/sex-lies-and-software-development/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Training Your Users ]]></title>
<link>https://blog.codinghorror.com/training-your-users/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
When it comes to user interface design, I'm no guru, but I do have one golden rule that I always try to follow:
</p>
<p>
</p>
<blockquote>
Make the right thing easy to do and the wrong thing awkward to do.
</blockquote>
<p>
The things you <i>want</i> users to do should be straightforward and clear -- as simple as <a href="http://www.codinghorror.com/blog/archives/000940.html">falling into the pit of success</a>. Make your software easy to use. Duh. Everyone knows that. The less obvious part of this rule is that <b>sometimes there are things you <i>don't</i> want users to do</b>. In those cases, you actually want your application, or at least certain areas of it, to be <i>harder to use</i>. For example, operations that are risky or dangerous should take more steps.
</p>
<p>
What you're doing with this design technique is <a href="http://www.nytimes.com/2006/06/25/fashion/25love.html?_r=2">training your users</a>:
</p>
<p>
</p>
<blockquote>
The central lesson I learned from exotic animal trainers is that I should reward behavior I like and ignore behavior I don't. After all, you don't get a sea lion to balance a ball on the end of its nose by nagging.
</blockquote>
<p>
When you make features easy to use, you are <b>rewarding user behavior you like</b>. You are guiding users through your application, giving them a clear and obvious path of least resistance. And when you intentionally choose <i>not</i> to make a feature easy to use, you are effectively <b>ignoring user behavior you don't like</b>. You are indirectly discouraging users from utilizing those features.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If you aren't taking advantage of both techniques in your user interface -- rewarding with simplicity, and (judiciously) ignoring with complexity where necessary -- you aren't properly <b>training your users</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/training-your-users/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Death to the Space Infidels! ]]></title>
<link>https://blog.codinghorror.com/death-to-the-space-infidels/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Ah, spring. What a wonderful time of year. A time when young programmers' minds turn to thoughts of ... <i><b>neverending last-man-standing filibuster arguments about code formatting</b></i>.
</p>
<p>
Naturally.
</p>
<p>
And there is no argument more evergreen than <a href="http://www.jwz.org/doc/tabs-vs-spaces.html">the timeless debate between tabs and spaces</a>.
</p>
<p>
</p>
<blockquote>
On defaultly-configured Unix systems, and on ancient dumb terminals and teletypes, the tradition has been for the TAB character to mean <i>move to the right until the current column is a multiple of 8.</i> This is also the default in the two most popular Unix editors, Emacs and vi.
<p>
In many Windows and Mac editors, the default interpretation is the same, except that multiples of 4 are used instead of multiples of 8.
</p>
<p>
A third interpretation is for the ASCII TAB character to mean <i>indent to the next tab stop</i>, where the tab stops are set arbitrarily: they might not necessarily be equally distanced from each other. Most word processors can do this; Emacs can do this. I don't think vi can do this, but I'm not sure.
</p>
<p>
With these three interpretations, the ASCII TAB character is essentially being used as a compression mechanism, to make sequences of SPACE-characters take up less room in the file.
</p>
</blockquote>
<p>
So, then, the question: should code* be indented with <b>spaces</b>..
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
or with <b>tabs</b>?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
According to Cyrus, there's <a href="http://blogs.msdn.com/cyrusn/archive/2004/09/14/229474.aspx">a third option</a>: an unholy melding of <b>both tabs <i>and</i> spaces</b>. Apparently you can use tab for primary indentation alignment and then spaces on top of that for detail alignment. Like so:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This way, in theory at least, the level of indent can be adjusted dynamically without destroying alignment. But I'm more inclined to think of it as combining all the complexity and pitfalls of both approaches, myself.
</p>
<p>
OK, so maybe you're an enlightened coder. You've moved beyond mere earthbound issues like tabs vs. spaces on your personal path to code nirvana. Perhaps you have some kind of fancy auto-formatter that runs on every checkin. Or, maybe you're using a next-<i>next</i>-generation editor that treats code as "data" and the layout (including whitespace) as a "view", making all these concerns largely irrelevant.
</p>
<p>
But there's a deeper issue here to consider. <b>The only programming project with no disagreement whatsoever on code formatting is the one you work on alone</b>. Wherever there are two programmers working on the same project, there are invariably disagreements about how the code should be formatted. Sometimes serious disagreements. The more programmers you add, the more divisive those disagreements get. And handling those disagreements can be .. tricky. Take this email I received from Philip Leitch:
</p>
<p>
</p>
<blockquote>
The place where I work currently has a developer (who is also the head of the development department), who will "clean up" the code of others.
<p>
That is -- reformat it, normally without changing what the code does, just changing the variable names, function names, but mainly moving things around to the way they like it.
</p>
<p>
It is a little perplexing ÃƒÆ’Ã¢â‚¬â€œ and I'm interested to see what responses people have on this issue.
</p>
</blockquote>
<p>
One of absolute worst, <i>worst</i> methods of <a href="http://www.codinghorror.com/blog/archives/001205.html">teamicide</a> for software developers is to engage in these kinds of passive-aggressive formatting wars. I know because I've been there. They destroy peer relationships, and depending on the type of formatting, can also damage your ability to effectively compare revisions in source control, which is <i>really</i> scary. I can't even imagine how bad it would get if the lead was guilty of this behavior. That's leading by example, all right. <i>Bad</i> example.
</p>
<p>
The depressing thing about all this is that <b>code formatting matters more than you think</b>. Perhaps even enough to justify the endless religious wars that are fought over it. Consider the 1984 study by Soloway and Ehrlich cited in <a href="http://www.amazon.com/dp/0735619670/?tag=codihorr-20">Code Complete</a>:
</p>
<p>
</p>
<blockquote>
Our studies support the claim that knowledge of programming plans and rules
of programming discourse can have a significant impact on program comprehension. In their book called <a href="http://www.amazon.com/dp/0070342075/?tag=codihorr-20">The Elements of Programming Style</a>, Kernighan and Plauger also identify what we would call discourse rules. Our empirical results put teeth into these rules: <b>It is not merely a matter of aesthetics that programs should be written in a particular style</b>. Rather there is a psychological basis for writing programs in a conventional manner:  programmers have strong expectations that other programmers will follow these discourse rules. If the rules are violated, then the utility afforded by the expectations that programmers have built up over time is effectively nullified. The results from the experiments with novice and advanced student programmers and with professional programmers described in this paper provide clear support for these claims.
</blockquote>
<p>
There's actual data from honest-to-goodness experiments to support the hypothesis that consistent code formatting is <i>worth fighting for</i>. And there are dozens of studies backing it up, too, as Steve McConnell notes:
</p>
<p>
</p>
<blockquote>
In their classic paper <a href="http://www.sil.org/lingualinks/Literacy/ReferenceMaterials/BibliographyLiteracy/ChaseAndSimon1973.htm">Perception in Chess</a>, Chase and Simon reported on a study that compared the abilities of experts and novices to remember the positions of pieces in chess. When pieces were arranged on the board as they might be during a game, the experts' memories were far superior to the novices'. When the pieces were arranged randomly, there was little difference between the memories of the experts and the novices. The traditional interpretation of this result is that an expert's memory is not inherently better than a novice's but that the expert has a knowledge structure that helps him or her remember particular kinds of information. When new information corresponds to the knowledge structure -- in this case,
the sensible placement of chess pieces -- the expert can remember it easily. When new information doesn't correspond to a knowledge structure -- the chess pieces are randomly positioned -- the expert can't remember it any better than the novice.
<p>
A few years later, Ben Shneiderman duplicated Chase and Simon's results in the computer-programming arena and reported his results in a paper called <a href="http://www.springerlink.com/content/m852q12168q76224/">Exploratory Experiments in Programmer Behavior</a>. Shneiderman found that <b>when program statements were arranged in a sensible order, experts were able to remember them better than novices. When statements were shuffled, the experts' superiority was reduced.</b> Shneiderman's results have been confirmed in other studies. The basic concept has also been confirmed in the games Go and bridge and in electronics, music, and physics.
</p>
</blockquote>
<p>
So yes, absurd as it may sound, fighting over whitespace characters and other seemingly trivial issues of code layout is actually justified. Within reason of course -- when done openly, in a fair and concensus building way, and without stabbing your teammates in the face along the way.
</p>
<p>
Choose tabs, choose spaces, choose whatever layout conventions make sense to you and your team. It doesn't actually matter which coding styles you pick. What <i>does</i> matter is that you, and everyone else on your team, <b>sticks with those conventions and uses them consistently</b>.
</p>
<p>
That said, only a moron would use tabs to format their code.
</p>
<p>
* unless you happen to be programming in <a href="http://compsoc.dur.ac.uk/whitespace/">whitespace</a> or <a href="http://www.python.org/">Python</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/death-to-the-space-infidels/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is Open Source Experience Overrated? ]]></title>
<link>https://blog.codinghorror.com/is-open-source-experience-overrated/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm a big advocate of <a href="http://www.codinghorror.com/blog/archives/000827.html">learning on the battlefield</a>. And that certainly includes what may be the most epic battle of them all: <b>open source software</b>.
</p>
<p>
</p>
<blockquote>
<b>Contribute to an open-source project</b>. There are thousands, so pick whatever strikes your fancy. But pick one and really dig in, become an active contributor. Absolutely nothing is more practical, more real, than working collaboratively with software developers all over the globe from all walks of life.
</blockquote>
<p>
If you're looking to polish your programming chops, what could possibly be better, more job-worthy experience than immersing yourself in a real live open source software project? There are thousands, maybe hundreds of thousands, and a few of them have arguably changed the world.
</p>
<p>
Unfortunately, that wasn't what happened for one particular open source developer. In an anonymous email to me, he related his experiences:
</p>
<p>
</p>
<blockquote>
I'm a programmer with 14 years of experience both inside academics and in commercial industry currently looking for work. In both my cover letters and my resume I indicate that <b>I am the architect of a couple of open source Java projects</b> where the code, design and applications were available on the web.
<p>
One company seemed impressed with my enthusiasm for the job but it was part of their policy to provide coding tests.  This seemed perfectly reasonable and I did it by using the first solution I thought about.  When I got to the phone interview, the guy spent about five minutes telling me how inefficient my coding solution was and that they were not very impressed.  Then I asked whether he had looked at the open source projects I mentioned.  He said no - but it seems his impression was already set based on my performance in the coding test.  The coding test did not indicate what criteria they were using for evaluation but my solution seemed to kill the interview.
</p>
<p>
In another call, I was talking with a recruiter who was trying to place someone for a contract Java development assignment.  I told her that most of my recent work was open source and that she could inspect it if she wanted to assess my technical competence.  Five minutes later she phoned back and said I appeared to lack any recent commercial experience.  I had demonstrable open source applications that used the technologies they wanted, but it didn't appear to matter.
</p>
<p>
With yet another recruiter I told him that even years ago when I had worked on commercial projects, before I went back to school, the proprietary nature of my jobs prevented me from mentioning the specifics about a lot of what I did.  The badge of commercial software experience didn't necessarily prove either my technical competence or my relative contribution to the projects.   What my experience of working in industry long ago did teach me was how to fill out a time sheet and estimate time for deliverables. But this experience would seem a bit dated now for recruiters.
</p>
</blockquote>
<p>
That's a terrible interview track record for the open source experience that I advocated so strongly. He continues:
</p>
<p>
</p>
<blockquote>
I think it's important that I try to see their point of view.  A lot of open source projects are probably poorly written and made in response to a neat idea rather than to requirements from some user community. In academia, the goal for development is often more about publishing papers than establishing a user base. Industry people sometimes have the view (sometimes justified and sometimes not) that open source developers who emerge from academic projects lack practical skills.  I don't necessarily claim my open source code is the best in the world but it works, it's documented and it's available for scrutiny. <b>One of the reasons I worked so hard on open source projects was to make job interviews easier.</b> By providing prospective employers with large samples of publically available working code, I thought I would give them something more useful to think about than my performance on a particular coding test or whether the acronyms in the job skills matched my "years spent". I am very aware of the hype behind open source. I've heard it, lived it and even spun some of it myself.  But sometimes it's good to take a sobering reality check -- <b>is open-source experience overrated?</b>
</blockquote>
<p>
It's disheartening to hear so many prospective employers completely disregard experience on open source projects. It's a part of <a href="http://www.codinghorror.com/blog/archives/000104.html">your programming portfolio</a>, and any company not even willing to take a cursory look at your portfolio before interviewing you is already suspect. This reflects poorly on the employers. I'm not sure I'd <i>want</i> to work at a place where a programmers' prior body of work is treated as inconsequential.
</p>
<p>
On the other hand, <b>perhaps the choice of open source project matters almost as much as the programming itself</b>. How many open source projects labor away in utter obscurity, solving problems that nobody cares about, problems so incredibly narrow that the authors are the only possible beneficiaries? Just as commercial software can't possibly exist without customers, perhaps open source experience is only valid if you work on a project that attains some moderate level of critical mass and user base. Remember, <a href="http://www.codinghorror.com/blog/archives/000773.html">shipping isn't enough</a>. Open source or not, if you aren't building software that <i>someone</i> finds useful, if you aren't convincing at least a <i>small</i> audience of programmers that <a href="http://www.codinghorror.com/blog/archives/001215.html">your project is worthwhile enough to join</a> --
</p>
<p>
Then what are you really doing?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-open-source-experience-overrated/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Exception-Driven Development ]]></title>
<link>https://blog.codinghorror.com/exception-driven-development/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you're waiting around for <b>users to tell you about problems with your website or application</b>, you're only seeing a tiny fraction of all the problems that are actually occurring. The proverbial tip of the iceberg.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Also, if this is the case, I'm sorry to be the one to have to tell you this, but you kind of suck at your job -- which is to <b>know more about your application's health than your users do.</b> When a user informs me about a bona fide error they've experienced with my software, I am deeply embarrassed. And more than a little ashamed. I have failed to see and address the issue before they got around to telling me. I have neglected to <a href="http://www.codinghorror.com/blog/archives/001118.html">crash responsibly</a>.
</p>
<p>
The first thing any responsibly run software project should build is an <b>exception and error reporting facility</b>. Ned Batchelder likens this to <a href="http://nedbatchelder.com/text/fix-err-hand.html">putting an oxygen mask on yourself before you put one on your child</a>:
</p>
<p>
</p>
<blockquote>
When a problem occurs in your application, always check first that the error was handled appropriately. If it wasn't, always fix the handling code first. There are a few reasons for insisting on this order of work:
<p>
</p>
<ol>
<li>With the original error in place, you have a perfect test case for the bug in your error handling code. Once you fix the original problem, how will you test the error handling? Remember, one of the reasons there was a bug there in the first place is that it is hard to test it.
</li>
<li>Once the original problem is fixed, the urgency for fixing the error handling code is gone. You can say you'll get to it, but what's the rush? You'll be like the guy with the leaky roof. When it's raining, he can't fix it because it's raining out, and when it isn't raining, there's no leak!
</li>
</ol>
</blockquote>
<p>
You need to have a central place that all your errors are aggregated, a place that all the developers on your team know intimately and visit every day. On Stack Overflow, we use a custom fork of <a href="http://code.google.com/p/elmah/">ELMAH</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
We monitor these exception logs daily; sometimes hourly. <b>Our exception logs are a de-facto to do list for our team</b>. And for good reason. Microsoft has collected similar sorts of failure logs for years, both for themselves and other software vendors, under the banner of their Windows Error Reporting service. The <a href="https://winqual.microsoft.com/help/About_Windows_Error_Reporting_for_Hardware.htm">resulting data</a> is compelling:
</p>
<p>
</p>
<blockquote>
When an end user experiences a crash, they are shown a dialog box which asks them if they want to send an error report. If they choose to send the report, WER collects information on both the application and the module involved in the crash, and sends it over a secure server to Microsoft.
<p>
The mapped vendor of a bucket can then <a href="http://www.sherylcanter.com/articles/oreilly_20040316_wer.php">access the data for their products</a>, analyze it to locate the source of the problem, and provide solutions both through the end user error dialog boxes and by providing updated files on Windows Update.
</p>
<p>
Broad-based trend analysis of error reporting data shows that <b>80% of customer issues can be solved by fixing 20% of the top-reported bugs</b>. Even addressing 1% of the top bugs would address 50% of the customer issues. The same analysis results are generally true on a company-by-company basis too.
</p>
</blockquote>
<p>
Although <a href="http://www.codinghorror.com/blog/archives/000640.html">I remain a fan of test driven development</a>, the speculative nature of the time investment is one problem I've always had with it. <b>If you fix a bug that no actual user will ever encounter, what have you actually <i>fixed?</i></b> While there are <a href="http://www.codinghorror.com/blog/archives/000265.html">many other valid reasons to practice TDD</a>, as a pure bug fixing mechanism it's always seemed far too much like premature optimization for my tastes. I'd much rather spend my time fixing bugs that are problems in <i>practice</i> rather than theory.
</p>
<p>
You can certainly do both. But given a limited pool of developer time, I'd prefer to allocate it toward fixing problems real users are having with my software based on cold, hard data. That's what I call <b>Exception-Driven Development</b>. Ship your software, get as many users in front of it as possible, and intently study the error logs they generate. Use those exception logs to hone in on and focus on the problem areas of your code. Rearchitect and refactor your code so the top 3 errors can't happen any more. <a href="http://www.codinghorror.com/blog/archives/000788.html">Iterate rapidly</a>, deploy, and repeat the proces. This data-driven feedback loop is so powerful you'll have (at least from the users' perspective) a rock stable app in a handful of iterations.
</p>
<p>
Exception logs are possibly the most powerful form of feedback your customers can give you. It's feedback based on <i>shipping software</i> that you don't have to ask or cajole users to give you. Nor do you have to interpret your users' weird, semi-coherent ramblings about what the problems are. The actual problems, with stack traces and dumps, are collected for you, automatically and silently. <b>Exception logs are the ultimate in customer feedback.</b>
</p>
<p>
<a href="http://twitter.com/Carnage4Life/status/1534037187"><img alt="image placeholder" >
</p>
<p>
Am I advocating shipping buggy code? Incomplete code? Bad code? Of course not. I'm saying that the sooner you can get your code out of your editor and in front of real users, the more data you'll have to <i>improve</i> your software. Exception logs are a big part of that; so is usage data. And you should talk to your users, too. If you can bear to.
</p>
<p>
Your software will ship with bugs anyway. <a href="http://www.codinghorror.com/blog/archives/000099.html">Everyone's software does</a>. Real software crashes. Real software loses data. Real software is hard to learn, and hard to use. The question isn't how many bugs you will ship with, but <b><i>how fast can you fix those bugs?</i></b> If your team has been practicing exception-driven development all along, the answer is -- why, we can improve our software in no time at all! Just watch us make it better!
</p>
<p>
And that is sweet, sweet music to every user's ears.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/exception-driven-development/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Not to Conduct an Online Poll ]]></title>
<link>https://blog.codinghorror.com/how-not-to-conduct-an-online-poll/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://musicmachinery.com/2009/04/15/inside-the-precision-hack/">Inside the Precision Hack</a> is a great read. It's all about how the Time Magazine <a href="http://www.time.com/time/specials/packages/0,28757,1883644,00.html">World's Most Influential People poll</a> was gamed. But the actual hack itself is somewhat less impressive when you start digging into the details.
</p>
<p>
Here's the voting UI for the Time poll in question.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Casting a vote submits a <code>HTTP GET</code> in the form of:
</p>
<p>
</p>
<pre>http://www.timepolls.com/contentpolls/Vote.do
?pollName=time100_2009&amp;<font color="red">id=1883924</font>&amp;<font color="red">rating=1</font>
</pre>
<p>
Where id is a number associated with the person being voted for, and rating is how influential you think that person is from 1 to 100. Simple enough, but Time's execution was .. less than optimal.
</p>
<p>
</p>
<blockquote>
In early stages of the poll, <b>Time.com didn't have any authentication or validation</b> -- the door was wide open to any client that wanted to stuff the ballot box.
<p>
Soon afterward, it was discovered that the Time.com Poll <b>didn't even range check its parameters</b> to ensure that the ratings fell within the 1 to 100 range
</p>
</blockquote>
<p>
The outcome of the 2009 Time 100 World's Most Influential People poll isn't <i>that</i> important in the big scheme of things, but it's difficult to understand why a high profile website would conduct an anonymous worldwide poll without even the most basic of safeguards in place. This isn't high security; this is web 101. Any programmer with even a rudimentary understanding of how the web works would have thought of these exploits immediately.
</p>
<p>
Without any safeguards, wannabe "hackers" set out to game the poll in every obvious way you can think of. Time eventually responded -- with all the skill and expertise of ... a team who put together the world's most insecure online poll.
</p>
<p>
</p>
<blockquote>
Shortly afterward, Time.com changed the protocol to attempt to authenticate votes by requiring a key be appended to the poll submission URL. The key consisted of an MD5 hash of the URL + a secret word (aka 'the salt'). [hackers eventually] discovered that the salt [..] was poorly hidden in Time.com's voting flash application. With the salt extracted, the autovoters were back online, rocking the vote.
</blockquote>
<p>
So-called secret poorly hidden on the client: check!
</p>
<p>
</p>
<blockquote>
Another challenge faced by the autovoters was that if you voted for the same person more often than once every 13 seconds, your IP would be banned from voting. However, it was noticed that you could cycle through votes for other candidates during those 13 seconds. The autovoters quickly adapted to take advantage of this loophole, interleaving up-votes for moot with down-votes for the competition -- ensuring that no candidate received a vote more frequently than once every 13 seconds, maximizing the voting leverage.
</blockquote>
<p>
Sloppy, incomplete IP throttling: check!
</p>
<p>
At this point, here's the mental image I had of the web developers running the show at time.com:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Remember my advice from <a href="http://www.codinghorror.com/blog/archives/001123.html">design for evil</a>?
</p>
<p>
</p>
<blockquote>
When good is dumb, evil will always triumph.
</blockquote>
<p>
Well, here's your proof. I'm not sure they come any dumber than these clowns.
</p>
<p>
The article goes on to document how the "hackers" exploited these truck sized holes in the time.com online voting system to not only put moot on top, but spell out a little message, too, for good measure:
</p>
<p>
</p>
<blockquote>
Looking at the first letters of each of the top 21 leading names in the poll we find the message "marblecake, also the game". The poll announces (perhaps subtly) to the world, that the most influential are not the Obamas, Britneys or the Rick Warrens of the world, the most influential are an extremely advanced intelligence: the hackers.
</blockquote>
<p>
It's a nice sentiment, I suppose. But <b>is it really a precision hack when your adversaries are incompetent?</b> If you want to read about a <i>real</i> hack -- one that took "extremely advanced intelligence" in the face of a nearly unstoppable adversary -- try <a href="http://www.codinghorror.com/blog/archives/001125.html">the black sunday hack</a>. Now <i>that's</i> a hack.
</p>
<p>
<font color="red">Update:</font> A <a href="http://musicmachinery.com/2009/04/27/moot-wins-time-inc-loses/">second article describing more Time poll hilarity</a>. Now with 100% more CAPTCHA!
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-not-to-conduct-an-online-poll/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Modest Proposal for the Copy and Paste School of Code Reuse ]]></title>
<link>https://blog.codinghorror.com/a-modest-proposal-for-the-copy-and-paste-school-of-code-reuse/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Is <b>copying and pasting code</b> dangerous? Should control-c and control-v be treated not as essential programming keyboard shortcuts, but registered weapons?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
(yes, I know that in OS X, the keyboard shortcut for cut and paste uses "crazy <a href="http://en.wikipedia.org/wiki/Love_Symbol">Prince symbol key</a>" instead of control, like God intended. Any cognitive dissonance you may be experiencing right now is also intentional.)
</p>
<p>
Here's my position on copy and paste for programmers:
</p>
<p>
</p>
<blockquote>
Copy and paste doesn't create bad code. Bad programmers create bad code.
</blockquote>
<p>
Or, if you prefer, guns don't kill people, <i>people</i> kill people. Just make sure that source code isn't pointed at me when it goes off. There are always risks. When you copy and paste code, vigilance is required to make sure you (or someone you work with) isn't falling into the trap of <a href="http://www.stevemcconnell.com/ieeesoftware/bp16.htm">copy and paste code duplication</a>:
</p>
<p>
</p>
<blockquote>
Undoubtedly the most popular reason for creating a routine is to avoid duplicate code. Similar code in two routines is a warning sign. <b>David Parnas says that if you use copy and paste while you're coding, you're probably committing a design error.</b> Instead of copying code, move it into its own routine. Future modifications will be easier because you will need to modify the code in only one location. The code will be more reliable because you will have only one place in which to be sure that the code is correct.
</blockquote>
<p>
Some programmers agree with Parnas, going so far as to <a href="http://www.secretgeek.net/copy_paste_dont_do_it.asp">advocate disabling cut and paste entirely</a>. I think that's rather extreme. I use copy and paste while programming all the time, but <b>never in a way that runs counter to <a href="http://www.codinghorror.com/blog/archives/000805.html">Curly's Law</a></b>.
</p>
<p>
But pervasive high-speed internet -- and a whole new generation of hyper-connected young programmers weaned on the web -- has changed the dynamics of programming. Copy and paste is no longer a pejorative term, but a simple observation about how a lot of modern coding gets done, like it or not. This new dynamic was codified into law as <a href="http://www.secretgeek.net/open_code_sharing.asp">Bambrick's 8th Rule of Code Reuse</a>:
</p>
<p>
</p>
<blockquote>
It's far easier and much less trouble to find and use a bug-ridden, poorly implemented snippet of code written by a 13 year old blogger on the other side of the world than it is to find and use the equivalent piece of code written by your team leader on the other side of a cubicle partition.
<p>
(And I think that <a href="http://secretgeek.net/howtobeaprogrammer.asp">the copy and paste school of code reuse</a> is flourishing, and will always flourish, even though it gives very suboptimal results.)
</p>
</blockquote>
<p>
<a href="http://www.secretgeek.net/open_code_sharing.asp">Per Mr. Bambrick</a>, copy and pasted code from the internet is <b>good</b> because:
</p>
<p>
</p>
<ul>
<li>Code stored on blogs, forums, and the web in general is very easy to find.
</li>
<li>You can inspect the code before you use it.
</li>
<li>Comments on blogs give some small level of feedback that might improve quality.
</li>
<li>Pagerank means that you're more likely to find code that might be higher quality.
</li>
<li>Code that is easy to read and understand will be copied and pasted more, leading to a sort of viral reproductive dominance.
</li>
<li>The programmer's ego may drive her to only publish code that she believes is of sufficient quality.
</li>
</ul>
<p>
But copy and pasted code from the internet is <b>bad</b> because:
</p>
<p>
</p>
<ul>
<li>If the author improves the code, you're not likely to get those benefits.
</li>
<li>If you improve the code, you're not likely to pass those improvements back to the author.
</li>
<li>Code may be blindly copied and pasted without understanding what the code actually does.
</li>
<li>Pagerank doesn't address the quality of the code, or its fitness for your purpose.
</li>
<li>Code is often 'demo code' and may purposely gloss over important concerns like error handling, sql injection, encoding, security, etc.
</li>
</ul>
<p>
Now, if you're copying entire projects or groups of files, you should be inheriting that code from a project that's already under proper source control. That's just basic software engineering (we hope). But the type of code I'm likely to cut and paste <i>isn't</i> entire projects or files.  It's probably a <b>code snippet</b> -- an algorithm, a routine, a page of code, or perhaps a handful of functions. There are several established code snippet sharing services:
</p>
<p>
</p>
<ul>
<li>
<a href="http://snippets.dzone.com/">DZone Snippets</a>
</li>
<li>
<a href="http://snipplr.com/">Snipplr</a>
</li>
<li>
<a href="http://refactormycode.com/">Refactor My Code</a>
</li>
<li>
<a href="http://www.codeproject.com/">CodeProject</a>
</li>
</ul>
<p>
Source control is great, but it's massive overkill for, say, <a href="http://snipplr.com/view/12252/animate-a-fadeout-of-a-nswindow-with-objectivec/">this little Objective-C animation snippet</a>:
</p>
<p>
</p>
<pre>
- (void)fadeOutWindow:(NSWindow*)window{
float alpha = 1.0;
[window setAlphaValue:alpha];
[window makeKeyAndOrderFront:self];
for (int x = 0; x &lt; 10; x++) {
alpha -= 0.1;
[window setAlphaValue:alpha];
[NSThread sleepForTimeInterval:0.020];
}
}
</pre>
<p>
To me, the most troubling limitation of <a href="http://everything2.com/title/copypasta">copypasta programming</a> is the complete disconnect between the code you've pasted and all the other viral copies of it on the web. It's impossible to locate new versions of the snippet, or fold your features and bugfixes back into the original snippet. Nor can you possibly hope to find all the other nooks and crannies of code all over the world this snippet has crept into.
</p>
<p>
What I propose is this:
</p>
<p>
</p>
<pre>
<font color="red">// codesnippet:1c125546-b87c-49ff-8130-a24a3deda659</font>
- (void)fadeOutWindow:(NSWindow*)window{
// code
}
}
</pre>
<p>
Attach <b>a one line comment convention</b> with <a href="http://createguid.com/">a new GUID</a> to any code snippet you publish on the web. This ties the snippet of code to its author and any subsequent clones. A trivial search for the code snippet GUID would identify every other copy of the snippet on the web:
</p>
<p>
</p>
<pre>
http://www.google.com/search?q=<font color="red">1c125546-b87c-49ff-8130-a24a3deda659</font>
</pre>
<p>
I realize that what I'm proposing, as simple as it is, might still be an onerous requirement for copy-paste programmers. They're too busy copying and pasting to bother with silly conventions! Instead, imagine the centralized code snippet sharing services <b>automatically applying a snippet GUID comment to every snippet they share</b>. If they did, this convention could get real traction virtually overnight. And why not? We're just following the fine software engineering tradition of <a href="http://www.globalnerdy.com/2007/06/01/do-the-stupidest-thing-that-could-possibly-work/">doing the stupidest thing that could possibly work</a>.
</p>
<p>
No, it isn't a perfect system, by any means. For one thing, variants and improvements of the code would probably need their own snippet GUID, ideally by adding a second line to indicate the parent snippet they were derived from. And what do you do when you combine snippets with your own code, or merge snippets together? But let's not over think it, either. This is a simple, easily implementable improvement over what we have now: utter copy-and-paste code chaos.
</p>
<p>
Sometimes, <b>small code requires small solutions</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-modest-proposal-for-the-copy-and-paste-school-of-code-reuse/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Has The Virtualization Future Arrived? ]]></title>
<link>https://blog.codinghorror.com/has-the-virtualization-future-arrived/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
On the eve of the Windows 7 <a href="http://community.winsupersite.com/blogs/paul/archive/2009/04/26/windows-7-release-candidate-availability.aspx">release candidate</a>, Microsoft announced that Windows 7 will include a <a href="http://community.winsupersite.com/blogs/paul/archive/2009/04/24/secret-no-more-revealing-virtual-windows-xp-for-windows-7.aspx">fully licensed, virtualized copy of Windows XP</a>:
</p>
<p>
</p>
<blockquote>
XP Mode consists of the Virtual PC-based virtual environment and a fully licensed copy of Windows XP. It will be made available, for free, to users of Windows 7 Professional, Enterprise, and Ultimate editions via a download from the Microsoft web site. XP Mode works much like today's Virtual PC products, but with one important exception: it does not require you to run the virtual environment as a separate Windows desktop. Instead, as you install applications inside the virtual XP environment, they are published to the host OS, with shortcuts placed in the Start Menu. Users can run Windows XP-based applications alongside Windows 7 applications under a single desktop.
</blockquote>
<p>
I've been talking about <a href="http://www.codinghorror.com/blog/archives/000491.html">our virtual machine future</a> for years. Shipping a fully licensed, virtualized XP along with <a href="http://www.penny-arcade.com/comic/2007/02/02/">some editions</a> of Windows 7 has <i>huge</i> implications for backwards compatibility in the Windows world.
</p>
<p>
For one thing, <a href="http://www.codinghorror.com/blog/archives/000646.html">Windows XP is ancient</a>. While XP may have been the apple of 2001's eye, in computing dog years, it's basically.. <i>dead</i>. The original system requirements for Windows XP are almost comically low:
</p>
<p>
</p>
<ul>
<li>233 MHz processor
</li>
<li>64 MB of RAM (128 MB recommended)
</li>
<li>Super VGA (800 x 600) display
</li>
<li>CD-ROM or DVD drive
</li>
<li>Keyboard and mouse
</li>
</ul>
<p>
It doesn't take much to virtualize an OS as old as Windows XP today. I was able to cram <a href="http://www.codinghorror.com/blog/archives/000639.html">a full Windows XP image into 641 MB of disk space</a>, and depending on what sort of apps you're running, 256 MB of memory is often plenty.
</p>
<p>
The attraction of virtualizing older operating systems is that it <b>throws off the eternal yoke of backwards compatibility</b>. Instead of bending over backwards to make sure you never break any old APIs, you can build new systems free of the contortions and compromises inherent in guaranteeing that new versions of the operating system <i>never</i> break old applications.
</p>
<p>
Modern virtualization solutions can make <b>running applications in a virtual machine almost seamless</b>, as in the <a href="http://www.parallels.com/products/coherence/">coherence mode of Parallels</a>, or the <a href="http://www.vmware.com/products/fusion/features.html">unity mode of VMWare</a>. Here's a shot of Internet Explorer 7 running under OS X, for example.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
From the user's perspective, it's just another application in a window on their desktop. They don't need to know or care if the application is running in a virtual machine. Substitute Windows 7 for OS X, and you get the idea. Same principle. Virtualization delivers nearly perfect backwards compatibility, because you <i>are</i> running a complete copy of the old operating system alongside the new one.
</p>
<p>
While the <a href="http://www.winsupersite.com/win7/xp_mode_pre_shots.asp">screenshot gallery</a> makes it clear to me that this feature of Windows 7 is not nearly as seamless as I'd like it to be, it's a small but important step forward. <b>The demand for perfect backwards compatibility has held the industry back for too long</b>, and having an officially blessed virtualization solution available in a major operating system release (albeit as a downloadable extra, and only in certain editions) opens the door for innovation. It frees software developers from the crushing weight of their own historical software mistakes.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/has-the-virtualization-future-arrived/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Optimizing Your Wallet ]]></title>
<link>https://blog.codinghorror.com/optimizing-your-wallet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>If we geeks obsessively optimize <a href="http://www.codinghorror.com/blog/2010/08/whats-on-your-utility-belt.html">what's on our keychain</a>, we'd be remiss if we didn't also obsessively optimize that <em>other</em> item most geeks carry around – our <strong>wallet</strong>.</p>
<p>My current Tumi wallet was almost 10 years old and starting to show its age. While I never had an enormous <a href="http://www.seinology.com/scripts/script-168.shtml">Constanza Wallet</a>, I felt I could do better.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/yoPf98i8A0g" frameborder="0" allowfullscreen></iframe>
<p>I was in the market for a new wallet, but I wanted something… <em>less</em>. In search of an alternative, a coworker turned me on to the <a href="http://www.amazon.com/dp/B000E1GRIO/?tag=codihorr-20">superthin All-Ett wallet</a>.</p>
<p><a href="http://www.amazon.com/dp/B000E1GRIO/?tag=codihorr-20"><img alt="image placeholder" >
</a></p>
<p>After seeing the All-Ett, I was sold. I ordered one. As promised, <strong>the fully populated All-ett was thinner – much thinner! – than my old wallet was <em>empty</em>.</strong> Amazing! It's so much more comfortable to sit down with this in my back pocket. I no longer feel motivated to remove my wallet from my back pocket when I sit down. That's important. I don't know about you guys, but I tend to lose my wallet when I leave it lying around various places. Not good.</p>
<p>I only have two minor criticisms:</p>
<ul>
<li>
<p>The ultra-thin spinnaker sailcloth they use is a tiny bit "crackly" in use. It's not a problem in practical use, you can't hear yourself sit down, but it is a little disconcerting at first.</p>
</li>
<li>
<p>The orientation of the pockets means the contents tend to fall towards the middle when you open it. It's a little more fiddly than a typical wallet when opening it and fishing items out of it. But given that I tend to open my wallet maybe 3-4 times per day, at most, that's a tradeoff I'm willing to make.</p>
</li>
</ul>
<p>Minus those minor criticisms, I'm very happy with it. Or at least I <em>was</em>, until I discovered the <a href="http://www.amazon.com/gp/redirect.html?ie=UTF8&amp;location=http%3A%2F%2Fwww.amazon.com%2Fs%3Fie%3DUTF8%26x%3D0%26ref%255F%3Dnb%255Fss%255Fgw%26y%3D0%26field-keywords%3DDynomighty%2520mighty%2520wallet%26url%3Dsearch-alias%253Daps&amp;tag=codihorr-20&amp;linkCode=ur2&amp;camp=1789&amp;creative=390957">Tyvek Mighty Wallets</a> – which even come in a glorious <b>fake dot matrix printout style!</b> Be still, my beating geek heart! Since the sailcloth of the all-ett proved a bit problematic, I'm thinking the Tyvek might be a better choice, and placing my new wallet order. Plus: digits of π! On a dot matrix print-out! Come on, man!</p>
<p><span style="color:red">Update</span>: I'm happy to report that I used my Mighty Wallet for years, and just decided to replace it in April 2013 (and again in June 2017) as it was finally getting a bit beat up. Since then, there's been an explosion of <a href="http://www.amazon.com/gp/redirect.html?ie=UTF8&amp;location=http%3A%2F%2Fwww.amazon.com%2Fs%3Fie%3DUTF8%26x%3D0%26ref%255F%3Dnb%255Fss%255Fgw%26y%3D0%26field-keywords%3DDynomighty%2520mighty%2520wallet%26url%3Dsearch-alias%253Daps&amp;tag=codihorr-20&amp;linkCode=ur2&amp;camp=1789&amp;creative=390957">amazing Mighty Wallet styles</a>. I liked my old dot matrix model so much I bought three new ones!</p>
<table>
<tr>
<td>
<a href="http://www.amazon.com/dp/B004WQ7WCM/?tag=codihorr-20"><img alt="image placeholder" >
</td>
<td>
<a href="http://www.amazon.com/dp/B00GEIHTCE/?tag=codihorr-20"><img alt="image placeholder" >
</td>
</tr>
<tr>
<td><a href="http://www.amazon.com/dp/B002T041EU/?tag=codihorr-20"><img alt="image placeholder" >
<td>
<a href="http://www.amazon.com/dp/B001KJE9DY/?tag=codihorr-20">
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>But there are other popular geek wallets, too, that I've either had directly recommended to me or seen people use:</p>
<ul>
<li>
<p><a href="http://www.thejimi.com/">Jimi Wallet</a></p>
</li>
<li>
<p>The <a href="http://www.amazon.com/dp/B004ZJACFA/?tag=codihorr-20">Umbra Bungee Card Case</a></p>
</li>
<li>
<p>The even smaller <a href="http://www.amazon.com/dp/B01LBT5PJY/?tag=codihorr-20">Junior All-Ett</a> (with only two pockets instead of four)</p>
</li>
<li>
<p><a href="http://www.amazon.com/dp/B006LQLSFS/?tag=codihorr-20">The Thin Super Skinny Wallet</a></p>
</li>
<li>
<p><a href="http://www.amazon.com/dp/B00013D2NI/?tag=codihorr-20">Slimmy: The Slim Front Pocket Wallet Alternative</a></p>
</li>
</ul>
<p>Those are the ones I see recommended most, but there are plenty of alternatives discussed in similar posts on <a href="http://www.43folders.com/2006/04/21/minimalist-wallet">43folders</a> and <a href="http://www.37signals.com/svn/archives2/wallet_roundup.php">37signals</a>.</p>
<p>On a related note, I've always wished I could carry a pen, but I've never found one small and convenient enough to <a href="https://blog.codinghorror.com/updating-your-utility-belt/">add to my existing keychain</a>. There's quite a bit of stuff on there already: a LED flashlight, a Leatherman Squirt, and of course my keys. I'm not sure if I want to add a pen to that list. But there's another way: <strong>I can carry a pen in my wallet!</strong> I found two wallet pens that could work.</p>
<p>The <a href="http://www.derringerpen.com/">Derringer Wallet Pen</a> is only $8. Unfortunately, it was slightly too large for my old wallet at 4" long. So I had to give it away.</p>
<p><a href="http://www.derringerpen.com/"><img alt="image placeholder" >
</a></p>
<p>The <a href="http://www.amazon.com/dp/B01N6BA10P/?tag=codihorr-20">wallet pen</a> is quite a bit more expensive at <s>$40</s> $70. But it's made of sterling silver, and most importantly, it's only 3" and even thinner. So it's even more portable.</p>
<p><a href="http://www.styluscentral.com/walletpen.html"><img alt="image placeholder" >
</a></p>
<p>The wallet pen, as small as it is, fits perfectly in the "crease" of a typical wallet. It does bulge up a tiny bit in the super thin All-ett (and we'll see how it does in the Tyvek wallet), but it still works.</p>
<p>Why not <strong>optimize your wallet</strong>? You could end up carrying something that's more comfortable, way thinner, and maybe even have something around to write with, too!</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-04-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/optimizing-your-wallet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I Just Logged In As You ]]></title>
<link>https://blog.codinghorror.com/i-just-logged-in-as-you/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I received this anonymous email a few days ago:
</p>
<p>
</p>
<blockquote>
I found what one could call a security hole in Stackoverflow.  I'm curious enough to go digging around for holes, but too ethical to actually do anything with them.  However, I'm afraid that by pointing it out I'll get banned, because a good member doesn't poke around like I just did.  I promise I did nothing with what I found out besides confirm the hole.
<p>
You may be wondering why I'm e-mailing you personally, rather than team@stackoverflow.com.  It'll make sense when I reveal the hole, which is...
</p>
<p>
I logged in as you.
</p>
<p>
How?  Well, there were two pieces of the puzzle, the password and the openid provider.  I had a possible password; today your blog post revealed the openid provider.  I logged in, freaked out that it <i>actually worked</i>, then logged out.  The only reason I had the password is because your password is totally inadequate for someone running a site like StackOverflow.  I don't want to go into any more detail than that, but man - dictionary password!
</p>
<p>
I've read about the secret "hacker" badge...  if you're not going to punish me for my transgression, then I will reveal who I am and I sure wouldn't mind getting it.  Still, I can understand if you're upset - I wouldn't want someone else digging up my password.  (That's why I send this friendly e-mail instead of hoarding, or worst, selling, the information.)
</p>
<p>
Please, go change your openid password, before someone less ethical than I finds it.
</p>
<p>
- A friend of the site
</p>
</blockquote>
<p>
These are the kinds of emails that make your blood run cold. Good thing I haven't made too many enemies. Today, I mean. So far. The day's not over, yet.
</p>
<p>
Is it true? Did someone just log in as me? I checked the OpenID logs, and sure enough, <b>there was a valid login from an IP address I didn't recognize</b>. He wasn't bluffing. <i>He really did log in as me.</i>
</p>
<p>
While it's true I probably should have used a more secure password, in my defense:
</p>
<p>
</p>
<ol>
<li>The particular OpenID account I use is typically for low-value logins like blog comments and so forth. It's not exactly a high security form of identity for the use I have in mind.*
</li>
<li>The password <i>was</i> relatively simple, but I wouldn't go so far as to characterize it as a "dictionary password" -- it wasn't quite "password1" or "monkey" or "happiness", or anything like that. It was weak, yes, but <a href="http://www.codinghorror.com/blog/archives/001206.html">dictionary password attacks</a>, like all brute force attacks, <a href="http://www.codinghorror.com/blog/archives/000986.html">are still for dummies</a>.
</li>
</ol>
<p>
What's interesting about this, though, is <b>how it happened</b>. I'll reveal that tomorrow, with this one hint: I've talked about this exact sort of vulnerability several times on this very blog.
</p>
<p>
Until then, take your best guess: <b>how do you think this person discovered my password?</b> I'll highlight the best response tomorrow with the answer.
</p>
<p>
* Although as a Stack Overflow moderator I have unusual powers and <a href="http://www.codinghorror.com/blog/archives/001206.html">probably should have</a> used an alternate OpenID with more security.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/i-just-logged-in-as-you/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I Just Logged In As You: How It Happened ]]></title>
<link>https://blog.codinghorror.com/i-just-logged-in-as-you-how-it-happened/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In my previous post <a href="http://www.codinghorror.com/blog/archives/001262.html">I Just Logged In As You</a>, I disclosed that someone was logging in as me -- specifically because they <b>discovered my password</b>. But how?
</p>
<p>
If I wanted to discover someone's password, I can think of a few ways:
</p>
<p>
</p>
<ol>
<li>
<b>Educated guess.</b> If you know someone's birthday, their pets, their children's names, favorite movies, and so on  -- these are all potential passwords in various forms. This is classic social engineering, and it can work; that's essentially <a href="http://www.wired.com/threatlevel/2008/09/palin-e-mail-ha/">how Sarah Palin's email was hacked</a>. While my password <i>was</i> weak, it wasn't anything you could reasonably guess based on public information available about me.
<br><br>
</li>
<li>
<b>Brute force dictionary attack.</b> If login attempts aren't meaningfully <a href="http://www.codinghorror.com/blog/archives/001228.html">rate limited</a>, then you can attempt a dictionary attack and pray the target password is a simple dictionary word. That's how <a href="http://www.wired.com/threatlevel/2009/01/professed-twitt/">one Twitter administrator's account was compromised</a>. But failing to rate limit password attempts is strictly amateur hour stuff (and I'd argue borderline incompetence); no OpenID provider of any consequence would make this mistake.
<br><br>
</li>
<li>
<b>Interception.</b> Eavesdrop on the user in any way you can to discover their password: install a hardware keylogger, software keylogger, or perform network sniffing of unencrypted traffic. If you have physical access to the user, low-tech analog methods such as watching over someone's shoulder as they type in their password are effectively the same thing. While I can't <i>rule out</i> paranoid fantasies of keyloggers, if my machine was so thoroughly <a href="http://dir.salon.com/story/tech/feature/2002/08/28/0wnz0red/index.html">0wnz0red</a>, I think my OpenID password would have been the least of my worries at that point.
<br><br>
</li>
<li>
<b>Impersonation.</b> Commonly known as phishing. You present the user with a plausible looking login page for a service they already use, and hope they enter their credentials. Alternately, in the depressingly common Web 2.0 style, you can just <a href="http://www.codinghorror.com/blog/archives/001128.html">demand that users give up their credentials</a> for some trivial integration feature with the target website. I consider both forms of phishing, and I call it <a href="http://www.codinghorror.com/blog/archives/000852.html">the forever hack</a> for good reason.
</li>
</ol>
<p>
So which of these methods did this person use to obtain my password? <b>None of them</b>.
</p>
<p>
</p>
<blockquote>
It wasn't a guess and it wasn't brute force.
<p>
I guess I can tell you, so you don't fall into this trap again.  <b>There's a site I help out with that doesn't salt their passwords.</b> They're MD5 encrypted, but if you've got a dictionary password, it's very easy to use a reverse-MD5 site to get the original.  I was able to figure out you were a user on the site some time back, and realized I could do this, if only I knew your openid provider...
</p>
<p>
(As an aside, I complained to the head of the site months ago that he ought to start salting passwords for this exact reason.  I also run my passwords I need to be secure through a few reverse-hash websites, just to ensure that it's not stored somewhere.)
</p>
<p>
So, the unethical part was actually looking up this information in the first place.  I apologize. But like I said, better than someone else getting into this data.
</p>
</blockquote>
<p>
Hey, it looks like <b><a href="http://www.codinghorror.com/blog/archives/000953.html">you're storing passwords incorrectly!</a></b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
We have met the enemy, and he is.. programmers just like us. Seriously, go <a href="http://www.codinghorror.com/blog/archives/000953.html">read that blog entry</a>. It is exactly, <i>exactly</i> what just happened to me.
</p>
<p>
When I say programmers like us, I mean me, too. I acknowledge that I am also at fault here, for...
</p>
<p>
</p>
<ul>
<li>using the same low-value credential password in two places.
</li>
<li>picking a particularly weak password.
</li>
<li>not using a high-value credential for something that clearly deserved it, namely, my moderator login to Stack Overflow.
</li>
</ul>
<p>
All of this is true, and I shoulder the blame for that. Perhaps I should <a href="http://www.codinghorror.com/blog/archives/000360.html">take my own advice</a>. A moment of weakness, I suppose.
</p>
<p>
The important thing to take away from this, if you're a programmer working on an application that stores user credentials, is to <b><i>get the hell out of the business of storing user credentials!</i></b> As we've seen today, the world is full of stupid users like me who do incredibly stupid things. Are you equipped and willing do everything necessary to protect idiots like me from myself? That's a key part of the promise of OpenID, and one of the reasons we chose it as the authentication system for Stack Overflow. As one commenter <a href="http://www.reddit.com/r/programming/comments/8hpog/i_just_logged_in_as_you/c09bq23">noted</a> on Reddit:
</p>
<p>
</p>
<blockquote>
I, for one, think that my OpenID provider is more secure than the average guy running a forum.
</blockquote>
<p>
Exactly. We outsourced our user credential system to people who are much better at it than us (well, depending on which OpenID provider you pick). And also because <a href="http://www.codinghorror.com/blog/archives/001121.html">we didn't think the world needed yet another username and password</a>. You're welcome. I think.
</p>
<p>
So, what have we learned?
</p>
<p>
</p>
<ol>
<li>Programmers are the enemy.
</li>
<li>Hey .. wait a second, <i>I'm</i> a programmer!
</li>
<li>
<code>GOTO 1</code>
</li>
</ol>
<p>
(Oh, and credit to <a href="http://joose-js.blogspot.com/">Malte</a>, the first commenter to correctly identify what the likely password vulnerability was -- less than an hour after the entry was posted!)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/i-just-logged-in-as-you-how-it-happened/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Pseudocode or Code? ]]></title>
<link>https://blog.codinghorror.com/pseudocode-or-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although I'm a huge fan of <a href="http://www.amazon.com/exec/obidos/ASIN/0735619670/codihorr-20">Code Complete</a> -- it is my <a href="http://www.codinghorror.com/blog/archives/000020.html">single most recommended programming book</a> for good reason -- there are chapters in it that I haven't been able to digest, even after 16 years.
</p>
<p>
One of those chapters describes something called the <b>Pseudocode Programming Process</b>. And on paper, at least, it sounds quite sensible. Before writing a routine, you describe what that routine should do in plain English. So if we we set out to write an error handling lookup routine, we'd first write it in <b>pseudocode</b>:
</p>
<p>
</p>
<pre>
set the default status to "fail"
look up the message based on the error code
if the error code is valid
if doing interactive processing, display the error message
interactively and declare success
if doing command line processing, log the error message to the
command line and declare success
if the error code isn't valid, notify the user that an
internal error has been detected
return status information
</pre>
<p>
Then, when you're satisfied that you understand what the routine should do, you turn that pseudocode into comments that describe the code you're about to write.
</p>
<p>
</p>
<pre>
<b>// set the default status to "fail"</b>
Status errorMessageStatus = Status_Failure;
<b>// look up the message based on the error code</b>
Message errorMessage = LookupErrorMessage( errorToReport );
<b>// if the error code is valid</b>
if ( errorMessage.ValidCode() ) {
<b>// determine the processing method</b>
ProcessingMethod errorProcessingMethod = CurrentProcessingMethod();
<b>// if doing interactive processing, display the error message</b>
<b>// interactively and declare success</b>
if ( errorProcessingMethod == ProcessingMethod_Interactive ) {
DisplayInteractiveMessage( errorMessage.Text() );
errorMessageStatus = Status_Success;
}
</pre>
<p>
Pseudocode is sort of like the <a href="http://en.wikipedia.org/wiki/Tang_(drink)%22">Tang</a> of programming languages -- you hydrate the code around it.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But why pseudocode? Steve offers some rationales:
</p>
<p>
</p>
<ul>
<li>
<b>Pseudocode makes reviews easier</b>. You can review detailed designs without examining source code. Pseudocode makes low-level design reviews easier and reduces the need to review the code itself.
</li>
<li>
<b>Pseudocode supports the idea of iterative refinement</b>. You start with a high-level design, refine the design to pseudocode, and then refine the pseudocode to source code. This successive refinement in small steps allows you to check your design as you drive it to lower levels of detail. The result is that you catch highlevel errors at the highest level, mid-level errors at the middle level, and low-level errors at the lowest level -- before any of them becomes a problem or contaminates work at more detailed levels.
</li>
<li>
<b>Pseudocode makes changes easier</b>. A few lines of pseudocode are easier to change than a page of code. Would you rather change a line on a blueprint or rip out a wall and nail in the two-by-fours somewhere else? The effects aren't as physically dramatic in software, but the principle of changing the product when it's most malleable is the same. One of the keys to the success of a project is to catch errors at the "least-value stage," the stage at which the least effort has been invested. Much less has been invested at the pseudocode stage than after full coding, testing, and debugging, so it makes economic sense to catch the errors early.
</li>
<li>
<b>Pseudocode minimizes commenting effort</b>. In the typical coding scenario, you write the code and add comments afterward. In the PPP, the pseudocode statements become the comments, so it actually takes more work to remove the comments than to leave them in.
</li>
<li>
<b>Pseudocode is easier to maintain than other forms of design documentation</b>. With other approaches, design is separated from the code, and when one changes, the two fall out of agreement. With the PPP, the pseudocode statements become comments in the code. As long as the inline comments are maintained, the pseudocode's documentation of the design will be accurate.
</li>
</ul>
<p>
All compelling arguments. As an acolyte of McConnell, it pains me to admit this, but every time I've tried the Pseudocode Programming Process, I almost immediately abandon it as impractical.
</p>
<p>
Why? Two reasons:
</p>
<p>
</p>
<ol>
<li>
<b>code &gt; pseudocode</b>. I find it easier to think about code <i>in code</i>. While I'm all for describing the overall general purpose of the routine before you write it in plain English -- this helps name it, which is <a href="http://www.codinghorror.com/blog/archives/000553.html">incredibly difficult</a> -- extending that inside the routine doesn't work well for me. There's something fundamentally.. unrealistic.. about attempting to using precise English to describe the nuts and bolts of code.
</li>
<li>
<b>Starting with the goal of adding comments to your code seems backwards</b>. I prefer <a href="http://www.codinghorror.com/blog/archives/001150.html">coding without comments</a>, in that I want the code to be as self-explanatory as humanly possible. Don't get me wrong; comments do occur regularly in my code, but only because the code could not be made any clearer without them. Comments should be a method of last resort, not something you start with.
</li>
</ol>
<p>
Of course, PPP is just one proposed way to code, not the perfect or ideal way. McConnell has no illusions about this, and acknowledges that refactoring, TDD, design by contract, and even plain old "hacking" are valid and alternative ways to construct code.
</p>
<p>
But still -- I have a hard time seeing pseudocode as useful in anything other than possibly job interviews. And even then, I'd prefer to sit down in front of a computer and write real code to solve whatever problem is being posed. What's your take? Is pseudocode a useful tool in your programming? <b>Do you write pseudocode before writing code?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/pseudocode-or-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Web Browser Address Bar is the New Command Line ]]></title>
<link>https://blog.codinghorror.com/the-web-browser-address-bar-is-the-new-command-line/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Google's <a href="http://www.codinghorror.com/blog/archives/001238.html">Chrome browser</a> passes anything you type into the address bar that isn't an obvious URI on to the default search engine.</p>
<p><img alt="image placeholder" >
<p>While web browsers should have some built-in smarts, they can never match the collective intelligence of a worldwide search engine. <a href="http://www.google.com/help/features.html">For example</a>:</p>
<blockquote>
<a href="http://www.google.com/search?q=weather+San+Francisco">weather San Francisco</a><br> <a href="http://www.google.com/search?q=CSCO">CSCO</a><br> <a href="http://www.google.com/search?q=time+London">time London</a><br> <a href="http://www.google.com/search?q=san+francisco+49ers">san francisco 49ers</a><br> <a href="http://www.google.com/search?q=5*9%2B(sqrt+10)%5E3%3D">5*9+(sqrt 10)^3=</a><br> <a href="http://www.google.com/search?q=Henry+Wadsworth+Longfellow">Henry+Wadsworth+Longfellow</a><br> <a href="http://www.google.com/search?q=earthquake">earthquake</a><br> <a href="http://www.google.com/search?q=10.5+cm+in+inches">10.5 cm in inches</a><br> <a href="http://www.google.com/search?q=population+FL">population FL</a><br> <a href="http://www.google.com/search?q=Italian+food+02138">Italian food 02138</a><br> <a href="http://www.google.com/search?q=movies+94705">movies 94705</a><br> <a href="http://www.google.com/search?q=homes+Los+Angeles">homes Los Angeles</a><br> <a href="http://www.google.com/search?q=150+GBP+in+USD">150 GBP in USD</a><br> <a href="http://www.google.com/search?q=Seattle+map">Seattle map</a><br> <a href="http://www.google.com/search?q=Patent+5123123">Patent 5123123</a><br> <a href="http://www.google.com/search?q=650">650</a><br> <a href="http://www.google.com/search?q=american+airlines+18">american airlines 18</a><br> <a href="http://www.google.com/search?q=036000250015">036000250015</a><br> <a href="http://www.google.com/search?q=JH4NA1157MT001832">JH4NA1157MT001832</a><br> 510-525-xxxx <small>(I'm hesitant to <a href="http://en.wikipedia.org/wiki/867-5309/Jenny#Popularity_and_litigation">link</a> a listed personal phone number here, but it does work)</small>
</blockquote>
<p>I like to think of the <strong>web browser address bar as the new command line</strong>.</p>
<p>Oh, you wanted dozens of cryptic, obscure UNIX style command line <a href="http://www.google.com/help/cheatsheet.html">operators</a> and parameters? <a href="http://www.codinghorror.com/blog/archives/000296.html">No problem</a>!</p>
<blockquote>
<a href="http://www.google.com/search?q=define%3Adefenestrate">define:defenestrate</a><br> <a href="http://www.google.com/search?q=presidents+1850...1860">presidents 1850...1860</a><br> <a href="http://www.google.com/search?q=%22plants+vs.+zombies%22+daterange%3A2454955-2454955">"plants vs. zombies" daterange:2454955-2454955</a><br> <a href="http://www.google.com/search?q=link%3Aexperts-exchange.com+sucks">link:experts-exchange.com sucks</a><br> <a href="http://www.google.com/search?q=+filetype%3Apdf+programming+language+poster">filetype:pdf programming language poster</a><br> <a href="http://www.google.com/search?q=allintitle%3Anigerian+site%3Awww.snopes.com">allintitle:nigerian site:www.snopes.com</a>
</blockquote>
<p>Any command line worth its salt has some kind of scripting language built in, too, right? No sweat. Just try entering this in your browser's address bar.</p>
<pre>javascript:alert('Hello, world!')
</pre>
<p>The sky's the limit from there; whatever JavaScript you can fit in the address bar is fair game. These are more commonly known as <a href="http://www.google.com/search?q=bookmarklets">"bookmarklets"</a>.</p>
<p>Apparently we've spent the last 20 years <a href="http://www.codinghorror.com/blog/archives/000840.html">reimplementing the UNIX command line in the browser</a>. Services like <a href="http://yubnub.org/">yubnub</a> make this process even more social, with collaborative group creation (and ranking!) of new commands. You can find some of the cooler ones on the <a href="http://yubnub.org/kernel/golden_eggs?args=">golden eggs page</a>.</p>
<blockquote>
<a href="http://yubnub.org/parser/parse?command=gimf+%22carrot%20top%22">gimf "carrot top"</a><br> <a href="http://yubnub.org/parser/parse?command=esv+Ezekiel+25:17">esv Ezekiel 25:17</a><br> <a href="http://yubnub.org/parser/parse?command=2g+color+colour">2g color colour</a>
</blockquote>
<p>Honestly, I was never a big command-line enthusiast; even way back when on my Amiga I'd choose the GUI over the CLI whenever I could. But maybe I bet on the wrong horse. Perhaps the command prompt – or more specifically, the <strong>search oriented, crowdsourced, world public command prompt</strong> – really <a href="http://www.codinghorror.com/blog/archives/000595.html">is the future</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-web-browser-address-bar-is-the-new-command-line/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Do Computers Suck at Math? ]]></title>
<link>https://blog.codinghorror.com/why-do-computers-suck-at-math/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
You've probably seen <a href="http://www.google.com/search?&amp;q=399999999999999-399999999999998">this old chestnut</a> by now.
</p>
<p>
<a href="http://www.google.com/search?&amp;q=399999999999999-399999999999998"><img alt="image placeholder" >
</p>
<p>
Insert your own joke here. Google can't be wrong -- <i>math is!</i> But Google is hardly alone; this is just another example in a long and storied history of obscure little computer math errors that go <i>way</i> back, such as <a href="http://support.microsoft.com/kb/72540">this bug report from Windows 3.0</a>.
</p>
<p>
</p>
<ol>
<li>Start Calculator.
</li>
<li>Input the largest number to subtract first (for example, 12.52).
</li>
<li>Press the MINUS SIGN (-) key on the numeric keypad.
</li>
<li>Input the smaller number that is one unit lower in the decimal portion (for example, 12.51).
</li>
<li>Press the EQUAL SIGN (=) key on the numeric keypad.
</li>
</ol>
<p>
On my virtual machine, 12.52 - 12.51 on Ye Olde Windows Calculator indeed results in 0.00.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
And then there was the <a href="http://www.lawtechguru.com/archives/2007/09/25_excel_2007_multiplication_math_bug.html">famous Excel bug</a>.
</p>
<p>
</p>
<blockquote>
If you have Excel 2007 installed, try this: Multiply 850 by 77.1 in Excel.
<p>
One way to do this is to type "=850*77.1" (without the quotes) into a cell. The correct answer is 65,535. However, Excel 2007 displays a result of 100,000.
</p>
</blockquote>
<p>
At this point, you might be a little perplexed, as <b>computers are supposed to be pretty good at this math stuff</b>. What gives? How is it possible to produce such blatantly incorrect results from seemingly trivial calculations? Should we even be trusting our computers to do math at all?
</p>
<p>
Well, numbers are <a href="http://www.johndcook.com/blog/2009/04/06/numbers-are-a-leaky-abstraction/">harder to represent on computers than you might think</a>:
</p>
<p>
</p>
<blockquote>
A standard floating point number has roughly 16 decimal places of precision and a maximum value on the order of 10<sup>308</sup>, a 1 followed by 308 zeros. (According to <a href="http://en.wikipedia.org/wiki/IEEE_754">IEEE standard 754</a>, the typical floating point implementation.)
<p>
Sixteen decimal places is a lot. Hardly any measured quantity is known to anywhere near that much precision. For example, the constant in Newton's Law of Gravity is only known to four significant figures. The charge of an electron is known to 11 significant figures, much more precision than Newton's gravitational constant, but still less than a floating point number. So <b>when are 16 figures not enough?</b> One problem area is subtraction. The other elementary operations -- addition, multiplication, division -- are very accurate. As long as you don't overflow or underflow,  these operations often produce results that are correct to the last bit. But subtraction can be anywhere from exact to completely inaccurate.  If two numbers agree to n figures, you can lose up to n figures of precision in their subtraction. This problem can show up unexpectedly in the middle of other calculations.
</p>
</blockquote>
<p>
Number precision is a funny thing; did you know that an <a href="http://en.wikipedia.org/wiki/0.999...">infinitely repeating sequence of 0.999.. is equal to one</a>?
</p>
<p>
</p>
<blockquote>
In mathematics, the repeating decimal 0.999Ãƒâ€“ denotes a real number equal to one. In other words: the notations 0.999Ãƒâ€“ and 1 actually represent the same real number.
<p>
<img alt="image placeholder" >
</p>
<p>
This equality has long been accepted by professional mathematicians and taught in textbooks. Proofs have been formulated with varying degrees of mathematical rigour, taking into account preferred development of the real numbers, background assumptions, historical context, and target audience.
</p>
</blockquote>
<p>
Computers <a href="http://www.codinghorror.com/blog/archives/000874.html">are awesome</a>, yes, but they aren't <i>infinite</i>.. yet. So any prospects of storing any infinitely repeating number on them are dim at best. The best we can do is work with approximations at varying levels of precision that are "good enough", where "good enough" depends on what you're doing, and how you're doing it. And it's complicated to get right.
</p>
<p>
Which brings me to <a href="http://docs.sun.com/source/806-3568/ncg_goldberg.html">What Every Computer Scientist Should Know About Floating-Point Arithmetic</a>.
</p>
<p>
</p>
<blockquote>
<b>Squeezing infinitely many real numbers into a finite number of bits requires an approximate representation.</b> Although there are infinitely many integers, in most programs the result of integer computations can be stored in 32 bits. In contrast, given any fixed number of bits, most calculations with real numbers will produce quantities that cannot be exactly represented using that many bits. Therefore the result of a floating-point calculation must often be rounded in order to fit back into its finite representation. This rounding error is the characteristic feature of floating-point computation.
</blockquote>
<p>
What do the Google, Windows, and <a href="http://www.lomont.org/Math/Papers/2007/Excel2007/Excel2007Bug.pdf">Excel</a> (pdf) math errors have in common? They're all related to number precision approximation issues. Google doesn't think it's important enough to fix. They're probably right. But some mathematical rounding errors can be <a href="http://www.maa.org/mathland/mathland_5_12.html">a bit more serious</a>.
</p>
<p>
</p>
<blockquote>
Interestingly, the launch failure of the Ariane 5 rocket, which exploded 37 seconds after liftoff on June 4, 1996, occurred because of a software error that resulted from converting a 64-bit floating point number to a 16-bit integer. The value of the floating point number happened to be larger than could be represented by a 16-bit integer. The overflow wasn't handled properly, and in response, the computer cleared its memory. The memory dump was interpreted by the rocket as instructions to its rocket nozzles, and an explosion resulted.
</blockquote>
<p>
I'm starting to believe that it's not the computers that suck at math, but the people programming those computers. I know I'm <a href="http://www.codinghorror.com/blog/archives/001187.html">living proof of that</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-do-computers-suck-at-math/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Isn't My Encryption.. Encrypting? ]]></title>
<link>https://blog.codinghorror.com/why-isnt-my-encryption-encrypting/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's as true in life as it is in client-server programming: the only secret that can't be compromised is the one you never revealed.
</p>
<p>
But sometimes, it's unavoidable. If you <i>must</i> send a secret down to the client, you can encrypt it. The most common form of encryption is <a href="http://en.wikipedia.org/wiki/Symmetric-key_algorithm">symmetric encryption</a>, where the same key is used to both encrypt and decrypt. Most languages have relatively easy to use libraries in place for symmetric encryption. Here's how we were doing it in .NET:
</p>
<p>
</p>
<pre>
public static string Encrypt(string toEncrypt, string key, bool useHashing)
{
byte[] keyArray = UTF8Encoding.UTF8.GetBytes(key);
byte[] toEncryptArray = UTF8Encoding.UTF8.GetBytes(toEncrypt);
if (useHashing)
keyArray = new MD5CryptoServiceProvider().ComputeHash(keyArray);
var tdes = new TripleDESCryptoServiceProvider()
{ Key = keyArray, Mode = CipherMode.ECB, Padding = PaddingMode.PKCS7 };
ICryptoTransform cTransform = tdes.CreateEncryptor();
byte[] resultArray = cTransform.TransformFinalBlock(
toEncryptArray, 0, toEncryptArray.Length);
return Convert.ToBase64String(resultArray, 0, resultArray.Length);
}
</pre>
<p>
This is how our symmetric encryption function works:
</p>
<p>
</p>
<ol>
<li>We start with a secret string we want to protect. Let's say it is "password123".
</li>
<li>We pick a key. Let's use the key "key-m4st3r"
</li>
<li>Before encrypting, we'll prefix our secret with a salt to <a href="http://www.codinghorror.com/blog/archives/000949.html">prevent dictionary attacks</a>. Let's call our salt "NaCl".
</li>
</ol>
<p>
We'd call the function like so:
</p>
<p>
</p>
<pre>
Encrypt("NaCl" + "password123", "key-m4ast3r", true);
</pre>
<p>
The output is a base64 encoded string of the <a href="http://en.wikipedia.org/wiki/Triple_DES">TripleDES encrypted</a> byte data. <b>This encrypted data can now be sent to the client without any reasonable risk that the secret string will be revealed</b>. There's always <i>unreasonable</i> risk, of the silent black government helicopter sort, but for all practical purposes there's no way someone could discover that your password is "password123" unless your key is revealed.
</p>
<p>
In our case, we were using this <code>Encrypt()</code> method to experiment with <b>storing some state data in web pages related to the login process</b>. We thought it was secure, because the data was encrypted. Sure it's encrypted! It says <code>Encrypt()</code> right there in the method name, right?
</p>
<p>
Wrong.
</p>
<p>
There's a bug in that code. A bug that makes our encrypted state data vulnerable. Do you see it? My coding mistakes, <a href="http://www.pantherkut.com/wp-content/uploads/2007/05/my_pokemons.jpg">let me show you them!</a>
</p>
<p>
</p>
<pre>
string key = "SuperSecretKey";
Debug.WriteLine(
Encrypt("try some different" +
"<font color="red">00000000000000000000000000000000</font>",
key, true).Base64ToHex());
Debug.WriteLine(
Encrypt("salts" +
"<font color="red">00000000000000000000000000000000</font>",
key, true).Base64ToHex());
3908024fc33b55c3
4e885c8946b80735
704cbe2a41d25f21
<font color="red">81bb6d726bd35152</font>
<font color="red">81bb6d726bd35152</font>
<font color="red">81bb6d726bd35152</font>
1367f10f2584ace3
4ae7661295a98e46
<font color="red">81bb6d726bd35152</font>
<font color="red">81bb6d726bd35152</font>
<font color="red">81bb6d726bd35152</font>
4ee5d23b3b5e3eb4
</pre>
<p>
(I'm using strings with multiples of 8 here to make the Base64 conversions easier.)
</p>
<p>
Do you see the mistake now? It's a short trip from here to unlimited data tampering, particularly since the state data from the login process contained user entered strings. An attacker could simply submit the form as many times as she likes, chop out the encrypted attack values from the middle, and insert them into the next encrypted request -- <b>which will happily decrypt and be processed as if our code had sent it down!</b>
</p>
<p>
The culprit is this line of code:
</p>
<p>
</p>
<pre>
{ Key = keyArray, <font color="red">Mode = CipherMode.ECB</font>, Padding = PaddingMode.PKCS7 }
</pre>
<p>
Which, much to our embarrassment, is an <i>incredibly</i> <a href="http://msdn.microsoft.com/en-us/library/system.security.cryptography.ciphermode.aspx">stupid parameter</a> to use in symmetric encryption:
</p>
<p>
</p>
<blockquote>
The Electronic Codebook (ECB) mode encrypts each block individually. This means that any blocks of plain text that are identical and are in the same message, or in a different message encrypted with the same key, will be transformed into identical cipher text blocks. If the plain text to be encrypted contains substantial repetition, it is feasible for the cipher text to be broken one block at a time. Also, it is possible for an active adversary to substitute and exchange individual blocks without detection.
</blockquote>
<p>
It's fairly standard for symmetric encryption algorithms to use feedback from the previous block to seed the next block. I honestly did not realize that it was <i>possible</i> to pick a cipher mode that did not do some kind of block chaining! <code>CipherMode.ECB</code>? More like <code>CipherMode.Fail</code>!
</p>
<p>
So, what have we learned?
</p>
<p>
</p>
<ol>
<li>
<b>If it doesn't <i>have</i> to be sent to the client, then don't!</b> Secrets sent to the client can potentially be tampered with and compromised in various ways that aren't easy to see or even predict. In our case, we can store login state on the server and avoid transmitting any of that state to the client altogether.<br><br>
</li>
<li>
<b>It isn't encryption until you've taken the time to fully understand the concepts behind the encryption code</b>. Specifically, we didn't notice that our encryption function was using a highly questionable <code>CipherMode</code> that allowed block level substitution of the encrypted data.
</li>
</ol>
<p>
Luckily, this was a somewhat experimental page on the site, so we were able to revert back to our standard server-side approach rather quickly once the exploit was discovered. I'm no <a href="http://www.schneier.com/">Bruce Schneier</a>, but I have <a href="http://www.codeproject.com/KB/security/SimpleEncryption.aspx">a reasonable grasp of encryption concepts</a>. And I <i>still</i> completely missed this problem.
</p>
<p>
So the next time you sit down to write some encryption code, consider the above two points carefully. Otherwise, like us, you'll be left wondering <b>why your encryption isn't... <i>encrypting</i></b>.
</p>
<p>
(Thanks to Daniel LeCheminant for his assistance in discovering this issue.)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-isnt-my-encryption-encrypting/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Bathroom Wall of Code ]]></title>
<link>https://blog.codinghorror.com/the-bathroom-wall-of-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/001267.html">Why Isn't My Encryption.. Encrypting?</a>, many were up in arms about the flawed function I posted. And rightfully so, as there was a huge mistake in that code that just about invalidates any so-called "encryption" it performs. But there's one small problem: <b>I didn't write that function</b>.
</p>
<p>
Now, I am certainly <i>responsible</i> for that function, in the sense that it magically appeared in our codebase one day -- and the the entire project is the sum of all the code contributed by every programmer working on it. I invoke the <a href="http://www.codinghorror.com/blog/archives/001079.html">First Rule of Programming: It's Always Your Fault</a>. And by "your", I don't mean the particular programmer who contributed this code, who shall remain blissfully nameless. I mean us -- the entire team. The onus is on us, as a team, to vet every line of code at the time it is contributed, and constantly <a href="http://www.codinghorror.com/blog/archives/001229.html">peer review each other's code</a>. It's a responsibility we shoulder together. Nobody owns the code, because <a href="http://www.codinghorror.com/blog/archives/000219.html">everybody owns the code</a>.
</p>
<p>
Yes, I failed. Because the <i>team</i> failed.
</p>
<p>
Geoff Weinhold left this prophetic comment on the post:
</p>
<p>
</p>
<blockquote>
The irony in this is that someone will inevitably end up here for sample encryption code and blindly copy/paste your flawed code.
</blockquote>
<p>
Indeed. Heaven forbid someone copy and paste flawed code <i>from the internet</i> into their project! In fact, a quick search on some of the unique strings in that original <code>Encrypt()</code> function turns up a few ... interesting ... search results.
</p>
<p>
</p>
<table width="600">
<tr>
<td>01/2006</td>
<td><a href="http://www.csharper.net/blog/library_encrypt_and_decrypt_methods_using_tripledes_and_md5.aspx">C# Shiznit - Library Encrypt and Decrypt Methods using TripleDES and MD5</a></td>
</tr>
<tr>
<td>05/2006</td>
<td><a href="http://www.codeproject.com/KB/web-security/Cryptography_MD5_TriDES.aspx?display=Print">Code Project - Encrypt and Decrypt Data with C#</a></td>
</tr>
<tr>
<td>04/2007</td>
<td><a href="http://bytes.com/groups/net-c/636048-string-encryption-help">Bytes - String Encryption Help</a></td>
</tr>
<tr>
<td>06/2008</td>
<td><a href="http://www.eggheadcafe.com/community/aspnet/7/10039720/insufficient-code-in-your.aspx">Egghead Cafe - invalid length while decrypting TripleDESCryptoServiceProvider</a></td>
</tr>
<tr>
<td>09/2008</td>
<td><a href="http://forums.asp.net/t/1313494.aspx">ASP.NET Forums - Need help on password-encrypted key used for signing</a></td>
</tr>
<tr>
<td>11/2008</td>
<td><a href="http://www.codekeep.net/snippets/af1cd375-059a-4175-93d7-25eea2c5c660.aspx">code:keep Encryption</a></td>
</tr>
<tr>
<td>12/2008</td>
<td><a href="http://www.dotnetspider.com/forum/185122-Encrypt-Decrypt-password-C-net.aspx">Encrypt/Decrypt the password in C# .net</a></td>
</tr>
<tr>
<td>05/2009</td>
<td><a href="http://www.codinghorror.com/blog/archives/001267.html">My Own Stupid Blog Post</a></td>
</tr>
</table>
<p>
That's just a sampling of the 131 web hits I got. To <a href="http://www.imdb.com/title/tt0118655/quotes#qt0367867">paraphrase Austin Powers</a>, <b>this <code>Encrypt()</code> function is like the village bicycle: everybody's had a ride.</b> It's a shame this <i>particular</i> bicycle happens to have a crippling lack of brakes that makes it dangerous to ride, but what can you do.
</p>
<p>
Scott Hanselman <a href="http://www.hanselman.com/blog/GoogleCodeSearchNowYouCanSearchTheBathroomWallOfCode.aspx">coined</a> a nice phrase for this: <b>the internet as the bathroom wall of code</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's true. People, being people, have gone and scrawled a bunch of random code graffiti all over the damn internet. Some of it is vanity tagging. Some of it is borderline vandalism. And some of it is art. How do we tell the difference?
</p>
<p>
That's the very reason I put forth a <a href="http://www.codinghorror.com/blog/archives/001257.html">modest proposal for the copy and paste school of code reuse</a>. Not that it would have helped in this case, but it sure would be nice if someone could <b>perform a grep replace</b> ...
</p>
<p>
</p>
<pre>
s/Mode = CipherMode.ECB/Mode = CipherMode.CBC/g
</pre>
<p>
... on, like, <i>the entire internet</i>. So other projects don't absorb this critically flawed code sample.
</p>
<p>
In the meantime, until that tool is developed, I recommend that you <b>apply extra-strength peer review to any code snippets you absorb into your project from the bathroom wall of code</b>. That internet code snippet you're looking at, the one that appears to be <i>just what you're looking for</i>, could also be random graffiti scrawled on a bathroom wall.
</p>
<p>
It's true that some bathrooms are nicer than others. But as we've learned, it pays to be especially careful when cribbing code from the internet.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-bathroom-wall-of-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How to Motivate Programmers ]]></title>
<link>https://blog.codinghorror.com/how-to-motivate-programmers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
There's an inherent paradox in motivating programmers. I think <a href="http://www.geekherocomic.com/2008/11/14/the-best-way-to-improve-code-performance/">this Geek Hero Comic</a> illustrates it perfectly:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's a phenomenon I've noticed even in myself. <b>Nothing motivates like having another programmer tell you they're rewriting your code because it sucks.</b> <a href="http://pragdave.pragprog.com/">Dave Thomas</a> has talked about this for years in his classic <a href="http://www.infoq.com/presentations/Developing-Expertise-Dave-Thomas">Developing Expertise presentation</a>, supported by the following quote:
</p>
<p>
</p>
<blockquote>
Interestingly enough, a friend of mine (who is a quality control manager in a hospital) often makes identical statements in reference to doctors: Polite requests, coercion, etc. are useless at best and often detrimental.  <b>Peer pressure and competition are the key</b>.
<p>
Don't try to race sheep,<br>
Don't try to herd race horses
</p>
</blockquote>
<p>
Yes, the use of the term sheep is mildly derogatory, but the general principle is sound: use motivational techniques that are appropriate to the level of developers you're working with. If you have neophyte developers, herd them with maxims, guidelines and static rules. If you have experienced developers, <a href="http://www.codinghorror.com/blog/archives/000203.html">rules are less useful</a>. Instead, encourage them to race: engage in a little friendly competition and show off how good they are to their peers.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-motivate-programmers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Penny Auctions: They're Gambling ]]></title>
<link>https://blog.codinghorror.com/penny-auctions-theyre-gambling/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Late last year, I encountered what may be <a href="http://www.codinghorror.com/blog/archives/001196.html">nearly perfect evil in business plan form: Swoopo</a>. What is Swoopo? It's a class of penny auction, where <a href="http://www.mercurynews.com/businessheadlines/ci_12431890">bidders pay for the privilege of bidding:</a>
</p>
<p>
</p>
<blockquote>
[Penny auctions] offer new televisions, computers, game consoles, appliances, handbags, gold bars and more for starting prices of a penny to 15 cents, depending on the site.
<p>
To "win" a product, shoppers must first buy a bundle of 10 to 700 bids for 60 cents to $1 each. Shoppers use one each time they place a virtual bid on a product. Each bid raises the price of the item by a penny to 15 cents, depending on the site. Some have automatic bidding functions similar to eBay.
</p>
<p>
Doing the math and not getting carried away is important: The final price of a product that retails for $100 might be $29, but the total price paid could be much more, depending upon the number of bids used. If a shopper bids 10 times at $1 a bid, for instance, the total price paid would jump to $39. And, there is the real possibility of using all your bids without getting the product.
</p>
<p>
Auction winners generally get their item for about 65 percent off retail but could save as much as 98 percent if there are few bidders.
</p>
<p>
Since the sites make the bulk of their revenue from the purchase of bids, they profit most when they feature a product that elicits a bidding war.
</p>
</blockquote>
<p>
One of Swoopo's investors recently contacted me via email, and I had to marvel at the size of the cojones you'd need to associate yourself with this kind of nastiness. Swoopo is evil beyond the likes of Saddam Hussein, The Balrog, OSB, Darth Vader, and Barbra Streisand -- combined.
</p>
<p>
He wanted to talk to me on the phone about positioning, and staunchly maintained that there was <i>no</i> element of chance in a Swoopo "auction". Once I stopped laughing, I told him these were my terms:
</p>
<p>
</p>
<blockquote>
If you believe in Swoopo, then data speaks much louder than words.
<p>
Let's conduct an experiment.
</p>
<p>
Doesn't have to be you, personally. Take n dollars, and use those n dollars in whatever strategy it takes to win items (of MSRP $399 or higher) on Swoopo.
</p>
<p>
If Swoopo isn't a game of chance or lottery, a skilled player should be able to win at least one item in this experiment, yes?
</p>
<p>
I'd be happy to run this experiment and write about it on my blog. Just let me know what terms you think make sense.
</p>
</blockquote>
<p>
I haven't heard from him since. (Now I'm curious if <i>anyone</i> is willing to take on this experiment, under the same terms.)
</p>
<p>
Because <b>Swoopo is, at its heart, thinly veiled gambling</b>. The companies backing Swoopo and other Penny Auction sites are hoping unsophisticated regulatory agencies will buy the "It's not a game of chance" argument if it's wrapped in a lot of technical intarweb mumbo-jumbo they can't fully comprehend.
</p>
<p>
But we're no government flacks. We're programmers, and many of us develop websites for a living. It's a bit tougher to pull the wool over our eyes. In <a href="http://jcs.org/notaweblog/2009/03/06/trying_to_game_swoopo_com/">Trying to Game Swoopo</a>, Joshua Stein pulled out everything in his programmer's bag of tricks to win a Swoopo auction -- and, predictably, <a href="http://jcs.org/notaweblog/2009/03/11/trying_to_game_swoopo_com_part_2/">failed</a>.
</p>
<p>
</p>
<blockquote>
With all of this data available, I concluded that <b>there is no way to reliably win an auction on swoopo.com without using their bidbutler service</b>. There are delays on their network/servers in processing manual bids, whether intentional or just due to bad design, that cause manual bids placed with 1 or 2 seconds remaining not to be cast. users of their bidbutler service have an unfair advantage in that their bids are placed on the server side and are not subject to these delays.
<p>
Since it is not possible to reliably place manual bids, the only way to guarantee that an auction can be won (while still coming out ahead) is to use the site's bidbutler service with high ceilings on the number of bids and amount that one will let it bid up to. Those ceilings have to take into account the item's current price, and will be lower the longer an item is being bid on.
</p>
</blockquote>
<p>
As Joshua's data shows, there is no way to win a Swoopo auction other than through sheer random chance --  that is, your client-side bid happens to wind its way through the umpteen internet routers between the server and your computer in time, ending up at the top of a queue with dozens or hundreds of other bids placed within a fraction of a second of each other. And what's worse, you may not have any chance at all, unless you place a server-side bet through their exploitatively expensive "bidbutler" service.
</p>
<p>
As I said in <a href="http://www.codinghorror.com/blog/archives/001196.html">my original post</a>, the only winning strategy at Swoopo, or any other penny auction site, is <i>not to play</i>. On Swoopo, there are nothing but millions of losers -- and by that I mean they are gambling and losing millions of real dollars to the house. Which would be OK, I guess, <b>if it was properly regulated as gambling</b>. Swoopo and all these other penny auction sites should be regulated and classified as the online gambling sites in sheep's clothing they really are.
</p>
<p>
Let's see what we can do to hasten this process along. Warn your friends and family. Complain to the Better Business Bureau and other regulatory agencies. And if you feel as strongly as I do about this, please write your congressmen/women and urge them to regulate these exploitative penny auctions.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/penny-auctions-theyre-gambling/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Beyond RAID ]]></title>
<link>https://blog.codinghorror.com/beyond-raid/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've always been <a href="http://www.codinghorror.com/blog/archives/000335.html">leery of RAID on the desktop</a>. But on the server, RAID is <a href="http://en.wikipedia.org/wiki/RAID">a definite must</a>:
</p>
<p>
</p>
<blockquote>
"RAID" is now used as an umbrella term for computer data storage schemes that can divide and replicate data among multiple hard disk drives. The different schemes/architectures are named by the word RAID followed by a number, as in RAID 0, RAID 1, etc. <b>RAID's various designs all involve two key design goals: increased data reliability or increased input/output performance.</b> When multiple physical disks are set up to use RAID technology, they are said to be in a RAID array. This array distributes data across multiple disks, but the array is seen by the computer user and operating system as one single disk.
</blockquote>
<p>
I hadn't worked much at all with RAID, as I felt the benefits did not outweigh the risks on the desktop machines I usually build. But the rules are different in the datacenter; the <a href="http://blog.stackoverflow.com/category/server/">servers I built for Stack Overflow</a> <i>all</i> use various forms of RAID, from RAID 1 to RAID 6 to RAID 10. While working with these servers, I was surprised to discover there are now umpteen zillion numbered variants of RAID -- but they all appear to be based on a few basic, standard forms:
</p>
<p>
<b>RAID 0: Striping</b>
</p>
<p>
Data is striped across (n) drives, which improves performance almost linearly with the number of drives, but at a steep cost in fault tolerance; a failure of any single striped drive renders the entire array unreadable.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>RAID 1: Mirroring</b>
</p>
<p>
Data is written across (n) drives, which offers near-perfect redundancy at a slight performance decrease when writing -- and at the cost of half your overall storage. As long as one drive in the mirror array survives, no data is lost.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Raid 5: Parity</b>
</p>
<p>
Data is written across (n) drives with a <a href="http://en.wikipedia.org/wiki/Parity_bit">parity block</a>. The array can tolerate one drive failure, at the cost of one drive in storage. There may be a serious performance penalty when writing (as parity and blocks are calculated), and when the array is rebuilding.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>Raid 6: Dual Parity</b>
</p>
<p>
Data is written across (n) drives with two <a href="http://en.wikipedia.org/wiki/Parity_bit">parity blocks</a>. The array can tolerate two drive failures, at the cost of two drives in storage. There may be a serious performance penalty when writing (as parity and blocks are calculated), and when the array is rebuilding.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
(yes, there are other forms of RAID, but they are rarely implemented or used as far as I can tell.)
</p>
<p>
It's also possible to generate so-called <b>RAID 10</b> or <b>RAID 50</b> arrays by <a href="http://en.wikipedia.org/wiki/Nested_RAID_levels">nesting these RAID levels together</a>. If you take four hard drives, stripe the two pairs, then mirror the two striped arrays -- why, you just created yourself a magical RAID 10 concoction! What's <i>particularly</i> magical about RAID 10 is that it inherits the strengths of both of its parents: mirroring provides excellent redundancy, and striping provides excellent speed. Some would say that <a href="http://weblogs.sqlteam.com/billg/archive/2007/06/18/RAID-10-vs.-RAID-5-Performance.aspx">RAID 10 is so good it completely obviates any need for RAID 5</a>, and I for one agree with them.
</p>
<p>
This was all fascinating new territory to me; I knew about RAID in theory but had never spent hands-on time with it. The above is sufficient as a primer, but I recommend <a href="http://en.wikipedia.org/wiki/RAID">reading through the wikipedia entry on RAID</a> for more depth.
</p>
<p>
It's worth mentioning here that <b><a href="http://www.google.com/search?q=raid+is+not+a+backup">RAID is in no way a substitute for a sane backup regimen</a></b>, but rather a way to offer improved uptime and survivability for your existing systems. Hard drives are cheap and getting cheaper every day -- why not use a whole slew of the things to get better performance <i>and</i> better reliability for your servers? That's always been the point of Redundant Array of Inexpensive Disks, as far as I'm concerned. I guess Sun agrees; check out <a href="http://techreport.com/discussions.x/13849">this monster</a>:
</p>
<p>
<a href="http://techreport.com/discussions.x/13849"><img alt="image placeholder" >
</p>
<p>
That's right, 48 commodity SATA drives in a massive array, courtesy of the <a href="http://www.sun.com/servers/x64/x4500/">Sun Sunfire X4500</a>. It also uses a new RAID system <a href="http://blogs.sun.com/bonwick/entry/raid_z">dubbed RAID-Z</a>:
</p>
<p>
</p>
<blockquote>
RAID-Z is a data/parity scheme like RAID-5, but it uses dynamic stripe width. Every block is its own RAID-Z stripe, regardless of blocksize. This means that every RAID-Z write is a full-stripe write. This, when combined with the copy-on-write transactional semantics of ZFS, completely eliminates the RAID write hole. RAID-Z is also faster than traditional RAID because it never has to do read-modify-write.
<p>
But far more important, going through the metadata means that ZFS can validate every block against its 256-bit checksum as it goes. Traditional RAID products can't do this; they simply XOR the data together blindly.
</p>
<p>
Which brings us to the coolest thing about RAID-Z: self-healing data. In addition to handling whole-disk failure, RAID-Z can also detect and correct silent data corruption. Whenever you read a RAID-Z block, ZFS compares it against its checksum. If the data disks didn't return the right answer, ZFS reads the parity and then does combinatorial reconstruction to figure out which disk returned bad data. It then repairs the damaged disk and returns good data to the application. ZFS also reports the incident through Solaris FMA so that the system administrator knows that one of the disks is silently failing.
</p>
<p>
Finally, note that RAID-Z doesn't require any special hardware. It doesn't need NVRAM for correctness, and it doesn't need write buffering for good performance. With RAID-Z, ZFS makes good on the original RAID promise: it provides fast, reliable storage using cheap, commodity disks.
</p>
</blockquote>
<p>
Pardon the pun, but I'm not sure if it makes traditional hardware RAID <i>redundant</i>, necessarily. Even so, there are certainly fantastic, truly next-generation ideas in ZFS. There's a great <a href="http://queue.acm.org/detail.cfm?id=1317400">ACM interview with the creators of ZFS</a> that drills down into much more detail. Hard drives may be (mostly) dumb hunks of spinning rust, but it's downright amazing what you can do when you get a whole bunch of them working together.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/beyond-raid/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Server Fault: Calling All Lusers ]]></title>
<link>https://blog.codinghorror.com/server-fault-calling-all-lusers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's pop quiz time! Put away your notes, and let's begin.
</p>
<p>
a) Do you own this book?*
</p>
<p>
<a href="http://www.amazon.com/dp/0130206016/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
b) Do you know who this man is?
</p>
<p>
<a href="http://blogs.technet.com/markrussinovich/"><img alt="image placeholder" >
</p>
<p>
c) Does this FAQ look <a href="http://www.faqs.org/faqs/sysadmin-recovery/">familiar</a> to you?
</p>
<p>
</p>
<blockquote>
3) OUR LITTLE FRIEND, THE COMPUTER<br>
3.1) Are there any OSes that don't suck?<br>
3.2) Are there any vendors that don't suck?<br>
3.3) How about any hardware?<br>
3.4) Just HOW MUCH does this system suck?<br>
3.5) Where can I find clueful tech support?<br>
3.6) What can I do to help my computers behave?<br>
</blockquote>
<p>
d) Does the acronym <a href="http://en.wikipedia.org/wiki/Bastard_Operator_From_Hell">BOFH</a> mean anything to you?
</p>
<p>
e) Do you think <a href="http://www.amazon.com/dp/1573980420/?tag=codihorr-20">this</a> is funny?
</p>
<p>
<a href="http://www.amazon.com/dp/1573980420/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
If you answered "yes" to any of the above, I am sorry to inform you that <b>you may be a system administrator or IT professional</b>. But I do have one bit of potentially, at least <i>theoretically</i> good news for you:
</p>
<p>
<b><a href="http://serverfault.com">Server Fault</a> is now in public beta!</b>
</p>
<p>
<a href="http://serverfault.com"><img alt="image placeholder" >
</p>
<p>
Server Fault is a sister site to Stack Overflow, which <a href="http://www.codinghorror.com/blog/archives/001169.html">we launched back in September 2008</a>. It uses the same engine, but it's <a href="http://serverfault.com/faq">not just for programmers</a> any more:
</p>
<p>
</p>
<blockquote>
Server Fault is for <b>system administrators and IT professionals</b>, people who manage or maintain computers in a professional capacity. If you are in charge of ...
<ul>
<li>servers
</li>
<li>networks
</li>
<li>many desktop PCs (other than your own)
</li>
</ul>
... then you're in the right place to ask your question! Well, as long as the question is about your servers, your networks, or desktops you support, anyway.
<p>
Please note that Server Fault is <b>not for general computer troubleshooting questions</b>; if you paid for that desktop hardware, and it's your personal workstation, it is unlikely that your question is appropriate for Server Fault.
</p>
</blockquote>
<p>
I occasionally dabble in system administration and IT professional stuff; <a href="http://www.codinghorror.com/blog/archives/001233.html">my last blog entry was about RAID</a>, for example. As a programmer who <a href="http://www.codinghorror.com/blog/archives/000874.html">loves hardware</a> as much as software, I've wanted this site for months, and I'm thrilled to see it go live, as I <a href="http://runasradio.com/default.aspx?showNum=109">explained on a recent RunAs radio podcast</a>.
</p>
<p>
Although there is certainly some crossover, we believe that the programming community and the IT/sysadmin community are different beasts. Just because you're a hotshot programmer doesn't mean you have mastered networking and server configuration. And I've met a few sysadmins who could script circles around my code. That's why <a href="http://serverfault.com">Server Fault</a> gets its own domain, user profiles, and reputation system.
</p>
<p>
<a href="http://www.userfriendly.org/cartoons/archives/99aug/19990815.html"><img alt="image placeholder" >
</p>
<p>
<b>So if you're a bona-fide BOFH, or just a wanna-be BOFH <a href="http://en.wikipedia.org/wiki/Luser">luser</a> like me, <a href="http://serverfault.com">join us on Server Fault</a></b>. Who knows, maybe we lusers can learn something from each other.
</p>
<p>
<small>* (For the record, yes, I do own that book -- although I am easily the world's <i>worst</i> UNIX system administrator.)</small>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-05-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/server-fault-calling-all-lusers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Girl Who Proved P = NP ]]></title>
<link>https://blog.codinghorror.com/the-girl-who-proved-p-np/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of my all time favorite blog entries is a truly epic tale of dating gone wrong that culminates in <a href="http://www.joeydevilla.com/2003/04/07/what-happened-to-me-and-the-new-girl-or-the-girl-who-cried-webmaster/">the strangest reference to P=NP you'll probably ever encounter</a>.
</p>
<p>
</p>
<blockquote>
<b>Joey</b>: So you really did graduate from computer engineering?
<p>
<b>New Girl</b>: Yes I did, from UBC!
</p>
<p>
<b>Joey</b>: And you took the "Algorithms" course?
</p>
<p>
<b>New Girl</b>: Of course!
</p>
<p>
<b>Joey</b>: And you have all the papers you wrote?
</p>
<p>
<b>New Girl</b>: <i>Yes!</i> I kept them all, and I'll show them to you tomorrow!
</p>
<p>
<b>Joey</b>: I want to see the one we always called the "Hell Paper" at Queen's -- the mandatory fourth-year paper. You know the one, where we prove P = NP?
</p>
<p>
<b>New Girl</b>: <font color="maroon">I did that! I proved P = NP!</font> I placed near the top of the class, and the professor used my paper as an example!
</p>
<p>
<b>Joey</b>: You proved P = NP?
</p>
<p>
<b>New Girl</b>: Yes!
</p>
<p>
<b>Joey</b>: Gotcha.
</p>
</blockquote>
<p>
Poor Joey. Dating crazy people is one thing, but dating crazy people who <i>claim to have proved P=NP</i> is another matter entirely. I know, I know, <a href="http://www.codinghorror.com/blog/archives/001187.html">my track record with P=NP</a> is hardly any better. But at least you're not dating me, right?
</p>
<p>
NP completeness is <a href="http://www.claymath.org/millennium/P_vs_NP/">one of the great unsolved mysteries in computer science</a>; perhaps the best way to illustrate is through <a href="http://xkcd.com/287/">this xkcd cartoon</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The defining characteristic of an NP-complete problem is that optimal solutions, using math and logic as we currently understand them, are effectively impossible. Sure, you can <a href="http://www.codinghorror.com/blog/archives/001187.html">approximate a solution</a>, but an <i>optimal</i> solution requires so many calculations as to be infeasible, even with computers that operated at, say .. the speed of light.
</p>
<p>
</p>
<blockquote>
In fact, one of the outstanding problems in computer science is determining whether questions exist whose answer can be quickly checked, but which require an impossibly long time to solve by any direct procedure. Problems like the one listed above certainly seem to be of this kind, but so far no one has managed to prove that any of them really are so hard as they appear, <b>i.e., that there really is no feasible way to generate an answer with the help of a computer.</b>
</blockquote>
<p>
It's doubtful <a href="http://www.cs.umd.edu/~gasarch/papers/poll.pdf">whether anyone will ever prove that P=NP</a> (pdf), but in the meantime it's useful to <a href="http://max.cs.kzoo.edu/~kschultz/CS510/ClassPresentations/NPCartoons.html">recognize problems that are NP complete</a>:
</p>
<p>
</p>
<blockquote>
Unfortunately, proving inherent intractibility can be just as hard as finding efficient algorithms.
<p>
The theory of NP-completeness provides many straightforward techniques for proving that a given problem is "just as hard" as a large number of other problems that are widely recognize as being difficult and that have been confounding the experts for years. Armed with these techniques, you might be able to prove that the bandersnatch problem is NP-complete and march into your boss's office and announce:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<i>I can't find an efficient algorithm, but neither can all these famous people.</i>
</p>
<p>
At the very least, this would inform your boss that it would do no good to fire you and hire another expert on algorithms.
</p>
<p>
Now you can spend your time looking for efficient algorithms that solve various special cases of the general problem. You might look for algorithms that, though not guaranteed to run quickly, seem likely to do so most of the time. Or you might even relax the problem somewhat, looking for a fast algorithm that merely finds designs that meet most of the component specifications. Thus, the primary application of the theory of NP-completeness is to assist algorithm designers in directing their problem-solving efforts toward those approaches that have the greatest likelihood of leading to useful algorithms.
</p>
</blockquote>
<p>
As with so many things in programming, <b>the first step is learning enough to know when you're <i>really</i> screwed</b>.
</p>
<p>
Unfortunately for poor Joey, this sad corollary to NP-completeness apparently applies to dating, too.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-girl-who-proved-p-np/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I Stopped Reading Your Blog Years Ago ]]></title>
<link>https://blog.codinghorror.com/i-stopped-reading-your-blog-years-ago/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><a href="http://emrahdiril.com/">Emrah Diril</a> recently asked me this via email:</p>
<blockquote>
<p>Steve Yegge <a href="http://steve-yegge.blogspot.com/2009/05/programmers-view-of-universe-part-3.html">mentioned in the comments of his last post</a> that he gets quite a bit of hate directed his way.</p>
<blockquote>
<p><i>Fake51: you underestimate the ability of people to get mad. Some people start mad and just take it out on you. The hating has gradually become a little too much for me.</i></p>
</blockquote>
<p>I read the guy's blog too, but don't understand where this is coming from. Some people just have this tendency I suppose.</p>
<p>Do you have a similar experience? I don't see you wanting to quit blogging, so how do you deal with this? Is it just a matter of personality? Are you better able to ignore this stuff?</p>
</blockquote>
<p>I answered with one of my favorite quotes from <a href="http://download.srv.cs.cmu.edu/~pausch/">Randy Pausch's</a> <a href="http://www.youtube.com/watch?v=ji5_MqicxSo">Last Lecture</a>:</p>
<blockquote>
<p>And when it was all over, one of the other assistant coaches came over and said, yeah, Coach Graham rode you pretty hard, didn't he? I said, yeah. He said, that's a good thing. He said, when you're screwing up and nobody's saying anything to you anymore, that means they gave up. And that's a lesson that stuck with me my whole life: <b>when you see yourself doing something badly and nobody's bothering to tell you anymore, that's a very bad place to be. Your critics are your ones telling you they still love you and care.</b></p>
</blockquote>
<p>Welcoming and appreciating reasonable criticism is the right attitude to have, but it's not the full story. Do I <i>love</i> criticism? Do I <i>seek it out?</i> No. I have many personality deficiencies, but masochism isn't one of them. I don't have fantasies of waking up every day to an <a href="http://blog.codinghorror.com/discipline-makes-strong-developers/">R. Lee Ermey</a> browbeating from commenters. Or, maybe I do. I should blog about that.</p>
<a href="http://www.nytimes.com/imagepages/2007/04/04/opinion/05opart.html">
<img alt="image placeholder" >
<p>Criticism, painful though it may be, is still a conversation. It means your readers and listeners are engaging with you, and <b>there's something to learn from following that conversation</b>. Those messages you're broadcasting out into the world are being received, in some form, by someone on the planet. Even if that person is, well .. this guy:</p>
<blockquote>
<p><b>I stopped reading the blog a while a go.</b> Joel explains my reasoning nicely in <a href="http://www.joelonsoftware.com/items/2008/11/18.html">his latest post</a>.</p>
</blockquote>
<p>The mystery of the non-reading Coding Horror reader. Another NP-complete problem, I guess.</p>
<p>If you think something sucks to the extent that it's actively harming the world and you want it to go away, leaving comments to that effect is not the way. I know, because I bear the psychic scars of a million online flamewars, dating all the way back to 300 baud dualup modems and BBSes. I've been doing this a very long time. I've seen what works, and what doesn't.</p>
<p>I'm here to tell you that <b>there is something much more powerful than criticism</b> that you can bring to bear in these situations. Something <a href="http://kottke.org/08/07/just-dont-look">almost unimaginably powerful in its ability to shape human behavior</a>.</p>
<blockquote>
<p>The "just don't look" strategy [is] effective in any situation where someone or something runs on attention. On the web attention comes in the form of links and pageviews so "just don't look" translates roughly into "just don't link or read". If you don't like who's on the cover of Wired, just don't look. If no one talks about her, she'll go away. Think media gossip sites are ruining the web? Don't read them. Leggy blonde conservative got your knickers in a knot? Just don't look. Commenters ruining the internet? Moderate your comments or close them up. If some Web 2.0 blowhard says something stupid, just don't look. Hate blonde socialites? Just. Don't. Look.</p>
</blockquote>
<p>I am absolutely sick to death of hearing about Susan Boyle, both in the traditional media and online. Nothing personal, you understand, I'm sure she's a perfectly lovely person. But I don't talk about Susan Boyle, because talking about her gives Susan Boyle power and currency. I just ignore Susan Boyle. I wish I had two brains so I could ignore her twice as hard. <b>I. Just. Don't. Look.</b> And if we could convince enough people to ignore her, she .. <i>disappears</i>. Poof. Like magic.</p>
<p>One of my favorite books as a child was <a href="http://en.wikipedia.org/wiki/The_Great_Brain">the Great Brain series</a>, the story of a family in rural Utah, set in the late 1800s.</p>
<p><a href="http://en.wikipedia.org/wiki/The_Great_Brain"><img alt="image placeholder" >
<p>In these books, the parents doled out a strange punishment to their children when they seriously misbehaved. For a period of a week, or longer – depending on the severity of the misbehavior – nobody in the family would talk to, acknowledge, or address in any way, that particular boy. It was called <b>"The Silent Treatment"</b>.</p>
<blockquote>
<p>Tom and I were the most unfortunate kids in town.</p>
<p>When any other kids did something wrong, all they got was a whipping. When Tom and I did something wrong, we got the silent treatment, which was ten times worse than a whipping. It meant that Papa and Mamma wouldn't speak to us, and if we spoke to them, they would pretend they didn't hear us. It was as if Tom and I didn't exist as far as they were concerned during the silent treatment. How I wished they would act like normal parents and give us a whipping, and get it all over with in a hurry.</p>
</blockquote>
<p>This didn't seem like much of a punishment to me. In fact, as an introverted kid who loved solitary activities like computers and reading more than anything, it seemed kind of like a .. <i>reward</i>. I couldn't reconcile this feeling with the semi-biographical reality depicted in the books. To the Fitzgerald boys, the silent treatment was the worst possible punishment, far worse than a physical beating. They would go to incredible lengths to avoid getting the silent treatment. As punishments go, it must have been a doozy, though I couldn't quite wrap my geeky, socially maladjusted young head around exactly why.</p>
<p>The silent treatment was a punishment I didn't fully understand until years later in life. <i>That's</i> how you change the world. Not by arguing with people. Certainly not by screaming at them. You do it <b>by ignoring them.</b></p>
<p>And if you feel strongly enough about me and what I do here, you can begin by ignoring this.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/i-stopped-reading-your-blog-years-ago/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Sharing Files With BitTorrent ]]></title>
<link>https://blog.codinghorror.com/sharing-files-with-bittorrent/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.codinghorror.com/blog/archives/000795.html">Everybody loves BitTorrent</a>. And rightfully so.
</p>
<p>
</p>
<blockquote>
With <a href="http://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a>, you also start by placing your large file on a central server. But once the downloading begins, something magical happens: as clients download the file, they share whatever parts of the file they have with each other. Clients can opportunistically connect with any other client to obtain multiple parts of the file at once. And it scales perfectly: as file size and audience size increases, the bandwidth of the BitTorrent distribution network also increases. Your server does less and less work with each connected client. It's an elegant, egalitarian way of sharing large files with large audiences.
<p>
BitTorrent radically shifts the economics of distribution. It's one of the most miraculous ideas ever conceived on the internet. As far as I'm concerned, there should be a Nobel prize for computing, and <a href="http://en.wikipedia.org/wiki/Bram_Cohen">the inventor of BitTorrent</a> should be its first recipient.
</p>
</blockquote>
<p>
I've been a happy <a href="http://www.codinghorror.com/blog/archives/000978.html">consumer of files distributed via BitTorrent</a> for years; it was only natural that I would turn to BitTorrent to distribute our cc-wiki licensed Stack Overflow data. I figured serving a several-hundred megabyte file with BitTorrent wouldn't be much harder than downloading one. Boy, was I ever wrong. <b>Sharing files with BitTorrent is <i>way</i> more complicated than downloading them!</b> After two frustrating hours, I finally came up with a relatively straightforward way to share a file via BitTorrent, and in the interests of saving future readers a little time, I'm documenting it here.
</p>
<p>
Now, I'm going to show you an easy way, but it isn't technically the <i>easiest</i> way. The easiest way is to let someone else do the sharing for you. If you own content that you want to share, <a href="http://legaltorrents.com/">LegalTorrents is the obvious choice</a>:
</p>
<p>
</p>
<blockquote>
LegalTorrents<sup>tm</sup> is an online digital media community.
<p>
We discover and distribute high quality open-license (Creative Commons) digital media and art, and provide support to Content Creators. We host creative content in its entirety, ensure fast, reliable downloads, and enable users to directly sponsor Content Creators and their work.
</p>
<p>
We distribute content with the full permission of the rights holders and use the peer-2-peer file-sharing technology called Bittorrent.
</p>
</blockquote>
<p>
The site is still in beta, but signup is a snap, because <a href="http://www.codinghorror.com/blog/archives/001121.html">they support OpenID</a>! I encourage anyone interested to check it out. If nothing else, <b>get the furtive thrill of actually downloading <i>legal</i> content through BitTorrent for once!</b> Yes, it can happen. Shocking, I know. Don't worry, you crazy kids can get right back to your regular non-copyright-respecting torrenting ways immediately afterwards.
</p>
<p>
Anyway, you can't start sharing files on LegalTorrents without some kind of special email-us-please permission, and I was in a hurry. I wanted to share files via BitTorrent <i>right now</i>. I did, and you can too! But you'll need a few things first:
</p>
<p>
</p>
<ol>
<li>A copy of <a href="http://www.utorrent.com/">uTorrent</a> (it's free!)<br>
<br>
</li>
<li>Your <b>external IP address</b>; if you don't know what it is, use <a href="http://www.whatismyipaddress.com/">http://www.whatismyipaddress.com</a> to find out.<br>
<br>
</li>
<li>The uTorrent <b>listen port</b>. This is under Options | Preferences | Connection. This is typically set randomly every time uTorrent starts, so you may want to specify a more memorable value here.<br>
<br>
</li>
<li>You must have <b>port forwarding properly configured</b> so the outside world can get to your IP address and the port specified above. A full discussion of how to do this is outside the scope of this post, but it usually starts with your firewall settings and/or router configuration. uTorrent has a fairly nice help page at Options | Speed Guide that's a good start; just click the <b>Test if port is forwarded properly</b> button on that dialog to begin.
</li>
</ol>
<p>
Here's where I hit a major roadblock: to share files via BitTorrent, <a href="http://en.wikipedia.org/wiki/BitTorrent_tracker">you need a tracker</a>.
</p>
<p>
</p>
<blockquote>
A BitTorrent tracker is a server that assists in the communication between peers using the BitTorrent protocol. It is also, in the absence of extensions to the original protocol, the only major critical point, as <b>clients are required to communicate with the tracker to initiate downloads</b>. Clients that have already begun downloading also communicate with the tracker periodically to negotiate with newer peers and provide statistics; however, after the initial reception of peer data, peer communication can continue without a tracker.
</blockquote>
<p>
Without a tracker, you're sort of hosed, as clients will never be able to find your file, much less each other. Unfortunately, most of the freely open, public trackers out there are sort of.. disreputable. And the LegalTorrents tracker won't track files unless they are on its creator whitelist, which involves that manual sign-up process. You've got precious few legit options for tracking, unless you're willing to take a trip to the wrong side of town, and associate yourself and your files with that kind of .. neighborhood. I wasn't.
</p>
<p>
Fortunately, uTorrent has a solution: <b>you can become your own tracker!</b>
</p>
<p>
</p>
<ol>
<li>in uTorrent, go to Options | Preferences | Advanced.
</li>
<li>Scroll down to <code>bt.enable_tracker</code> and set it to <code>True</code>
</li>
<li>Restart uTorrent.
</li>
</ol>
<p>
<img alt="image placeholder" >
</p>
<p>
Now, let's create the torrent for the file we want to host, which will point to our newly created tracker.
</p>
<p>
</p>
<ol>
<li>In uTorrent, click the Create New Torrent button.
</li>
<li>Select the file or directory you want to share.
</li>
<li>Enter your tracker in this format: <b>http://my-ip-address:my-port/announce</b>
</li>
<li>That's it! Click Create and save the new *.torrent file you've created.
</li>
</ol>
<p>
<img alt="image placeholder" >
</p>
<p>
Now go forth and share your *.torrent file with the world. Share it with anyone and everyone! The more the merrier! Any client that opens your *.torrent file <b>will attempt to connect to <i>your</i> tracker, download your file, and share it with other downloading clients in classic BitTorrent stylee</b>. Pat yourself on the back; you just shared a file with the world using the transformative distribution power of BitTorrent!
</p>
<p>
But you do have to keep uTorrent running as a desktop application all the time, which is sort of a bummer. What if you wanted to <b>share your file on a server</b>, or via a silent background process? No problem. It's just a few more steps:
</p>
<p>
</p>
<ol>
<li>Enable the uTorrent web interface under Preferences, Web UI. Note that the URL for it is, by default, <b>http://my-ip-address:my-port/gui/</b>, and it requires a username and password to be set here.<br>
<br>
</li>
<li>Obtain a copy of the <a href="http://support.microsoft.com/kb/137890">user-defined service utilities</a>, srvany.exe and instsrv.exe. Copy them to the same folder as uTorrent.exe.<br>
<br>
</li>
<li>Issue this command to make uTorrent run as a service:<br>
<br>
<pre>instsrv uTorrent "C:uTorrentsrvany.exe"</pre>
<br>
</li>
<li>Enter this registry file to set the path for the service named "uTorrent" you just created in the previous step:<br>
<br>
<pre>
Windows Registry Editor Version 5.00
[HKEY_LOCAL_MACHINESYSTEMCurrentControlSetServicesuTorrentParameters]
"Application"="C:uTorrentuTorrent.exe"
</pre>
<br>
</li>
<li>In Control Panel, Services, set the account that the uTorrent service will run under. Note that you must use the <i>same</i> account that you set uTorrent options with if you want the service to respect those settings, so plan accordingly.<br>
<br>
<img alt="image placeholder" >
<br>
<br>
</li>
<li>Start the uTorrent service.
</li>
</ol>
<p>
(Obviously, replace the above paths with the actual paths that you installed uTorrent to.)
</p>
<p>
Bam -- you're sharing files with the world using BitTorrent, even when you're not logged in.  You can control everything remotely, too, by navigating your browser to the WebUI URL.
</p>
<p>
Like so many things in Windows, it ain't pretty, but it gets the job done. It's ironic that BitTorrent, which is justly famous for equalizing the highly asymmetric nature of most people's internet connections, is itself so asymmetric when it comes to sharing: <b>trivially easy to consume, but awkward and confusing to share</b>. That's too bad, because BitTorrent is such a powerful tool for sharing. Hopefully this post demystifies the process a bit!
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/sharing-files-with-bittorrent/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Unix is Dead, Long Live Unix ]]></title>
<link>https://blog.codinghorror.com/unix-is-dead-long-live-unix/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.computerworld.com/action/article.do?command=printArticleBasic&amp;taxonomyName=Operating+Systems&amp;articleId=9133570&amp;taxonomyId=89">Unix turns 40: The past, present and future of a revolutionary OS</a> is fascinating reading.
</p>
<p>
</p>
<blockquote>
Forty years ago this summer, a programmer sat down and knocked out in one month what would become one of the most important pieces of software ever created.
<p>
<img alt="image placeholder" >
</p>
<p>
In August 1969, <a href="http://en.wikipedia.org/wiki/Ken_Thompson">Ken Thompson</a> (pictured at left), a programmer at AT&amp;T subsidiary Bell Laboratories, saw the month-long departure of his wife and young son as an opportunity to put his ideas for a new operating system into practice. He wrote the first version of Unix in assembly language for a wimpy Digital Equipment Corp. (DEC) PDP-7 minicomputer, spending one week each on the operating system, a shell, an editor and an assembler.
</p>
</blockquote>
<p>
The article is accompanied by <a href="http://commons.wikimedia.org/wiki/File:Unix_history-simple.png">a graph from wikipedia</a>, illustrating the lineage of the Unix family.
</p>
<p>
<a href="http://commons.wikimedia.org/wiki/File:Unix_history-simple.png"><img alt="image placeholder" >
</p>
<p>
To me, Unix has become synonymous with <a href="http://en.wikipedia.org/wiki/Linux">Linux</a>, and the open source movement in general. The last *nixes standing shake out as follows:
</p>
<p>
</p>
<table width="500">
<tr>
<td><b>Open Source</b></td>
<td><b>Mixed / Shared Source</b></td>
<td><b>Closed Source</b></td>
</tr>
<tr>
<td valign="top">
Minix<br>
Linux<br>
FreeBSD<br>
NetBSD<br>
OpenBSD<br>
OpenSolaris
</td>
<td valign="top">
Mac OS X
</td>
<td valign="top">
AIX<br>
OpenServer<br>
HP/UX
</td>
</tr>
</table>
<p>
I didn't realize there were that many closed source Unix variants still surviving in the wild. It's also odd how OS X brings us full circle with the original Unics and BSD licensing. If it's lonely in the "Closed" column, imagine the existential angst of being the only vendor in the "Mixed / Shared Source" column. (NB: I think the currently tiny category Apple occupies represents the future of commercial software, but that's a topic for another blog post.)
</p>
<p>
I've been primarily a Windows developer since the early 90s, but over time, <b>I've developed a grudging <a href="http://www.codinghorror.com/blog/archives/001046.html">respect</a> for Unix</b>. I think Michael Feathers <a href="http://beautifulcode.oreillynet.com/2008/01/on_loving_c.php">summarized it best</a>:
</p>
<p>
</p>
<blockquote>
There's something deep in software development that not everyone gets but the people at Bell Labs did. It's the undercurrent of "the New Jersey Style", "Worse is Better", and "the Unix philosophy" - and it's not just a feature of Bell Labs software either. You see it in the original Ethernet specification where packet collision was considered normal.. and the same sort of idea is deep in the internet protocol. It's deep awareness of design ramification - <b>a willingness to live with a little less to avoid the bigger mess and a willingness to see elegance in the real rather than the vision</b>.
</blockquote>
<p>
I find this to be deeply and profoundly true in everything I've ever worked on as a programmer, and to the extent that Unix reflects these philosophies, it is undeniably on the right path. Unlike Rich Skrenta, <a href="http://www.skrenta.com/2007/05/giving_up_on_microsoft.html">I didn't grow up as a Unix developer</a>, so I have come late in life to this appreciation. Joel Spolsky's take on the Unix / Windows divide, after reading <a href="http://www.amazon.com/dp/0131429019/?tag=codihorr-20">The Art of UNIX Programming</a>, is <a href="http://www.joelonsoftware.com/articles/Biculturalism.html">this</a>:
</p>
<p>
</p>
<blockquote>
What are the cultural differences between Unix and Windows programmers? There are many details and subtleties, but for the most part it comes down to one thing: Unix culture values code which is useful to other programmers, while Windows culture values code which is useful to non-programmers. This is, of course, a major simplification, but really, that's the big difference: are we programming for programmers or end users? Everything else is commentary.
</blockquote>
<p>
So on one side, you have hundreds of command line applications, built in wildly different styles, with thousands of arcane command line parameters, all of which can be flexibly combined together to accomplish almost anything. And on the other side, you have the <a href="http://www.codinghorror.com/blog/archives/000939.html">windows registry</a> and <a href="http://en.wikipedia.org/wiki/Microsoft_Foundation_Class_Library">MFC</a>.
</p>
<p>
Sometimes, <a href="http://www.codinghorror.com/blog/archives/000796.html">you just can't win</a>.
</p>
<p>
So, yes, I'm a fan of Unix. And I'm also a fan of Windows. I think it's worth studying what both are getting right and wrong, because as a programmer, I'm a fan of whatever the heck <i>works</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/unix-is-dead-long-live-unix/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Regular Expressions for Regular Programmers ]]></title>
<link>https://blog.codinghorror.com/regular-expressions-for-regular-programmers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you've followed my blog for any length of time, you know that <strong>I am a total regular expression fanboy</strong>. It's almost <a href="http://www.codinghorror.com/blog/archives/000245.html">embarrassing</a> how much I love the damn things. I'm pretty sure my teammates roll their eyes every time they see yet another class I've touched that has <code>using System.Text.RegularExpressions</code> at the top. You might as well rename it to <code>JeffHasBeenHere</code>.
</p>
<p>
I say that because I end up writing a lot of string handling code, even when people <a href="http://www.codinghorror.com/blog/archives/001172.html">tell me I shouldn't</a>. Now, I only advocate <a href="http://www.codinghorror.com/blog/archives/001016.html">responsible and judicious use of regular expressions</a> when you happen to be dealing with strings. In the wrong hands, regular expressions can be dangerous. You might end up wondering <a href="http://www.codinghorror.com/blog/archives/000214.html">if Q*Bert just vomited all over your source code</a>. Or you might be programming in Perl. Is there any difference? (<a href="http://www.instantrimshot.com/">instant rimshot</a>)
</p>
<p>
But I digress. Although I love regex, I've never been a fan of the classic regular expression reference book, Friedl's <a href="http://www.amazon.com/dp/0596528124/?tag=codihorr-20">Mastering Regular Expressions</a>. I found it dry, a bit academic, and lacking in practical real world examples. It just didn't speak to me as a working programmer in the way that regular expressions themselves did, and that was disappointing.
</p>
<p>
That's why I was so excited to discover that two of the gnarliest regex gurus I knew – <a href="http://www.just-great-software.com/aboutjg.html">Jan Goyvaerts</a> (author of <a href="http://www.regexbuddy.com/cgi-bin/affref.pl?aff=jatwood">RegexBuddy</a> and <a href="http://www.regular-expressions.info/">regular-expressions.info</a>) and <a href="http://blog.stevenlevithan.com/">Steven Levithan</a> (author of <a href="http://blog.stevenlevithan.com/code">XRegExp</a> and <a href="http://regexpal.com/">RegexPal</a>) – were putting their heads together to create <strong>a regular expression reference for the rest of us</strong>. I <em>immediately</em> pre-ordered it sight unseen.
</p>
<p>
That book is <a href="http://www.amazon.com/dp/1449319432/?tag=codihorr-20">Regular Expressions Cookbook</a>. It arrived a few days ago, and although my expectations were high, I think this book has exceeded even the loftiest expectations I had. It is <em>outstanding</em>.
</p>
<p>
<a href="http://www.amazon.com/dp/1449319432/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
What I love about this book is <s>two</s>three things:
</p>
<ol>
<li>It's filled with <strong>practical, real world examples of RegEx use</strong>. At every step of the way, from beginner to master level, you're building regular expressions that are actually useful in the wild, and not just abstract, obtuse academic exercises in solving string matching puzzles.<br><br>
</li>
<li>It covers all the <strong>common gotchas</strong> that you inevitably run into when you start building non-trivial regular expressions. Things like the sometimes massive (and painful) differences between regex libraries in various languages, subtle regex flavor quirks, catastrophic backtracking, unicode support, and so forth. These are all presented in context of the solutions, exactly as you'd encounter them in real programming. I know because I have the scars to prove it.<br><br>
</li>
<li>It was <b>updated and revised in the second edition</b> to reflect current flavor differences with new recipes, plus a whole new chapter on source code and log files. It also covers <a href="https://github.com/slevithan/xregexp">XRegExp</a>, an emerging standard, fully-featured regex library for JavaScript.
</li>
</ol>
<p>
<a href="http://www.amazon.com/dp/1449319432/?tag=codihorr-20">Regular Expressions Cookbook </a> manages to be simultaneously accessible and almost <em>ridiculously</em> comprehensive. I consider myself a fairly advanced regex user and about 50 pages in I've already had three big "oh, wow, I didn't realize that" moments. In my mind, at least, this completely replaces the Friedl book as the go-to reference for programmers of any skill level or background who seek regular expression enlightenment.
</p>
<p>
Needless to say, <em>recommended</em>.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/regular-expressions-for-regular-programmers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Wrong Level of Abstraction ]]></title>
<link>https://blog.codinghorror.com/the-wrong-level-of-abstraction/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/001267.html">Why Isn't My Encryption.. Encrypting?</a> we learned that your encryption is only as good as your <i>understanding</i> of the encryption code. And that the best encryption of all is <i>no</i> encryption, because you kept everything on the server, away from the prying eyes of the client.
</p>
<p>
In <a href="http://www.codinghorror.com/blog/archives/001268.html">The Bathroom Wall of Code</a> we learned the potential danger of copy-pasting code from the internet, and the continued importance of regular peer review for every line of code that enters your codebase, from whatever source.
</p>
<p>
I didn't anticipate this series becoming a trilogy, but apparently it has, because Thomas Ptacek of Matsano Security <a href="http://www.matasano.com/log/1749/typing-the-letters-a-e-s-into-your-code-youre-doing-it-wrong/">wrote a long blog entry about it</a>. A blog entry masquerading as an overly dramatic college screenplay, but still. These guys, unlike us, are real security experts, so it's worth reading.
</p>
<p>
But you don't have to read that screenplay, because I'm going to reveal the twist in the final act right here.
</p>
<p>
</p>
<ol>
<li>The root problem <i>wasn't</i> failing to understand the encryption.
</li>
<li>The root problem <i>wasn't</i> copy and pasting code from the internet.
</li>
<li>The root problem <i>wasn't</i> failing to peer review the code.
</li>
</ol>
<p>
Mr. Ptacek is absolutely right. The root problem was that <b>we were working at the wrong layer of abstraction</b>.
</p>
<p>
Rather than construct code from the low-level cryptography primitives provided in .NET, <b>we should have used a library to handle our encryption needs</b>. I'm reminded of a <a href="http://stackoverflow.com/questions/471597/is-jquery-always-the-answer">common Stack Overflow joke</a>:
</p>
<p>
</p>
<blockquote>
Q: How do I write this in JavaScript?
<p>
A: You don't. You use <a href="http://jquery.com/">JQuery</a>.
</p>
</blockquote>
<p>
You can save a tremendous amount of time and effort by using the browser-independent framework that JQuery has spent untold man-hours testing, debugging, and proving in the field. While there's nothing <i>wrong</i> with writing JavaScript, why not speed your development time by writing to the library instead? As I've always said, <a href="http://www.codinghorror.com/blog/archives/001145.html">don't reinvent the wheel, unless you plan on learning more about wheels</a>.
</p>
<p>
Abstractions are important. You could view most of computer programming history as slowly, painfully clawing our way up the evolutionary tree of abstraction -- from assembly language, to C, to Java, to JavaScript, all the way up to JQuery, where the air starts to get pretty darn thin. We've already layered an operating system, web browser, <i>and</i> interpreted scripting language on top of each other to get to this point. It's a <a href="http://www.codinghorror.com/blog/archives/000277.html">testament to the power of abstraction</a> that any of it works at all.
</p>
<p>
Getting back to specifics: how can you stop programmers from working at the wrong layer of abstraction? One solution would be to <b>disallow the .NET encryption primitives entirely</b>. This is akin to Steve Gibson's <a href="http://technet.microsoft.com/en-us/library/cc751041.aspx">holy crusade against raw socket programming in Windows XP</a>. That's one way to do it, I suppose. But putting roadblocks in front of programmers is tantamount to a challenge; why not offer them more attractive alternatives, instead?
</p>
<p>
Hiding the low-level encryption primitives feels like a temporary solution. That said, I'd <i>strongly</i> recommend marking some of the older encryption methods as <b>deprecated</b>, so programmers who do stumble down some dusty old code path at least have some warning sign that they're using an algorithm with a lot of known vulnerabilities. I'm envisioning a <a href="http://www.codinghorror.com/blog/archives/000424.html">Clippy that pops up</a> with something like:
</p>
<p>
</p>
<blockquote>
"Hey! It looks like you're using a method of encryption that's widely regarded as insecure by security experts! Would you like to see alternatives?"
</blockquote>
<p>
One of those alternatives would be a full-blown library, perhaps something like <a href="http://www.bouncycastle.org/">Bouncy Castle</a>, or <a href="http://www.keyczar.org/">Keyczar</a>, or <a href="http://www.cs.auckland.ac.nz/~pgut001/cryptlib/">cryptlib</a>. What could be easier than a <code>EncryptStringForBrowser()</code> method which has security and tamper-resistance built in, that's part of a proven, domain-expert-tested set of code that thousands if not millions of developers already rely on?
</p>
<p>
Using encryption libraries doesn't mean that crucial encryption mistakes will magically disappear overnight. But these libraries, because they force developers to work at a higher level of abstraction, do make it <i>harder</i> to misuse cryptography. And perhaps more importantly, usability improvements to the library can be better handled by the specialists who created the library, rather than the generalists working on the .NET framework itself.
</p>
<p>
So the next time you set out to write code -- not just encryption code, <i>any</i> code -- ask yourself: <b>am I working at the right level of abstraction?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-wrong-level-of-abstraction/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Url Shorteners: Destroying the Web Since 2002 ]]></title>
<link>https://blog.codinghorror.com/url-shorteners-destroying-the-web-since-2002/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Is anyone else as sick as I am of all the mainstream news coverage on <a href="http://twitter.com">Twitter</a>? Don't get me wrong, I'm a Twitter fan, and I've been a <a href="http://twitter.com/codinghorror">user</a> since 2006. To me, it's a form of <a href="http://www.codinghorror.com/blog/archives/000840.html">public instant messaging</a> -- yet another way to <a href="http://www.codinghorror.com/blog/archives/000854.html">maximize the value of my keystrokes</a>. Still, I'm a little perplexed as to the media's near-<i>obsession</i> with the service. If a day goes by now without the New York Times or CNN mentioning Twitter in some way, I become concerned. Am I really getting <i>all</i> the news? Or just the stupid, too long, non-140-character version of the news?
</p>
<p>
I guess I should be pleased that I was a (relatively) early adopter and advocate of software that has achieved the rarest of feats in the software industry -- critical mass. Adoption by the proverbial "average user". Whatever you may think of Twitter, consider this: as a software developer, you'll be fortunate to build <i>one</i> project that achieves critical mass in your entire life. And even then, only if you are a very, <i>very</i> lucky programmer: in the right place, at the right time, with the right idea, working with the right people. Most of us never get there. I don't think I will.
</p>
<p>
There is one side effect of this unprecedented popularity, though, that I definitely wouldn't have predicted: <b>the mainstreaming of URL shortening services</b>. You can barely use Twitter without being forced into near-mastery of URL shortening. For example, this is the super-secret, patented formula I often use when composing <a href="http://twitter.com/codinghorror">my Twitter messages</a>:
</p>
<p>
</p>
<blockquote>
"brief summary or opinion" [link for more detail]
</blockquote>
<p>
Twitter only allows 140 characters in each status update. Some might view this as a limitation, but I consider it Twitter's best feature. I am all for enforced brevity. Maybe that's due to the pain of living through <a href="http://www.codinghorror.com/blog/archives/001191.html">a lifetime of e<s>m</s>fail</a>. But depending on the size of the comment and the URL (and some URLs can be ridiculously long), I can't <i>quite</i> fit everything in there without sounding like an SMS-addled teenage girl. This is where URL shortening comes in.
</p>
<p>
Now, I know what you're thinking. You're a clever programmer. <i>You</i> could implement some kind of fancy jQuery callback to shorten the URL, and replace the longer URL with the shorter URL right there in the text as the user pauses in typing. But you don't even have to be that clever; most of the URL shortening services (that aren't in their infancy) deliver a rather predictable size for the URLs they return. You could simply estimate the size of the URL post-shortening -- maybe adding 1 character as a fudge factor for safety -- and allow the update.
</p>
<p>
Twitter, I can assure you, is far more brain damaged than you can possibly imagine. It will indeed shorten URLs that fit in the 140 character limit (whoopee!), but it does <i>nothing</i> for URLs that don't fit -- it will not allow you to submit the message. All part of its endearing charm.
</p>
<p>
Lame, yes, but it means that the typical, mainstream browser-based Twitter user <b>is forced to become proficient with URL shortening services</b>.  Due to the increased exposure they've enjoyed through Twitter's meteoric rise to fame, the number of URL shortening services has exploded, and rapidly evolved -- they're no longer viewed as utility services to make URLs more convenient, but <b>a way to subjugate, control, and perhaps worst of all, "monetize" the web experience</b>.
</p>
<p>
This is dangerous territory we're veering into now, <a href="http://joshua.schachter.org/2009/04/on-url-shorteners.html">as Joshua Schachter explains</a>.
</p>
<p>
</p>
<blockquote>
So there are clear benefits for both the service (low cost of entry, potentially easy profit) and the linker (the quick rush of popularity). But URL shorteners are bad for the rest of us.
<p>
The worst problem is that shortening services add another layer of indirection to an already creaky system. A regular hyperlink implicates a browser, its DNS resolver, the publisher's DNS server, and the publisher's website. With a shortening service, you're adding something that acts like a third DNS resolver, except one that is assembled out of unvetted PHP and MySQL, without the benevolent oversight of luminaries like Dan Kaminsky and St. Postel.
</p>
</blockquote>
<p>
The web is little more than a maze of hyperlinks, and if you can insert yourself as an intermediary in that maze, you can transform or undermine the experience in fundamental ways. Consider the <a href="http://en.wikipedia.org/wiki/URL_shortening#History">disturbing directions newer URL shortening services are taking</a>:
</p>
<p>
</p>
<ul>
<li>NotifyURL sends an email when the link is first visited.
</li>
<li>SnipURL introduces social bookmarking features such as usernames and RSS feeds.
</li>
<li>DwarfURL generates statistics.
</li>
<li>Adjix, XR.com and Linkbee are ad-supported models of URL shorteners that share the revenue with their users.
</li>
<li>bit.ly offers gratis click-through statistics and charts.
</li>
<li>Digg offers a shortened URL which includes not just the target URL, but an iframed version that includes a set of Digg-related controls called the Digg bar.
</li>
<li>Doiop allows the shortening to be selected by the user, and Unicode can be used to achieve really short URLs.
</li>
</ul>
<p>
Believe it: <b>the humble hyperlink, thanks to pervasive URL shortening, can now be wielded as a weapon</b>. The internet is <a href="http://www.codinghorror.com/blog/archives/001132.html">the house that PageRank built</a>, and it's all predicated on hyperlinks. Once you start making every link your special flavor of "shortened" link, framing the target content -- heck, maybe wrapping it in a few ads for good measure -- you've completely turned that system on its head.
</p>
<p>
What's aggravating to me is that <b>the current situation is completely accidental</b>. If Twitter had provided a sane way to link a single word, none of these weaselly URL shortening clones would have reared their ugly heads at all. Consider how simple it is to decouple the hyperlink from the display text in, say, phpBB, or Markdown, or even good old HTML markup itself:
</p>
<p>
</p>
<pre>
&lt;a href="http://example.com"&gt;foo&lt;/a&gt;
[url=http://example.com]foo[/url]
[foo](http://example.com)
</pre>
<p>
Every tiny URL is <b>another baby step towards destroying the web as we know it</b>. Which is exactly what you'd want to do if you're attempting to <a href="http://www.readwriteweb.com/archives/bitly_alternative_to_tinyurl.php">build a business on top of the ruins</a>. Personally, I'd prefer to see the big, objective search engines who naturally sit at the center of the web offer their own URL shortening services. Who better to generate <a href="http://www.codinghorror.com/blog/archives/000935.html">short hashes of every possible URL</a> than the companies who already have cached copies of every URL on the internet, anyway?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/url-shorteners-destroying-the-web-since-2002/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ We Done Been ... Framed! ]]></title>
<link>https://blog.codinghorror.com/we-done-been-framed/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In my previous post, <a href="http://www.codinghorror.com/blog/archives/001276.html">Url Shorteners: Destroying the Web Since 2002</a>, I mentioned that one of the "features" of the new generation of URL shortening services is to frame the target content.
</p>
<p>
Digg is one of the most popular sites to implement this strategy. Here's how it works. If you're logged in to <a href="http://digg.com/">Digg</a>, every target link you click from Digg is a shortened URL of their own creation. If I click through to a Stack Overflow article someone else has "Dugg", I'm sent to this link.
</p>
<p>
<a href="http://digg.com/d1tBya">http://digg.com/d1tBya</a>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
For logged in users, every outgoing Digg link is framed inside the <a href="http://digg.com/tools/diggbar">"DiggBar"</a>. It's a way of dragging the Digg experience with you wherever you go -- while you're reading the target article, you can vote it up, see related articles, share, and so forth. And if you share this shortened URL with other users, they'll get the same behavior, provided they also hold a Digg login cookie.
</p>
<p>
At this point you're probably expecting me to rant about how evil the DiggBar is, and how it, too, is destroying the web, etcetera, etcetera, so on, and so forth. But I can't muster the indignant rage. I can give you, at best, ambivalence. Here's why:
</p>
<p>
</p>
<ol>
<li>The DiggBar is not served to the vast majority of anonymous users, but only to users who have opted in to the Digg experience by signing up.
</li>
<li>The <a href="http://www.google.com/support/webmasters/bin/answer.py?hl=en&amp;answer=139394">new rel="canonical" directive</a> is used on target links so search engines can tell which links are the "real", authoritative links to the content. They won't be confused or have search engine juice diluted by Digg's shortened URLs. At least that's the theory, anyway.
</li>
<li>No Digg ads are served via the DiggBar, so the framed content is not "wrapped" in ads.
</li>
<li>I believe Digg users themselves can opt out of DiggBar via a preferences setting.
</li>
</ol>
Digg is trying to build a business, just like we are with Stack Overflow. I can't fault them for their desire to extend the Digg community outward a little bit, given the zillions of outgoing links they feed to the world. Particularly when they attempted to do so in a semi-ethical way, actively soliciting community feedback along the way.
<p>
In short, Digg isn't the problem. But even if they <i>were</i> -- if you don't want to be framed by the DiggBar, or any other website for that matter, you could <b>put so-called "frame-busting" JavaScript</b> in your pages.
</p>
<p>
</p>
<pre>
if (parent.frames.length &gt; 0) {
top.location.replace(document.location);
}
</pre>
<p>
Problem solved! This code (or the many frame-busting variants thereof) <i>does</i> work on the DiggBar. But not every framing site is as reputable as Digg. What happens when we put on our hypothetical black hats and start <a href="http://www.codinghorror.com/blog/archives/001123.html">designing for evil?</a>
</p>
<p>
I'll tell you what happens. <a href="http://coderrr.wordpress.com/2009/02/13/preventing-frame-busting-and-click-jacking-ui-redressing/">This happens</a>.
</p>
<p>
</p>
<blockquote>
<pre>
var prevent_bust = 0
window.onbeforeunload = function() { prevent_bust++ }
setInterval(function() {
if (prevent_bust &gt; 0) {
prevent_bust -= 2
window.top.location = 'http://server-which-responds-with-204.com'
}
}, 1)
</pre>
<p>
On most browsers a <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">204 (No Content) HTTP response</a> will do nothing, meaning it will leave you on the current page. But the request attempt will override the previous frame busting attempt, rendering it useless. If the server responds quickly this will be almost invisible to the user.
</p>
</blockquote>
<p>
When life serves you lemons, make a lemon cannon. Produce frame-busting-<i>busting</i> JavaScript. This code does the following:
</p>
<p>
</p>
<ul>
<li>increments a counter every time the browser attempts to navigate away from the current page, via the <code>window.onbeforeonload</code> event handler
</li>
<li>sets up a timer that fires every millisecond via <code>setInterval()</code>, and if it sees the counter incremented, changes the current location to an URL of the attacker's control
</li>
<li>that URL serves up a page with HTTP status code 204, which does not cause the browser to navigate anywhere
</li>
</ul>
<p>
Net effect: frame-busting busted. Which might naturally lead you to wonder -- <b>hey buster, can you bust the frame-busting buster?</b> And, if so, <a href="http://www.youtube.com/watch?v=Iw3G80bplTg">where does it end?</a>
</p>
<p>
</p>
<blockquote>
In the 1998 movie, <a href="http://www.imdb.com/title/tt0120609/">The Big Hit</a>, the protagonists kidnap the daughter of an extremely wealthy Japanese businessman. When they call to deliver the ransom notice, they turn to Gump who employs a brand name Trace Buster to prevent police from tracing the call.
<p>
<a href="http://www.imdb.com/title/tt0120609/"><img alt="image placeholder" >
</p>
<p>
Unbeknownst to Gump, the father has a Trace-Buster-Buster at his disposal. This in turn triggers Gump to use his Trace-Buster-Buster-Buster in an ever escalating battle to evade detection.
</p>
</blockquote>
<p>
What's really scary is that <a href="http://stackoverflow.com/questions/958997/frame-buster-buster-buster-code-needed">near as I can tell</a>, <b>there is no solution</b>. Due to cross-domain JavaScript security restrictions, it is almost impossible for the framed site to block or interfere with the parent page's evil JavaScript that is intentionally and aggressively blocking the framebusting.
</p>
<p>
<b>If an evil website decides it's going to frame your website, you <i>will</i> be framed. Period.</b> Frame-busting is nothing more than a false sense of security; it doesn't work. This was a disturbing revelation to me, because framing is the first step on the road to <a href="http://en.wikipedia.org/wiki/Clickjacking">clickjacking</a>:
</p>
<p>
</p>
<blockquote>
A clickjacked page tricks a user into performing undesired actions by clicking on a concealed link. On a clickjacked page, the attackers show a set of dummy buttons, then load another page over it in a transparent layer. <b>The users think that they are clicking the visible buttons, while they are actually performing actions on the hidden page.</b> The hidden page may be an authentic page, and therefore the attackers can trick users into performing actions which the users never intended to do and there is no way of tracing such actions later, as the user was genuinely authenticated on the other page.
<p>
For example, a user might play a game in which they have to click on some buttons, but another authentic page like a web mail site from a popular service is loaded in a hidden iframe on top of the game. The iframe will load only if the user has saved the password for its respective site. The buttons in the game are placed such that their positions coincide exactly with the select all mail button and then the delete mail button. The consequence is that the user unknowingly deleted all the mail in their folder while playing a simple game. Other known exploits have been tricking users to enable their webcam and microphone through flash (which has since been corrected by Adobe), tricking users to make their social networking profile information public, making users follow someone on Twitter, etc.
</p>
</blockquote>
<p>
I've fallen prey to <a href="http://dsandler.org/wp/archives/2009/02/12/dontclick">a mild clickjacking exploit</a> on Twitter myself! It really does happen -- and it's not hard to do.
</p>
<p>
Yes, Digg frames ethically, so your frame-busting of the DiggBar will appear to work. But if the framing site is evil, good luck. When faced with a determined, skilled adversary that wants to frame your contnet, all bets are off. I don't think it's possible to escape. So consider this a wakeup call: you should build clickjacking countermeasures as if your website could be framed <i>at any time</i>.
</p>
<p>
I was a skeptic. I didn't want to believe it either. But once shown the exploits on our own site  -- fortunately, by a white hat security expert -- I lived to regret that. <b>Don't let frame-busting code lull you into a false sense of security, too.</b>
</p>
<p>
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/we-done-been-framed/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Monty Hall, Monty Fall, Monty Crawl ]]></title>
<link>https://blog.codinghorror.com/monty-hall-monty-fall-monty-crawl/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Remember <a href="http://www.codinghorror.com/blog/archives/001203.html">The Problem of the Unfinished Game</a>? And the almost 2,500 comments those two posts generated? I know, I like to pretend it didn't happen, either. Some <a href="http://paulbuchheit.blogspot.com/2009/01/question-is-wrong.html">objected to the way I asked the question</a>, but it was a simple question asked in simple language. I think what they're <em>really</em> objecting to is <strong>how unintuitive the answer is</strong>.</p>
<p>Which reminds me of another question that you've probably heard of:</p>
<blockquote>Suppose the contestants on a game show are given the choice of three doors: behind one door is a car; behind the others, goats. After a contestant picks a door, the host, who knows what's behind all the doors, opens one of the unchosen doors, which reveals a goat. He then asks the contestant, "Do you want to switch doors?"
<p><img alt="image placeholder" >
<p><strong>Should the contestant switch doors?</strong></p>
</blockquote>
<p>This is, of course, <a href="http://en.wikipedia.org/wiki/Monty_Hall_problem">the Monty Hall problem</a>. It's been covered to death, and quite well I might add, by dozens of writers who are <a href="http://www.codingthewheel.com/archives/21-and-the-monty-hall-paradox">far</a> <a href="http://dilbertblog.typepad.com/the_dilbert_blog/2008/04/monte-hall-prob.html">more</a> <a href="http://www.letsmakeadeal.com/problem.htm">talented</a> than I.</p>
<p>What's interesting about this problem, to me at least, is not the solution, but the vehemence with which people react to the solution – as described in <a href="http://www.amazon.com/dp/0375424040/?tag=codihorr-20">The Drunkard's Walk: How Randomness Rules Our Lives</a>.</p>
<p><a href="http://www.amazon.com/dp/0375424040/?tag=codihorr-20"><img alt="image placeholder" >
<blockquote>It appears to be a pretty silly question. Two doors are available – open one and you win; open the other and you lose – so it seems self-evident that whether you change your choice or not, your chances of winning are 50/50. What could be simpler? The thing is, Marilyn <a href="http://www.marilynvossavant.com/articles/gameshow.html">said in her column</a> that it is better to switch.
<p>Despite the public's much-heralded lethargy when it comes to mathematical issues, Marilyn's readers reacted as if she'd advocated ceding California back to Mexico. Her denial of the obvious brought her an avalanche of mail, 10,000 letters by her estimate. If you ask the American people whether they agree that plants create the oxygen in the air, light travels faster than sound, or you cannot make radioactive milk by boiling it, you will get double-digit disagreement in each case (13 percent, 24 percent, and 35 percent, respectively). But on this issue, <strong>Americans were united: Ninety-two percent agreed Marilyn was wrong.</strong></p>
</blockquote>
<p>Perhaps the public can be forgiven their ignorance, but what of the experts? Surprisingly, the mathematicians fare little better.</p>
<blockquote>Almost 1,000 Ph.D.s wrote in, many of them math professors, who seemed especially irate. "You blew it," wrote a mathematician from George Mason University. From Dickinson State University came this: "I am in shock that after being corrected by at least three mathematicians, you still do not see your mistake." From Georgetown: "How many irate mathematicians are needed to change your mind?" And someone from the U.S. Army Research Institute remarked, "If all those Ph.D.s are wrong the country would be in serious trouble." Responses continued in such great numbers and for such a long time that after devoting quite a bit of column space to the issue, Marilyn decided she whould no longer address it.
<p>The army PhD who wrote in may have been correct that if all those PhDs were wrong, it would be a sign of trouble. But Marilyn <em>was</em> correct. When told of this, <a href="http://en.wikipedia.org/wiki/Paul_Erdos">Paul Erdos</a>, one of the leading mathematicians of the 20th century, said, "That's impossible." Then, when presented with a formal mathematical proof of the correct answer, he still didn't believe it and grew angry. Only after a colleague arranged for a computer simulation in which Erdos watched hundreds of trials that came out 2-to-1 in favor of switching did Erdos concede that he was wrong.</p>
</blockquote>
<p>You may recognize Paul Erdos from a <a href="http://xkcd.com/599/">particularly obscure XKCD cartoon</a> last week. So if <em>you</em> feel like an idiot because you couldn't figure out the Monty Hall problem, take heart. <strong>The problem is so unintuitive one of the most notable mathematicians of the last century couldn't wrap his head around it.</strong> That's ... well, that's <em>amazing</em>.</p>
<p>How can something that seems so obvious be so wrong? Apparently our brains are not wired to do these sorts of probability problems very well. Personally, I found the text of Jeffrey Rosenthal's <a href="http://www.probability.ca/jeff/writing/montyfall.pdf">Monty Hall, Monty Fall, Monty Crawl</a> (pdf) to be the most illuminating, because it asks us to consider some related possibilities, and how they might affect the outcome:</p>
<blockquote>
<strong>Monty Fall Problem</strong>: In this variant, once you have selected one of the three doors, the host slips on a banana peel and accidentally pushes open another door, which just happens not to contain the car. Now what are the probabilities that you will win, either by sticking with your original door, or switching doors?
<p><strong>Monty Crawl Problem</strong>: Once you have selected one of the three doors, the host then reveals one non-selected door which does not contain the car. However, the host is very tired, and crawls from his position (near Door #1) to the door he is to open. In particular, if he has a choice of doors to open, then he opens the smallest number available door. (For example, if you selected Door #1 and the car was indeed behind Door #1, then the host would always open Door #2, never Door #3.) Now what are the probabilities that you will win the car if you stick versus if you switch?</p>
</blockquote>
<p>Paul Erdos was brilliant, but even he realized his own limits when presented with the highly unintuitive Monty Hall problem. For his epitaph, he suggested, in his native Hungarian, "Végre nem butulok tovább". This translates into English as "I've finally stopped getting dumber."</p>
<p>If only the rest of us could be so lucky.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/monty-hall-monty-fall-monty-crawl/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Scaling Up vs. Scaling Out: Hidden Costs ]]></title>
<link>https://blog.codinghorror.com/scaling-up-vs-scaling-out-hidden-costs/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/001195.html">My Scaling Hero</a>, I described the amazing scaling story of plentyoffish.com. It's impressive by any measure, but also particularly relevant to us because we're on the Microsoft stack, too. I was intrigued when Markus <a href="http://plentyoffish.wordpress.com/2009/06/14/upgrades-themes-date-night/">posted this recent update</a>:
</p>
<p>
</p>
<blockquote>
Last monday we upgraded our core database server after a power outage knocked the site offline. I haven't touched this machine since 2005 so it was a major undertaking to do it last minute. We upgraded from a machine with 64 GB of ram and 8 CPUs to <b>a HP ProLiant DL785 with 512 GB of ram and 32 CPUs</b> ...
</blockquote>
<p>
The <a href="http://h10010.www1.hp.com/wwpc/us/en/en/WF05a/15351-15351-3328412-241644-3328423-3716072.html">HP ProLiant DL785 G5</a> <i>starts</i> at $16,999 -- and that's barebones, with nothing inside. Fully configured, as Markus describes, it's <a href="http://h18004.www1.hp.com/products/quickspecs/13046_na/13046_na.html">kind of a monster</a>:
</p>
<p>
</p>
<ul>
<li>7U size (a typical server is 2U, and mainstream servers are often 1U)
</li>
<li>8 CPU sockets
</li>
<li>64 memory sockets
</li>
<li>16 drive bays
</li>
<li>11 expansion slots
</li>
<li>6 power supplies
</li>
</ul>
<p>
It's unclear if they bought it pre-configured, or added the disks, CPUs, and memory themselves. The most expensive configuration shown on the HP website is $37,398 and that includes only 4 processors, no drives, and a paltry 32 GB memory. When topped out with ultra-expensive 8 GB memory DIMMs, 8 high end Opterons, 10,000 RPM hard drives, and everything else -- by my estimates, it probably <b>cost closer to $100,000</b>. That might even be a lowball number, considering that <a href="http://www.tpc.org/results/individual_results/HP/HP_DL785_300G_11-17-2008_ES.pdf">the DL785 submitted to the TPC benchmark website</a> (pdf) had a "system cost" of $186,700. And that machine only had 256 GB of RAM. (But, to be fair, that total included another major storage array, and a bunch of software.)
</p>
<p>
At any rate, let's assume $100,000 is a reasonable ballpark for the monster server Markus purchased. It is the very definition of <b>scaling up</b> -- a seriously big iron single server.
</p>
<p>
But what if you <b>scaled out</b>, instead -- <a href="http://hadoop.apache.org/">Hadoop</a> or <a href="http://labs.google.com/papers/mapreduce.html">MapReduce</a> style, across lots and lots of inexpensive servers? After some initial configuration bumps, I've been happy with the inexpensive Lenovo ThinkServer RS110 servers we use. They're no match for that DL785 -- but they aren't exactly chopped liver, either:
</p>
<p>
</p>
<table width="400">
<tr>
<td>Lenovo ThinkServer RS110 barebones</td>
<td>$600</td>
</tr>
<tr>
<td>8 GB RAM</td>
<td>$100</td>
</tr>
<tr>
<td>2 x eBay <a href="http://www.codinghorror.com/blog/archives/001200.html">drive brackets</a>
</td>
<td>$50</td>
</tr>
<tr>
<td>2 x 500 GB SATA hard drives, mirrored</td>
<td>$100</td>
</tr>
<tr>
<td>Intel Xeon X3360 2.83 GHz quad-core CPU</td>
<td>$300</td>
</tr>
</table>
<p>
Grand total of <b>$1,150</b> per server. Plus another 10 percent for tax, shipping, and so forth. I replace the bundled CPU and memory that the server ships with, and then resell the salvaged parts on eBay for about $100 -- so let's call the total price per server $1,200.</p>
<p>
Now, assuming a <b>fixed spend of $100,000</b>, we could build <b>83</b> of those 1U servers. Let's compare what we end up with for our money:
</p>
<p>
</p>
<table width="400">
<tr>
<td> 
</td>
<td align="right">
<b>Scaling Up</b>
</td>
<td align="right">
<b>Scaling Out</b>
</td>
</tr>
<tr>
<td>CPUs
</td>
<td align="right">32
</td>
<td align="right">332
</td>
</tr>
<tr>
<td>RAM
</td>
<td align="right">512 GB
</td>
<td align="right">664 GB
</td>
</tr>
<tr>
<td>Disk
</td>
<td align="right">4 TB
</td>
<td align="right">40.5 TB
</td>
</tr>
</table>
<p>
<i>Now</i> which approach makes more sense?
</p>
<p>
(These numbers are a bit skewed because that DL785 is at the absolute extreme end of the big iron spectrum. You pay a hefty premium for fully maxxing out. It is possible to build a slightly less powerful server with <i>far</i> better bang for the buck.)
</p>
<p>
But there's something else to consider: software licensing.
</p>
<p>
</p>
<table width="400">
<tr>
<td> 
</td>
<td align="right">
<b>Scaling Up</b>
</td>
<td align="right">
<b>Scaling Out</b>
</td>
</tr>
<tr>
<td>OS
</td>
<td align="right">$2,310
</td>
<td align="right">$33,200*
</td>
</tr>
<tr>
<td>SQL
</td>
<td align="right">$8,318
</td>
<td align="right">$49,800*
</td>
</tr>
</table>
<p>
(If you're using all open source software, then of course these costs will be very close to zero. We're assuming a Microsoft shop here, with the necessary licenses for Windows Server 2008 and SQL Server 2008.)
</p>
<p>
<i>Now</i> which approach makes more sense?
</p>
<p>
What about the power costs? Electricity and rack space isn't free.
</p>
<p>
</p>
<table width="400">
<tr>
<td> 
</td>
<td align="right">
<b>Scaling Up</b>
</td>
<td align="right">
<b>Scaling Out</b>
</td>
</tr>
<tr>
<td>Peak Watts
</td>
<td align="right">1,200w
</td>
<td align="right">16,600w
</td>
</tr>
<tr>
<td>Power Cost / Year
</td>
<td align="right">$1,577
</td>
<td align="right">$21,815
</td>
</tr>
</table>
<p>
<i>Now</i> which approach makes more sense?
</p>
<p>
I'm not picking favorites. This is presented as food for thought. There are at least a dozen other factors you'd want to consider depending on the particulars of your situation. Scaling up and scaling out are <i>both</i> viable solutions, depending on what problem you're trying to solve, and what resources (financial, software, and otherwise) you have at hand.
</p>
<p>
That said, I think it's fair to conclude that <b>scaling out is only frictionless when you use open source software</b>. Otherwise, you're in a bit of a conundrum: scaling up means paying less for licenses and a lot more for hardware, while scaling out means paying less for the hardware, and a <i>whole</i> lot more for licenses.
</p>
<p>
<small>* I have <i>no</i> idea if these are the right prices for Windows Server 2008 and SQL Server 2008, because <a href="http://www.microsoft.com/Sqlserver/2005/en/us/licensing.aspx">reading about the licensing models makes my brain hurt</a>. If anything, it could be substantially more.</small>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/scaling-up-vs-scaling-out-hidden-costs/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The iPhone Software Revolution ]]></title>
<link>https://blog.codinghorror.com/the-iphone-software-revolution/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The original iPhone was for <s>suckers</s> <a href="http://www.codinghorror.com/blog/archives/000896.html">hard-core gadget enthusiasts only</a>. But as I predicted, 12 months later, the iPhone 3G rectified all the shortcomings of the first version. And now, with the iPhone 3GS, we've reached the <a href="http://www.seattlepi.com/business/palm18.shtml">mythical third version</a>:
</p>
<p>
</p>
<blockquote>
A computer industry adage is that Microsoft does not make a successful product until version 3. Its Windows operating system was not a big success until the third version was introduced in 1990 and, similarly, its Internet Explorer browsing software was lackluster until the third version.
</blockquote>
<p>
The platform is now so compelling and polished that <b>even I took the plunge</b>. For context, this is the first Apple product I've owned <a href="http://www.codinghorror.com/blog/archives/001051.html">since 1984</a>. Literally.
</p>
<p>
I am largely ambivalent towards Apple, but it's impossible to be ambivalent about the iPhone -- and in particular, <a href="http://www.apple.com/iphone/iphone-3gs/">the latest and greatest iPhone 3GS</a>. It is the Pentium to the 486 of the iPhone 3G. A landmark, genre-defining product, no longer a mere smartphone but an honest to God fully capable, no-compromises <i>computer</i> in the palm of your hand.
</p>
<p>
Here's how far I am willing to go: <b>I believe the iPhone will ultimately be judged a more important product than the original Apple Macintosh</b>.
</p>
<p>
<a href="http://www.apple.com/iphone/iphone-3gs/"><img alt="image placeholder" >
</p>
<p>
Yes, I am dead serious. Just check back here in fifteen to twenty years to see if I was right. (Hint: I will be.)
</p>
<p>
There's always been a weird tension in Apple's computer designs, because they attempt to control every nuance of the entire experience from end to end. For the best Apple<sup>tm</sup> experience, you run custom Apple<sup>tm</sup> applications on <a href="http://www.codinghorror.com/blog/archives/001044.html">artfully designed Apple<sup>tm</sup> hardware dongles</a>. That's fundamentally at odds with the classic hacker mentality that birthed the general purpose computer. You can see it in the wild west, anything goes Linux ecosystem. You can even see it in the Wintel axis of evil, where a million motley mixtures of hardware, software, and operating system variants are allowed to bloom, like little beige stickered flowers, for a price.
</p>
<p>
But a cell phone? It's a closed ecosystem, by <i>definition</i>, running on a proprietary network. By <b>a status quo of incompetent megacorporations who wouldn't know user friendliness or good design if it ran up behind them and bit them in the rear end of their expensive, tailored suits</b>. All those things that bugged me about Apple's computers are utter non-issues in the phone market. Proprietary handset? So is every other handset. Locked in to a single vendor? Everyone signs a multi-year contract. One company controlling your entire experience? That's how it's always been done. Nokia, Sony/Ericsson, Microsoft, RIM -- these guys clearly had no <i>idea</i> what they were in for when Apple set their sights on the cell phone market -- a market that is a nearly perfect match to Apple's strengths.
</p>
<p>
<b>Apple was <i>born</i> to make a kick-ass phone</b>. And with the lead they have, I predict they will dominate the market for years to come.
</p>
<p>
Consider all the myriad devices that the iPhone 3GS can sub for, and in some cases, outright replace:
</p>
<p>
</p>
<ul>
<li>GPS
</li>
<li>Netbook (for casual web browsing and email)
</li>
<li>Gameboy
</li>
<li>Watch
</li>
<li>Camera
</li>
<li>MP4 Video Recorder
</li>
<li>MP3 player
</li>
<li>DVD player
</li>
<li>eBook reader
</li>
</ul>
<p>
Oh yeah, and I heard you can make phone calls with it, too. Like any general purpose computer, it's a jack of all trades.
</p>
<p>
As <a href="http://www.anandtech.com/gadgets/showdoc.aspx?i=3587">impressive as the new hardware is</a>, the software story is even bigger. If you're a software developer, the iPhone can become a <b>career changing device</b>, all thanks to one little teeny-tiny icon on the iPhone home screen:
</p>
<p>
<a href="http://www.apple.com/iphone/apps-for-iphone/"><img alt="image placeholder" >
</p>
<p>
The <a href="http://www.apple.com/iphone/apps-for-iphone/">App Store</a> makes it <i>brainlessly</i> easy to install, upgrade, and purchase new applications. But more importantly, any software developer -- at the mild entry cost of owning a Mac, and signing up for the <a href="http://developer.apple.com/iPhone/program/">$99 iPhone Developer Program</a> -- can build an app and sell it to the worldwide audience of iPhone users. Apple makes this stuff look <i>easy</i>, when historically it has been anything but. How many successful garage developers do you know for Nintendo DS? For the Motorola Razr? For Palm? For Windows Mobile?
</p>
<p>
Apple has never been particularly great at supporting software developers, but I have to give them their due: with the iPhone developer program, <b>they've changed the game</b>. Nowhere is this more evident than in software pricing. I went on a software buying spree when I picked up my iPhone 3GS, ending up with almost three pages of new applications from the App Store. I was a little worried that I might rack up a substantial bill, but how can I resist when cool stuff like ports of the <a href="http://toucharcade.com/2009/05/15/pinball-dreaming-pinball-dreams-gets-a-lite-version/">classic Amiga Pinball Dreams</a> are available, or the <a href="http://toucharcade.com/2009/05/25/guru-meditation-a-peaceful-retro-relaxer/">historic Guru Meditation</a>? The list of useful (and useless) apps is almost endless, and growing every day.
</p>
<p>
My total bill for 3 screens worth of great iPhone software applications? <b>About fifty bucks</b>. I've paid more than that for Xbox 360 games I ended up playing for a total of maybe three hours! About half of the apps were free, and the rest were a few bucks. I think the most I paid was $9.99, and that was for <a href="http://blog.sangsara.net/2009/05/comparing-ebooks-classics-stanza-and.html">an entire library</a>.  What's revolutionary here isn't just the development ecosystem, but the economics that support it, too. <b>At these crazy low prices, why <i>not</i> fill your phone with cool and useful apps?</b> You might wonder if developers can really make a living selling apps that only cost 99 cents. Sure you can, if you sell hundreds of thousands of copies:
</p>
<p>
</p>
<blockquote>
Freeverse, one of the leading developers and publishers of iPhone games, <a href="http://news.freeverse.com/archives/2009/06/22/freeverses-flic.php">sold the millionth copy of its Flick Fishing game over the weekend</a>, making Flick Fishing the first paid application to reach the one million download milestone. Flick Fishing, which costs 99 cents, allows iPhone and iPod touch users to take a virtual fishing trip with the flick of a wrist. The game uses the iPhone's accelerometer to recreate a casting motion, then a combination of bait choice and fishing skill helps players land the big fish.
<p>
Preliminary weekly reports for the period from 23 March to 19 April indicate that Flight Control <a href="http://firemintgames.blogspot.com/2009/04/flight-control-sales-numbers.html">sold a total of 587,485 units during this time</a>. We estimate total sales are now over 700,000 units, with the bulk of sales occurring in a 3 week period.
Flight Control
</p>
</blockquote>
<p>
That's an honorable way to <a href="http://www.codinghorror.com/blog/archives/000872.html">get rich programming</a>, and a nice business alternative to the dog-eat-dog world of advertising subsidized apps.
</p>
<p>
I love nothing more than <a href="http://www.codinghorror.com/blog/archives/000735.html">supporting my fellow software developers</a> by voting with my wallet. it does my heart good to see so many indie and garage developers making it big on the iPhone. (Also, I'm a <a href="http://www.codinghorror.com/blog/archives/001135.html">sucker for physics games</a>, and there are a bunch of great ones available in the App Store). I'm more than happy to pitch in a few bucks every month for a great new iPhone app.
</p>
<p>
If this has all come across as too rah-rah, too uncritical a view of the iPhone, I apologize. There are certainly things to be critical about, such as the App Store's weird enforcement policies, the lack of support for emulators, or Flash, or anything else that might somehow undermine the platform as decided in some paranoid, secretive Apple back room. Not that we'd ever hear about it.
</p>
<p>
I didn't write this to kiss Apple's ass. I wrote this because I truly feel that the iPhone is a key inflection point in software development. We will look back on this as the time when "software" stopped being something that geeks buy (or worse, bootleg), and <b>started being something that <i>everyone</i> buys, every day</b>. You'd have to be a jaded developer indeed not to find something magical and transformative in this formula, and although others will clearly follow, the iPhone is leading the way.
</p>
<p>
"There's an app for that." Kudos, Apple. From the bottom of my hoary old software developer heart.
</p>
<p>
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-iphone-software-revolution/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ All Abstractions Are Failed Abstractions ]]></title>
<link>https://blog.codinghorror.com/all-abstractions-are-failed-abstractions/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In programming, <a href="http://www.advogato.org/person/Bram/diary.html?start=43">abstractions are powerful things</a>:
</p>
<p>
</p>
<blockquote>
Joel Spolsky has <a href="http://www.joelonsoftware.com/articles/LeakyAbstractions.html">an article</a> in which he states
<p>
</p>
<blockquote>
<i>All non-trivial abstractions, to some degree, are leaky.</i>
</blockquote>
<p>
This is overly dogmatic - for example, bignum classes are exactly the same regardless of the native integer multiplication. Ignoring that, this statement is essentially true, but rather inane and missing the point. Without abstractions, all our code would be completely interdependent and unmaintainable, and abstractions do a remarkable job of cleaning that up. <b>It is a testament to the power of abstraction and how much we take it for granted that such a statement can be made at all</b>, as if we always expected to be able to write large pieces of software in a maintainable manner.
</p>
</blockquote>
<p>
But they can cause problems of their own. Let's consider a particular <a href="http://msdn.microsoft.com/en-us/library/bb425822.aspx">LINQ to SQL</a> query, designed to retrieve the most recent 48 Stack Overflow questions.
</p>
<p>
</p>
<pre>
var posts =
(from p in DB.Posts
where
p.PostTypeId == PostTypeId.Question &amp;&amp;
p.DeletionDate == null &amp;&amp;
p.Score &gt;= minscore
orderby p.LastActivityDate descending
select p).
Take(maxposts);
</pre>
<p>
The big hook here is that <b>this is code the compiler actually understands</b>. You get code completion, compiler errors if you rename a database field or mistype the syntax, and so forth. Perhaps best of all, you get an honest to goodness <code>post</code> object as output! So you can turn around and immediately do stuff like this:
</p>
<p>
</p>
<pre>
foreach (var post in posts.ToList())
{
Render(post.Body);
}
</pre>
<p>
Pretty cool, right?
</p>
<p>
Well, that Linq to SQL query is functionally equivalent to this old-school SQL blob. More than functionally, <b>it is <i>literally</i> identical</b>, if you examine the SQL string that LINQ generates behind the scenes:
</p>
<p>
</p>
<pre>
string query =
"select top 48 * from Posts
where
PostTypeId = 1 and
DeletionDate is null and
Score &gt;= -4
order by LastActivityDate desc";
</pre>
<p>
This text blob is of course totally opaque to the compiler. Fat-finger a syntax error in here, and you won't find out about it until runtime. Even if it does run without a runtime error, processing the output of the query is awkward. It takes row level references and a lot of tedious data conversion to get at the underlying data.
</p>
<p>
</p>
<pre>
var posts = DB.ExecuteQuery(query);
foreach (var post in posts.ToList());
{
Render(post["Body"].ToString());
}
</pre>
<p>
So, LINQ to SQL is an abstraction -- we're <b>abstracting away raw SQL and database access in favor of native language constructs and objects</b>. I'd argue that Linq to SQL is a <i>good</i> abstraction. Heck, it's <a href="http://www.codinghorror.com/blog/archives/000033.html">exactly what I asked for five years ago</a>.
</p>
<p>
But even a good abstraction can break down in unexpected ways.
</p>
<p>
Consider this optimization, which is trivial in the old-school SQL blob code: instead of pulling down every single field in the post records, why not pull just the id number? Makes sense, if that's all I need. And it's faster -- much faster!
</p>
<p>
</p>
<table width="400">
<tr>
</tr>
<tr>
<td>select top 48 <font color="red">*</font> from Posts</td>
<td align="right">827 ms</td>
</tr>
<tr>
<td>select top 48 <font color="red">Id</font> from Posts</td>
<td align="right">260 ms</td>
</tr>
</table>
<p>
Selecting all columns with the star (*) operator is expensive, and that's what LINQ to SQL always does by default. Yes, <a href="http://mkdot.net/blogs/thearchitect/archive/2008/04/24/lazy-load-in-linq-to-sql.aspx">you can specify lazy loading</a>, but not on a per-query basis. Normally, this is a non-issue, because selecting all columns for simple queries is not all <i>that</i> expensive. And you'd think pulling down <b>48 measly little post records</b> would be squarely in the "not expensive" category!
</p>
<p>
So let's compare apples to apples. What if we got just the id numbers, then retrieved the full data for each row?
</p>
<p>
</p>
<table width="400">
<tr>
<td>select top 48 Id from Posts</td>
<td align="right">260 ms</td>
</tr>
<tr>
<td>select * from Posts where Id = 12345</td>
<td align="right">3 ms</td>
</tr>
</table>
<p>
Now, retrieving 48 individual records one by one is sort of silly, becase you could easily construct a single <code>where Id in (1,2,3..,47,48)</code> query that would grab all 48 posts in one go. But even if we did it in this naive way, the total execution time is still a very reasonable (48 * 3 ms) + 260 ms = 404 ms. <b>That is <i>half</i> the time of the standard select-star SQL emitted by LINQ to SQL!</b>
</p>
<p>
An extra 400 milliseconds doesn't sound like much, but <a href="http://radar.oreilly.com/2009/06/bing-and-google-agree-slow-pag.html">slow pages lose users</a>. And why in the world would you perform a slow database query on every single page of your website when you don't have to?
</p>
<p>
It's tempting to blame Linq, but is Linq really at fault here? These seem like <i>identical</i> database operations to me:
</p>
<p>
</p>
<blockquote>
1. Give me all columns of data for the top 48 posts.
</blockquote>
<p>
or
</p>
<p>
</p>
<blockquote>
1. Give me just the ids for the top 48 posts.<br>
2. Retrieve all columns of data for each of those 48 ids.
</blockquote>
<p>
So why in the wide, wide world of sports would one of these <b>seemingly identical operations</b> be twice as slow as the other?
</p>
<p>
The problem isn't Linq to SQL. The problem is that <b>we're attempting to spackle a nice, clean abstraction over a database that is full of highly irregular and unusual real world behaviors.</b> Databases that:
</p>
<p>
</p>
<ul>
<li>may not have the right indexes
</li>
<li>may misinterpret your query and generate an inefficient query plan
</li>
<li>are trying to perform an operation that doesn't fit well in available memory
</li>
<li>are paging data from disks which might be busy at that particular moment
</li>
<li>might contain irregularly sized column datatypes
</li>
</ul>
<p>
That's what's so frustrating. We can't just pretend all our data is formatted into neat, orderly data structures sitting there in memory, lined up in convenient little queues for us to reach out and casually scoop them up. As I've demonstrated, even trivial queries can have bizarre behavior and performance characteristics that are not at all clear.
</p>
<p>
To its credit, Linq to SQL is quite flexible: we can use strongly typed queries, or we can  use SQL blob queries that we cast to the right object type. That flexibility is critical, because <b>so much of our performance depends on these quirks of the database</b>. We default to the built-in Linq language constructs, and drop down to hand-tuning ye olde SQL blobs where the performance traces tell us we need to.
</p>
<p>
Either way, it's clear that you've <i>got</i> to know what's happening in the database every step of the way to even begin understanding the performance of your application, much less troubleshoot it.
</p>
<p>
I think you could make a fairly solid case that Linq to SQL is, in fact, a leaky and failed abstraction. Exactly the kind of thing Joel was complaining about. But I'd also argue that <b>virtually <i>all</i> good programming abstractions are failed abstractions</b>. I don't think I've ever used one that didn't leak like a sieve. But I think that's an awfully <a href="http://www.codinghorror.com/blog/archives/000165.html">architecture astronaut</a> way of looking at things. Instead, let's ask ourselves a more pragmatic question:
</p>
<p>
</p>
<blockquote>
Does this abstraction make our code at least a <i>little</i> easier to write? To understand? To troubleshoot? Are we better off <i>with</i> this abstraction than we were without it?
</blockquote>
<p>
It's our job as modern programmers not to abandon abstractions due to these deficiencies, but to embrace the useful elements of them, to adapt the working parts and construct ever so slightly <i>less</i> leaky and broken abstractions over time. Like desperate citizens manning a dike in a category 5 storm, <b>we programmers keep piling up these leaky abstractions, shoring up as best we can, desperately attempting to stay ahead of the endlessly rising waters of complexity.</b>
</p>
<p>
As much as I may curse Linq to SQL as yet another failed abstraction, I'll continue to use it. Yes, I may end up soggy and irritable at times. But it sure as <i>heck</i> beats drowning.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-06-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/all-abstractions-are-failed-abstractions/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Oh, You Wanted "Awesome" Edition ]]></title>
<link>https://blog.codinghorror.com/oh-you-wanted-awesome-edition/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>We recently upgraded our database server to 48 GB of memory -- because <a href="http://www.codinghorror.com/blog/archives/001198.html">hardware is cheap, and programmers are expensive</a>.</p>
<p>Imagine our surprise, then, when we rebooted the server and saw only 32 GB of memory available in Windows Server 2008. Did we install the memory wrong? No, the BIOS screen reported the full 48 GB of memory. In fact, the system information applet even reports 48 GB of memory:</p>
<p><img alt="image placeholder" >
<p>But there's only 32 GB of <em>usable</em> memory in the system, somehow.</p>
<p><img alt="image placeholder" >
<p>Did you feel that? A great disturbance in the Force, as if 17 billion bytes simultaneously cried out in terror and were suddenly silenced. It's so profoundly sad.</p>
<p>That's when I began to suspect the real culprit: <strong>weasels</strong>.</p>
<p><img alt="image placeholder" >
<p>No. Not the cute weasels. I'm referring to angry, evil <strong><em>marketing</em> weasels</strong>.</p>
<p><img alt="image placeholder" >
<p>That's more like it. Those marketing weasels are <em>vicious</em>.</p>
<p>We belatedly discovered post-upgrade that we are foolishly using Windows Server 2008 <strong>Standard</strong> edition. Which has been <a href="http://www.sadtrombone.com/">arbitrarily limited to 32 GB of memory</a>. Why? So the marketing weasels can <a href="http://www.joelonsoftware.com/articles/CamelsandRubberDuckies.html">segment the market</a>.</p>
<blockquote>It's sort of like if you were all set to buy that new merino wool sweater, and you <em>thought</em> it was going to cost $70, which is well worth it, and when you got to Banana Republic it was on sale for only $50! Now you have an extra $20 in found money that you would have been perfectly happy to give to the Banana Republicans!
<p>Yipes!</p>
<p>That bothers good capitalists. Gosh darn it, if you're <em>willing to do without it</em>, well, give it to me! I can put it to good use, buying a SUV or condo or Mooney or yacht one of those other things capitalists buy!</p>
<p>In economist jargon, capitalists want to capture the <a href="http://en.wikipedia.org/wiki/Consumer_surplus">consumer surplus</a>.</p>
<p>Let's do this. Instead of charging $220, <strong>let's ask each of our customers if they are rich or if they are poor. If they say they're rich, we'll charge them $349. If they say they're poor, we'll charge them $220.</strong></p>
<p>Now how much do we make? Back to Excel. Notice the quantities: we're still selling the same 233 copies, but the richest 42 customers, who were all willing to spend $349 or more, are being asked to spend $349. And our profits just went up! from $43K to about $48K! NICE!</p>
<p>Capture me some more of that consumer surplus stuff!</p>
</blockquote>
<p>How many versions of WIndows Server 2008 are there? <a href="http://www.microsoft.com/windowsserver2008/en/us/editions-overview.aspx">I count at least six</a>. They're capturing some <em>serious</em> consumer surplus, over there in Redmond.</p>
<ul>
<li>Datacenter Edition </li>
<li>Enterprise Edition </li>
<li>Standard Edition </li>
<li>Foundation </li>
<li>Web </li>
<li>HPC </li>
</ul>
<p>Already, I'm confused. <strong>Which one of these versions allows me to use all 48 GB of my server's memory?</strong> There are no less than six individual "compare" pages to slice and dice all the different features each version contains. Just try to <a href="http://www.microsoft.com/windowsserver2008/en/us/editions-overview.aspx">make sense of it all</a>. I dare you. No, I double dog dare you! Oh, and by the way, there's <em>zero</em> pricing information on any of these pages. So open another browser window and factor that into your decisionmaking, too.</p>
<p>I don't mean to single out Microsoft here; lots of companies use this segmented pricing trick. Even Web 2.0 darlings <a href="http://www.basecamphq.com/signup">37 Signals</a>.</p>
<p><img alt="image placeholder" >
<p>Heck, our very <em>own</em> product <a href="http://stackexchange.com/">segments the market</a>.</p>
<p><img alt="image placeholder" >
<p>37signals just does it .. prettier, that's all. They're still asking you if you're poor or rich, and charging you more if you're rich.</p>
<p>Eric Sink also advocates the same <a href="http://www.ericsink.com/bos/Product_Pricing.html">"rich customer, poor customer" software pricing policy</a>:</p>
<blockquote>In an ideal world, the price would be different for every customer. The "perfect" pricing scheme would charge every customer a different amount, extracting from each one the maximum amount they are willing to pay.
<ul>
<li>The IT guy at Podunk Lutheran College has no money: Gratis. </li>
<li>The IT guy at a medium-sized real estate agency has some money: $500. </li>
<li>The IT guy at a Fortune 100 company has tons of money: $50,000. </li>
</ul>
<p>You can never make your pricing "perfect," but you can do much better than simply setting one constant price for all situations. By carefully tuning all these details, you can <strong>find ways to charge more money from the people who are willing to pay more</strong>.</p>
</blockquote>
<p>This sort of pricing seems exploitative, but it <a href="http://www.codinghorror.com/blog/archives/000323.html">can also be an act of public good</a> -- remember that the <em>poorest</em> customers are paying less; with a one-size-fits-all pricing policy, they might not be able to afford the product at all. Drug companies often follow the same pricing model when selling life-saving drugs to third-world countries. First-world countries end up subsidizing the massive costs of drug development, but the whole world benefits.</p>
<p>What I object to isn't the money involved, but the mental overhead. The whole thing runs so contrary to the spirit of <a href="http://www.codinghorror.com/blog/archives/000377.html">Don't Make Me Think</a>. Sure, don't make us customers think. Unless you want us to think about <strong>how much we'd like to pay you</strong>, that is.</p>
<p>And what are we paying for? The privilege of flipping the magic bits in the software that say "I am <em>blah</em> edition!" It's all so.. anticlimactic. All that effort, all that poring over complex feature charts and stressing out about pricing plans, and for what? Just to get the one simple, stupid thing I care about -- using all the memory in my server.</p>
<p>Perhaps these complaints, then, point to one unsung advantage of open source software:</p>
<p><strong>Open source software only comes in one edition: <em>awesome</em>.</strong></p>
<p>The money is irrelevant; the expensive resource here is my brain. If I choose open source, I don't have to think about licensing, feature matrices, or recurring billing. I know, I know, <a href="http://www.codinghorror.com/blog/archives/001097.html">we don't use software that costs money here</a>, but I'd almost be willing to pay for the privilege of not having to think about that stuff <em>ever again</em>.</p>
<p>Now if you'll excuse me, I'm having trouble deciding between <a href="http://www.penny-arcade.com/comic/2007/02/02/">Windows 7 Smoky Bacon Edition and Windows 7 Kenny Loggins Edition</a>. Bacon is delicious, but I <em>also</em> love that <a href="http://www.imdb.com/title/tt0087277/">Footloose</a> song..</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/oh-you-wanted-awesome-edition/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Code: It's Trivial ]]></title>
<link>https://blog.codinghorror.com/code-its-trivial/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Remember that Stack Overflow thing we've been working on? Some commenters on a recent <a href="http://news.ycombinator.com/item?id=678398">Hacker News article</a> questioned the pricing of <a href="http://stackexchange.com">Stack Exchange</a> -- essentially, a hosted Stack Overflow:</p>
<blockquote>
Seems really pricey for a relatively simple software like this. Someone write an open source alternative? it looks like something that can be thrown together in a weekend.
</blockquote>
<p>Ah, yes, the stereotypical programmer response to most projects: <b>it's trivial!</b> I could write that in a week!*</p>
<p>It's even easier than that. Open source alternatives to Stack Overflow <a href="http://meta.stackoverflow.com/questions/2267/so-clones">already exist</a>, so you've got a head start. <b>Gentlemen, start your compilers! Er, I mean, <i>interpreters!</i></b></p>
<p>No, I don't take this claim seriously. Not enough to write a response. And fortunately for me, now I don't need to, because <a href="http://blog.bitquabit.com/">Benjamin Pollack</a> -- one of the few people outside our core team who has access to the Stack Overflow source code -- already <a href="http://blog.bitquabit.com/2009/07/01/one-which-i-call-out-hacker-news/">wrote a response</a>. Even if I had written a response, I doubt it would have been half as well written as Benjamin's.</p>
<blockquote>
Developers think cloning a site like StackOverflow is easy for the same reason that open-source software remains such a horrible pain in the ass to use. <b>When you put a developer in front of StackOverflow, they don't really see StackOverflow</b>. What they actually see is this:
<pre>
create table QUESTION (ID identity primary key,
TITLE varchar(255),
BODY text,
UPVOTES integer not null default 0,
DOWNVOTES integer not null default 0,
USER integer references USER(ID));
create table RESPONSE (ID identity primary key,
BODY text,
UPVOTES integer not null default 0,
DOWNVOTES integer not null default 0,
QUESTION integer references QUESTION(ID))
</pre>
<p>If you then tell a developer to replicate StackOverflow, what goes into his head are the above two SQL tables and enough HTML to display them without formatting, and that really <i>is</i> completely doable in a weekend. The smarter ones will realize that they need to implement login and logout, and comments, and that the votes need to be tied to a user, but that's still totally doable in a weekend; it's just a couple more tables in a SQL back-end, and the HTML to show their contents. Use a framework like Django, and you even get basic users and comments for free.</p>
<p>But that's <i>not</i> what StackOverflow is about. Regardless of what your feelings may be on StackOverflow in general, most visitors seem to agree that the user experience is smooth, from start to finish. They feel that they're interacting with a polished product. Even if I didn't know better, I would guess that very little of what actually makes StackOverflow a continuing success has to do with the database schema--and having had a chance to read through StackOverflow's source code, I know how little really does. There is a <i>tremendous</i> amount of spit and polish that goes into making a major website highly usable. A developer, asked how hard something will be to clone, simply <i>does not think about the polish, because the polish is incidental to the implementation</i>.</p>
</blockquote>
<p>I have zero doubt that <b>given enough time, open source clones will begin to approximate what we've created with Stack Overflow</b>. It's as inevitable as evolution itself. Well, depending on what time scale you're willing to look at. With a smart, motivated team of closed-source dinosaurs, it is indeed possible to outrun those teeny tiny open-source mammals. For now, anyway. Let's say we're those speedy, clever <a href="http://en.wikipedia.org/wiki/Velociraptor">Velociraptor</a> types of dinosaurs -- those are cool, right?</p>
<p>Despite Benjamin's well reasoned protests, the source code to Stack Overflow is, in fact, actually, kind of ... well, trivial. Although there is starting to be quite a lot of it, as we've been beating on this stuff for almost a year now. That doesn't mean our source code is  good, by any means; as usual, <a href="http://www.codinghorror.com/blog/archives/000099.html">we make crappy software, with bugs</a>. But every day, our tiny little three person team of speedy-but-doomed Velociraptors starts out with the same goal. Not to write the best Stack Overflow <i>code</i> possible, but to <b>create the best Stack Overflow <i>experience</i> possible.</b> That's our mission: make Stack Overflow better, in some small way, than it was the day before. We don't always succeed, but <b>we try very, very hard not to suck</b> -- and more importantly, <a href="http://www.codinghorror.com/blog/archives/001207.html">we keep plugging away at it, day after day</a>.</p>
<p>Building a better Stack Overflow experience does involve writing code and building cool features. But more often, it's anything but:</p>
<ol>
<li>synthesizing cleaner, saner HTML markup
</li>
<li>optimizing our pages for speed and load time efficiency
</li>
<li>simplifying or improving our site layout, CSS, and graphics
</li>
<li>responding to support and feedback emails
</li>
<li>writing a <a href="http://blog.stackoverflow.com/">blog post</a> explaining some aspect of the site engine or philosophy
</li>
<li>being customers of our own sites, asking our own <a href="http://stackoverflow.com">programming questions</a> and <a href="http://serverfault.com">sysadmin questions</a>
</li>
<li>interacting with the community on our <a href="http://meta.stackoverflow.com/">dedicated meta-discussion site</a> to help gauge what we should be working on, and where the rough edges are that need polishing
</li>
<li>
<a href="http://blog.stackoverflow.com/2009/05/welcome-new-community-moderators/">electing community moderators</a> and <a href="http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/">building moderation tools</a> so the community can police and regulate itself as it scales
</li>
<li>producing <a href="http://blog.stackoverflow.com/category/cc-wiki-dump/">Creative Commons dumps</a> of our user-contributed questions and answers
</li>
<li>coming up with schemes for <a href="http://www.codinghorror.com/blog/archives/000893.html">responsible advertising</a> so we can all make a living
</li>
<li>producing the <a href="http://itc.conversationsnetwork.org/series/stackoverflow.html">Stack Overflow podcast</a> with Joel
</li>
<li>helping set up logistics for the <a href="http://stackoverflow.carsonified.com/">Stack Overflow DevDays</a> conferences
</li>
<li>setting up <a href="http://blog.stackoverflow.com/2009/05/the-stack-overflow-trilogy/">the next site in the trilogy</a>, and figuring out where we go next
</li>
</ol>
<p>As programmers, as much as we might want to believe that</p>
<pre>
lots_of_awesome_code = success;
</pre>
<p>There's nothing particularly magical about the production of source code. In fact, <a href="http://www.codinghorror.com/blog/archives/000710.html">writing code is a tiny proportion of what makes most businesses successful</a>.</p>
<blockquote>
Code is meaningless if nobody knows about your product. Code is meaningless if the IRS comes and throws you in jail because you didn't do your taxes. Code is meaningless if you get sued because you didn't bother having a software license created by a lawyer.
</blockquote>
<p>Writing code <i>is</i> trivial. And fun. And something I continue to love doing. But if you <i>really</i> want your code to be successful, you'll <b><a href="http://www.codinghorror.com/blog/archives/000878.html">stop coding</a> long enough to do all that other, even <i>more</i> trivial stuff around the code that's necessary to <i>make</i> it successful.</b></p>
<p><small>* Although, to be fair, I really could write Twitter in a week. It's so ridiculously simple! Come on!</small></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/code-its-trivial/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Testing With "The Force" ]]></title>
<link>https://blog.codinghorror.com/testing-with-the-force/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Markdown was one of the <a href="http://www.codinghorror.com/blog/archives/001116.html">humane markup languages</a> that we evaluated and adopted for Stack Overflow. I've been pretty happy with it, overall. So much so that I wanted to implement a tiny, lightweight subset of Markdown for comments as well.
</p>
<p>
I settled on these three commonly used elements:
</p>
<p>
</p>
<pre>
*italic* or _italic_
**bold** or __bold__
`code`
</pre>
<p>
I <a href="http://www.codinghorror.com/blog/archives/001016.html">loves me some regular expressions</a> and this is exactly the stuff regex was born to do! It doesn't <i>look</i> very tough. So I dusted off <a href="http://www.regexbuddy.com/cgi-bin/affref.pl?aff=jatwood">my copy of RegexBuddy</a> and began.
</p>
<p>
I typed some test data in the test window, and whipped up a little regex in no time at all. This isn't my first time at the disco.
</p>
<p>
<a href="http://www.regexbuddy.com/cgi-bin/affref.pl?aff=jatwood"><img alt="image placeholder" >
</p>
<p>
Bam! Yes! Done and <i>done!</i> By gum, <a href="http://code.google.com/events/io/sessions/MythGeniusProgrammer.html">I must be a genius programmer!</a>
</p>
<p>
Despite my obvious genius, I began to have some small, nagging doubts. Is the test phrase...
</p>
<pre>
I would like this to be *italic* please.
</pre>
<p>
... <i>really</i> enough testing?
</p>
<p>
Sure it is! I can feel in my bones that this thing freakin' works! It's almost like I'm being pulled toward shipping this code by some inexorable, dark, testing ... force. It's so <i>seductively easy!</i>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But wait. <b>I have this whole database of real world comments</b> that people have entered on Stack Overflow. shouldn't I perhaps try my awesome regular expression on that corpus of data to see what happens? Oh, fine. If we must. Just to humor you, nagging doubt. Let's run a query and see.
</p>
<p>
</p>
<pre>
select Text from PostComments
where dbo.RegexIsMatch(Text, '*(.*?)*') = 1
</pre>
<p>
Which produced this list of matches, among others:
</p>
<p>
</p>
<blockquote>
Interesting fact about math: x <font color="red">* 7 == x + (x *</font> 2) + (x * 4), or x + x &gt;&gt; 1 + x &gt;&gt; 2.  Integer addition is usually pretty cheap.
<p>
Thanks.  What I needed was to turn on Singleline mode too, and use .<font color="red">*? instead of .*</font>.
</p>
<p>
yeah, see my edit - change select <font color="red">* to select RESULT.*</font>  one row - are sure you have more than one row item with the same InstanceGUID?
</p>
<p>
Not your main problem, but you are mix and matching wchar_t and TCHAR.  mbstowcs() converts from char <font color="red">* to wchar_t *</font>.
</p>
<p>
aawwwww.... Brainf<font color="red">**</font>k is not valid. :/
</p>
</blockquote>
<p>
Thank goodness I listened to my midichlorians and let <b>the light side of the testing force</b> prevail here!
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
So how do we fix this regex? We use the light side of the force -- brute force, that is, against a ton of test cases! My job here is relatively easy because I have over 20,000 test cases sitting in a database. You may not have that luxury. Maybe you'll need to go out and find a bunch of test data on the internet somewhere. Or write a function that generates random strings to feed to the routine, also known as <a href="http://en.wikipedia.org/wiki/Fuzz_testing">fuzz testing</a>.
</p>
<p>
I wanted to leave the rest of this regular expression as an exercise for the reader, as I'm a sick guy who finds that sort of thing entertaining. If you don't -- well, what the heck is wrong with <i>you</i>, man? But I digress. I've been criticized for not providing, you know, "the answer" in my blog posts. Let's walk through some improvements to our italic regex pattern.
</p>
<p>
First, let's make sure we have <b>at least one non-whitespace character inside the asterisks</b>. And more than one character in total so we don't match the ** case. We'll use <a href="http://www.regular-expressions.info/lookaround.html">positive lookahead and lookbehind</a> to do that.
</p>
<p>
</p>
<pre>
*<font color="red">(?=S)</font>(.+?)<font color="red">(?&lt;=S)</font>*
</pre>
<p>
That helps a lot, but we can test against our data to discover some other problems. We get into trouble when there are unexpected characters in front of or behind the asterisks, like, say, <code>p*q*r</code>. So let's specify that <b>we only want certain characters outside the asterisks</b>.
</p>
<p>
</p>
<pre>
<font color="red">(?&lt;=[s^,(])</font>*(?=S)(.+?)(?&lt;=S)*<font color="red">(?=[s$,.?!])</font>
</pre>
<p>
Run this third version against the data corpus, and wow, that's starting to look pretty darn good! There are undoubtedly some edge conditions, particularly since we're unlucky enough to be talking about code in a lot of our comments, which has wacky asterisk use.
</p>
<p>
This regex doesn't have to be (and probably <i>cannot</i> be, given the huge possible number of human inputs) perfect, but running it against a large set of input test data gives me reasonable confidence that I'm not totally screwing up.
</p>
<p>
So by all means, test your code with the force -- brute force! It's good stuff! Just <b>be careful not to get sloppy, and let the dark side of the testing force prevail</b>. If you think one or two simple test cases covers it, that's taking the easy (and most likely, buggy and incorrect) way out.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/testing-with-the-force/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Not to Advertise on the Internet ]]></title>
<link>https://blog.codinghorror.com/how-not-to-advertise-on-the-internet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Games that run in your web browser are all the rage, and <a href="http://www.codinghorror.com/blog/archives/000872.html">understandably so</a>. Why not build your game for the largest audience in the world, using freely available technology, and pay zero licensing fees? One such game is Evony, formerly known as Civony – a browser-based clone of <a href="http://en.wikipedia.org/wiki/Civilization_%28video_game%29">the game Civilization</a> with <a href="http://kevinsung.org/?p=2111">a buy-in mechanism</a>.</p>
<blockquote>There are also plentiful opportunities to 'pay money' now. In the end, Civony is still a business. And to be honest, it's probably better to give the option for some elite folks to finance the game for the masses than to make everyone pay a subscription or watch in-game ads. In addition to the old $0.30 per line world chat, you can spend money to speed up resource gathering, boost stats, and buy in-game artifacts. I'm sure there are other ways to pay money that I haven't discovered yet. But whenever you see a green plus-sign (+), you know the option exists to pay money for a perk.</blockquote>
<p>The game is ostensibly free, but supported by a tiny fraction of players making cash payments for optional items (sometimes referred to as <a href="http://en.wikipedia.org/wiki/Freemium">"freemium"</a>). Thus, the player base needs to be quite large for the business of running the game to be sustainible, and the game's creators <strong>regularly purchase internet ad space to promote their game</strong>. The most interesting thing about Evony isn't the game, per se, but the game's advertising. Here's one of the early ads.</p>
<p><img alt="image placeholder" >
<p>Totally reasonable advertisement. Gets the idea across that this is some sort of game <a href="http://www.youtube.com/watch?v=bc_4_IVURHE">set in medieval times</a>, and emphasizes the free angle.</p>
<p>Apparently that ad didn't perform up to expectations at Evony world HQ, because the ads got progressively ... well, take a look for yourself. These are presented in <strong>chronological order of appearance on the internet</strong>.</p>
<p><img alt="image placeholder" >
<p>(if this lady looks familiar, <a href="http://blog.costumecraze.com/2009/05/dubious-civony-game-uses-costume-photo">there's a reason</a>.)</p>
<p><img alt="image placeholder" >
<p><img alt="image placeholder" >
<p><img alt="image placeholder" >
<p><img alt="image placeholder" >
<p>To be clear, <strong>these are <em>real</em> ads that were served on the internet</strong>. This is <em>not</em> a parody. Just to prove it, here's a screenshot of the last ad in context at <a href="http://www.tesnexus.com/">The Elder Scrolls Nexus</a>.</p>
<p><img alt="image placeholder" >
<p>I've talked about <a href="http://www.codinghorror.com/blog/archives/000893.html">advertising responsibly</a> in the past. This is about as far in the opposite direction as I could possibly imagine. It's yet another way, sadly, <a href="http://www.imdb.com/title/tt0387808/">the brilliant satire Idiocracy</a> turned out to be right on the nose.</p>
<p><a href="http://www.amazon.com/dp/B000K7VHOG/?tag=codihorr-20"><img alt="image placeholder" >
<p>The dystopian future of <a href="http://www.amazon.com/dp/B000K7VHOG/?tag=codihorr-20">Idiocracy</a> predicted the reduction of advertising to the inevitable lowest common denominator of all, with Starbucks Exotic Coffee for Men, H.R. Block "Adult" Tax Return (home of the gentleman's rebate), and Pollo Loco chicken advertising a Bucket of Wings with "full release".</p>
<p>Evony, thanks for showing us what it means to <strong>take advertising on the internet to the absolute rock bottom</strong> ... then dig a sub-basement under that, and keep on digging until you reach the white-hot molten core of the Earth. I've always wondered what that would be like. I guess now I know.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-not-to-advertise-on-the-internet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Meta Is Murder ]]></title>
<link>https://blog.codinghorror.com/meta-is-murder/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Are you familiar with the term "meta"? It permeates many concepts in programming, from <a href="http://www.codinghorror.com/blog/archives/000653.html">metadata</a> to <a href="http://www.codinghorror.com/blog/archives/000455.html">the &lt;meta&gt; tag</a>. But since we're on a blog, let's use blogging to explain what meta means. If you've read this blog for any length of time you've probably heard me rant about the evil of <a href="http://www.codinghorror.com/blog/archives/000297.html">blogging about blogging</a>, a.k.a. <strong>meta-blogging</strong>. As I said in <a href="http://www.codinghorror.com/blog/archives/000834.html">Thirteen Blog Cliches</a>:</p>
<blockquote>I find meta-blogging -- blogging about blogging -- incredibly boring. I said as much in <a href="http://www.dailyblogtips.com/interview-with-jeff-atwood-from-coding-horror/">a recent interview</a> on a site that's all about blogging (hence the title, Daily Blog Tips). I wasn't trying to offend or shock; I was just being honest. Sites that contain nothing but tips on how to blog more effectively bore me to tears.
<p>If you accept the premise that most of your readers are not bloggers, then it's highly likely they won't be amused, entertained, or informed by a continual stream of blog entries on the art of blogging. Even if they're filled with extra bloggy goodness.</p>
<p>Meta-blogging is like masturbating. Everyone does it, and there's nothing wrong with it. But writers who regularly get out a little to explore other topics will be healthier, happier, and ultimately more interesting to be around-- regardless of audience.</p>
</blockquote>
<p>Triple-meta alert! That blog entry was me blogging about blogging about blogging. See? Painful. I told you.</p>
<p>Generally speaking, I am not a fan of the meta. It's seductive in a way that is subtly but deeply dangerous. It's far easier to introspect and write about the process of, say .. blogging .. than it is to think up, research, and write about an interesting new topic on your blog. Meta-work becomes a reflex, a habit, an addiction, and ultimately a replacement for real productive work. It's something I think <em>everyone</em> should watch out for, whatever walk of life or career you happen to have. In fact, I've come up with a zingy little catch phrase to help people remind themselves, and their coworkers, how toxic this stuff can be -- <strong>meta is murder</strong>.</p>
<p><img alt="image placeholder" >
<p>Yes, you read that right. <em>Murder</em>. I mean it. If enough productive work is replaced by navelgazing meta-work, then <strong>people will be killed</strong>.  Or at least, the community will be.</p>
<p>Joel Spolsky had a great example of how meta-discussion can kill community in <a href="http://blog.stackoverflow.com/2009/07/podcast-60/">our latest podcast</a>.</p>
<blockquote>Let's say that you become a podcaster, so you get really interested in podcasting gear. You're going to buy some mixers, and want to know what kind of headphones to use, what kinds of microphones, when should I do the A/D conversions, all that kind of stuff.
<p>So you find this awesome podcasting gear website. And you go on there, and the first subject of conversation is who's going to be elected to the podcasting gear website board of directors. And the second subject of conversation is whether the election that was done last year was orthodox, or was it slightly ... was there something suspicious about that whole thing. And you find a whole bunch of people arguing about that. And then you find a conversation about whether all the people who came in last year from South America and don't speak very good English should be allowed to hang around or should maybe be read-only users for the first six months.</p>
<p>That's all you find there, and you want to talk about mixers and mics. That's why you came to this site!</p>
<p>But they're bored talking about mixers and mics -- they've already had the full mixers and mics conversation all the way to the end, to its logical extreme. They all have, now, the perfect podcasting setup. Except for there's this one minor little thing about whether you should use Monster Cables that people still argue about.</p>
<p><strong>So all they're talking about on this so-called "podcasting gear" website is the podcasting gear website itself. </strong></p>
</blockquote>
<p>If you don't control it, meta-discussion, like weeds run amok in a garden, will choke out a substantial part of the normal, natural growth of a healthy community.</p>
<p>The danger and peril of meta has been known for years. We had <a href="http://www.metafilter.com/user/7418">Josh Millard</a>, a <a href="http://www.metafilter.com/">MetaFilter</a> moderator, as <a href="http://blog.stackoverflow.com/2008/09/podcast-22/">a guest on the podcast last year</a>. He <a href="https://stackoverflow.fogbugz.com/default.asp?W24227">described</a> how quickly MetaFilter realized that meta-discussion, if not controlled, can destroy a community:</p>
<blockquote>
<strong>Millard:</strong> Matt set up MetaTalk sometime like 8 months after he started [MetaFilter], right about the beginning of 2000, because people were talking about MetaFilter on the front page.  It's natural enough.  People would say, hey what's with this, hey look at the post, hey this guy's a jerk.  So he started up MetaTalk and directed stuff that was metacommentary to that part of the site.  You could delete something and say, hey take it over there. If people wanted to have an extended argument that was derailing a thread, they could do it there.
<p>A lot of people cite MetaTalk as a reason that MetaFilter works. If you talk to a regular from the site they'll tell you MetaTalk is key to the success of the site because it's a sort of release valve. Talk pages on Wikipedia are a similar thing. I had the same experience as you the first time I checked those out -- it's not necessarily comprehensible to the casual user what is going on there.  But for the people who are regulars, the people who develop a certain amount of passionate attachment to the sites, or really, really need to make their voice heard out of day one beyond just normal participation, you have this safe place you can let people ... let their freak flag fly, as it were, without damaging the core function of the site.  You don't have big messes on the front page.</p>
<p>So there's a pretty strong culture of regulars who hang out on MetaTalk.  Insofar as you have the big contributors and the serious regulars at any given site that make up the core of the community, there's a strong correlation between those people and the people who actually spend time on MetaTalk dealing with policy stuff and talking about user issues.</p>
<p><strong>Atwood</strong>: Right.  I totally get that.  This is one of the things about designing social software -- you don't really understand it until you've lived through it. For the longest time I couldn't understand why people couldn't respect the rule we had to not discuss this meta stuff on the site itself. I totally get this now.</p>
</blockquote>
<p>We've <a href="http://blog.stackoverflow.com/2009/06/cmon-get-meta/">dealt with our meta problem on Stack Overflow</a>, finally. OK, I had to be dragged kicking and screaming to finally do what I should have done <em>months</em> ago, but what else is new?</p>
<p>Anyway, my point is that meta isn't just a social <em>software</em> problem. <strong>Meta is a social problem, period.</strong> It's applicable to everything you do in life.</p>
<p><a href="http://twitter.com/codinghorror/status/2385850535"><img alt="image placeholder" >
<p>Software developers are known for their introspection, and a certain amount of meta is healthy. It qualifies as <a href="http://www.codinghorror.com/blog/archives/001236.html">sharpening the saw</a> -- mindfulness of what you're doing, and how it can be improved. But it's amazing how rapidly that can devolve into a crutch, a sort of <a href="http://en.wikipedia.org/wiki/Methadone">methadone</a> for Getting Things Done<sup>tm</sup>.</p>
<p>So sure, get meta when it makes sense to. But do be aware of what percentage of the time you're spending on meta. And consider: how is progress made in the world? By sitting around and debating the process of how things are done ad nauseam? Or by, y'know … <em>doing stuff?</em></p>
<p>Allocate your time accordingly.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/meta-is-murder/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Engineering: Dead? ]]></title>
<link>https://blog.codinghorror.com/software-engineering-dead/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was utterly floored when I read this <a href="http://www2.computer.org/cms/Computer.org/ComputingNow/homepage/2009/0709/rW_SO_Viewpoints.pdf">new IEEE article by Tom DeMarco</a> (pdf). See if you can tell why.
</p>
<p>
</p>
<blockquote>
My early metrics book, <a href="http://www.amazon.com/dp/0131717111/?tag=codihorr-20">Controlling Software Projects: Management, Measurement, and Estimates</a> [1986], played a role in the way many budding software engineers quantified work and planned their projects. In my reflective mood, I'm wondering, was its advice correct at the time, is it still relevant, and do I still believe that metrics are a must for any successful software development effort? My answers are no, no, and no.
<p>
I'm gradually coming to the conclusion that <strong>software engineering is an idea whose time has come and gone</strong>.
</p>
<p>
Software development is and always will be somewhat <strong>experimental</strong>. The actual software construction isn't necessarily experimental, but its conception is. And this is where our focus ought to be. It's where our focus always ought to have been.
</p>
</blockquote>
<p>
If your head just exploded, don't be alarmed. Mine did too. To somewhat reduce the migraine headache you might now be experiencing from reading the above summary, I <em>highly</em> recommend scanning <a href="http://www2.computer.org/cms/Computer.org/ComputingNow/homepage/2009/0709/rW_SO_Viewpoints.pdf">the entire two page article pdf</a>.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Tom_DeMarco">Tom DeMarco</a> is one of the most deeply respected authority figures in the software industry, having coauthored the <a href="http://www.amazon.com/exec/obidos/ASIN/0932633439/codihorr-20">brilliant and seminal Peopleware</a> as well as many other near-classic software project management books like <a href="http://www.amazon.com/dp/0932633609/?tag=codihorr-20">Waltzing With Bears</a>. For a guy of Tom's caliber, experience, and influence to come out and just <em>flat out say</em> that <strong>Software Engineering is Dead</strong> …
</p>
<p>
… well, as Keanu Reeves once said, <em>whoa.</em>
</p>
<p>
That's kind of a big deal. It's scary.
</p>
<p>
And yet, it's also a release. It's as if a crushing weight has been lifted from my chest. I can publicly acknowledge what I've slowly, gradually realized over the last 5 to 10 years of my career as a software developer: <strong>what we do is craftsmanship, not engineering.</strong> And I can say this proudly, unashamedly, with nary a shred of self-doubt.
</p>
<p>
I think Joel Spolsky, my business partner, recently had a similar epiphany. He wrote about it in <a href="http://www.inc.com/magazine/20081101/how-hard-could-it-be-the-unproven-path.html">How Hard Could It Be?: The Unproven Path</a>:
</p>
<p>
</p>
<blockquote>
I have pretty deeply held ideas about how to develop software, but I mostly kept them to myself. That turned out to be a good thing, because as the organization took shape, nearly all these principles were abandoned.
<p>
As for what this all means, I'm still trying to figure that out. I abandoned seven long-held principles about business and software engineering, and nothing terrible happened. Have I been too cautious in the past? Perhaps I was willing to be a little reckless because this was just a side project for me and not my main business. The experience is certainly a useful reminder that it's OK to throw caution to the wind when you're building something completely new and have no idea where it's going to take you.
</p>
</blockquote>
<p>
Yes, I could add a lot of <a href="http://www.codinghorror.com/blog/archives/000917.html">defensive software engineering caveats here</a> about the particulars of the software project you're working on: its type (<a href="http://www.codinghorror.com/blog/archives/000113.html">mission critical</a>, of course), its size (<a href="http://teddziuba.com/2008/04/im-going-to-scale-my-foot-up-y.html">Google scale</a>, naturally), the audience (<a href="http://www.codinghorror.com/blog/archives/000664.html">millions of daily users</a>, obviously), and so forth.
</p>
<p>
But I'm not going to do that.
</p>
<p>
What DeMarco seems to be saying – and, at least, what I am <em>definitely</em> saying – is that <strong>control is ultimately illusory on software development projects</strong>. If you want to move your project forward, the only reliable way to do that is to cultivate a deep sense of software craftsmanship and professionalism around it.
</p>
<p>
The guys and gals who show up every day <a href="http://www.codinghorror.com/blog/archives/000856.html">eager to hone their craft</a>, who are passionate about building stuff that <em>matters</em> to them, and perhaps in some small way, to the rest of the world – those are the people and projects that will ultimately succeed.
</p>
<p>
Everything else is just noise.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-engineering-dead/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Nobody Hates Software More Than Software Developers ]]></title>
<link>https://blog.codinghorror.com/nobody-hates-software-more-than-software-developers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>A few months ago we bought a new digital camera, all the better to take pictures of our <a href="http://www.codinghorror.com/blog/archives/001242.html">new spawned process</a>. My wife, who was in charge of this purchase, dutifully unboxed the camera, installed the batteries, and began testing it out for the first time. Like so many electronic gadgets, it came bundled with a CD of software. So she innocently ejected the DVD tray, and dropped the CD in.</p>
<p>I happened to notice out of the corner of my eye that this was happening. At which point,  I – now, try to imagine this in exaggerated slow motion, for full effect – screamed "noooooo<small>ooo</small><small><small>ooo</small></small>", and frantically launched myself across the room in a desperate attempt to keep that CD from launching and installing its payload of software. It worked, but I nearly took out a cat in the process.</p>
<p>There's nothing <em>wrong</em> with the software that comes bundled with a digital camera. Or is there?</p>
<ol>
<li>
<strong>It's probably unnecessary</strong>. Any modern operating system (and even Windows XP!) can see and automatically download pictures from a new digital camera. No extra software needed. But in a questionable attempt to add "value" and distinguish themselves from their many digital camera competitors, some executive at the camera company came up with a harebrained scheme to include software with a bunch of wacky, unique features that nobody else has.<br><br> </li>
<li>
<strong>Hardware companies don't generally do software well</strong>. Digital camera companies excel at building digital camera hardware. Software, if it exists at all, is an afterthought, a side effect, a checkbox on some marketing weasel's clipboard.<br><br> </li>
<li>
<strong>Software of unknown provenance is likely written by bad programmers</strong>. All other things being equal, the odds that new, random bit of software you're about to install will be pleasant, useful, and stress free are ... uh, low. </li>
</ol>
<p>One of the (many) unfortunate side effects of choosing a career in software development is that, over time, you learn to hate software. I mean really hate it. With a <em>passion</em>. Take the angriest user you've ever met, multiply that by a thousand, and you still haven't come close to how we programmers feel about software. <strong>Nobody hates software more than software developers.</strong> Even now, writing about the stuff is making me physically angry.</p>
<p>Isn't that an odd attitude coming from people whose job it is to write software? How can we hate what we get paid to create every day?</p>
<p>David Parnas explained <a href="http://www.sigsoft.org/SEN/parnas.html">in an interview</a>:</p>
<blockquote>Q: What is the most often-overlooked risk in software engineering?
<p>A: Incompetent programmers. There are estimates that the number of programmers needed in the U.S. exceeds 200,000. This is entirely misleading. It is not a quantity problem; we have a quality problem. One bad programmer can easily create two new jobs a year. Hiring more bad programmers will just increase our perceived need for them. If we had more good programmers, and could easily identify them, we would need fewer, not more.</p>
</blockquote>
<p>How do I know, incontrovertibly, beyond the shadow of a doubt, that the world is full of incompetent programmers? <em>Because I'm one of them!</em></p>
<p>We work at the sausage factory, so we know how this stuff is made. And <a href="http://www.codinghorror.com/blog/archives/000588.html">it is not pretty</a>. Most software is created by bad programmers like us (or worse!), which means that by definition, <strong>most software sucks</strong>. Let's refer to <a href="http://www.scottberkun.com/essays/46-why-software-sucks/">Scott Berkun's Why Software Sucks</a> to nail down the definition:</p>
<blockquote>When people say "this sucks" they mean one or more of the following:
<ul>
<li>This doesn't do what I need </li>
<li>I can't figure out how to do what I need </li>
<li>This is unnecessarily frustrating and complex </li>
<li>This breaks all the time </li>
<li>It's so ugly I want to vomit just so I have something prettier to look at </li>
<li>It doesn't map to my understanding of the universe </li>
<li>I'm thinking about the tool, instead of my work </li>
</ul>
</blockquote>
<p>How many of those do you think would be true of the software on that CD bundled with the digital camera? I'm guessing all of them. That's why <strong>the best choice of software is often <em>no</em> software</strong> – and barring that, as little software as you can possibly get away with, and even then, only from the most reputable and reliable sources.</p>
<p>I don't look forward to installing new software. On the contrary, I dread it.</p>
<p>Let me share a recurring nightmare I have with you. In this dream, I'm sitting down in front of a computer which boots up, running an operating system I've written. I then launch a web browser I've created from scratch, all by myself, and navigate to a website I've constructed. I click on the first link and the whole thing bluescreens. And the bluescreen itself bluescreens and begins to fold in on itself, collapsing into a massive explosion that destroys an entire city block.</p>
<p>That's the <em>good</em> version of the dream. In the other one, there's just … screaming. And darkness.</p>
<p>In short, I hate software – most of all and <em>especially</em> my own – because <strong>I know how hard it is to get it right</strong>. It may sound strange, but it's a natural and healthy attitude for a software developer. It's a bond, a rite of passage that you'll find all competent programmers share.</p>
<p>In fact, I think you can tell a competent software developer from an incompetent one with a single interview question:</p>
<blockquote>What's the worst code you've seen recently?</blockquote>
<p>If their answer isn't immediately and without any hesitation these two words:</p>
<blockquote>My own.</blockquote>
<p>Then you should end the interview immediately. Sorry, pal. <strong>You don't hate software enough yet.</strong> Maybe in a few more years, if you keep at it.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/nobody-hates-software-more-than-software-developers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Windows 7: The Best Vista Service Pack Ever ]]></title>
<link>https://blog.codinghorror.com/windows-7-the-best-vista-service-pack-ever/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
While I haven't been unhappy with Windows Vista, it had <a href="http://www.codinghorror.com/blog/archives/001208.html">a lot of rough edges</a>:
</p>
<p>
</p>
<blockquote>
This is why the screenshot of the Windows 7 Calculator, although seemingly trivial, is so exciting to me. It's evidence that Microsoft is going to pay attention to the <b>visible</b> parts of the operating system this time around. I'm a fan of Vista, despite all the <a href="http://techreport.com/discussions.x/13303">nerd rage</a> on the topic, but I'll be the first to admit that Vista had <a href="http://www.codinghorror.com/blog/archives/001126.html">all the polish of a particularly dull rock</a>. Let's just say the overall user experience was.. uninspiring. This led many people to shrug, sigh "why bother?", and stick with crusty old XP.
</blockquote>
<p>
Vista was like a solid B student who shows up at your doorstep reeking of body odor and dressed in shabby clothing from the local thrift shop. There's something decent at the core, but it's a real challenge to get past the obvious surface deficiencies.
</p>
<p>
Thus, I've been following the development of Windows 7 with cautious optimism. It's important to me not because I am an operating system fanboy, but mostly because <b>I want the world to get the hell off Windows XP</b>. A world where people regularly use 9 year old operating systems is not a healthy computing ecosystem. Nobody is forcing anyone to use Windows, of course, but given the fundamental inertia in most people's computing choices, the lack of a compelling Windows upgrade path is a dangerous thing.
</p>
<p>
Now that <a href="http://blogs.computerworld.com/windows_7_is_ready_for_manufacturing_7600_16385_is_rtm_id?source=rss_blogs">Windows 7 has reached its "release to manufacturing" milestone</a>, I had the opportunity to install it for myself and see.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Within 5 minutes of installation it was immediately obvious to me -- <b>Windows 7 is the best Vista Service Pack ever!</b>
</p>
<p>
The core of the operating system isn't that different, but the experience is absolutely what Vista should have been on day one. Microsoft took that B student, gave him a bath and a makeover, and even improved his grades ever so slightly.
</p>
<p>
It sounds like a subtle thing, but it's not. Sit down and use Windows 7 for even a few minutes and you'll find an operating system that is faster, cleaner looking, and filled with lots of little useful, thoughtful touches utterly lacking in Vista. Where Vista was half-implemented and often clunky, Windows 7 is competent bordering on pleasant. I won't bore you with all the details, as Windows 7 has been getting lots of positive press from all corners of the web. There's no need for me to add my voice to the chorus. But suffice it to say that <b>Windows 7 finally offers a compelling upgrade path from Windows XP</b>. So from my perspective, <i>mission accomplished</i>. Three years late, but hey, who's counting.
</p>
<p>
(Note that this is <a href="http://www.codinghorror.com/blog/archives/000796.html">not an invitation to rekindle the eternal OS flame war</a>, as I'm much more interested in the cool stuff you're <i>creating</i> than what OS you use to create it with. I'm sorry, but <a href="http://www.codinghorror.com/blog/archives/000186.html">screwdrivers just aren't that sexy to me</a>.)
</p>
<p>
I normally do clean installs for operating system upgrades, but I've been busy recently, and I don't have any <a href="http://www.codinghorror.com/blog/archives/000905.html">new PC hardware builds scheduled</a>. If you're already on Vista, the upgrade path is perhaps more compelling than it otherwise would be. All the breaking fundamental changes were in Vista, so if you've made it over the Vista hump, then an in-place Windows 7 upgrade is relatively painless -- or at least, it has been for me on the two machines I've tried so far.
</p>
<p>
I think Windows 7 works well as a <b>de-facto Vista service pack</b>. I guess that's not surprising if you compare the version numbers.
</p>
<p>
</p>
<pre>
C:UsersJeff&gt;ver<br>
Microsoft Windows [Version 6.0.6002]
</pre>
<p>
</p>
<pre>
C:UsersJeff&gt;ver<br>
Microsoft Windows [Version 6.1.7600]
</pre>
<p>
Here's to exactly <code>0.1.1598</code> worth of improvement for the Windows ecosystem. Now can we <i>please</i> get the hell off Windows XP already?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/windows-7-the-best-vista-service-pack-ever/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Coding Horror: Movable Type Since 2004 ]]></title>
<link>https://blog.codinghorror.com/coding-horror-movable-type-since-2004/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
When I <a href="http://www.codinghorror.com/blog/archives/000004.html">started this blog</a>, way back in the dark ages of 2004, the best of the options I had was <a href="http://www.movabletype.org/">Movable Type</a>.
</p>
<p>
<a href="http://www.movabletype.org/"><img alt="image placeholder" >
</p>
<p>
A Perl and MySQL based blogging platform may seem like an odd choice for a Windows-centric developer like me, but I felt it was the best of the available blog solutions at the time, and <i>clearly</i> ahead of the .NET blogging solutions.
</p>
<p>
Sure, I have areas of expertise that I like to stick to, but my attitude has always been to <b>put religion aside and use what works</b>, regardless of language or platform. That's much more of a reality today than it was five years ago. Today, we have embarrassing amounts of CPU power and memory in our servers, and a plethora of good virtualization solutions. Spinning up a Linux virtual machine to solve some problem is no big deal, and we do it every day on Stack Overflow.
</p>
<p>
In retrospect, my choice of Movable Type was a fortunate one. Although I also use and appreciate <a href="http://wordpress.org/">WordPress</a>, it's <a href="http://www.codinghorror.com/blog/archives/001105.html">a bit of a CPU hog</a>. Given the viral highs and lows of my blogging career, there's no way this modest little server could have survived the onslaught of growth with WordPress. It would have been inexorably crushed under the weight of all those pageviews.
</p>
<p>
What's Movable Type's performance secret? For the longest time -- almost 5 years -- I used the version I started with, 2.66. That version of Movable Type writes each new blog entry out to disk as a single, static HTML file. In fact, every blog entry you see here is a physical HTML file, served up by IIS just like it would serve up any other HTML file sitting in a folder. It's lightning fast, and serving up hundreds of thousands of pageviews is no sweat. The one dynamic feature of the page, comments, are handled via a postback CGI which writes the page back to disk as each new comment is added. (This is also the source of the occasional comment disk write collision, when two commenters happen to leave a comment at the same time.) Yes, it's a little primitive, but it's also very much in the spirit of KISS: why not do the simplest possible thing that could work?
</p>
<p>
This static publishing mode precludes glitzy dynamic per-page widgets, but I am a minimalist who <a href="http://www.codinghorror.com/blog/archives/000834.html">likes his pages austere</a>. That restriction suits me fine. The other downside is that a site-wide change requires republishing hundreds or thousands of blog entries. Over time, that can get painful. Modern versions of Movable Type offer both <a href="http://www.movabletype.org/documentation/administrator/publishing/static-and-dynamic-publishing.html">static and dynamic publishing modes</a>, which can give you the best of both worlds.
</p>
<p>
Movable Type was created by <a href="http://www.sixapart.com/">Six Apart</a>. Over the last few years, I've had the opportunity to meet <a href="http://www.dashes.com/anil/">Anil Dash</a>, who is not only the chief evangelist for and first employee of Six Apart, but also an old-school blogger from way back in 1999. This is a guy who has been through the intertubes a time or two. That's why I sought out Anil's advice when we were struggling to come up with a decent name for this crazy website concept Joel Spolsky and I were working on  -- and it was his excellent advice on naming that eventually <a href="http://www.codinghorror.com/blog/archives/001095.html">guided us to the name Stack Overflow</a>.
</p>
<p>
Anil isn't just a <a href="http://www.dashes.com/anil/">brilliant blogger</a> and community evangelist, he's quite influential in his own humble way. And despite his well earned status as a lion of the Web 1.0 blogging era, he's also willing to go far, <i>far</i> out of his way to help a fellow blogger. Anil <i>personally</i> helped me drag Coding Horror from the dark ages of 2004-era Movable Type 2.66 to today's modern Movable Type 4.2x. And by that I mean he logged in himself and did the grunt work to make it happen, including following up with me personally and going through at least two rounds of my crazy demands to make everything as primitive and featureless as I need it to be.
</p>
<p>
In short, Anil's a mensch.
</p>
<p>
So, if you're considering a blogging platform, I can vouch for not only the Movable Type software, but the Six Apart team, and the community around it. In all honesty, <a href="http://www.codinghorror.com/blog/archives/000983.html">blogging changed my life</a>. I'm not sure that's directly attributable to me choosing Movable Type, exactly, but I <i>can</i> give it the highest praise I give any software I've used:
</p>
<p>
<b>It Just Works.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/coding-horror-movable-type-since-2004/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Paper Data Storage Option ]]></title>
<link>https://blog.codinghorror.com/the-paper-data-storage-option/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As programmers, <a href="http://www.codinghorror.com/blog/archives/000178.html">we regularly work with text encodings</a>. But there's another sort of encoding at work here, one we process so often and so rapidly that it's invisible to us, and we forget about it. I'm talking about <b>visual encoding -- translating the visual glyphs of the alphabet you're reading right now</b>. The alphabet is no different than any other optical machine readable input, except the machines are <i>us</i>.
</p>
<p>
But how efficient is the alphabet at encoding information on a page? Consider some of the alternatives -- different visual representations of data you could print on a page, or display on a monitor:
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Punched_card#IBM_80_column_punch_card_format">5081 punch card</a><br>
up to 80 alphanumeric characters
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://en.wikipedia.org/wiki/MaxiCode">Maxicode</a><br>
up to 93 alphanumeric characters
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Data_matrix_%28computer%29">Data Matrix</a><br>
up to 2,335 alphanumeric characters
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://en.wikipedia.org/wiki/QR_Code">QR Code</a><br>
up to 4,296 alphanumeric characters
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Aztec_Code">Aztec Code</a><br>
up to 3,067 alphanumeric characters
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://en.wikipedia.org/wiki/High_Capacity_Color_Barcode">High Capacity Color Barcode</a><br>
varies by # of color and density; up to 3,500 characters per square inch
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Printed page<br>
about 10,000 characters per page
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Paper the way we typically use it is criminally inefficient. It has a ton of wasted data storage space. That's where programs like <a href="http://ollydbg.de/Paperbak/">PaperBack</a> come in:
</p>
<p>
</p>
<blockquote>
PaperBack is a free application that allows you to back up your precious files on ordinary paper in the form of oversized bitmaps. <b>If you have a good laser printer with the 600 dpi resolution, you can save up to 500,000 bytes of uncompressed data on a single sheet.</b>
<p>
You may ask - why? Why, for heaven's sake, do I need to make paper backups, if there are so many alternative possibilities like CD-R's, DVDÂ±R's, memory sticks, flash cards, hard disks, streaming tapes, ZIP drives, network storage, magneto-optical cartridges, and even 8-inch double-sided floppy disks formatted for DEC PDP-11? The answer is simple: you don't. However, by looking on CD or magnetic tape, you are not able to tell whether your data is readable or not. You must insert your medium into the drive, if you even have one, and try to read it.
</p>
<p>
Paper is different. Do you remember punched cards? For years, cards were the main storage medium for the source code. I agree that 100K+ programs were... inconvenient, but hey, only real programmers dared to write applications that large. And used cards were good as notepads, too. Punched tapes were also common. And even the most weird encodings, like <a href="http://en.wikipedia.org/wiki/CDC_display_code">CDC</a> or <a href="http://en.wikipedia.org/wiki/Extended_Binary_Coded_Decimal_Interchange_Code">EBCDIC</a>, were readable by humans (I mean, by real programmers).
</p>
<p>
Of course, bitmaps produced by PaperBack are also human-readable (with the small help of any decent microscope). I'm joking. What you need is a scanner attached to your PC.
</p>
</blockquote>
<p>
PaperBack, like many of the other visual encodings listed above, includes provisions for:
</p>
<p>
</p>
<ul>
<li>compression -- to increase the amount of data stored in a given area.
</li>
<li>redundancy -- in case part of the image becomes damaged or is otherwise unreadable.
</li>
<li>encryption -- to prevent the image from being readable by anyone except the intended recipient.
</li>
</ul>
<p>
<img alt="image placeholder" >
</p>
<p>
Sure, it's still paper, but the digital "alphabet" you're putting on that paper is a far more sophisticated way to store the underlying data than traditional ASCII text.
</p>
<p>
This may all seem a bit fanciful, since the alphabet is about all us poor human machines can reasonably deal with, at least not without the assistance of a computer and scanner.  But there is at least one legitimate use for this stuff, the <a href="http://en.wikipedia.org/wiki/Trusted_paper_key">trusted paper key</a>. There's even software for this purpose, <a href="http://www.jabberwocky.com/software/paperkey/">PaperKey</a>:
</p>
<p>
</p>
<blockquote>
The goal with paper is not secure storage. There are countless ways to store something securely. A paper backup also isn't a replacement for the usual machine readable (tape, CD-R, DVD-R, etc) backups, but rather as an if-all-else-fails method of restoring a key. Most of the storage media in use today do not have particularly good long-term (measured in years to decades) retention of data. If and when the CD-R and/or tape cassette and/or USB key and/or hard drive the secret key is stored on becomes unusable, the paper copy can be used to restore the secret key.
<p>
For paper, on the other hand, to claim it will last for 100 years is not even vaguely impressive. High-quality paper with good ink regularly lasts many hundreds of years even under less than optimal conditions.
</p>
<p>
Another bonus is that ink on paper is readable by humans. Not all backup methods will be readable 50 years later, so even if you have the backup, you can't easily buy a drive to read it. I doubt this will happen anytime soon with CD-R as there are just so many of them out there, but the storage industry is littered with old now-dead ways of storing data.
</p>
</blockquote>
<p>
Computer encoding formats and data storage schemes come and go. This is why so much archival material survives best in the simplest possible formats, like unadorned ASCII. Depending on what your goals are, <b>a combination of simple digital encoding and the good old boring, reliable, really <i>really</i> old school technology of physical paper</b> can still make sense.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-07-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-paper-data-storage-option/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Pricing: Are We Doing It Wrong? ]]></title>
<link>https://blog.codinghorror.com/software-pricing-are-we-doing-it-wrong/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the side effects of <a href="http://www.codinghorror.com/blog/archives/001280.html">using the iPhone App store so much</a> is that it's started to fundamentally alter my perception of software pricing. So many excellent iPhone applications are either free, or no more than a few bucks at most. That's below the threshold of impulse purchase and squarely in no-brainer territory for anything decent that I happen to be interested in.
</p>
<p>
But applications that cost $5 or more? <i>Outrageous! Highway robbery!</i>
</p>
<p>
This is all very strange, as a guy who is used to spending at least $30 for software of any consequence whatsoever. I love <a href="http://www.codinghorror.com/blog/archives/000735.html">supporting my fellow software developers with my wallet</a>, and the iPhone App Store has never made that easier.
</p>
<p>
While there's an <a href="http://mashable.com/2009/07/21/iphone-app-race-bottom/">odd aspect of race to the bottom</a> that I'm not sure is entirely healthy for the iPhone app ecosystem, the idea that <b>software should be priced low enough to pass the average user's "why not" threshold</b> is a powerful one.
</p>
<p>
What I think isn't well understood here is that low prices can be a force multiplier all out of proportion to the absolute reduction in price. Valve software has been aggressively experimenting in this area; consider the <a href="http://www.shacknews.com/onearticle.x/57308">example of the game Left 4 Dead</a>:
</p>
<p>
</p>
<blockquote>
Valve co-founder Gabe Newell announced during a DICE keynote today that last weekend's half-price sale of Left 4 Dead resulted in a 3000% increase in sales of the game, posting overall sales (in dollar amount) that beat the title's original launch performance.
</blockquote>
<p>
It's sobering to think that cutting the price in half, months later, made <i>more</i> money for Valve in total than launching the game at its original $49.95 price point. (And, incidentally, that's the price I paid for it. No worries, I got my fifty bucks worth of gameplay out of this excellent game months ago.)
</p>
<p>
The experiments didn't end there. Observe the utterly non-linear scale at work as the price of software is experimentally reduced even further on their <a href="http://store.steampowered.com/">Steam</a> network:
</p>
<p>
</p>
<blockquote>
The massive <a href="http://store.steampowered.com/">Steam</a> holiday sale was also a big win for Valve and its partners. The following holiday sales data was released, showing the sales breakdown organized by price reduction:
<p>
</p>
<ul>
<li>10% sale = 35% increase in sales (<b>real dollars</b>, not units shipped)
</li>
<li>25% sale = 245% increase in sales
</li>
<li>50% sale = 320% increase in sales
</li>
<li>75% sale = 1470% increase in sales
</li>
</ul>
</blockquote>
<p>
Note that <i>these are total dollar sale amounts!</i> Let's use some fake numbers to illustrate how dramatic the difference really is. Let's say our hypothetical game costs $40, and we sold <b>100 copies</b> of it at that price.
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="400">
<tr>
<td>Original price</td>
<td>Discount</td>
<td>Sale Price</td>
<td align="right">Total Sales</td>
</tr>
<tr>
<td>$40</td>
<td>none</td>
<td>$40</td>
<td align="right">$4,000</td>
</tr>
<tr>
<td>$40</td>
<td>10%</td>
<td>$36</td>
<td align="right">$5,400</td>
</tr>
<tr>
<td>$40</td>
<td>25%</td>
<td>$30</td>
<td align="right">$9,800</td>
</tr>
<tr>
<td>$40</td>
<td>50%</td>
<td>$20</td>
<td align="right">$12,800</td>
</tr>
<tr>
<td>$40</td>
<td>75%</td>
<td>$10</td>
<td align="right">$58,800</td>
</tr>
</table>
<p>
If this pattern Valve documented holds true, and if my experience on the iPhone App store is any indication, <b>we've been doing software pricing completely wrong</b>. At least <a href="http://www.codinghorror.com/blog/archives/000995.html">for digitally distributed software</a>, anyway.
</p>
<p>
In particular, I've always felt that Microsoft has priced their operating system upgrades far, far too high -- and would have sold a <i>ton</i> more licenses if they had sold them at the "heck, why not?" level. For example, take a look at these upgrade options:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="400">
<tr>
<td><a href="http://www.amazon.com/dp/B001AMHWP8/?tag=codihorr-20">Mac OS X 10.6 Upgrade</a></td>
<td align="right">$29</td>
</tr>
<tr>
<td><a href="http://www.amazon.com/dp/B002DHLUWK/?tag=codihorr-20">Microsoft Windows 7 Home Premium Upgrade</a></td>
<td align="right">$119</td>
</tr>
</table>
<p>
Putting aside <a href="http://www.codinghorror.com/blog/archives/000796.html">schoolyard OS rivalries</a> for a moment, which one of these would you be more likely to buy? I realize this isn't entirely a fair comparison, so if $29 seems as bonkers to you as an application for 99 cents -- which I'd argue is much less crazy than it sounds -- then fine. Say the Windows 7 upgrade price was a more rational $49, or $69. I'm sure the thought of that drives the Redmond <a href="http://www.codinghorror.com/blog/archives/001283.html">consumer surplus capturing marketing weasels</a> apoplectic. But the Valve data -- and my own gut intuition -- leads me to believe that they'd actually make <i>more</i> money if they priced their software at the "why not?" level.
</p>
<p>
I'm not saying these pricing rules should apply to <i>every</i> market and <i>every</i> type of software in the world. But for software sold in high volumes to a large audience, I believe they might. At the very least, if you sell software, you might consider experimenting with pricing, as Valve has. You could be pleasantly surprised.
</p>
<p>
<a href="http://www.codinghorror.com/blog/archives/000735.html">I love buying software</a>, and I know I buy a <i>heck</i> of a lot more of it when it's priced right. So why not?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-08-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-pricing-are-we-doing-it-wrong/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ COBOL: Everywhere and Nowhere ]]></title>
<link>https://blog.codinghorror.com/cobol-everywhere-and-nowhere/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'd like to talk to you about <a href="http://www.codinghorror.com/blog/archives/001092.html">ducts</a>. Wait a minute. Strike that. I meant <a href="http://en.wikipedia.org/wiki/COBOL">COBOL</a>. The Common Business Oriented Language is celebrating its fiftieth anniversary as <a href="http://advice.cio.com/stephen_kelly_micro_focus/cobol_still_doing_the_business">the language that is everywhere and nowhere at once</a>:
</p>
<p>
</p>
<blockquote>
As a result, today COBOL is everywhere, yet is largely unheard of among the millions of people who interact with it on a daily basis. Its reach is so pervasive that it is almost unthinkable that the average person could go a day without it. Whether using an ATM, stopping at traffic lights or purchasing a product online, the vast majority of us will use COBOL in one form or another as part of our daily existence.
<p>
The statistics that surround COBOL attest to its huge influence upon the business world. <b>There are over 220 billion lines of COBOL in existence, a figure which equates to around 80% of the world's actively used code.</b> There are estimated to be over a million COBOL programmers in the world today. Most impressive perhaps, is that 200 times as many COBOL transactions take place each day than Google searches - a figure which puts the influence of Web 2.0 into stark perspective.
</p>
<p>
Every year, COBOL systems are responsible for transporting up to 72,000 shipping containers, caring for 60 million patients, processing 80% of point-of-sales transactions and connecting 500 million mobile phone users. COBOL manages our train timetables, air traffic control systems, holiday bookings and supermarket stock controls. And the list could go on.
</p>
</blockquote>
<p>
I have a hard time reconciling this data point with the fact that I have never, in my entire so-called "professional" programming career, met <i>anyone</i> who was actively writing COBOL code. That probably says more about my isolation as a programmer than anything else, but still. I find the whole situation a bit perplexing. <b>If these 220 billion lines of COBOL code are truly running out there somewhere, where are all the COBOL programmers?</b> Did they write software systems so perfect, so bug-free, that all these billions of lines of code are somehow maintaining themselves without the need for legions and armies of COBOL programmers, decades later?
</p>
<p>
If so, that's a mighty impressive feat.
</p>
<p>
And if COBOL is so pervasive, why is it number one in this list of <a href="http://www.computerworld.com/s/article/9020942/The_top_10_dead_or_dying_computer_skills?source=rss_news50">dead (or dying) computer skills</a> compiled in 2007?
</p>
<p>
</p>
<blockquote>
Y2k was like a second gold rush for Cobol programmers who were seeing dwindling need for their skills. But six-and-a-half years later, there's no savior in sight for this fading language. At the same time, while there's little curriculum coverage anymore at universities teaching computer science, "when you talk to practitioners, they'll say there are applications in thousands of organizations that have to be maintained," says Heikki Topi, chair of computer information services at Bentley College in Waltham, Mass., and a member of the education board for the Association for Computing Machinery.
</blockquote>
<p>
When you dig in and <a href="http://www.computerworld.com/s/article/266228/Cobol_Coders_Going_Going_Gone_?taxonomyId=10&amp;pageNumber=1">read about some of these real world COBOL systems</a>, you can get a glimpse of the sort of difficulties they're facing.
</p>
<p>
</p>
<blockquote>
Read says Columbia Insurance's policy management and claims processing software is 20 years old and has 1 million lines of COBOL code with some 3,000 modifications layered on over the years. "Despite everyone pronouncing Cobol dead for a couple of decades, it's still around," he says. "We continue to enhance the base system. It's still green-screen, if you can believe that."
<p>
Read says getting younger workers to take on Cobol chores is a "real challenge, because that's not where technology is today." He simply tells them they must do some Cobol work, promising a switch to other things at the earliest opportunity.
</p>
</blockquote>
<p>
Remember how the common language runtime of .NET promised rich support for a plethora of different languages -- but none of that ever mattered because <a href="http://www.codinghorror.com/blog/archives/000235.html">everyone pretty much just uses C# anyway?</a> Well, that CLR didn't go to waste, because it <i>is</i> possible to write code in COBOL.NET.
</p>
<p>
<a href="http://www.c-sharpcorner.com/UploadFile/rickmalek/dialconv12052005002746AM/dialconv.aspx">See for yourself</a>.
</p>
<p>
</p>
<pre>
private void button1_Click(object sender, System.EventArgs e)
{
button1.Text = "Call COBOL";
}
</pre>
<p>
That was C#, of course. Here's the COBOL.NET version of same:
</p>
<p>
</p>
<pre>
METHOD-ID. button1_Click PRIVATE.
DATA DIVISION.
LINKAGE SECTION.
01 sender OBJECT REFERENCE CLASS-OBJECT.
01 e OBJECT REFERENCE CLASS-EVENTARGS.
PROCEDURE DIVISION USING BY VALUE sender e.
SET PROP-TEXT OF button1 TO "Call COBOL".
END METHOD button1_Click.
</pre>
<p>
Is there anything I could write here that the above code doesn't make abundantly clear?
</p>
<p>
COBOL: so vibrantly alive, yet â€¦ <b>so very, <i>very</i> dead</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-08-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/cobol-everywhere-and-nowhere/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Are You a Digital Sharecropper? ]]></title>
<link>https://blog.codinghorror.com/are-you-a-digital-sharecropper/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><a href="https://www.bloomberg.com/news/articles/2008-12-28/will-work-for-praise-the-webs-free-labor-economybusinessweek-business-news-stock-market-and-financial-advice">Will Work for Praise: The Web's Free-Labor Economy</a> describes how many of today's websites are built by the users themselves:</p>
<blockquote>It's dawn at a Los Angeles apartment overlooking the Hollywood Hills. Laura Sweet, an advertising creative director in her early 40s, sits at a computer and begins to surf the Net. She searches intently, unearthing such bizarre treasures for sale as necklaces for trees and tattoo-covered pigs. As usual, she posts them on a shopping site called ThisNext.com. Asked why in the world she spends so many hours each week working for free, she answers: "It's a labor of love."</blockquote>
<p>This raises some disturbing parallels. Are users being <a href="http://www.roughtype.com/archives/2006/12/sharecropping_t.php">turned into digital sharecroppers</a>?</p>
<blockquote>MySpace, Facebook, and many other businesses have realized that they can give away the tools of production but maintain ownership over the resulting products. One of the fundamental economic characteristics of Web 2.0 is the distribution of production into the hands of the many and the concentration of the economic rewards into the hands of the few. <strong>It's a sharecropping system, but the sharecroppers are generally happy because their interest lies in self-expression or socializing, not in making money</strong>, and, besides, the economic value of each of their individual contributions is trivial.
<p><a href="http://en.wikipedia.org/wiki/Sharecropping"><img alt="image placeholder" >
<p>It's only by aggregating those contributions on a massive scale - on a web scale - that the business becomes lucrative.</p>
</blockquote>
<p>In essence, any website where user generated content <em>is</em> the website, that is also a for-profit business (not a non-profit organization, ala Wikipedia) — is <strong>effectively turning their users into digital sharecroppers</strong>. Digital sharecroppers typically get nothing in return for the content they've provided, and often <a href="http://www.cnn.com/2009/TECH/02/17/facebook.terms.service/index.html">give up all rights to what they've created</a>. At least a real world sharecropper would get to keep a percentage of the crops produced on the land.</p>
<p>The tone of the relationship between virtual land owner and so-called digital sharecroppers is critical. When crowdsourcing goes sour, <a href="http://www.guardian.co.uk/technology/2008/jul/31/wikipedia">there can be mass revolts</a>.</p>
<blockquote>
<a href="http://www.wikia.com/wiki/Wikia">Wikia</a> is a for-profit corporation launched by several high level people involved with Wikipedia, such as co-founder Jimmy Wales. Wikipedia has no significant financial connection to Wikia. But an enormous publicity benefit accrues to Wikia due to Wikipedia's fame: $14m of venture capital has been invested in Wikia. <strong>Its business model is to have a "community" (writers who work for free) to build a wiki website about a topic, and then to sell advertising on those pages.</strong> In short, Wikia hosts sites in return for all the ad revenues.
<p>At the start of June, Wikia's CEO announced that many changes would be made to the appearance of sites, mainly to have more advertising and for the ads to be more prominent. As Wikia's community development manager put it: "We have to change things in order to make Wikia financially stable. Unfortunately, Google ads in the footer pay pennies a click, and nobody clicks". He went on to explain that ads paying based on view count were needed. And that type of advertiser wants their ad to be displayed where viewers are sure to see it, such as within an article, near the top.</p>
<p>In reaction, various content creators made it clear they understood the needs of the company and had no objection to advertising per se. But putting ads inside content risked changing their material from articles into decorated billboards. The conflict between management and (unpaid) labour became acrimonious. There were declarations such as: "If Wikia does not resolve this situation to our satisfaction, then we will leave, taking our content, our communities' inward links, our established service marks and our fellow editors with us."</p>
</blockquote>
<p>This is a topic that I've spent a great deal of time thinking about, because we happen to run a site chock full of user generated questions and answers.  The last thing I want to do is exploit <a href="http://stackoverflow.com">Stack Overflow</a> users for corporate gain, even accidentally. That's horrible.</p>
<p>So if you spend a lot of time creating content on someone else's website — whether it's Stack Overflow, or anywhere else on the internet — <b>you should be asking yourself some tough questions:</b></p>
<ul>
<li>What do <em>you</em> get out of the time and effort you've invested in this website? Personally? Professionally? Tangibly? Intangibly? </li>
<li>Is your content attributed to you, or is it part of a communal pool? </li>
<li>What rights do you have for the content you've contributed? </li>
<li>Can your contributions be revoked, deleted, or permanently taken offline without your consent? </li>
<li>Can you download or archive your contributions? </li>
<li>Are you comfortable with the business model and goals of the website you're contributing to, and thus directly furthering? </li>
</ul>
<p>There should always be a healthy, reciprocal relationship between you and any websites you're contributing to. I like to think that Stack Overflow gives back to the community as much as it absorbs — both in the form of <a href="https://www.brentozar.com/archive/2015/10/how-to-download-the-stack-overflow-database-via-bittorrent/">Creative Commons shared ownership of the underlying data</a>, and the strong emphasis on showing off the individual skills and knowledge of your fellow programmers.</p>
<p>Ultimately, you have to decide which is more important — building <em>your own</em> brand, or building the brand of the website you're contributing to? While these two concepts are not necessarily opposed, I strongly urge everyone reading this to err on the side of building <strong>your own brand</strong> whenever possible. Websites tend to come and go; the only sensible long term strategy is to invest in something that's guaranteed to be around for the rest of your life: you.</p>
<p>But I guess I'm biased.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-08-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/are-you-a-digital-sharecropper/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ All Programming is Web Programming ]]></title>
<link>https://blog.codinghorror.com/all-programming-is-web-programming/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Michael Braude <a href="http://michaelbraude.blogspot.com/2009/05/why-ill-never-be-web-guy.html">decries the popularity of web programming</a>:
</p>
<p>
</p>
<blockquote>
<b>The reason most people want to program for the web is that they're not smart enough to do anything else</b>.  They don't understand compilers, concurrency, 3D or class inheritance.  They haven't got a clue why I'd use an interface or an abstract class.  They don't understand: virtual methods, pointers, references, garbage collection, finalizers, pass-by-reference vs. pass-by-value, virtual C++ destructors, or the differences between C# structs and classes.  They also know nothing about process.  Waterfall?  Spiral?  Agile?  Forget it.  They've never seen a requirements document, they've never written a design document, they've never drawn a UML diagram, and they haven't even heard of a sequence diagram.
<p>
But they do know a few things: they know how to throw an ASP.NET webpage together, send some (poorly done) SQL down into a database, fill a dataset, and render a grid control.  This much they've figured out.  And the chances are good it didn't take them long to figure it out.
</p>
<p>
So forgive me for being smarmy and offensive, but I have no interest in being a 'web guy'. And there are two reasons for this.  First, it's not a challenging medium for me.  And second, because the vast majority of Internet companies are filled with bad engineers - precisely because you don't need to know complicated things to be a web developer.  As far as I'm concerned, the Internet is responsible for a collective dumbing down of our intelligence.  You just don't have to be that smart to throw up a webpage.
</p>
<p>
I really hope everybody's wrong and everything doesn't "move to the web."  Because if it does, one day I will either have to reluctantly join this boring movement, or I'll have to find another profession.
</p>
</blockquote>
<p>
Let's put aside, for the moment, the absurd argument that web development is not challenging, and that it attracts sub-par software developers. Even if that was true, it's irrelevant.
</p>
<p>
I hate to have to be the one to break the bad news to Michael, but for an increasingly large percentage of users, <a href="http://www.codinghorror.com/blog/archives/000883.html">the desktop application is already dead</a>. Most desktop applications typical users need have been replaced by web applications for years now. And more are replaced every day, as web browsers evolve to become more robust, more capable, more powerful.
</p>
<p>
You <i>hope</i> everything doesn't "move to the web"? Wake the hell up! <b>It's already happened!</b>
</p>
<p>
Any student of computing history will tell you that the dominance of web applications is  <a href="http://www.codinghorror.com/blog/archives/000913.html">exactly what the principle of least power predicts</a>:
</p>
<p>
</p>
<blockquote>
Computer Science spent the last forty years making languages which were as powerful as possible. <b>Nowadays we have to appreciate the reasons for picking not the most powerful solution but the least powerful.</b> The less powerful the language, the more you can do with the data stored in that language. If you write it in a simple declarative from, anyone can write a program to analyze it. If, for example, a web page with weather data has RDF describing that data, a user can retrieve it as a table, perhaps average it, plot it, deduce things from it in combination with other information. At the other end of the scale is the weather information portrayed by the cunning Java applet. While this might allow a very cool user interface, it cannot be analyzed at all. The search engine finding the page will have no idea of what the data is or what it is about. The only way to find out what a Java applet means is to set it running in front of a person.
</blockquote>
<p>
The web is the very embodiment of <a href="http://c2.com/xp/DoTheSimplestThingThatCouldPossiblyWork.html">doing the <s>stupidest</s>simplest thing that could possibly work</a>. If that scares you -- if that's disturbing to you -- then I humbly submit that you have no business being a programmer.
</p>
<p>
Should <i>all</i> applications be web applications? Of course not. There will continue to be important exceptions and classes of software that have nothing to do with the web. But these are minority and specialty applications. Important niches, to be sure, but niches nonetheless.
</p>
<p>
If you want your software to be <b>experienced by as many users as possible</b>, there is absolutely no better route than a web app. The web is the most efficient, most pervasive, most immediate distribution network for software ever created. Any user with an internet connection and a browser, anywhere in the world, is two clicks away from interacting with the software you wrote. The audience and reach of even the <i>crappiest</i> web application is astonishing, and getting larger every day. That's why I coined Atwood's Law.
</p>
<p>
</p>
<blockquote>
<b><a href="http://www.codinghorror.com/blog/archives/000913.html">Atwood's Law</a></b>: any application that <i>can</i> be written in JavaScript, <i>will</i> eventually be written in JavaScript.
</blockquote>
<p>
Writing Photoshop, Word, or Excel in JavaScript makes zero engineering sense, but it's inevitable. It will happen. In fact, it's already happening. Just look around you.
</p>
<p>
As a software developer, <b>I am happiest writing software <a href="http://www.codinghorror.com/blog/archives/000773.html">that gets used</a></b>. What's the point of <a href="http://www.codinghorror.com/blog/archives/001288.html">all this craftsmanship</a> if your software ends up locked away in a binary executable, which has to be <i>purchased</i> and <i>licensed</i> and <i>shipped</i> and <i>downloaded</i> and <i>installed</i> and <i>maintained</i> and <i>upgraded</i>? With all those old, traditional barriers between programmers and users, it's a wonder the software industry managed to exist at all. But in the brave new world of web applications, those limitations fall away. There are no boundaries. Software can be everywhere.
</p>
<p>
Web programming is far from perfect. It's <b>downright kludgy</b>. It's true that any J. Random Coder can plop out a terrible web application, and 99% of web applications are absolute crap. But this also means the truly <i>brilliant</i> programmers are now getting their code in front of hundreds, thousands, maybe even millions of users that they would have had absolutely no hope of reaching pre-web. There's nothing sadder, for my money, than code that dies unknown and unloved. Recasting software into web applications empowers programmers to get their software in front of <i>someone</i>, somewhere. Even if it sucks.
</p>
<p>
If the audience and craftsmanship argument isn't enough to convince you, <a href="http://www.skrenta.com/2007/07/fletchers_angry_list_of_startu.html">consider the business angle</a>.
</p>
<blockquote>
You're doing a web app, right? This isn't the 1980s. Your crummy, half-assed web app will still be more successful than your competitor's most polished software application.
</blockquote>
<p>
Pretty soon, <b>all programming will be web programming.</b> If you don't think that's a cause for celebration for the average working programmer, then maybe you <i>should</i> find another profession.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-08-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/all-programming-is-web-programming/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Only Truly Failed Project ]]></title>
<link>https://blog.codinghorror.com/the-only-truly-failed-project/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Do you remember <a href="http://en.wikipedia.org/wiki/Microsoft_Bob">Microsoft Bob</a>? If you do, you probably remember it as an intensely marketed but laughable failure – what some call <a href="http://www.microsoft-watch.com/content/operating_systems/bill_gates_legacy_microsofts_top_10_flops.html">the "number one flop" at Microsoft</a>.</p>
<p><img alt="image placeholder" >
<p>There's no <em>question</em> that Microsoft Bob was nothing short of an unmitigated disaster. But that's the funny thing about failures – <strong>they often lead to later successes</strong>. Take it from someone who <a href="http://www.techflash.com/microsoft/Innovation_The_lessons_of_Bob_53605837.html">lived and breathed the Bob project</a>:</p>
<blockquote>
<p>I was the one who sent Bill Gates email at the height of the positive Bob-mania that said we were likely to face a horrible backlash. Tech influentials had started telling me that they were going to bury Bob. They not only didn't like it, they were somehow angry that it had even been developed. It was personal.</p>
<p>And that's exactly what happened. Bob got killed. But first, it was ridiculed and stomped.</p>
<p>For Microsoft, it was a costly mistake. For the people who worked on it, Bob taught many lessons. Lessons that came into play for subsequent products that made a big impact, both at Microsoft and beyond.</p>
<p>How many people know that the lead developer for Bob 2.0 was also the <a href="http://en.wikipedia.org/wiki/Gabe_Newell">co-founder of Valve</a> and the development lead for Half-Life, which became an industry phenomenon, winning more than 50 Game of the Year awards and selling more than 10 million copies?</p>
<p>Or that Darrin Massena - development lead for Bob 1.0, most recently named Technical Innovator of the Year here in Washington State - and Valve co-founder <a href="http://en.wikipedia.org/wiki/Mike_Harrington">Mike Harrington</a> are the co-founders and partners behind <a href="http://en.wikipedia.org/wiki/Picnik">Picnik</a> - which is now the world's leading online photo editor, attracting almost 40 million visits a month and a million unique users a day.</p>
</blockquote>
<p>And then, of course, I'd be remiss if I didn't mention that Melinda French – Bill Gates' <a href="http://en.wikipedia.org/wiki/Melinda_Gates">future wife</a> – managed the Microsoft Bob project at one point. Bob was the first Microsoft consumer project that <a href="http://www.post-gazette.com/businessnews/19990523bob6.asp">Bill Gates personally had a hand in launching</a>. Well, at least he got a wife out of it.</p>
<p>Yes, Bob was an obvious, undisputed and epic failure. We can point and laugh at Bob. But to me, <strong>Bob is less of a comic figure than a tragic one</strong>.</p>
<p>Unless you're an exceptionally lucky software developer, you've probably worked on more projects that failed than projects that succeeded. Failure is <a href="http://www.codinghorror.com/blog/archives/000588.html">de rigeur in our industry</a>. Odds are, you're working on a project that will fail <em>right now</em>. Oh sure, it may not seem like a failure yet. Maybe it'll fail in some completely unanticipated way. Heck, maybe your project will buck the odds and even succeed.</p>
<p>But I doubt it.</p>
<p>I <a href="http://www.codinghorror.com/blog/archives/000770.html">own a boxed copy of Microsoft Bob</a>. I keep it on my shelf to remind me that these kinds of relentless, inevitable failures aren't the crushing setbacks they often appear from the outside. On the contrary; I believe it's <a href="http://www.codinghorror.com/blog/archives/000300.html">impossible to succeed without failing</a>.</p>
<blockquote>
<p>Charles Bosk, a sociologist at the University of Pennsylvania, once conducted a set of interviews with young doctors who had either resigned or been fired from neurosurgery-training programs, in an effort to figure out what separated the unsuccessful surgeons from their successful counterparts.</p>
<p>He concluded that, far more than technical skills or intelligence, <strong>what was necessary for success was the sort of attitude that Quest has – a practical-minded obsession with the possibility and the consequences of failure</strong>. "When I interviewed the surgeons who were fired, I used to leave the interview shaking," Bosk said. "I would hear these horrible stories about what they did wrong, but the thing was that they didn't know that what they did was wrong. In my interviewing, I began to develop what I thought was an indicator of whether someone was going to be a good surgeon or not. It was a couple of simple questions: Have you ever made a mistake? And, if so, what was your worst mistake? The people who said, 'Gee, I haven't really had one,' or, 'I've had a couple of bad outcomes but they were due to things outside my control' – invariably those were the worst candidates. And the residents who said, 'I make mistakes all the time. There was this horrible thing that happened just yesterday and here's what it was.' They were the best. They had the ability to rethink everything that they'd done and imagine how they might have done it differently."</p>
</blockquote>
<p>I recently watched the documentary <a href="http://www.amazon.com/dp/B000OV967S/?tag=codihorr-20">Tilt: The Battle to Save Pinball</a>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/JIolBJwH9p0" frameborder="0" allowfullscreen></iframe>
<p>It's a gripping story of a pinball industry in crisis. In order to save it, the engineers at Williams – the only remaining manufacturer of pinball machines in the United States – were given a herculean task: invent a new form of pinball <em>so compelling</em> that it makes all previous pinball machines seem obsolete. I don't want to spoil the whole documentary, so I'll gloss over exactly how that happened, but astoundingly enough – they succeeded.</p>
<p>And then were promptly laid off en masse, as Williams shut down its pinball operations.</p>
<p>Unlike Microsoft Bob, the Williams engineers built an almost revolutionary product that was both critically acclaimed and sold well – but <strong>none of that mattered</strong>. It's sobering to watch the end reel of Tilt, as the engineers involved mournfully discuss the termination of their bold and seemingly successful project.</p>
<blockquote>
<p>Everyone was in awe. They couldn't understand why it happened. Here we'd just done this thing that from all we could tell was a total success. Why would they do that?</p>
<p>We succeeded. Management gave us an impossible goal, and we sat there and we actually did what they thought we couldn't do.</p>
<p>You know, we didn't really win... we lost. I gave it everything I had. I think that those fifty guys that worked on it, they also passionately did everything that they could.</p>
</blockquote>
<p>Sometimes, <strong>even when your project succeeds, you've failed</strong>. Due to forces entirely beyond your control. It's depressing, but it's reality.</p>
<p>The trailout isn't all doom and gloom. It also documents the ways in which these talented pinball engineers went on to practice their craft after being laid off. Most of them still work in the video game or pinball industry. Some freelance. Others formed their own companies. A few went on to work at Stern Pinball, which figured out how to make a small number of pinball machines and still turn a profit.</p>
<p>These two stories, these two projects – the abject failure of Microsoft Bob, and the aborted success of Pinball 2000 – have something in common beyond mere failure. All the engineers involved <strong>not only survived these failures, but often went on to greater success afterwards</strong>. Possibly as a direct result of their work on these "failures".</p>
<p>Failure is a wonderful teacher. But there's no need to seek out failure. It will find you. Whatever project you're working on, consider it an opportunity to learn and practice your craft. <a href="http://www.codinghorror.com/blog/archives/001207.html">It's worth doing because, well, it's worth doing</a>. The journey of the project should be its own reward, regardless of whatever happens to lie at the end of that journey.</p>
<p>The only truly <em>failed</em> project is <strong>the one where you didn't learn anything along the way</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-08-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-only-truly-failed-project/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ That Means It's Working ]]></title>
<link>https://blog.codinghorror.com/that-means-its-working/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We may kid ourselves into thinking we're writing out of some sense of public good, or to create connections, or contribute some small bit of knowledge to the world. But let's face it. Most of us blog because <b>we're raving egomaniacs</b>. We not only love to hear ourselves talk, we're incredibly eager to hear other people talk about <i>us</i>, and the more the better. I think <a href="http://www.codinghorror.com/blog/archives/000752.html">Dale Carnegie put it best</a>.
</p>
<p>
</p>
<blockquote>
Nothing is sweeter to someone's ears than their own name.
</blockquote>
<p>
So it should come as no surprise that I have an automatic Google ego search set up for my name. Nothing special about that. It is considered neighborly to have your ear to the ground (within reason), and to politely comment on relevant articles mentioning you and your "stuff". All very standard, banal, ego-fluffing stuff.
</p>
<p>
But of all the mentions I've gotten, nobody has utterly nailed it in <a href="http://tncrocks.com/log/2009/03/10/ive-come-to-the-realization-t/">the way that Brian Gianforcaro has</a>.
</p>
<p>
<a href="http://www.codinghorror.com/blog/images/atwood-blog-post.png"><img alt="image placeholder" >
</p>
<p>
Right on. That's one thing you and I have in common, burny.
</p>
<p>
As a software developer, <a href="http://www.codinghorror.com/blog/archives/000878.html">you are your own worst enemy</a>. The sooner you realize that, the better off you'll be. In fact, that's the tipping point between amateurs and professionals in our industry: the professionals realize <a href="http://www.codinghorror.com/blog/archives/001020.html">everything they write sucks</a>.
</p>
<p>
So, to the extent that I can become a conduit for other programmers to have that same epiphany in their <i>own</i> programming careers, <b>that means it's working.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-08-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/that-means-its-working/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Have You Met Your Dog, Patches? ]]></title>
<link>https://blog.codinghorror.com/have-you-met-your-dog-patches/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The Gamasutra article <a href="http://www.gamasutra.com/view/feature/4111/dirty_coding_tricks.php">Dirty Coding Tricks</a> is a fantastic read. One part of it in particular rang true for me.
</p>
<p>
</p>
<blockquote>
Consider the load of pain I found myself in when working on a conversion of a 3D third person shooter from the PC to the original PlayStation.
<p>
Now, the PS1 has no support for floating point numbers, so we were doing the conversion by basically recompiling the PC code and overloading all floats with fixed point. That actually worked fairly well, but were it fell apart was in collision detection.
</p>
<p>
The level geometry that was supplied to us worked reasonably well in the PC version of the game, but when converted to fixed point, all kinds of seams, T-Junctions and other problems were nudged into existence by the microscopic differences in values between fixed and floats. This problem would manifest itself by the main character (called "Damp") simply falling through those tiny holes, into the abyss below the level.
</p>
<p>
We patched the holes we found, tweaking the geometry until Damp no longer fell through. But then the game went into test at the publisher, and suddenly a flood of "falling off the world" bugs were delivered to us. Every day a fresh batch of locations were found with these little holes that Damp could slip through. We would fix that bit of geometry, then the next day they would send us ten more. This went on for several days. The publisher's test department employed one guy whose only job was to jump around the world for ten hours a day, looking for places he could fall through.
</p>
<p>
<b>The problem here was that the geometry was bad.</b> It was not tight and seamless geometry. It worked on the PC, but not on the PS1, where the fixed point math vastly magnified the problems. The ideal solution was to fix the geometry to make it seamless.
</p>
<p>
However, this was a vast task, impossible to do in the time available with our limited resources, so we were relying on the test department to find the problem areas for us.
</p>
</blockquote>
<p>
There's never time to do it right, but there's always time to do it over. If this sounds familiar, you're not alone. I have at times found myself slipping into this pattern, continually patching the same code over and over. It's the kind of code that, when submitted for code review, you're tempted to self-deprecatingly introduce as <b>have you met my dog, patches?</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
While "patchiness" isn't always a bad thing -- the venerable Apache HTTP Server is testament to that -- it's <a href="http://en.wikipedia.org/wiki/Apache_HTTP_Server#History_and_name">probably an exception</a>.
</p>
<p>
</p>
<blockquote>
the original FAQ on the Apache Server project's website, from 1996 to 2001, claimed that "The result after combining [the NCSA httpd patches] was a patchy server."
</blockquote>
<p>
Reading the Gamasutra article shamed me into to attacking a section of extra-patchy Stack Overflow code. Code which I constantly had to tweak in various ongoing ways to get it to work right. But first, I had to <a href="http://www.codinghorror.com/blog/archives/000123.html">get over my fear</a>. Fear. That's what led to all the patching in the first place. It was obvious this was <a href="http://www.codinghorror.com/blog/archives/001230.html">working code which had become crufty over time</a>, but it <i>was working</i>. And it's one of the core bits of functionality in the site. In those circumstances, it's easy to mentally justify "just this small change, just this once" rather than the fundamental rewrite you really need.
</p>
<p>
When you finally realize you've spent the last six months telling yourself the same "just this small change, just this once" lie, then <b>you've met your dog patches, too</b>.
</p>
<p>
Now what are you going to do about that rascally scamp?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-08-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/have-you-met-your-dog-patches/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ If It Looks Corporate, Change It ]]></title>
<link>https://blog.codinghorror.com/if-it-looks-corporate-change-it/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Are you familar with <a href="http://www.codinghorror.com/blog/archives/000163.html">happy talk</a>?
</p>
<p>
</p>
<blockquote>
If you're not sure whether something is happy talk, there's one sure-fire test: if you listen very closely while you're reading it, you can actually hear a tiny voice in the back of your head saying "Blah blah blah blah blah...."
<p>
A lot of happy talk is the kind of self-congratulatory promotional writing that you find in badly written brochures. Unlike good promotional copy, it conveys no useful information, and focuses on saying how great we are, as opposed to delineating what makes us great.
</p>
</blockquote>
<p>
Happy talk is the kudzu of the internet; the place is lousy with the stuff.
</p>
<p>
And then there's the visual equivalent of happy talk. Those cloying, meaningless stock photos of happy users doing ... <i>something</i> ... with a computer.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
What is going on here? Given the beatific expressions, you'd think they were undergoing some kind of nerd rapture. Maybe they're getting a sneak preview of <a href="http://en.wikipedia.org/wiki/Technological_singularity">the singularity</a>, I don't know.
</p>
<p>
It's unclear to me why companies (and even some individuals) think they need happy talk, stock photos of multicultural computer users, or the occasional <a href="http://www.headsethotties.com/">headset hottie</a>. Jason Cohen <a href="http://blog.asmartbear.com/blog/youre-a-little-company-now-act-like-one.html">provides an explanation</a>:
</p>
<p>
</p>
<blockquote>
Even before I had a single customer, I "knew" it was important to look professional. My website would need to look and feel like a "real company." I need culture-neutral language complimenting culturally-diverse clip-art photos of frighteningly chipper co-workers huddled around a laptop, awash with the thrill and delight of configuring a JDBC connection to SQL Server 2008.
<p>
It also means adopting typical "marketing-speak," so my "About Us" page started with:
</p>
<p>
</p>
<blockquote>
Smart Bear is the leading provider of enterprise version control data-mining tools. Companies world-wide use Smart Bear's Code Historian software for risk-analysis, root-cause discovery, and software development decision-support.
</blockquote>
<p>
"Leading provider?" "Data mining?" I'm not even sure what that means. But you have to give me credit for an impressive quantity of hyphens.
</p>
<p>
That's what you're supposed to do, right? That's what other companies do, so it must be right. Who am I to break with tradition?
</p>
</blockquote>
<p>
I'm not sure where we got our ideas about this stuff, but it is true that some large companies promote a kind of doublespeak "professionalism". <a href="http://headrush.typepad.com/creating_passionate_users/2005/09/dignity_is_dead.html">Kathy Sierra describes her experiences at Sun</a>:
</p>
<p>
</p>
<blockquote>
By the time I got to Sun, using the word "cool" in a customer training document was enough to warrant an entry in your annual performance eval. <i>And not in a good way.</i>
<p>
I cannot count the times I heard the word "professionalism" used as justification for why we couldn't do something. But I can count the few times I heard the word "passion" used in a meeting where the goal was to get developers to adopt our newest Java technologies. What changed?
</p>
<p>
Some argue that by maintaining strict professionalism, we can get the more conservative, professional clients and thus grow the business. Is this true? Do we really need these clients? Isn't it possible that we might even grow more if we became braver?
</p>
</blockquote>
<p>
It's a shame that this misguided sense of professionalism is sometimes used as an excuse to put up weird, Orwellian communication barriers between yourself and the world. At best it is a facade to hide behind; at worst it encourages us to emulate so much of what is wrong with large companies. Allow me to paraphrase the <a href="http://www.codinghorror.com/blog/archives/000516.html">simple advice of Elmore Leonard</a>:
</p>
<p>
</p>
<blockquote>
If it looks corporate, change it.
</blockquote>
<p>
The next time you find yourself using <i>professional</i> text, or <i>professional</i> stock images, consider the value of this "professionalism". Is it legitimately helping you communicate? Or is it getting in the way?
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-09-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/if-it-looks-corporate-change-it/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ 9 Ways Marketing Weasels Will Try to Manipulate You ]]></title>
<link>https://blog.codinghorror.com/9-ways-marketing-weasels-will-try-to-manipulate-you/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I recently read <a href="http://www.amazon.com/dp/0061854549/?tag=codihorr-20">Predictably Irrational</a>.</p>
<p><a href="http://www.amazon.com/dp/0061854549/?tag=codihorr-20"><img alt="image placeholder" >
<p>It's a fascinating examination of why human beings are wired and conditioned to react irrationally. We human beings are a selfish bunch, so it's all the more surprising to see how easily we can be manipulated to behave in ways that run counter to our own self-interest.</p>
<p>This isn't just a "gee-whiz" observation; understanding how and why we behave irrationally is important. If you don't understand how these irrational behaviors are triggered, <b>the marketing weasels will use them against you.</b></p>
<p>In fact, it's already happening. Witness <a href="http://www.seomoz.org/blog/10-irrational-human-behaviors-how-to-leverage-them-to-improve-web-marketing">10 Irrational Human Behaviors and How to Leverage Them to Improve Web Marketing</a>. Don't say I didn't warn you.</p>
<p>Let's take a look at the various excerpts presented in that article, and consider <b>how we can avoid falling into the rut of predictably irrational behavior</b> – and defend ourselves from those vicious marketing weasels.</p>
<h2 id="1encouragefalsecomparisons">1. Encourage false comparisons</h2>
<blockquote>
<p>When Williams-Sonoma introduced bread machines, sales were slow. When they added a "deluxe" version that was 50% more expensive, they started flying off the shelves; the first bread machine now appeared to be a bargain</p>
<p>When contemplating the purchase of a $25 pen, the majority of subjects would drive to another store 15 minutes away to save $7. When contemplating the purchase of a $455 suit, the majority of subjects would not drive to another store 15 minutes away to save $7. The amount saved and time involved are the same, but people make very different choices. Watch out for relative thinking; it comes naturally to all of us.</p>
</blockquote>
<ul>
<li>Realize that some premium options exist as decoys – that is, they are there only to make the less expensive options look more appealing, because they're easy to compare. Don't make binding decisions solely based on how easy it is to compare two side-by-side options from the same vendor. Try comparing all the alternatives, even those from other vendors.</li>
<li>Don't be swayed by relative percentages for small dollar amounts. Yes, you saved 25%, but how much effort and time did you expend on that seven bucks?</li>
</ul>
<h2 id="2reinforceanchoring">2. Reinforce Anchoring</h2>
<blockquote>
<p>Savador Assael, the Pearl King, single-handedly created the market for black pearls, which were unknown in the industry before 1973. His first attempt to market the pearls was an utter failure; he didn't sell a single pearl. So he went to his friend, Harry Winston, and had Winston put them in the window of his 5th Avenue store with an outrageous price tag attached. Then he ran full page ads in glossy magazines with black pearls next to diamonds, rubies, and emeralds. Soon, black pearls were considered precious.</p>
<p>Simonsohn and Loewenstein found that people who move to a new city remain anchored to the prices they paid in their previous city. People who move from Lubbock to Pittsburgh squeeze their families into smaller houses to pay the same amount. People who move from LA to Pittsburgh don't save money, they just move into mansions.</p>
</blockquote>
<ul>
<li>Scale your purchases to your needs, not your circumstances or wallet size. What do you actually use? How much do you use it, and how frequently?</li>
<li>Try to objectively measure the value of what you're buying; don't be tricked into measuring relative to similar products or competitors. How much does buying this save you or your company? How much benefit will you get out of it? Attempt to measure that benefit by putting a concrete dollar amount on it.</li>
</ul>
<h2 id="3itsfree">3. It's "Free"!</h2>
<blockquote>
<p>Ariely, Shampanier, and Mazar conducted an experiment using Lindt truffles and Hershey's Kisses.  When a truffle was $0.15 and a kiss was $0.01, 73% of subjects chose the truffle and 27% the Kiss. But when a truffle was $0.14 and a kiss was <i>free</i>, 69% chose the kiss and 31% the truffle.</p>
<p>According to standard economic theory, the price reduction shouldn't have lead to any behavior change, but it did.</p>
<p>Ariely's theory is that for normal transactions, we consider both upside and downside. But when something is free, we forget about the downside. "Free" makes us perceive what is being offered as immensely more valuable than it really is. Humans are loss-averse; when considering a normal purchase, loss-aversion comes into play. But when an item is free, there is no visible possibility of loss</p>
</blockquote>
<ul>
<li>You will tend to overestimate the value of items you get for free. Resist this by viewing free stuff skeptically rather than welcoming it with open arms. If it was really that great, why would it be free?</li>
<li>Free stuff often comes with well hidden and subtle strings attached. How will using a free service or obtaining a free item influence your future choices? What paid alternatives are you avoiding by choosing the free route, and why?</li>
<li>How much effort will the free option cost you? Are there non-free options which would cost less in time or effort? How much is your time worth?</li>
<li>When you use a free service or product, you are implicitly endorsing and encouraging the provider, effectively beating a path to their door. Is this something you are comfortable with?</li>
</ul>
<h2 id="4exploitsocialnorms">4. Exploit social norms</h2>
<blockquote>
<p>The AARP asked lawyers to participate in a program where they would offer their services to needy employees for a discounted price of $30/hour. No dice. When the program manager instead asked if they'd offer their services for free, the lawyers overwhelmingly said they would participate</p>
</blockquote>
<ul>
<li>Companies may appeal to your innate sense of community or public good to convince you to do their work at zero pay. Consider carefully before choosing to participate; what do <i>you</i> get out of contributing your time and effort? Is this truly a worthy cause? Would this be worth doing if it was a paid gig?</li>
<li>When it comes to the web, make sure you aren't being turned into <a href="http://www.codinghorror.com/blog/archives/001295.html">a digital sharecropper</a>.</li>
</ul>
<h2 id="5designforprocrastination">5. Design for Procrastination</h2>
<blockquote>
<p>Ariely conducted an experiment on his class.  Students were required to write three papers.  Ariely asked the first group to commit to dates by which they would turn in each paper.  Late papers would be penalized 1% per day.  There was no penalty for turning papers in early.  The logical response is to commit to turning all three papers in on the last day of class. The second group was given no deadlines; all three papers were due in the last day of class. The third group was directed to turn their papers in on the 4th, 8th, and 12th weeks.</p>
<p>The results? Group 3 (imposed deadlines) got the best grades. Group 2 (no deadlines) got the worst grades, and Group 1 (self-selected deadlines) finished in the middle. Allowing students to pre-commit to deadlines improved performance. Students who spaced out their commitments did well; students who did the logical thing and gave no commitments did badly.</p>
</blockquote>
<ul>
<li>Steer clear of offers of low-rate trial periods which auto-convert into automatic recurring monthly billing. They know that most people will procrastinate and forget to cancel before the recurring billing kicks in.</li>
<li>Either favor fixed-rate, fixed-term plans – or become meticulous about cancelling recurring services when you're not using them.</li>
</ul>
<h2 id="6utilizetheendowmenteffect">6. Utilize the Endowment Effect</h2>
<blockquote>
<p>Ariely and Carmon conducted an experiment on Duke students, who sleep out for weeks to get basketball tickets; even those who sleep out are still subjected to a lottery at the end.  Some students get tickets, some don't. The students who didn't get tickets told Ariely that they'd be willing to pay up to $170 for tickets. The students who did get the tickets told Ariely that they wouldn't accept less than $2,400 for their tickets.</p>
<p>There are three fundamental quirks of human nature. We fall in love with what we already have. We focus on what we might lose, rather than what we might gain. We assume that other people will see the transaction from the same perspective as we do.</p>
</blockquote>
<ul>
<li>The value of what you've spent so far on a service, product, or relationship – in effort or money – is probably far less than you think. Be willing to walk away.</li>
<li>Once you've bought something, never rely on your internal judgment to assess its value, because you're too close to it now. Ask other people what they'd pay for this service, product, or relationship. Objectively research what others pay online.</li>
</ul>
<h2 id="7capitalizeonouraversiontoloss">7. Capitalize on our Aversion to Loss</h2>
<blockquote>
<p>Ariely and Shin conducted an experiment on MIT students. They devised a computer game which offered players three doors: Red, Blue, and Green. You started with 100 clicks. You clicked to enter a room. Once in a room, each click netted you between 1-10 cents. You could also switch rooms (at the cost of a click). The rooms were programmed to provide different levels of rewards (there was variation within each room's payoffs, but it was pretty easy to tell which one provided the best payout).</p>
<p>Players tended to try all three rooms, figure out which one had the highest payout, and then spend all their time there. (These are MIT students we're talking about). Then, however, Ariely introduced a new wrinkle: Any door left unvisited for 12 clicks would disappear forever.  With each click, the unclicked doors shrank by 1/12th.</p>
<p>Now, players jumped from door to door, trying to keep their options open.They made 15% less money; in fact, by choosing any of the doors and sticking with it, they could have made more money.</p>
<p>Ariely increased the cost of opening a door to 3 cents; no change–players still seemed compelled to keeping their options open. Ariely told participants the exact monetary payoff of each door; no change. Ariely allowed participants as many practice runs as they wanted before the actual experiment; no change. Ariely changed the rules so that any door could be "reincarnated" with a single click; no change.</p>
<p>Players just couldn't tolerate the idea of the loss, and so they did whatever was necessary to prevent their doors from closing, even though disappearance had no real consequences and could be easily reversed. We feel compelled to preserve options, even at great expense, even when it doesn't make sense.</p>
</blockquote>
<ul>
<li>If your choices are artificially narrowed, don't passively get funneled towards the goal they're herding you toward. Demand choice, even if it means switching vendors or allegiances.</li>
<li>Don't pay extra for options, unless you can point to hard evidence that you <i>need</i> those options. Some options exist just to make you doubt yourself, so you'll worry about not having them.</li>
</ul>
<h2 id="8engenderunreasonableexpectations">8. Engender Unreasonable Expectations</h2>
<blockquote>
<p>Ariely, Lee, and Frederick conducted yet another experiment on MIT students. They let students taste two different beers, and then choose to get a free pint of one of the brews.  Brew A was Budweiser.  Brew B was Budweiser, plus 2 drops of balsamic vinegar per ounce.</p>
<p>When students were not told about the nature of the beers, they overwhelmingly chose the balsamic beer. When students were told about the true nature of the beers, they overwhelmingly chose the Budweiser. If you tell people up front that something might be distasteful, the odds are good they'll end up agreeing with you–because of their expectations.</p>
</blockquote>
<ul>
<li>Whatever you've heard about a brand, company, or product – there's no substitute for your own hands-on experience. Let your own opinions guide you, not the opinions of others.</li>
<li>Just because something is labelled "premium" or "pro" or "award-winning" doesn't mean it is. Research these claims; don't let marketing set your expectations. Rely on evidence and facts.</li>
</ul>
<h2 id="9leveragepricingbias">9. Leverage Pricing Bias</h2>
<blockquote>
<p>Ariely, Waber, Shiv, and Carmon made up a fake painkiller, Veladone-Rx. An attractive woman in a business suit (with a faint Russian accent) told subjects that 92% of patients receiving VR reported significant pain relief in 10 minutes, with relief lasting up to 8 hours.</p>
</blockquote>
<blockquote>
<p>When told that the drug cost $2.50 per dose, nearly all of the subjects reported pain relief. When told that the drug cost $0.10 per dose, only half of the subjects reported pain relief. The more pain a person experienced, the more pronounced the effect. A similar study at U Iowa showed that students who paid list price for cold medications reported better medical outcomes than those who bought discount (but clinically identical) drugs.</p>
</blockquote>
<ul>
<li>Price often has nothing to do with value. Expensive is not synonymous with quality. Investigate whether the price is justified; never accept it at face value.</li>
<li>Don't fall prey to the "moneymoon"; just because you paid for something doesn't mean it's automatically worthwhile. Not everything we pay money for works well, or was even worth what we spent for it. We all make mistakes when buying things, but we don't want to admit it.</li>
</ul>
<p>What I learned from <a href="http://www.amazon.com/dp/0061854549/?tag=codihorr-20">Predictably Irrational</a> is that <b>everyone is irrational sometimes, and that's OK</b>. We're not perfectly logical Vulcans, after all. The trick is training yourself to know when you're <i>most likely</i> to make irrational choices, and to resist those impulses.</p>
<p>If you aren't at least aware of our sad, irrational human condition, well … that's exactly where the marketing weasels want you.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-09-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/9-ways-marketing-weasels-will-try-to-manipulate-you/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Email: The Variable Reinforcement Machine ]]></title>
<link>https://blog.codinghorror.com/email-the-variable-reinforcement-machine/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
How often do you check your email per day?
</p>
<p>
Does checking your email make you more productive or less productive?
</p>
<p>
Oh, sure, we delude ourselves into <i>thinking</i> we're being extra-productive by obsessively checking and responding to our email, but in reality we're attending too frequently to our own desire for gratification and sabotaging our own productivity in the process.
</p>
<p>
As Dan Ariely explains in a postscript to <a href="http://www.amazon.com/dp/0061854549/?tag=codihorr-20">Predictably Irrational</a>, he smells a rat, and so should you:
</p>
<p>
</p>
<blockquote>
Skinner distinguished between fixed-ratio schedules of reinforcement and variable-ratio schedules of reinforcement. Under a fixed schedule, a rat received a reward of food after it pressed the lever a fixed number of times -- say 100 times. Under the variable schedule, the rat earned a food pellet after it pressed the lever a <i>random</i> number of times. Sometimes it would receive the food pellet after pressing 10 times, and sometimes after pressing 200 times.
<p>
Under the variable schedule of reinforcement, the arrival of the reward is unpredictable. On the face of it, one might expect that the fixed schedules of reinforcement would be more motivating and rewarding because the rat can learn to predict the outcome of his work. Instead, Skinner found that the variable schedules were actually <i>more</i> motivating. The most telling result was that <b>when the rewards ceased, the rats who were under the fixed schedule stopped working almost immediately, but those under the variable schedules kept working for a very long time.</b>
</p>
</blockquote>
<p>
If this reminds you of gambling,  that's because <b>gambling explicitly works under the very same schedule of variable reinforcement</b>.
</p>
<p>
<a href="http://headrush.typepad.com/creating_passionate_users/2007/03/is_twitter_too_.html"><img alt="image placeholder" >
</p>
<p>
Go ahead, pull the "new email' lever. Take a chance. Most of the time you'll end up a loser, the proud recipient of yet another spam email, a press release you don't care about, or some irrelevant conversation someone has cc:ed you into. But not always. There are those rare few times when you'll hit the jackpot: you'll get an important bit of information you needed, or tentative contact from a long lost friend or associate, or other good news.
</p>
<p>
We're so ecstatic to get that single useful email out of hundreds that we can't keep ourselves from compulsively pressing the new email lever over and over and over, hoping it will happen again soon, like the caged rats in Skinners' experiments.
</p>
<p>
We desperately need to ask ourselves, and those around us, to <b>revisit the purpose of email</b>. Given what we know about <a href="http://softwarenation.blogspot.com/2009/01/importance-of.html">the importance of flow to productive work</a>, and how <a href="http://www.codinghorror.com/blog/archives/000691.html">multi-tasking is largely a myth</a>, is it worth the constant stream of minor interruptions?
</p>
<p>
We've overloaded email with so many meanings that it has imploded as a communication medium. Need an urgent answer to your question within a few minutes? Fire off a quick email and demand a response! Want to have a long back and forth discussion with several people? Email everyone! Do you have a new theory that you desperately want to explain to someone? Send it to them via email! Got a funny joke or picture you're dying to share? Email it to the office alias!
</p>
<p>
When we treat email as the kitchen sink of communication, appropriate for everything, <a href="http://www.codinghorror.com/blog/archives/001191.html">it simply ceases to work at all</a>.
</p>
<p>
Kathy Sierra was <a href="http://headrush.typepad.com/creating_passionate_users/2007/03/is_twitter_too_.html">concerned that Twitter had the same variable reinforcement problem</a>, but I think Twitter is in fact part of the <i>answer</i> to the problem.
</p>
<p>
</p>
<h1>Stop. Sending. Email.</h1>
<p>
Instead of abusing email as a "one size fits all" conduit for communication, be smart. <a href="http://www.codinghorror.com/blog/archives/001064.html">Know when to escalate your communication</a> to the right medium for the particular message you're trying to deliver:
</p>
<p>
</p>
<ul>
<li>Broad kudos? Post it on a feedback forum or your blog.
</li>
<li>Need an urgent, immediate answer? Pick up the phone and call.
</li>
<li>Got something that needs a lot of touchy feely discussion? Set up a face to face meeting.
</li>
<li>Discussing a particular topic or product? Post it on a public message board.
</li>
<li>Is this more of a friendly, social thing? Try using a social network like Twitter or Facebook.
</li>
<li>Business proposal? Perhaps it would be smart to approach indirectly, through soliciting recommendations of business associates.
</li>
</ul>
<p>
The real solution here is to move people beyond email silos wherever and whenever possible. Some amount of email is still inevitable, though. What steps can we take to turn our email from a dangerous variable reinforcement machine to something more Ã¢â‚¬Â¦ sane? Predictable, even?
</p>
<p>
</p>
<ul>
<li>Turn off all notification and interruption features in your email client.
</li>
<li>Only check your email at regular, scheduled intervals.
</li>
<li>Set up your email client to automatically highlight those emails from friends and business associates who are historically known to send you useful email.
</li>
</ul>
<p>
Before you send that next email -- or press the "retrieve mail" button again -- ask yourself: <i>do I smell a rat?</i>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-09-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/email-the-variable-reinforcement-machine/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Xanadu Dream ]]></title>
<link>https://blog.codinghorror.com/the-xanadu-dream/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Links are the <a href="https://blog.codinghorror.com/dont-click-here-the-art-of-hyperlinking/">fundamental building blocks of the web</a>. And every time I click on one, I can't help recalling the odd visionary who came up with the original idea of clickable links in text, aka <a href="http://en.wikipedia.org/wiki/Hypertext">hypertext</a>, in 1963 -- <a href="http://en.wikipedia.org/wiki/Ted_Nelson">Ted Nelson</a>.</p>
<p>Ted Nelson is, shall we say, a <i>character</i>. He has gone on record many times with the four maxims that guide his life. He isn't shy about sharing them with anyone he meets:</p>
<ul>
<li>most people are fools</li>
<li>most authority is malignant</li>
<li>God does not exist</li>
<li>everything is wrong</li>
</ul>
<p>And that, in a nutshell, is pretty much everything you need to know about Ted Nelson. He is <b>the archetypal borderline autistic, non-conformist, free-thinking technologist</b>. Any resemblance between Ted and your average programmer is, I'm sure, completely coincidental. That's why his story is so fascinating to me. It hits close to home.</p>
<p>Like most programmers, Ted's reach often exceeded his grasp. Ted's vision of hypertext was far more grandiose than the motley assortment of links that is today's web. His vision was (and is) a bit of computer history lore that has become the stuff of legend: <a href="http://en.wikipedia.org/wiki/Project_Xanadu">Project Xanadu</a>.</p>
<blockquote>
<p>Xanadu, a global hypertext publishing system, is the longest-running vaporware story in the history of the computer industry. It has been in development for more than 30 years. This long gestation period may not put it in the same category as the Great Wall of China, which was under construction for most of the 16th century and still failed to foil invaders, but, given the relative youth of commercial computing, Xanadu has set a record of futility that will be difficult for other companies to surpass. The fact that Nelson has had only since about 1960 to build his reputation as the king of unsuccessful software development makes Xanadu interesting for another reason: the project's failure (or, viewed more optimistically, its long-delayed success) coincides almost exactly with the birth of hacker culture. Xanadu's manic and highly publicized swerves from triumph to bankruptcy show a side of hackerdom that is as important, perhaps, as tales of billion-dollar companies born in garages.</p>
<p><a href="http://www.imdb.com/title/tt0081777/"><img alt="image placeholder" >
<p>Among people who consider themselves insiders, Nelson's Xanadu is sometimes treated as a joke, but this is superficial. Nelson's writing and presentations inspired some of the most visionary computer programmers, managers, and executives - including Autodesk Inc. founder John Walker - to pour millions of dollars and years of effort into the project. Xanadu was meant to be a universal library, a worldwide hypertext publishing tool, a system to resolve copyright disputes, and a meritocratic forum for discussion and debate. By putting all information within reach of all people, Xanadu was meant to eliminate scientific ignorance and cure political misunderstandings. And, on the very hackerish assumption that global catastrophes are caused by ignorance, stupidity, and communication failures, Xanadu was supposed to save the world.</p>
</blockquote>
<p>The above text is excerpted from <a href="https://www.wired.com/1995/06/xanadu/">the definitive 1995 Wired article on Project Xanadu</a>, which is still as electrifying to read today as it was then. The hubris and sheer scale of the Xanadu dream are at turns both inspiring and desperately, hopelessly out of touch.</p>
<p>Xanadu has 17 rules defining its behavior. As you're reading through this list, ask yourself <b>how many of these rules are satisfied by the current world wide web</b>, even in part:</p>
<ol>
<li>Every Xanadu server is uniquely and securely identified.</li>
<li>Every Xanadu server can be operated independently or in a network.</li>
<li>Every user is uniquely and securely identified.</li>
<li>Every user can search, retrieve, create and store documents.</li>
<li>Every document can consist of any number of parts each of which may be of any data type.</li>
<li>Every document can contain links of any type including virtual copies ("transclusions") to any other document in the system accessible to its owner.</li>
<li>Links are visible and can be followed from all endpoints.</li>
<li>Permission to link to a document is explicitly granted by the act of publication.</li>
<li>Every document can contain a royalty mechanism at any desired degree of granularity to ensure payment on any portion accessed, including virtual copies ("transclusions") of all or part of the document.</li>
<li>Every document is uniquely and securely identified.</li>
<li>Every document can have secure access controls.</li>
<li>Every document can be rapidly searched, stored and retrieved without user knowledge of where it is physically stored.</li>
<li>Every document is automatically moved to physical storage appropriate to its frequency of access from any given location.</li>
<li>Every document is automatically stored redundantly to maintain availability even in case of a disaster.</li>
<li>Every Xanadu service provider can charge their users at any rate they choose for the storage, retrieval and publishing of documents.</li>
<li>Every transaction is secure and auditable only by the parties to that transaction.</li>
<li>The Xanadu client-server communication protocol is an openly published standard. Third-party software development and integration is encouraged.</li>
</ol>
<p>It is instructive, then, to consider the primary ways in which the modern web is functionally broken:</p>
<ul>
<li>
<b>Link rot</b>. The odds of a hyperlink working are inversely proportional to the age of that hyperlink. Old links frequently break, because the server hosting the content disappears for any number of reasons over time. I've gotten to the point where I dread clicking on links from old web pages, because the per-click success rate is so abysmally low.</li>
<li>
<b>Every website has unique usernames and passwords</b>. There is almost no <a href="https://blog.codinghorror.com/openid-does-the-world-really-need-yet-another-username-and-password/">reliable centralized form of identity on the internet</a>, and those few that do exist are often poisoned by explicit commercial affiliation, such as Facebook Connect and Microsoft Passport. This is why curated anonymous, lightweight participation dominates the net -- best illustrated by Wikipedia.</li>
<li>
<b>No redundancy</b>. If content is driven offline by temporary high traffic levels or, worse, catastrophic data loss, there may not be any way to recover that content. I know that Digg has services which auto-mirror highly rated links because Digg traffic can be so toxic to the destination links. (Ironically, all duggmirror.com links redirect to amazon.com now, which illustrates how ephemeral all this stuff tends to be.) I suppose if you're lucky the <a href="http://www.archive.org/">wayback machine</a> will eventually pick up a historical copy of the content, or the <a href="http://www.googleguide.com/cached_pages.html">Google cache</a> will hold a copy for some unknown amount of time while the site is offline. You'd probably have better odds praying for missing content to reappear.</li>
</ul>
<p>Let's put aside the more ambitious parts of Project Xanadu for the moment. <b>The current world wide web does basically <i>one</i> thing: simple, stupid, mindless hyperlinks</b>. But even that alone was enough to build a functional and useful internet for the world. And Google was able to build a <a href="https://blog.codinghorror.com/markov-and-you/">zillion dollar algorithm</a> out of discovering the relationship between those dumb hyperlinks.</p>
<p>All that, when the most fundamental building block of the web, the hyperlink, <i>barely works at all</i>. Hyperlinks are fraught with peril and pitfalls even under the best of conditions. The current state of hyperlinking is almost literally the stupidest thing we could build that works. Frankly, the current system sucks beyond belief, as Ted himself notes:</p>
<blockquote>
<p>HTML is precisely what we were trying to <i>prevent</i> -- ever-breaking links, links going outward only, quotes you can't follow to their origins, no version management, no rights management.</p>
</blockquote>
<p>The next time you're about to embark on a grandiose, glorious software Xanadu Dream of your own, <a href="http://www.25hoursaday.com/weblog/2009/09/27/DuctTapeProgrammersAndTheCultureOfComplexityInSoftwareProjects.aspx">take Dare's advice</a>.</p>
<blockquote>
<p>The bottom line is that a lot of the time it's OK to create a solution that solves 80% of the problem. Always remember that shipping is a feature.</p>
</blockquote>
<p>Consider the reality of what's actually possible, what people can understand, and what us all too human programmers can practically implement. It might not be the Xanadu you dreamed of -- heck, it might even <i>suck</i> – but it'll at least have a fighting chance of <b>existing in reality rather than fantasy</b>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-10-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-xanadu-dream/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The State of Solid State Hard Drives ]]></title>
<link>https://blog.codinghorror.com/the-state-of-solid-state-hard-drives/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've seen a lot of people play <a href="http://www.codinghorror.com/blog/archives/001235.html">The Computer Performance Shell Game</a> poorly. They overinvest in a fancy CPU, while pairing it with limited memory, a plain jane hard drive, or a generic video card. For most users, that fire-breathing quad-core CPU is sitting around twiddling its virtual thumbs most of the time. Computer performance is typically limited by the <i>slowest</i> part in your system. You'd get better overall performance by building a balanced system and removing bottlenecks.
</p>
<p>
One of those key bottlenecks -- and in my experience, the one typical users are most likely to underestimate -- is the hard drive. I've been a long time <a href="http://www.codinghorror.com/blog/archives/000800.html">advocate of having a small, fast 10,000 RPM boot drive</a> for your OS and key applications, and a larger, slower secondary drive for storage. The two drive approach is a smart strategy, regardless of your budget.
</p>
<p>
Hard drives may not be particularly sexy bits of hardware, but we're on the verge of a <b>major transition point in storage hardware</b> -- from physical, magnetic platters to solid state memory. I was an early solid state (SSD) drive adopter with <a href="http://www.codinghorror.com/blog/archives/000927.html">my last laptop purchase</a>, and it was a profound disappointment. Those first and second generation SSD drives turned out to be <i>slower</i> than their magentic equivalents, despite the eager promises of vendors. On top of that, they were incredibly expensive, and of limited capacity. Running Windows Vista on an early 32 gigabyte SSD was an exercise in pain and frustration on so many levels. What's not to love? A lot.
</p>
<p>
I eventually sold that SSD and replaced it with a traditional hard drive. I had grown deeply disillusioned with SSD drives. That is, until I read <a href="http://torvalds-family.blogspot.com/2008/10/so-i-got-one-of-new-intel-ssds.html">Linus Torvalds' report on the Intel X-25 SSD</a>:
</p>
<p>
</p>
<blockquote>
I can't recall the last time that a new tech toy I got made such a dramatic difference in performance and just plain usability of a machine of mine.
<p>
The whole thing just rocks. Everything performs well. You can put that disk in a machine, and suddenly you almost don't even need to care whether things were in your page cache or not. Firefox starts up pretty much as snappily in the cold-cache case as it does hot-cache. You can do package installation and big untars, and you don't even notice it, because your desktop doesn't get laggy or anything.
</p>
<p>
So here's the deal: right now, don't buy any other SSD than the Intel ones, because as far as I can tell, all the other ones are pretty much inferior to the much cheaper traditional disks, unless you never do any writes at all (and turn off 'atime', for that matter).
</p>
</blockquote>
<p>
At that moment, SSD drives came of age. And by that I mean, <b>they began to justify their hefty price premium at last</b>. But that was almost a year ago, and even the Intel drives -- as great as they were -- had <a href="http://hardware.slashdot.org/article.pl?sid=09/02/13/2337258">some teething problems</a>. Not to mention that price and capacity were still ongoing concerns.
</p>
<p>
But when Intel introduced the <a href="http://techreport.com/articles.x/17269/1">second generation, mainstream X25-M drives</a>, that's when I knew SSDs were poised to go mainstream. Now, those drives are still anything but <i>cheap</i>, at <b>$289 for 80 GB</b> and <b>$609 for 160 GB</b>. But they offer more performance than the original X25-E that Linus reviewed, at about half the price, with hardware fixes to address the fragmentation issue that plagued the original model.
</p>
<p>
Intel was the only game in town for about a year, but fortunately for us consumers, the competition finally caught up. The new Indilinx controller models, such as this <a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820148319%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-Crucial%2BTechnology-_-20148319&amp;cjsku=N82E16820148319">Crucial 128 GB SSD</a>, are just as fast as the X25-M. And, best of all, they're <i>cheaper</i>, while also offering a not-insubstantial bump to 128 GB of storage!
</p>
<p>
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820148319%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-Crucial%2BTechnology-_-20148319&amp;cjsku=N82E16820148319"><img alt="image placeholder" >
</p>
<p>
I picked this model up for <b>$325</b> plus tax and shipping. And, frankly, I was <b>blown away by the performance difference</b> compared to the 300 GB Velociraptor I had in my system before. That drive is not exactly chopped liver; it's incredibly fast by magnetic platter drive standards. But it's <i>beyond</i> slow next to the latest SSDs. See for yourself:
</p>
<p>
<a href="http://www.bjorn3d.com/read.php?cID=1651&amp;pageID=7405"><img alt="image placeholder" >
</p>
<p>
This is just an excerpt, <a href="http://www.google.com/search?q=crucial+CT128M225+ssd+review">browse the reviews</a> for more detail, but I was astonished how often this drive (based on the Indilinx Barefoot controller) topped the charts. Suffice it to say, <b>the performance increase is not subtle</b>. All those little pauses while your system pulls some chunk of data off the hard drive? They simply <i>cease to exist</i>.
</p>
<p>
How much do I like this drive? I like it so very much I bought one for every member of the Stack Overflow team, as a small gesture of thanks for enduring <a href="http://blog.stackoverflow.com/2009/10/introducing-stack-overflow-careers/">new feature crunch mode</a>. I couldn't sell my old Velociraptor on eBay fast enough.
</p>
<p>
In my humble opinion, $200 - $300 for a SSD is <i>easily</i> <b>the most cost effective performance increase you can buy</b> for a computer of anything remotely resembling recent vintage. Whether you prefer the <a href="http://www.jdoqocy.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820167016%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-Intel-_-20167016&amp;cjsku=N82E16820167016">80 GB X25-M SSD</a> or the <a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820148319%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-Crucial%2BTechnology-_-20148319&amp;cjsku=N82E16820148319">128 GB Crucial SSD</a>, it's money well invested for people like us who are obsessive about how their computer performs.
</p>
<p>
Trust me, you <i>will</i> feel the performance difference of a modern SSD in day to day computing. That's <b>far more than I can say for most of today's CPU and memory upgrades</b>. The transition from magnetic storage to solid state storage is nothing less than a breakthrough. It's already transformative; I can only imagine how fast, cheap, and large these drives are going to be in a few years. So, if you've ever wondered what performance would be like if everything was in RAM all the time -- well, we just got one giant step closer to that.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-10-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-state-of-solid-state-hard-drives/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Interview With The Programmer ]]></title>
<link>https://blog.codinghorror.com/the-interview-with-the-programmer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If the internet has perfected anything, it's the art of the crappy, phoned-in, half-assed email "interview". For all those who have bemoaned the often pathetic state of internet journalism, when it comes to interviews, you're largely correct. The purpose of most of these interviews is quick and dirty content filler with semi-famous folk spouting off whatever random thoughts they happen to have in their head at that exact moment. <a href="http://en.wikipedia.org/wiki/The_Nixon_Interviews">The Nixon Interviews</a>, it ain't.
</p>
<p>
That's why I'm normally not a huge fan of interview books, because interviews take an enormous amount of time and an enormous amount of legitimate, skilled journalistic effort to get right. Almost nobody does.
</p>
<p>
Imagine my surprise when <a href="http://www.amazon.com/dp/1430219483/?tag=codihorr-20">Coders at Work: Reflections on the Craft of Programming</a> turns out to be that wonderfully rare intersection of uncommonly skilled interviewing and 15 of the most influential programmers to ever touch a keyboard.
</p>
<p>
<a href="http://www.amazon.com/dp/1430219483/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
Yes, this is the same book Joel recently recommended in his controversial <a href="http://www.joelonsoftware.com/items/2009/09/23.html">Duct Tape Programmer</a> entry, which is why I was all the more skeptical. But he's dead on. I could (and probably will, knowing me) fill a year worth of blog posts just with the thought provoking quotes and two-paragraph insights revealed in these interviews. It's astonishingly good. If, after reading what these brilliant programmers have to say, you aren't motivated to research some programming topic mentioned inside, pack it in, because you aren't even <i>trying</i> any more.
</p>
<p>
I also realized Coders at Work can potentially serve as a job interview filter. If the next programmer you interview can't identify at least <i>one</i> of the programmers interviewed in <a href="http://www.amazon.com/dp/1430219483/?tag=codihorr-20">Coders at Work</a> and tell you roughly what they're famous for Ã¢â‚¬Â¦
</p>
<p>
</p>
<table width="450">
<tr>
<td>Frances Allen</td>
<td>Joe Armstrong</td>
<td>Joshua Bloch</td>
</tr>
<tr>
<td>Bernie Cosell</td>
<td>Douglas Crockford</td>
<td>L. Peter Deutsch</td>
</tr>
<tr>
<td>Brendan Eich</td>
<td>Brad Fitzpatrick</td>
<td>Dan Ingalls</td>
</tr>
<tr>
<td>Simon Peyton Jones</td>
<td>Donald Knuth</td>
<td>Peter Norvig</td>
</tr>
<tr>
<td>Guy Steele</td>
<td>Ken Thompson</td>
<td>Jamie Zawinski</td>
</tr>
</table>
<p>
Ã¢â‚¬Â¦ I'd say that's an immediate no-hire.
</p>
<p>
Incidentally, I saw the first Stack Overflow user reference on page 265, in the interview with Simon Peyton Jones, who mentions one <a href="http://www.cs.tufts.edu/~nr/">Norman Ramsey</a>. Hmm, I thought, that name sounds awfully familiar. And indeed <a href="http://stackoverflow.com/users/41661/norman-ramsey">it was</a>!
</p>
<p>
I would be remiss if I did not mention that the author, Peter Seibel, was <a href="http://www.codersatwork.com/">directly inspired</a> by Susan Lammers' classic 1986 book <a href="http://www.amazon.com/dp/1556152116/?tag=codihorr-20">Programmers at Work: Interviews With 19 Programmers Who Shaped the Computer Industry</a>.
</p>
<p>
<a href="http://www.amazon.com/dp/1556152116/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
This is one of my absolute favorite musty old computer books for many of the same reasons. As sources of inspiration go, this one is particularly Ã¢â‚¬Â¦ er, inspired. <a href="http://www.amazon.com/dp/1556152116/?tag=codihorr-20">Programmers at Work</a> isn't just <i>the</i> archetypal programmer interview book -- it also holds up amazingly well for a book that is over twenty years old. It is a testament to the timelessness of not just code, but the art of coding, as exemplified by these 19 programmers. I believe Peter has legitimately crafted a modern remake that will be relevant for another twenty years. And I hope I don't have to tell you how extraordinarily rare that is among technical books.
</p>
<p>
(Some -- but not all from what I can tell -- key interviews from Programmers at Work were <a href="http://programmersatwork.wordpress.com/">placed online</a> last year by the author. So if you want to get a flavor of the book, check it out.)
</p>
<p>
Another notable recent collection of interviews is <a href="http://www.amazon.com/dp/0596515170/?tag=codihorr-20">Masterminds of Programming: Conversations with the Creators of Major Programming Languages</a>.
</p>
<p>
<a href="http://www.amazon.com/dp/0596515170/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
Although I definitely enjoyed this book, there's something about the focus on programming languages and interview style that didn't quite grab me as forcefully as Coders at Work did. Also, if we're going to do languages, I'd like to see a bit broader representation -- perhaps a Volume II with Smalltalk, Ada, Pascal and so on?
</p>
<p>
These books are a potent reminder that computers are mostly a reflection of the people using them. In the art of software development, studying code isn't enough: <b>you have to study the people behind the software, too</b>.
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-10-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-interview-with-the-programmer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Treating User Myopia ]]></title>
<link>https://blog.codinghorror.com/treating-user-myopia/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I try not to talk too much about the <a href="http://blog.stackoverflow.com/2009/05/the-stack-overflow-trilogy/">trilogy</a> here, because there's <a href="http://blog.stackoverflow.com/">a whole other blog</a> for that stuff. But some of the lessons I've learned in the last year while working on them really put into bold relief some of my earlier blog entries on usability and user behavior.
</p>
<p>
One entry in particular that I keep coming back to is <a href="http://www.codinghorror.com/blog/archives/000114.html">Teaching Users to Read</a>. That was specific to dialog boxes, which not only <a href="http://www.codinghorror.com/blog/archives/000676.html">stop the proceedings with idiocy</a>, but are their own delightful brand of user interface poison. Fortunately, you don't see dialogs in web apps much, but this sort of modal dialog lunacy is, sadly, becoming more popular in today's AJAX-y world of web 2.5. Those who can't learn from history are <a href="http://en.wikiquote.org/wiki/George_Santayana">doomed to repeat it</a>, I guess.
</p>
<p>
Having five more years of development experience under my belt, I no longer believe that classic Larson strip is specific to dialog boxes.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The plain fact is <strong>users will not read <em>anything</em> you put on the screen</strong>.
</p>
<p>
What we're doing with the trilogy is not exactly rocket surgery. At its core, we run Q&amp;A websites. And the most basic operation of any Q&amp;A website is – asking a question. Something any two year old child knows how to do.
</p>
<p>
When we launched <a href="http://superuser.com">superuser.com</a>, that was our <s>third</s>fourth Q&amp;A website. This one is for power users, and it's the broadest to date, topic-wise: most things dealing with computer software or hardware (that isn't gaming, or shopping) is allowed.
</p>
<p>
We've been at this for over a year now, doing nothing but relentlessly polishing and improving our Q&amp;A engine based on community feedback. We're not particularly good, but we do try very, very hard not to suck. I thought surely, <em>surely</em> we must have something as simple as <strong>the ask question form</strong> down by now.
</p>
<p>
How foolish I was.
</p>
<p>
Let's take a look at one recent superuser question. I'm presenting it here as it would have been seen by the user who asked the question, while they were entering it on the ask question form.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Immediately, there's a problem. <strong>The question formatting is completely wrong!</strong> It's one big jumble of text.
</p>
<p>
Our formatting rules aren't complicated. You can get a lot done with a bunch of simple paragraphs. <a href="http://www.codinghorror.com/blog/archives/001116.html">We use Markdown</a>, which offers basic formatting conventions that ape ASCII conventions. On top of that, we offer a <strong>real-time preview</strong> of how your question will look once submitted, directly under the question entry area. But none of that seemed to work for this particular asker, who, apparently, was totally satisfied with obviously broken formatting – even though a few choice carriage returns would have worked wonders, and been immediately visible in the live preview.
</p>
<p>
Yes, yes, it inevitably gets whipped into shape through the collective efforts of our legions of community editors – but that's not the point. It's best if the original asker gets the question formatted right to start with, and it is our job as UI designers to make that outcome as statistically likely as we can.
</p>
<p>
To that end, we've put a bunch of helpful tools on the ask question page to help users get the formatting right. <strong>As UI designers, here's how we see the ask question page</strong>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
We've provided a toolbar with a <em>neon pink</em> help button above the question body, and to the right of the question body, we've provided a handy formatting quick reference with a link to the full formatting reference (which opens in a tab / new window by default).
</p>
<p>
But none of that matters, because <strong>here's how the user sees the ask question page</strong>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Or rather, here's everything the user <em>doesn't</em> see.
</p>
<p>
When I said users don't read anything you put on the screen, I was lying. Users do read. But <strong>users will only read the <em>absolute minimum</em> amount of text on the screen necessary to complete their task</strong>. I can't quite explain it, but this kind of user myopia is epidemic. It's the same problem, everywhere I turn.
</p>
<p>
How do we treat user myopia? How do we reach these users? The ask question page is already dangerously close to cluttered with helpful tips, but apparently these helpful buttons, links, and text are all but invisible to a large segment of the user population. Sure, you could argue that <a href="http://superuser.com/">Super User</a> tends to attract less sophisticated users, but I see the exact same problem with programmers on <a href="http://stackoverflow.com">Stack Overflow</a>. As new users, a significant percentage of them can't figure out how to format code, even though there's not only a toolbar button that does it for you, but help text on the right explicitly describing how to do it manually. (Just indent 4 spaces. Spoiler alert!)
</p>
<p>
More and more, I'm thinking we need to put the formatting help – for new users only – <strong>directly in their line of sight</strong>. That is, pre-populate the question entry area with some example formatting that is typical of the average question. Nothing complicated. But at least then it'd be in the one – and apparently the <em>only</em> one – place myopic users are willing to look. Right in front of their freakin' faces.
</p>
<p>
The next time you're designing a UI, consider user myopia. You might be surprised just how myopic your users can be. Think long and hard about placing things <em>directly</em> in front of them, where they are not just visible, but <em>unavoidable</em>. Otherwise they might not be seen at all.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-10-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/treating-user-myopia/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Revisiting "The Fold" ]]></title>
<link>https://blog.codinghorror.com/revisiting-the-fold/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
After I posted my blog entry on <a href="http://www.codinghorror.com/blog/archives/001306.html">Treating User Myopia</a> I got a lot of advice. Some useful, some not so useful. But the one bit of advice I hadn't anticipated was that we were not making good use of the area "above the fold". This surprised me. <b>Does the fold still matter?</b>
</p>
<p>
The fold refers to the border at the bottom of the browser window at the user's default screen resolution. Like so:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Way back in the dark ages of 1996, it was commonly thought that <a href="http://www.codinghorror.com/blog/archives/000376.html">users didn't know how to scroll a web page</a>.
</p>
<p>
</p>
<blockquote>
On the Web, the inverted pyramid becomes even more important since we know from several user studies that users don't scroll, so they will very frequently be left to read only the top part of an article.
</blockquote>
<p>
Thus, it was critically important to <b>cram in as much content in as possible above that fold</b>, as anything below it was invisible to a huge number of users. They didn't know how to scroll, so they would never find it. Jacob Neilsen, renowned usability expert, is the author of the above quote. But he recanted his position in 2003:
</p>
<p>
</p>
<blockquote>
In 1996, I said that "users don't scroll." This was true at the time: many, if not most, users only looked at the visible part of the page and rarely scrolled below the fold. The evolution of the Web has changed this conclusion. As users got more experience with scrolling pages, many of them started scrolling.
</blockquote>
<p>
Scrolling is an example <a href="http://www.codinghorror.com/blog/archives/000376.html">usability versus learnability</a>. It was always my belief that users quickly learned to scroll, otherwise they were permanently crippled as web citizens. If you can't learn to scroll within an hour or so of using the web, you're going to have an awfully stunted experience -- so much so that you're probably better off not using it at all. In short, if you use the web, <i>you know how to scroll</i>, almost by definition. It is a fundamental skill.
</p>
<p>
Even today, people will <b>cite the ancient, irrelevant rule of The Fold</b> as if it's still law. In fact, I was just talking to a friend of mine who expressed his frustration at dealing with a middle manager who was using the "content must be above the fold" rule as a weapon, and demanding that all page content appear above the fold. It's terribly misguided.
</p>
<p>
Although thoroughly debunked, there are <b>still some hidden dangers from the fold</b>, and subtlety to how users react to it. As documented by <a href="http://www.cxpartners.co.uk/thoughts/the_myth_of_the_page_fold_evidence_from_user_testing.htm">a recent usability study on the fold</a>, there are three specific pitfalls to watch out for:
</p>
<p>
</p>
<ol>
<li>
<b>Don't cram everything in above the fold.</b> Users will explore and find your content -- as long as the page "looks" scrollable.
</li>
<li>
<b>Watch out for stark, horizontal lines that happen to line up with the fold.</b> This is the only factor that causes users to stop scrolling, because the page looks done and complete. Instead, have a small amount of content just visible, poking up above the fold. This encourages scrolling.
</li>
<li>
<b>Avoid in-page scroll bars</b>. The standard browser scrollbar is an indicator of the amount of content on the page that users learn to rely on. Placing &lt;iframe&gt; and other elements with scroll bars on the page can break this convention -- and may lead to users not scrolling.
</li>
</ol>
<p>
These are excellent guidelines, <a href="http://www.cxpartners.co.uk/thoughts/the_myth_of_the_page_fold_evidence_from_user_testing.htm">backed by actual eye tracking and experimental results</a>. You know, <i>science!</i> But how do they apply to me? First, I established where the fold actually was. Per Google Analytics, <b>about 25% of our users are using screen resolutions where the page fold is at about 700 or 800 pixels of height</b>. And remember, browsers have a lot of horizontal chrome that tends to squander that height -- toolbars, status bars, tabs, etcetera. The fold is probably much closer than you think it is.
</p>
<p>
Next, I looked at the advice I had been given regarding the top of the page. Sure enough, we had a bunch of irrelevant UI at the top that didn't really matter: things like redundant page titles, and two line title entry. <b>We were wasting critical real estate at the top of the page!</b> For the 25% of users who have a 700 or 800 pixel fold, items were pushed down far enough that they might not actually be visible. Worse still, the strong bottom border of the text entry area with the drag slider <i>could</i> possibly align with the page fold itself -- leading the user to believe that nothing is below there and failing to scroll.
</p>
<p>
It's not only a basic rule of writing, it's also a basic rule of the web: put the most important content at as close to the top of the page as you can. This isn't new advice, but it's so important that it never hurts to revisit it periodically in your own designs.
</p>
<p>
In treating user myopia, it's not enough to place important stuff directly in the user's eyepoint. You also need to ensure that you've placed the absolute <i>most important stuff</i> at the top of the page -- and haven't created any accidental barriers to scrolling, so they can find the rest of it. The fold is far less important than it used to be, but it isn't quite as mythical as Bigfoot and the Loch Ness Monster quite yet.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-10-26T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/revisiting-the-fold/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Stack Overflow Careers: Amplifying Your Awesome ]]></title>
<link>https://blog.codinghorror.com/stack-overflow-careers-amplifying-your-awesome/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
That <a href="http://www.codinghorror.com/blog/archives/001101.html">Stack Overflow thing we launched a year ago</a>? It's been <a href="http://blog.stackoverflow.com/2009/08/us-versus-hyphen/">going pretty well</a> so far.
</p>
<p>
Of course, everyone knows you could code Stack Overflow in a long weekend. <a href="http://www.codinghorror.com/blog/archives/001284.html">It's trivial</a>. Assembling a worldwide community of smart, engaged software developers? <i>That's</i> a whole different ball of wax. Stack Overflow is a site by programmers, for programmers; it's only as good as the programmers who <a href="http://blog.stackoverflow.com/2008/11/stack-overflow-is-you/">choose to participate</a>.
</p>
<p>
</p>
<blockquote>
Stack Overflow isn't about me. Or anybody else on the Stack Overflow team for that matter.
<p>
<b>Stack Overflow is <i>you</i>.</b>
</p>
<p>
This is the scary part, the great leap of faith that Stack Overflow is predicated on: trusting your fellow programmers. The programmers who choose to participate in Stack Overflow are the "secret sauce" that makes it work. You are the reason I continue to believe in developer community as the greatest source of learning and growth. You are the reason I continue to get so many positive emails and testimonials about Stack Overflow. I can't take credit for that. But you can.
</p>
<p>
I learned the collective power of my fellow programmers long ago writing on Coding Horror. The community is far, far smarter than I will ever be. All I can ask â€“ all any of us can ask â€“ is to help each other along the path.
</p>
</blockquote>
<p>
I am continually humbled by the skill and expertise of the programmers who volunteer time to Stack Overflow. These programmers graciously donate tiny slivers of their day to help us -- and themselves -- become better programmers. These 5 and 10 minute slices of effort, across hundreds of thousands of questions and answers, become a permanently archived (and <a href="http://blog.stackoverflow.com/2009/06/stack-overflow-creative-commons-data-dump/">creative commons wiki licensed</a>) bread crumb content trail for future programmers to follow, edit, and contribute to themselves over time.
</p>
<p>
I'm thrilled to see Stack Overflow working so well for both askers and answerers; the "pay it forward" model of programmers helping their peers is <i>exactly</i> what we were shooting for. We'll never change the world, but it sure is nice to be able to improve our small corner of it just a little bit. Remember: bad code that isn't written, is bad code that another poor programmer won't have to debug. If we don't reach out to <s>slap</s>help new programmers and teach them the lessons we learned the hard way, who will? I'm only exaggerating a little when I say that <i>the future of our entire profession depends on it.</i>
</p>
<p>
If you're actively participating on Stack Overflow, we now have another way to convert those slices of effort into something that actively furthers your professional goals â€“ <a href="http://careers.stackoverflow.com/">Stack Overflow Careers</a>.
</p>
<p>
<a href="http://careers.stackoverflow.com/"><img alt="image placeholder" >
</p>
<p>
What is <a href="http://careers.stackoverflow.com/">careers.stackoverflow.com</a>? It's a few things:
</p>
<p>
</p>
<ul>
<li>a <b>completely free, public CV hosting service for programmers</b>, to share the cool stuff you've coded and created with the world.
</li>
<li>a way to explicitly <b>link your Stack Overflow profile</b> with your CV, to provide concrete examples of your communication skills and individual expertise to anyone who is interested.
</li>
<li>a better way to <b>connect great programmers with the best programming jobs</b>, for those who opt into the small annual listing fee.
</li>
</ul>
<p>
In short, Stack Overflow Careers <b>amplifies your awesome</b>.
</p>
<p>
I won't lie to you. This is also a business. That's why there are nominal opt-in listing fees for those programmers interested in seeking employment, and <i>substantial</i> fees for hiring managers who want to tap into the smart developers who grok Stack Overflow.
</p>
<p>
<font color="red">update:</font> I apologize if I wasn't clear. It is 100% free, forever, to create a public CV, put whatever HTML content you want in it, and link it to your Stack Overflow profile. Like so:
</p>
<p>
</p>
<ul>
<li>
<a href="http://careers.stackoverflow.com/klmr">http://careers.stackoverflow.com/klmr</a>
</li>
<li>
<a href="http://careers.stackoverflow.com/jongalloway">http://careers.stackoverflow.com/jongalloway</a>
</li>
<li>
<a href="http://careers.stackoverflow.com/brandan">http://careers.stackoverflow.com/brandan</a>
</li>
<li>
<a href="http://careers.stackoverflow.com/brentkeller">http://careers.stackoverflow.com/brentkeller</a>
</li>
<li>
<a href="http://careers.stackoverflow.com/mfoord">http://careers.stackoverflow.com/mfoord</a>
</li>
</ul>
<p>
These are of course freely indexable and searchable on the web.
</p>
<p>
Beyond the free public component, there is a private (and completely optional) subscription component. For those programmers actively seeking employment, a small annual subscription fee allows inclusion in a private employer search UI. This is also explained in the <a href="http://careers.stackoverflow.com/faq">faq</a> and <a href="http://careers.stackoverflow.com/about">about</a>.
</p>
<p>
That said, we're also trying to do something a bit different here. Something better than the endless, mind-numbing acronym sea of monster.com, dice.com, et al. Joel and I believe <b>current hiring practices for programmers are incredibly broken</b>. We think we can do better.
</p>
<p>
<a href="http://www.dilbert.com"><img alt="image placeholder" >
</p>
<p>
We love our work, and so should you. Our goal isn't to put warm bodies in front of interviewers. <b>Our goal is to create love connections.</b> Instead of avid programmers pursuing disinterested and distracted companies, it's the other way around -- savvy companies who understand the competitive advantages of having the best programmers will pursue <i>you</i>. We connect smart, engaged hiring managers who "get it" with top programmers who love to code.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If you love to code, too, I encourage you to <a href="http://careers.stackoverflow.com/">create your own Stack Overflow CV</a>. Keep it private, or make it public via the URL of your choice -- it's completely free either way. If you think you might be actively looking for a job in the next 3 years, take advantage of <b>our <i>outrageously</i> low promotional pricing of $29 for a 3 year filing</b>. That way, at any point in those 3 years, you can flip a switch and become visible to hiring managers. Or not. It's totally up to you.
</p>
<p>
(also, if you're hiring, and your company appreciates top software engineers -- and you think you can convince our tough audience of that -- <a href="mailto:careers@stackoverflow.com">email us</a>)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-11-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/stack-overflow-careers-amplifying-your-awesome/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Preserving Our Digital Pre-History ]]></title>
<link>https://blog.codinghorror.com/preserving-our-digital-pre-history/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I've spent a significant part of my life online. Not just on the internet, I mean, but on modems and early, primitive online communities. Today's internet is everything we couldn't have possibly dared to imagine twenty-five years ago, but there is a real risk of these early, tentative digital artifacts -- and for some, the beginnings of <a href="http://www.codinghorror.com/blog/archives/001194.html">our Hacker Odyssey</a> -- being lost forever in the relentless deluge of online progress. Sure, every single thing that happened in 2004 is documented exhaustively online. But 1994? <em>1984?</em> Not so much.</p>
<p>That's where <a href="http://ascii.textfiles.com/">Jason Scott</a> comes in.</p>
<p>You may know Jason Scott from <a href="http://www.bbsdocumentary.com/">BBS The Documentary</a>. Or, perhaps you're familiar with <a href="http://www.textfiles.com/">textfiles.com</a>, his massive (and growing) archive of what passed for blogs and forums in the earliest online era.</p>
<blockquote>A wonderful thing happened in the 1980s: Life started to go online. And as the world continues this trend, everyone finding themselves drawn online should know what happened before, to see where it all really started to come together and to know what went on, before it's forgotten.
<p>When a historian or reporter tries to capture the feelings and themes that proliferated through the BBS Scene of the early 1980's, the reader nearly always experiences a mere glimpse of what went on. This is probably true of most any third-party reporting, but when the culture is your own, and when the experiences were your own, the gap between story and reality is that much wider, and it's that much harder to sit back and let the cliche-filled summary become "The Way It Was." You want to do something, anything so that the people who stumble onto the part of history that was yours know what it was like to grow up through it, to meet the people you did, to do the things you enjoyed doing. Maybe, you hope, they might even see the broader picture and the conclusions that you yourself couldn't see at the time. This is history the way the chronicled want it to be.</p>
</blockquote>
<p>Jason is nothing less than <strong>our generation's digital historian in residence</strong>. When <a href="http://help.yahoo.com/l/us/yahoo/geocities/close/close-01.html">GeoCities went permanently offline</a> a week ago, <a href="http://ascii.textfiles.com/archives/2291">he was there</a> to help preserve it for posterity.</p>
<p><a href="http://www.bbsdocumentary.com/"><img alt="image placeholder" >
<p>BBS: The Documentary was a major milestone in his ongoing effort to document our digital pre-history. But it's only the beginning; there's also a huge documentary on text adventures, <a href="http://www.getlamp.com/">Get Lamp</a>, that's been in the works for a few years now. Unfortunately, progress has been slow. Because while being a digital historian is great, it's not exactly something you get <em>paid to do</em>.</p>
<p>But <strong>maybe we can change that</strong>. Witness <a href="http://www.kickstarter.com/projects/textfiles/the-jason-scott-sabbatical">Jason's kickstarter proposal</a>:</p>
<blockquote>Throughout all this, I had a day job - computer administration. It paid well, but I paid for it with my health. When my most recent employer and I parted ways, I decided I'd take this time finish some of the bigger projects I've been working on.
<p>I suddenly thought back to Kickstarter and got this crazy idea - <strong>what if I simply asked the world and fans to contribute a bit of money towards keeping me somewhat solvent, and give me the opportunity to go full-time with computer history?</strong> If I was able to get all these things done over the years, what if I just asked people to subscribe or give me some patronage and in return I fill their free time with cool stuff to look at, learn from, and enjoy?</p>
</blockquote>
<p>There are so many people whose online presences I greatly admire. But very few of them will go on to become part of the permanent written history of this era. I have no doubt whatsoever that Jason Scott is one of those people who <em>will</em>, thanks to his tireless efforts to preserve the flotsam and jetsam of our digital past, stuff that would otherwise be overlooked by the mainstream and lost forever.</p>
<p>I've pledged $100. <strong>It is an honor to support his ongoing work of preserving our shared digital pre-history</strong>. His history, is my history, is <em>our</em> history. A history of geeks, dorks, dweebs, nerds, and generally computer-obsessed misfits, but nonetheless -- it's something we all share.</p>
<p>If this is something you believe in, I <a href="http://www.kickstarter.com/projects/textfiles/the-jason-scott-sabbatical">urge you to pledge as well</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-11-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/preserving-our-digital-pre-history/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Whitespace: The Silent Killer ]]></title>
<link>https://blog.codinghorror.com/whitespace-the-silent-killer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Ever have one of those days where <b>everything you check into source control is wrong?</b>
</p>
<p>
Also, how exactly is that day is different from any other? But seriously.
</p>
<p>
Code that is visible is <a href="http://www.codinghorror.com/blog/archives/000878.html">code that can be wrong</a>. No surprise there. But did you know that even the code you <i>can't</i> see may be wrong, too?
</p>
<p>
These are the questions that drive young programmers to madness. Take this perfectly innocent code, for example.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Looks fine, doesn't it? But hold on. Wait a second. Let's take another, closer look.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<i>OH. MY. <b>GOD!</b></i>
</p>
<p>
If you're not a programmer, you may be looking at these two images and wondering what the big deal is. That's fine. But I humbly submit that, well, you're not one of us. You don't appreciate what it's like to spend every freaking minute of every freaking day agonizing over the tiniest details of the programs you write. Not because we <i>want</i> to, you understand, but because the world explodes when we don't.
</p>
<p>
I mean that literally. Well, <a href="http://bugsniffer.blogspot.com/2007/11/infamous-software-failures.html">almost</a>. If one semicolon is out of place, <a href="http://www.google.com/search?q=failure+'missing+semicolon'">everything goes sideways</a>. That's how programming works. It's fun! Sometimes! I swear!
</p>
<p>
We got into this industry because, quite frankly, we are control freaks. It's who we are. It's what we do. Now to imagine, to our dismay, that there's all this stupid, useless <i>whitespace</i> at the ends of our lines. Stuff that's there, but we can't see it. Well, those are the nightmares OCD horror movies are made of. I have a full-body itchiness just talking about it.
</p>
<p>
Depending on how far down the rabbit-hole you want to go, there's any number of things you could do here:
</p>
<p>
</p>
<ul>
<li>Have a post-build step, perhaps something with a regular expression like <code>s*?$</code> in it, that auto-cleans extra spaces checked into source control
</li>
<li>Execute a local macro which removes whitespace from ends of lines
</li>
<li>Have a special rule to highlight extra spaces
</li>
<li>Run your IDE in whitespace-always-visible mode, or toggle it frequently
</li>
</ul>
<p>
OK, fine, so maybe the world won't explode if there are a few extra bits of whitespace in my code.
</p>
<p>
But all the same, I think I'll go back and make <i>extra double plus sure</i> no more of that pesky whitespace has accumulated in my code when I wasn't looking. Just because I can't see it doesn't mean it's not out to get me.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-11-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whitespace-the-silent-killer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Parsing Html The Cthulhu Way ]]></title>
<link>https://blog.codinghorror.com/parsing-html-the-cthulhu-way/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Among programmers of any experience, it is generally regarded as A Bad Idea<sup>tm</sup> to attempt to parse HTML with regular expressions. How bad of an idea? It apparently <a href="http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454">drove one Stack Overflow user to the brink of madness</a>:</p>
<blockquote>
You can't parse [X]HTML with regex. Because HTML can't be parsed by regex. Regex is not a tool that can be used to correctly parse HTML. As I have answered in HTML-and-regex questions here so many times before, the use of regex will not allow you to consume HTML.
<p>Regular expressions are a tool that is insufficiently sophisticated to understand the constructs employed by HTML. HTML is not a regular language and hence cannot be parsed by regular expressions. Regex queries are not equipped to break down HTML into its meaningful parts. so many times but it is not getting to me. Even enhanced irregular regular expressions as used by Perl are not up to the task of parsing HTML. You will never make me crack. HTML is a language of sufficient complexity that it cannot be parsed by regular expressions.</p>
<p>Even Jon Skeet cannot parse HTML using regular expressions. Every time you attempt to parse HTML with regular expressions, the unholy child weeps the blood of virgins, and Russian hackers pwn your webapp. Parsing HTML with regex summons tainted souls into the realm of the living. HTML and regex go together like love, marriage, and ritual infanticide. The &lt;center&gt; cannot hold it is too late. The force of regex and HTML together in the same conceptual space will destroy your mind like so much watery putty. If you parse HTML with regex you are giving in to Them and their blasphemous ways which doom us all to inhuman toil for the One whose Name cannot be expressed in the Basic Multilingual Plane, he comes.</p>
</blockquote>
<p>(The <a href="https://blog.codinghorror.com/content/images/2014/Apr/stack-overflow-regex-zalgo.png">unicode action in the post</a>, not shown here, is the best part of the gag.)</p>
<p>That's right, if you attempt to parse HTML with regular expressions, you're succumbing to the temptations of the dark god <a href="http://en.wikipedia.org/wiki/Cthulhu">Cthulhu's</a> … er … <i>code</i>.</p>
<img alt="image placeholder" >
<p>This is all good fun, but the warning here is only partially tongue in cheek, and it is born of <a href="http://oubliette.alpha-geek.com/2004/01/12/bring_me_your_regexs_i_will_create_html_to_break_them">a very real frustration</a>.</p>
<blockquote>
I have heard this argument before. Usually, I hear it as justification for seeing something like the following code:
<pre>
# pull out data between &lt;td&gt; tags
($table_data) = $html =~ /&lt;td&gt;(.*?)&lt;/td&gt;/gis;
</pre>
<p>"But, it works!" they say.<br><br>
"It's easy!"<br><br>
"It's quick!"<br><br>
"It will do the job just fine!"<br></p>
<p>I berate them for not being lazy. You need to be lazy as a programmer. <b>Parsing HTML is a solved problem. You do not need to solve it. You just need to be lazy.</b> Be lazy, use CPAN and use <a href="http://search.cpan.org/~nesting/HTML-Sanitizer-0.04/Sanitizer.pm">HTML::Sanitizer</a>. It will make your coding easier. It will leave your code more maintainable. You won't have to sit there hand-coding regular expressions. Your code will be more robust. You won't have to bug fix every time the HTML breaks your crappy regex</p>
</blockquote>
<p>For many novice programmers, there's something unusually seductive about parsing HTML the Cthulhu way instead of, y'know, using a library like a sane person. Which means this discussion gets reopened almost every single day on Stack Overflow. The above post from five years ago could be a discussion from <i>yesterday</i>. I think we can forgive a momentary lapse of reason under the circumstances.</p>
<p>Like I said, this is a well understood phenomenon in most programming circles. However, I was surprised to see a few experienced programmers <a href="http://www.metafilter.com/86689/So-does-anyone-know-how-to-make-an-HTML-regex-parser">in metafilter comments</a> actually <b>defend the use of regular expressions to parse HTML</b>. I mean, they've heeded the <a href="http://en.wikipedia.org/wiki/The_Call_of_Cthulhu">Call of Cthulhu</a> … and <i>liked</i> it.</p>
<blockquote>
Many programs will neither need to, nor should, anticipate the entire universe of HTML when parsing. In fact, designing a program to do so may well be a completely wrong-headed approach, if it changes a program from a few-line script to a bullet-proof commercial-grade program which takes orders of magnitude more time to properly code and support. Resource expenditure should always (oops, make that very frequently, I about overgeneralized, too) be considered when creating a programmatic solution.
<p>In addition, hard boundaries need not always be an HTML-oriented limitation. They can be as simple as "work with these sets of web pages", "work with this data from these web pages", "work for 98% users 98% of the time", or even "OMG, we have to make this work in the next hour, do the best you can".</p>
</blockquote>
<p>We live in a world full of newbie PHP developers doing the first thing that pops into their collective heads, with more born every day. What we have here is an ongoing education problem. The real enemy isn't regular expressions (or, for that matter, <a href="http://www.codinghorror.com/blog/archives/000982.html">goto</a>), but ignorance. The only crime being perpetrated is not knowing what the alternatives are.</p>
<p>So, while I may <i>attempt</i> to parse HTML using regular expressions <a href="http://www.codinghorror.com/blog/archives/001172.html">in certain situations</a>, I go in knowing that:</p>
<ul>
<li>It's generally a bad idea.
</li>
<li>Unless you have discipline and put very strict conditions on what you're doing, matching HTML with regular expressions rapidly devolves into madness, <i>just how Cthulhu likes it</i>.
</li>
<li>I had what I thought to be good, rational, (semi) defensible reasons for choosing regular expressions in this specific scenario.
</li>
</ul>
<p>It's considered good form to demand that regular expressions be considered verboten, totally off limits for processing HTML, but I think that's just as wrongheaded as demanding <b>every trivial HTML processing task be handled by a full-blown parsing engine</b>. It's more important to understand the tools, and their strengths and weaknesses, than it is to knuckle under to knee-jerk dogmatism.</p>
<p>So, yes, generally speaking, it <i>is</i> a bad idea to use regular expressions when parsing HTML. We should be teaching neophyte developers that, absolutely. Even though it's an apparently neverending job. But we should also be teaching them the very real difference between <a href="http://en.wikipedia.org/wiki/Parsing">parsing HTML</a> and the simple expedience of processing a few strings. And how to tell which is the right approach for the task at hand.</p>
<p>Whatever method you choose – just don't leave the &lt;cthulhu&gt; tag open, for humanity's sake.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-11-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/parsing-html-the-cthulhu-way/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Buy Bad Code Offsets Today! ]]></title>
<link>https://blog.codinghorror.com/buy-bad-code-offsets-today/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Let's face it: <a href="http://www.codinghorror.com/blog/archives/000099.html">we all write bad code</a>.
</p>
<p>
But not every programmer <i>does something</i> about the bad code they're polluting the world with, day in and day out. There's a whole universe of possibilities:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/archives/000568.html">Follow the instructions on the paint can</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000446.html">Become a software apprentice</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/001229.html">Get a coding buddy</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000954.html">Practice the fundamentals</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/001138.html">A program of effortful study</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/001236.html">Participate in the community to sharpen your saw</a>
</li>
</ul>
<p>
But that's a lot of work. Really freaking <b>hard work!</b> Wouldn't it be nice if you could do something a bit simpler and easier to, just â€¦ say â€¦ <i>offset</i> the bad code you're producing?
</p>
<p>
Well, now you can -- with <b><a href="http://codeoffsets.com/Buy.aspx">Bad Code Offsets</a></b>.
</p>
<p>
<a href="http://codeoffsets.com/Buy.aspx"><img alt="image placeholder" >
</p>
<p>
<a href="http://codeoffsets.com/Buy.aspx"><img alt="image placeholder" >
</p>
<p>
I am a proud member of the <a href="http://codeoffsets.com">Alliance for Code Excellence</a>, and this is our vision:
</p>
<p>
</p>
<blockquote>
We envision a world where software runs cleanly and correctly as it simplifies, enhances and enriches our day to day work and home lives. Mitigating the scope and negative impact of bad code on our jobs, our lives and our world is our all-consuming passion. We foresee a time when bad coding practices and their rotten fruits have been eliminated from this earth and its server farms thereby heralding a new age of software brilliance and efficacy.
<p>
Nettlesome bugs and poorly written code have been constant impediments towards realizing our full potential as programmers and engineers. <b>Bad Code Offsets provides the vehicle for balancing the scales of poor past practice while freeing us to pursue current excellence in code development.</b> Until the dawn of the worldwide, bug free code base, each of us can take steps towards reducing our bad code footprint and remediate the bad code that we have each individually and collectively left behind on the desktops, servers and mainframes at school, at work and at home.
</p>
</blockquote>
<p>
Yes, this is partly tongue in cheek, but we aren't just <a hef="http://knowyourmeme.com/memes/i-did-it-for-the-lulz">doing it for the lulz</a>. Bad code offsets cost real money, because the Alliance has a goal:
</p>
<p>
</p>
<blockquote>
Q: Where does my money go?
<p>
<b>A: The proceeds from the sale of Bad Code Offsets are donated to various worthy Open Source initiatives that are carrying the fight against bad code on a daily basis.</b> These organizations include:
</p>
<p>
</p>
<ul>
<li>
<a href="http://jquery.com/">jQuery</a>
</li>
<li>
<a href="http://www.postgresql.org/">PostgreSQL</a>
</li>
<li>
<a href="http://apache.org/">The Apache Software Foundation</a>
</li>
</ul>
</blockquote>
<p>
This is the awesome part: the money you spend on Bad Code Offsets <i>really does offset bad code!</i>
</p>
<p>
All the money spent on bad code offsets goes directly to open source projects that actively make programmers' lives better. For every ten thousand lines of <a href="http://www.bioinformatics.org/phplabware/sourceer/sourceer.php?&amp;Sfs=htmLawed.php&amp;Sl=./internal_utilities/htmLawed">mind-bendingly bad code</a> produced, we hope to subsidize a thousand lines of quality open source code.
</p>
<p>
So, please -- <b><a href="http://codeoffsets.com/Buy.aspx">buy bad code offsets</a></b> today. It is, quite literally, the <i>least</i> you could do.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-11-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/buy-bad-code-offsets-today/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Version 1 Sucks, But Ship It Anyway ]]></title>
<link>https://blog.codinghorror.com/version-1-sucks-but-ship-it-anyway/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I've been unhappy with every single piece of software I've ever released. Partly because, like many software developers, I'm a perfectionist. And then, there are inevitably … <i>problems</i>:</p>
<ul>
<li>The schedule was too aggressive and too short. We need more time!</li>
<li>We ran into unforeseen technical problems that forced us to make compromises we are uncomfortable with.</li>
<li>We had the wrong design, and needed to change it in the middle of development.</li>
<li>Our team experienced internal friction between team members that we didn't anticipate.</li>
<li>The customers weren't who we thought they were.</li>
<li>Communication between the designers, developers, and project team wasn't as efficient as we thought it would be.</li>
<li>We overestimated how quickly we could learn a new technology.</li>
</ul>
<p>The list goes on and on. Reasons for failure on a software project <a href="http://blog.codinghorror.com/escaping-from-gilligans-island/">are legion</a>.</p>
<p>At the end of the development cycle, you end up with <b>software that is a pale shadow of the shining, glorious monument to software engineering that you envisioned when you started</b>.</p>
<p>It's tempting, at this point, to throw in the towel – to add more time to the schedule so you can get it right before shipping your software. Because, after all, <a href="http://blog.codinghorror.com/shipping-isnt-enough/">real developers ship</a>.</p>
<p>I'm here to tell you that <b>this is a mistake</b>.</p>
<p>Yes, you did a ton of things wrong on this project. But you also did a ton of things wrong that <i>you don't know about yet</i>. And there's no other way to find out what those things are until you ship this version and get it in front of users and customers. I think <a href="http://www.slate.com/id/2081042/">Donald Rumsfeld put it best</a>:</p>
<blockquote>
<p>As we know,<br><br>
There are known knowns.<br><br>
There are things we know we know.<br><br>
We also know<br><br>
There are known unknowns.<br><br>
That is to say<br><br>
We know there are some things<br><br>
We do not know.<br><br>
But there are also unknown unknowns,<br><br>
The ones we don't know<br><br>
We don't know.</p>
</blockquote>
<p>In the face of the inevitable end-of-project blues – rife with compromises and totally unsatisfying quick fixes and partial soutions – you could hunker down and lick your wounds. You could regroup and spend a few extra months fixing up this version before releasing it. You might even feel good about yourself for making the hard call to get the engineering right before unleashing yet another buggy, incomplete chunk of software on the world.</p>
<p>Unfortunately, this is an even bigger mistake than shipping a flawed version.</p>
<p>Instead of spending three months fixing up this version in a sterile, isolated lab, you <i>could</i> be spending that same three month period <b>listening to feedback from real live, honest-to-god, <s>annoying</s>dedicated users of your software</b>. Not the software as you imagined it, and the users as you imagined them, but as they exist in the real world. You can turn around and use that directed, real world feedback to not only <i>fix</i> all the sucky parts of version 1, but spend your whole development budget more efficiently, predicated on hard usage data from your users.</p>
<p>Now, I'm not saying you should release crap. Believe me, we're all perfectionists here. But the real world can be a cruel, unforgiving place for us perfectionists. It's saner to let go and realize that when your software crashes on the rocky shore of the real world, disappointment is inevitable … <i>but fixable!</i> What's important isn't so much the initial state of the software – in fact, some say <a href="http://successfulsoftware.net/2007/08/07/if-you-arent-embarrassed-by-v10-you-didnt-release-it-early-enough/">if you aren't embarrassed by v1.0 you didn't release it early enough</a> – but what you do <i>after</i> releasing the software.</p>
<p>The velocity and responsiveness of your team to user feedback will set the tone for your software, far more than any single release ever could. That's what you need to get good at. Not the platonic ideal of shipping mythical, perfect software, but being responsive to your users, to your customers, and demonstrating that through the act of continually improving and refining your software based on their feedback. So to the extent that you're optimizing for near-perfect software releases, you're optimizing for the wrong thing.</p>
<p>There's no <i>question</i> that, for whatever time budget you have, you will end up with better software by releasing as early as practically possible, and then spending the rest of your time <a href="http://blog.codinghorror.com/boyds-law-of-iteration/">iterating rapidly based on real world feedback</a>.</p>
<p>So trust me on this one: <b>even if version 1 sucks, ship it anyway</b>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-12-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/version-1-sucks-but-ship-it-anyway/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Microformats: Boon or Bane? ]]></title>
<link>https://blog.codinghorror.com/microformats-boon-or-bane/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I recently added <a href="http://en.wikipedia.org/wiki/Microformat">microformat</a> support to the free public CVs at <a href="http://careers.stackoverflow.com/">careers.stackoverflow.com</a> by popular demand.
</p>
<p>
</p>
<blockquote>
Designed for humans first and machines second, <b>microformats are a set of simple, open data formats built upon existing and widely adopted standards</b>.
</blockquote>
<p>
The <a href="http://microformats.org/">official</a> microformat <a href="http://www.codinghorror.com/blog/archives/000962.html">"elevator pitch"</a> tells us nothing useful. That's not a good sign. It doesn't get much better on the <a href="http://microformats.org/about">learn more</a> link, either.
</p>
<p>
I'm left scratching my head, wondering <b>why I should care</b>. What problem, exactly, do microformats solve for me as a user? As a software developer? There's lots of hand-wavy talk about <i>data</i>, but precious little in the way of concrete stories or real world examples.
</p>
<p>
But I have a real world example: a CV. To some human resource departments the standard web interchange format for a CV or Resume is already established -- it's called "Microsoft Word". I have no beef with Word, but certainly we'd like to pick a more <b>simple, open data format</b> for our personal data than Microsoft Word -- and the <a href="http://en.wikipedia.org/wiki/HResume">hResume</a> microformat seems to fit the bill. And if your CV is published on the web in a standard(ish) format, it's easier to take it with you wherever you need to go.
</p>
<p>
I had already implemented the <a href="http://microformats.org/wiki/rel-tag">tag</a> and <a href="http://microformats.org/wiki/rel-me">identity</a> microformats on Stack Overflow many months ago. I wasn't convinced of the benefits, but the implementation was so easy that it seemed like more work to argue the point than to actually <i>get it done</i>. Judge for yourself:
</p>
<p>
</p>
<pre>
&lt;a href="http://www.codinghorror.com/" <font color="red">rel="me"</font>&gt;codinghorror.com&lt;/a&gt;
&lt;a href="/questions/tagged/captcha" <font color="red">rel="tag"</font>&gt;captcha&lt;/a&gt;
</pre>
<p>
Fairly clean and simple, right? That was the extent of my experience with microformats. Limited, but positive. Then I read through the <a href="http://microformats.org/wiki/hresume">hResume microformat spec</a>. You should read it too. Go ahead. I'll wait here.
</p>
<p>
My first impression was not positive, to put it mildly. So you want me to <b>take the ambiguous, crappy "HTML" markup we already have and layer some ambiguous, crappy "microformat" markup on <i>top</i> of it?</b> And that's â€¦ a solution? If that's what microformats are going to be about, I think I might want off the microbus.
</p>
<p>
Let's take a look at a representative slice of hResume markup:
</p>
<p>
</p>
<pre>
&lt;div <font color="red">class="vcard"</font>&gt;
&lt;a <font color="red">class="fn org url"</font> href="http://example.com/"&gt;Example&lt;/a&gt;
&lt;div <font color="red">class="adr"</font>&gt;
&lt;span <font color="red">class="type"</font>&gt;Work&lt;/span&gt;:
&lt;div <font color="red">class="street-address"</font>&gt;169 Maple Ave&lt;/div&gt;
&lt;span <font color="red">class="locality"</font>&gt;Anytown&lt;/span&gt;,
&lt;abbr <font color="red">class="region"</font> title="Iowa"&gt;IA&lt;/abbr&gt;
&lt;span <font color="red">class="postal-code"</font>&gt;50981&lt;/span&gt;
&lt;div <font color="red">class="country-name"</font>&gt;USA&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</pre>
<p>
As you can see, <b>the crux of microformats is overloading CSS classes</b>. When you give something the "adr" class within the "vcard" class, that means it's the address data field within the hCard, within the hResume.
</p>
<p>
While I can see the attraction, this approach makes me uneasy:
</p>
<p>
</p>
<ol>
<li>
<b>We're overloading the class attribute with two meanings.</b> Is "adr" the name of a class that contains styling information, or the name of a data field? Or both? It's impossible to tell. The minute you introduce a microformat into your HTML, the semantics of the class attribute have been permanently altered.
</li>
<li>
<b>The microformat css class names may overlap with existing css classes</b>. Woe betide the poor developer who has to retrofit a microformat on an established site where "locality" or "region" have already been defined in the CSS and are associated with elements all over the site. And let me tell you, many of the microformat css field names are, uh, <i>conveniently</i> named what you've probably already used in your HTML somewhere. In the wrong way, inevitably.
</li>
<li>
<b>There's no visual indication whatsoever that any given css class is a microformat</b>. If you hire a new developer, how can they possibly be expected to know that "postal-code" isn't just an arbitrarily chosen CSS class name, it's a gosh darned officially blessed <i>microformat</i>? What if they decide they don't like dashes in CSS class names and rename the style "postalcode"? Wave bye bye to your valid microformat. If it seems fragile and obtuse, that's because it is.
</li>
<li>
<b>The spec is <i>incredibly</i> ambiguous</b>. I read through the hResume, hCard, and hCalendar spec multiple times, checked all the samples, viewed source on existing sites, used all the <a href="http://ufxtract.com/">validators</a> I could find, and I <i>still</i> got huge swaths of the format wrong! For a "simple" and "easy" format, it's â€¦ anything but, in my experience. The specification is full of ambiguities and requires a lot of interpretation to even get close. I'm not the <a href="http://www.codinghorror.com/blog/archives/000051.html">world's best developer</a>, but I'm theoretically competent, and if I can't implement hResume without wanting to cut myself and/or writing snarky blog posts like this, how can we expect everyone else to?
</li>
<li>
<b>It doesn't handle unstructured data well</b>. On Stack Overflow, we have a single "location" field. No city, state, zip, lat, long, and all that jazz: just an unstructured, freeform, enter-whatever-pleases-you "location" field. This was awkward to map in hCard, which practically <i>demands</i> that addresses be chopped up into meticulous little sub-fields. This is a bit ironic for a format supposedly designed to work with the loose, unstructured world wide web. Oh, and this goes double for dates. If you don't have an ISO datetime value, good luck.
</li>
</ol>
<p>
Maybe I have a particular aversion to getting my chocolate data structure mixed up with my peanut butter layout structure, but it totally skeeves me out that the microformat folks actually <i>want</i> us to design our CSS and HTML around these specific, ambiguous and non-namespaced microformat CSS class names. It feels like a hacky overload. While you could argue this is no different than the web and HTML in general -- a giant wobbly teetering tower of nasty, patched-together hacks -- something about it fundamentally bothers me.
</p>
<p>
Now, all that said, <b>I still think microformats are useful and worth implementing</b>, if for no other reason than it's <i>too easy not to</i>. If you have semi-structured data, and it maps well to an existing microformat, why not? Yes, it is kind of a hack, but it might even be a useful hack if <a href="http://microformats.org/wiki/google-search">Google starts indexing your microformats and presenting them in search results</a>. While I'm unclear on the general benefits of microformats for end users or developers, seeing stuff like this in search results â€¦
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
â€¦ is enough to convince me that microformats are a step in the right direction. Warts and all. While we're waiting for HTML5 and <a href="http://ejohn.org/blog/html-5-data-attributes/">its mythical data attributes</a> to ship sometime this century, it's better than nothing.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-12-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/microformats-boon-or-bane/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ International Backup Awareness Day ]]></title>
<link>https://blog.codinghorror.com/international-backup-awareness-day/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
You may notice that commenting is currently disabled, and many old Coding Horror posts are missing images. That's because, sometime early on Friday, <strong>the server this blog is hosted on suffered catastrophic data loss</strong>.
</p>
<p>
Here's what happened:
</p>
<p>
</p>
<ol>
<li>The server experienced routine hard drive failure.
</li>
<li>Because of the hard drive failure, the virtual machine image hosting this blog was corrupted.
</li>
<li>Because the blog was hosted in a virtual machine, the standard daily backup procedures at the host were unable to ever back it up.
</li>
<li>Because I am an idiot, I didn't have my own (recent) backups of Coding Horror. Man, I wish I had <a href="http://www.codinghorror.com/blog/archives/001045.html">read some good blog entries on backup strategies!</a>
</li>
<li>Because there were no good backups, there was catastrophic data loss. Fin, draw curtain, exeunt stage left.
</li>
</ol>
<p>
At first, I was upset with our provider, <a href="http://crystaltech.com/dedicated-windows.aspx?uid=101">CrystalTech</a>.
</p>
<p>
<a href="http://www.youtube.com/watch?v=N7fuuVrweYQ"><img alt="image placeholder" >
</p>
<p>
I am still confused how the most common, routine, predictable, and mundane of server hardware failures -- losing a mechanical hard drive -- could cause such extreme data loss carnage. What about, oh, I don't know, <a href="http://www.codinghorror.com/blog/archives/001233.html">a RAID array</a>? Aren't they <em>designed</em> to prevent this kind of single point of failure drive loss catastrophe? Isn't a multi drive RAID array sort of standard on datacenter servers? I know we have multi-drive RAID arrays on <a href="http://blog.stackoverflow.com/2009/12/stack-overflow-rack-glamour-shots/">all of our Stack Overflow servers</a>.
</p>
<p>
I also wish their routine backup procedures had greater awareness of virtual machine images. While I'll grant you that backing up a live virtual machine is somewhat complex, and typically requires <a href="http://technet.microsoft.com/en-us/library/cc720377%28WS.10%29.aspx">special operating system support and API hooks</a>, it is not exactly an unknown science at this point in time. Heck, at the very least, just let us know when the backup has been regularly failing each day, every day, for <em>years</em>.
</p>
<p>
Then I belatedly realized that this was, after all, <em>my</em> data. And <strong>it is irresponsible of me to leave the fate of my data entirely in someone else's hands</strong>, regardless of how reliable they may or may not be. Responsibility for my data begins with me. If I haven't taken appropriate measures, who am I to cast aspersions on others for not doing the same? Glass houses and all that.
</p>
<p>
So, I absolve <a href="http://crystaltech.com/dedicated-windows.aspx?uid=101">CrystalTech</a> of all responsibility in this matter. They've given us a great deal on our dedicated server, and performance and reliability (with one recent, uh... exception) have been excellent to date. <strong>It is completely my fault that I neglected to have proper backups in place for Coding Horror.</strong> Well, technically, I did have a backup but it was on the virtual machine itself. Does that count? No? Halfsies?
</p>
<p>
Apparently, I was <em>gambling</em> that nothing bad would ever happen at the datacenter. Because that's what you're doing when you run without your own backups. <strong>Gambling.</strong>
</p>
<p>
<a href="http://www.amazon.com/dp/B000TE38VA/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
I'll add gambling to the long, long list of things I suck at. I don't know when to hold 'em <em>or</em> when to fold 'em.
</p>
<p>
Now that I've apologized, it's time to let the healing begin. And by healing, I mean <strong>the excruciatingly painful process of reconstructing Coding Horror from internet caches and the few meager offsite backups I do have</strong>. My first order of business was to ask on SuperUser what strategies people recommend for <a href="http://superuser.com/questions/82036/recovering-a-lost-website-with-no-backup">recovering a lost website with no backup</a>. Strategies other than berating me for my obvious mistake. Also, comments are currently disabled while the site is being reconstructed from static HTML. Oh, <em>darn!</em>
</p>
<p>
I'll let my son <a href="http://twitter.com/rockhardawesome">Rock Hard Awesome</a> stand in for the zinger of a comment that I know some of you were <em>just dying</em> to leave.
</p>
<p>
<a href="http://twitter.com/rockhardawesome"><img alt="image placeholder" >
</p>
<p>
I'm not saying I don't deserve it. Consider me totally zingatized.
</p>
<p>
I mentioned my woes on <a href="http://twitter.com/codinghorror">Twitter</a> and I was humbled by the outpouring of community support. Thanks to everyone who reached out with support of any kind. It is greatly appreciated.
</p>
<p>
I was able to get a static HTML version of Coding Horror up almost immediately thanks to Rich Skrenta of <a href="http://blekko.com">blekko.com</a>. He kindly provided a tarball of every spidered page on the site. Some people have goals, and some people have <em><a href="http://www.skrenta.com/2008/03/who_will_stop_google_from_goin.html">big hairy audacious goals</a></em>. Rich's is especially awe-inspiring: taking on Google on their home turf of search. That's why he just happened to have a complete text archive of Coding Horror at hand. Rich, <a href="http://www.youtube.com/watch?v=oiS8YokFzeY">have I ever told you that you're my hero?</a> Anyway, you're viewing the static HTML version of Coding Horror right now thanks to Rich. Surprisingly, there's not a tremendous amount of difference between a static HTML version of this site and the live site. One of the benefits of being a minimalist, I suppose.
</p>
<p>
That pretty much solved all my text post recovery problems in one fell swoop. Through this process, I've learned that anything even remotely popular you put on the web will be archived as text, forever, by a dozen different web spiders. <strong>I don't think you can actually <em>lose</em> text you post on the web.</strong> Not in any meaningful sense; I'm not sure it's possible. As long as you're willing to spend the time digging through web spider archives in some form (and yes, I did cheat mightily), you can always get textual content back, all of it.
</p>
<p>
The blog <em>images</em>, however, are another matter entirely. I have learned the hard way that <strong>there are almost no organizations spidering and storing images on the web</strong>. Yes, there is <a href="http://www.archive.org/web/web.php">archive.org</a>, and God bless 'em for that. But they have an impossible job they're trying to do with limited resources. Beyond that, there's ... well, frankly, a whole lot of nothing. A desperate, depressing void of nothing. In fact, if you can only back up one thing on your public website, <strong>it should be the images.</strong> Because that's the thing you'll have the most difficulty recovering when catastrophe happens. I'm planning to donate $100 to archive.org as I have a whole new appreciation for how rare an internet-wide full archive service – one that includes images – really is.
</p>
<p>
That said, There are some limited, painful avenues to explore for recovering lost website images. I started with an ancient complete backup from mid 2006 with full images. And then Maciej Ceglowski of the nifty full-archive bookmarking service <a href="http://pinboard.in/">pinboard.in</a> generously contributed about 200 blog posts that he had images for.
</p>
<p>
I also went through a period when <a href="http://www.codinghorror.com/blog/archives/000807.html">I was going on a bandwidth diet</a> and experimenting with hosting Coding Horror images elsewhere on the web. I'm slowly going through and recovering images locally from there. Beyond that, several avid Coding Horror readers contributed some archived images -- so thanks to Yasushi Aoki, Marcin Goabiowski, Peter Mortensen, and anybody else I've forgotten.
</p>
<p>
Also, I should point out that a few enterprising programmers have proposed clever schemes for automatic recovery of images, such as Niyaz with his blog post <a href="http://www.diovo.com/2009/12/getting-cached-images-in-your-website-from-the-visitors/">Get cached images from your visitors</a>, and <a href="http://arstechnica.com/staff/fatbits/">John Siracusa</a> with his <a href="http://superuser.com/questions/82036/recovering-a-lost-website-with-no-backup/82060#82060">highly voted 304 idea</a>. I haven't had time to follow up on these yet but they seem plausible to me.
</p>
<p>
I've restored all the images I have so far, but it's still woefully incomplete. The most important part of Coding Horror is definitely the text of the posts, but I do have some regrets that I've lost key images from many blog posts, including those about <a href="http://www.codinghorror.com/blog/archives/001242.html">my son</a>. It feels like irresponsible parenting, in the broadest possible sense of the words.
</p>
<p>
<s>The process of image recovery is still ongoing. <strong>If you'd like to contribute lost Coding Horror images, please do.</strong> I'd be more than happy to mail stickers on my dime to anyone who contributes an image that is currently a 404 on the site.</s> <font color="red">Update:</font> That was fast. Carmine Paolino, a computer science student at the University of Bologna, somehow had a nearly complete mirror of the site backed up on his Mac! Thanks to his mirror, we've now recovered nearly 100% of the missing images and content. I've offered to donate $100 to the charity or open source project of Carmine's choice.
</p>
<p>
What can we all learn from this sad turn of events?
</p>
<p>
</p>
<ol>
<li>I suck.
</li>
<li>No, really, I suck.
</li>
<li>Don't rely on your host or anyone else to back up your important data. Do it yourself. If you aren't <em>personally</em> responsible for your own backups, <strong>they are effectively not happening.</strong>
</li>
<li>If something really bad happens to your data, how would you recover? What's the process? What are the hard parts of recovery? I think in the back of my mind I had false confidence about Coding Horror recovery scenarios because I kept thinking of it as mostly text. Of course, the text turned out to be the <em>easiest</em> part. The images, which I had thought of as a "nice to have", were more essential than I realized and far more difficult to recover. Some argue that <a href="http://www.joelonsoftware.com/items/2009/12/14.html">we shouldn't be talking about "backups"</a>, but recovery.
</li>
<li>It's worth revisiting your recovery process periodically to make sure it's still alive, kicking, and fully functional.
</li>
<li>I'm awesome! No, just kidding. I suck.
</li>
</ol>
<p>
So when, exactly, is International Backup Awareness Day? Today. Yesterday. This week. This month. This year. It's a trick question. <strong><em>Every</em> day is International Backup Awareness Day</strong>. And the sooner I figure that out, the better off I'll be.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-12-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/international-backup-awareness-day/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Building a PC, Part VI: Rebuilding ]]></title>
<link>https://blog.codinghorror.com/building-a-pc-part-vi-rebuilding/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I can't believe it's been almost <strong>two and a half years since I built my last PC</strong>. I originally documented that process in a series of posts:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/archives/000905.html">Building a PC, Part I: Minimal boot</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000907.html">Building a PC, Part II: Burn in</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000908.html">Building a PC, Part III: Overclocking</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000918.html">Building a PC, Part IV: Now It's Your Turn</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/001102.html">Building a PC, Part V: Upgrading</a>
</li>
</ul>
<p>
Now, lest you think I am some kind of freakish, cave-dwelling luddite, what with my <em>ancient</em> two and a half year old PC, I have <a href="http://www.codinghorror.com/blog/archives/001102.html">upgraded the CPU</a>, <a href="http://www.codinghorror.com/blog/archives/001304.html">upgraded the hard drive</a>, and <a href="http://www.codinghorror.com/blog/archives/001185.html">upgraded the video card</a> since then. I also went from 4 GB of RAM to 8 GB of RAM, but I didn't happen to blog about that. Normal computers age in dog years -- every year they get seven years older -- but mine isn't so bad with all my upgrades! I swear!
</p>
<p>
Judge for yourself; here's a picture of it.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But seriously.
</p>
<p>
A big part of the value proposition of building your own PC is <strong>upgrading it in pieces and parts over time.</strong> When you're unafraid to pop the cover off and get your hands dirty with a little upgrading, you can spend a lot less to stay near the top of the performance heap over time. It's like the argument for buying a car versus renting it; the smart buyers keep the car for as long as possible to maximize the value of their investment. That's what we're doing here with our upgrades, and a rebuild is the ultimate upgrade.
</p>
<p>
In defense of my creaky old computer, the Core 2 series from Intel has been unusually strong over time, one of their best overall platforms in recent memory. It was <em>almost</em> good enough to banish the excerable Pentium 4 series from my mind. Man <a href="http://www.codinghorror.com/blog/archives/000867.html">those were horrible</a>! But the Core 2 series was a solid design with some serious legs; it and scaled brilliantly, from single to dual to quad core, and in frequency from 1 GHz to 3.5 GHz.
</p>
<p>
I was initially unimpressed with the new Core i7 architecture that Intel launched to replace the Core 2. While <a href="http://www.anandtech.com/weblog/showpost.aspx?i=532">the new Nehalem architecture is a <em>huge</em> win on servers</a>, it's kind of "meh" on the desktop. I have endless battles with overzealous developers who swear up and down that they <a href="http://www.codinghorror.com/blog/archives/000335.html">use their desktops like servers</a>. Sure you do! And you're <a href="http://www.codinghorror.com/blog/archives/000113.html">building the space shuttle</a> with it, right? Of course you are. Yeah.
</p>
<p>
Meanwhile, back on Planet Desktop, there were some other reasons that I started thinking seriously about upgrading from my <a href="http://www.codinghorror.com/blog/archives/001102.html">overclocked Core 2 Duo</a> to a Core i7 upgrade:
</p>
<p>
</p>
<ul>
<li>The Core i7 platform uses <strong>triple channel DDR3 memory</strong>. While the benefits of the additional bandwidth are somewhat debatable on the desktop (as usual), one interesting side-effect is that motherboards have 6 memory slots. While 16 GB is theoretically possible on Core 2 systems, it required extremely expensive 8 GB DIMMs. But with 6 memory slots, we can achieve 12 GB without breaking the bank -- by using <strong>six 2 GB DIMMs</strong>.
</li>
<li>The Core i7 is <strong>Intel's first "real" quad-core architecture</strong>. Intel's previous quad core CPUs were basically two dual core CPUs duct taped together on the same die. No such shortcuts were taken with the i7. While the difference is sort of academic, there are some smallish real world performance implications.
</li>
<li>Mainstream <strong>software is finally ready for quad core CPUs</strong>. It's not uncommon today to find applications and games that can actually use two CPU cores reasonably effectively, and those that can use four or more cores are not the extreme rarity they used to be. Don't get me wrong, scaling well to four or more CPU cores is still rare, but it's no longer spit-take rare.
</li>
<li>Intel introduced the <strong>mainstream second generation Core i5</strong> series, so the platform is fairly mature. All the new architecture bugs are worked out. It's also less prohibitively expensive than it was when it was when it was introduced.
</li>
</ul>
<p>
At this point, I had the seven year upgrade itch really bad. My 3.8 GHz Core 2 Duo with 8 GB of RAM was not exactly chopped liver, but I started fantasizing a lot about the prospect of having a next generation quad-core CPU (of similar clock speed) with hyperthreading and 12 GB of RAM.
</p>
<p>
If you're wondering why I need this, or why in fact <em>anyone</em> would need such an embarrassment of desktop power, then I'll <a href="http://www.maximumpc.com/article/columns/hard_case_looking_forward_2010">refer you to my friend Loyd Case</a>.
</p>
<p>
</p>
<blockquote>
Donâ€™t ask me why I need six cores and 24GB. To paraphrase a Zen master, <strong>if you have to ask, you do not know.</strong>
</blockquote>
<p>
Loyd has indirectly brought up another reason to choose the i7 platform; it's pin-compatible with Intel's upcoming "Gulftown" high end 6-core CPU. So, your upgrade path is clear. (It's also rumored that the next iteration of the Mac Pro will have two of these brand new 6-core CPUs, before any other vendor gets access to them, which is totally plausible.)
</p>
<p>
As far as I'm concerned, <strong>until everything on my computer happens instantaneously, my computer <em>is not nearly fast enough</em></strong>. Besides, relative to how much my time costs, these little $200-$500 upgrades to get amazing performance are freakin' chump change. If I save a measly 15 minutes a day, it's worth it. As I like to remind pointy-haired managers all over the world, <a href="http://www.codinghorror.com/blog/archives/001198.html">Hardware is Cheap, and Programmers are Expensive</a>. OK, maybe I'm biased, but the conclusion was overwhemingly clear: it's UPGRAYEDD time!
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Idiocracy"><img alt="image placeholder" >
</p>
<p>
This is a more than an upgrade, though, it's a <strong>rebuild</strong> -- a platform upgrade. That means I'll be assembling the following â€¦
</p>
<p>
</p>
<ul>
<li>new Motherboard
</li>
<li>new RAM
</li>
<li>new CPU
</li>
<li>new heatsink
</li>
</ul>
<p>
â€¦ and dropping that into my existing system, which is <a href="http://www.codinghorror.com/blog/archives/000665.html">highly optimized for silence</a>. The case, power supply, hard drives, DVD-R, etc won't change. On the outside, it'll look the same, but on the inside, it's a whole new PC. This is analogous to replacing the engine in a sports car, I suppose. On the outside, it will appear to be the same car, but there's a lot more horses under the hood.
</p>
<p>
As I said in <a href="http://www.codinghorror.com/blog/archives/000905.html">the first part of my building your own PC series</a>, if <strong>you can assemble a LEGO kit, you can build a PC</strong>.
</p>
<p>
Take your time, be careful, and go in the right order. So, first things first. Let's assemble the CPU, heatsink, and memory on the motherboard -- in that specific sequence, because modern heatsinks can be a pain to attach.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Man, check out at all that hot, sweet, PC hardware! I get a little residual thrill just cropping the picture. Love this stuff! Anyway, that gives us a mountable motherboard with all the important bits pre-installed:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.jdoqocy.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16813157163%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Motherboards%2B-%2BIntel-_-ASRock-_-13157163&amp;cjsku=N82E16813157163">ASRock X58 Extreme motherboard</a> ($169)<br>
Inexpensive, has all the essential features I care about, and <a href="http://www.tomshardware.com/reviews/asrock-x58-supercomputer,2275-5.html">is recommended by Tom's Hardware</a>. I'm not into fancy, spendy motherboards; I think they're a ridiculous waste of money.
</li>
<li>
<a href="http://www.jdoqocy.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16835233003%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-CPU%2BCooling-_-XIGMATEK-_-35233003&amp;cjsku=N82E16835233003">XIGMATEK HDT-S1283 cooler</a> ($35).<br>
Direct contact between the CPU cooler heatpipes and the CPU surface is the new hotness, or rather, coolness. It really works, since <a href="http://www.frostytech.com/top5heatsinks.cfm">all the top performing CPU coolers</a> use it now. This one is fairly inexpensive at $35 and gets <a href="http://www.frostytech.com/articleview.cfm?articleid=2233&amp;page=5">great reviews</a>. Also, I highly recommend <a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16835233027%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-CPU%2BCooling-_-XIGMATEK-_-35233027&amp;cjsku=N82E16835233027">the optional screw mount kit</a> ($8). Modern CPU coolers are large, and the mounting mechanism needs to be more solid than plastic pushpins.
</li>
<li>
<a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820104161%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Memory%2B%28Desktop%2BMemory%29-_-Kingston%2BHyperX-_-20104161&amp;cjsku=N82E16820104161">Kingston HyperX 4GB (2 x 2GB) DDR3 2000</a> ($135) Ã— 3<br>
I've had good luck with Kingston in the past. I went with their semi-premium brand this time, as I plan to do a bit of overclocking and the price difference is fairly small. Remember, this is a 12 GB build, so we'll need three of these kits to populate all 6 memory slots on the motherboard.
</li>
<li>
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16819115216%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Processors%2B-%2BDesktops-_-Intel-_-19115216&amp;cjsku=N82E16819115216">Intel Core i7-960 3.2 GHz CPU</a> ($590)<br>
While you could make a very solid argument that the <a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16819115202%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Processors%2B-%2BDesktops-_-Intel-_-19115202&amp;cjsku=N82E16819115202">Core i7-920 CPU</a> ($289) is a better choice because it's identical and overclocks to the same level, I was willing to spend a bit more here as "insurance" that I get to the magical 3.8 Ghz level that my old Core 2 Duo was overclocked to.
</li>
</ul>
<p>
<font color="red">update:</font> since a few people asked, here are my case and power supply recommendations.
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.kqzyfj.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16811129061%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Cases%2B%28Computer%2BCases%2B-%2BATX%2BForm%29-_-Antec-_-11129061&amp;cjsku=N82E16811129061">Antec P183 Black Computer Case</a> ($140)<br>
I used the older P180/P182 Antec case in my original series; it's still one of my favorites. This version brings some much needed improvements to airflow to accommodate higher power CPUs and video cards, as documented in a <a href="http://www.silentpcreview.com/antec-p183">recent Silent PC review article</a>.
</li>
<li>
<a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16817139012%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Power%2BSupplies-_-Corsair%2BMemory-_-17139012&amp;cjsku=N82E16817139012">CORSAIR CMPSU-650HX 650W Power Supply</a> ($120)<br>
You don't want to skimp on the power supply, but there's no need to spend exorbitant amounts, either. Forget the wattage rating and look at the quality. Corsair is known for very high quality power supplies. The HX series is a bit more, but has modular cables, which makes for a cleaner build.
</li>
</ul>
<p>
It adds up to about <strong>$1000</strong> all told. A rebuild is definitely more expensive than one-off upgrades of CPU, memory, and hard drive. But, remember, this is a <em>rebuild</em> of my PC -- and a fire-breathing, top of the line performance rebuild at that. That takes spending a moderate (but not exorbitant) amount of money.
</p>
<p>
Now that we've got all that stuff assembled, the next thing to do is open my existing PC, disconnect all the cables going to the motherboard, temporarily remove any expansion cards, unscrew the motherboard and lift it out.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Once the old motherboard assembly was pulled out, I plopped in the new motherboard, screwed it down, and reattached the cables and expansion cards. <em>Don't</em> close up the PC at this point, though. Before powering it on, <strong>double check and make sure all the cables are reattached correctly</strong>:
</p>
<p>
</p>
<ul>
<li>Power cables from the PSU to the motherboard. There are usually at least two, on modern PCs.
</li>
<li>Hard drive cables from the HDDs to the motherboard.
</li>
<li>Power switch, Reset switch, Activity light cables. Without the power switch connected, good luck powering up. This motherboard happens to have built-in power and reset switches for testing, but most don't.
</li>
<li>Fan connectors from the Heatsink and case fans to the motherboard.
</li>
<li>Power cables from the PSU to the video card, if you have a fancy video card.
</li>
</ul>
<p>
If anything is wrong, we'll just have to re-open the case again. On top of that, we need to monitor temperatures and airflow, and that's much easier with the case open.
</p>
<p>
Fortunately, my rebuild booted up on the first try. If you're not so lucky, don't fret! Disconnect the power cord, then go back and re-check everything. I get it wrong, sometimes, too; I actually forgot to reconnect the video card power connectors, and was wondering why only the secondary video card was booting up. Once I re-checked, I immediately saw my mistake, fixed it, and rebooted.
</p>
<p>
Once you have a successful boot, don't even <em>think</em> about booting into the operating system yet. Enter the BIOS (this is typically done by pressing F12 or Delete during bootup) and check the BIOS screens to make sure it's detecting your hard drives, memory, and any optical drives successfully. Browse around and do some basic reality checks. Then do not pass GO, do not collect $200, go <em>straight</em> to your motherboard manufacturer's website and <strong>download the latest BIOS</strong>. On another computer, obviously. Most modern motherboards allow updating the BIOS from a USB key, so just copy the BIOS files on the USB key, reboot, and use the BIOS menus to update. After you've updated the BIOS, set BIOS options to taste, and we're finally ready to boot into an operating system.
</p>
<p>
While this may <em>sound</em> like a lot of work, it really isn't. All told it was maybe an hour, tops. I'm fairly experienced at this stuff, but it's fundamentally not that complicated; it's still just a very fancy adult LEGO kit.
</p>
<p>
<strong>Courtesy of this $1000 rebuild, my ancient 2.5 year old PC is reborn as a completely new state-of-the-art PC</strong>, at least internally. That was always part of the plan! Next up -- once we've proven that it's stable in typical use -- overclocking, naturally. I'll have more on that in a future blog post, but I can tell you right now that Core i7 overclocking is â€¦ <em>interesting</em>.
</p>
<p>
</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-12-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-pc-part-vi-rebuilding/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Responsible Open Source Code Parenting ]]></title>
<link>https://blog.codinghorror.com/responsible-open-source-code-parenting/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm a big fan of <a href="http://daringfireball.net/projects/markdown/">John Gruber's Markdown</a>. When it comes to humane markup languages for the web, I don't think anyone's quite nailed it like Mr. Gruber. His philosophy was clear from the outset:
</p>
<blockquote>
Markdown is intended to be as easy-to-read and easy-to-write as is feasible.
<p>
Readability, however, is emphasized above all else. <strong>A Markdown-formatted document should be publishable as-is, as plain text, without looking like it's been marked up with tags or formatting instructions.</strong> While Markdown's syntax has been influenced by several existing text-to-HTML filters – including Setext, atx, Textile, reStructuredText, Grutatext, and EtText – the single biggest source of inspiration for Markdown's syntax is the format of plain text email.
</p>
</blockquote>
<p>
If you're an ASCII-head of any kind, you will feel immediately at home in Markdown. It was so obviously designed by someone who has done a <em>lot</em> of writing online, as it apes common plaintext conventions that we've collectively been using for decades now. It's certainly <a href="http://www.codinghorror.com/blog/archives/001116.html">far more intuitive than the alternatives I've researched</a>.
</p>
<p>
With a year and a half of real world Markdown experience <a href="http://blog.stackoverflow.com/2009/10/markdown-one-year-later/">under our belts</a> on Stack Overflow, we've been quite happy. I'd say that Markdown is the <em>worst</em> form of markup except for all the other forms of markup that I've tried. Of course, tastes vary, and there are plenty of viable alternatives, but I'd promote Markdown without hesitation as one of the best – if not <em>the</em> best – humane markup options out there.
</p>
<p>
Not that Markdown is perfect, mind you. After exposing it to a large audience, both Stack Overflow <a href="http://github.github.com/github-flavored-markdown/">and GitHub</a> independently discovered that Markdown had three particular characteristics that confused a lot of users:
</p>
<ol>
<li>URLs are never hyperlinked without placing them in some kind of explicit markup.
</li>
<li>The underscore [_] can be used to delimit bold and italic, but also works for intra-word emphasis. While a typical use like "_italic_" is clear, there are disturbing and unexpected side effects in phrases such as "some_file_name" and "file_one and file_two".
</li>
<li>It is paragraph and not line oriented. Returns are not automatically converted to linebreaks. Instead, paragraphs are detected as one or more consecutive lines of text, separated by one or more blank lines.
</li>
</ol>
<p>
Items #1 and #2 are so fundamental and universal that I think <strong>they deserve to be changed in the Markdown specification itself</strong>. There was so much confusion around unexpected intra-word emphasis and the failure to auto-hyperlink URLs that we changed these Markdown rules before we even came out of private beta. Item #3, the conversion of returns to linebreaks, is somewhat more debatable. I'm on the fence on that one, but I do believe it's significant enough to warrant an explicit choice either way. It should be a standard configurable option in every Markdown implementation that you can switch on or off depending on the intended audience.
</p>
<p>
Markdown was originally introduced in 2004, and since then it has gained quite a bit of traction on the web. I mean, <a href="http://www.mediawiki.org/wiki/Help:Formatting">it's no MediaWiki</a> (thank God), but it's in active use on a bunch of websites, some of them <a href="http://www.joelonsoftware.com/items/2009/12/13.html">quite popular</a>. And for such a popular form of markup, it's a bit odd that the last official update to the specification and reference implementation was in late 2004.
</p>
<p>
Which leads me to the biggest problem with Markdown: <strong>John Gruber</strong>.
</p>
<p>
I don't mean this as a personal criticism. John's a <a href="http://daringfireball.net/">fantastic writer</a> and Markdown has a (mostly) solid specification, with a strong vision statement. But the fact that there has been no improvement whatsoever to the specification or reference implementation for <em>five years</em> is â€¦ kind of a problem.
</p>
<p>
There are some <strong>fairly severe bugs</strong> in that now-ancient 2004 Markdown 1.0.1 Perl implementation. Bugs that John has already fixed in eight 1.0.2 betas that have somehow never seen the light of day. Sure, if you know the right Google incantations you can <a href="http://six.pairlist.net/pipermail/markdown-discuss/2007-May/000615.html">dig up the unreleased 1.0.2b8 archive</a>, surreptitiously posted May 2007, and start prying out the bugfixes by hand. That's what I've had to do to fix bugs in <a href="http://blog.stackoverflow.com/2009/12/introducing-markdownsharp/">our open sourced C# Markdown implementation</a>, which was naturally based on that fateful (and technically <em>only</em>) 1.0.1 release.
</p>
<p>
I'd also expect a reference implementation to come with some <strong>basic test suites or sample input/output files</strong> so I can tell if I've implemented it correctly. No such luck; the official archives from Gruber's site include the naked Perl file along with a readme and license. The word "test" does not appear in either. I had to do a ton more searching to finally <a href="http://six.pairlist.net/pipermail/markdown-discuss/2009-February/001526.html">dig up MDTest 1.1</a>. I can't quite tell where the tests came from, but they seem to be maintained by Michel Fortin, the author of the <a href="http://michelf.com/projects/php-markdown/">primary PHP Markdown implementation</a>.
</p>
<p>
But John Gruber <em>created</em> Markdown. He came up with the concept and the initial implementation. He is, in every sense of the word, <strong>the parent of Markdown</strong>. It's his baby.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As Markdown's "parent", John has a few key responsibilities in shepherding his baby to maturity. Namely, to lead. To set direction. Beyond that initial 2004 push, he's done precious little of either. <strong>John is running this particular open source project the way Steve Jobs runs Apple – by sheer force of individual ego.</strong> And that sucks.
</p>
<p>
Since then, all I can find is sporadic activity on obscure mailing lists and a bit of <a href="http://six.pairlist.net/pipermail/markdown-discuss/2008-March/001173.html">passive-aggressive interaction with the community</a>.
</p>
<blockquote>
On 15 Mar 2008, at 02:55, John Gruber wrote:
<blockquote>
<em>I despise what you've done with Text::Markdown, which is to more or less make it an alias for MultiMarkdown, almost every part of which I disagree with in terms of syntax additions.</em>
</blockquote>
Wow, that's pretty strong language. I'm glad I'm provoking strong opinions, and it's nice to see you actively contributing to Markdown's direction ;)
<p>
Personally, I don't actually like (or use) the MultiMarkdown extensions. As noted several times on list, I <em>do not</em> consider what I've done to in any way be a good solution technically / internally in it's current form, and as such
Markdown.pl is still a better 'reference' implementation.
</p>
<p>
However I find it somewhat ironic that you can criticise an active effort to actually move Markdown forwards (who's current flaws have been publicly acknowledged), when it passes more of your test suite than your effort does, and when you haven't even been bothered to update your own website about the project since 2004, despite having updated the code which can be found on your site (if you dig) much more recently than this.
</p>
<p>
I despise copy-pasted code, and forks for no (real) reason - seeing <em>another two</em> dead copies of the same code on CPAN made me sad, and so I've done <em>something</em> to take the situation forwards. <strong>Maybe if you'd put the effort into maintaining a community and taking Markdown.pl forwards at any time within the last 4 years, you wouldn't be in a situation where people have taken 'your baby' and perverted it to a point that you despise.</strong> If starting with Markdown.pl and going forwards with that <em>had been an option</em>, then that would have been my preferred route - but I didn't see any value in producing what would have been a fifth perl Markdown implementation.
</p>
</blockquote>
<p>
It's almost at the point where John Gruber, the very person who brought us Markdown, is the biggest obstacle preventing Markdown from moving forward and maturing. It saddens me greatly to see such negligent open source code parenting. Why work against the community when you can work with it? It doesn't have to be this way. And it shouldn't be.
</p>
<p>
I think the most fundamental problem with Markdown, in retrospect, is that the official home of the project is <strong>a static set of web pages on John's site</strong>. Gruber could have hosted the Markdown project in a way that's more amenable to open source collaboration than a bunch of static HTML. I'm pretty sure SourceForge was around in late 2004, and there are lots of options for proper open source project hosting today – GitHub, Google Code, CodePlex, and so forth. What's stopping him from setting up shop on any of those sites with Markdown, right now, today? Markdown is Gruber's baby, without a doubt, but it's also bigger than any one person. It's open source. It belongs to the community, too.
</p>
<p>
Right now we have the worst of both worlds. Lack of leadership from the top, and a bunch of fragmented, poorly coordinated community efforts to advance Markdown, <em>none</em> of which are officially canon. This isn't merely incovenient for anyone trying to find accurate information about Markdown; it's actually harming the project's future. <strong>Maybe it's true that you can't kill an open source project, but bad parenting is surely enough to cause it to grow up stunted and maybe even a little maladjusted.</strong>
</p>
<p>
I mean no disrespect. I wouldn't bring this up if I didn't care, if I didn't think the project and John Gruber were both eminently worthy. Markdown is a small but important part of the open source fabric of the web, and the project deserves better stewardship. While the community can do a lot with the (many) open source orphan code babies out there, they have a much, much brighter future when their parents take responsibility for them.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2009-12-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/responsible-open-source-code-parenting/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Democracy of Netbooks ]]></title>
<link>https://blog.codinghorror.com/a-democracy-of-netbooks/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As a long time reader of Joey DeVilla's excellent blog, <a href="http://www.globalnerdy.com">Global Nerdy</a>, I take exception to his post <a href="http://www.globalnerdy.com/2009/05/26/fast-food-apple-pies-and-why-netbooks-suck/">Fast Food, Apple Pies, and Why Netbooks Suck</a>:
</p>
<p>
</p>
<blockquote>
The end result, to my mind, is a device that occupies an uncomfortable, middle ground between laptops and smartphones that tries to please everyone and pleases no one. Consider the factors:
<p>
</p>
<ul>
<li>Size: A bit too large to go into your pocket; a bit too small for regular day-to-day work.
</li>
<li>Power: Slightly more capable than a smartphone; slightly less capable than a laptop.
</li>
<li>Price: Slightly higher than a higher-end smartphone but lacking a phone's capability and portability; slightly lower than a lower-end notebook but lacking a notebook's speed and storage.
</li>
</ul>
To summarize: Slightly bigger and pricier than a phone, but can't phone. Slightly smaller and cheaper than a laptop, but not that much smaller or cheaper. To adapt a phrase I used in an article I wrote yesterday, <strong>netbooks are like laptops, but lamer.</strong>
<p></p>
</blockquote>
<p>
This is so wrongheaded I am not sure where to begin. I happen to <a href="http://www.scripting.com/stories/2008/10/22/whyILikeNetbooks.html">agree with Dave Winer's definition of "netbook"</a>:
</p>
<p>
</p>
<blockquote>
<ol>
<li>Small size.
</li>
<li>Low price.
</li>
<li>Battery life of 4+ hours. Battery can be replaced by user.
</li>
<li>Rugged.
</li>
<li>Built-in wifi, 3 USB ports, SD card reader.
</li>
<li>Runs my software.
</li>
<li>Runs any software I want; no platform vendor to decide what's appropriate.
</li>
<li>Competition. Users have choice and can switch vendors at any time.
</li>
</ol>
</blockquote>
<p>
Netbooks are the endpoint of four decades of computing -- the final, ubiquitous manifestation of <a href="http://en.wikipedia.org/wiki/Microsoft">"A PC on every desk and in every home"</a>. But netbooks are more than just PCs. If the internet is the ultimate force of democratization in the world, then netbooks are the instrument by which that democracy will be achieved.
</p>
<p>
No monthly fees and contracts.
</p>
<p>
No gatekeepers.
</p>
<p>
Nobody telling you what you can and can't do with your hardware, or on their network.
</p>
<p>
To dismiss netbooks as <em>like laptops, but lamer</em> is to completely miss the importance of this pivotal moment in computing -- when pervasive internet and the mass production of inexpensive portable computers finally intersected. I'm talking about <strong>unlimited access to the complete sum of human knowledge, and free, unfettered communication with anyone on earth.</strong> For everyone.
</p>
<p>
It's true that smartphones are slowly becoming little PCs, but they will never be <em>free</em> PCs. They will forever be locked behind an imposing series of gatekeepers and toll roads and walled gardens. Anyone with a $199 netbook and access to the internet can make free Skype videophone calls to anywhere on Earth, for as long as they want. Meanwhile, sending a single text message on a smartphone costs 4 times as much as <a href="http://www.physorg.com/news129793047.html">transmitting data to the Hubble space telescope</a>.
</p>
<p>
I don't care how "smart" your smartphone is, it will never escape those corporate shackles. Smartphones are simply <em>not free enough</em> to deliver the type of democratic transformation that netbooks -- mobile PCs cheap enough and fast enough and good enough for everyone to afford -- absolutely will.
</p>
<p>
That's why I love netbooks. In all their cheap, crappy glory. And you should too. Because they're <a href="http://www.scripting.com/stories/2009/10/14/whatsObviousAboutNetbooks.html">instruments of user power</a>.
</p>
<p>
</p>
<blockquote>
The truly significant thing is this -- the users took over.
<p>
Let me say that again: <em>The users took over</em>.
</p>
<p>
I always say this is the lesson of the tech industry, but the people in the tech industry never believe it, but this is the loop. In the late 70s and early 80s the minicomputer and mainframe guys said the same kinds of things about Apple IIs and IBM PCs that Michael Dell is saying about netbooks. It happens over and over again, I've recited the loops so many times that every reader of this column can recite them from memory. All that has to be said is that it happened again.
</p>
<p>
Once out, the genie never goes back in the bottle.
</p>
<p></p>
<p></p>
</blockquote>
<p>
Netbooks aren't an alternative to notebook computers. <strong>They <em>are</em> the new computers.</strong>
</p>
<p>
Cheap and crappy? Maybe those early models were, but having purchased a new netbook for $439 shipped, it is difficult for me to imagine the average user ever paying more than $500 for a laptop.
</p>
<p>
<a href="http://www.amazon.com/s?ie=UTF8&amp;keywords=Acer%20AS1410&amp;tag=codihorr-20&amp;index=blended&amp;link_code=qs"><img alt="image placeholder" >
</p>
<p>
For the price, this is an astonishingly capable PC:
</p>
<p>
</p>
<ul>
<li>Dual Core 1.2 GHz Intel CULV Celeron processor
</li>
<li>2 GB RAM
</li>
<li>Windows 7 Home Premium
</li>
<li>11.6" screen with 1366 x 768 resolution
</li>
<li>Thin (1") and light (3.5 lbs)
</li>
<li>Good battery life (5 hours)
</li>
<li>3 USB ports, WiFi, webcam, gigabit ethernet
</li>
</ul>
<p>
Windows 7 is a fine OS, but this machine would surely be cheaper without <a href="http://www.codinghorror.com/blog/archives/000870.html">the Microsoft Tax</a>, too.
</p>
<p>
The <a href="http://www.amazon.com/s?ie=UTF8&amp;keywords=Acer%20AS1410&amp;tag=codinghorror_20&amp;index=blended&amp;link_code=qs">Acer Aspire 1410</a> isn't just an adequate netbook, it's a damn good <em>computer</em>. At these specifications, it is a huge step up from those early netbook models in every way. But don't take my word for it; read the reviews at <a href="http://netbooked.net/netbook-reviews/review/11.6-acer-aspire-as1410-celeron-su2300-review/">netbooked</a> and <a href="http://www.liliputing.com/2009/11/acer-aspire-1410-review-dual-core-version.html">Liliputing</a>. (Caveat emptor -- there are lots of 1410 models, and the newer dual core CPU version is the one you want.)
</p>
<p>
Of particular note is the CPU. While the Intel Atom is <a href="http://www.anandtech.com/cpuchipsets/intel/showdoc.aspx?i=3276">a technological coup</a>, I don't feel current Atom CPUs deliver quite enough performance for a modern, JavaScript-heavy, video-intensive internet experience. It is quite clear that Intel is <a href="http://www.anandtech.com/mobile/showdoc.aspx?i=3693&amp;p=8">intentionally hobbling</a> newer iterations of the Atom CPU in the name of market segregation, and to prevent too much netbook price erosion.
</p>
<p>
That's why the current <a href="http://en.wikipedia.org/wiki/Consumer_Ultra-Low_Voltage">Intel CULV CPUs</a> are far more attractive options -- they're <a href="http://www.anandtech.com/mobile/showdoc.aspx?i=3699&amp;p=4">dramatically faster</a>, and have become power-efficient marvels. I hooked up <a href="http://www.codinghorror.com/blog/archives/000353.html">my watt meter</a> to this Aspire 1410 and I was surprised to find it consume <strong>between 13 and 16 watts</strong> of power in typical use -- while my wife was browsing the web in Firefox, over a wireless connection, with multiple tabs open. I fired up Prime95 torture test to force the CPU to 100% load, and measured <strong>21 watts</strong> with one CPU core fully loaded, and <strong>26 watts</strong> when both were. These are wall measurements which reflect power conversion inefficiencies of at least 20%, so real consumption was between 10 and 20 watts. I was wondering why it ran so cool; now I know. It barely uses enough power to generate any heat!
</p>
<p>
Modern netbooks are not cheap and crappy. They're remarkable computers in their own right, and they're getting better every day. Which <a href="http://bits.blogs.nytimes.com/2008/10/21/read-my-lips/">makes me wonder</a>:
</p>
<p>
</p>
<blockquote>
A recurring question among Apple watchers for decades has been, Ã¢â‚¬Å“When is Apple going to introduce a low-cost computer?
<p>
Steve Jobs answered that decades-old complaint by stating, "We don't know how to build a sub-$500 computer that is not a piece of junk."
</p>
</blockquote>
<p>
They may be pieces of junk to Mr. Jobs, but to me, these modest little boxes are marvels -- inspiring evidence of the inexorable march of powerful, open computing technology to everyman and everywhere.
</p>
<p>
We have produced <strong>a democracy of netbooks</strong>. And the geek in me can't wait to see what happens next.
</p>
<p>
</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-01-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-democracy-of-netbooks/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Great Newline Schism ]]></title>
<link>https://blog.codinghorror.com/the-great-newline-schism/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Have you ever opened a simple little ASCII text file to see it inexplicably displayed as onegiantunbrokenline?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Opening the file in a different, smarter text editor results in the file displayed properly in multiple paragraphs.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The answer to this puzzle lies in our old friend, <a href="http://www.codinghorror.com/blog/archives/001310.html">invisible characters that we can't see but that are <em>totally</em> not out to get us</a>. Well, except when they are.
</p>
<p>
The invisible problem characters in this case are <strong>newlines</strong>.
</p>
<p>
Did you ever wonder what was at the end of your lines? As a programmer, I knew there were end of line characters, but I honestly never thought much about them. They just â€¦ <em>worked</em>. But newlines aren't a universally accepted standard; they are different depending who you ask, and what platform they happen to be computing on:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="500">
<tbody>
<tr>
<td><strong>DOS / Windows</strong></td>
<td>CR LF</td>
<td><code>rn</code></td>
<td><code>0x0D 0x0A</code></td>
</tr>
<tr>
<td>
<strong>Mac</strong> (early)</td>
<td>CR</td>
<td><code>r</code></td>
<td><code>0x0D</code></td>
</tr>
<tr>
<td><strong>Unix</strong></td>
<td>LF</td>
<td><code>n</code></td>
<td><code>0x0A</code></td>
</tr>
</tbody>
</table>
<p>
The Carriage Return (CR) and Line Feed (LF) terms derive from manual typewriters, and old printers based on typewriter-like mechanisms (typically referred to as <a href="http://en.wikipedia.org/wiki/Daisy_wheel_printer">"Daisywheel" printers</a>).
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
On a typewriter, pressing Line Feed causes the carriage roller to push up one line -- without changing the position of the carriage itself -- while the <a href="http://en.wikipedia.org/wiki/Carriage_return">Carriage Return</a> lever slides the carriage back to the beginning of the line. In all honesty, I'm not <em>quite</em> old enough to have used electric typewriters, so I have a dim recollection, at best, of the entire process. The distinction between CR and LF does seem kind of pointless -- why would you want to move to the beginning of a line <em>without</em> also advancing to the next line? This is another analog artifact, as Wikipedia explains:
</p>
<p>
</p>
<blockquote>
On printers, teletypes, and computer terminals that were not capable of displaying graphics, the carriage return was used without moving to the next line to allow characters to be placed on top of existing characters to produce character graphics, underlines, and crossed out text.
</blockquote>
<p>
So far we've got:
</p>
<p>
</p>
<ul>
<li>Confusing terms based on archaic hardware that is no longer in use, and is confounding to new users who have no point of reference for said terms;
</li>
<li>Completely arbitrary platform "standards" for what is exactly the same function.
</li>
</ul>
<p>
Pretty much business as usual in computing. If you're curious, as I was, about the historical basis for these decisions, <a href="http://en.wikipedia.org/wiki/Newline#History">Wikipedia delivers all the newline trivia you could possibly want, and more</a>:
</p>
<p>
</p>
<blockquote>
The sequence <code>CR+LF</code> was in common use on many early computer systems that had adopted teletype machines, typically an ASR33, as a console device, because this sequence was required to position those printers at the start of a new line. On these systems, text was often routinely composed to be compatible with these printers, since the concept of device drivers hiding such hardware details from the application was not yet well developed; applications had to talk directly to the teletype machine and follow its conventions. <strong>The separation of the two functions concealed the fact that the print head could not return from the far right to the beginning of the next line in one-character time. That is why the sequence was always sent with the CR first. In fact, it was often necessary to send extra characters (extraneous CRs or NULs, which are ignored) to give the print head time to move to the left margin.</strong> Even after teletypes were replaced by computer terminals with higher baud rates, many operating systems still supported automatic sending of these fill characters, for compatibility with cheaper terminals that required multiple character times to scroll the display.
<p>
CP/M's use of <code>CR+LF</code> made sense for using computer terminals via serial lines. MS-DOS adopted CP/M's <code>CR+LF</code>, and this convention was inherited by Windows.
</p>
</blockquote>
<p>
This <em>exciting</em> difference in how newlines work means you can expect to see one of three (or more, as we'll find out later) newline characters in those "simple" ASCII text files.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If you're fortunate, you'll pick a fairly intelligent editor that can detect and properly display the line endings of whatever text files you open. If you're less fortunate, you'll see onegiantunbrokenline, or a bunch of extra <code>^M</code> characters in the file.
</p>
<p>
Even worse, <strong>it's possible to mix all three of these line endings in the same file.</strong> Innocently copy and paste a comment or code snippet from a file with a different set of line endings, then save it. <em>Bam</em>, you've got a file with multiple line endings. That you can't see. I've accidentally done it myself. (Note that this depends on your choice of text editor; some will auto-normalize line endings to match the current file's settings upon paste.)
</p>
<p>
This is complicated by the fact that some editors, even editors that should know better, like Visual Studio, have <strong>no mode that shows end of line markers</strong>. That's why, when attempting to open a file that has multiple line endings, Visual Studio will politely ask you if it can normalize the file to one set of line endings.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This Visual Studio dialog presents the following five (!) possible set of line endings for the file:
</p>
<ol>
<li>Windows (CR LF)
</li>
<li>Macintosh (CR)
</li>
<li>Unix (LF)
</li>
<li>Unicode Line Separator (LS)
</li>
<li>Unicode Paragraph Separator (PS)
</li>
</ol>
<p>
The last two are new to me. I'm not sure under what circumstances you would want those <a href="http://en.wikipedia.org/wiki/Newline#Unicode">Unicode newline markers</a>.
</p>
<p>
Even if you <a href="http://www.codinghorror.com/blog/archives/000178.html">rule out unicode</a> and stick to old-school ASCII, like most Facebook relationships â€¦ it's complicated. I find it fascinating that the mundane ASCII newline has so much ancient computing lore behind it, and that it still <em>regularly</em> bites us in unexpected places.
</p>
<p>
If you work with text files in any capacity -- and what programmer doesn't -- you should know that not all newlines are created equally. <strong>The Great Newline Schism is something you need to be aware of</strong>. Make sure your tools can show you not just those pesky <a href="http://www.codinghorror.com/blog/archives/001310.html">invisible white space characters</a>, but line endings as well.
</p>
<p>
</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-01-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-great-newline-schism/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Cultivate Teams, Not Ideas ]]></title>
<link>https://blog.codinghorror.com/cultivate-teams-not-ideas/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>How much is a good idea worth? According to Derek Sivers, <a href="http://sivers.org/multiply">not much</a>:</p>
<blockquote>
<p>It's so funny when I hear people being so protective of ideas. (People who want me to sign an NDA to tell me the simplest idea.) To me, <strong>ideas are worth nothing unless executed</strong>. They are just a multiplier. Execution is worth millions.</p>
<p>To make a business, you need to multiply the two. The most brilliant idea, with no execution, is worth $20. The most brilliant idea takes great execution to be worth $20,000,000. That's why I don't want to hear people's ideas. I'm not interested until I see their execution.</p>
</blockquote>
<p>I was reminded of Mr. Sivers article when <a href="http://groups.google.com/group/barcampla/browse_thread/thread/4b4091eaf6fb6743?pli=1">this email</a> made the rounds earlier this month:</p>
<blockquote>
<p>I feel that this story is important to tell you because Kickstarter.com copied us.  I tried for 4 years to get people to take Fundable seriously, traveling across the country, even giving a presentation to FBFund, Facebook's fund to stimulate development of new apps.  It was a series of rejections for 4 years.  I really felt that I presented myself professionally in every business situation and I dressed appropriately and practiced my presentations.  That was not<br>
enough. The idiots wanted us to show them charts with massive profits and widespread public acceptance so that they didn't have to take any risks.</p>
<p>All it took was 5 super-connected people at Kickstarter (especially Andy Baio) to take a concept we worked hard to refine, tweak it with Amazon Payments, and then take credit.  You could say that that's capitalism, but I still think you should acknowledge people that you take inspiration from.  I do.  I owe the concept of Fundable to many things, including living in cooperative student housing and studying Political Science at Michigan.  Rational choice theory, tragedy of the commons, and collective action are a few political science concepts that are relevant to Fundable.</p>
<p>Yes, Fundable had some technical and customer service problems. That's because we had no money to revise it.  I had plans to scrap the entire CMS and start from scratch with a new design.  We were just so burned out that motivation was hard to come by.  What was the point if we weren't making enough money to live on after 4 years?</p>
</blockquote>
<p>The disconnect between idea and execution here is so vast it's hard to understand why the author himself can't see it.</p>
<p>I wouldn't call ideas <em>worthless</em>, per se, but it's clear that ideas alone are a hollow sort of currency. Success is rarely determined by the quality of your ideas. But it <em>is</em> frequently determined by the quality of your execution. So instead of worrying about whether the Next Big Idea you're all working on is sufficiently brilliant, <strong>worry about how well you're executing.</strong></p>
<p>The criticism that all you need is "super-connected people" to be successful was also leveled at Stack Overflow. In an email to me last year, Andy Baio  –  ironically, the very person being cited in the email  –  said:</p>
<blockquote>
<p>I very much enjoyed <a href="http://www.codinghorror.com/blog/archives/001284.html">the Hacker News conversation about cloning the site in a weekend</a>.  My favorite comments were from the people that believe Stack Overflow is only successful because of the Cult of Atwood &amp; Spolsky. Amazing.</p>
</blockquote>
<p>I don't care how internet famous you are; <i>nobody</i> gets a pass on execution. Sure, you may have a few more eyeballs at the beginning, but if you don't build something useful, the world will eventually just shrug its collective shoulders and move along to more useful things.</p>
<p>One of my all time favorite software quotes is <a href="http://daringfireball.net/2007/08/c4_1_in_a_nut">from Wil Shipley</a>:</p>
<blockquote>
<p>This is all your app is: a collection of tiny details.</p>
</blockquote>
<p><strong>In software development, execution is staying on top of all the tiny details that make up your app.</strong> If you're not constantly obsessing over every aspect of your application, relentlessly polishing and improving every little part of it  –  no matter how trivial  –  you're not executing. At least, not well.</p>
<p>And unless you work alone, which is a rarity these days, your ability to stay on top of the collection of tiny details that makes up your app will hinge entirely on whether or not you can build a great team. They are the building block of any successful endeavor. This talk by <a href="http://en.wikipedia.org/wiki/Edwin_Catmull">Ed Catmull</a> is almost exclusively focused on how Pixar learned, through trial and error, to build teams that can <i>execute</i>.</p>
<iframe width="480" height="360" src="//www.youtube.com/embed/k2h2lvhzMDc" frameborder="0" allowfullscreen></iframe>
<p>It's a fascinating talk, full of some great insights, and you should <a href="http://www.youtube.com/watch?v=k2h2lvhzMDc">watch the whole thing</a>. In it, Mr. Catmull amplifies Mr. Sivers' sentiment:</p>
<blockquote>
<p>If you give a good idea to a mediocre group, they'll screw it up. <strong>If you give a mediocre idea to a good group, they'll fix it.</strong> Or they'll throw it away and come up with something else.</p>
</blockquote>
<p>Execution isn't merely a multiplier. It's far more powerful. How your team executes has the power to transform your idea from gold into lead, or from lead into gold. That's why, when building Stack Overflow, I was so fortunate to not only <a href="http://blog.codinghorror.com/introducing-stackoverflow-com/">work with Joel Spolsky</a>, but also to cherry-pick two of the best developers I had ever worked with in my previous jobs and drag them along with me. Kicking and screaming if necessary.</p>
<p>If I had to point to <b>the one thing that made our project successful</b>, it was not the idea behind it, our internet fame, the tools we chose, or the funding we had (precious little, for the record).</p>
<p>It was our team.</p>
<p>The value of my advice is debatable. But you would do well to heed the advice of Mr. Sivers and Mr. Catmull. If you want to be successful, stop worrying about the great ideas, and concentrate on cultivating great teams.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-01-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/cultivate-teams-not-ideas/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Welcome Back Comments ]]></title>
<link>https://blog.codinghorror.com/welcome-back-comments/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I apologize for the scarcity of updates lately. There have been two things in the way:</p>
<ol>
<li>
<p>Continuing fallout from <a href="http://www.codinghorror.com/blog/2009/12/international-backup-awareness-day.html">International Backup Awareness Day</a>, which meant all updates to Coding Horror from that point onward were hand-edited text files. Which, believe me, isn't <i>nearly</i> as sexy as it … uh … doesn't sound.</p>
</li>
<li>
<p>I am <a href="http://www.webstock.org.nz/10/programme/presentations.php">presenting and conducting a workshop at Webstock 2010</a> in New Zealand. This is a two week trip I'm taking with the whole family, including our little buddy <a href="http://www.codinghorror.com/blog/2009/03/spawned-a-new-process.html">Rock Hard Awesome</a>, so the preparations have been more intense than usual.</p>
</li>
</ol>
<p>On top of all that, <a href="http://www.webstock.org.nz/10/programme/presentations.php">according to the program</a>, I just found that my presentation involves <i>interpretive dance</i>, too. Man. I wish someone had told me! My moves are so rusty, they've barely improved from <a href="http://en.wikipedia.org/wiki/Breakin'_2:_Electric_Boogaloo">Electric Boogaloo</a>. But hey, at least I don't have to sing Andrews Sister songs like poor Brian Fling.</p>
<p>And then, of course, there's that crazy <a href="http://www.codinghorror.com/blog/2008/04/introducing-stackoverflow-com.html">Stack Overflow thing</a> I'm always yammering on about. Very busy there, our <a href="http://blog.stackoverflow.com/2010/01/eating-our-own-careers-dogfood/">team is expanding</a>, and we have big plans for this year, too.</p>
<p>But, there is hope!</p>
<p>Thanks to the fine folks at <a href="http://www.sixapart.com/">Six Apart</a> – and more specifically the herculean efforts of one <a href="http://sippey.typepad.com/">Michael Sippey</a> – <b>Coding Horror is now hosted in the <a href="http://typepad.com/">TypePad</a> ecosystem</b>. Which means, at least in theory, better "cloud" type reliability in the future. (cough)</p>
<p>One accidental bit of collateral damage was that comments, by necessity, were disabled during this two month period. At first, I was relieved. This may seem a bit hypocritical, since I originally wrote <a href="http://www.codinghorror.com/blog/2006/04/a-blog-without-comments-is-not-a-blog.html">A Blog Without Comments is Not a Blog</a>. And I still believe it too. But as I prophetically noted in the very same post:</p>
<blockquote>
<p>I am sympathetic to issues of scale. <b>Comments don't scale worth a damn.</b> If you have thousands of readers and hundreds of comments for every post, you should disable comments and switch to forums, probably moderated forums at that. But the number of bloggers who have that level of readership is so small as to be practically nil. And when you get there, believe me, you'll know. Until then, you should enable comments.</p>
</blockquote>
<p>I guess you can put this in the "nice problems to have" category, but let me tell you, it's not so nice of a problem when it's on your plate. <b>At a large enough scale, comments require active moderation or they rapidly go sour.</b> People get mean, the crazies come out in full force, and the comments start to resemble an out of control trailer park reality show brawl. It's fun, I suppose, but in a way that drives out all the sane people. Left unchecked, the best you can hope for is to end up head resident at the sanitarium. And that's a hell of a way to go out.</p>
<p><a href="http://redwing.hutman.net/~mreed/warriorshtm/howlers.htm"><img alt="image placeholder" >
<p>(the above is from Mike Reed's <a href="http://www.codinghorror.com/blog/2005/11/which-online-discussion-archetype-are-you.html">amazing Flame Warriors series</a>, by the way. Well worth your time if you haven't seen it already.)</p>
<p>The degeneration of comments was a shame, because it undermined my claim that <a href="http://www.codinghorror.com/blog/2008/06/finally-a-definition-of-programming-i-can-actually-understand.html">comments are awesome</a>.</p>
<blockquote>
<p>It's an open secret amongst bloggers that the blog comments are often better than the original blog post, and it's because the community collectively knows far more than you or I will ever know.</p>
</blockquote>
<p>The best part of a blog post often begins where the blog post ends. If you are offended by that, I humbly submit you don't understand why blogs work.</p>
<p>Why would I have bothered to found Stack Overflow with Joel Spolsky if I didn't believe in the power of community – that <a href="http://www.codinghorror.com/blog/2008/09/stack-overflow-none-of-us-is-as-dumb-as-all-of-us.html">none of us is as dumb as all of us?</a> Honestly, a lot of the design of Stack Overflow comes from my personal observations about how blog comments work. But my creaky old Coding Horror comments offered none of the fancy voting and moderation facilities that make Stack Overflow work. And without ample free personal time and attention from me to weed the comment garden, the comments got out of control.</p>
<p><b>Most of all, I blame myself.</b></p>
<p>I got some amazing emails in lieu of comments on my last few blog posts, and it positively <i>kills</i> me that these emails were only seen by two sets of eyes instead of the thousands they deserve. That's a big part of why I <a href="http://www.codinghorror.com/blog/2007/05/maximizing-the-value-of-your-keystrokes.html">hate email silos</a>. And really, <a href="http://blog.stackoverflow.com/2010/02/podcast-83/">email in general</a>.</p>
<p>But there was another unanticipated side effect of having comments disabled that Stephane Charette pointed out to me in email.</p>
<blockquote>
<p>Here is an interesting "silver lining" to the crash you had.  Without<br>
comments, it forces us, your faithful readers, to think more about what you have to say.</p>
<p>In a way, things are back to how your blog used<br>
to be.  In recent years, the huge influx of comments means that we – or just I? – end up spending 1/4 of my time reading what you wrote, and then merging in what everyone else wrote.  Depending on how I feel about the topic and your approach to the issue, the weight values may be very different than 50/50.  But regardless, I always have to consider when clicking on my Coding Horror bookmark:  "Is now the right time to check if he has a new entry?  Do I have enough time to read through a hundred comments?  Should I wait until later tonight when the kids are in bed to go read his latest article?"</p>
<p>I never thought about it until recently.  Your crash is what brought this up to light.  Like tonight, when I saw your new headline in my iGoogle page, I didn't have to consider whether or not it was the right time.  I read the article, and then <i>thought for myself</i>. I didn't let other people's comments steer my thoughts.  How nice!</p>
<p>I'm not certain why it works like this.  Often, the sheer number of comments distracts from what you wrote, but for some reason, it is impossible not to at the very least scroll through what people say. In a way, your blog has ended up like a slashdot article, with a paragraph or two of content at the top, and then everyone wanting to insert their $0.02.</p>
</blockquote>
<p>Thinking for yourself. Now there's a <a href="http://www.codinghorror.com/blog/2008/10/youre-reading-the-worlds-most-dangerous-programming-blog.html">novel idea</a>. In the reverberating echo chamber that is the internet, I think we would <i>all</i> do well to remind ourselves of that periodically.</p>
<p>He's also right that the psychic burden of all those comments was weighing not just on readers, but on me, the writer, too. That's why I had a false sense of freedom when comments were disabled. <i>You mean I can say whatever I want, and nobody can contradict me underneath my very own post? Revolutionary!</i></p>
<p>There are some absolute gems of insight and observation in comments, but sometimes extracting them was too much like pulling teeth. At the same time, I felt obligated to read all the comments on every post of mine. If I was asking people to read the random words I'm spewing all over the internet, how could I not extend my commenters the same courtesy? That's just rude.</p>
<p>It seems the only thing worse than comments being on was comments being <i>off</i>. It started to feel empty. As if I was in an enormous room, presenting to an eerily mute audience.</p>
<p>So, while I am very glad to have comments back, and I welcome dialog with the community, there will be … changes. For the benefit of everyone's mental health.</p>
<ol>
<li>
<b>No more anonymous comments</b>. While I would prefer to allow anonymous comments, it is clear that at this scale I don't have time to deal properly with anonymous comments. If you want to say something, you'll need to authenticate. If what you have to say isn't worth authenticating to post, it's probably best for both of us if you keep it to yourself anyway.</li>
</ol>
<p>The good news is that the TypePad commenting system supports a veritable laundry list of authentication mechanisms -- OpenID (naturally), Twitter, Facebook, Google, Yahoo, and many others. So authenticating to post a comment should only present a mild, but necessary, barrier to conversation.</p>
<ol start="2">
<li>
<b>Comment moderation will be more stringent</b>. If you don't have something useful and reasonably constructive to say in your comment, it will be removed without hesitation. You can be <a href="http://www.codinghorror.com/blog/2009/06/i-stopped-reading-your-blog-years-ago.html">as critical of me</a> (or, better still, my arguments and ideas) as you like, but you must convince me that you're <i>contributing</i> to the conversation and not just yelling at me or anyone else.</li>
</ol>
<p>I'm not looking for sycophants, but shrill argument is every bit as bad. When you comment here, try to show the class something interesting they can use. That's all I'm asking.</p>
<p>It feels good to be back. Thanks to Six Apart for making it happen.</p>
<p>And, most of all, thanks to <i>you</i> for reading.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-02-12T23:03:12.000Z</pubDate>
<guid>https://blog.codinghorror.com/welcome-back-comments/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Non-Programming Programmer ]]></title>
<link>https://blog.codinghorror.com/the-nonprogramming-programmer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I find it difficult to believe, but the reports keep pouring in via Twitter and email: <b>many candidates who show up for programming job interviews can't program. At all.</b> Consider this recent email from Mike Lin:
</p>
<p>
</p>
<blockquote>
The article <a href="http://www.codinghorror.com/blog/2007/02/why-cant-programmers-program.html">Why Can't Programmers... Program?</a> changed the way I did interviews.  I used to lead off by building rapport. That proved to be too time-consuming when, as you mentioned, the vast majority of candidates were simply non-technical. So I started leading off with technical questions. First progressing from easy to hard questions. Then I noticed I identified the rejects faster if I went the other way – hard questions first – so long as the hard questions were still in the "if you don't know this then you can't work here" category.  Most of my interviews still took about twenty minutes, because tough questions take some time to answer and evaluate.  But it was a big improvement over the rapport-building method; and it could be done over the phone.
<p>
After reading your article, I started doing code interviews over the phone, using web meetings. My interview times were down to about 15 minutes each to identify people who just can't code— the vast majority.
</p>
</blockquote>
<p>
I wrote that article in 2007, and I am stunned, but not entirely surprised, to hear that  three years later "the vast majority" of so-called programmers who apply for a programming job interview are unable to write the smallest of programs. To be clear, hard is a relative term -- we're not talking about complicated, Google-style graduate computer science interview problems. This is <a href="http://www.codinghorror.com/blog/2007/02/why-cant-programmers-program.html">extremely simple stuff</a> we're asking candidates to do. And they can't. <b>It's the equivalent of attempting to hire a truck driver and finding out that 90 percent of the job applicants can't find the gas pedal or the gear shift.</b>
</p>
<p>
I agree, it's insane. But it happens every day, and is (apparently) an epidemic hiring problem in our industry.
</p>
<p>
You have to get to the simple technical interview questions immediately to screen out the legions of non-programming programmers. <a href="http://www.codinghorror.com/blog/2008/01/getting-the-interview-phone-screen-right.html">Screening over the telephone</a> is a wise choice, as I've noted before. But screening over the internet is even better, and arguably more natural for code.
</p>
<p>
</p>
<blockquote>
I still wasn't super-happy with having to start up the web meeting and making these guys share their desktops with me.  I searched for other suitable tools for doing short "pen-and-paper" style coding interviews over the web, but I couldn't find any.  So I did what any self-respecting programmer would do.  <a href="http://i.seemikecode.com/">I wrote one</a>.
<p>
Man, was it worth it! I schedule my initial technical screenings with job applicants in 15-minute blocks. I'm usually done in 5-10 minutes, sadly. <b>I schedule an actual interview with them if they can at least write simple a 10-line program.</b> That doesn't happen often, but at least I don't have to waste a whole lot of time anymore.
</p>
</blockquote>
<p>
Mike adds a disclaimer that his homegrown coding interview tool isn't meant to show off <i>his</i> coding prowess. He needed a tool, so he wrote one -- and thoughtfully shared it with us. There might well be others out there; what online tools do you use to screen programmers?
</p>
<p>
Three years later, I'm still wondering: <b>why do people who can't write a simple program <i>even entertain the idea</i> they can get jobs as working programmers?</b> Clearly, some of them must be succeeding. Which means our industry-wide interviewing standards for programmers are woefully inadequate, and that's a disgrace. It's degrading to every working programmer.
</p>
<p>
At least bad programmers <i>can</i> be educated; non-programming programmers are not only hopeless but also cheapen the careers of everyone around them. They must be eradicated, starting with simple technical programming tests that should be a part of <i>every</i> programmer interview.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-02-22T02:41:13.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-nonprogramming-programmer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Compiled or Bust? ]]></title>
<link>https://blog.codinghorror.com/compiled-or-bust/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
While I may have <a href="http://www.codinghorror.com/blog/2009/06/all-abstractions-are-failed-abstractions.html">mixed emotions toward LINQ to SQL</a>, we've had great success with it on Stack Overflow. That's why I was <a href="http://weblogs.asp.net/omarzabir/archive/2008/10/28/solving-common-problems-with-compiled-queries-in-linq-to-sql-for-high-demand-asp-net-websites.aspx">surprised to read the following</a>:
</p>
<p>
</p>
<blockquote>
If you are building an ASP.NET web application that's going to get thousands of hits per hour, the execution overhead of Linq queries is going to consume too much CPU and make your site slow. Thereâ€™s a runtime cost associated with each and every Linq Query you write. The queries are parsed and converted to a nice SQL Statement on <i>every</i> hit. Itâ€™s not done at compile time because thereâ€™s no way to figure out what you might be sending as the parameters in the queries during runtime.
<p>
So, if you have common Linq to Sql statements like the following one ..
</p>
<p>
</p>
<pre>
var query = from widget in dc.Widgets
where widget.ID == id &amp;&amp; widget.PageID == pageId
select widget;
var widget = query.SingleOrDefault();
</pre>
<p>
..  throughout your growing web application, you are soon going to have scalability nightmares.
</p>
</blockquote>
<p>
J.D. Conley <a href="http://www.jdconley.com/blog/archive/2007/11/28/linq-to-sql-surprise-performance-hit.aspx">goes further</a>:
</p>
<p>
</p>
<blockquote>
So I dug into the call graph a bit and found out the code causing by far the most damage was the creation of the LINQ query object for every call! The actual round trip to the database paled in comparison.
</blockquote>
<p>
I must admit, these results seem ... unbelievable. Querying the database is so slow (relative to typical code execution) that if you have to ask how long it will take, <i>you can't afford it</i>. I have a very hard time accepting the idea that <b>dynamically parsing a Linq query would take longer than round-tripping to the database.</b> Pretend I'm from Missouri: show me. Because I am unconvinced.
</p>
<p>
All of this is very curious, because Stack Overflow uses naive, uncompiled Linq queries on every page, and we are a top 1,000 website on the public internet by most accounts these days. We get a considerable amount of traffic; the last time I checked it was about 1.5 million pageviews per day. We go to great pains to make sure everything is as fast as we can. We're not as fast as we'd like to be yet, but I think we're doing a reasonable job so far. The journey is still very much underway -- we realize that <a href="http://www.codinghorror.com/blog/2009/01/overnight-success-it-takes-years.html">overnight success takes years</a>.
</p>
<p>
Anyway, <b>Stack Overflow has dozens to hundreds of plain vanilla uncompiled Linq to SQL queries on every page</b>. What we <i>don't</i> have is "scalability nightmares". CPU usage has been one of our least relevant constraints over the last two years as the site has grown. We've also heard from other development teams, multiple times, that Linq to SQL is "slow". But we've never been able to reproduce this even when armed with a profiler.
</p>
<p>
Quite the mystery.
</p>
<p>
Now, it's absolutely true that Linq to SQL has the performance peculiarity both posters are describing. We know that's true because <a href="http://blogs.msdn.com/ricom/archive/2008/01/14/performance-quiz-13-linq-to-sql-compiled-query-cost-solution.aspx">Rico tells us so</a>, and Rico ... well, Rico's <i>the man</i>.
</p>
<p>
</p>
<blockquote>
In short the problem is that <b>the basic Linq construction (we donâ€™t really have to reach for a complex query to illustrate) results in repeated evaluations of the query if you ran the query more than once.</b>
<p>
Each execution builds the expression tree, and then builds the required SQL. In many cases all that will be different from one invocation to another is a single integer filtering parameter. Furthermore, any databinding code that we must emit via lightweight reflection will have to be jitted each time the query runs. Implicit caching of these objects seems problematic because we could never know what good policy is for such a cache -- only the user has the necessary knowledge.
</p>
</blockquote>
<p>
It's fascinating stuff; you should <a href="http://blogs.msdn.com/ricom/archive/2007/06/22/dlinq-linq-to-sql-performance-part-1.aspx">read the whole series</a>.
</p>
<p>
What's unfortunate about Linq in this scenario is that you're intentionally sacrificing something that any <a href="http://www.yafla.com/dforbes/Getting_Real_about_NoSQL_and_the_SQL_Isnt_Scalable_Lie/">old and busted SQL database</a> gives you for free. When you send a garden variety parameterized SQL query through to a traditional SQL database, it's hashed, then matched against existing cached query plans. The computational cost of pre-processing a given query is only paid the first time the database sees the new query. All subsequent runs of that same query use the cached query plan and skip the query evaluation. Not so in Linq to SQL. As Rico said, <b>every single run of the Linq query is fully parsed every time it happens</b>.
</p>
<p>
Now, there <i>is</i> a way to compile your Linq queries, but I personally find the syntax kind of ... ugly and contorted. You tell me:
</p>
<p>
</p>
<pre>
Func&lt;Northwinds, IQueryable&lt;Orders&gt;, int&gt; q =
CompiledQuery.Compile&lt;Northwinds, int, IQueryable&lt;Orders&gt;&gt;
((Northwinds nw, int orderid) =&gt;
from o in nw.Orders
where o.OrderId == orderid
select o );
Northwinds nw = new Northwinds(conn);
foreach (Orders o in q(nw, orderid))
{
}
</pre>
<p>
Anyway, that's neither here nor there; we can confirm the performance penalty of failing to compile our queries ourselves. We recently wrote a one time conversion job against a simple 3 column table containing about 500,000 records. The meat of it looked like this:
</p>
<p>
</p>
<pre>
db.PostTags.Where(t =&gt; t.PostId == this.Id).ToList();
</pre>
<p>
Then we compared it with the SQL variant; note that this is also being auto-cast down to the handy <code>PostTag</code> object as well, so the only difference is whether or not the query itself is SQL.
</p>
<p>
</p>
<pre>
db.ExecuteQuery<posttag>(
"select * from PostTags where PostId={0}", this.Id).ToList();
</posttag></pre>
<p>
On an Intel Core 2 Quad running at 2.83 GHz, the former took <b>422 seconds</b> while the latter took <b>275 seconds</b>.
</p>
<p>
The penalty for failing to compile this query, across 500k iterations, was 147 seconds. Wow! That's 1.5 times slower! Man, only a <i>BASIC programmer</i> would be dumb enough to skip compiling all their Linq queries. But wait a second, no, wait 147 seconds. Let's do the math, even though I suck at it. Each uncompiled run of the query took less than <b><i>one third of a millisecond</i></b> longer.
</p>
<p>
At first I was worried that every Stack Overflow page was 1.5 times slower than it should be. But then I realized it's probably more realistic to make sure that any page we generate isn't doing <b>500 freakin' thousand queries!</b>  Have we found ourselves in <a href="http://www.codinghorror.com/blog/2009/01/the-sad-tragedy-of-micro-optimization-theater.html">the sad tragedy of micro-optimization theater</a> ... again? I think we might have. Now I'm just depressed.
</p>
<p>
While it's arguably correct to say that every compiled Linq query (or for that matter, any compiled anything) will be faster, your decisions should be a bit more nuanced than <b>compiled or bust</b>. How much benefit you get out of compilation depends how many times you're doing it. Rico would be the first to point this out, and in fact <a href="http://blogs.msdn.com/ricom/archive/2008/01/14/performance-quiz-13-linq-to-sql-compiled-query-cost-solution.aspx">he already has</a>:
</p>
<p>
</p>
<pre>
Testing 1 batches of 5000 selects
<p>
uncompiled  543.48 selects/sec
compiled    925.75 selects/sec
</p><p>
Testing 5000 batches of 1 selects
</p><p>
uncompiled  546.03 selects/sec
compiled    461.89 selects/sec
</p></pre>
<p>
Have I mentioned that Rico is the man? Do you see the inversion here? Either you're doing 1 batch of 5000 queries, or 5000 batches of 1 query. One is dramatically faster when compiled; the other is actually a big honking net negative if you consider the developer time spent converting all those beautifully, wonderfully simple Linq queries to the contorted syntax necessary for compilation. Not to mention the implied code maintenance.
</p>
<p>
I'm a big fan of compiled languages. Even Facebook will tell you that <a href="http://developers.facebook.com/news.php?story=358&amp;blog=1">PHP is about as half as fast as it should be</a> on a good day with a tailwind. But compilation alone is not the entire performance story. Not even close. If you're compiling something -- whether it's PHP, a regular expression, or a Linq query, don't expect <a href="http://en.wikipedia.org/wiki/No_Silver_Bullet">a silver bullet</a>, or you may end up disappointed.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-03-19T04:56:46.000Z</pubDate>
<guid>https://blog.codinghorror.com/compiled-or-bust/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Opposite of Fitts' Law ]]></title>
<link>https://blog.codinghorror.com/the-opposite-of-fitts-law/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>If you've ever wrangled a user interface, you've probably heard of <a href="http://www.codinghorror.com/blog/2006/08/fitts-law-and-infinite-width.html">Fitts' Law</a>. It's pretty simple – <b>the larger an item is, and the closer it is to your cursor, the easier it is to click on</b>. Kevin Hale put together <a href="http://particletree.com/features/visualizing-fittss-law/">a great visual summary of Fitts' Law</a>, so rather than over-explain it, I'll refer you there.</p>
<p>The short version of Fitts' law, to save you all that tedious <i>reading</i>, is this:</p>
<ul>
<li>Put commonly accessed UI elements on the edges of the screen. Because the cursor automatically stops at the edges, they will be easier to click on.
</li>
<li>Make clickable areas as large as you can. Larger targets are easier to click on.
</li>
</ul>
<p>I know, it's very simple, almost too simple, but humor me by following along with some thought exercises. Imagine yourself trying to click on ...</p>
<ul>
<li>a 1 x 1 target at a random location
</li>
<li>a 5 x 5 target at a random location
</li>
<li>a 50 x 50 target at a random location
</li>
<li>a 5 x 5 target in the corner of your screen
</li>
<li>a 1 x 100 target at the bottom of your screen
</li>
</ul>
<p>Fitts' Law is mostly common sense, and enjoys enough currency with UI designers that they're likely to know about it even if <a href="http://yokozar.org/blog/archives/194">they don't follow it as religiously as they should</a>. Unfortunately, I've found that designers are much less likely to consider the <i>opposite</i> of Fitts' Law, which is arguably just as important.</p>
<p>If we should make UI elements we <i>want</i> users to click on large, and ideally place them at corners or edges for maximum clickability – <b>what should we do with UI elements we <i>don't</i> want users to click on?</b> Like, say, the "delete all my work" button?</p>
<p>Alan Cooper, in <a href="http://www.codinghorror.com/blog/2007/06/the-three-faces-of-about-face.html">About Face 3</a>, calls this the ejector seat lever.</p>
<blockquote>
<p>In the cockpit of every jet fighter is a brightly painted lever that, when pulled, fires a small rocket engine underneath the pilot's seat, blowing the pilot, still in his seat,<br>
out of the aircraft to parachute safely to earth. Ejector seat levers can only be used<br>
once, and their consequences are significant and irreversible.</p>
<p>Applications must have ejector seat levers so that users can "occasionally" move<br>
persistent objects in the interface, or dramatically (sometimes irreversibly) alter the function or behavior of the application. The one thing that must never happen is accidental deployment of the ejector seat.</p>
<img alt="image placeholder" >
<p>The interface design must assure that a user can never inadvertently fire the ejector seat when all he wants to do is make some minor adjustment to the program.</p>
</blockquote>
<p>I can think of a half-dozen applications I regularly use where <b>the ejector seat button is inexplicably placed right next to the cabin lights button</b>. Let's take a look at our old friend GMail, for example:</p>
<img alt="image placeholder" >
<p>I can tell what you're thinking. Did he click <b>Send</b> or <b>Save Now</b>? Well, to tell you the truth, in all the excitement of composing that angry email, I kind of lost track myself. Good thing we can easily undo a sent mail! Oh wait, we <i>totally can't</i>. Consider my seat, or at least that particular rash email, ejected.</p>
<p>It's even worse when I'm archiving emails.</p>
<img alt="image placeholder" >
<p>While there were at least 10 pixels between the buttons in the previous example, here there are all of ... <i>three</i>. Every few days I accidentally click <b>Report Spam</b> when I really meant to click <b>Archive</b>. Now, to Google's credit, they do offer a simple, obvious undo path for these accidental clicks. But I can't help wondering why it is, exactly, that these two buttons with such radically different functionality just <i>have</i> to be right next to each other.</p>
<p>Undo is powerful stuff, but wouldn't it be better still if I wasn't pulling the darn ejector seat lever all the time? Wouldn't it make more sense to put that risky ejector seat lever in a different location, and make it smaller? Consider the WordPress post editor.</p>
<img alt="image placeholder" >
<p>Here, the common <b>Update</b> operation is large and obviously a button – it's easy to see and easy to click on. The less common <b>Move to Trash</b> operation is smaller, presented as a vanilla hyperlink, and placed well away from Update.</p>
<p>The next time you're constructing a user interface, you should absolutely follow Fitts' law. It just makes sense. But don't forget to follow the opposite of Fitts' law, too – uncommon or dangerous UI items should be <i>difficult</i> to click on!</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-03-24T04:11:18.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-opposite-of-fitts-law/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Usability On The Cheap and Easy ]]></title>
<link>https://blog.codinghorror.com/usability-on-the-cheap-and-easy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Writing code? That's the easy part. Getting your application <a href="http://blog.codinghorror.com/shipping-isnt-enough/">in the hands of users</a>, and creating applications that <a href="http://blog.codinghorror.com/youll-never-have-enough-cheese/">people actually want to use</a> — now that's the hard stuff.</p>
<p>I've been a long time fan of Krug's book <a href="http://www.amazon.com/exec/obidos/ASIN/0321965515/codihorr-20">Don't Make Me Think</a>. Not just because it's a quick, easy read (and it is!) but because it's the most concise and most approachable book I've ever found to teach the fundamental importance of usability. As far as I'm concerned, if you want to help us make the software industry a saner place, the first step is getting <a href="http://www.amazon.com/exec/obidos/ASIN/0321965515/codihorr-20">Don't Make Me Think</a> in the hands of as many of your coworkers as you can. <b>If you don't have people that care about usability on your project, your project is doomed</b>.</p>
<p>Beyond getting people over the hurdle of at least <i>paging through</i> the Krug book, and perhaps begrudgingly conceding that this usability stuff <i>matters</i>, the next challenge is figuring out how to integrate usability testing into your project. It's easy to parrot "Usability is Important!", but you have to walk the walk, too. I touched on some low friction ways to get started in <a href="http://blog.codinghorror.com/low-fi-usability-testing/">Low-Fi Usability Testing</a>. That rough outline is now available in handy, more complete book form as <a href="http://www.amazon.com/dp/0321657292/?tag=codihorr-20">Rocket Surgery Made Easy: The Do-It-Yourself Guide to Finding and Fixing Usability Problems</a>.</p>
<p><a href="http://www.amazon.com/dp/0321657292/?tag=codihorr-20"><img alt="image placeholder" >
<p>Don't worry, Krug's book is just as usable as his advice. It's yet another quick, easy read. Take it from the man himself:</p>
<ul>
<li>
<b>Usability testing is one of the best things people can do to improve Web sites (or almost anything they're creating that people have to interact with)</b>.</li>
<li>Since most organizations can't afford to hire someone to do testing for them<br>
on a regular basis, everyone should learn to do it themselves. And …</li>
<li>I could probably write a pretty good book explaining how to do it.</li>
</ul>
<p>If you're wondering what the beginner's "how do I boil water?" recipe for software project usability is, stop reading this post and get a copy of <a href="http://www.amazon.com/dp/0321657292/?tag=codihorr-20">Rocket Surgery Made Easy</a>. Now.</p>
<p>One of the holy grails of usability testing is <a href="http://www.useit.com/eyetracking/">eyetracking</a> – measuring where people's eyes look as they use software and web pages. Yes, there are clever JavaScript tools that can measure where users move their <i>pointers</i>, but that's only a small part of the story. Where the eye wanders, the pointer may not, and vice-versa. But, who has the time and equipment necessary to conduct an actual eyetracking study? Almost nobody.</p>
<p>That's where <a href="http://www.amazon.com/dp/0321498364/?tag=codihorr-20">Eyetracking Web Usability</a> comes in.</p>
<p><a href="http://www.amazon.com/dp/0321498364/?tag=codihorr-20"><img alt="image placeholder" >
<p>Eyetracking Web Usability is chock full of incredibly detailed eyetracking data for dozens of websites. Even though you (probably) can't afford to do real eyetracking, you can certainly use this book as a reference. There is enough variety in UI and data that you can map the results, observations, and explanations found here to what <i>your</i> project is doing.</p>
<p>This particular book is rather eyetracking specific, but it's just the latest entry in <a href="http://blog.codinghorror.com/usability-is-timeless/">a whole series on usability</a>, and I recommend them all highly. These books are a fount of worthwhile data for anyone who works on software and cares about usability, from one of the most preeminent usability experts on the web.</p>
<p>Usability isn't really cheap or easy. It's an endless war, with innumerable battlegrounds, stretching all the way back to the dawn of computing. But these books, at least, are cheap and easy in the sense that they give you some <b>basic training in <i>fighting the good (usability) fight</i></b>. That's the best I can do, and it's all I'd ask from anyone else I work with.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-03-31T22:59:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/usability-on-the-cheap-and-easy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Three Monitors For Every User ]]></title>
<link>https://blog.codinghorror.com/three-monitors-for-every-user/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As far as I'm concerned, you can never be too rich, too thin, or have too much screen space. By "screen", I mean not just large monitors, but <i>multiple</i> large monitors. I've been evangelizing multiple monitors since the dark days of <a href="http://en.wikipedia.org/wiki/Windows_Me">Windows Millennium Edition</a>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/archives/000012.html">Multiple Monitors and Productivity</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000217.html">Multiple LCDs</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000740.html">Joining the Prestigious Three Monitor Club</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000928.html">The Large Display Paradox</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000959.html">LCD Monitor Arms</a>
</li>
</ul>
<p>
If you're a long time reader you're probably sick of hearing about this stuff by now, but something rather wonderful has happened since I last wrote about it:
</p>
<p>
</p>
<blockquote>
If you're only using one monitor, you are cheating yourself out of potential productivity. Two monitors is a no-brainer. It's so fundamental that I included it as a part of the <a href="http://www.codinghorror.com/blog/2006/08/the-programmers-bill-of-rights.html">Programmer's Bill of Rights</a>.
<p>
But you can do better.
</p>
<p>
<b>As good as two monitors is, three monitors is even better</b>. With three monitors, there's a "center" to focus on. And 50% more display area. While there's certainly a point of diminishing returns for additional monitors, I think three is the sweet spot. Even Edward Tufte, in the <a href="http://www.codinghorror.com/blog/archives/000739.html">class I recently attended</a>, explicitly mentioned multiple monitors. I don't care how large a single display can be; you can never have enough desktop space.
</p>
<p>
Normally, to achieve three monitors, you have to either:
</p>
<p>
</p>
<ol>
<li>Buy an exotic video card that has more than 2 monitor connections.
</li>
<li>Install a second video card.
</li>
</ol>
</blockquote>
<p>
Fortunately, that is no longer true. I was excited to learn that the latest ATI video cards have gone from two to three video outputs. Which means <b>you can now achieve triple monitors with a single video card upgrade!</b>  They call this <a href="http://sites.amd.com/us/underground/products/eyefinity/Pages/eyefinity.aspx">"eyefinity"</a>, but it's really just shorthand for "raising the standard from two display outputs to three".
</p>
<p>
But, there is a (small) catch. The PC ecosystem is in the middle of shifting display output standards. For evidence of this, you need look no further than the back panel of one of these newfangled triple display capable ATI video cards:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It contains:
</p>
<p>
</p>
<ul>
<li>two DVI outputs
</li>
<li>one HDMI output
</li>
<li>one <a href="http://en.wikipedia.org/wiki/DisplayPort">DisplayPort</a> output
</li>
</ul>
<p>
I suspect part of this odd connector layout is due to space restrictions (DVI is awfully chunky), but I've always understood DisplayPort to be the new, improved DVI connector for computer monitors, and HDMI to be the new, improved s-video/component connector for televisions. Of course these worlds are blurring, as <a href="http://www.codinghorror.com/blog/2006/12/will-your-next-computer-monitor-be-a-hdtv.html">modern high-definition TVs make surprisingly effective computer monitors</a>, too.
</p>
<p>
Anyway, since all my monitors have only DVI inputs, I wasn't sure what to do with the other output. So <a href="http://superuser.com/questions/118957/converting-displayport-and-or-hdmi-to-dvi-d">I asked on Super User</a>. The helpful answers led me to discover that, as I suspected, the third output has to be DisplayPort. So to connect my third monitor, I needed to <b>convert DisplayPort to DVI</b>, and there are two ways:
</p>
<p>
</p>
<ol>
<li>a <a href="http://www.amazon.com/dp/B0007MWE1Y/?tag=codihorr-20">passive, analog DisplayPort to DVI conversion cable</a> for ~$30 that supports up to 1920x1200
</li>
<li>an <a href="http://www.amazon.com/dp/B002ISVI3U/?tag=codihorr-20">active, digital DisplayPort to DVI converter</a> for $110 that supports all resolutions
</li>
</ol>
<p>
I ended up going with the active converter, which has mixed reviews, but it's worked well for me over the last few weeks.
</p>
<p>
<a href="http://www.amazon.com/dp/B002ISVI3U/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
Note that this adapter requires USB power, and given the spotty results others have had with it, some theorize that it needs quite a bit of juice to work reliably. I plugged it into my system's nearby rear USB ports which do tend to deliver more power (they're closer to the power supply, and have short cable paths). Now, I <i>have</i> gotten the occasional very momentary black screen with it, but nothing severe enough to be a problem or frequent enough to become a pattern. If you have DisplayPort compatible monitors, of course, this whole conversion conundrum is a complete non-issue. But DisplayPort is fairly new, and even my new-ish LCD monitors don't support it yet.
</p>
<p>
The cool thing about this upgrade, besides <a href="http://www.codinghorror.com/blog/2008/11/feeding-my-graphics-card-addiction.html">feeding my video card addiction</a>, is that <b>I was able to simplify my hardware configuration</b>. That's always good. I went from two video cards to one, which means less power consumption, simpler system configuration, and fewer overall driver oddities. Basically, it makes triple monitors -- dare I say it -- almost a <i>mainstream</i> desktop configuration. How could I not be excited about that?
</p>
<p>
I was also hoping that Nvidia would follow ATI's lead here and <b>make three display outputs the standard for all their new video cards</b>, too, but sadly that's not the case. It turns out their new GTX 480 fails in other ways, in that <a href="http://www.maximumpc.com/article/features/nvidias_hot_rod_gtx_480_powerful_and_power_hungry?page=0,1">it's basically the Pentium 4 of video cards</a> -- generating ridiculous amounts of heat for very little performance gain. Based on those two facts, I am comfortable endorsing ATI wholeheartedly at this point. But, do be careful, because not all ATI cards support triple display outputs (aka "eyefinity"). These are the ones that I know do:
</p>
<p>
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.amazon.com/dp/B0033WSDO2/?tag=codihorr-20">Radeon HD 5670</a> (~$100)
</li>
<li>
<a href="http://www.amazon.com/dp/B002SP113K/?tag=codihorr-20">Radeon HD 5770</a> (~$150)
</li>
<li>
<a href="http://www.amazon.com/dp/B0039YOMZI/?tag=codihorr-20">Radeon HD 5830</a> (~$250)
</li>
<li>
<a href="http://www.amazon.com/dp/B002QEBGGA/?tag=codihorr-20">Radeon HD 5850</a> (~$320)
</li>
<li>
<a href="http://www.amazon.com/dp/B003D0QQJS/?tag=codihorr-20">Radeon HD 5870</a> (~$450)
</li>
</ul>
<p>
Unless you're a gamer, there's no reason to care about anything other than the least expensive model here, which will handily <i>crush</i> any 2D or 3D desktop GUI acceleration needs you might have. As an addict, of course I bought the high end model and it absolutely did not disappoint -- more than doubling my framerates in the excellent game <a href="http://www.amazon.com/dp/B002NIP2SM/?tag=codihorr-20">Battlefield: Bad Company 2</a> over the GTX 280 I had <a href="http://www.codinghorror.com/blog/2008/11/feeding-my-graphics-card-addiction.html">before</a>.
</p>
<p>
I'm excited that a triple monitor setup is now, thanks to ATI, so easily attainable for desktop users -- as long as you're aware of the DisplayPort caveat I discussed above. I'd encourage anyone who is even <i>remotely</i> interested in the (many) productivity benefits of a triple monitor setup to seriously consider an ATI video card upgrade.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-04-04T22:10:08.000Z</pubDate>
<guid>https://blog.codinghorror.com/three-monitors-for-every-user/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ So You'd Like to Send Some Email (Through Code) ]]></title>
<link>https://blog.codinghorror.com/so-youd-like-to-send-some-email-through-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I have what I would charitably describe as a <a href="http://www.google.com/search?q=site:codinghorror.com+email">hate-hate</a> relationship with email. I desperately try to avoid sending email, not just for myself, but also in the code I write.</p>
<p>Despite my misgivings, <b>email is the cockroach of communication mediums: <i>you just can't kill it</i></b>. Email is the one method of online contact that almost everyone -- at least for that subset of "everyone" which includes people who can bear to touch a computer at all -- is guaranteed to have, and use. Yes, you can make a fairly compelling case that email is <a href="http://www.techdirt.com/articles/20071114/144228.shtml">for old stupid people</a>, but let's table that discussion for now.</p>
<p>So, reluctantly, we come to the issue of <b>sending email through code</b>. It's easy! Let's send some email through oh, I don't know, let's say ... Ruby, courtesy of some sample code I found while <a href="http://stackoverflow.com/questions/tagged/ruby">browsing the Ruby tag</a> on Stack Overflow.</p>
<pre>
require 'net/smtp'

def send_email(to, subject = "", body = "")
    from = "my@email.com"
    body= "From: #{from}\r\nTo: #{to}\r\nSubject: #{subject}\r\n\r\n#{body}\r\n"

    Net::SMTP.start('192.168.10.213', 25, '192.168.0.218') do |smtp|
        smtp.send_message body, from, to
    end
end

send_email "my@email.com", "test", "blah blah blah"
</pre>
<p>There's a bug in this code, though. Do you see it?</p>
<p><b>Just because you <i>send</i> an email doesn't mean it will arrive.</b> Not by a long shot. Bear in mind this is <i>email</i> we're talking about. It was never designed to survive a bitter onslaught of criminals and spam, not to mention the explosive, exponential growth it has seen over the last twenty years. Email is a well that has been truly and thoroughly poisoned -- the digital equivalent of a superfund cleanup site. The ecosystem around email is a dank miasma of half-implemented, incompletely supported anti-spam hacks and workarounds.</p>
<p>Which means the odds of that random email your code just sent getting to its specific destination is .. spotty. At best.</p>
<p>If you want email your code sends to actually <i>arrive</i> in someone's AOL mailbox, to <a href="http://www.fastcompany.com/magazine/18/voice.html">the dulcet tones of "You've Got Mail!"</a>, there are a few things you must do first. And most of them are only peripherally related to writing code.</p>
<p><b>1. Make sure the computer sending the email has a Reverse PTR record</b></p>
<p>What's a <a href="http://aplawrence.com/Blog/B961.html">reverse PTR record</a>? It's something your ISP has to configure for you -- a way of verifying that the email you send from a particular IP address actually belongs to the domain it is purportedly from.</p>
<blockquote>
Not every IP address has a corresponding PTR record. In fact, if you took a random sampling of addresses your firewall blocked because they were up to no good, you'd probably find most have no PTR record - a dig -x gets you no information. That's also apt to be true for mail spammers, or their PTR doesn't match up: if you do a dig -x on their IP you get a result, but if you look up that result you might not get the same IP you started with.
<p>That's why PTR records have become important. Originally, PTR records were just intended as a convenience, and perhaps as a way to be neat and complete. There still are no requirements that you have a PTR record or that it be accurate, but because of the abuse of the internet by spammers, certain conventions have grown up. For example, you may not be able to send email to some sites if you don't have a valid PTR record, or if your pointer is "generic".</p>
<p>How do you get a PTR record? You might think that this is done by your domain registrar - after all, they point your domain to an IP address. Or you might think whoever handles your DNS would do this. But the PTR record isn't up to them, it's up to the ISP that "owns" the IP block it came from. They are the ones who need to create the PTR record.</p>
</blockquote>
<p>A reverse PTR record is critical. How critical? <font color="red">Don't even bother reading any further until you've verified that your ISP has correctly configured the reverse PTR record for the server that will be sending email</font>. It is absolutely the most common check done by mail servers these days. Fail the reverse PTR check, and I guarantee that a <i>huge</i> percentage of the emails you send will end up in the great bit bucket in the sky -- and not in the email inboxes you intended.</p>
<p><b>2. Configure DomainKeys Identified Mail in your DNS and code</b></p>
<p>What's <a href="http://en.wikipedia.org/wiki/DKIM">DomainKeys Identified Mail</a>? With DKIM, you "sign" every email you send with your private key, a key only <i>you</i> could possibly know. And this can be verified by attempting to decrypt the email using the public key stored in your public DNS records. It's really quite clever!</p>
<p>The first thing you need to do is generate some public-private key pairs (one for every domain you want to send email from) via OpenSSL. I used <a href="http://www.slproweb.com/products/Win32OpenSSL.html">a win32 version I found</a>. Issue these commands to produce the keys in the below files:</p>
<pre><code>$ openssl genrsa -out rsa.private 1024
$ openssl rsa -in rsa.private -out rsa.public -pubout -outform PEM
</code></pre>
<p>These public and private keys are just big ol' Base64 encoded strings, so plop them in your code as configuration string resources that you can retrieve later.</p>
<p>Next, add some DNS records. You'll need two new TXT records.</p>
<ol>
<li>
<font color="red">_domainkey</font>.example.com<br>
"o=~; r=contact@example.com"
</li>
<li>
<font color="red">selector._domainkey</font>.example.com<br>
"k=rsa; p={public-key-base64-string-here}"
</li>
</ol>
<p>The first TXT DNS record is the global DomainKeys policy and contact email.</p>
<p>The second TXT DNS record is the public base64 key you generated earlier, as one giant unbroken string. Note that the "selector" part of this record can be anything you want; it's basically just a disambiguating string.</p>
<p>Almost done. One last thing -- we need to sign our emails before sending them. In any rational world this would be handled by an email library of some kind. We use <a href="http://www.afterlogic.com/products/net-email-components">Mailbee.NET</a> which makes this fairly painless:</p>
<pre>
smtp.Message = dk.Sign(smtp.Message,
null, <font color="red">AppSettings.Email.DomainKeyPrivate</font>, false, "selector");
</pre>
<p><b>3. Set up a SPF / SenderID record in your DNS</b></p>
<p>To be honest, <a href="http://en.wikipedia.org/wiki/Sender_ID">SenderID</a> is a bit of a "nice to have" compared to the above two. But if you've gone this far, you might as well go the distance. SenderID, while a little antiquated and kind of.. Microsoft/Hotmail centric.. doesn't take much additional effort.</p>
<p>SenderID isn't complicated. It's another TXT DNS record at the root of, say, example.com, which contains a specially formatted string documenting all the allowed IP addresses that mail can be expected to come from. Here's an example:</p>
<pre>
"v=spf1 a mx ip4:10.0.0.1 ip4:10.0.0.2 ~all"
</pre>
<p>You can use the <a href="http://www.microsoft.com/mscorp/safety/content/technologies/senderid/wizard/">Sender ID SPF Record Wizard</a> to generate one of these for each domain you send email from.</p>
<p><b>That sucked. How do I know all this junk is working?</b></p>
<p>I agree, it sucked. Email sucks; what did you expect? I used two methods to verify that all the above was working:</p>
<ol>
<li>Test emails sent to a GMail account.<br><br>
Use the "show original" menu on the arriving email to see the raw message content as seen by the email server. You want to verify that the headers definitely contain the following:
<pre>Received-SPF: pass
Authentication-Results: ... spf=pass ... dkim=pass</pre>
<p>If you see that, then the Reverse PTR and DKIM signing you set up is working. Google provides <i>excellent</i> diagnostic feedback in their email server headers, so if something isn't working, you can usually discover enough of a hint there to figure out why.<br><br></p>
</li>
<li>Test emails sent to the Port25 email verifier<br><br>
Port25 offers a really nifty public service -- you can send email to check-auth@verifier.port25.com and it will reply to the from: address with an extensive diagnostic! Here's an example summary result from a test email I just sent to it:
<pre>
SPF check:          pass
DomainKeys check:   fail
DKIM check:         pass
Sender-ID check:    pass
SpamAssassin check: ham
</pre>
<p>You want to pass SPF, DKIM, and Sender-ID. Don't worry about the DomainKeys failure, as I believe it is spurious -- DKIM is the "newer" version of that same protocol.</p>
</li>
</ol>
<p>Yes, the above three steps are quite a bit of work just to send a lousy email. But I don't send email lightly. By the time I've reached the point where I am forced to write code to send out email, <b>I really, <i>really</i> want those damn emails to arrive</b>. By any means necessary.</p>
<p>And for those who are the unfortunate recipients of these emails: my condolences.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-04-21T02:37:36.000Z</pubDate>
<guid>https://blog.codinghorror.com/so-youd-like-to-send-some-email-through-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's Wrong With CSS ]]></title>
<link>https://blog.codinghorror.com/whats-wrong-with-css/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We're currently in the midst of a <a href="http://www.codinghorror.com/blog/2005/12/the-css-zen-garden-and-aspnet.html">CSS Zen Garden type excerise</a> on our family of Q&amp;A websites, which I affectionately refer to as <a href="http://blog.stackoverflow.com/2009/05/the-stack-overflow-trilogy/">"the Trilogy"</a>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://serverfault.com">Server Fault</a>
</li>
<li>
<a href="http://superuser.com">Super User</a>
</li>
<li>
<a href="http://stackoverflow.com">Stack Overflow</a>
</li>
<li>
<a href="http://meta.stackoverflow.com">Meta Stack Overflow</a>
</li>
</ul>
<p>
(In case you were wondering, yes, meta <i>is</i> the <a href="http://en.wikipedia.org/wiki/The_Star_Wars_Holiday_Special">Star Wars Holiday Special</a>.)
</p>
<p>
These sites all run the same core engine, but the logo, domain, and CSS "skin" that lies over the HTML skeleton is different in each case:
</p>
<p>
</p>
<table>
<tr>
<td>
<a href="http://serverfault.com"><img alt="image placeholder" >
</td>
<td>
<a href="http://superuser.com"><img alt="image placeholder" >
</td>
</tr>
<tr>
<td>
<a href="http://meta.stackoverflow.com"><img alt="image placeholder" >
</td>
<td>
<a href="http://stackoverflow.com"><img alt="image placeholder" >
</a>
</td>
</tr>
</table>
<p>
They are not <i>terribly</i> different looking, it's true, but we also want them to be recognizable as a family of sites.
</p>
<p>
We're working with two amazing designers, <a href="http://www.8164.org/">Jin Yang</a> and <a href="http://uxhero.com/">Nathan Bowers</a>, who are helping us whip the CSS and HTML into shape so they can produce a set of about 10 different Zen Garden designs. As new sites in our network <a href="http://blog.stackexchange.com/post/518474918/stack-exchange-2-0">get democracied into being</a>, these designs will be used as a palette for the community to choose from. (And, later, the community will decide on a domain name and logo as well.)
</p>
<p>
Anyway, I bring this up not because <i><a href="http://www.google.com/images?q=my+pokemans+let+me+show+you">my pokemans, let me show you them</a></i>, but because I have to personally maintain four different CSS files. And that number is only going to get larger. <i>Much</i> larger. That scares me a little.
</p>
<p>
Most of all, what I've learned from this exercise in site theming is that <b>CSS is kind of painful</b>. I fully support CSS as a (mostly) functional <a href="http://www.codinghorror.com/blog/2008/05/understanding-model-view-controller.html">user interface Model-View-Controller</a>. But even if you have extreme HTML hygiene and Austrian levels of discipline, CSS has some <a href="http://en.wikipedia.org/wiki/Cascading_Style_Sheets#Limitations">serious limitations</a> in practice.
</p>
<p>
Things in particular that bite us a lot:
</p>
<p>
</p>
<ul>
<li>Vertical alignment is a giant, hacky PITA. (Tables work great for this though!)
</li>
<li>Lack of variables so we have to repeat colors all over the place.
</li>
<li>Lack of nesting so we have to repeat huge blocks of CSS all over the place.
</li>
</ul>
<p>
In short, CSS violates the living crap out of <a href="http://www.codinghorror.com/blog/2007/03/curlys-law-do-one-thing.html">the DRY principle</a>. You are <i>constantly</i> and <i>unavoidably</i> repeating yourself.
</p>
<p>
That's why I'm so intrigued by two Ruby gems that attempt to directly address the deficiencies of CSS.
</p>
<p>
1. <b><a href="http://lesscss.org/">Less CSS</a></b>
</p>
<p>
</p>
<table width="700">
<tr>
<td valign="top">
<pre>
/* CSS */
#header {
-moz-border-radius: 5;
-webkit-border-radius: 5;
border-radius: 5;
}
#footer {
-moz-border-radius: 10;
-webkit-border-radius: 10;
border-radius: 10;
}
</pre>
</td>
<td valign="top">
<pre>
// LessCSS
.rounded_corners (@radius: 5px) {
-moz-border-radius: @radius;
-webkit-border-radius: @radius;
border-radius: @radius;
}
#header {
.rounded_corners;
}
#footer {
.rounded_corners(10px);
}
</pre>
</td>
</tr>
</table>
<p>
2. <b><a href="http://sass-lang.com/">SASS</a></b>
</p>
<p>
</p>
<table width="700">
<tr>
<td valign="top">
<pre>
/* CSS */
.content_navigation {
border-color: #3bbfce;
color: #2aaebd;
}
.border {
padding: 8px;
margin: 8px;
border-color: #3bbfce;
}
</pre>
</td>
<td valign="top">
<pre>
// Sass
!blue = #3bbfce
!margin = 16px
.content_navigation
border-color = !blue
color = !blue - #111
.border
padding = !margin / 2
margin = !margin / 2
border-color = !blue
</pre>
</td>
</tr>
</table>
<p>
As you can see, in both cases we're <b>transmogrifying CSS into a bit more of a programming language</b>, rather than the static set of layout rules it currently exists as. Behind the scenes, we're generating plain vanilla CSS using these little dynamic languages. This could be done at project build time, or even dynamically on every page load if you have a good caching strategy.
</p>
<p>
I'm not sure how many of these improvements <a href="http://www.w3.org/Style/CSS/current-work">CSS3</a> will bring, never mind when the bulk of browsers in the world will support it. But I definitely feel that the core changes identified in both <a href="http://lesscss.org/">Less CSS</a> and <a href="http://sass-lang.com/">SASS</a> address very real pain points in practical CSS use. It's worth checking them out to understand why they exist, what they bring to the table, and how you could possibly adopt some of these strategies in your own CSS and your favorite programming language.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-04-30T06:49:21.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-wrong-with-css/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ On Working Remotely ]]></title>
<link>https://blog.codinghorror.com/on-working-remotely/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>When I first <a href="http://www.codinghorror.com/blog/2008/03/choosing-your-own-adventure.html">chose my own adventure</a>, I didn't know what working remotely from home was going to be like. I had never done it before. As <i>programmers</i> go, I'm fairly social. Which still means I'm a borderline sociopath by normal standards. All the same, I was worried that I'd go stir-crazy with no division between my work life and my home life.</p>
<p>Well, I haven't gone stir-crazy yet. I think. But in building Stack Overflow, I have learned a few things about what it means to work remotely – at least when it comes to programming. Our current team encompasses 5 people, distributed all over the USA, along with the team in NYC.</p>
<img alt="image placeholder" >
<p>My first mistake was <a href="http://www.codinghorror.com/blog/2007/06/in-programming-one-is-the-loneliest-number.html">attempting to program alone</a>. I had weekly calls with my business partner, <a href="http://www.joelonsoftware.com/">Joel Spolsky</a>, which were quite productive in terms of figuring out what it was we were trying to do together – but he wasn't writing code. I was coding alone. Really alone. One guy working all by yourself alone. This didn't work <i>at all</i> for me. I was unmoored, directionless, suffering from analysis paralysis, and barely able to get motivated enough to write even a few lines of code. I rapidly realized that I'd made a huge mistake in not <a href="http://www.codinghorror.com/blog/2009/02/whos-your-coding-buddy.html">having a coding buddy</a> to work with.</p>
<p>That situation <a href="http://www.codinghorror.com/blog/2010/01/cultivate-teams-not-ideas.html">rectified itself soon enough</a>, as I was fortunate enough to find one of my favorite old coding buddies was available. Even though Jarrod was in North Carolina and I was in California, the shared source code was the mutual glue that stuck us together, motivated us, and kept us moving forward. To be fair, we also had the considerable advantage of prior history, because we had worked together at a previous job. But the minimum bar to work remotely is to find <b>someone who loves code as much as you do</b>. It's … enough. Anything else on top of that – old friendships, new friendships, a good working relationship – is icing that makes working together all the sweeter. I eventually expanded the team in the same way by adding another old coding buddy, Geoff, who lives in Oregon. And again by adding Kevin, who I didn't know, but had built amazing stuff for us <i>without even being asked to</i>, from Texas. And again by adding Robert, in Florida, who I also didn't know, but spent so much time on every single part of our sites that I felt he had been running alongside our team the whole way, there all along.</p>
<p>The reason remote development worked for us, in retrospect, wasn't just shared love of code. I picked developers who I knew – I had incontrovertible <i>proof</i> – were amazing programmers. I'm not saying they're perfect, far from it, merely that they were top programmers by any metric you'd care to measure. <i>That's</i> why they were able to work remotely. Newbie programmers, or competent programmers who are phoning it in, are absolutely not going to have the moxie necessary to get things done remotely – at least, not without a pointy haired manager, or grumpy old team lead, breathing down their neck. Don't even <i>think</i> about working remotely with anyone who doesn't freakin' <i>bleed</i> ones and zeros, and has a proven track record of getting things done.</p>
<p>While Joel certainly had a lot of high level input into what Stack Overflow eventually became, I only talked to him once a week, at best (these calls were <a href="http://itc.conversationsnetwork.org/series/stackoverflow.html">the genesis of our weekly podcast series</a>). <b>I had a strong, clear vision of what I wanted Stack Overflow to be, and how I wanted it to work.</b> Whenever there was a question about functionality or implementation, my team was able to rally around me and collectively make decisions we liked, and that I personally felt were in tune with this vision. And if you know me at all, you know <a href="http://www.codinghorror.com/blog/2004/10/just-say-no.html">I'm not shy about saying no</a>, either. We were able to build exactly what we wanted, exactly how we wanted.</p>
<p>Bottom line, we were <a href="http://www.youtube.com/results?search_query=we're+on+a+mission+from+god">on a mission from God</a>. And we still are.</p>
<p>So, there are a few basic ground rules for remote development, at least as I've seen it work:</p>
<ul>
<li>The minimum remote team size is two. Always have a buddy, even if your buddy is on another continent halfway across the world.</li>
<li>Only grizzled veterans who absolutely <i>love</i> to code need apply for remote development positions. Mentoring of newbies or casual programmers simply doesn't work at all remotely.</li>
<li>To be effective, remote teams need full autonomy and a leader (PM, if you will) who has a strong vision <i>and</i> the power to fully execute on that vision.</li>
</ul>
<p>This is all well and good when you have a remote team size of <i>three</i>, as we did for the bulk of Stack Overflow development. And all in the same country. <a href="http://blog.stackoverflow.com/2010/05/announcing-our-series-a/">Now we need to grow the company</a>, and I'd like to grow it in distributed fashion, by hiring other amazing developers from around the world, many of whom I have met through Stack Overflow itself.<br>
<b>But how do you scale remote development?</b> Joel had some deep seated concerns about this, so I tapped one of my heroes, Miguel de Icaza – who I'm proud to note is on <a href="http://stackoverflow.com/about/management#advisors">our all-star board of advisors</a> – and he was generous enough to give us some personal advice based on his experience running the <a href="http://www.mono-project.com/">Mono project</a>, which has dozens of developers distributed all over the world.</p>
<img alt="image placeholder" >
<p>At the risk of summarizing mercilessly (and perhaps too much), I'll boil down Miguel's advice the best I can. There are three tools you'll need in place if you plan to grow a large-ish and still functional remote team:</p>
<ul>
<li>
<p><b>Real time chat</b></p>
<p>When your team member lives in Brazil, you can't exactly walk by his desk to ask him a quick question, or bug him about something in his recent checkin. Nope. You need a way to <i>casually</i> ping your fellow remote team members and get a response back quickly. This should be low friction and available to all remote developers at all times. IM, IRC, some web based tool, laser beams, smoke signals, carrier pigeon, two tin cans and a string: whatever. As long as everyone really <i>uses</i> it. <br></p>
<p>We're currently experimenting with <a href="http://campfirenow.com/">Campfire</a>, but whatever floats your boat and you can get your team to consistently <i>use</i>, will work. Chat is the most essential and omnipresent form of communication you have when working remotely, so you need to make absolutely sure it's functioning before going any further.</p>
</li>
<li>
<p><b>Persistent mailing list</b></p>
<p>Sure, your remote team may know the details of <i>their</i> project, but what about all the other work going on? How do they find out about that stuff or even know it exists in the first place? You need a virtual bulletin board: a place for announcements, weekly team reports, and meeting summaries. This is where a classic old-school mailing list comes in handy.</p>
<p>We're using <a href="http://groups.google.com/">Google Groups</a> and although it's old school in spades, it works plenty well for this. You can get the emails as they arrive, or view the archived list via the web interface. One word of caution, however. Every time you see something arrive in your inbox from the mailing list you better believe, in your heart of hearts, that it contains useful information. The minute the mailing list becomes just another "whenever I have time to read that stuff", noise engine, or distraction from work … you've let someone cry wolf too much, and ruined it. So be very careful. Noisy, argumentative, or useless things posted to the mailing list should be punishable by death. Or noogies.</p>
</li>
<li>
<p><b>Voice and video chat</b><br></p>
<p>As much as I love ASCII, sometimes faceless ASCII characters just aren't enough to capture the full intentions and feelings of the human being behind them. When you find yourself sending kilobytes of ASCII back and forth, and still are unsatisfied that you're <i>communicating</i>, you should instill a reflexive habit of "going voice" on your team.</p>
<p>Never underestimate the power of actually <i>talking</i> to another human being. I know, I know, the whole reason we got into this programming thing was to <i>avoid</i> talking to other people, but bear with me here. You can't be face to face on a remote team without flying 6 plus hours, and who the heck has that kind of time? I've got work I need to get done! Well, the next best thing to hopping on a plane is to fire up <a href="http://www.skype.com/">Skype</a> and have a little voice chat. Easy peasy. All that human nuance which is totally lost in faceless ASCII characters (yes, even with our old pal <a href="http://en.wikipedia.org/wiki/Emoticon"><code>*&lt;:-)</code></a>) will come roaring back if you <i>regularly</i> schedule voice chats. I recommend at least once a week at an absolute minimum; they don't have to be long meetings, but it sure helps in understanding the human being behind all those awesome checkins.</p>
</li>
</ul>
<p>Nobody hates meetings and process claptrap more than I do, but there is a certain amount of process you'll need to keep a bunch of loosely connected remote teams and developers in sync.</p>
<ol>
<li><b>Monday team status reports</b></li>
</ol>
<p>Every Monday, as in <a href="http://www.youtube.com/results?search_query=somebody's+got+a+case+of+the+mondays">somebody's-got-a-case-of-the</a>, each team should produce a brief, summarized rundown of:</p>
<ul>
<li>What we did <u>last week</u>
</li>
<li>What we're planning to do <u>this week</u>
</li>
<li>Anything that is <u>blocking</u> us or we are <u>concerned</u> about</li>
</ul>
<p>This doesn't have to be (and in fact <i>shouldn't</i> be) a long report. The briefer the better, but do try to capture all the useful highlights. Mail this to the mailing list every Monday like clockwork. Now, how many "teams" you have is up to you; I don't think this needs to be done at the individual developer level, but you could.</p>
<ul>
<li>
<p><b>Meeting minutes</b></p>
<p>Any time you conduct what you would consider to be a "meeting" with someone else, <u>take minutes</u>! That is, write down what happened in bullet point form, so those remote team members who couldn't be there can benefit from – or at least hear about – whatever happened.</p>
<p>Again, this doesn't have to be long, and if you find taking meeting minutes onerous then you're probably doing it wrong. A simple bulleted list of sentences should suffice. We don't need to know every little detail, just the big picture stuff: <u>who</u> was there? What <u>topics</u> were discussed? What <u>decisions</u> were made? What are the <u>next steps</u>?</p>
</li>
</ul>
<p>Both of the above should, of course, be mailed out to the mailing list as they are completed so everyone can be notified. You do have a mailing list, right? Of course you do!</p>
<p>If this seems like a lot of jibba-jabba, well, that's because <b>remote development is hard</b>. It takes discipline to make it all work, certainly more discipline than piling a bunch of programmers into the same cubicle farm. But when you imagine what this kind of intellectual work – not just programming, but anything where you're working in mostly thought-stuff – will be like in ten, twenty, even thirty years … don't you think it will look a lot like what happens every day <i>right now</i> on Stack Overflow? That is, a programmer in Brazil helping a programmer in New Jersey solve a problem?</p>
<p>If I have learned anything from Stack Overflow it is that the world of programming is <a href="http://www.codinghorror.com/blog/2009/03/the-ugly-american-programmer.html">truly global</a>. I am honored to meet these brilliant programmers from every corner of the world, even if only in a small way through a website. Nothing is more exciting for me than the prospect of adding international members to the Stack Overflow team. The development of Stack Overflow should be reflective of what Stack Overflow <i>is</i>: an international effort of like-minded – and dare I say <i>totally awesome</i> – programmers. I wish I could hire each and every one of you. OK, maybe I'm a little biased. But to me, that's how awesome the Stack Overflow community is.</p>
<p>I believe <b>remote development represents the future of work</b>. If we have to spend a little time figuring out how this stuff works, and maybe even make some mistakes along the way, it's worth it. As far as I'm concerned, the future is now. Why wait?</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-05-06T05:27:15.000Z</pubDate>
<guid>https://blog.codinghorror.com/on-working-remotely/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Vast and Endless Sea ]]></title>
<link>https://blog.codinghorror.com/the-vast-and-endless-sea/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>After we created Stack Overflow, some people were convinced we had built a marginally better mousetrap for asking and answering questions. The inevitable speculation began: <b>can we use your engine to build a Q&amp;A site about {topic}?</b> Our answer was Stack Exchange. Pay us $129 a month (and up), and you too can create a hosted Q&amp;A community on our engine – for whatever topic you like!</p>
<p>Well, I have a confession to make: my heart was never in Stack Exchange. It was a parallel effort in a parallel universe only tangentially related to my own. There's a whole host of reasons why, but if I had to summarize it in a sentence, I'd say that <b>money is poisonous to communities</b>. That $129/month doesn't sound like much – and it isn't – but the commercial nature of the enterprise permeated and distorted everything from the get-go.</p>
<p>(fortunately, the model is changing with <a href="http://blog.stackoverflow.com/2010/04/changes-to-stack-exchange/">Stack Exchange 2.0</a>, but that's a topic for another blog post.)</p>
<p>Yes, Stack Overflow Internet Services Incorporated©®™ is technically a business, even <a href="http://blog.stackoverflow.com/2010/05/announcing-our-series-a/">a venture capital backed business</a> now – but I didn't co-found it because I wanted to make money. I co-founded it because <b>I wanted to build something cool that made the internet better</b>. Yes, selfishly for myself, of course, but also in conjunction with all of my fellow programmers, because I know <a href="http://www.codinghorror.com/blog/2008/09/stack-overflow-none-of-us-is-as-dumb-as-all-of-us.html">none of us is as dumb as all of us</a>.</p>
<p>Nobody is participating in Stack Overflow to <i>make money</i>. We're participating in Stack Overflow because …</p>
<ul>
<li>We love programming
</li>
<li>We want to leave breadcrumb trails for other programmers to follow so they can avoid making the same dumb mistakes we did
</li>
<li>Teaching peers is one of the best ways to develop mastery
</li>
<li>We can follow our own interests wherever they lead
</li>
<li>We want to collectively build something great for the community with our tiny slices of effort
</li>
</ul>
<p>I don't care how much you pay me, you'll never be able to recreate the incredibly satisfying feeling I get when <b>demonstrating mastery within my community of peers</b>. That's what we do on Stack Overflow: have <i>fun</i>, while making the internet one infinitesimally tiny bit better every day.</p>
<p>So is it any wonder that some claim <a href="http://meta.stackoverflow.com/questions/28642/why-do-i-get-more-satisfaction-out-of-participating-in-so-than-out-of-my-job">Stack Overflow is more satisfying than their real jobs?</a> Not to me.</p>
<p>If this all seems like a bunch of <b>communist hippie bullcrap</b> to you, I understand. It's hard to explain. But there is quite a bit of science documenting these strange motivations. Let's start with <a href="http://www.ted.com/talks/dan_pink_on_motivation.html">Dan Pink's 2009 TED talk</a>.</p>
<iframe src="http://embed.ted.com/talks/dan_pink_on_motivation.html" width="640" height="360" frameborder="0" scrolling="no" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
<p>Dan's talk centers on <a href="http://en.wikipedia.org/wiki/The_Candle_Problem">the candle problem</a>. Given the following three items …</p>
<ol>
<li>A candle</li>
<li>A box of thumbtacks</li>
<li>A book of matches</li>
</ol>
<p>… how can you attach the candle to the wall?</p>
<p>It's not a very interesting problem on its own – that is, until you try to <b>incentivize</b> teams to solve it:</p>
<blockquote>
<p>Now I want to tell you about an experiment using the candle problem by a scientist from Princeton named Sam Glucksberg. Here's what he did.</p>
<p>To the first group, he said, "I'm going to time you to establish norms, averages for how long it typically takes someone to solve this sort of problem."</p>
<p>To the second group, he said, "If you're in the top 25 percent of the fastest times you get five dollars. If you're the fastest of everyone we're testing here today you get 20 dollars." (This was many years ago. Adjusted for inflation, it's a decent sum of money for a few minutes of work.)</p>
<p>Question: How much faster did this group solve the problem?</p>
<p>Answer: It took them, on average, three and a half minutes longer. Three and a half minutes longer. Now this makes no sense, right? I mean, I'm an American. I believe in free markets. That's not how it's supposed to work. If you want people to perform better, you reward them. Give them bonuses, commissions, their own reality show. Incentivize them. That's how business works. But that's not happening here. <b>You've got a monetary incentive designed to sharpen thinking and accelerate creativity – and it does just the opposite. It dulls thinking and blocks creativity.</b></p>
</blockquote>
<p>It turns out that traditional carrot-and-stick incentives are only useful for repetitive, mechanical tasks. The minute you have to do anything even slightly complex that requires even a little problem solving without a clear solution or rules – those incentives not only don't work, they <i>make things worse!</i></p>
<p>Pink eventually wrote a book about this, <a href="http://www.amazon.com/dp/1594488843/?tag=codihorr-20">Drive: The Surprising Truth About What Motivates Us</a>.</p>
<p><a href="http://www.amazon.com/dp/1594488843/?tag=codihorr-20"><img alt="image placeholder" >
<p>There's no need to read the book; this clever ten minute whiteboard animation will walk you through the main points. If you view only one video today, view this one.</p>
<iframe width="640" height="360" src="//www.youtube.com/embed/u6XAPnuFjJc" frameborder="0" allowfullscreen></iframe>
<p>The concept of <a href="http://www.codinghorror.com/blog/2007/04/is-amazons-mechanical-turk-a-failure.html">intrinsic motivation</a> may not be a new one, but I find that very few companies are brave enough to actually implement them.</p>
<p><b>I've tried mightily to live up to the ideals that Stack Overflow was founded on when building out my team.</b> I don't care when you come to work or what your schedule is. I don't care <a href="http://www.codinghorror.com/blog/2010/05/on-working-remotely.html">where in the world you live</a> (provided you have a great internet connection). I don't care how you do the work. I'm not going to micromanage you and assign you a queue of task items. There's no need.</p>
<blockquote>
<p>If you want to build a ship, don't drum up the men to gather wood, divide the work and give orders. Instead, teach them to yearn for the vast and endless sea.<br><br>
– <a href="http://en.wikiquote.org/wiki/Antoine_de_Saint-Exupery#Unsourced">Antoine de Saint-Exupéry</a></p>
</blockquote>
<p>Because I know you yearn for the vast and endless sea, just like we do.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-06-01T03:05:41.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-vast-and-endless-sea/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Whatever Happened to Voice Recognition? ]]></title>
<link>https://blog.codinghorror.com/whatever-happened-to-voice-recognition/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Remember that Scene in <a href="http://www.imdb.com/title/tt0092007/">Star Trek IV</a> where Scotty tried to use a Mac Plus?
</p>
<p>
<a href="http://www.youtube.com/watch?v=19BWJQ8kjrw"><img alt="image placeholder" >
</p>
<p>
Using a mouse or keyboard to control a computer? Don't be silly. In the future, clearly there's only one way computers will be controlled: by <b>speaking to them</b>.
</p>
<p>
There's only <a href="http://robertfortner.posterous.com/the-unrecognized-death-of-speech-recognition">one teeny-tiny problem</a> with this magical future world of computers we control with our voices.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It doesn't work.
</p>
<p>
Despite ridiculous, <a href="http://www.codinghorror.com/blog/2006/12/moores-law-in-practical-terms.html">order of magnitude increases in computing power</a> over the last decade, we can't figure out how to get speech recognition accuracy above 80% -- when the baseline <i>human</i> voice transcription accuracy rate is anywhere from 96% to 98%!
</p>
<p>
</p>
<blockquote>
In 2001 recognition accuracy topped out at 80%, far short of HAL-like levels of comprehension. Adding data or computing power made no difference. Researchers at Carnegie Mellon University checked again in 2006 and found the situation <a href="http://www.cs.brandeis.edu/~marc/misc/proceedings/lrec-2006/pdf/802_pdf.pdf">unchanged</a>. With human discrimination as high as 98%, the unclosed gap left little basis for conversation. But sticking to a few topics, like numbers, helped. Saying â€œoneâ€ into the phone works about as well as pressing a button, approaching 100% accuracy. But loosen the vocabulary constraint and recognition begins to drift, turning to vertigo in the wide-open vastness of linguistic space.
</blockquote>
<p>
As Robert Fortner explained in <a href="http://robertfortner.posterous.com/the-unrecognized-death-of-speech-recognition">Rest in Peas: The Unrecognized Death of Speech Recognition</a>, after all these years, we're desperately far away from any sort of universal speech recognition that's useful or practical.
</p>
<p>
Now, we do have to clarify that we're talking about universal recognition: saying <i>anything</i> to a computer, and having it reliably convert that into a valid, accurate text representation. When you constrain the voice input to a more limited vocabulary -- say, just numbers, or only the names that happen to be in your telephone's address book -- it's not unreasonable to expect a high level of accuracy. I tend to think of this as "voice control" rather than "voice recognition".
</p>
<p>
Still, I think we're avoiding the real question: <b>is voice control, even hypothetically <i>perfect</i> voice control, more effective than the lower tech alternatives?</b> In my experience, speech is one of the least effective, inefficient forms of communicating with other human beings. By that, I mean ...
</p>
<ul>
<li>typical spoken communication tends to be off-the-cuff and ad-hoc. Unless you're extremely disciplined, on average you will be unclear, rambling, and excessively verbose.
</li>
<li>people tend to hear about half of what you say at any given time. <a href="http://www.codinghorror.com/blog/2006/03/the-value-of-repetition-again.html">If you're lucky</a>.
</li>
<li>spoken communication puts a highly disproportionate burden on the listener. Compare the time it takes to process a voicemail versus the time it takes to read an email.
</li>
</ul>
<p>
I am by no means <i>against</i> talking with my fellow human beings. I have a very deep respect for those rare few who are great communicators in the challenging medium of conversational speech. Though we've all been trained literally from birth how to use our voices to communicate, <b>voice communication remains filled with pitfalls and misunderstandings</b>. Even in the best of conditions.
</p>
<p>
So why in the world -- outside of a disability -- would I want to extend the creaky, rickety old bridge of voice communication to controlling my computer? Isn't there a better way?
</p>
<p>
Robert's <a href="http://robertfortner.posterous.com/the-unrecognized-death-of-speech-recognition">post</a> contains some examples in the comments from voice control enthusiasts:
</p>
<p>
</p>
<blockquote>
in addition to extremely accurate voice dictation, there are those really cool commands, like being able to say something like "search Google for Balloon Boy" or something like that and having it automatically open up your browser and enter the search term -- something like this is accomplished many times faster than a human could do it. Or, being able to total up a column of numbers in Microsoft Excel by saying simply "total this column" and seeing the results in a blink of an eye, literally.
</blockquote>
<p>
That's funny, because <b>I just fired up the Google app on my iPhone, said "balloon boy" into it, and got .. a search for "blue boy"</b>. I am not making this up. As for the Excel example, total <i>which</i> column? Let's assume you've dealt with the tricky problem of selecting what column you're talking about with only your voice. (I'm sorry, was it D5? B5?) Wouldn't it be many times faster to click the toolbar icon with your mouse, or press the keyboard command equivalent, to sum the column -- rather than methodically and tediously saying the words "sum this column" out loud?
</p>
<p>
I'm also trying to imagine a room full of people controlling their computers or phones using their voices. It's difficult enough to get work done in today's chatty work environments without the added burden of a floor full of people saying <a href="http://www.youtube.com/watch?v=Vxq9yj2pVWk">"zoom ... enhance"</a> to their computers all day long. Wouldn't we all end up hoarse <i>and</i> deaf?
</p>
<p>
Let's look at another practical example -- YouTube's <a href="http://googlesystem.blogspot.com/2009/11/youtube-audio-transcription.html">automatic speech recognition feature</a>. I clicked through to <a href="http://www.youtube.com/ucberkeley#p/u/0/BL9gmMzpRr4">the first UC Berkeley video</a> with this feature, clicked the CC (closed caption) icon, and immediately got .. this.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
"Light exerts force on matter". But according to Google's automatic speech recognition, it's "like the search for some matter". Unsurprisingly, it does not get better from there. You'd be way more confused than educated if you had to learn this lecture from the automatic transcription.
</p>
<p>
Back when Joel Spolsky and I <a href="http://itc.conversationsnetwork.org/series/stackoverflow.html">had a podcast together</a>, <b>a helpful listener suggested using speech recognition to get a basic podcast transcript going</b>. Everything I knew about voice recognition told me this wouldn't help, but harm. What's worse: transcribing everything by hand, from scratch -- or correcting every third or fourth word in an auto-generated machine transcript? Maybe it's just me, but the friction of the huge error rate inherent in the machine transcript seems far more intimidating than a blank slate human transcription. The humans may not be particularly efficient, but they all <i>add</i> value along the way -- collective human judgment can editorially improve the transcript, by removing all the duplication, repetition, and "ums" of a literal, by-the-book transcription.
</p>
<p>
In 2004, Mike Bliss <a href="http://www.theblisspages.com/cms.php?mbid=147">composed a poem about voice recognition</a>. He then read it to voice recognition software on his PC, and rewrote it as recognized.
</p>
<p>
</p>
<table width="600" cellpadding="4" cellspacing="4">
<tr>
<td valign="top">
a poem by Mike Bliss<br>
<br>
like a baby, it listens<br>
it can't discriminate<br>
it tries to understand<br>
it reflects what it thinks you say<br>
it gets it wrong... sometimes<br>
sometimes it gets it right.<br>
One day it will grow up,<br>
like a baby, it has potential<br>
will it go to work?<br>
will it turn to crime?<br>
you look at it indulgently.<br>
you can't help loving it, can you?<br>
</td>
<td valign="top">
a poem by like myth<br>
<br>
like a baby, it nuisance<br>
it can't discriminate<br>
it tries to oven<br>
it reflects lot it things you say<br>
it gets it run sometimes<br>
sometimes it gets it right<br>
won't day it will grow bop<br>
Ninth a baby, it has provincial<br>
will it both to look?<br>
will it the two crime?<br>
you move at it inevitably<br>
you can't help loving it, cannot you?<br>
</td>
</tr>
</table>
<p>
The real punchline here is that Mike re-ran the experiment in 2008, and after 5 minutes of voice training, <b>the voice recognition got all but 2 words of the original poem correct!</b>
</p>
<p>
I suspect that's still not good enough in the face of the existing simpler alternatives. Remember handwriting recognition? It was all the rage in the era of the <a href="http://en.wikipedia.org/wiki/Newton_(platform)">Apple Newton</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It wasn't as bad as Doonesbury made it out to be. I learned <a href="http://en.wikipedia.org/wiki/Graffiti_(Palm_OS)">Palm's Graffiti</a> handwriting recognition language and got fairly proficient with it. <b>More than ten years later, you'd expect to see <i>massively</i> improved handwriting recognition of some sort in today's iPads and iPhones and iOthers, right?</b> Well, maybe, if by "massively improved" you mean "nonexistent".
</p>
<p>
While it still surely has its niche uses, I personally don't miss handwriting recognition. Not even a little. And I can't help wondering if voice recognition will go the same way.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-06-21T03:37:37.000Z</pubDate>
<guid>https://blog.codinghorror.com/whatever-happened-to-voice-recognition/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Groundhog Day, or, the Problem with A/B Testing ]]></title>
<link>https://blog.codinghorror.com/groundhog-day-or-the-problem-with-ab-testing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>On a recent airplane flight, I happened to catch the movie <a href="http://www.imdb.com/title/tt0107048/">Groundhog Day</a>. Again.</p>
<img alt="image placeholder" >
<p>If you aren't familiar with this classic film, the premise is simple: Bill Murray, somehow, gets stuck reliving the same day over and over.</p>
<p>It's been at least 5 years since I've seen Groundhog Day. I don't know if it's my advanced age, or what, but it really struck me on this particular viewing: this is no comedy. There's a veneer of broad comedy, yes, but <b>lurking just under that veneer is a deep, dark existential conundrum.</b></p>
<p>It might be amusing to relive the same day a few times, maybe even a few dozen times. But an entire year of the same day – an entire <i>decade</i> of the same day – everything happening in precisely, exactly the same way? My back of the envelope calculation easily ran to a decade. But I was wrong. The director, Harold Ramis <a href="http://www.wolfgnards.com/index.php/2009/08/18/harold-ramis-responds-to-the-wolf-gnards">thinks it was actually 30 or 40 years</a>.</p>
<blockquote>
I think the 10-year estimate is too short. It takes at least 10 years to get good at anything, and alloting for the down time and misguided years [Phil] spent, it had to be more like 30 or 40 years [spent reliving the same day].
</blockquote>
<p>We only see bits and pieces of the full experience in the movie, but this time my mind began filling in the gaps. Repeating the same day for <i>decades</i> plays to our secret collective fear that our lives are irrelevant and ultimately pointless. None of our actions – even suicide, in endless grisly permutations – ever change anything. What's the point? Why bother? How many of us are trapped in here, and how can we escape?</p>
<p>This is some dark, scary stuff when you really think about it.</p>
<blockquote>
<p>You want a prediction about the weather, you're asking the wrong Phil.</p>
<p>I'll give you a winter prediction.<br>
It's gonna be cold,<br>
it's gonna be gray,<br>
and it's gonna last you for the rest of your life.</p>
</blockquote>
<p>Comedy, my ass. I wanted to cry.</p>
<p>But there is a way out: redemption through repetition. If you have to watch Groundhog Day a few times to appreciate it, you're not alone. Indeed, that seems to be the whole point. Just <a href="http://rogerebert.suntimes.com/apps/pbcs.dll/article?AID=/20050130/REVIEWS08/501300301/1023">ask Roger Ebert</a>:</p>
<blockquote>
<p>"Groundhog Day" is a film that finds its note and purpose so precisely that its genius may not be immediately noticeable. It unfolds so inevitably, is so entertaining, so apparently effortless, that you have to stand back and slap yourself before you see how good it really is.</p>
</blockquote>
<p>Certainly I underrated it in my original review; I enjoyed it so easily that I was seduced into cheerful moderation. But there are a few films, and this is one of them, that burrow into our memories and become reference points. When you find yourself needing the phrase This is like "Groundhog Day" to explain how you feel, a movie has accomplished something.</p>
<p>There's something delightfully <a href="http://en.wikipedia.org/wiki/Ouroboros">Ouroboros</a> about the epiphanies and layered revelations in repeated viewings of a movie <i>that is itself about (nearly) endless repetition</i>.</p>
<p>Which, naturally, <b>brings me to <a href="http://en.wikipedia.org/wiki/A/B_testing">A/B testing.</a></b> That's what Phil spends most of those thirty years doing. He spends it pursuing a woman, technically, but it's <i>how</i> he does it that is interesting:</p>
<blockquote>
<p>Rita: This whole day has just been one long setup.</p>
<p>Phil: No it hasn't.</p>
<p>Rita: And I hate fudge! <em>Yuck!</em></p>
<p>Phil: [making a mental list] No white chocolate. No fudge.</p>
<p>Rita: What are you doing? Are you making some kind of list or something? Did you call up my friends and ask what I like and what I don't like? Is this what love is for you?</p>
<p>Phil: No, this is real. This is love.</p>
<p>Rita: Stop saying that! You must be crazy.</p>
</blockquote>
<p>Phil doesn't just go on one date with Rita, he goes on <i>thousands</i> of dates. During each date, he makes note of what she likes and responds to, and drops everything she doesn't. At the end he arrives at – quite literally – the perfect date. Everything that happens is the most ideal, most desirable version of all possible outcomes on that date on that particular day. Such are the luxuries afforded to a man repeating the same day forever.</p>
<iframe width="640" height="360" src="//www.youtube.com/embed/7L92dBuVdE8?start=200" frameborder="0" allowfullscreen></iframe>
<p><b>This is the purest form of A/B testing imaginable.</b> Given two choices, pick the one that "wins", and keep repeating this ad infinitum until you arrive at the ultimate, most scientifically desirable choice. Your <a href="http://www.codinghorror.com/blog/2009/09/9-ways-marketing-weasels-will-try-to-manipulate-you.html">marketing weasels</a> would probably collapse in an ecstatic, religious fervor if they could achieve anything even remotely close to the level of perfect A/B testing depicted in Groundhog Day.</p>
<p>But at the end of this perfect date, something impossible happens: <b>Rita rejects Phil</b>.</p>
<p>Phil wasn't making these choices because he honestly believed in them. He was making these choices because he wanted a specific outcome – winning over Rita – and the experimental data told him which path he should take. Although the date was technically perfect, it didn't ring true to Rita, and that made all the difference.</p>
<p>That's the problem with A/B testing. It's empty. It has no feeling, no empathy, and at worst, <a href="http://learningischange.com/2010/01/22/question-22-of-365-farmville-practices-ghetto-testing-why-arent-we/">it's dishonest</a>. As my friend Nathan Bowers <a href="http://twitter.com/NathanBowers/status/16801715177">said</a>:</p>
<blockquote>
<p>A/B testing is like sandpaper. You can use it to smooth out details, but you can't actually create anything with it.</p>
</blockquote>
<p>The next time you reach for A/B testing tools, remember what happened to Phil. You can achieve a shallow local maximum with A/B testing – but you'll never win hearts and minds. If you, or anyone on your team, is still having trouble figuring that out, well, the solution is simple: <b>just watch Groundhog Day again</b>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-07-20T02:05:37.000Z</pubDate>
<guid>https://blog.codinghorror.com/groundhog-day-or-the-problem-with-ab-testing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's On Your Utility Belt? ]]></title>
<link>https://blog.codinghorror.com/whats-on-your-utility-belt/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Like any self-respecting geek, I'm mostly an <a href="http://www.codinghorror.com/blog/2007/10/geek-diet-and-exercise-programs.html">indoor enthusiast</a>.
</p>
<p>
But on those unfortunate occasions when I am compelled -- for reasons entirely beyond my control -- to leave the house, I do so fully armed with my crucial <b>utility belt items</b>. Yes, you heard me, I transform from the geeky Bruce Wayne <i>to the gosh-darned Batman!</i>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
At least, that's how I like to think of it.
</p>
<p>
I've been talking about this <a href="http://www.codinghorror.com/blog/2008/01/whats-on-your-keychain-2008-edition.html">every-day carry stuff</a> for <a href="http://www.codinghorror.com/blog/2006/06/whats-on-your-keychain-in-2006.html">quite</a> a <a href="http://www.codinghorror.com/blog/2005/03/whats-on-your-keychain.html">while</a> now. The 2010 edition of <b>my personal utility belt</b> is mostly subtle tweaks, but I daresay it's the best one yet.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The art of <a href="http://en.wikipedia.org/wiki/Every_day_carry">every-day carry</a> must go on. What you see here is the contents of my pocket:
</p>
<p>
</p>
<ol>
<li>
<b><a href="http://www.amazon.com/exec/obidos/ASIN/B001IWOQXQ/codihorr-20">Patriot 32 GB USB flash drive</a></b><br><br>
Now you can have a whole freakin' hard drive worth of files in your pocket. Just in case, you know, you have an emergency need to <a href="http://en.wikipedia.org/wiki/Independence_Day_(film)">upload a virus to an alien mothership</a>, or something. Beware the many cheap, slow USB flash drives out there; this one is a real gem. It's inexpensive, and per my measurements, about as fast as they get. This is important because the larger the flash drive, <a href="http://www.codinghorror.com/blog/2008/06/large-usb-flash-drive-performance.html">the more important speed becomes</a>. Hard to believe I've gone from carrying a 512 megabyte flash drive in 2005 to a 32 <i>gigabyte</i> flashdrive in 2010.<br><br>
</li>
<li>
<b><a href="http://www.amazon.com/exec/obidos/ASIN/B0007UQ1CO/codihorr-20">Leatherman Squirt P4</a></b><br><br>
Ounce for ounce, nothing beats the utility of the Leatherman Squirt. This time I opted for the plier (P) version instead of the scissors (S), and after seeing how much more generally useful the pliers are, I am now a little ashamed to admit I ever carried the wussy scissors version. Pliers all the way, baby. And yes, that is a <a href="http://www.imdb.com/title/tt0110912/">Pulp Fiction</a> joke you see on it.  <br><br>
</li>
<li>
<b><a href="http://www.amazon.com/exec/obidos/ASIN/B002YKL2ZQ/codihorr-20">Fenix mini AAA LED flashlight model LD01R2</a></b><br><br>
Since I've been carrying them in 2005, the average LED flashlight has gone from bright, to very bright, to amazingly bright, to <i>ridiculously blinding laser-like bright</i>. It's scary how bright these fancy milled aluminum AAA LED flashlights get now. What I like about this one is that it lets you trade off stupid-brightness for something practical, like greater runtime: you can twist the top to switch levels: 9 Lumens for 11 hours, 28 Lumens for 3.5 hours, or 85 Lumens for 1 hour.<br><br>
</li>
<li>
<b><a href="http://www.amazon.com/exec/obidos/ASIN/B002MD01KC/codihorr-20">Small Nite Ize s-biner</a></b><br><br>
These little nite-ize carabiners are awesome for quick attachment and detachment of your EDC items, but I'll warn you: resist the urge to put everything you carry on a carabiner, because if you do, the weight and "jangliness" goes up a lot -- and <a href="http://www.amazon.com/exec/obidos/ASIN/B0037GZZCC/codihorr-20">this way lies madness</a>. Consider how many items you actually <i>remove</i> from your keychain regularly. For me, the only item I frequently removed to work with was the Squirt, so that's the only one I put on a carabiner.
</li>
</ol>
<p>
Rest assured, everything here is carefully selected with the appropriate levels of monomaniacal attention to detail. For this weight and size, I don't think you can do better. (And don't think I've forgotten about <a href="http://www.codinghorror.com/blog/2009/04/optimizing-your-wallet.html">optimizing my wallet</a>, either. Oh no. Quite the contrary.)
</p>
<p>
However, I have to add a special category this year for the other must-have EDC utility belt item: the smartphone. <b>What self-respecting superhero would leave the house these days without their smartphone?</b> I'm not religious about it, but <a href="http://www.codinghorror.com/blog/2009/06/the-iphone-software-revolution.html">I use and rather like the iPhone 4</a>, and I'm continually amazed how many things it does that I used to carry separate items for:
</p>
<p>
</p>
<ul>
<li>cell phone (obviously)
</li>
<li>"Nintendo DSwhatever" for portable gaming
</li>
<li>GPS
</li>
<li>point and shoot digital camera
</li>
<li>near-desktop quality mobile web browser and email client
</li>
<li>mp3 player with speakers
</li>
<li>audio and hi-def video recorder
</li>
<li>DVD player
</li>
<li>ebook reader
</li>
<li>watch, alarm
</li>
<li>emergency flashlight (via front facing LED flash control)
</li>
<li>scanner
</li>
<li>level and ruler
</li>
</ul>
<p>
Smartphones really are <a href="http://gadgets.stackexchange.com/">the ultimate gadget</a>. The list of functions is already enormous, and I'm sure I'm leaving out a few other things that you can do with a modern smartphone.
</p>
<p>
In a pinch, I <i>could</i> conceivably drop the AAA LED flashlight and the USB flash drive from my EDC kit and substitute the smartphone. Not exactly, mind you, but it's getting closer every year. At this rate, Apple could introduce a flip-out blade on the iPhone 7 and reduce my entire EDC kit to one item.
</p>
<p>
Anyway, that's what's on my utility belt in 2010. What's on yours?
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-08-13T04:10:50.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-on-your-utility-belt/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Vampires (Programmers) versus Werewolves (Sysadmins) ]]></title>
<link>https://blog.codinghorror.com/vampires-programmers-versus-werewolves-sysadmins/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Kyle Brandt, a system administrator, asks <a href="http://blog.serverfault.com/post/893001713/should-developers-have-access-to-production">Should Developers have Access to Production?</a>
</p>
<p>
</p>
<blockquote>
A question that comes up <a href="http://serverfault.com/questions/62885/sysadmin-developer-responsibilities">again</a> and <a href="http://serverfault.com/questions/7907/access-to-the-production-systems-for-non-sys-admins">again</a> in web development companies is:
<p>
<i>"Should the developers have access to the production environment, and if they do, to what extent?"</i>
</p>
<p>
My view on this is that as a whole they should have limited access to production. A little
disclaimer before I attempt to justify this view is that this standpoint is in no way based on the perceived quality or attitude of the developers -- so please don't take it this way.
</p>
</blockquote>
<p>
This is a tricky one for me to answer, because, well, I'm a developer. More specifically, <b>I'm one of the developers Kyle is referring to</b>. How do I know that? Because Kyle works for our company, Stack Overflow Internet Services Incorporated©®™. And Kyle is a great system administrator. How do I know that? Two reasons:
</p>
<p>
</p>
<ol>
<li>He's one of the top <a href="http://serverfault.com">Server Fault</a> users.
</li>
<li>He had the audacity to write about this issue on the Server Fault blog.
</li>
</ol>
<p>
From my perspective, <i>the whole point of the company</i> is to talk about what we're doing. <a href="http://www.codinghorror.com/blog/2007/07/yes-but-what-have-you-done.html">Getting things done is important</a>, of course, but we have to stop occasionally to write up what we're doing, how we're doing it, and why we're even doing it in the first place -- including all our doubts and misgivings and concerns. If we don't, we're cheating ourselves, and you guys, out of something much deeper. Yes, writing about what we're doing and explaining it to the community helps us focus. It lets our peers give us feedback. But most importantly of all, it lets <i>anyone</i> have the opportunity to learn from our many, many mistakes … and who knows, perhaps even the occasional success.
</p>
<p>
That's basically the entire philosophy behind our <a href="http://stackexchange.com/">Stack Exchange Q&amp;A network</a>, too. Let's <i>all</i> talk about this stuff in public, so that <b>we can teach each other how to get better at whatever the heck it is we love to do</b>.
</p>
<p>
(Sometimes I get the feeling this idea makes <a href="http://www.joelonsoftware.com/AboutMe.html">my co-founder</a> nervous, which I continually struggle to understand. If we don't walk the walk, why are we even doing this? But I digress.)
</p>
<p>
The saga of System Administrators versus Programmers is not a new one; I don't think I've ever worked at any company where these two factions weren't continually battling with each other in some form. It's truly an epic struggle, but to understand it, you have to appreciate that <b>both System Administrators and Programmers have different, and perhaps complementary, supernatural powers</b>.
</p>
<p>
Programmers are like <b>vampires</b>. They're frequently up all night, paler than death itself, and generally <a href="http://www.codinghorror.com/blog/2007/10/geek-diet-and-exercise-programs.html">afraid of being exposed to daylight</a>. Oh yes, and they tend think of themselves (or at least their code) as immortal.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
System Administrators are like <b>werewolves</b>. They may look outwardly ordinary, but are incredibly strong, mostly invulnerable to stuff that would kill regular people -- and prone to strange transformations during a moon "outage".
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Let me be very clear that just as Kyle respects programmers, I have <a href="http://www.codinghorror.com/blog/2009/05/server-fault-calling-all-lusers.html">a deep respect for system administrators</a>:
</p>
<p>
</p>
<blockquote>
Although there is certainly some crossover, we believe that the programming community and the IT/sysadmin community are different beasts. Just because you're a hotshot programmer doesn't mean you have mastered networking and server configuration. And I've met a few sysadmins who could script circles around my code. That's why Server Fault gets its own domain, user profiles, and reputation system.
</blockquote>
<p>
Different "beasts" indeed.
</p>
<p>
Anyway, if you're looking for a one size fits all answer to the question of how much access programmers should have to production environments, I'm sorry, I can't give you one. Every company is different, every team is different. I know, it's a sucky answer, but <i>it depends</i>.
</p>
<p>
However, as anyone who has watched the latest season of <a href="http://en.wikipedia.org/wiki/True_Blood">True Blood</a> (or, God help us all, the <a href="http://www.imdb.com/title/tt1325004/">Twilight Eclipse</a> movie) can attest, there <i>are</i> ways for vampires and werewolves to work together. In a healthy team, everyone feels their abilities are being used and not squandered.
</p>
<p>
On our team, we're all fair-to-middling sysadmins. But there are a million things to do, and having a professional sysadmin means we can focus on the programming while the networking, hardware, and operational stuff gets a whole lot more TLC and far better (read: non-hacky) processes put in place. We're happy to refocus our efforts on what we're expert at, and let Kyle put his skills to work in areas that he's expert at. Now, that said, we don't want to cede full access to the production servers -- but there's a happy middle ground where our access becomes infrequent and minor over time, except in the hopefully rare event of an all hands on deck emergency.
</p>
<p>
The art of managing vampires and werewolves, I think, is to ensure that they spend their time not fighting amongst themselves, but instead, <b>using those supernatural powers together to achieve a common goal they could not otherwise</b>. In my experience, when programmers and system administrators fight, it's because they're bored. You haven't given them a sufficiently daunting task, one that requires the full combined use of their unique skills to achieve.
</p>
<p>
Remember, it's not vampires versus werewolves. It's vampires <i>and</i> werewolves.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-08-27T05:26:43.000Z</pubDate>
<guid>https://blog.codinghorror.com/vampires-programmers-versus-werewolves-sysadmins/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Go That Way, Really Fast ]]></title>
<link>https://blog.codinghorror.com/go-that-way-really-fast/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>When it comes to running Stack Overflow, <a href="http://stackexchange.com/about/management">the company</a>, I take all my business advice from one person, and one person alone: <b>Curtis Armstrong</b>.</p>
<p><a href="http://www.imdb.com/name/nm0035664/"><img alt="image placeholder" >
<p>More specifically, Curtis Armstrong as <b>Charles De Mar</b> from the 1985 absurdist teen comedy classic, <a href="http://www.imdb.com/title/tt0088794/">Better Off Dead</a>. When asked for advice on how to ski down a particularly treacherous mountain, he replied:</p>
<video poster="/content/images/2015/08/go-that-way-really-fast-poster.jpg" width="100%" height="384" preload="none" controls>
<source src="http://discourse-cdn.codinghorror.com/uploads/default/original/3X/e/c/ec36e4402a6f8b838624051060a8694dfd084862.mp4">
</source></video>
<p><b>Go that way, <i>really</i> fast. If something gets in your way … turn.</b></p>
<p>(I recommend watching <a href="http://www.amazon.com/dp/B00005JKFA/?tag=codihorr-20">the entire movie</a>. It's brilliant in ways I can't possibly explain here.)</p>
<p>In the five months since we <a href="http://blog.stackoverflow.com/2010/05/announcing-our-series-a/">announced our funding</a>, we have …</p>
<ul>
<li>Built an <a href="http://blog.codinghorror.com/on-working-remotely/">international team</a>
</li>
<li>Created an entirely new open, democratic process for creating Q&amp;A sites at <a href="http://area51.stackexchange.com/faq">Area 51</a>
</li>
<li>Launched ~24 new community-driven <a href="http://stackexchange.com/sites">Stack Exchange network sites</a>
</li>
<li>Implemented <a href="http://blog.stackoverflow.com/2010/07/new-per-site-metas/">per-site meta discussion</a> and <a href="http://blog.stackoverflow.com/2010/08/chat-now-in-public-beta/">per-site real time chat</a>
</li>
<li>Rolled out new versions of <a href="http://careers.stackoverflow.com/">Careers</a> and <a href="http://careers.stackoverflow.com/Jobs">Jobs</a>
</li>
<li>Built and open-sourced a tool for exploring and sharing all our creative commons data in the <a href="http://odata.stackexchange.com/">Stack Exchange Data Explorer</a>
</li>
<li>Finalized V1 of the <a href="http://stackapps.com/">Stack Exchange API</a>, for building your own apps against our Q&amp;A platform
</li>
</ul>
<p>… and honestly, I'm a little worried we're <i>still not going fast enough</i>.</p>
<p>There are any number of Stack Overflow engine clones out there already, and I say more power to 'em. I'm proud to have something worth copying. If we do nothing else except help lead the world away from the ancient, creaky, horribly broken bulletin board model of phpBB and vBulletin – attempting to get information out of those things is like <b>panning for gold in a neverending river of sewage</b> – then that is more than I could have ever hoped for.</p>
<p>It is our stated goal as a company to live in harmony with the web, by only doing things that we believe make the internet better, at least in some small way. No, seriously. It's in writing and everything, I swear! We're not here to subvert or own anyone or anything. We just love community, and we love getting great answers to our questions. So if something gets in our way while doing that, well, we're not gonna fight you. <b>We'll just turn</b>. And keep going forward, really fast. Which is why those clones better move quick if they want to keep up with us.</p>
<p>While I like to think that having Charles De Mar as a business advisor is unique to our company, the idea that speed is important is hardly original to us. For example, certain Google projects also appear to understand <a href="http://blog.codinghorror.com/boyds-law-of-iteration/">Boyd's Law of Iteration</a>.</p>
<blockquote>
<p>Boyd decided that the primary determinant to winning dogfights was not observing, orienting, planning, or acting better. The primary determinant to winning dogfights was observing, orienting, planning, and acting <i>faster</i>. In other words, how quickly one could iterate. <i>Speed of iteration</i>, Boyd suggested, beats <i>quality of iteration</i>.</p>
</blockquote>
<p>Speed of iteration – the <a href="http://en.wikipedia.org/wiki/Google_Chrome">Google Chrome</a> project has it.</p>
<table cellpadding="4" cellspacing='4"' width="400">
<tr>
<td>1.0</td>
<td>December 11, 2008</td>
</tr>
<tr>
<td>2.0</td>
<td>May 24, 2009</td>
</tr>
<tr>
<td>3.0</td>
<td>October 12, 2009</td>
</tr>
<tr>
<td>4.0</td>
<td>January 25, 2010</td>
</tr>
<tr>
<td>5.0</td>
<td>May 25, 2010</td>
</tr>
<tr>
<td>6.0</td>
<td>September 2, 2010</td>
</tr>
</table>
<p>Chrome was a completely respectable browser in V1 and V2. The entire project has moved forward so fast that it now is, at least in my humble opinion, the best browser on the planet. Google went from nothing, no web browser at all, to best-of-breed in <b>under two years</b>. Meanwhile, Internet Explorer took longer than the entire development period of Chrome to go from version 7 to version 8. And by the time Internet Explorer 9 ships – even though it's actually looking like Microsoft's best, most competent technical upgrade of the browser yet – it will be completely outclassed at launch by both Firefox and Chrome.</p>
<p>The <a href="http://en.wikipedia.org/wiki/Android_(operating_system)">Google Android</a> project is another example. Android doesn't have to be better than the iPhone (and it most <i>definitely</i> isn't; it's been mediocre at best until recent versions). They just need to be <i>faster at improving</i>. Google is pushing out <a href="http://en.wikipedia.org/wiki/Android_(operating_system)#Update_history">Froyos and Gingerbreads and Honeycombs</a> with incredible, breakneck speed. Yes, Apple has indisputably better taste – and an impeccably controlled experience. But at their current rate of progress, they'll be playing second or third fiddle to Google in the mobile space inside a few years. It's inevitable.</p>
<p>So, until further notice, we'll be following the same strategy as the Android and Chrome teams. <b>We're going to go that way, <i>really</i> fast. And if something gets in our way, we'll turn.</b></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-09-11T23:52:55.000Z</pubDate>
<guid>https://blog.codinghorror.com/go-that-way-really-fast/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Revisiting Solid State Hard Drives ]]></title>
<link>https://blog.codinghorror.com/revisiting-solid-state-hard-drives/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's been almost a year since I covered <a href="http://www.codinghorror.com/blog/2009/10/the-state-of-solid-state-hard-drives.html">The State of Solid State Hard Drives</a>. Not a heck of a lot has changed, but the topic is still worth revisiting, because if you care at all about how your computer performs, <b>solid state hard drives remain a life changing experience</b>. Here's why:
</p>
<p>
</p>
<ol>
<li>A solid state hard drive is easily the best and most obvious performance upgrade you can make on any computer for a given amount of money. Unless your computer is absolute crap to start with.
</li>
<li>The practical minimum solid state hard drive size, <b>128 GB</b>, has modestly declined in price -- from about $350 to about $250.
</li>
</ol>
<p>
(yes, you can get by with 64 GB, but at least with my Windows installs I find that I have to <i>think</i> about disk space with 64 GB, whereas with 128 GB I don't have to worry -- ever. <a href="http://www.codinghorror.com/blog/2005/08/dont-make-me-think-second-edition.html">Don't make me think, man!</a>)
</p>
<p>
The rest of the components inside your PC are downright boring in comparison. CPUs? All stupid fast at any price, with more cores and gigahertz than you'll ever need unless you're one of those freaks who does nothing but raytracing and video transcoding all day long. Memory? Dirt cheap, and average users won't need more than 2 gigabytes of the stuff in practical use, which at the current going rate for DDR3 is less than 50 bucks.
</p>
<p>
Thanks to the <a href="http://www.codinghorror.com/blog/2006/12/moores-law-in-practical-terms.html">neverending march of Moore's Law</a>, PCs are becoming speedy at <i>any</i> price these days. It's difficult for me to <a href="http://www.codinghorror.com/blog/2009/12/building-a-pc-part-vi-rebuilding.html">muster any enthusiasm for the latest Intel CPU updates</a> when I spend almost zero real world time waiting for the CPU to do anything on my computer. I guess it's true: absolute power corrupts absolutely.
</p>
<p>
<a href="http://www.despair.com/power.html"><img alt="image placeholder" >
</p>
<p>
But hard drives, now, there's where you can pay a bit more and see a groundbreaking, generational leap in performance <i>worthy</i> of that investment -- as long as you skip over the old and busted spinning rust hard drives, and choose a newfangled <b>solid state hard drive</b>.
</p>
<p>
The current king of the hill seems to be the <a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820148348%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-Crucial%2BTechnology-_-20148348&amp;cjsku=N82E16820148348">Crucial RealSSD C300</a>.
</p>
<p>
<a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820148348%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-Crucial%2BTechnology-_-20148348&amp;cjsku=N82E16820148348"><img alt="image placeholder" >
</p>
<p>
Pretty sexy, right? Oh, who am I kidding, it's a boring slab of aluminum and silicon. But like all truly sexy things, what turns me on is the part I <i>can't</i> see -- the <a href="http://www.techreport.com/articles.x/19162/9">sexy, sexy, <i>sexy</i> performance inside this baby</a>.
</p>
<p>
<a href="http://www.techreport.com/articles.x/19162/9"><img alt="image placeholder" >
</p>
<p>
See those bars dragging down the bottom of this graph? All spinning rust. Heck, even the SSD I recommended last year is only middle of the pack here. AnandTech <a href="http://www.anandtech.com/show/3812/the-ssd-diaries-crucials-realssd-c300/4">concurs</a> -- the <a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820148348%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-Crucial%2BTechnology-_-20148348&amp;cjsku=N82E16820148348">Crucial RealSSD C300</a> is top dog, at least for now.
</p>
<p>
(Be careful, though, that your operating system supports the <a href="http://en.wikipedia.org/wiki/TRIM">SSD TRIM command</a>, otherwise you'll suffer severe performance degradation over time with almost any SSD. Operating systems earlier than Windows 7 and the latest, greatest Linux kernel should beware -- and, shockingly, OSX still doesn't support TRIM!)
</p>
<p>
Where it gets trickier, though, is when you need more than 128 GB of storage, or when you are limited to one 2.5" hard drive -- like in a laptop. In that case, ideally you'd like something that has the <i>speed</i> of a solid state hard drive, but the <i>capacity</i> (and economical price per gigabyte) of a traditional magnetic platter hard drive. You might say … <b>a hybrid hard drive</b>, <a href="http://www.codinghorror.com/blog/2006/09/vista-and-the-rise-of-the-flash-drives.html">the kind I was dreaming about back in 2006</a> …
</p>
<p>
</p>
<blockquote>
After all this analysis, it's clear to me that traditional hard drives and flash memory are quite complimentary; they're strong in different areas. But flash drives are the future. They will definitely replace hard drives in almost all low end and low power devices-- and future high performance hard drives will need to have a substantial chunk of flash memory on board to stay competitive.
</blockquote>
<p>
I had always been disappointed that hybrid hard drives, drives that combine both flash memory <i>and</i> traditional magnetic platters, never came to fruition. It was either traditional or SSD and nothing in between. It seemed like such an obvious "best of both worlds" scenario to me. But I recently discovered that <b>decent hybrid drives do finally exist</b> -- though in a small and mostly unheralded way.
</p>
<p>
<a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16822148591%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives%2B-%2BNotebooks%2B%2F%2BLaptops-_-Seagate-_-22148591&amp;cjsku=N82E16822148591">Seagate's Momentus XT</a> takes a totally respectable 2.5", 7200 RPM drive with a 32 megabyte buffer and <b>combines it with 4 gigabytes of flash memory</b>. The result is the <a href="http://www.anandtech.com/show/3734/seagates-momentus-xt-review-finally-a-good-hybrid-hdd">exactly what I had always hoped</a>:
</p>
<p>
</p>
<blockquote>
Seagate's Momentus XT should become the standard hard drive in any notebook shipped. The biggest problem I have with using any brand new machine, regardless of how fast it is, is that it never feels fast because it usually has a HDD and not an SSD. While the Momentus XT isn't quite as fast as an SSD, it's a significant improvement over the mechanical drives found in notebooks today.
<p>
In many cases the Momentus XT performs like a VelociRaptor, but in a lower power, quieter package. The impact of adding just a small amount of SLC NAND is tremendous. The potential for hybrid drives continues to be huge; what Seagate has shown here is that with a minimal amount of NAND you can achieve some tremendous performance gains.
</p>
</blockquote>
<p>
And the best part? <a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16822148591%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives%2B-%2BNotebooks%2B%2F%2BLaptops-_-Seagate-_-22148591&amp;cjsku=N82E16822148591">500 gigabytes of near-SSD performance for $130!</a> Or, if that's too spendy, how about <a href="http://www.kqzyfj.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16822148592%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives%2B-%2BNotebooks%2B%2F%2BLaptops-_-Seagate-_-22148592&amp;cjsku=N82E16822148592">320 gigabytes of near-SSD performance for $99</a>?
</p>
<p>
I've ordered a few of these drives to upgrade my laptops and <a href="http://www.codinghorror.com/blog/2008/04/building-your-own-home-theater-pc.html">home theater PC</a>. Sure, I'll invest in a SSD for my beastly desktop, but I can't justify $300 to put a SSD in a laptop I spent all of $800 on, or a home theater PC that set me back a mere $500. But <b>a hundred bucks for near-SSD performance <i>and</i> decent capacity</b>? Sign me up. And hard drive vendors: although I love SSDs to death, please keep these improved hybrid drives coming, too, please!
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-09-15T01:30:23.000Z</pubDate>
<guid>https://blog.codinghorror.com/revisiting-solid-state-hard-drives/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ YouTube vs. Fair Use ]]></title>
<link>https://blog.codinghorror.com/youtube-vs-fair-use/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In <a href="http://www.codinghorror.com/blog/2007/10/youtube-the-big-copyright-lie.html">YouTube: The Big Copyright Lie</a>, I described my love-hate relationship with YouTube, at least as it existed in way back in the dark ages of 2007.</p>
<blockquote>
<p>Now think back through all the videos you've watched on YouTube. How many of them contained any original content?</p>
<p>It's perhaps the ultimate case of cognitive dissonance: by YouTube's own rules [which prohibit copyrighted content], YouTube cannot exist. And yet it does.</p>
<p>How do we reconcile YouTube's official hard-line position on copyright with the reality that 90% of the content on their site is clearly copyrighted and clearly used without permission? It seems YouTube has an awfully convenient "don't ask, don't tell" policy-- they make no effort to verify that the uploaded content is either original content or fair use. The copyrighted content stays up until the copyright owner complains. Then, and only then, is it removed.</p>
</blockquote>
<p>Today's lesson, then, is <b>be careful what you ask for</b>.</p>
<p>At the time, I just assumed that YouTube would never be able to resolve this problem through technology. The idea that you could somehow fingerprint every user-created uploaded video against <i>every piece of copyrighted video ever created</i> was so laughable to me that I wrote it off as impossible.</p>
<p>A few days ago I uploaded a small clip from the movie <a href="http://www.imdb.com/title/tt0088794/">Better Off Dead</a> to YouTube, in order to use it in the <a href="http://blog.codinghorror.com/go-that-way-really-fast/">Go That Way, Really Fast</a> blog entry. This is quintessential <b>fair use</b>: a tiny excerpt of the movie, presented in the context of a larger blog entry. So far, so good.</p>
<p>But then I uploaded a small clip from a different movie that I'm planning to use in another, future blog entry. Within an hour of uploading it, I received this email:</p>
<blockquote>
<p>Dear {username},</p>
<p>Your video, {title}, may have content that is owned or licensed by {company}.</p>
<p>No action is required on your part; however, if you are interested in learning how this affects your video, please visit <a href="http://www.youtube.com/my_videos_copyright">the Content ID Matches section of your account</a> for more information.</p>
<p>Sincerely,<br></p>
<ul>
<li>The YouTube Team</li>
</ul>
</blockquote>
<p>This 90 second clip is <a href="http://blog.codinghorror.com/but-you-did-not-persuade-me/">from a recent movie</a>. Not a hugely popular movie, mind you, but a movie you've probably heard of. This email both fascinated and horrified me. <b>How did they match a random, weirdly cropped (thanks, Windows Movie Maker) clip from the middle of a non-blockbuster movie</b> within an hour of me uploading it? This had to be some kind of automated process that checks uploaded user content against every piece of copyrighted content ever created (or the top n subset thereof), <i>exactly the kind that I thought was impossible.</i></p>
<p>Uh oh.</p>
<p>I began to do some research. I quickly found <a href="http://www.csh.rit.edu/~parallax/">Fun with YouTube's Audio Content ID System</a>, which doesn't cover video, but it's definitely related:</p>
<blockquote>
<p>I was caught by surprise one day when I received an automated email from YouTube informing me that my video had a music rights issue and it was removed from the site. I didn't really care.</p>
<p>Then a car commercial parody I made (arguably one of my better videos) was taken down because I used an unlicensed song. That pissed me off. I couldn't easily go back and re-edit the video to remove the song, as the source media had long since been archived in a shoebox somewhere. And I couldn't simply re-upload the video, as it got identified and taken down every time. I needed to find a way to outsmart the fingerprinter. I was angry and I had a lot of free time. Not a good combination.</p>
<p>I racked my brain trying to think of every possible audio manipulation that might get by the fingerprinter. I came up with an almost-scientific method for testing each modification, and I got to work.</p>
</blockquote>

<p>Further research led me to this brief TED talk, <a href="http://www.ted.com/talks/margaret_stewart_how_youtube_thinks_about_copyright.html">How YouTube Thinks About Copyright</a>.</p>
<blockquote>
<p>We compare each upload against all the reference files in our database. This heat map is going to show you how the brain of this system works.</p>
<img alt="image placeholder" >
<p>Here we can see the reference file being compared to the user generated content. The system compares every moment of one to the other to see if there's a match. This means we can identify a match even if the copy uses just a portion of the original file, plays it in slow motion, and has degraded audio or video.</p>
<p>The scale and speed of this system is truly breathtaking – we're not just talking about a few videos, we're talking about over 100 years of video every day between new uploads and the legacy scans we regularly do across all of the content on the site. And when we compare those 100 years of video, we're comparing it against millions of reference files in our database. It'd be like 36,000 people staring at 36,000 monitors each and every day without as much as a coffee break.</p>
</blockquote>
<p>I have to admit that I'm astounded by the scope, scale, and sheer effectiveness of  YouTube's new copyright detection system <i>that I thought was impossible!</i> Seriously, <a href="http://www.ted.com/talks/margaret_stewart_how_youtube_thinks_about_copyright.html">watch the TED talk</a>. It's not long. The more I researched <a href="http://www.google.com/support/youtube/bin/answer.py?hl=en&amp;answer=83766">YouTube's video identification tool</a>, the more I realized that <b>resistance is futile</b>. It's <i>so</i> good that the only way to defeat it is by degrading your audio and video so much that you have effectively ruined it. And when it comes to copyright violations, if you can achieve mutually assured destruction, then you have won. Absolutely and unconditionally.</p>
<p>This is an outcome so incredible I am still having trouble believing it. But I have the automatically blocked uploads to prove it.</p>
<p>Now, <b>I am in no way proposing that copyright is something we should be trying to defeat or work around</b>. I suppose I was just used to the <a href="http://en.wikipedia.org/wiki/Laissez-faire">laissez faire</a> status quo on YouTube, and the idea of a video copyright detection system this effective was completely beyond the pale. My hat is off to the engineers at Google who came up with this system. They aren't the bad guys here; they offer some rather sane alternatives when copyright matches are found:</p>
<blockquote>
<p>If Content ID identifies a match between a user upload and material in the reference library, it applies the usage policy designated by the content owner. The usage policy tells the system what to do with the video. Matches can be to only the audio portion of an upload, the video portion only, or both.</p>
<p>There are three usage policies – <b>Block, Track or Monetize</b>. If a rights owner specifies a <b>Block</b> policy, the video will not be viewable on YouTube. If the rights owner specifies a <b>Track</b> policy, the video will continue to be made available on YouTube and the rights owner will receive information about the video, such as how many views it receives. For a <b>Monetize</b> policy, the video will continue to be available on YouTube and ads will appear in conjunction with the video. The policies can be region-specific, so a content owner can allow a particular piece of material in one country and block the material in another.</p>
</blockquote>
<p>The particular content provider whose copyright I matched chose the draconian block policy. That's certainly not Google's fault, but I guess you could say <a href="http://www.codinghorror.com/blog/2007/07/googles-number-one-ui-mistake.html">I'm Feeling Unlucky</a>.</p>
<p>Although the 90 second clip I uploaded is clearly copyrighted content – I would never dispute that – <b>my intent is not to facilitate illegal use, but to "quote" the movie scene as part of a larger blog entry.</b> YouTube does provide recourse for uploaders; they make it easy to file a dispute once the content is flagged as copyrighted. So I dutifully filled out the dispute form, indicating that I felt I had a reasonable claim of fair use.</p>
<img alt="image placeholder" >
<p>Unfortunately, my fair use claim was denied without explanation by the copyright holder.</p>
<p>Let's consider the four guidelines for fair use I outlined in <a href="http://www.codinghorror.com/blog/2007/10/youtube-the-big-copyright-lie.html">my original 2007 blog entry</a>:</p>
<ol>
<li>Is the use transformative?</li>
<li>Is the source material intended for the public good?</li>
<li>How much was taken?</li>
<li>What's the market effect?</li>
</ol>
<p>While we're clear on 3 and 4, items 1 and 2 are hazy in a mashup. This would definitely be transformative, and I like to think that I'm writing for the erudition of myself and others, not merely to entertain people. I uploaded with the <i>intent</i> of the video being viewed through a blog entry, with YouTube as the content host only. But it was still 90 seconds of the movie viewable on YouTube by anyone, context free.</p>
<p>So I'm torn.</p>
<p>On one hand, this is an <i>insanely</i> impressive technological coup. The idea that YouTube can (with the assistance of the copyright holders) really validate every minute of uploaded video against <b>every minute of every major copyrighted work</b> is unfathomable to me. When YouTube promised to do this to placate copyright owners, I was sure they were delaying for time. But much to my fair-use-loving dismay, they've actually gone and <i>built</i> the damn thing – and it works.<br>
Just, maybe, it works a little <i>too</i> well. I'm still looking for video sharing services that <a href="http://webapps.stackexchange.com/questions/6445/web-video-sharing-service-with-fair-use-protection">offer some kind of fair use protection</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-09-17T09:33:39.000Z</pubDate>
<guid>https://blog.codinghorror.com/youtube-vs-fair-use/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Because Everyone Needs a Router ]]></title>
<link>https://blog.codinghorror.com/because-everyone-needs-a-router/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Do you remember when a router used to be an exotic bit of network kit?
</p>
<p>
Those days are long gone. A router is one of those salt-of-the-earth items now; <b>anyone who pays for an internet connection needs a router</b>, for:
</p>
<ol>
<li>NAT and basic hardware firewall protection from internet evildoers
</li>
<li>A wired network hub to connect local desktop PCs
</li>
<li>A wireless hub to connect laptops, phones, consoles, etcetera
</li>
</ol>
<p>
Let me put it this way: my mom – and my wife's mom – both own routers. If that isn't the definition of <i>mainstream</i>, I don't know what is.
</p>
<p>
Since my livelihood revolves around being on the internet, and because I'm a bit of a tweaker, I have a fancy-ish router. But <a href="http://www.codinghorror.com/blog/2007/12/gifts-for-geeks-2007-edition.html">it is of late 2007 vintage</a>:
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/B000Z7AKGC/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Although the <a href="http://www.amazon.com/exec/obidos/ASIN/B000Z7AKGC/codihorr-20">DGL-4500</a> is a nice router, and it has served me well with no real complaints, the last major firmware update for it was a year and a half ago. There have been some desultory minor updates since then, but clearly the vendor has, shall we say, <i>moved on</i> to focusing on newer models.
</p>
<p>
The router is (literally!) the central component in my overall internet experience, and I was growing increasingly uncomfortable with the status quo. Frankly, the prospect of three year old hardware with year old firmware gives me the heebie-jeebies.
</p>
<p>
So, I asked the pros at <a href="http://superuser.com/">Super User</a>, even going so far as to set up <a href="http://chat.superuser.com/rooms/19/recommend-me-a-router">a Recommend Me a Router chat room</a>. (We disallow product recommendation questions as they become uselessly out of date so quickly, but this is a perfect topic for a chat room.) I got some fantastic advice from my fellow Super Users via chat, though much of it was of the far too sane "if it ain't broke don't fix it" variety. Well, that's just <a href="http://www.codinghorror.com/blog/2004/11/dont-be-afraid-to-break-stuff.html">not how I work</a>. To be fair, the router market is not exactly a hotbed of excitement at the moment; it is both saturated and heavily commoditized, particularly now that the dust has settled from the whole <a href="http://en.wikipedia.org/wiki/IEEE_802.11">802.11 A/B/G/N debacle</a>. There just isn't much going on.
</p>
<p>
But in the process of doing my router research, I discovered something important, and maybe even revolutionary in its own quiet little way. <b>The best router models all run open source firmware!</b>
</p>
<p>
</p>
<ul>
<li>
<a href="http://en.wikipedia.org/wiki/DD-WRT">DD-WRT</a>
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Tomato_(firmware)">Tomato</a>
</li>
</ul>
<p>
That's right, the truly great routers <a href="http://www.codinghorror.com/blog/2009/07/oh-you-wanted-awesome-edition.html">are available in "awesome" edition</a>. (There may be other open source router firmwares out there, but these are the two I saw most frequently.) I learned that these open source firmwares can turn a boring Clark Kent router into Superman. And they are <i>always</i> kept updated by the community, in perpetuity.
</p>
<p>
In my weaker moments, I toyed with the idea of building <a href="http://techreport.com/articles.x/19227">a silent mini x86 PC</a> that could run a routing optimized distribution of Linux, but the reality is that current commodity routers have <i>more</i> than enough memory and embedded CPU power – not to mention the necessary wireless and gigabit ethernet hub bits already built in. Dedicating a whole x86 PC to routing is power inefficient, overly complex, and awkward.
</p>
<p>
Yes, today's router marketplace is commoditized and standardized and boring – but there are still a few clear hardware standouts. I turned to the experts at <a href="http://www.smallnetbuilder.com/">SmallNetBuilder</a> for their in-depth technical reviews, and found two consensus recommendations:
</p>
<p>
<span style="color:red">Update:</span> Though these models are still fine choices, particularly if you can find a great deal on them, I have newer recommendations in <a href="http://www.codinghorror.com/blog/2012/06/because-everyone-still-needs-a-router.html">Because Everyone (Still) Needs a Router</a>.
</p>
<p>
<a href="http://www.smallnetbuilder.com/wireless/wireless-reviews/30889-buffalo-nfiniti-wireless-n-high-power-router-a-access-point-reviewed">Buffalo Nfiniti Wireless-N High Power Router</a> ($80)
</p>
<p>
<a href="http://www.amazon.com/dp/B0028ACYEK/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
<a href="http://www.smallnetbuilder.com/wireless/wireless-reviews/30925-start-your-buying-netgear-wndr3700-reviewed">NETGEAR WNDR3700 RangeMax Dual Band Wireless-N</a> ($150)
</p>
<p>
<a href="http://www.amazon.com/dp/B002HWRJY4/?tag=codihorr-20">
<img alt="image placeholder" >
</p>
<p>
Both of these models got glowing reviews from the networking experts at SmallNetBuilder, and both are 100% compatible with the <a href="http://www.dd-wrt.com/site/index">all-important open source dd-wrt firmware</a>. You can't go wrong with either, but I chose the less expensive <a href="http://www.amazon.com/dp/B0028ACYEK/?tag=codihorr-20">Buffalo Nfiniti router</a>. Why?
</p>
<p>
</p>
<ol>
<li>It's almost half the price, man!
</li>
<li>The "high power" part is verifiably and benchmarkably true, and I have some <a href="http://www.codinghorror.com/blog/2008/02/extending-your-wireless-network-with-better-antennas.html">wireless range problems at my home</a>.
</li>
<li>I do most of my heavy network lifting through wired gigabit ethernet, so I can't think of any reason I'd need the higher theoretical wireless throughput of the Netgear model.
</li>
<li>Although the Netgear has a 680 Mhz embedded CPU and 128mb RAM, the Buffalo's 400 MHz embedded CPU and 64mb of RAM is not exactly chopped liver, either; it's plenty for dd-wrt to work with. I'd almost go so far as to say the Netgear is a bit overkill… if you're into that sort of thing.
</li>
</ol>
<p>
I received my Buffalo Nfiniti and immediately installed dd-wrt on it, which was very simple and accomplished through <a href="http://dd-wrt.com/wiki/index.php/Buffalo_WZR-HP-G300NH">the existing web UI on the router</a>. (Buffalo has a history of shipping rebranded dd-wrt distributions in their routers, so the out-of-box firmware is a kissing cousin.)
</p>
<p>
After rebooting, I was in love. The (more) modern gigabit hardware, CPU, and chipset was noticably snappier everywhere, even just dinking around in the admin web pages. And <b>dd-wrt scratches <i>every geek itch I have</i></b> – putting that newer hardware to great use. Just check out the detailed stats I can get, including that pesky wireless signal strength problem. The top number is the Xbox 360 outside, the bottom number is my iPhone from about 10 feet away.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Worried your router is running low on embedded CPU grunt, or that 64 megabytes of memory is insufficient? Never fear; dd-wrt has you covered. Just check out the detailed, real time memory and cpu load stats.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Trying to figure out how much WAN/LAN/Wireless bandwidth you're using? How does a real time SVG graph, right from the router admin pages, grab you?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's just great all around. And I haven't even covered <a href="http://www.dd-wrt.com/wiki/index.php/What_is_DD-WRT%3F">the proverbial laundry list of features that dd-wrt offers</a> above and beyond most stock firmware! Suffice it to say that this is one of those times when the "let's support everything" penchant of open source projects works in our favor. Don't worry, it's all (mostly) disabled by default. Those features and tweaks can all safely be ignored; just know that they're available to you when and if you need them.
</p>
<p>
This is boring old plain vanilla commodity router hardware, but when combined with an open source firmware, it is a <i>massive</i> improvement over my three year old, proprietary high(ish) end router. The magic router formula these days is <b>a combination of commodity hardware and open-source firmware.</b> I'm so enamored of this one-two punch combo, in fact, I might even say it represents the future. Not just of the everyday workhorse routers we all need to access the internet – but the future of all commodity hardware.
</p>
<p>
Routers; we all need 'em, and they are crucial to our internet experience. Pick whichever router you like – as long as it's compatible with one of the open source firmware packages! Thanks to a wide variety of mature commodity hardware choices, plus infinitely and perpetually updated open source router firmware, I'm happy to report that <b>now everyone can have a <i>great</i> router</b>.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-09-25T01:44:38.000Z</pubDate>
<guid>https://blog.codinghorror.com/because-everyone-needs-a-router/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Keyboard Cult ]]></title>
<link>https://blog.codinghorror.com/the-keyboard-cult/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As a guy who spends most of his day <b>typing words on a screen</b>, it's hard for me to take touch computing seriously. I love my iPhone 4, and smartphones are the <a href="http://www.codinghorror.com/blog/2010/08/whats-on-your-utility-belt.html">ultimate utility belt item</a>, but attempting to compose any kind of text on the thing is absolutely <i>crippling</i>. It is a reasonable compromise for a device that fits in your pocket … but that's all.
</p>
<p>
The minute I switch back to my regular keyboard, I go from being Usain Bolt to <i>the Flash</i>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Touchscreens are great for passively browsing, as <a href="http://www.dilbert.com/blog/entry/the_amazingness_of_instant/">Scott Adams noted</a>:
</p>
<p>
</p>
<blockquote>
Another interesting phenomenon of the iPhone and iPad era is that we are being transformed from producers of content into consumers. With my BlackBerry, I probably created as much data as I consumed. It was easy to thumb-type long explanations, directions, and even jokes and observations. With my iPhone, I try to avoid creating any message that are over one sentence long. But I use the iPhone browser to consume information a hundred times more than I did with the BlackBerry. I wonder if this will change people over time, in some subtle way that isn't predictable. What happens when people become trained to think of information and entertainment as something they receive and not something they create?
</blockquote>
<p>
Because we run <a href="http://stackexchange.com/sites">an entire network of websites</a> devoted to learning by typing words on a page, it's difficult for me to get past this.
</p>
<p>
But I'm not here to decry the evils of touchscreen typing. It has its place in the pantheon of computing. <b>I'm here to sing the praises of the humble keyboard</b>. The device that, when combined with the internet, turns every human being into a highly efficient global printing press.
</p>
<p>
My love affair with the keyboard goes way back:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/2005/02/keyboarding.html">Keyboarding</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2008/11/we-are-typists-first-programmers-second.html">We Are Typists First, Programmers Second</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2009/02/have-keyboard-will-program.html">Have Keyboard, Will Program</a>
</li>
</ul>
<p>
Maybe I'm biased. As I recently <a href="http://programmers.stackexchange.com/questions/492/how-important-is-the-ability-to-touch-type/4339#4339">remarked on programmers.stackexchange.com</a>, I can't take slow typists seriously as programmers. <b>When was the last time you saw a hunt-and-peck pianist?</b>
</p>
<p>
I've been <a href="http://www.codinghorror.com/blog/2005/09/keyboarding-microsoft-natural-ergonomic-4000.html">monogamous with the Microsoft Natural Keyboard 4000</a> for a long time. But in this supposedly happy marriage, I was accidentally neglecting one of the most crucial aspects of the keyboard experience.
</p>
<blockquote>
The vast majority of keyboards included with white box systems or sold at office supply stores are <b>rubber dome or membrane keyboards</b>.
<p>
<img alt="image placeholder" >
</p>
<p>
They are inexpensive, mass produced, relatively low quality devices that are inconsistent and degrade the user experience. Most users don't know this, or simply don't care. The appeal of cheap rubber dome or membrane keyboards is that they're usually available in a variety of styles, are included "free" with a new system, and they may sport additional features like media controls or wireless connectivity. But these cheap keyboards typically don't provide users with any tactile feedback, the keys feel mushy and may not all actuate at the same point, and the entire keyboard assemblies themselves tend to flex and move around when typed on. Not fun.
</p>
</blockquote>
<p>
All this time, I've been <b>typing on keyboards with least-common-denominator rubber dome innards</b>. I was peripherally aware of higher quality mechanical keyboards, but I never appreciated them until I located this <a href="http://www.overclock.net/keyboards/491752-mechanical-keyboard-guide.html">absolutely epic mechanical keyboard guide thread</a>. It's also the source of an entire forum of people at <a href="http://geekhack.org">geekhack.org</a> who are mechanical keyboard enthusiasts. These kinds of communities and obsessions, writ so large and with such obvious passion, fascinate me. They are the inspiration for what we are trying to do with Stack Overflow and the <a href="http://stackexchange.com/sites">Stack Exchange network</a>.
</p>
<p>
If you don't have time to read <a href="http://www.overclock.net/keyboards/491752-mechanical-keyboard-guide.html">that epic guide</a> (but you should!), allow me to summarize:
</p>
<p>
</p>
<ol>
<li>Almost all computer and laptop keyboards today use <b>cheap, low quality switches</b> -- rubber dome, membrane, scissor, or foam element.
</li>
<li>
<b>Mechanical switches</b> are considered superior in every way by keyboard enthusiasts.
</li>
<li>Because the general public largely doesn't care about keyboard feel or durability, and because mechanical switches are more expensive, mechanical switch keyboards are quite rare these days.
</li>
</ol>
<p>
Mechanical switches look, well, mechanical. They're spiritually the same as those old-school arcade buttons we used to mash on in the 1980s. You push down on the key, and the switch physically actuates.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Yes, we are rapidly approaching the threshold of esoterica here. Mechanical keyboards were already becoming rare even before the internet, so I'd wager many people now reading this can't possibly know the difference between a typical cheap membrane keyboard and a fancy mechanical model because <i>they've never had the opportunity to try one!</i>
</p>
<p>
We should rectify that.
</p>
<p>
If you want to <b>dip your fingers into the world of mechanical switch keyboards</b>, start by asking yourself a few questions:
</p>
<p>
</p>
<ul>
<li>Are you willing to spend $70 to $300 for a keyboard?
</li>
<li>How noisy do you want your typing to be?
</li>
<li>Do you want a tactile "snap" when the key is depressed?
</li>
<li>How much force do you type with -- do you have a light or heavy touch?
</li>
<li>How much key travel do you want?
</li>
</ul>
Next, there are further subtleties to consider, like <i>how the keys are printed</i>:
<p>
</p>
<ul>
<li>
<b>Pad Printed</b> -- the standard cheap stuff. Little more than stickers. Keycaps will wear off fast.
</li>
<li>
<b>Laser Etched</b> -- permanent, but leaves tiny surface scars on the keys due to the characters being literally burned into the keys. May also be a tiny bit blurry.
</li>
<li>
<b>Dye Sublimated</b> -- dye set into plastic; expensive but nearly optimal.
</li>
<li>
<b>Injection Molded</b> -- two keys in different colors are physically bonded together. Very expensive but considered as close to perfect as you can get. Notably, NeXT keyboards used this method.
</li>
</ul>
<p>
And what about the shape of the keycaps? Cylindrical? Spherical? Flat? And if you're an avid keyboard gamer, you might want to consider <a href="http://en.wikipedia.org/wiki/Rollover_(key)">n-key rollover</a>, too. I warned you this rabbit hole was deep.
</p>
<p>
Let's start looking at a few likely candidates. The one you may already know is <a href="http://www.daskeyboard.com/">Das Keyboard</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Das is a good, reliable brand of mechanical keyboards. They have two primary models. Each is available in the "blank keycaps" versions if you are the sort of ninja typist who doesn't need to look at the keyboard -- you type by chanelling the Force.
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.daskeyboard.com/model-s-professional-silent/">DAS Keyboard Model S Professional silent</a>
</li>
<li>
<a href="http://www.daskeyboard.com/model-s-professional/">DAS Model S Professional</a>
</li>
</ul>
<p>
The "silent" mechanical switch distinction is an important one: <b>mechanical switches can be loud.</b> How loud? The DAS website <a href="http://store.daskeyboard.com/Reusable-Earplugs/dp/B003ALN3QE">actually sells honest-to-god earplugs as a keyboard accessory</a>. I'm sure it's <i>slightly</i> tongue in cheek. Maybe. But consider yourself warned, and choose the silent model if you aren't a fan of the clickety-clack typing.
</p>
<p>
If you want the most old-school IBM-esque experience possible, and a true classic <b>buckling spring</b> keyboard, then <a href="http://pckeyboards.stores.yahoo.net//keyboards.html">Unicomp</a> is your huckleberry. The common models are the <a href="http://pckeyboards.stores.yahoo.net//customizer.html">Customizer 104/105</a> and <a href="http://pckeyboards.stores.yahoo.net//en104bl.html">SpaceSaver 104/105</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Next up is <a href="http://elitekeyboards.com">Elite Keyboards</a>, but I can only recommend the (slightly expensive) <a href="http://elitekeyboards.com/products.php?sub=topre_keyboards,realforce&amp;pid=rf_se02b0">Topre Realforce model</a> due to the cheap pad keycap printing used on their other models.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Finally, <a href="http://www.deckkeyboards.com/">Deck Keyboards</a> -- I remember writing about these guys years ago. They have a full sized keyboard now with a lot of attention to detail: <a href="http://www.deckkeyboards.com/">The Deck Legend</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It is also the only keyboard in its class that is backlit, if that's your bag.
</p>
<p>
Of course, none of these premium fancypants mechanical switch keyboards are really <i>necessary</i>. The most important aspect of writing isn't the keyboard you use, but the simple act of <a href="http://www.codinghorror.com/blog/2006/02/fear-of-writing.html">getting out there and writing as much as you can</a>. But if, like me, you accidentally fall in love with the keyboard and everything it represents -- then I think you owe it to yourself to <b>find out what a great keyboard is <i>supposed</i> to feel like.</b>
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-10-22T16:33:12.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-keyboard-cult/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Breaking the Web's Cookie Jar ]]></title>
<link>https://blog.codinghorror.com/breaking-the-webs-cookie-jar/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The Firefox add-in <a href="http://codebutler.com/firesheep">Firesheep</a> caused quite an uproar a few weeks ago, and justifiably so. Here's how it works:
</p>
<p>
</p>
<ul>
<li>Connect to a public, <i>unencrypted</i> WiFi network. In other words, a WiFi network that doesn't require a password before you can connect to it.
</li>
<li>Install Firefox and the Firesheep add-in.
</li>
<li>Wait. Maybe have a latte while you're waiting.
</li>
<li>Click on the user / website icons that appear over time in Firesheep to <b>instantly log in as that user on that website</b>.
</li>
</ul>
<p>
Crazy! This guy who wrote Firesheep must be a world-class hacker, right?
</p>
<p>
Well, no. The work to package this up in a point-and-click way that is (sort of) accessible to power users is laudable, but what Firesheep actually <i>does</i> is far from magical. It's more of an art project and PR stunt than an actual hack of any kind. Still, I was oddly excited to see Firesheep get so much PR, <b>because it highlights a fundamental issue with the architecture of the web.</b>
</p>
<p>
The web is kind of a primitive medium. The only way websites know who you are is through tiny, uniquely identifiying strings your browser sends to the webserver on each and every click:
</p>
<p>
</p>
<pre>
GET / HTTP/1.1
Host: diy.stackexchange.com
Connection: keep-alive
User-Agent: Chrome/7.0.517.44
Accept-Language: en-US,en;q=0.8
<font color="red">Cookie: diyuser=t=ZlQOG4kege&amp;s=8VO9gjG7tU12s</font>
If-Modified-Since: Tue, 09 Nov 2010 04:41:12 GMT
</pre>
<p>
These are the typical sort of HTTP headers your browser sends to a website on every click. See that little cookie in bright red? To a website, that's your fingerprint, DNA, and social security number all rolled into one. <b>Some part of the cookie contains a unique user ID that tells the website you are <i>you</i></b>.
</p>
<p>
And guess what? That cookie is always broadcast in plain text every single time you click a link on any website. Right out in the open where anyone -- well, technically, <i>anyone who happens to be on the same network as you and is in a position to view your network packets</i> -- can just grab it out of the ether and <b>immediately impersonate you on any website you are a member of.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Now that you know how cookies work (and I'm not saying it's rocket surgery or anything), you also know that what Firesheep does is relatively straightforward:
</p>
<p>
</p>
<ol>
<li>Listen to all HTTP traffic.
</li>
<li>Wait for HTTP headers from a known website.
</li>
<li>Isolate the part of the cookie header that identifies the user.
</li>
<li>Launch a new browser session with that cookie. Bam! As far as the target webserver is concerned, you <i>are</i> that user!
</li>
</ol>
<p>
All Firesheep has to do, really, is <i>listen</i>. That's pretty much all there is to this "hack". Scary, right? Well, then you should be positively quaking in your boots, because <b>this is the way the entire internet has worked since 1994</b>, when <a href="http://en.wikipedia.org/wiki/HTTP_cookie#History">cookies were invented</a>.
</p>
<p>
So why wasn't this a problem in, say, 2003? Three reasons:
</p>
<p>
</p>
<ol>
<li>Commodity public wireless internet connections were not exactly common until a few years ago.
</li>
<li>Average people have moved beyond mostly anonymous browsing and transferred significant parts of their identity online (aka the Facebook effect).
</li>
<li>The tools required to listen in on a wireless network are slightly … less primitive now.
</li>
</ol>
<p>
Firesheep came along at the exact inflection point of these three trends. And mind you, it is still not a sure thing -- Firesheep requires a particular set of wireless network chipsets that support <a href="http://en.wikipedia.org/wiki/Promiscuous_mode">promiscuous mode</a> in the lower level WinPcap library that Firesheep relies on. But we can bet that the floodgates have been opened, and future tools similar to this one will become increasingly a one-click affair.
</p>
<p>
The other reason this wasn't a problem in 2003 is because <b>any website that truly <i>needed</i> security switched to encrypted HTTP -- aka <a href="http://en.wikipedia.org/wiki/HTTP_Secure">Secure HTTP</a> -- long ago</b>. HTTPS was invented in 1994, at the same time as the browser cookie. This was not a coincidence. The creators of the cookie knew from day one they needed a way to protect them from prying eyes. Even way, way back in the dark, primitive ages of 2003, any banking website or identity website worth a damn wouldn't even <i>consider</i> using plain vanilla HTTP. They'd be laughed off the internet!
</p>
<p>
The outpouring of concern over Firesheep is justified, because, well, the web's cookie jar has always been kind of broken -- and we ought to do something about it. But what?
</p>
<p>
Yes, <b>you can naively argue that every website should encrypt all their  traffic all the time</b>, but to me that's a "boil the sea" solution. I'd rather see a better, more secure identity protocol than ye olde HTTP cookies. I don't actually care if anyone sees the rest of my public activity on Stack Overflow; it's hardly a secret. But gee, I sure <i>do</i> care if they <a href="http://www.codinghorror.com/blog/2008/08/protecting-your-cookies-httponly.html">somehow sniff out my cookie and start running around doing stuff as me!</a> Encrypting everything just to protect that one lousy cookie header seems like a whole lot of overkill to me.
</p>
<p>
I'm not holding my breath for that to happen any time soon, though. So here's what you can do to protect yourself, right now, today:
</p>
<p>
</p>
<ol>
<li>
<b>We should be very careful how we browse on unencrypted wireless networks</b>. This is the great gift of Firesheep to all of us. If nothing else, we should be thanking the author for this simple, stark warning. It's an unavoidable fact of life: if you must go wireless, seek out <i>encrypted</i> wireless networks. If you have no other choices except unencrypted wireless networks, browse anonymously -- quite possible if all you plan to do is casually surf the web and read a few articles -- and <i>only</i> log in to websites that support https. Anything else risks identity theft.
</li>
<li>
<b>Get in the habit of accessing your web mail through HTTPS</b>. Email is <a href="http://www.codinghorror.com/blog/2008/06/please-give-us-your-email-password.html">the de-facto skeleton key to your online identity</a>. When your email is compromised, all is lost. If your webmail provider does not support secure http, they are idiots. Drop them like a hot potato and <i>immediately</i> switch to one that does. Heck, the smart webmail providers <a href="http://gmailblog.blogspot.com/2010/01/default-https-access-for-gmail.html">already switched to https by default!</a>
</li>
<li>
<b>Lobby the websites you use to offer HTTPS browsing</b>. I think we're clearly past the point where only banks and finance sites should be expected to use secure HTTP. As more people shift more of their identities online, it makes sense to protect those identities by moving HTTPS from the domain of a massive bank vault door to just plain <i>locking the door</i>. <a href="http://www.imperialviolet.org/2010/06/25/overclocking-ssl.html">SSL isn't as expensive as it used to be</a>, in every dimension of the phrase, so this is not an unreasonable thing to ask your favorite website for.
</li>
</ol>
<p>
This is very broad advice, and there are a whole host of technical caveats to the above. But it's a starting point toward evangelizing the risks and responsible use of open wireless networks. Firesheep may indeed have broken the web's cookie jar. But it was kind of an old, beat up, cracked cookie jar in the first place. I hope the powers that be will use Firesheep as incentive to <b>build a better online identity solution than creaky old HTTP cookies</b>.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-11-13T23:34:45.000Z</pubDate>
<guid>https://blog.codinghorror.com/breaking-the-webs-cookie-jar/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Your Internet Driver's License ]]></title>
<link>https://blog.codinghorror.com/your-internet-drivers-license/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Back in summer 2008 when we were building Stack Overflow, I chose OpenID logins for reasons documented in <a href="http://www.codinghorror.com/blog/2008/05/openid-does-the-world-really-need-yet-another-username-and-password.html">Does The World Really Need Yet Another Username and Password</a>:</p>
<blockquote>
<p>I realize that OpenID is far from an ideal solution. But right now, the one-login-per-website problem is so bad that I am willing to accept these tradeoffs for a partial <a href="http://www.codinghorror.com/blog/archives/001046.html">worse is better</a> solution. There's absolutely no way I'd put my banking credentials behind an OpenID. But there are also dozens of sites that I don't need anything remotely approaching banking-grade security for, and I use these sites far more often than my bank. The <a href="http://www.codinghorror.com/blog/2006/03/the-login-explosion.html">collective pain of remembering all these logins</a> -- and the way my email inbox becomes a de-facto collecting point and <a href="http://www.codinghorror.com/blog/2008/06/please-give-us-your-email-password.html">security gateway</a> for all of them -- is substantial.</p>
</blockquote>
<p>It always pained me greatly that <b>every rinky-dink website on the entire internet demanded that I create a special username and password <i>just for them</i></b>. Yes, if you're an alpha geek, then you probably use a combination of special software and USB key from your <a href="http://www.codinghorror.com/blog/2010/08/whats-on-your-utility-belt.html">utility belt</a> to generate secure usernames and passwords for the dozens of websites you frequent. But for the vast, silent majority of normals, who know nothing of security but desire convenience above all, this means one thing: <i>using the same username and password over and over</i>. And it's <a href="http://www.codinghorror.com/blog/2009/01/dictionary-attacks-101.html">probably a simple password</a>, too.</p>
<p>This is the status quo of identity on the internet. It is deeply and fundamentally broken.</p>
<p>But it doesn't have to be this way. If you <a href="http://www.codinghorror.com/blog/2009/04/optimizing-your-wallet.html">open your wallet</a> (or purse, or man-purse, or whatever), I bet you'll find a variety of credentials you use to prove your identity wherever you go.</p>
<p><a href="http://www.flickr.com/photos/joits/31346894/"><img alt="image placeholder" >
<p>The average wallet contains a few different forms of identity with varying strengths:</p>
<ul>
<li>Strong: California driver's license, student ID</li>
<li>Moderate: credit cards, health insurance card, video rental membership, gym card</li>
<li>Weak: Albertson's Preferred Card, Best Buy Rewards Zone Card, Coffee loyalty card</li>
</ul>
<p>(and sometimes even, uh, cards for free lapdances, apparently)</p>
<p><b>In the real world, we don't regularly hold two dozen forms of identity like we expect people to on the web.</b> Not only would you be carrying around the <a href="http://www.seinology.com/scripts/script-168.shtml">freaking Constanza wallet</a> at that point, it would be <i>insane</i>. In the real world, we somehow manage to get by with about two or three strong forms of identity, complemented by a few other weaker forms to taste.</p>
<p>I'm proposing that our web wallets begin to mimic our physical wallets. <b>Whenever a website needs to know who I am, they should ask to see my Internet Driver's License.</b></p>
<img alt="image placeholder" >
<p>Now, I don't <i>literally</i> mean a driver's license. I'm using this term figuratively to mean online credentials that I can re-use in more than one place on the internet. If all I want to do is leave a comment on a blog -- like, say, <a href="http://www.codinghorror.com/blog/2010/02/welcome-back-comments.html"><i>this one</i></a> -- then one of the weaker forms of identity will surely do. If I'm starting a new bank account, or setting up a profile on a dating website, then maybe a stronger credential from my virtual wallet is necessary.</p>
<p>The core concept that users need to get used to is <b>logging in to a website by showing a third party credential</b> to validate their identity. This idea isn't nearly as crazy as it seemed in 2008. How many websites can you log into by showing your Facebook, Google, or Twitter credentials now? <i>Lots!</i></p>
<img alt="image placeholder" >
<p>The whole online identity situation may seem as impossible as peace in the Middle East at this point. But when faced with a problem that appears intractable, is your solution to throw your hands up, mindlessly embrace the status quo, and wearily sigh <i>"whaddaya gonna do?"</i></p>
<p>Some people do that. It's their right. Personally, I prefer to <b>be the change I want to see</b>. So for us, on Stack Overflow and the <a href="http://stackexchange.com/">Stack Exchange network</a>, that means <i>aggressively promoting the concept of the Internet Driver's License</i>. Including educating users as necessary.</p>
<p>For example, consider this ATM machine. To use it, <b>do I need to sign up for an account at Shanghai Peking Development Bank?</b> No. I can use any form of trusted third-party credentials the machine supports.</p>
<img alt="image placeholder" >
<p>Similarly, to log into <a href="http://stackexchange.com/">any Stack Exchange site</a>, including Stack Overflow, <b>present any OpenID or OAuth 2.0 compliant identity provider as your Internet Driver's License.</b></p>
<img alt="image placeholder" >
<p>When we founded Stack Overflow, we set out with the explicit mission to make the internet better. Adding yet another meaningless username and password to the fabric of the web does not make it better. <b>What <i>does</i> make the internet better is continued pursuit of better, simpler, re-usable forms of third party online identity.</b></p>
<p>That's why I urge you to join me in supporting <a href="http://openid.net/">OpenID</a>, <a href="http://wiki.oauth.net/w/page/25236487/OAuth-2">OAuth 2.0</a>, and any other promising implementations of the Internet Driver's License.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-11-24T01:55:02.000Z</pubDate>
<guid>https://blog.codinghorror.com/your-internet-drivers-license/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ My Holiday in Beautiful Panau ]]></title>
<link>https://blog.codinghorror.com/my-holiday-in-beautiful-panau/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
There is a high correlation between "programmer" and "gamer". One of the first <a href="http://area51.stackexchange.com/">Area 51 sites</a> we launched, based on community demand, was <a href="http://gaming.stackexchange.com/">gaming.stackexchange.com</a>. Despite my fundamental skepticism about gaming as a Q&amp;A topic -- as expressed on <a href="http://herdingcode.com/?p=263">episode 87 of Herding Code</a> -- I have to admit it has <i>far</i> exceeded my expectations.
</p>
<p>
But then maybe I shouldn't be so surprised. I've talked about the relationship between gamer and programmer before:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/2007/08/programming-games-analyzing-games.html">Programming Games, Analyzing Games</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2008/04/everything-i-needed-to-know-about-programming-i-learned-from-basic.html">Everything I Needed to Know About Programming I Learned from BASIC</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2006/08/game-player-game-programmer.html">Game Player, Game Programmer</a>
</li>
</ul>
<p>
I used to recommend games on this very blog that I particularly enjoyed and felt were worthy of everyone's attention. I don't do this a lot any more, now that my blogging schedule has slipped to one post a week, if I'm lucky. (If you're wondering why, it's because running your own business is <i>crazy stupid</i> amounts of work when you <a href="http://blog.stackoverflow.com/2010/05/announcing-our-series-a/">turn it up to eleven</a>.) Here are a few games I've recommended in the past:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/2005/11/guitar-hero-are-you-ready-to-rock.html%20">Guitar Hero: Are You Ready to Rock?</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2006/02/darwinia.html">Darwinia</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2006/10/defcon-shall-we-play-a-game.html">DEFCON: Shall We Play a Game?</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2006/09/company-of-heroes.html">Company of Heroes</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2007/11/living-the-dream-rock-band.html">Living the Dream: Rock Band</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2008/11/feeding-my-graphics-card-addiction.html">Feeding my Graphics Card Addiction (Fallout 3)</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/2008/12/my-software-is-being-pirated.html">My Software is Being Pirated (World of Goo)</a>
</li>
</ul>
<p>
I haven't had a ton of time to play games, other than <a href="http://www.fakeplasticrock.com/2010/10/the-ultimate-rock-band-3-setup/">the inevitable Rock Band 3</a>, but I've been consumed by another game I had no idea would become so addictive -- <a href="http://www.justcause.com/home">Just Cause 2</a>.
</p>
<p>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=%22just%20cause%202%22&amp;tag=codihorr-20&amp;index=videogames&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325"><img alt="image placeholder" >
</p>
<p>
It's what you might call <b>an open world sandbox game</b>, in the vein of the Grand Theft Autos. But I could never get into the GTA games, even after trying GTA 3 and its sequels Vice City and San Andreas. They just left me cold, somehow.
</p>
<p>
Where GTA and its ilk often felt a tad too much like work for my tastes, Just Cause 2 is almost the opposite -- it is non-stop, full blown open world pandemonium from start to finish. One of the game's explicit goals is that <b>you advance the plot by <i>blowing stuff up</i></b>. No, seriously. I'm not kidding. You have an entire 1000+ square kilometer island paradise at your disposal, filled with cities and military bases, spanning the range from snowy mountains to deserts to idyllic beaches -- all just waiting for you to turn them into "chaos points" … by any means necessary.
</p>
<p>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=%22just%20cause%202%22&amp;tag=codihorr-20&amp;index=videogames&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325"><img alt="image placeholder" >
</p>
<p>
Of course, you get around by hijacking whatever vehicles happen by, be they boats, airplanes, jumbo jets, cars, tanks, trucks, buses, monster trucks, motorcycles, scooters, tractors or anything in between. Even <i>on foot</i> it is fun to navigate the island of Panau, because the developers gave us an <b>impossibly powerful personal zipline</b> that you can fire at any object in the game to propel yourself toward it. Combine that with the magical parachute you can deploy anywhere, anytime, and they make for some fascinating diversions (parasailing anyone?). You can also use the zipline to attach any two objects together. Think about that for a second. Have you ever wondered what happens when you zipline a moving vehicle to a tree? Or a pedestrian? Or another vehicle? Hmm. As a result, simply going walkabout on the island is <a href="http://www.rockpapershotgun.com/2010/04/02/postcards-from-panau/">more fun than I ever would have imagined</a>.
</p>
<p>
Between the 49 plot missions, 9 stronghold takeovers, 104 unique vehicles, the optional boat/plane/car/parachute race missions,the <a href="http://www.youtube.com/watch?v=nqLNLOaOXbk">opportunities</a> for <a href="http://www.youtube.com/watch?v=ZHlJ7DCdkzw">insane stunt</a> points, the umpteen zillion upgrade crates and faction objects to collect, and the 360+ locations in the 1000+ square kilometers of Panau -- there's always something interesting happening around every corner. And whatever it is, it's probably beautiful and <i>blows up real good</i>.
</p>
<p>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=%22just%20cause%202%22&amp;tag=codihorr-20&amp;index=videogames&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325"><img alt="image placeholder" >
</p>
<p>
In short, <b>Just Cause 2 is deliriously, stupidly, absurdly entertaining</b>. I can't even remember the last game I completed where I felt compelled to go back after finishing the main storyline to discover even more areas I missed during my initial playthrough and get (most of) the in-game achievements. Whatever amount of time you have to play, Just Cause 2 will happily fill it with totally unscripted, awesome open world pandemonium.
</p>
<p>
Don't take my word for it; even the notoriously acidic game reviewer Yahtzee <a href="http://www.escapistmagazine.com/videos/view/zero-punctuation/1632-Just-Cause-2">had almost nothing negative to say about Just Cause 2</a>, which is his version of a positive review. And Metacritic gives Just Cause 2 a <a href="http://apps.metacritic.com/games/platforms/pc/justcause2">solid 84</a>. Not that it can't be improved, of course; after such a sublime sandbox experience, I'm desperately curious to see what they'll add for Just Cause 3.
</p>
<p>
Luckily for you, the game has been out long enough that it can be <b>picked up for a song on PS3, Xbox, or PC</b>. Steam has <a href="http://store.steampowered.com/app/8190/">Just Cause 2 on sale right now</a> in an 8 player pack for $60, and <a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=%22just%20cause%202%22&amp;tag=codihorr-20&amp;index=videogames&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">Amazon has all versions in stock for under $30</a>. Beware, though, as the PC version does require a pretty solid video card along with Windows Vista or newer -- but the upside is that I have mine cranked up to 2048x1152 with almost all the options on, and it rarely dips below 60 fps.
</p>
<p>
<b>I spent my holidays on the beautiful island of Panau, and I don't regret a second of it.</b> If you're looking for a vacation spot, I heartily recommend the open world sandbox of Panau. But while you're visiting, <i>do</i> be mindful of any errant gunfire, vehicles, and explosions.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2010-11-28T21:25:07.000Z</pubDate>
<guid>https://blog.codinghorror.com/my-holiday-in-beautiful-panau/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Dirty Truth About Web Passwords ]]></title>
<link>https://blog.codinghorror.com/the-dirty-truth-about-web-passwords/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>This weekend, <b>the Gawker network was compromised</b>.</p>
<blockquote>
This weekend we discovered that Gawker Media's servers were compromised, resulting in a security breach at Lifehacker, Gizmodo, Gawker, Jezebel, io9, Jalopnik, Kotaku, Deadspin, and Fleshbot. If you're a commenter on any of our sites, you probably have several questions.
</blockquote>
<p>It's no <a href="http://www.codinghorror.com/blog/2008/05/revisiting-the-black-sunday-hack.html">Black Sunday</a> or <a href="http://www.codinghorror.com/blog/2005/02/ipod-hacking-via-modem.html">iPod modem firmware hack</a>, but it has <em>release notes</em> – and the story it tells is as epic as Beowulf:</p>
<blockquote>
So, here we are again with a monster release of ownage and data droppage. Previous attacks against the target were mocked, so we came along and raised the bar a little. How's this for "script kids"? Your empire has been compromised, your servers, your databases, online accounts and source code have all been ripped to shreds!<br><br>
You wanted attention, well guess what, You've got it now!
</blockquote>
<p><a href="http://www.codinghorror.com/blog/gawker-hack-release-notes.html">Read those release notes</a>. It'll explain how the compromise unfolded, blow by blow, from the inside.</p>
<p>Gawker is operated by Nick Denton, notorious for the unapologetic and often unethical "publish whatever it takes to get traffic" methods endorsed on his network. Do you remember the <a href="http://www.fastcompany.com/1621516/iphone-leak-iphone-4-apple-gizmodo">iPhone 4 leak</a>? That was Gawker. Do you remember the article about <a href="http://www.newyorker.com/reporting/2010/10/18/101018fa_fact_mcgrath">bloggers being treated as virtual sweatshop workers</a>? That was Gawker. Do you remember hearing about a blog lawsuit? <a href="http://www.google.com/search?q=gawker+lawsuit">That was probably Gawker, too</a>.</p>
<p>Some might say having every account on your network compromised is <em>exactly</em> the kind of unwanted publicity attention that Gawker was founded on.</p>
<p>Personally, I'm more interested in <b>how we can learn from this hack</b>. Where did Gawker go wrong, and how can we avoid making those mistakes on <i>our</i> projects?</p>
<ol>
<li>
<b>Gawker saved passwords</b>. You should never, <i>ever</i> store user passwords. If you do, <a href="http://www.codinghorror.com/blog/2007/09/youre-probably-storing-passwords-incorrectly.html">you're storing passwords incorrectly</a>. Always store the <a href="http://www.codinghorror.com/blog/2007/09/rainbow-hash-cracking.html">salted hash</a> of the password – <i>never</i> the password itself! It's so easy, even <a href="http://www.codinghorror.com/blog/2008/06/smart-enough-not-to-build-this-website.html">members of Mensa</a> er … can't … figure it out.<br><br>
</li>
<li>
<b>Gawker used encryption incorrectly</b>. The odd choice of archaic DES encryption meant that the passwords they saved were all truncated to 8 characters. No matter how long your password actually <i>was</i>, you only had to enter the first 8 characters for it to work. So much for <a href="http://www.codinghorror.com/blog/2005/08/passphrase-evangelism.html">choosing a secure pass phrase</a>. Encryption is only as effective as the person using it. I'm not smart enough to use encryption, either, as you can see in <a href="http://www.codinghorror.com/blog/2009/05/why-isnt-my-encryption-encrypting.html">Why Isn't My Encryption.. Encrypting?</a><br><br>
</li>
<li>
<b>Gawker asked users to create a username and password on their site</b>. The FAQ they posted about the breach has <a href="http://lifehacker.com/5712785/#2">two interesting clarifications</a>:
<blockquote>
<i>2) What if I logged in using Facebook Connect? Was my password compromised?</i><br>
<b>No.</b> We never stored passwords of users who logged in using Facebook Connect.<br><br>
<i>3) What if I linked my Twitter account with my Gawker Media account? Was my Twitter password compromised?</i><br>
<b>No.</b> We never stored Twitter passwords from users who linked their Twitter accounts with their Gawker Media account.
</blockquote>
<p>That's right, people who used their <a href="http://www.codinghorror.com/blog/2010/11/your-internet-drivers-license.html">internet driver's license</a> to authenticate on these sites <i>had no security problems at all!</i> Does the need to post a comment on Gizmodo really <i>justify</i> polluting the world with <a href="http://www.codinghorror.com/blog/2008/05/openid-does-the-world-really-need-yet-another-username-and-password.html">yet another username and password?</a> It's only the poor users who decided to entrust Gawker with a unique username and 'secure' password who got compromised.</p>
</li>
</ol>
<p>(Beyond that, "don't be a jerk" is good advice to follow in  business as well as your personal life. I find that you generally get back what you give. When your corporate mission is to succeed by exploiting every quasi-legal trick in the book, surely you can't be surprised when you get the same treatment in return.)</p>
<p>But honestly, as much as we can point and laugh at Gawker and blame them for this debacle, there is absolutely nothing unique or surprising about any of this. Regular readers of my blog are probably bored out of their minds by now because I just trotted out a whole bunch of blog posts I wrote 3 years ago. <a href="http://www.codinghorror.com/blog/2006/03/the-value-of-repetition-again.html">Again</a>.</p>
<p><b>Here's the dirty truth about website passwords: the internet is full of websites exactly like the Gawker network</b>. Let's say you have good old traditional username and passwords on 50 different websites. That's 50 different programmers who all have different ideas of how your password should be stored. I hope for your sake you used a different (and extremely secure) password on every single one of those websites. Because <i>statistically speaking, you're screwed</i>.</p>
<p>In other words, the more web sites you visit, the more networks you touch and trust with a username and password combination – the greater the odds that at least <i>one</i> of those networks will be <b>compromised exactly like Gawker was</b>, and give up your credentials for the world to see. At that point, unless you picked a strong, unique password on every single site you've ever visited, the situation gets ugly.</p>
<p>The bad news is that most users don't pick strong passwords. This has been proven <a href="http://www.codinghorror.com/blog/2009/01/dictionary-attacks-101.html">time and time again</a>, and the Gawker data is <a href="http://blogs.wsj.com/digits/2010/12/13/the-top-50-gawker-media-passwords/">no different</a>. Even worse, most users re-use these bad passwords across multiple websites. That's how <a href="http://mashable.com/2010/12/13/acai-berry-twitter-worm-warning/">this ugly Twitter worm</a> suddenly appeared on the back of a bunch of compromised Gawker accounts.</p>
<p><a href="http://xkcd.com/792/"><img alt="image placeholder" >
<p>Now do you understand why I've been so aggressive about promoting the concept of the <a href="http://www.codinghorror.com/blog/2010/11/your-internet-drivers-license.html">internet driver's license</a>? That is, logging on to a web site using a set of <b>third party credentials from a company you can actually trust</b> to not be utterly incompetent at security? Sure, we're centralizing risk here to, say, Google, or Facebook – but I trust Google a heck of a lot more than I trust J. Random Website, and this really is no different in practice than having password recovery emails sent to your GMail account.</p>
<p>I'm not here to criticize Gawker. On the contrary, I'd like to thank them for illustrating in broad, bold relief the dirty truth about website passwords: we're all better off without them. If you'd like to see a future web free of Gawker style password compromises – <b>stop trusting every random internet site with a unique username and password!</b> Demand that they allow you to use your internet driver's license – that is, your existing Twitter, Facebook, Google, or OpenID credentials – to log into their website.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2010-12-14T06:51:48.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-dirty-truth-about-web-passwords/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Trouble In the House of Google ]]></title>
<link>https://blog.codinghorror.com/trouble-in-the-house-of-google/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Let's look at <a href="http://blog.stackoverflow.com/2010/12/stack-overflow-2010-analytics/">where stackoverflow.com traffic came from for the year of 2010</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>When 88.2% of all traffic for your website comes from a single source</b>, criticizing that single source feels … <i>risky</i>. And perhaps a bit churlish, like looking a gift horse in the mouth, or saying something derogatory in public about your Valued Business Partner<sup>tm</sup>.
</p>
<p>
Still, looking at the statistics, it's hard to avoid the obvious conclusion. I've been told many times that Google isn't a monopoly, but they apparently <a href="http://www.codinghorror.com/blog/2009/02/the-elephant-in-the-room-google-monoculture.html">play one on the internet</a>. You are perfectly free to switch to whichever non-viable alternative web search engine you want at any time. Just breathe in that sweet freedom, folks.
</p>
<p>
Sarcasm aside, I greatly admire Google. My goal is not to be acquired, because <a href="http://www.codinghorror.com/blog/2009/01/overnight-success-it-takes-years.html">I'm in this thing for the long haul</a> – but if I <i>had</i> to pick a company to be acquired by, it would probably be Google. I feel their emphasis on the information graph over the social graph aligns more closely with our mission than almost any other potential suitor I can think of. Anyway, we've been perfectly happy with Google as our de-facto traffic sugar daddy since the beginning. But last year, something strange happened: <b>the content syndicators began to regularly outrank us in Google for our own content</b>.
</p>
<p>
Syndicating our content is not a problem. In fact, it's encouraged. It would be deeply unfair of us to assert ownership over the content so generously contributed to our sites and create an <a href="http://www.codinghorror.com/blog/2009/08/are-you-a-digital-sharecropper.html">underclass of digital sharecroppers</a>. Anything posted to Stack Overflow, or any <a href="http://stackexchange.com/sites">Stack Exchange Network site</a> for that matter, is licensed back to the community in perpetuity under <a href="http://creativecommons.org/licenses/by-sa/2.5/">Creative Commons cc-by-sa</a>. The community owns their contributions. We want <i>the whole world</i> to teach each other and learn from the questions and answers posted on our sites. Remix, reuse, share – and teach your peers! That's our mission. That's why I get up in the morning.
</p>
<p>
<a href="http://startupquote.com/post/2163563107">
<img alt="image placeholder" >
</a>
</p>
<p>
However, implicit in this strategy was the assumption that we, as the canonical source for the original questions and answers, would always rank first. Consider Wikipedia – <b>when was the last time you clicked through to a page that was nothing more than a legally copied, properly attributed Wikipedia entry encrusted in advertisements?</b> Never, right? But it is in theory a completely valid, albeit dumb, business model. That's why Joel Spolsky and I were confident in sharing content back to the community with almost no reservations – because Google mercilessly penalizes sites that attempt to game the system by unfairly profiting on copied content. Remixing and reusing is fine, but mass-producing cheap copies encrusted with ads … isn't.
</p>
<p>
I think of this as common sense, but it's also spelled out explicitly in <a href="http://www.google.com/support/webmasters/bin/answer.py?answer=66361">Google's webmaster content guidelines</a>.
</p>
<p>
</p>
<blockquote>
However, some webmasters attempt to improve their page's ranking and attract visitors by creating pages with many words but little or no authentic content. <b>Google will take action against domains that try to rank more highly by just showing scraped or other auto-generated pages that don't add any value to users.</b> Examples include:
<p>
Scraped content. Some webmasters make use of content taken from other, more reputable sites on the assumption that increasing the volume of web pages with random, irrelevant content is a good long-term strategy. Purely scraped content, even from high-quality sources, may not provide any added value to your users without additional useful services or content provided by your site. It's worthwhile to take the time to create original content that sets your site apart. This will keep your visitors coming back and will provide useful search results.
</p>
</blockquote>
<p>
In 2010, our mailboxes suddenly started overflowing with complaints from users – complaints that they were doing perfectly reasonable Google searches, and ending up on scraper sites that mirrored Stack Overflow content with added advertisements. Even worse, in some cases, the original Stack Overflow question was nowhere to be found in the search results! That's <i>particularly</i> odd because our attribution terms require linking directly back to us, the canonical source for the question, without nofollow. Google, in indexing the scraped page, cannot avoid seeing that the scraped page links back to the canonical source. This culminated in, of all things, <a href="http://hackerne.ws/item?id=1985264">a special browser plug-in that redirects to Stack Overflow from the ripoff sites</a>. How totally depressing. Joel and I thought this was impossible. And I felt like I had personally failed all of you.
</p>
<p>
The idea that there could be something wrong with Google was inconceivable to me. Google is gravity on the web, an omnipresent constant; <b>blaming Google would be like blaming gravity for my own clumsiness.</b> It wasn't even an option. I started with the golden rule: <a href="http://www.codinghorror.com/blog/2008/03/the-first-rule-of-programming-its-always-your-fault.html">it's always my fault</a>. We did a ton of due diligence on <a href="http://webmasters.stackexchange.com/">webmasters.stackexchange.com</a> to ensure we weren't doing anything overtly stupid, and uber-mensch <a href="http://www.mattcutts.com/blog/">Matt Cutts</a> went out of his way to investigate the hand-vetted search examples contributed in response to my tweet asking for search terms where the scrapers dominated. Issues were found on both sides, and <a href="http://webmasters.stackexchange.com/questions/6556/does-the-order-of-keywords-matter-in-a-page-title">changes were made</a>. Success!
</p>
<p>
Despite the semi-positive resolution, I was disturbed. If these dime-store scrapers were doing so well and generating so much traffic on the back of our content – how was the rest of the web faring? My enduring faith in the gravitational constant of Google had been shaken. Shaken to the very core.
</p>
<p>
Throughout my investigation I had nagging doubts that we were seeing <b>serious cracks in the algorithmic search foundations of the house that Google built</b>. But I was afraid to write an article about it for fear I'd be claimed an incompetent kook. I wasn't comfortable sharing that opinion widely, because we might be doing something obviously wrong. Which we tend to do frequently and often. <i>Gravity can't be wrong. We're just clumsy … right?</i>
</p>
<p>
I can't help noticing that we're not the only site to have serious problems with Google search results in the last few months. In fact, the drum beat of deteriorating Google search quality has been practically <i>deafening</i> of late:
</p>
<p>
</p>
<ul>
<li>
<a href="http://techcrunch.com/2011/01/01/why-we-desperately-need-a-new-and-better-google-2/">Why We Desperately Need a New (and Better) Google</a>
</li>
<li>
<a href="http://paul.kedrosky.com/archives/2009/12/dishwashers_dem.html">Dishwashers, and How Google Eats Its Own Tail</a>
</li>
<li>
<a href="http://www.readwriteweb.com/archives/content_farms_impact.php">Content Farms: Why Media, Blogs &amp; Google Should Be Worried</a>
</li>
<li>
<a href="http://broadstuff.com/archives/2370-On-the-increasing-uselessness-of-Google......html">On the increasing uselessness of Google</a>
</li>
<li>
<a href="http://shoeblogs.com/2010/12/20/google-google-why-hast-thou-forsaken-the-manolo/#more-13002">Google, Google, Why Hast Thou Forsaken the Manolo?</a>
</li>
</ul>
<p>
Anecdotally, my personal search results have also been noticeably worse lately. As part of Christmas shopping for my wife, I searched for "iPhone 4 case" in Google. I had to give up completely on the first two pages of search results as utterly useless, and searched Amazon instead.
</p>
<p>
People whose opinions I respect have all been echoing the same sentiment -- <b>Google, the once essential tool, is somehow losing its edge. The spammers, scrapers, and SEO'ed-to-the-hilt content farms are winning.</b>
</p>
<p>
Like any sane person, I'm rooting for Google in this battle, and I'd love nothing more than for Google to tweak a few algorithmic knobs and make this entire blog entry moot. Still, this is the first time since 2000 that I can recall Google search quality ever <i>declining</i>, and it has inspired some rather heretical thoughts in me -- are we seeing the first signs that algorithmic search has failed as a strategy? Is the next generation of search destined to be less algorithmic and more social?
</p>
<p>
It's a scary thing to even entertain, but <i>maybe gravity really is broken</i>.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-01-03T03:36:32.000Z</pubDate>
<guid>https://blog.codinghorror.com/trouble-in-the-house-of-google/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ 24 Gigabytes of Memory Ought to be Enough for Anybody ]]></title>
<link>https://blog.codinghorror.com/24-gigabytes-of-memory-ought-to-be-enough-for-anybody/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Are you familiar with this quote?
</p>
<p>
</p>
<blockquote>
640K [of computer memory] ought to be enough for anybody. — Bill Gates
</blockquote>
<p>
It's amusing, but <a href="http://en.wikiquote.org/wiki/Bill_Gates#Misattributed">Bill Gates never actually said that</a>:
</p>
<p>
</p>
<blockquote>
I've said some stupid things and some wrong things, but not that. No one involved in computers would ever say that a certain amount of memory is enough for all time … I keep bumping into that silly quotation attributed to me that says 640K of memory is enough. There's never a citation; the quotation just floats like a rumor, repeated again and again.
</blockquote>
<p>
One of the few killer features of the <a href="http://www.codinghorror.com/blog/2009/12/building-a-pc-part-vi-rebuilding.html">otherwise unexciting Intel Core i7 platform upgrade</a>* is the subtle fact that Core i7 chips use <b>triple channel memory</b>. That means three memory slots at a minimum, and in practice most Core i7 motherboards have six memory slots.
</p>
<p>
The price of DDR3 ram has declined to the point that populating <b>all six slots</b> of memory with 4 GB memory is, well, not cheap -- but <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16820231357">quite attainable at $299 and declining</a>.
</p>
<p>
<a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16820231357"><img alt="image placeholder" >
</p>
<p>
Twenty-four gigabytes of system memory for a mere $299! That's about $12.50 per gigabyte.
</p>
<p>
(And if you don't have a Core i7 system, they're not expensive to build, either. You can pair an <a href="http://www.jdoqocy.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16813157163%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Motherboards%2B-%2BIntel-_-ASRock-_-13157163&amp;cjsku=N82E16813157163">inexpensive motherboard</a> with even the slowest and cheapest triple channel compatible <a href="http://www.newegg.com/Product/Product.aspx?Item=N82E16819115211">i7-950</a>, which is plenty speedy – and overclocks well, if you're into that. Throw in the 24 GB of ram, and it all adds up to about $800 total. Don't forget the power supply and CPU cooler, though.)
</p>
<p>
Remember when <i>one</i> gigabyte of system memory was considered a lot? For context, <a href="http://blog.stackoverflow.com/2009/01/new-stack-overflow-server-glamour-shots/">our first "real" Stack Overflow database server</a> had 24 GB of memory. Now I have that much in my desktop … just because I can. Well, that's not <i>entirely</i> true, as we do work with some sizable databases while building the <a href="http://stackexchange.com/sites">Stack Exchange network</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I guess having 24 gigabytes of system memory is a little extravagant, but at these prices -- why not? What's the harm in having obscene amounts of memory, making my system effectively future proof?
</p>
<p>
</p>
<blockquote>
I have to say that in 1981, making those decisions, I felt like I was providing enough freedom for 10 years. That is, a move from 64k to 640k felt like something that would last a great deal of time. Well, it didn't – it took about only 6 years before people started to see that as a real problem. — <a href="http://en.wikiquote.org/wiki/Bill_Gates#RAM1989">Bill Gates</a>
</blockquote>
<p>
To me, it's more about no longer needing to <i>think</i> about memory as a scarce resource, something you allocate carefully and manage with great care. There's just .. <i>lots</i>. As <a href="http://www.codinghorror.com/blog/2008/05/its-clay-shirkys-internet-we-just-live-in-it.html">Clay Shirky</a> once related to me, via one of his college computer science professors:
</p>
<p>
</p>
<blockquote>
Algorithms are for people who don't know how to buy RAM.
</blockquote>
<p>
I mean, 24 GB of memory should be enough for anybody… right?
</p>
<p>
<small>* it's only blah on the <i>desktop</i>; on the server <a href="http://blog.stackoverflow.com/2010/10/database-upgrade/">the Nehalem architecture is indeed a monster</a> and anyone running a server should upgrade to it, stat.</small>
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-01-20T21:50:24.000Z</pubDate>
<guid>https://blog.codinghorror.com/24-gigabytes-of-memory-ought-to-be-enough-for-anybody/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Lived Fast, Died Young, Left a Tired Corpse ]]></title>
<link>https://blog.codinghorror.com/lived-fast-died-young-left-a-tired-corpse/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's easy to forget just <b>how crazy things got during the Web 1.0 bubble in 2000</b>. That was over ten years ago. For context, <a href="http://en.wikipedia.org/wiki/Mark_Zuckerberg">Mark Zuckerberg</a> was all of <i>sixteen</i> when the original web bubble popped.
</p>
<p>
<a href="http://finance.yahoo.com/echarts?s=%5EIXIC+Interactive#chart2:symbol=%5Eixic"><img alt="image placeholder" >
</p>
<p>
There's plenty of evidence that <a href="http://www.avc.com/a_vc/2010/11/pacing-yourself.html">we're entering <i>another</i> tech bubble</a>. It's just less visible to people outside the tech industry because there's no corresponding stock market IPO frenzy. <i>Yet.</i>
</p>
<p>
There are two films which captured the hyperbole and excess of the original dot com bubble especially well.
</p>
<p>
<a href="http://www.amazon.com/dp/B00005N5QV/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
The first is the documentary <a href="http://www.amazon.com/dp/B00005N5QV/?tag=codihorr-20">Startup.com</a>. It's about the prototypical web 1.0 company: one predicated on an idea that made absolutely no sense, which proceeded to flame out in a spectacular and all too typical way for the era. This one just happened to occur on digital film. The <a href="http://govworks.com/">govworks.com</a> website described in the documentary, the one that burned through $60 million in 18 months, is now one of those ubiquitous domain squatter pages. A sign of the times, perhaps.
</p>
<p>
The second film was one I had always wanted to see, but wasn't able to until a few days ago: <a href="http://clickmovement.org/coderush">Code Rush</a>. For a very long time, Code Rush was almost impossible to find, but <a href="http://waxy.org/2009/07/code_rush_in_the_creative_commons/">the activism of Andy Baio</a> nudged the director to make the film available under Creative Commons. You can now watch it online — and you absolutely should.
</p>
<p>
<iframe title="YouTube video player" type="text/html" width="480" height="390" src="https://www.youtube.com/embed/u404SLJj7ig?rel=0" frameborder="0" allowfullscreen></iframe>
</p>
<p>
Remember when people <i>charged money for a web browser?</i> That was Netscape.
</p>
<p>
Code Rush is a PBS documentary recorded at Netscape from 1998 - 1999, focusing on the <a href="http://www.mozilla.org/about/history.html">open sourcing of the Netscape code</a>. As the documentary makes painfully clear, this wasn't an act of strategy so much as an act of desperation. That's what happens when the company behind the world's most ubiquitous operating system decides a web browser should be a standard part of the operating system.
</p>
<p>
Everyone in the documentary knows they're doomed; in fact, the phrase "we're doomed" is a common refrain throughout the film. But despite the gallows humor and the dark tone, parts of it are oddly inspiring. These are engineers who are working heroic, impossible schedules for a goal they're not sure they can achieve — or that they'll even survive as an organization long enough to even finish.
</p>
<p>
The most vivid difference between Startup.com and Code Rush is that Netscape, despite all their other mistakes and missteps, didn't just burn through millions of dollars for no discernable reason. They produced a <b>meaningful legacy</b>:
</p>
<p>
</p>
<ul>
<li>Through Netscape Navigator, the original popularization of HTML and the internet itself.
</li>
<li>With the release of the Netscape source code on March 31st, 1998, the unlikely birth of the commercial open source movement.
</li>
<li>Eventually producing the first credible threat to Internet Explorer in the form of Mozilla Firefox 1.0 in 2004.
</li>
</ul>
<p>
Do you want money? Fame? Job security? Or do you want to change the world … eventually? Consider how many legendary hackers went on to brilliant careers from Netscape: Jamie Zawinski, Brendan Eich, Stuart Parmenter, Marc Andreeseen. The lessons of Netscape live on, even though the company doesn't. Code Rush is ultimately a <b>meditation on the meaning of work as a programmer</b>.
</p>
<p>
I'd like to think that when Facebook – the next Google and Microsoft rolled into one – <a href="http://dealbook.nytimes.com/2011/01/11/with-facebook-debate-renews-over-i-p-o-regulation/">goes public in early 2012</a>, the markets will react rationally. More likely, people will all collectively lose their damn minds again and we'll be thrust into a newer, bigger, even <i>more</i> insane tech bubble than the first one.
</p>
<p>
Yes, you will have incredibly lucrative job offers in this bubble. That's the easy part. As Startup.com and Code Rush illustrate, the hard part is figuring out <i>why</i> you are working all those long hours. Consider carefully, lest the arc of your career mirror that of so many failed tech bubble companies: <b>lived fast, died young, left a tired corpse.</b>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-01-31T08:03:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/lived-fast-died-young-left-a-tired-corpse/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How to Write Without Writing ]]></title>
<link>https://blog.codinghorror.com/how-to-write-without-writing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I have a confession to make: in a way, I founded Stack Overflow to <b>trick my fellow programmers</b>.
</p>
<p>
Before you trot out the pitchforks and torches, let me explain.
</p>
<p>
Over the last 6 years, I've come to believe deeply in the idea that becoming a great programmer has very little to do with <i>programming</i>. Yes, it takes a modicum of technical skill and dogged persistence, absolutely. But even more than that, it takes <a href="http://www.joelonsoftware.com/articles/CollegeAdvice.html">serious communication skills</a>:
</p>
<p>
</p>
<blockquote>
The difference between a tolerable programmer and a great programmer is not how many programming languages they know, and it's not whether they prefer Python or Java. <b>It's whether they can communicate their ideas.</b> By persuading other people, they get leverage. By writing clear comments and technical specs, they let other programmers understand their code, which means other programmers can use and work with their code instead of rewriting it. Absent this, their code is worthless.
</blockquote>
<p>
That is of course a quote from my co-founder Joel Spolsky, and it's one of my favorites.
</p>
<p>
In defense of my fellow programmers, communication with other human beings is not exactly what we signed up for. We didn't launch our careers in software development because we loved chatting with folks. Communication is just plain <i>hard</i>, particularly written communication. How exactly do you get better at something you self-selected out of? <a href="http://www.codinghorror.com/blog/2006/02/fear-of-writing.html">Blogging is one way</a>:
</p>
<p>
</p>
<blockquote>
People spend their entire lives learning how to write effectively. It isn't something you can fake. It isn't something you can buy. You have to work at it.
<p>
That's exactly why people who are afraid they <i>can't</i> write should be blogging.
</p>
<p>
It's exercise. No matter how out of shape you are, if you exercise a few times a week, you're bound to get fitter. Write a small blog entry a few times every week and you're bound to become a better writer. If you're not writing because you're intimidated by writing, well, you're likely to stay that way forever.
</p>
</blockquote>
<p>
Even with the best of intentions, telling someone "you should blog!" never works. I know this from painful first hand experience. Blogging isn't for everyone. Even a small blog entry can seem like an insurmountable, impenetrable, arbitrary chunk of writing to the average programmer. How do I get my fellow programmers to blog without blogging, to write without <i>writing?</i>
</p>
<p>
By cheating like <i>hell</i>, that's how.
</p>
<p>
Consider <a href="http://blog.stackoverflow.com/2009/04/what-stack-overflow-can-teach-you/">this letter I received</a>:
</p>
<p>
</p>
<blockquote>
I'm not sure if you have thought about this side effect or not, but <b>Stack Overflow has taught me more about writing effectively than any class I've taken, book I've read, or any other experience I have had before.</b>
<p>
I can think of no other medium where I can test my writing chops (by writing an answer), get immediate feedback on its quality (particularly when writing quality trumps technical correctness, such as subjective questions) and see other peoples attempts as well and how they compare with mine. Votes don't lie and it gives me a good indicator of how well an email I might send out to future co-workers would be received or a business proposal I might write.
</p>
<p>
Over the course of the past 5 months all the answers I've been writing have been more and more refined in terms of the quality. If I don't end up as the top answer I look at the answer that did and study what they did differently and where I faltered. Was I too verbose or was I too terse? Was I missing the crux of the question or did I hit it dead on?
</p>
<p>
I know that you said that writing your Coding Horror blog helped you greatly in refining your writing over the years. Stack Overflow has been doing the same for me and I just wanted to thank you for the opportunity. I've decided to setup a coding blog in your footsteps and I just registered a domain today. Hopefully that will go as well as writing on SO has. There are no tougher critics than fellow programmers who scrutinize every detail, every technical remark and grammar structure looking for mistakes. If you can effectively write for and be accepted by a group of programmers you can write for anyone.
</p>
</blockquote>
<p>
Joel and I have always positioned Stack Overflow, and all the other <a href="http://stackexchange.com/sites">Stack Exchange Q&amp;A sites</a>, as lightweight, focused, "fun size" units of writing.
</p>
<p>
Yes, by God, <b>we will <i>trick</i> you into becoming a better writer if that's what it takes – and it always does</b>. Stack Overflow has many overtly gamelike elements, but it is a game in service of the greater good – to make the internet better, and more importantly, to make <i>you</i> better. Seeing my fellow programmers naturally improve their written communication skills while participating in a focused, expert Q&amp;A community with their peers? Nothing makes me prouder.
</p>
<p>
Beyond programming, there's a whole other community of peers out there who grok how important writing is, and will support you in <a href="http://www.codinghorror.com/blog/2009/03/sharpening-the-saw.html">sharpening your saw, er, pen</a>. We have our own, too.
</p>
<p>
<a href="http://writers.stackexchange.com"><img alt="image placeholder" >
</p>
<p>
If you're an <b>author, editor, reviewer, blogger, copywriter, or aspiring writer of <i>any</i> kind, professional or otherwise</b> – check out <a href="http://writers.stackexchange.com/">writers.stackexchange.com</a>. Becoming a  more effective writer is the one bedrock skill that will further your professional career, no matter <i>what</i> you choose to do.
</p>
<p>
But mostly, you should write. I thought Jon Skeet <a href="http://blog.stackoverflow.com/2009/10/podcast-71/#comment-40649">summed it up particularly well here</a>:
</p>
<p>
</p>
<blockquote>
Everyone should write a <i>lot</i> – whether it's a blog, a book, Stack Overflow answers, emails or whatever. Write, and take some care over it. Clarifying your communication helps you to clarify your own internal thought processes, in my experience. It's amazing how much you find you don't know when you try to explain something in detail to someone else. It can start a whole new process of discovery.
</blockquote>
<p>
The process of writing is indeed a journey of discovery, one that will last the rest of your life. It doesn't ultimately matter whether you're writing a novel, a printer review, a Stack Overflow answer, fan fiction, a blog entry, a comment, a technical whitepaper, some emo LiveJournal entry, or even meta-talk about writing itself. Just <b>get out there and <i>write!</i></b>
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2011-02-04T04:38:51.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-write-without-writing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Importance of Net Neutrality ]]></title>
<link>https://blog.codinghorror.com/the-importance-of-net-neutrality/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although I remain <a href="http://www.codinghorror.com/blog/2006/02/presentation-zen.html">a huge admirer of Lawrence Lessig</a>, I am ashamed to admit that <b>I never fully understood the importance of net neutrality until last week</b>. Mr. Lessig <a href="http://www.washingtonpost.com/wp-dyn/content/article/2006/06/07/AR2006060702108.html">described network neutrality in these urgent terms in 2006</a>:
</p>
<p>
</p>
<blockquote>
At the center of the debate is the most important public policy you've probably never heard of: "network neutrality." Net neutrality means simply that all like Internet content must be treated alike and move at the same speed over the network. The owners of the Internet's wires cannot discriminate. This is the simple but brilliant "end-to-end" design of the Internet that has made it such a powerful force for economic and social good: All of the intelligence and control is held by producers and users, not the networks that connect them.
</blockquote>
<p>
Fortunately, the good guys are winning. Recent legal challenges to network neutrality have been defeated, <a href="http://en.wikipedia.org/wiki/Network_neutrality_in_the_United_States">at least under US law</a>. I remember hearing about these legal decisions at the time, but I glossed over them because I thought they were fundamentally about file sharing and BitTorrent. Not to sound dismissive, but someone's legal right to download a complete video archive of Firefly wasn't exactly keeping me up at night.
</p>
<p>
But network neutrality is about far more than file sharing bandwidth. To understand what's at stake, study the sordid history of the world's communication networks – starting with the telegraph, radio, telephone, television, and onward. Without historical context, it's impossible to appreciate how scarily easy it is for <a href="http://en.wikipedia.org/wiki/Common_carrier">common carriage</a> to get subverted and undermined by corporations and government in subtle (and sometimes not so subtle) ways, with <i>terrible</i> long-term consequences for society.
</p>
<p>
That's the genius of Tim Wu's book
<a href="http://www.amazon.com/dp/0307269930/?tag=codihorr-20">The Master Switch: The Rise and Fall of Information Empires</a>.
</p>
<p>
<a href="http://www.amazon.com/dp/0307269930/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>
One of the most fascinating stories in the book is that of <a href="http://en.wikipedia.org/wiki/Hush-A-Phone_v._United_States">Harry Tuttle and AT&amp;T</a>.
</p>
<p>
</p>
<blockquote>
Harry Tuttle was, for most of his life, president of the Hush-a-Phone Corporation, manufacturer of the telephone silencer. Apart from Tuttle, Hush-a-Phone employed his secretary. The two of them worked alone out of a small office near Union Square in New York City. Hush-a-Phone's signature product was shaped like a scoop, and it fit around the speaking end of a receiver, so that no one could hear what the user was saying on the telephone. The company motto emblazoned on its letterhead stated the promise succinctly: "Makes your phone private as a booth."
<p>
If the Hush-a-Phone never became a household necessity, Tuttle did a decent business, and by 1950 he would claim to have sold 125,000 units. But one day late in the 1940s, Henry Tuttle received alarming news. AT&amp;T had launched a crackdown on the Hush-a-Phone and similar products, like the Jordaphone, a creaky precursor of the modern speakerphone, whose manufacturer had likewise been put on notice. Bell repairmen began warning customers that Hush-a-Phone use was a violation of a federal tariff and that, failing to cease and desist, they risked termination of their telephone service.
</p>
<p>
Was AT&amp;T merely blowing smoke? Not at all: the company was referring to a special rule that was part of their covenant with the federal government. It stated: <i>No equipment, apparatus, circuit or device not furnished by the telephone company shall be attached to or connected with the facilities furnished by the telephone company, whether physically, by induction, or otherwise.</i>
</p>
<p>
Tuttle hired an attorney, who petitioned the FCC for a modification of the rule and an injunction against AT&amp;T's threats. In 1950 the FCC decided to hold a trial (officially a "public hearing") in Washington, D.C., to consider whether AT&amp;T, the nation's regulated monopolist, could punish its customers for placing a plastic cup over their telephone mouthpiece.
</p>
<p>
The story of the Hush-a-Phone and its struggle with AT&amp;T, for all its absurdist undertones, offers a window on the mindset of the monopoly at its height, as well as a picture of the challenges facing even the least innovative innovator at that moment.
</p>
</blockquote>
<p>
Absurdist, indeed – Harry Tuttle is also not-so-coincidentally the name of a character in the movie <a href="http://www.imdb.com/title/tt0088846/">Brazil</a>, one who attempts to work as a renegade, outside oppressive centralized government systems. Often at great peril to his own life and, well, that of anyone who happens to be nearby, too.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But the story of Harry Tuttle isn't just a cautionary tale about the dangers of large communication monopolies. Guess who was on Harry Tuttle's side in his <a href="http://en.wikipedia.org/wiki/Hush-A-Phone_v._United_States">sadly doomed legal effort against the enormously powerful Bell monopoly</a>? No less than an acoustics professor by the name of <b>Leo Beranek</b>, and an expert witness by the name of <b>J.C.R. Licklider</b>.
</p>
<p>
If you don't recognize those names, you should. <a href="http://en.wikipedia.org/wiki/J._C._R._Licklider">J.C.R. Licklider</a> went on to propose and design ARPANET, and <a href="http://en.wikipedia.org/wiki/Leo_Beranek">Leo Beranek</a> became one of the B's in <a href="http://en.wikipedia.org/wiki/BBN_Technologies">Bolt, Beranek and Newman</a>, who helped build ARPANET. In other words, these gentlemen went on from battling the Bell monopoly in court in the 1950s to designing a system in 1968 that would ultimately <i>defeat</i> it: the internet.
</p>
<p>
The internet is <i>radically</i> unlike all the telecommunications networks that have preceded it. It's the first national and global communication network designed from the outset to resist mechanisms for centralized control and monopoly. But resistance is not necessarily enough; <a href="http://www.amazon.com/dp/0307269930/?tag=codihorr-20">The Master Switch</a> makes a compelling case that, historically speaking, all communication networks <b>start out open and then rapidly swing closed as they are increasingly commercialized</b>.
</p>
<p>
</p>
<blockquote>
Just as our addiction to the benefits of the internal combustion engine led us to such demand for fossil fuels as we could no longer support, so, too, has our dependence on our mobile smart phones, touchpads, laptops, and other devices delivered us to a moment when our demand for bandwidth – the new black gold – is insatiable. Let us, then, not fail to protect ourselves from the will of those who might seek domination of those resources we cannot do without. If we do not take this moment to secure our sovereignty over the choices that our information age has allowed us to enjoy, we cannot reasonably blame its loss on those who are free to enrich themselves by taking it from us in a manner history has foretold.
</blockquote>
<p>
It's up to us to be vigilant in protecting the concepts of common carriage and network neutrality on the internet. Even devices that you may love, like an iPad, Kindle, or Xbox, can easily be turned against you – if you let them.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-02-14T17:26:48.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-importance-of-net-neutrality/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Revisiting the Home Theater PC ]]></title>
<link>https://blog.codinghorror.com/revisiting-the-home-theater-pc/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's been almost three years since I <a href="http://www.codinghorror.com/blog/2008/04/building-your-own-home-theater-pc.html">built my home theater PC</a>. I <i>adore</i> that little machine; it drives all of our family entertainment and serves as a general purpose home media server and streaming box. As I get older, I find that I'm no longer interested in having a home full of PCs whirring away. I only want <i>one</i> PC in my house on all the time, and I want it to be as efficient and versatile as possible.
</p>
<p>
My old low-power Athlon X2 based HTPC generally worked great, but still struggled with some occasional 1080p content. And when you have a toddler in the house, believe me, you <i>need</i> reliable 1080p playback. Only the finest in children's entertainment for my <a href="http://www.codinghorror.com/blog/2009/03/spawned-a-new-process.html">spawned process</a>, I say!
</p>
<p>
When I recently had to transcode <a href="http://www.imdb.com/title/tt1001526/">Megamind</a> down to 720p to get it to play back without stuttering or pausing at times… I knew my current HTPC's days were numbered.
</p>
<p>
<a href="http://www.imdb.com/title/tt1001526/"><img alt="image placeholder" >
</p>
<p>
(Megamind is <i>hilarious</i> and highly recommended, by the way; it's far better than its Metacritic and Rotten Tomatoes percentages would seem to indicate.)
</p>
<p>
Now that Intel has finally released their Sandy Bridge CPUs -- the first with integrated GPUs -- I was eager to revisit and rebuild. The <a href="http://ark.intel.com/Product.aspx?id=53423">low power Core i3-2100T</a> is the one I had my eye on, with <b>a miserly TDP of 35 watts</b>. Combine that with a decent <a href="http://www.codinghorror.com/blog/2006/01/the-impossibly-small-pc-nano-itx.html">Mini-ITX</a> motherboard and a few other essential parts, and you're good to go:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="350px">
<tr>
<td>CPU</td>
<td><a href="http://www.directron.com/bx80623i32100t.html">Intel Core i3-2100T</a></td>
<td>$135
</td>
</tr>
<tr>
<td>Motherboard</td>
<td><a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16813157239%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Motherboards%2B-%2BIntel-_-ASRock-_-13157239&amp;cjsku=N82E16813157239">ASRock H67M ITX</a></td>
<td>$100
</td>
</tr>
<tr>
<td>RAM</td>
<td><a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820145278%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Memory%2B%28Desktop%2BMemory%29-_-Corsair-_-20145278&amp;cjsku=N82E16820145278">Corsair 4GB DDR3</a></td>
<td>$45
</td>
</tr>
<tr>
<td>Case + PSU</td>
<td><a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16811129068%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Cases%2B%28Computer%2BCases%2B-%2BATX%2BForm%29-_-Antec-_-11129068&amp;cjsku=N82E16811129068">Antec ISK 300-65</a></td>
<td>$70
</td>
</tr>
<tr>
<td>HDD</td>
<td><a href="http://www.jdoqocy.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16822149204%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Hard%2BDrives%2B-%2BNotebooks%2B%2F%2BLaptops-_-Toshiba-_-22149204&amp;cjsku=N82E1682214920">750GB 2.5"</a></td>
<td>$70
</td>
</tr>
</table>
<p>
Now, I am fudging a bit here. This is just the basic level of hardware to get a functional home theater PC. I didn't actually buy a case, PSU, or even hard drive for that matter; I recycled many of my old existing parts, so my personal outlay was all of 300 bucks. I'm including the fuller part list as courtesy recommendations in case you're starting from scratch. You also might want to add a <a href="http://www.jdoqocy.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16827106325%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Blu-Ray%2BDrives-_-Lite-On-_-27106325&amp;cjsku=N82E16827106325">Blu-Ray drive</a>, and perhaps a <a href="http://www.anrdoezrs.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16832116754%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Software%2B-%2BOperating%2BSystems-_-Microsoft-_-32116754&amp;cjsku=N82E16832116754">Windows 7 Home Premium license</a> ($99) for its excellent 10-foot <a href="http://www.codinghorror.com/blog/2007/02/windows-vista-media-center.html">Windows Media Center</a> interface.
</p>
<p>
<a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16813157239%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Motherboards%2B-%2BIntel-_-ASRock-_-13157239&amp;cjsku=N82E16813157239"><img alt="image placeholder" >
</p>
<p>
The magical part here is the extreme level of hardware integration: the CPU has a GPU and memory controller on die, and the motherboard has optical digital out and HDMI out built in. It's delightfully simple to build and downright <i>cheap</i>. Just assemble it, install your OS of choice (sorry, Apple fans), then plug it into your receiver and television and boot it up.
</p>
<p>
My results? I'll just get right to the good part, but please bear in mind <b>each step is about twice as powerful</b> as the one before:
</p>
<p>
</p>
<table cellpadding="4" cellspacing="4" width="550px">
<tr>
<td><a href="http://www.codinghorror.com/blog/2005/02/pentium-m-home-theater-pc.html">2005</a></td>
<td>~$1000</td>
<td>512 MB RAM, single core CPU</td>
<td>80 watts idle
</td>
</tr>
<tr>
<td><a href="http://www.codinghorror.com/blog/2008/04/building-your-own-home-theater-pc.html">2008</a></td>
<td>~$520</td>
<td>2 GB RAM, dual core CPU</td>
<td>45 watts idle
</td>
</tr>
<tr>
<td><b>2011</b></td>
<td><b>~$420</b></td>
<td><b>4 GB RAM, dual core CPU + GPU</b></td>
<td>
<font color="red"><b>22 watts idle</b></font>
</td>
</tr>
</table>
<p>
I know I get way too excited about this stuff, but … <i>holy crap, 22 tesla-lovin' watts at idle!</i> </p>
<p>
<img alt="image placeholder" >
</p>
<p>
The <a href="http://www.codinghorror.com/blog/archives/001099.html">kill-a-watt never lies</a>. To be fair, it's more like 25 watts idle with <a href="http://www.codinghorror.com/blog/2007/02/everybody-loves-bittorrent.html">torrents in the background</a>. This little box is remarkably efficient; even when playing back a 1080p video it's not unusual to see CPU usage well under 50%, which equates to around 30-35 watts in practice. Under full, artificial multithreaded Prime95 load, it tops out at an absolute peak of 55 watts.
</p>
<p>
(<font color="red">Update:</font> I ended up replacing my old Seasonic ECO 300 SFX power supply with a <a href="http://www.amazon.com/exec/obidos/ASIN/B0035UETHW/codihorr-20">Pico PSU-90 plus 60 watt adapter</a> kit. That got the idle power down from 22 watts to <b>17 watts</b>, a solid savings of 22%. Recommended!)
</p>
<p>
This is a killer setup, but don't take my word for it. There is an <a href="http://www.missingremote.com/review/intel-core-i3-2100t-and-bh67cf-mini-itx-motherboard">excruciatingly in-depth review</a> of essentially the same system at <a href="http://www.missingremote.com/">Missing Remote</a>, with a particular eye toward home theater duties. Spoiler: they loved the hell out of it too. And it compromises almost nothing in performance, with a Windows Experience score of 5.1 -- that would be a solid 5.8 if you factored out desktop Aero performance.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
(Also, in case you're wondering, I intentionally dropped the analog cable tuner. All modern cable is now digital, which means awkward DRM-ed up the wazoo CableCard systems. I've cancelled cable altogether; I'd rather take that $60+ per month and use it to support innovative companies who will deliver media through the internet, like Netflix, Hulu, etcetera. Or as I like to call it: <i>the future</i>, unless the media congolomerates with vaults full of cash manage to <a href="http://www.codinghorror.com/blog/2011/02/the-importance-of-net-neutrality.html">subvert net neutrality</a>.)
</p>
<p>
When all is said and done, I have a new always-on, does-anything home theater box that is <b>twice as fast as the one I built in 2008, while consuming less than half the power</b>.
</p>
<p>
I've been a computer nerd since age 8, and I just turned 40. I should be jaded by <a href="http://www.codinghorror.com/blog/2007/05/computer-hardware-pornography.html">computer hardware pornography</a> by now, but I still find this progress <i>amazing</i>. At this rate, I can't wait to find out what my 2014 home theater PC will look like.
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-03-28T01:51:23.000Z</pubDate>
<guid>https://blog.codinghorror.com/revisiting-the-home-theater-pc/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Working with the Chaos Monkey ]]></title>
<link>https://blog.codinghorror.com/working-with-the-chaos-monkey/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
</p>
<p>
Late last year, the Netflix Tech Blog wrote about <a href="http://techblog.netflix.com/2010/12/5-lessons-weve-learned-using-aws.html">five lessons they learned moving to Amazon Web Services</a>. AWS is, of course, the preeminent provider of so-called "cloud computing", so this can essentially be read as <b>key advice for any website considering a move to the cloud</b>. And it's great advice, too. Here's the one bit that struck me as most essential:
</p>
<p>
</p>
<blockquote>
<p>
We’ve sometimes referred to the Netflix software architecture in AWS as our Rambo Architecture. Each system has to be able to succeed, no matter what, even all on its own. We’re designing each distributed system to expect and tolerate failure from other systems on which it depends.
</p>
<p>
If our recommendations system is down, we degrade the quality of our responses to our customers, but we still respond. We’ll show popular titles instead of personalized picks. If our search system is intolerably slow, streaming should still work perfectly fine.
</p>
<p>
One of the first systems our engineers built in AWS is called the Chaos Monkey. <b>The Chaos Monkey’s job is to randomly kill instances and services within our architecture.</b> If we aren’t constantly testing our ability to succeed despite failure, then it isn’t likely to work when it matters most – in the event of an unexpected outage.
</p>
</blockquote>
<p>
Which, let's face it, seems like insane advice at first glance. I'm not sure many companies even understand why this would be a good idea, much less have the guts to attempt it. Raise your hand if where you work, <i>someone deployed a daemon or service that randomly kills servers and processes in your server farm</i>.
</p>
<p>
Now raise your other hand if that person is still employed by your company.
</p>
<p>
Who in their right mind would willingly choose to work with a Chaos Monkey?
</p>
<p>
<a href="http://www.youtube.com/watch?v=WgjcvxQjpKA"><img alt="image placeholder" >
</p>
<p>
Sometimes you don't get a choice; the Chaos Monkey chooses you. At <a href="http://stackexchange.com/">Stack Exchange</a>, we struggled for months with a bizarre problem. <b>Every few days, one of the servers in the <a href="http://blog.stackoverflow.com/2010/01/stack-overflow-network-configuration/">Oregon web farm</a> would simply stop responding to all external network requests.</b> No reason, no rationale, and no recovery except for a slow, excruciating shutdown sequence requiring the server to bluescreen before it would reboot.
</p>
<p>
We spent months -- literally <i>months</i> -- chasing this <a href="http://serverfault.com/questions/104791/windows-server-2008-r2-network-adapter-stops-working-requires-hard-reboot">problem</a> down. We walked the list of everything we could think of to solve it, and then some:
</p>
<p>
</p>
<ul>
<li>swapping network ports
</li>
<li>replacing network cables
</li>
<li>a different switch
</li>
<li>multiple versions of the network driver
</li>
<li>tweaking OS and driver level network settings
</li>
<li>simplifying our network configuration and removing <a href="http://www.balabit.com/support/community/products/tproxy">TProxy</a> for more traditional <code>X-FORWARDED-FOR</code>
</li>
<li>switching virtualization providers
</li>
<li>changing our <a href="http://en.wikipedia.org/wiki/Host_model">TCP/IP host model</a>
</li>
<li>getting Kernel hotfixes and applying them
</li>
<li>involving high-level vendor support teams
</li>
<li>some other stuff that I've now forgotten because I blacked out from the pain
</li>
</ul>
<p>
At one point in this saga our team almost came to blows because we were so frustrated. (Well, as close to "blows" as a <a href="http://www.codinghorror.com/blog/2010/05/on-working-remotely.html">remote team</a> can get over Skype, but you know what I mean.) Can you blame us? Every few days, one of our servers -- no telling which one -- would randomly wink off the network. <b>The Chaos Monkey strikes again!</b>
</p>
<p>
Even in our time of greatest frustration, I realized that there was a positive side to all this:
</p>
<p>
</p>
<ul>
<li>Where we had one server performing an essential function, we switched to two.
</li>
<li>If we didn't have a sensible fallback for something, we created one.
</li>
<li>We removed dependencies all over the place, paring down to the absolute minimum we required to run.
</li>
<li>We implemented workarounds to stay running at all times, even when services we previously considered essential were suddenly no longer available.
</li>
</ul>
<p>
Every week that went by, we made our system a tiny bit more redundant, because we had to. Despite the ongoing pain, it became clear that Chaos Monkey was actually doing us a big favor by forcing us to become extremely resilient. Not tomorrow, not someday, not at some indeterminate "we'll get to it eventually" point in the future, but <i>right now where it hurts</i>.
</p>
Now, none of this is new news; our problem is long since solved, and the Netflix Tech Blog article I'm referring to was posted last year. I've been meaning to write about it, but <a href="http://stackexchange.com/sites">I've been a little busy</a>. Maybe the timing is prophetic; <a href="http://www.zdnet.com/blog/btl/amazons-web-services-outage-end-of-cloud-innocence/47731">AWS had a huge multi-day outage last week</a>, which took several major websites down, along with a constellation of smaller sites.
<p>
Notably absent from that list of affected AWS sites? Netflix.
</p>
<p>
When you work with the Chaos Monkey, you quickly learn that everything happens for a reason. Except for those things which happen completely randomly. And that's why, even though it sounds crazy, <b>the best way to avoid failure is to fail constantly.</b>
</p>
<p>
(<font color="red">update:</font> Netflix <a href="https://github.com/Netflix/SimianArmy">released their version of Chaos Monkey on GitHub</a>. Try it out!)
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2011-04-25T02:53:48.000Z</pubDate>
<guid>https://blog.codinghorror.com/working-with-the-chaos-monkey/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Hot/Crazy Solid State Drive Scale ]]></title>
<link>https://blog.codinghorror.com/the-hot-crazy-solid-state-drive-scale/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As an early advocate of solid state hard drives …
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/2009/10/the-state-of-solid-state-hard-drives.html">The State of Solid State Hard Drives</a> (October 2009)
</li>
<li>
<a href="http://www.codinghorror.com/blog/2010/09/revisiting-solid-state-hard-drives.html">Revisiting Solid State Hard Drives</a> (October 2010)
</li>
</ul>
<p>
… I feel ethically and morally obligated to let you in on a dirty little secret I've discovered in the last two years of full time SSD ownership. <b>Solid state hard drives fail. A lot.</b> And not just any fail. I'm talking about <i>catastrophic, oh-my-God-what-just-happened-to-all-my-data instant gigafail</i>. It's not pretty.
</p>
<p>
I bought a set of three Crucial 128 GB SSDs in October 2009 for the original two members of the Stack Overflow team plus myself. As of last month, two out of three of those had failed. And just the other day I was chatting with Joel on the podcast (yep, <a href="http://blog.stackoverflow.com/2011/04/se-podcast-02/">it's back</a>), and he casually mentioned to me that the Intel SSD in his Thinkpad, which was purchased roughly around the same time as ours, had also failed.
</p>
<p>
<a href="http://portmanwills.com/">Portman Wills</a>, friend of the company and generally awesome guy, has a far scarier tale to tell. He got infected with the SSD religion based on my original 2009 blog post, and he went all in. He purchased <i>eight</i> SSDs over the last two years … and <i>all of them failed</i>. The tale of the tape is frankly a little terrifying:
</p>
<p>
</p>
<ul>
<li>Super Talent 32 GB SSD, failed after 137 days
</li>
<li>OCZ Vertex 1 250 GB SSD, failed after 512 days
</li>
<li>G.Skill 64 GB SSD, failed after 251 days
</li>
<li>G.Skill 64 GB SSD, failed after 276 days
</li>
<li>Crucial 64 GB SSD, failed after 350 days
</li>
<li>OCZ Agility 60 GB SSD, failed after 72 days
</li>
<li>Intel X25-M 80 GB SSD, failed after 15 days
</li>
<li>Intel X25-M 80 GB SSD, failed after 206 days
</li>
</ul>
<p>
You might think after this I'd be swearing off SSDs as unstable, unreliable technology. Particularly since <a href="http://www.codinghorror.com/blog/2009/12/international-backup-awareness-day.html">I am the world's foremost expert on backups</a>.
</p>
<p>
Well, you'd be wrong. I just went out and bought myself <a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820227707%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-OCZ%2BTechnology-_-20227707&amp;cjsku=N82E16820227707">a hot new OCZ Vertex 3 SSD</a>, the clear winner of the latest generation of SSDs to arrive this year. <a href="http://www.storagereview.com/ocz_vertex_3_review_240gb">Storage Review</a> calls it <i>the fastest SATA SSD we've seen</i>.
</p>
<p>
</p>
<blockquote>
Beta firmware or not though, the Vertex 3 is a scorcher. We'll get into the details later in the review, but our numbers show it as clearly the fastest SATA SSD to hit our bench.
<p>
<a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820227707%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-OCZ%2BTechnology-_-20227707&amp;cjsku=N82E16820227707"><img alt="image placeholder" >
</p>
<p>
While that shouldn't be entirely surprising, it's not just faster like, "Woo, it edged out the prior generation SF-1200 SSDs, yeah!" <b>It's faster like, "Holy @% that's fast," boasting 69% faster results in some of our real-world tests.</b>
</p>
</blockquote>
<p>
Solid state hard drives are so freaking amazing performance wise, and the experience you will have with them is so transformative, that <i>I don't even care if they fail every 12 months on average!</i> I can't imagine using a computer without a SSD any more; it'd be like going back to <a href="http://www.codinghorror.com/blog/2006/05/do-modems-still-matter.html">dial-up internet</a> or 13" CRTs or single button mice. Over my dead body, man!
</p>
<p>
It may seem irrational, but … well, I believe the phenomenon was explained best on the television show <a href="http://www.imdb.com/title/tt0460649/">How I Met Your Mother</a> by Barney Stinson, a character played brilliantly by geek favorite Neil Patrick Harris:
</p>
<p>
</p>
<blockquote>
<p>
Barney: There's no way she's above the line on <a href="http://www.youtube.com/watch?v=5zADosF3XoQ">the 'hot/crazy' scale</a>.
</p>
<p>
Ted: She's not even on the 'hot/crazy' scale; she's just hot.
</p>
<p>
Robin: Wait, 'hot/crazy' scale?
</p>
<p>
Barney: Let me illustrate!
</p>
<p>
<a href="http://www.youtube.com/watch?v=5zADosF3XoQ"><img alt="image placeholder" >
</p>
<p>
Barney: A girl is allowed to be crazy as long as she is equally hot. Thus, if she's <i>this</i> crazy, she has to be <i>this</i> hot. You want the girl to be above this line. Also known as the 'Vickie Mendoza Diagonal'. This girl I dated. She played jump rope with that line. She'd shave her head, then lose 10 pounds. She'd stab me with a fork, then get a boob job. [pause] I should give her a call.
</p>
</blockquote>
<p>
Thing is, <b>SSDs are so scorching hot that I'm willing to put up with their craziness.</b> Consider that just in the last two years, their performance has <i>doubled</i>. Doubled! And the latest, fastest SSDs can even <a href="http://www.anandtech.com/show/4186/ocz-vertex-3-preview-the-first-client-focused-sf2200/5">saturate existing SATA interfaces</a>; they need brand new 6 Gbps interfaces to fully strut their stuff. No CPU or memory upgrade can come close to touching that kind of real world performance increase.
</p>
<p>
Just make sure you have a <a href="http://www.codinghorror.com/blog/2008/01/whats-your-backup-strategy.html">good backup plan</a> if you're running on a SSD. I do hope they iron out the reliability kinks in the next 2 generations … but I've spent the last two months checking out the hot/crazy solid state drive scale in excruciating detail, and trust me, you want <a href="http://www.tkqlhce.com/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16820227707%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Solid%2BState%2BDisk-_-OCZ%2BTechnology-_-20227707&amp;cjsku=N82E16820227707">one of these new Vertex 3 SSDs</a> <i>right now</i>.
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-05-02T01:24:36.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-hot-crazy-solid-state-drive-scale/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Who Needs a Sound Card, Anyway? ]]></title>
<link>https://blog.codinghorror.com/who-needs-a-sound-card-anyway/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The last sound card I purchased was in 2006, and that's only because I'm (occasionally) a bleeding edge PC gamer. The very same card was still in my current PC until a few days ago. It's perhaps too generous to describe PC sound hardware as stagnant; it's borderline <i>irrelevant</i>.
</p>
<p>
<b>The default, built-in sound chips on most motherboards have evolved from "totally crap" to "surprisingly decent" in the last 5 years.</b> But besides that, in this era of ubiquitous quad core CPUs nearing 4 GHz, it'd be difficult to make a plausible case that you <i>need</i> a discrete set of silicon to handle sound processing, even for <a href="http://www.codinghorror.com/blog/2006/01/3d-positional-audio-and-hrtfs.html">the very fanciest of 3D sound algorithms and HRTFs</a>.
</p>
<p>
That said, if you enjoy music even a <i>little</i>, I still strongly recommend investing in a quality set of headphones. As I wrote in 2005's <a href="http://www.codinghorror.com/blog/2005/12/headphone-snobbery.html">Headphone Snobbery</a>:
</p>
<p>
</p>
<blockquote>
<b>Am I really advocating spending two hundred dollars on a set of headphones?</b> <i>Yes. Yes I am.</i> Now, you could spend a lot more. This is about extracting the maximum bang for your buck:
<p>
</p>
<ol>
<li>Unlike your computer, or your car, your headphones will never wear out or become obsolete. I hesitate to say lifetime, but they're multiple decade investments at the very least.
</li>
<li>The number one item that affects the music you hear is the speakers. Without a good set of headphones, everything else is irrelevant.
</li>
<li>The right headphones can deliver sound equivalent to extremely high-end floorstanding speakers worth thousands of dollars.
</li>
</ol>
<p>
If you're the type of person who is perfectly happy listening to 64 kilobit MP3s through a $5 set of beige headphones, that's fine. There's nothing wrong with that. Keep on scrolling; this post is not for you.
</p>
</blockquote>
<p>
I realize that there's a fine line between audiophile and bats**t insane -- <i>and that line better not be near any sources of interference!</i> But nice headphones require powerful, reasonably clean output to deliver the best listening experience. This isn't <a href="http://www.amazon.com/AudioQuest-K2-terminated-speaker-cable/dp/B000J36XR2">high end audio crackpot snake oil</a>, it's actual physics.
</p>
<p>
I'll let the guys at headroom <a href="http://www.headphone.com/learning-center/how-do-i-know-if-my-headphones-need-an-amp.php">explain</a>:
</p>
<p>
</p>
<blockquote>
You may have heard of a headphone's "impedance." Impedance is the combined resistance and reactivity the headphones present to the amplifier as an electrical load. High impedance cans will usually need more voltage to get up to a solid listening level, so they will often benefit from an amp, especially with portable players that have limited voltage available from their internal batteries. But low impedance cans may require more current, and will lower the damping factor between the amp and headphones. So while low impedance headphones may be driven loud enough from a portable player, the quality of sound may be dramatically improved with an amp.
<p>
The size of your headphone will give you some clues to whether an amp may be warranted. Most earbud and in ear headphones are typically very efficient and are less likely to benefit strongly from an amp. Many larger headphones will benefit, or even require, a headphone amp to reach listenable volume levels with portable players.
</p>
</blockquote>
<p>
Thus, once you have a set of nice headphones, you <i>do</i> need some kind of amplified output for them. Something like the <a href="http://boostaroo.com/">Boostaroo</a>, or a <a href="http://www.amazon.com/exec/obidos/ASIN/B003WXBFS8/codihorr-20">Total BitHead</a>. And if you're on a laptop these outboard solutions might be your only options.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/B003WXBFS8/codihorr-20"><img alt="image placeholder" >
</p>
<p>
But desktops offer the option of adding a sound card. The good news is that <b>arguably the best sound card on the planet, the <a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16829132020%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Sound%2BCard-_-ASUS-_-29132020&amp;cjsku=N82E16829132020">Xonar DG</a>, is all of 30 measly bucks.</b> It's a big step up in fundamental sound quality from even the best current integrated HD audio motherboard sound chips, per <a href="http://techreport.com/articles.x/19997/1">this Tech Report review</a>.
</p>
<p>
</p>
<table width="700">
<tr>
<td width="*"></td>
<td colspan="9">
<a href="http://audio.rightmark.org">RightMark Audio Analyzer</a> audio quality, 16-bit/44.1kHz</td>
</tr>
<tr>
<td width="*"></td>
<td align="center" width="60">freq response</td>
<td align="center" width="60">noise level</td>
<td align="center" width="60">range</td>
<td align="center" width="60">THD</td>
<td align="center" width="60">THD + Noise</td>
<td align="center" width="60">IMD + Noise</td>
<td align="center" width="60">crosstalk</td>
<td align="center" width="60">IMD at 10kHz</td>
<td align="center" width="60">overall</td>
</tr>
<tr>
<td width="*">Realtek ALC892 HD</td>
<td align="center" width="60">5</td>
<td align="center" width="60">4</td>
<td align="center" width="60">4</td>
<td align="center" width="60">3</td>
<td align="center" width="60">1</td>
<td align="center" width="60">3</td>
<td align="center" width="60">5</td>
<td align="center" width="60">3</td>
<td align="center" width="60">4</td>
</tr>
<tr>
<td width="*"><a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16829132020%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Sound%2BCard-_-ASUS-_-29132020&amp;cjsku=N82E16829132020">Xonar DG</a></td>
<td align="center" width="60">5</td>
<td align="center" width="60">6</td>
<td align="center" width="60">6</td>
<td align="center" width="60">5</td>
<td align="center" width="60">4</td>
<td align="center" width="60">6</td>
<td align="center" width="60">6</td>
<td align="center" width="60">6</td>
<td align="center" width="60">5</td>
</tr>
</table>

It also includes a little something extra of particular interest to us music loving programmers with nice headphones:
<p>
</p>
<blockquote>
<b>Built-in headphone amplification</b> is something you won't find on a motherboard, but it's featured in both Xonars. On the DG, Asus has gone with Texas Instruments' DRV601RTJR, which is optimized for headphone impedances of 32-150 Ω according to the card's spec sheet. The Xense gets something considerably fancier: a TI amp capable of pushing headphones with impedances up to 600 Ω. Of course, the headphones bundled with the card are rated for an impedance of only 150 Ω. Mid-range stereo cans like Sennheiser's excellent HD 555s, which we use for listening tests, have a rated impedance of just 50 Ω. You don't need big numbers for high-quality sound.
</blockquote>
<p>
The headphone amplification options are a bit buried in the Xonar driver user interface. To get there, select headphone mode, then click the little hammer icon to bring up the headphone amp gain settings.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
After my last upgrade, I was truly hoping I could get away with just the on-board Realtek HD audio my motherboard provides. I resisted mightily -- but the drop in headphone output quality with the onboard stuff was noticeable. Not to mention that I had to absolutely <i>crank</i> the volume to get even moderate loudness with my fancy-ish Sennheiser HD 600 headphones. The Xonar DG neatly solves both of these problems.
</p>
<p>
As you probably expected, the answer to the question "Who needs a sound card?" is "Almost nobody." <i>Except those of us who <a href="http://www.codinghorror.com/blog/2005/12/headphone-snobbery.html">invested in quality headphones</a>.</i> Rather than spending $30 or $150 on an outboard headphone amp, <a href="http://www.dpbolvw.net/click-2338938-10440897?url=http%3A%2F%2Fwww.newegg.com%2FProduct%2FProduct.aspx%3FItem%3DN82E16829132020%26nm_mc%3DAFC-C8Junction%26cm_mmc%3DAFC-C8Junction-_-Sound%2BCard-_-ASUS-_-29132020&amp;cjsku=N82E16829132020">spend $30 on the Xonar DG</a> to get a substantial sound quality upgrade <i>and</i> a respectable headphone amp to boot.
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-05-04T19:34:18.000Z</pubDate>
<guid>https://blog.codinghorror.com/who-needs-a-sound-card-anyway/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Infinite Version ]]></title>
<link>https://blog.codinghorror.com/the-infinite-version/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the things I like most about Google's Chrome web browser is <a href="http://www.codinghorror.com/blog/2010/09/go-that-way-really-fast.html">how often it is updated</a>. But now that Chrome has rocketed through <a href="http://en.wikipedia.org/wiki/Google_Chrome#Release_history">eleven versions in two and a half years</a>, the thrill of seeing that version number increment has largely worn off. It seems they've picked off all the low hanging fruit at this point and are mostly polishing. The highlights from <b>Version 11</b>, the current release of Chrome?
</p>
<p>
</p>
<blockquote>
HTML5 Speech Input API. Updated icon.
</blockquote>
<p>
Exciting, eh? Though there was no shortage of hand-wringing over the new icon, <a href="http://www.google.com/search?q=new+google+chrome+icon+sucks">of course</a>.
</p>
<p>
Chrome's version number has been changing so rapidly lately that every time someone opens a Chrome bug on a Stack Exchange site, I have to check my version against theirs just to make sure we're still talking about the same software. And once -- I swear I am not making this up -- <i>the version incremented while I was checking the version</i>.
</p>
<p>
<a href="http://twitter.com/#!/codinghorror/status/64432690597871616">
<img alt="image placeholder" >
</a>
</p>
<p>
That was the day I officially stopped caring what version Chrome is. I mean, I care in the sense that sometimes <a href="http://www.codinghorror.com/blog/2007/02/whats-in-a-version-number-anyway.html">I need to check its dogtags in battle</a>, but as a regular user of Chrome, I no longer think of myself as using <i>a specific version</i> of Chrome, I just … use Chrome. Whatever the latest version is, I have it automagically.
</p>
<p>
For the longest time, web browsers have been strongly associated with specific versions. The very mention of Internet Explorer 6 or Netscape 4.77 should send a shiver down the spine of any self-respecting geek. And for good reason! Who can forget what a breakout hit Firefox 3 was, or the epochs that Internet Explorer 7, 8 and 9 represent in Microsoft history. But Chrome? <b>Chrome is so fluid that it has transcended software versioning altogether.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This fluidity is difficult to achieve for client software that runs on millions of PCs, Macs, and other devices. Google put an extreme amount of engineering effort into making the Chrome auto-update process "just work". They've <a href="http://blog.chromium.org/2009/07/smaller-is-faster-and-safer-too.html">optimized the heck out of the update process</a>.
</p>
<p>
</p>
<blockquote>
Rather then push put a whole new 10MB update [for each version], we send out a diff that takes the previous version of Google Chrome and generates the new version. We tried several binary diff algorithms and have been using bsdiff up until now. We are big fans of <a href="http://www.daemonology.net/bsdiff/">bsdiff</a> - it is small and worked better than anything else we tried.
<p>
But bsdiff was still producing diffs that were bigger than we felt were necessary. So we wrote a new diff algorithm that knows more about the kind of data we are pushing - large files containing compiled executables. Here are the sizes for the recent 190.1 -&gt; 190.4 update on the developer channel:
</p>
<p>
</p>
<ul>
<li>Full update: 10 megabytes
</li>
<li>bsdiff update: 704 kilobytes
</li>
<li>Courgette update: 78 kilobytes
</li>
</ul>
<p>
The small size in combination with Google Chrome's silent update means we can update as often as necessary to keep users safe.
</p>
</blockquote>
<p>
Google's <a href="http://dev.chromium.org/developers/design-documents/software-updates-courgette">Courgette</a> -- the French word for Zucchini, oddly enough -- is an amazing bit of software optimization, capable of producing uncannily small diffs of binary executables. To achieve this, it has to know intimate details about the source code:
</p>
<p>
</p>
<blockquote>
The problem with compiled applications is that even a small source code change causes a disproportional number of byte level changes.  When you add a few lines of code, for example, a range check to prevent a buffer overrun, all the subsequent code gets moved to make room for the new instructions.  The compiled code is full of internal references where some instruction or datum contains the address (or offset) of another instruction or datum.  It only takes a few source changes before almost all of these internal pointers have a different value, and there are a lot of them - roughly half a million in a program the size of chrome.dll.
<p>
The source code does not have this problem because all the entities in the source are symbolic. Functions don't get committed to a specific address until very late in the compilation process, during assembly or linking.  If we could step backwards a little and make the internal pointers symbolic again, could we get smaller updates?
</p>
</blockquote>
<p>
Since the version updates are relatively small, they can be downloaded in the background. But even Google hasn't figured out how to install an update while the browser is running. Yes, there are little alert icons to let you know your browser is out of date, and you eventually do get nagged if you are woefully behind, but <b>updating <i>always</i> requires the browser to restart</b>.
</p>
<p>
<a href="http://www.flickr.com/photos/factoryjoe/4841343705/"><img alt="image placeholder" >
</p>
<p>
Web applications have it far easier, but they have version delivery problems, too. Consider WordPress, one of the largest and most popular webapps on the planet. We run WordPress on multiple blogs and even have <a href="http://wordpress.stackexchange.com/">our own WordPress community</a>. WordPress doesn't auto-update to each new version, but it makes it as painless as I've seen for a webapp. Click the update link on the dashboard and WordPress (and its add-ons) update to the latest version all by themselves. There might be the briefest of interruptions in service for visitors to your WordPress site, but then you're back in business with the latest update.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>WordPress needs everyone to update to the latest versions regularly</b> for the same reasons Google Chrome does -- security, performance, and stability. An internet full of old, unpatched WordPress or Chrome installations is no less dangerous than an internet full of old, unpatched Windows XP machines.
</p>
<p>
These are both relatively seamless update processes. But they're nowhere near as seamless as they <i>should</i> be. <b>One click updates that require notification and restart aren't good enough.</b> To achieve the infinite version, we software engineers have to go a lot deeper.
</p>
<p>
<a href="http://twitter.com/#!/jilliancyork/status/50024539610034176">
<img alt="image placeholder" >
</p>
<p>
Somehow, we have to be able to automatically update software while it is running without interrupting the user at all. <b>Not <i>if</i> -- but <i>when</i> -- the infinite version arrives</b>, our users probably won't even know. Or care. And that's how we'll know we've achieved our goal.
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2011-05-23T03:36:57.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-infinite-version/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
</channel>
</rss>
