<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title><![CDATA[ Did IE6 Make Web 2.0 Possible? ]]></title>
<link>https://blog.codinghorror.com/did-ie6-make-web-20-possible/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the cornerstones of Web 2.0 is the <a href="http://en.wikipedia.org/wiki/XMLHttpRequest">XMLHttpRequest object</a>. It allows JavaScript to call back to a web server without incurring a traditional HTTP postback. It's the <a href="http://builder.com.com/5100-6371-6056954.html">heart and soul of AJAX</a>, and it's <b>a completely proprietary feature Microsoft introduced along with IE 5.0 in March 1999</b>. Supposedly it was introduced so the Exchange team could <a href="http://www.franklinmint.fm/blog/archives/000294.html">build Outlook Web Access</a>.
</p>
<p>
The first mention of Mozilla and XMLHttpRequest I could find on Usenet is this <a href="http://groups.google.com/group/netscape.public.mozilla.jseng/browse_thread/thread/6c237a9fc01611f5/0ca2e89450cf28ec">post to netscape.public.mozilla.jseng</a> from January 2000. XMLHttpRequest was eventually implemented in Mozilla 1.0, which was released in June 2002. It isn't implemented as an exact copy of the IE version, however. The declaration is a little different. In IE, it's an ActiveX object:
</p>
<p>
</p>
<pre>
var req = new ActiveXObject("Microsoft.XMLHTTP");
</pre>
<p>
In Firefox and Safari, it's a native object:
</p>
<p>
</p>
<pre>
var req = new XMLHttpRequest();
</pre>
<p>
And things were quiet on that front until <a href="http://www.google.com/webhp?complete=1">Google Suggest</a> was revealed near the end of 2004. In April 2006, XMLHttpRequest was belatedly submitted to the <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=b6a6febf-51ba-4263-84a0-360e67d98391">W3C as a standard</a>.
</p>
<p>
But how did we get here?
</p>
<p>
<a href="http://www.google.com/press/zeitgeist.html">Google's Zeitgeist</a> used to break down Google searchers by browser and operating system. Unforunately, they stopped reporting this after <a href="http://www.google.com/press/zeitgeist/zeitgeist-jun04.html">June 2004's Zeitgeist</a>. Here's an enlarged version of the last browser share graph:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's a stark picture of <b>how monoculture the browser world became between January 2001 and June 2004</b>. Google is the best source of data for browser market share, in my opinion, because nothing is as egalitarian and universal as the number one search engine. I wonder why Google discontinued reporting this data? Was it a competitive advantage?
</p>
<p>
Google is a good source for this kind of data, but it isn't the only one. there are dozens of different agencies and organizations offering browser market share statistics. Wikipedia has a comprehensive page that tracks <a href="http://en.wikipedia.org/wiki/Usage_share_of_web_browsers">browser market share across a multitude of different sources</a>. Although <a href="http://www.tgdaily.com/2005/07/21/is_any_web_browser_/">opinions vary on the reliability of browser market share figures</a>, a quick scan through all the data reveals one interesting commonality across <i>all</i> the data sources: <b>IE6 market share peaked at around 95 percent sometime in mid-2004</b>.
</p>
<p>
Ninety-five percent is an incredible number. Super-saturation for a <i>single version</i> of a browser was historically unheard of in the browser market; the progression of IE (and most other browsers) up to that point was steady and regular:
</p>
<p>
</p>
<ul>
<li>Internet Explorer 1.0, August 1995
</li>
<li>Internet Explorer 2.0, November 1995
</li>
<li>Internet Explorer 3.0, August 1996
</li>
<li>Internet Explorer 4.0, September 1997
</li>
<li>Internet Explorer 5.0, March 1999
</li>
<li>Internet Explorer 5.5, July 2000
</li>
<li>Internet Explorer 6.0, August 2001
</li>
</ul>
<p>
The next version of IE was never more than a year off. IE 7.0 is slated for release in early 2007; at that point, it will have been <b>almost six years since Microsoft released a new version of Internet Explorer</b>. The super-saturation of IE 6.0 is a direct consequence of Microsoft virtually abandoning development on IE.
</p>
<p>
If 95% of the world is browsing with IE 6, pursuing browser independence is a waste of time. <b>If you don't have to worry about browser independence, you are suddenly free to exploit advanced browser techniques like XMLHttpRequest.</b> And, even more conveniently, alternative browsers have adopted XMLHttpRequest. Not that it mattered in late 2004, since IE6 still had 90 to 95 percent market share-- depending on which figures you trust.
</p>
<p>
Surely Microsoft is concerned about the internet as an application platform, and thus, as an alternative to Windows applications. Some pundits think Microsoft was intentionally trying to cripple internet application development by halting all development on IE. Personally, I don't subscribe to this theory. But if that was the plan, it backfired <i>spectacularly</i>. Having everyone on the same browser platform, with a 95 percent market share, didn't create a stagnant development platform. <b>The super-saturation and monoculture of IE6 from 2002 to 2004 created an incredibly rich, vibrant development platform where developers were free to push the capabilities of the browser to its limits.</b> Without worrying about backward compatibility. Without writing thousands of if..else statements to accommodate a half-dozen alternative browsers.
</p>
<p>
If you subscribe to the "evil Microsoft" theory, Microsoft would have been far better off releasing new, mildly incompatible versions of Internet Explorer every year.
</p>
<p>
Ironic, isn't it?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/did-ie6-make-web-20-possible/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What's on Your Keychain.. in 2006? ]]></title>
<link>https://blog.codinghorror.com/whats-on-your-keychain-in-2006/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
A little over a year ago, I documented what was <a href="http://www.codinghorror.com/blog/archives/000251.html">on my keychain</a>. Here's what I have today:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If you're troubled by what appears to be profanity on the <a href="http://www.leatherman.com/products/tools/s4/default.asp">Leatherman Squirt</a>, I'll refer you to my <a href="http://www.codinghorror.com/blog/archives/000251.html">previous post</a>-- it's a <a href="http://www.imdb.com/title/tt0110912/">Pulp Fiction</a> joke. This amazing little <b>pocket knife</b> is the only item that I haven't changed since 2005. I use it all the time, mostly for its scissors, screwdriver, or knife functionality (in that order). It sure does come in handy-- <a href="http://www.mikepope.com/blog/DisplayBlog.aspx?permalink=1517">bricolage</a> in action!
</p>
<p>
<b>USB flash drives</b> are a dime a dozen these days. <a href="http://www.codinghorror.com/blog/archives/000215.html">It's the new floppy disk</a>. This particular flash drive is a 1 gigabyte <a href="http://www.iomega.com/direct/products/family.jsp?FOLDER%3C%3Efolder_id=27075041&amp;ASSORTMENT%3C%3East_id=26890319&amp;bmUID=1150003983671">Iomega Micro Mini</a>. It's by far my favorite USB flash drive model, for two key reasons:
</p>
<p>
</p>
<ol>
<li>It's really, really small. Tiny, even.
</li>
<li>The end cap is physically attached to the drive; rotate it to expose the usb interface.
</li>
</ol>
<p>
So many USB flash drives have end caps that aren't physically attached to the drive. The first thing I do is lose them! The Mini's design cleverly solves this problem. There's even a little cutout so you can see the drive activity LED with the cap rotated.
</p>
<p>
The ARC <b>LED AAA battery flashlight</b> I used to carry sadly died. And the company that made it isn't around any more. But the replacement is even better-- the <a href="http://www.dansdata.com/peakled.htm">Peak LED Matterhorn</a>. Here's why:
</p>
<p>
</p>
<ol>
<li>It has three LEDs instead of a single LED. It's much brighter.
</li>
<li>The lanyard attachment point screws apart, so it can be easily detached from the keychain.
</li>
<li>The runtime profile of the three-LED model is superior: seven hours before it drops to half its original brightness.
</li>
</ol>
<p>
It is a wee bit longer, but otherwise it's a much welcomed improvement over the ARC. I stuck with the basic black keychain model, but there are a <a href="http://www.peakledsolutions.net/aaa.html">variety of styles to choose from</a>.
</p>
<p>
The one item I wish I had on my keychain is a <b>pen</b>. I haven't been able to find anything appropriately compact and portable. Dan carries a <a href="http://www.dansdata.com/inka.htm">space pen</a>, but I need something that'll attach to a keyring.
</p>
<p>
I should mention that I do, in fact, carry <i>keys</i> on my keychain as well. I just removed them in the photo to highlight the important stuff.
</p>
<p>
So what's on <i>your</i> keychain?
</p>
<p>
<font color="red">update</font>: Here's my <a href="http://www.codinghorror.com/blog/archives/001036.html">2008 edition of the keychain</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whats-on-your-keychain-in-2006/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Noble Art of Maintenance Programming ]]></title>
<link>https://blog.codinghorror.com/the-noble-art-of-maintenance-programming/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Mention the words "maintenance programming" to a group of developers and they'll, to a man (or woman), recoil in horror. <b>Maintenance programming is widely viewed as janitorial work</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But maybe that's an unfair characterization.
</p>
<p>
In <a href="http://www.amazon.com/exec/obidos/ASIN/0977213307/codihorr-20">Software Conflict 2.0 : The Art and Science of Software Engineering</a>, Robert L. Glass extols the virtues of software maintenance:
</p>
<p>
</p>
<blockquote>
Software maintenance is...
<ul>
<li>
<b>Intellectually complex</b> - it requires innovation while placing severe constraints on the innovator
</li>
<li>
<b>Technically difficult</b> - the maintainer must be able to work with a concept and a design and its code all at the same time
</li>
<li>
<b>Unfair</b> - the maintainer never gets all the things the maintainer needs, such as documentation
</li>
<li>
<b>No-win</b> - the maintainer only sees people who have problems
</li>
<li>
<b>Dirty work</b> - the maintainer must work at the grubby level of detailed coding
</li>
<li>
<b>Living in the past</b> - the code was probably written by someone else before they got good at it
</li>
<li>
<b>Conservative</b> - the going motto for maintenance is "if it ain't broke, don't fix it"
</li>
</ul>
<p>
Software maintenance is pretty complex, challenging stuff.
</p>
<p>
In most computing installations, the people who do maintenance tend to be those who are new on the job or not very good at development. There's a reason for that. Most people would rather do original development; maintenance is too constraining to the creative juices for most people to enjoy doing it. And so by default, the least capable and the least in demand are the ones who most often do the maintenance.
</p>
<p>
The status quo is all wrong. Maintenance is a significant intellectual challenge as well as a solution and not a problem. If we want to maximize our effectiveness at doing it, we need to significantly change the way in which we assign people to it.
</p>
</blockquote>
<p>
Perhaps it depends on how you look at your code. According to Andy and Dave, <a href="http://www.artima.com/intv/dry.html">all programming is maintenance programming</a>:
</p>
<p>
</p>
<blockquote>
Dave Thomas: <b>All programming is maintenance programming, because you are rarely writing original code</b>. If you look at the actual time you spend programming, you write a bit here and then you go back and make a change. Or you go back and fix a bug. Or you rip it out altogether and replace it with something else. But you are very quickly maintaining code even if it's a brand new project with a fresh source file. You spend most of your time in maintenance mode. So you may as well just bite the bullet and say, "I'm maintaining from day one." The disciplines that apply to maintenance should apply globally.
<p>
Andy Hunt: It's only the first 10 minutes that the code's original, when you type it in the first time. That's it.
</p>
</blockquote>
<p>
According to Joel Spolsky, developers are <a href="http://www.joelonsoftware.com/articles/fog0000000069.html">too lazy to do software maintenance</a>:
</p>
<p>
</p>
<blockquote>
We're programmers. Programmers are, in their hearts, architects, and the first thing they want to do when they get to a site is to bulldoze the place flat and build something grand. We're not excited by incremental renovation: tinkering, improving, planting flower beds.
<p>
There's a subtle reason that programmers always want to throw away the code and start over. The reason is that they think the old code is a mess. And here is the interesting observation: they are probably wrong. The reason that they think the old code is a mess is because of a cardinal, fundamental law of programming:
</p>
<p>
<b>It's harder to read code than to write it.</b>
</p>
<p>
This is why code reuse is so hard. This is why everybody on your team has a different function they like to use for splitting strings into arrays of strings. They write their own function because it's easier and more fun than figuring out how the old function works.
</p>
<p>
As a corollary of this axiom, you can ask almost any programmer today about the code they are working on. "It's a big hairy mess," they will tell you. "I'd like nothing better than to throw it out and start over."
</p>
</blockquote>
<p>
I agree that most developers have an unnatural knee-jerk tendency to rewrite for the sake of rewriting. But other than resisting this urge, I can't agree with Joel.
</p>
<p>
It's a balancing act.
</p>
<p>
</p>
<ol>
<li>
<b>We should probably have our best developers doing software maintenance</b>, not whoever draws the shortest straw. I've seen too many systems devolve into a patchwork of duct tape, spit, and a prayer. Probably because the least experienced and least talented developers are the only ones left to do any maintenance.
<p></p>
</li>
<li>
<b>At some point, you have to bite the bullet and reset the foundation so you have a stable platform to build on.</b> If a house's foundation is unsound, no amount of routine maintenance is going to fix it. Total rewrites like Mozilla and Windows NT may have taken years to get traction, but imagine where open-source browsers-- and Microsoft-- would be if they hadn't ever started.
</li>
</ol>
<p>
Software maintenance, like Rodney Dangerfield, gets no respect. It's time we changed that perception. But don't use maintenance as a crutch for deeper problems, either; renovate fearlessly when the situation calls for it.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-noble-art-of-maintenance-programming/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ WWWWWDD? ]]></title>
<link>https://blog.codinghorror.com/wwwwwdd/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Or, <a href="http://www.whatwouldjesusdo.com/">What Would World Wide Web Developers Do</a>?
</p>
<p>
To get an idea of what web <i>developers</i> are using -- as compared to typical web users -- take a look at the <a href="http://www.w3schools.com/browsers/browsers_stats.asp">comprehensive w3schools browser statistics</a>, picking up from mid-2004 when the <a href="http://www.codinghorror.com/blog/archives/000606.html">Google statistics</a> end:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Quite a difference from the <a href="http://en.wikipedia.org/wiki/Usage_share_of_web_browsers">other browser market share statistics</a>; IE 6.0 is dominant, but not overwhelmingly dominant to the tune of 95% market share at its peak in late 2004. It's also interesting that <a href="http://www.codinghorror.com/blog/archives/000242.html">despite being five years old and generally reviled by most serious web developers</a>, IE 6 usage has only dipped ten percent from its historical peak on w3schools.
</p>
<p>
The other statistics from w3schools are also quite interesting:
</p>
<p>
</p>
<ul>
<li>
<b>Roughly 10 percent of web developers have javascript disabled.</b> This number has remained nearly constant from 2002 to 2006.
</li>
<li>
<b>More than 80 percent of web developers have true color displays.</b> This has increased by about 10 percent every year.
</li>
<li>
<b>Only 17 percent of web developers are using resolutions greater than 1024x768</b>.  Only 57 percent are even at 1024x768-- the remainder are using resolutions below that!
</li>
<li>
<b>74 percent of web developers are using Windows XP.</b> That's an increase of 10 percent over this time last year.
</li>
</ul>
<p>
I'm not sure how much we can conclude from a single source of data. But it's still a little discouraging that <i>even on a developer-oriented site</i>, the rate of new hardware and software adoption is so slow.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/wwwwwdd/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Long Would It Take if Everything Went Wrong? ]]></title>
<link>https://blog.codinghorror.com/how-long-would-it-take-if-everything-went-wrong/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm currently reading Steve McConnell's new book, <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art</a>. The section on individual expert judgment provided one simple reason why my estimates are often so horribly wrong:
</p>
<blockquote>
<p>
If you ask a developer to estimate a set of features, the developer will often come back with an estimate that looks like this:
</p>
<p>
</p>
<table width="250">
<tr>
<td><u>Feature</u></td>
<td>
<u>Estimated Days</u>
</td>
</tr>
<tr>
<td>Alpha</td>
<td>1.5
</td>
</tr>
<tr>
<td>Bravo</td>
<td>1.5
</td>
</tr>
<tr>
<td>Charlie</td>
<td>2.0
</td>
</tr>
<tr>
<td>Delta</td>
<td>0.5
</td>
</tr>
<tr>
<td>Echo</td>
<td>0.5
</td>
</tr>
<tr>
<td>Foxtrot</td>
<td>0.25
</td>
</tr>
<tr>
<td>Golf</td>
<td>2.0
</td>
</tr>
<tr>
<td>Hotel</td>
<td>1.0
</td>
</tr>
<tr>
<td>India</td>
<td>0.75
</td>
</tr>
<tr>
<td>Juliet</td>
<td>1.25
</td>
</tr>
<tr>
<td><b>Total</b></td>
<td>
<b>11.25</b>
</td>
</tr>
</table>
<p>
If you then ask the same developer to reestimate each feature's best case and worst case, the developer will often return with estimates similar to these:
</p>
<p>
</p>
<table width="400">
<tr>
<td><u>Feature</u></td>
<td><u>Best Case (days)</u></td>
<td>
<u>Worst Case (days)</u>
</td>
</tr>
<tr>
<td>Alpha</td>
<td>1.25</td>
<td>2.0
</td>
</tr>
<tr>
<td>Bravo</td>
<td>1.5</td>
<td>2.5
</td>
</tr>
<tr>
<td>Charlie</td>
<td>2.0</td>
<td>3.0
</td>
</tr>
<tr>
<td>Delta</td>
<td>0.75</td>
<td>2.0
</td>
</tr>
<tr>
<td>Echo</td>
<td>0.5</td>
<td>1.25
</td>
</tr>
<tr>
<td>Foxtrot</td>
<td>0.25</td>
<td>0.5
</td>
</tr>
<tr>
<td>Golf</td>
<td>1.5</td>
<td>2.5
</td>
</tr>
<tr>
<td>Hotel</td>
<td>1.0</td>
<td>1.5
</td>
</tr>
<tr>
<td>India</td>
<td>0.5</td>
<td>1.0
</td>
</tr>
<tr>
<td>Juliet</td>
<td>1.25</td>
<td>2.0
</td>
</tr>
<tr>
<td><b>Total</b></td>
<td><b>10.5</b></td>
<td>
<b>18.25</b>
</td>
</tr>
</table>
<p>
When you compare the original single-point estimates to the Best Case and Worst Case estimates, you see that the 11.25 total of the single-point estimates is much closer to the Best Case estimate of 10.5 days than to the Worst Case total of 18.25 days.
</p>
<p>
You'll also notice that both the Best Case and Worst Case estimates are higher than the original single-point estimate. Thinking through the worst case result can sometimes expose additional work that must be done even in the best case, which can raise the nominal estimate. <b>In thinking through the worst case, I like to ask developers how long the task would take if <i>everything</i> went wrong. People's worst case estimates are often optimistic worst cases rather than <i>true</i> worst cases.</b>
</p>
</blockquote>
<p>
It's an eye-opening exercise. And I'm ashamed to report that I've always used single-point estimates when estimating my work. This is the starting point for many project scheduling disasters, something McConnell refers to as a <b>Collusion of Optimists</b>:
</p>
<p>
</p>
<blockquote><i>
Considering that optimism is a near-universal fact of human nature, software estimates are often undermined by what I think of as a Collusion of Optimists. Developers present estimates that are optimistic. Executives like the optimistic estimates because they imply that desirable business targets are achievable. Managers like the estimates because they imply that they can support upper management's objectives. And so the software project is off and running with no one ever taking a critical look at whether the estimates were well founded in the first place
</i></blockquote>
<p>
While it's impossible to give a perfect estimate, it's a good idea to start with the worst case scenario and extrapolate backwards to the best case.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-long-would-it-take-if-everything-went-wrong/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Desktopitis ]]></title>
<link>https://blog.codinghorror.com/desktopitis/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
This guy* who gave a presentation with <a href="http://www.cauldwell.net/patrick/blog/">Patrick Cauldwell</a> yesterday revealed his desktop during the presentation. Here's what it looked like:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
After the presentation, I ribbed him about his desktop. You have a few square millimeters of desktop left uncovered, I said. Clearly you have your work cut out for you.
</p>
<p>
He said he considers the desktop dead space if it <i>doesn't</i> have something on it. I think his exact words were "make the desktop work for you". That's a unique perspective. It's more of a <b>portal philosophy</b>. Fill the desktop to the brim with tons of stuff that's relevant to you, so it's always at your fingertips.
</p>
<p>
This made me stop and think a bit.
</p>
<p>
The desktop is usually dead space, that's true. And dead speace is never useful. But it's not a destination, either. <b>My goal is to never see the desktop.</b> I should always have the task I'm working on front and center, <i>not</i> the desktop. If I need something, I don't want to be forced to press Windows-D to context switch and reveal some links or files sitting on my desktop. That interrupts my task and my flow. I'd rather perform some kind of popup ad-hoc search-- or better yet, use a hotkey-- to get directly to what I want.
</p>
<p>
The last thing I want is for my desktop to <a href="http://www.codinghorror.com/blog/archives/000529.html">look like the Yahoo home page</a>.
</p>
<p>
That said, I realize there's no right answer. Some people strive for blank, zen-like desktops, and some people fill their desktop with as many icons, gadgets, and gewgaws as they can possibly jam in there. It's a religious debate, and people get cranky when someone puts peanut butter in their chocolate.
</p>
<p>
But I still maintain that <b>it's unhealthy to turn the desktop into an artificial <i>destination</i>.</b>  It's like the Las Vegas strip; no matter how many zany attractions they add, eventually visitors have to come to terms with the fact that they've arbitrarily chosen to build those attractions in the middle of a vast, inhospitable desert.
</p>
<p>
* I think his name was gretelman.. something..
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/desktopitis/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Laptop Alternatives ]]></title>
<link>https://blog.codinghorror.com/laptop-alternatives/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was desperately trying to avoid the expense of buying a new laptop, but my work-provided Thinkpad T43 just isn't cutting it for me.
</p>
<p>
The problem with Thinkpads, even the <a href="http://blogs.vertigosoftware.com/scott/archive/2006/05/04/2714.aspx">very nice new T60 models</a>, is deeper than the hardware and the classic black box design. <b>Thinkpads are <i>uninspiring</i>. They're the gray flannel suit of the IT industry.</b> Every other attendee at TechEd 2006 was sporting the same old boring corporate issue ThinkPad.  Every time I pulled the T43 out of my bag, I felt like I was advertising the fact that I didn't give a damn.
</p>
<p>
I want something different. Something more interesting. Here's what I'm looking for:
</p>
<p>
</p>
<ul>
<li>
<b>A Core Duo CPU</b>. Easily the best CPU Intel has produced in years. The latest batch of Core Duo laptops, even the slowest and smallest ones, are plenty powerful enough for pretty much anything except high-end gaming or video editing. And Core Duo 2 is right around the corner, in the unlikely event that you happen to need even more CPU power.
</li>
<li>
<b>Near ultra-portable</b>, to the tune of 5 pounds <i>maximum</i>, with a reasonably sized 13" or 14" screen. I figure the whole point of having a laptop is so that you can easily take it with you-- without it becoming <a href="http://www.oqo.com/hardware/basics/">absurdly, awkwardly small</a>. I do want to stick with the standard, proven laptop form factor.
</li>
<li>
<b>Dedicated video hardware</b>. I want Vista to run well with its hardware accelerated GUI. That means real third-party graphics hardware with dedicated graphics memory, not that Intel onboard integrated shared memory crap. This also means I could possibly play a game or two in a pinch, but that's not a priority. It's more like a fringe benefit of Vista compatibility.
</li>
<li>
<b>No optical drive</b>. Or at least provide the option to remove the optical drive. Really, who uses optical drives any more? That's an extra half-pound I'd rather not carry around. I can drag an external USB slimline optical drive with me if I'm ever going to need it. Which is probably never.
</li>
</ul>
<p>
After obsessively searching through all my options, here's what I arrived at:
</p>
<p>
</p>
<ol>
<li>
<a href="http://laptopmag.com/Review/Lenovo-ThinkPad-X60s.htm">Lenovo Thinkpad X60</a><br>
<br>
A non-starter for several reasons, the first of which is that it's a Thinkpad. It's also very spendy. And no <a href="http://www.codinghorror.com/blog/archives/000600.html">touchpad</a>? No purchase. The lack of an embedded optical drive is a big-- and rare-- plus, however.
<p>
</p>
</li>
<li>
<a href="http://www.trustedreviews.com/article.aspx?page=7130&amp;head=0">Samsung Q35</a><br>
<br>
The Q35 is very tempting. But integrated video is a showstopper. If it had dedicated video, I think this would have been my final choice.
<p>
</p>
</li>
<li>
<a href="http://arstechnica.com/reviews/hardware/macbookpro.ars">MacBook Pro</a><br>
<br>
Apple laptops are actually <a href="http://www.codinghorror.com/blog/archives/000591.html">a good value for the money now that they've switched to Intel</a>. I like the design and the hardware choices Apple made a lot, but I ultimately decided against it. I'd never use OSX. It seems a waste to boot this machine to Windows exclusively. Plus, the keyboard and trackpad are designed for the Mac world and require some annoying rejiggering for proper Windows support.
<p>
</p>
</li>
<li>
<a href="http://www.notebookreview.com/default.asp?newsID=2950&amp;review=Dell+Inspiron+e1405">Dell e1405</a><br>
<br>
Yes, Dell laptops are a great value. My current laptop is a Dell. But they're too mainstream for my taste. We live in a world of platform choices; repeatedly choosing a Dell is a catastrophic failure of imagination. And there's that ubiquitous integrated graphics problem, anyway.
<p>
</p>
</li>
<li>
<a href="http://www.notebookreview.com/default.asp?newsID=2862&amp;review=Sony+VAIO+SZ270P%2FC+Notebook+%2D+VGN%2DSZ270P%2FC">Sony VAIO SZ</a><br>
<br>
The integrated camera and biometric reader on the VAIO is a nice touch. But I don't trust Sony for drivers and support; their stuff is always pretty but vapid. The integrated nVidia 7400 video is solid, if about 20 percent slower than the X1600 on the MacBook Pro. And the lack of gigabit ethernet is just plain sloppy.
<p>
</p>
</li>
<li>
<a href="http://www.trustedreviews.com/article.aspx?art=3031">Asus W3J</a><br>
<br>
Ladies and gentlemen, we have a winner.
</li>
</ol>
<p>
Asus is the OEM who manufactures Apple's laptops, and it shows: the <a href="http://usa.asus.com/products4.aspx?l1=5&amp;l2=61&amp;l3=0&amp;model=1072&amp;modelmenu=1">Asus W3J</a> hits the sweet spot on all my criteria.
</p>
<p>
</p>
<ul>
<li>14" 1280x768 widescreen Core Duo
</li>
<li>4.4 lbs without DVD-R
</li>
<li>Clean, slimline aluminum design
</li>
<li>Dedicated ATI x1600 graphics
</li>
<li>A nifty swappable bay which supports DVD-R (included), blank bay for lightest weight, an extra battery, or an extra hard drive.
</li>
</ul>
<p>
The <a href="http://forum.notebookreview.com/showthread.php?t=55880">W3J owner's forum on notebook review</a> is full of glowing praise and almost nothing in the way of complaints.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Another bit of good news is that Asus has <b>silently upgraded the specs on the W3J</b>. The vendor I purchased the computer from called me to verify my order, and while he was chatting with me he mentioned that any W3J that ships from the Asus factory in June will have the following spec improvements:
</p>
<ul>
<li>a single 1 gigabyte DIMM instead of the two 512 megabyte DIMMs
</li>
<li>a 2.0 GHz Core Duo chip instead of the 1.83 GHz Core Duo
</li>
</ul>
<p>
And they throw in a bluetooth mouse to boot. Of course, the first thing I'll be doing is <a href="http://www.37signals.com/svn/archives2/does_this_company_respect_me_try_the_sticker_test.php">peeling those ridiculous stickers</a> off the machine.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/laptop-alternatives/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ PC Pinball Sims ]]></title>
<link>https://blog.codinghorror.com/pc-pinball-sims/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of my favorite things to play on <a href="http://blogs.vertigosoftware.com/jatwood/archive/2005/11/18/1654.aspx">Verticade</a>, our full size MAME arcade machine, is <b>pinball simulators</b>. There's something about the completely digital simulation of analog gameplay that fascinates me. Plus, it's easy to take five or ten minutes out for a quick game of pinball. No MMORPG time commitment necessary.
</p>
<p>
Of course, it helps to have the right controls; our <a href="http://www.slikstik.com/co2features.htm">SlikStik arcade controller</a> includes the optional pinball kit: two buttons on each side for flipper and nudge, and a single button on the front right for the plunger. It may not sound like much, but as any <a href="http://www.codinghorror.com/blog/archives/000437.html">Guitar Hero</a> fan will tell you, sometimes the controller makes all the difference. There are some <a href="http://www.lastbandit.com/pinrevue.html?pbr_thrust">obscure pinball controllers</a> out <a href="http://www.pcpinball.com/reviews/english/hardware/pvrpb.html">there</a>, but a garden variety keyboard will do in a pinch.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Unfortunately, PC pinball sims are a dying breed. And <b>of the few commercial pinball games that were ever released, only a handful can be considered true <i>simulators</i></b>, with realistic approximations of the complex newtonian physics at work on a pinball playfield. If you're a fan, here are three pinball sims you definitely shouldn't miss:
</p>
<p>
</p>
<ol>
<li>
<b>Empire Interactive's <a href="http://www.mobygames.com/game_group/sheet/gameGroupId,113/">Pro Pinball series</a></b> is widely regarded as the best of the best. I agree. Start here:
<p>
</p>
<ul>
<li>
<a href="http://www.gamespot.com/pc/puzzle/propinballtheweb/index.html">Pro Pinball - The Web</a> (1996)
</li>
<li>
<a href="http://www.gamespot.com/pc/puzzle/propinballtimeshock/index.html">Pro Pinball - Timeshock!</a> (1997)
</li>
<li>
<a href="http://www.gamespot.com/pc/puzzle/propinballbigraceusa/index.html">Pro Pinball - Big Race U.S.A.</a> (1998)
</li>
<li>
<a href="http://www.gamespot.com/pc/puzzle/propinballfantasticjourney/index.html">Pro Pinball - Fantastic Journey</a> (1999)
</li>
</ul>
</li>
<p>
The physics are reasonable enough in The Web, but starting with Timeshock!, they're impeccable. In Big Race USA and Fantastic Journey, you can even cause the ball to pop up off the table and <i>hit the backglass!</i>
</p>
<p>
</p>
<li>
<b>Team 17's <a href="http://www.gamespot.com/pc/puzzle/addictionpinball/index.html">Addiction Pinball</a></b> is a very close second to the Pro Pinball series. The physics are slighly relaxed, but still quite accurate. And the two tables are a bit more forgiving as well.
<p>
</p>
</li>
<li>
<b>3D Realms' <a href="http://www.gamespot.com/pc/puzzle/ballsofsteel/index.html">Balls of Steel</a></b> is also worthwhile if you're willing to forgo realistic physics entirely in favor of fun. This is probably the purest old-school arcade style pinball I've found.
</li>
</ol>
<p>
I've played most of the tables in the top 25 of the <a href="http://www.pcpinball.com/cgi-bin/reviews/reviews.cgi?language=english&amp;platform=PC&amp;category=RECS&amp;list_type=RANK">Tower of Pin review rankings</a>, and these three are head and shoulders above the rest. They're all true Windows apps that <b>run fine under Windows XP and Windows Vista</b>, too. Some of the others in the top 10 are old DOS apps that are painful to get running properly, even in <a href="http://dosbox.sourceforge.net/news.php?show_news=1">DOSBox</a>.  Some of these games are fairly old by now, so they can be difficult to find:
</p>
<p>
</p>
<ol>
<li>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=%26%2334%3Bpro%20pinball%26%2334%3B&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">Pro Pinball</a> on Amazon; <a href="http://rover.ebay.com/rover/1/711-53200-19255-0/1?type=3&amp;campid=5335832961&amp;toolid=10001&amp;customid=&amp;ext=pro+pinball&amp;satitle=pro+pinball">Pro Pinball</a> on eBay
</li>
<li>
<a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=addiction%20pinball&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">Addiction Pinball</a> on Amazon; <a href="http://rover.ebay.com/rover/1/711-53200-19255-0/1?type=3&amp;campid=5335832961&amp;toolid=10001&amp;customid=&amp;ext=addiction+pinball&amp;satitle=addiction+pinball">Addiction Pinball</a> on eBay
</li>
<li>If you have a decent 3D card, these newer pinball sims offer the rough equivalent of Balls of Steel level physics, with <i>much</i> better graphics: <a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=pure%20pinball%202.0&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">Pure Pinball 2.0</a> and <a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=dream%20pinball%203d&amp;tag=codihorr-20&amp;index=blended&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">Dream Pinball 3D</a> on Amazon
</li>
</ol>
<p>
And no, the <a href="http://www.rdrop.com/~half/General/GameTips/space.cadet.html">Space Cadet pinball bundled with Windows XP</a> doesn't count. Although, if you like that style of pinball, you can pick up Maxis' <a href="http://www.gamespot.com/pc/puzzle/fulltiltpinball/index.html">Full Tilt!</a> and <a href="http://www.gamespot.com/pc/puzzle/fulltilt2pinball/index.html">Full Tilt! 2</a>, which is where the Space Cadet table was lifted from.
</p>
<p>
The good news is that <b>the community is picking up the slack in commercial pinball sim releases</b>. I'm not really a fan of <a href="http://www.randydavis.com/vp/">Visual Pinball</a>, due to the wonky physics and strictly 2D gameplay, but the community around it is vibrant and prolific.
</p>
<p>
I'm much more excited about <a href="http://www.futurepinball.com/">Future Pinball</a>, which truly takes pinball sims to the next level-- no more pre-rendered playfields! Future Pinball is essentially an editor which lets you design your own tables in full 3D, and play them in hardware accelerated 3D, too. It comes with one so-so demo table that has a generic alien theme, but there are already a <a href="http://fprelease.free.fr/">number of excellent community-created tables out there</a> for Future Pinball.
</p>
<p>
And now we've come completely full circle to my childhood...
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
.. and the hours and hours I spent building my own pinball machines in <a href="http://archive.gamespy.com/halloffame/september02/pcs/">Bill Budge's Pinball Construction Set</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/pc-pinball-sims/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Pretty Code, Ugly Code ]]></title>
<link>https://blog.codinghorror.com/pretty-code-ugly-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Christopher Seiwald's <a href="http://www.perforce.com/perforce/papers/prettycode.html">Seven Pillars of Pretty Code</a> argues that <b>code that looks good, works good</b>:
</p>
<p>
</p>
<ol>
<li>
<b>Code changes should blend in with the original style.</b>
<p>
It should not be possible to discern previous changes to a file without seeing the previous revisions. Nothing obscures the essential visual cues more than a shift in style. This practice should be applied as wide as possible: absolutely within functions, generally within a file, and if you're lucky across the system.
</p>
<p>
</p>
</li>
<li>
<b>Keep columns narrow.</b>
<p>
Just as with books and magazines, code should be narrow to focus the gaze. As I mention in "Overcome Indentation," the left edge of the code holds the structure and the right side holds the detail, and big long lines mix zones of structure and detail, confusing the reader.
</p>
<p>
</p>
</li>
<li>
<b>Break code into logical blocks so that each does a single thing or single kind of thing.</b>
<p>
This principle should apply within functions, and in a larger sense, among separate code blocks. A reader can only avoid a total reading if a cursory inspection can reveal the whole block's nature.
</p>
<p>
</p>
</li>
<li>
<b>Set off code blocks with whitespace and comments that describe each block.</b>
<p>
Comments should rephrase what happens in the block, not be a literal translation into English. Even if your code is inscrutable and your comments jibberish, the reader can at least attempt to triangulate on the actual purpose.
</p>
<p>
</p>
</li>
<li>
<b>Reduce, reduce, reduce. Remove anything that will distract the reader.</b>
<p>
Use short names (like i, x) for variables with a short, local scope or ubiquitous names. Use medium length for member names. Use longer names only for global scope (like distant or OS interfaces). The tighter the scope, the shorter the name. Long, descriptive names may help the first time reader but hinder him every time thereafter.
</p>
<p>
</p>
</li>
<li>
<b>Two or more pieces of code that do the same or similar thing should be made to look the same.</b>
<p>
Nothing speeds the reader along better than seeing a pattern. These similar looking pieces of code should be lined up one after the other. Grouping reduces the number of entities the reader has to grasp, a critical approach to simplifying the apparent complexity of code.
</p>
<p>
</p>
</li>
<li>
<b>The left edge of the code defines its structure, while the right side holds the detail.</b>
<p>
You must fight indentation to safeguard this property. Code which moves too quickly from left to right (and back again) mixes major control flow with minor detail. Forcibly align the main flow of control down the left side, with one level of indentation for if/while/for/do/switch statements. Use break, continue, return, even 'goto' to coerce the code into left-side alignment. Rearrange conditionals so that the block with the quickest exit comes first, and then return (or break, or continue) so that the other leg can continue at the same indentation level.
</p>
</li>
</ol>
<p>
It's an entirely reasonable set of advice. Until you realize that Christopher is using his very own <a href="http://www.codinghorror.com/blog/files/make.c.htm">jam/make.c</a> as a shining example of the pillars of pretty code.
</p>
<p>
And <b>make.c is extremely ugly to me</b>.
</p>
<p>
I don't know if I'd ever consider C code <i>pretty</i>, per se. Maybe it has a nice personality. But pretty? No way. And I'm sure Ruby, Lisp, and Smalltalk aficionados feel the same way about C# code. I know most C# developers can barely force themselves to even look at VB.NET code.
</p>
<p>
Clearly, pretty code is in the eye of the beholder.
</p>
<p>
Besides the fact that it's C, I have a few other problems with Mr. Seiwald's <a href="http://www.codinghorror.com/blog/files/make.c.htm">make.c code</a>:
</p>
<p>
</p>
<ul>
<li>It embeds source control information in the comments. Isn't this why we have source control systems?
</li>
<li>It uses complex, difficult to maintain block alignments in the comments, variables, and function declarations. Unless your IDE does this for you, this is the formatting equivalent of a house of cards.
</li>
<li>There are functions named make and make0. Ouch.
</li>
</ul>
<p>
The code formatting, as promised, is pretty. But the emphasis on formatting does make me wonder-- rather than focusing on the external, cosmetic attributes of the code, shouldn't we be searching for something prettier on the <i>inside?</i> Such as a higher level language?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/pretty-code-ugly-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is Writing More Important Than Programming? ]]></title>
<link>https://blog.codinghorror.com/is-writing-more-important-than-programming/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>The unofficial wikipedia blog entry <a href="http://wikip.blogspot.com/2005/08/future-of-open-source-5-years-ago.html">The Future of Open Source Five Years Ago</a> makes some fascinating comparisons between the adoption rate of Linux and the adoption rate of Wikipedia.</p>
<blockquote>Server-side Linux is still a powerful force, but what happened to the desktop utopia that was supposed to unseat Windows? And will the same developed-world disenchantment hit Wikipedia as it grows?
<p>While in principle anyone can contribute to an open source project, Linux's barriers to entry are higher than Wikipedia's. Even correcting minor Linux bugs is well beyond my expertise, but my grandmother could edit Wikipedia. All you need is an internet connection and literacy (mid-level literacy, at that; other people will fix your grammar and spelling).</p>
<p><strong>Wikipedia can draw on half a billion potential contributors; only about 100,000 people can code Linux.</strong></p>
<p>It's hard to overstate this difference.</p>
</blockquote>
<p>To illustrate this point, it's accompanied by an amusing graph.</p>
<p><a href="https://blog.codinghorror.com/content/images/uploads/2006/06/6a0120a85dcdae970b0163033e684d970d-pi.png"><img alt="image placeholder" >
<p>I've resized the graph to a more manageable size. Click through to see it full size. The writing on the bars is hard to make out. On the left, it's..</p>
<p><em>Number of programmers who can contribute to Linux, including minor bugfixes.</em></p>
<p>And on the right?</p>
<p><em>Number of people in the world who speak English well enough to edit Wikipedia and who have access to the internet. (This includes non-native speakers. It omits potential contributors to non English-language wikipedias only because this bar is already absurdly tall. (Okay, and because wikipedias of seperate languages are, to some degree, islands, and don't function as a cohesive whole.))</em></p>
<p>It's probably not fair to compare programming and writing in this manner, but I am reminded again of Joel Spolsky's <a href="http://www.joelonsoftware.com/articles/CollegeAdvice.html">classic advice for computer science college students</a>:</p>
<blockquote>The difference between a tolerable programmer and a great programmer is not how many programming languages they know, and it's not whether they prefer Python or Java. <strong>It's whether they can communicate their ideas.</strong> By persuading other people, they get leverage. By writing clear comments and technical specs, they let other programmers understand their code, which means other programmers can use and work with their code instead of rewriting it. Absent this, their code is worthless. By writing clear technical documentation for end users, they allow people to figure out what their code is supposed to do, which is the only way those users can see the value in their code. There's a lot of wonderful, useful code buried on sourceforge somewhere that nobody uses because it was created by programmers who don't write very well (or don't write at all), and so nobody knows what they've done and their brilliant code languishes.</blockquote>
<p>Programming, like all writing, is just another form of communication. Writing code that the compiler understands is easy. Writing code that <em>other people</em> understand is far more difficult. And that's assuming you're persuasive enough to convince other people that your code, in a world positively overflowing with free code, is <em>worth</em> looking at in the first place.</p>
<p>Good luck. You're gonna need it.</p>
<blockquote>Over the next few years, Wikipedia (and some of its Wikimedia sister sites) will become comparable to Linux in economic and social significance. Maybe Linux will catch up again a few decades later, if schools start teaching as many kids to program as they teach to write.</blockquote>
<p>This quote was originally written in August 2005. I'd argue that Wikipedia was already more significant to the average internet user than Linux at that time. Now there's no question.</p>
<p>Technical programming skills are certainly important. But general writing and communication skills are far, far more important. Even if you're merely a humble programmer.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-writing-more-important-than-programming/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ When Object-Oriented Rendering is Too Much Code ]]></title>
<link>https://blog.codinghorror.com/when-object-oriented-rendering-is-too-much-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Let's say you wanted to generate and render this XML fragment:
</p>
<p>
</p>
<pre language="xml" name="code">
&lt;status code="1" /&gt;
&lt;data&gt;
&lt;usergroup id="usr" /&gt;
&lt;/data&gt;
</pre>
<p>
Here's a fully object-oriented way of building it:
</p>
<p>
</p>
<pre language="c#" name="code">
System.Text.StringBuilder sb = new System.Text.StringBuilder();
XmlWriterSettings xs = new XmlWriterSettings();
xs.ConformanceLevel = ConformanceLevel.Fragment;
xs.Indent = true;
XmlWriter xw = XmlWriter.Create(sb, xs);
xw.WriteStartElement("status");
xw.WriteAttributeString("code", "1");
xw.WriteEndElement();
xw.WriteStartElement("data");
xw.WriteStartElement("usergroup");
xw.WriteAttributeString("id", "usr");
xw.WriteEndElement();
xw.WriteEndElement();
xw.Flush();
return sb.ToString();
</pre>
<p>
That seems like a <i>tremendous</i> amount of code to do something relatively simple. I could abandon the pure object approach and do it in two lines of code:
</p>
<p>
</p>
<pre language="c#" name="code">
string s =
@"&lt;status code=""{0}"" /&gt;
&lt;data&gt;
&lt;usergroup id=""{1}"" /&gt;
&lt;/data&gt;";
return String.Format(s, "1", "usr");
</pre>
<p>
It's far less code. And it's much easier to read!
</p>
<p>
I've worked with developers who insisted that <b>everything had to be generated through an object model</b>, even if the object-oriented way required many times the amount of code. Although I haven't worked with Daniel Cazzulino, he <a href="http://weblogs.asp.net/cazzu/archive/2004/07/15/AwfulResponseWrite.aspx">typifies this attitude</a>:
</p>
<blockquote>
If you're using Response.Write, you're a dreadful citizen of the ASP.NET world.
<p>
As my friend Victor said, "Response.Write is there just for compatibility reasons and for old script programmers to not feel lonely".
</p>
<p>
An app written in such a way will not only be difficult to maintain and evolve, it will be almost impossible to customize (specially its layout), will never catch up with the upcoming mobile features and just hurts the eye.  Everytime I see a Response.Write, and specially if it's not even kind enough to use HtmlTextWriterTag, HtmlTextWriterAttribute and HtmlTextWriterStyle, the developer who wrote it is instantly removed from my in-memory list of good ASP.NET programmers.
</p>
</blockquote>
<p>
<a href="http://west-wind.com/weblog/posts/5906.aspx">Like Rick Strahl</a>, I'm not convinced the verbosity of objects like HtmlTextWriter and XmlTextWriter are warranted.
</p>
<p>
The idea of "write once, run anywhere" via a complex set of objects and adapters is a pleasant one, but it also adds a heavy burden of verbosity and complexity to your project. And <a href="http://xp.c2.com/YouArentGonnaNeedIt.html">you probably aren't gonna need it</a> anyway. <b>Sometimes it's simpler and clearer to render the HTML or XML directly to the page without all that OO cruft gunking up the works.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/when-object-oriented-rendering-is-too-much-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Text Columns: How Long is Too Long? ]]></title>
<link>https://blog.codinghorror.com/text-columns-how-long-is-too-long/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Ian Griffiths recently <a href="http://www.interact-sw.co.uk/iangblog/2006/06/21/wpfmsdn">wrote a proof of concept WPF browser for the MSDN online help</a>. One of the improvements cited is multi-column text:</p>
<blockquote>This is why WPF offers a column-based reading experience. <strong>We know from experience in the print world that breaking text into columns can make it much easier to read.</strong> Indeed, once you've got used to reading in columns, going back to the long unbroken lines offered by the standard SDK viewer feels like punishment!</blockquote>
<p>Code is a highly specialized form of writing, but the same sort of questions always come up. Should we use short lines or long lines? A recent comment from Buggy Fun Bunny* describes this conundrum well:</p>
<blockquote>What I've found amusing for the last 20 years is this insistence, by people who should know better, on 80 column (or less) line limits. That was invented by COBOL (which only has ~66 characters available after you subtract the line number from 73) around 1960. It's just silly. I remember how wonderful it was when the VT-220 came along and I could use 132 character lines. If nothing else, formatting a report both in code and as output was a piece of cake.
<p>Beyond the character world, we have wide screen taking over, and folks still think that 80 columns is King. There's more horizontal real estate, and always was. Use it well.</p>
<p>And as to scanning narrow: not everybody does; I've had the Great Books set and can't read them because those narrow double columns drive my eyes over the edge.</p>
</blockquote>
<p>Hey, I'm a <a href="http://www.greatbooks.org/">Great Books</a> fan from way back in the day. Nothing blows a seventh grader's mind quite like <a href="http://www.greatbooks.org/typ/index.php?id=116">reading</a> Graham Greene's <em>The Destructors</em>, or Carson McCuller's <em>Sucker</em>. No wonder people want to burn books. They're subversive.</p>
<p>So what's the best way to structure columns of text on a computer screen? How long is too long? Luckily, the <a href="http://psychology.wichita.edu/surl/">Software Usability Research Laboratory at Wichita State</a> has already <a href="http://psychology.wichita.edu/surl/usabilitynews/72/columns.htm">researched</a>  and answered  this question.</p>
<p>But before I reveal the answer, what do you think? Which of these passages is easier to read and comprehend?</p>
<h3>Single column, left aligned</h3>
<div style="margin-left: 15px; font-family:georgia;">
<p>Alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, and what is the use of a book, thought Alice, without pictures or conversations?</p>
<p>So she was considering, in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.</p>
<p>There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself Oh dear! Oh dear! I shall be too late! (when she thought it over afterwards it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but, when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and was just in time to see it pop down a large rabbit-hole under the hedge.</p>
</div>
<h3>Single column, justified</h3>
<div style="margin-left: 15px; text-align:justify; font-family:georgia;">
<p>Alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, and what is the use of a book, thought Alice, without pictures or conversations?</p>
<p>So she was considering, in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.</p>
<p>There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself Oh dear! Oh dear! I shall be too late! (when she thought it over afterwards it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but, when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and was just in time to see it pop down a large rabbit-hole under the hedge.</p>
</div>
<h3>Double column, left aligned</h3>
<div style="margin-left: 15px; font-family:georgia;">
<table width="800px;">
<tr>
<td style="width:50%; vertical-align: top; padding-right:2em;">
<p>Alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, and what is the use of a book, thought Alice, without pictures or conversations?</p>
<p>So she was considering, in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.</p>
</td>
<td style="width:50%; vertical-align: top;">
<p>There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself Oh dear! Oh dear! I shall be too late! (when she thought it over afterwards it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but, when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and was just in time to see it pop down a large rabbit-hole under the hedge.</p>
</td>
</tr>
</table>
</div>
<h3>Double column, justified</h3>
<div style="margin-left: 15px; text-align:justify; font-family:georgia;">
<table width="800px;">
<tr>
<td style="width:50%; vertical-align: top; padding-right:2em;">
<p>Alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, and what is the use of a book, thought Alice, without pictures or conversations?</p>
<p>So she was considering, in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.</p>
</td>
<td style="width:50%; vertical-align: top;">
<p>There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself Oh dear! Oh dear! I shall be too late! (when she thought it over afterwards it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but, when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and was just in time to see it pop down a large rabbit-hole under the hedge.</p>
</td>
</tr>
</table>
</div>
<p>The answer is more complex than you might think. The SURL paper first summarizes <strong>past findings of previous research</strong>:</p>
<ul>
<li>Longer line lengths generally facilitate faster reading speeds. </li>
<li>Shorter line lengths result in increased comprehension. </li>
<li>The optimal number of characters per line is between 45 and 65. </li>
<li>Paging through online text generally results in better comprehension than scrolling. </li>
<li>Reading speed is faster for both single and multiple columns, but preference is for multiple short columns. </li>
<li>Left-justified text is read faster than full-justified text. </li>
</ul>
<p>And here's what they found in <a href="http://psychology.wichita.edu/surl/usabilitynews/72/columns.htm">their study</a>:</p>
<blockquote>
<img alt="image placeholder" >
<p>The results of this study suggest that there is not one best way to present text online. Although <strong>fast readers performed best at the two-column full-justified condition, slow readers benefited from a single column non-justified layout</strong>.</p>
</blockquote>
<p>Personally, I was surprised that <strong>justification had such a strong influence on the results.</strong> Simply breaking up text into columns actually <em>hurts</em> reading speed noticeably for both slow and fast readers. However, if you fully justify the columns, then  and only then  reading speed increases dramatically for everyone. And clearly, three column layouts aren't worth it, no matter how you align the text.</p>
<p>So what conclusion can we draw for coders? Probably not much. Code is always left aligned, and in a single column. A related SURL study examines the <a href="http://psychology.wichita.edu/surl/usabilitynews/72/LineLength.htm">effect of line length alone</a> which might be more relevant:</p>
<blockquote>This study examined the effects of line length on reading performance. <strong>Reading rates were found to be fastest at 95 cpl.</strong> Readers reported either liking or disliking the extreme line lengths (35 cpl, 95 cpl). Those that liked the 35 cpl indicated that the short line length facilitated "faster" reading and was easier because it required less eye movement. Those that liked the 95 cpl stated that they liked having more information on a page at one time. <strong>Although some participants reported that they felt like they were reading faster at 35 cpl, this condition actually resulted in the slowest reading speed.</strong>
</blockquote>
<p>Furthermore, line length had no effect on comprehension. Although I'm hesitant to draw broad parallels between source code and a news article, perhaps arbitrarily short lines aren't <em>always</em> necessary in source code to achieve good readability and comprehension.</p>
<p><small>* I just write this stuff down. I don't make it up.</small></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/text-columns-how-long-is-too-long/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Vive la Programming Revolution! ]]></title>
<link>https://blog.codinghorror.com/vive-la-programming-rvolution/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><img alt="image placeholder" >
<p>Or you could just read his <a href="http://alarmingdevelopment.org/index.php?p=5">blog post</a>. Here are a few highlights:</p>
<blockquote>Compared to every other field of design and engineering, programming is an embarrassment and a failure. The "software crisis" has dogged us from almost the beginning. We who have made programming our life will no longer tolerate this.
<p>Programming languages are the fundamental technology of programming. To make fundamental improvements in programming you need a fundamentally better programming language.</p>
<p>There is a widespread belief in both industry and academia that working on new programming languages is pointless. This is short-sighted. Historically, all sciences and technologies undergo revolutionary change. The lack of meaningful progress in the last 20 years means that there is an enormous pent-up potential for change, and the lack of interest in it means there is an enormous opportunity for the intrepid. It is a good time for a revolution.</p>
<p>To fully embrace adaptation as the essence of programming will require a change of attitude that is quite difficult: discarding elegant yet fragile constructions in favor of messy but flexible ones. One case in point is copy-and-paste programming. This violates all the accepted rules of modularity and hygiene, yet everyone still does it routinely. Either most programmers are stupid and evil, or the accepted rules are idealistic and impractical. The latter is the case. It is necessary to embrace copy-and-paste as a first-class "semi-modularity" mechanism in the language  to track it, manage it, and eventually refactor it into "proper" modularity. This may be heretical, yet an honest appraisal of how programmers really work requires something like it. Usability is a subversive idea.</p>
<p>In Science and Math, formulas are typically one-liners. Even small programs are far larger than any mathematical statement. Expression-based languages attempt to scale up formulas to hundreds or thousands of lines. One reason this does not work is that people can not easily handle more than about 2 levels of nesting. We are not stack machines! Natural languages rely on linear narrative flow and avoid deep nesting. This may be the real problem with LISP: people complain about parentheses, but they are really complaining about deep nesting.</p>
<p>Commercial considerations often dictate that compatibility and performance have the highest priority, with disastrous consequences (witness C++). As the Open Source movement has demonstrated, progress requires overthrowing the economics of software. <strong>We will need to go even further, freeing our minds of traditions established with the very first programming languages.</strong> Usability is the guiding light to rationally reinvent programming from scratch.</p>
<p>Programming is at a dead-end. The only way things will get better is with a complete revolution. More conservative attempts over the years have repeatedly failed to make a difference, leading to the widespread abandonment of hope. We have nothing to lose.</p>
</blockquote>
<p>You might say it's a <a href="http://en.wikipedia.org/wiki/Open-air_preaching">street corner preacher</a> rant. But that's what makes it so good.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/vive-la-programming-rvolution/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Meet the Arch-Nemesis of Productivity: The Internet ]]></title>
<link>https://blog.codinghorror.com/meet-the-arch-nemesis-of-productivity-the-internet/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In a world of <a href="http://www.43folders.com/">43Folders</a>* and dozens of other blogs that worship at the altar of <a href="http://www.43folders.com/2004/09/08/getting-started-with-getting-things-done/">Getting Things Done</a>, it's a little surprising that nobody has taken aim at the #1 enemy of productivity everywhere: <b>The Internet</b>.
</p>
<p>
Do you spend so much time obsessively keeping up with the latest ninja tips on productivity, programming, and time management that you <i>run out of time to actually Get Things Done?</i>
</p>
<p>
If so, you're not alone.
</p>
<p>
I have a <i>wee problem</i> with procrastination. The internet, and chain upon chain of fascinating links, is never more than a keystroke away. It's a problem.
</p>
<p>
<a href="http://www.ashersarlin.com/archives/2004/09/honestly_who_co.php"><img alt="image placeholder" >**
</p>
<p>
Sometimes I truly think I'd be more productive if I <b>disconnected my ethernet jack.</b>
</p>
<p>
All things in moderation, I suppose, but it's hard to sip from a firehose of information.
</p>
<p>
* Soon to be a book, I'm sure.<br>
** Reprinted from Asher Sarlin's <a href="http://www.ashersarlin.com/">Elephantitis of the Mind</a>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/meet-the-arch-nemesis-of-productivity-the-internet/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Object-Relational Mapping is the Vietnam of Computer Science ]]></title>
<link>https://blog.codinghorror.com/object-relational-mapping-is-the-vietnam-of-computer-science/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I had an opportunity to meet <a href="http://blogs.tedneward.com/">Ted Neward</a> at <a href="http://www.codinghorror.com/blog/archives/000609.html">TechEd</a> this year. Ted, among other things, famously coined the phrase <strong>"Object-Relational mapping is the Vietnam of our industry"</strong> in <a href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">late 2004</a>.</p>
<p><img alt="image placeholder" >
<p>It's a scary analogy, but an apt one. I've seen developers struggle for <em>years</em> with the huge mismatch between relational database models and traditional object models. And all the solutions they come up with seem to make the problem worse. I agree with Ted completely; <strong>there is no good solution to the object/relational mapping problem</strong>. There are solutions, sure, but they all involve serious, painful tradeoffs. And the worst part is that you can't usually see the consequences of these tradeoffs until much later in the development cycle.</p>
<p>Ted posted a <a href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">much anticipated blog entry analyzing the ORM problem in minute detail</a>. It's a long post. But unless you're a battle-scarred veteran of the ORM wars, I highly recommend at least skimming through it so you're aware of the many pitfalls you can run into trying to implement an ORM solution. There are a lot of magic bullets out there, and no shortage of naive developers.</p>
<p>Ted's post is excellent and authoritative, but it's a little wordy; I felt like I was experiencing a little slice of Vietnam while reading it. Let's skip directly to the summary at the end which provides an great list of current (and future) solutions to the ORM problem:</p>
<blockquote><ol>
<li>
<strong>Abandonment.</strong> Developers simply give up on objects entirely, and return to a programming model that doesn't create the object/relational impedance mismatch. While distasteful, in certain scenarios an object-oriented approach creates more overhead than it saves, and the ROI simply isn't there to justify the cost of creating a rich domain model. ([Fowler] talks about this to some depth.) This eliminates the problem quite neatly, because if there are no objects, there is no impedance mismatch.<br><br> </li>
<li>
<strong>Wholehearted acceptance.</strong> Developers simply give up on relational storage entirely, and use a storage model that fits the way their languages of choice look at the world. Object-storage systems, such as the <a href="http://blogs.tedneward.com/ct.ashx?id=33e0e84c-1a82-4362-bb15-eb18a1a1d91f&amp;url=http%3a%2f%2fwww.db4objects.com">db4o project</a>, solve the problem neatly by storing objects directly to disk, eliminating many (but not all) of the aforementioned issues; there is no "second schema", for example, because the only schema used is that of the object definitions themselves. While many DBAs will faint dead away at the thought, in an increasingly service-oriented world, which eschews the idea of direct data access but instead requires all access go through the service gateway thus encapsulating the storage mechanism away from prying eyes, it becomes entirely feasible to imagine developers storing data in a form that's much easier for them to use, rather than DBAs. <br><br>
</li>
<li>
<strong>Manual mapping.</strong> Developers simply accept that it's not such a hard problem to solve manually after all, and write straight relational-access code to return relations to the language, access the tuples, and populate objects as necessary. In many cases, this code might even be automatically generated by a tool examining database metadata, eliminating some of the principal criticism of this approach (that being, "It's too much code to write and maintain"). <br><br>
</li>
<li>
<strong>Acceptance of ORM limitations.</strong> Developers simply accept that there is no way to efficiently and easily close the loop on the O/R mismatch, and use an ORM to solve 80% (or 50% or 95%, or whatever percentage seems appropriate) of the problem and make use of SQL and relational-based access (such as "raw" JDBC or ADO.NET) to carry them past those areas where an ORM would create problems. Doing so carries its own fair share of risks, however, as developers using an ORM must be aware of any caching the ORM solution does within it, because the "raw" relational access will clearly not be able to take advantage of that caching layer. <br><br>
</li>
<li>
<strong>Integration of relational concepts into the languages.</strong> Developers simply accept that this is a problem that should be solved by the language, not by a library or framework. For the last decade or more, the emphasis on solutions to the O/R problem have focused on trying to bring objects closer to the database, so that developers can focus exclusively on programming in a single paradigm (that paradigm being, of course, objects). Over the last several years, however, interest in "scripting" languages with far stronger set and list support, like Ruby, has sparked the idea that perhaps another solution is appropriate: bring relational concepts (which, at heart, are set-based) into mainstream programming languages, making it easier to bridge the gap between "sets" and "objects". Work in this space has thus far been limited, constrained mostly to research projects and/or "fringe" languages, but several interesting efforts are gaining visibility within the community, such as functional/object hybrid languages like Scala or F#, as well as direct integration into traditional OO languages, such as the LINQ project from Microsoft for C# and Visual Basic. One such effort that failed, unfortunately, was the SQL/J strategy; even there, the approach was limited, not seeking to incorporate sets into Java, but simply allow for embedded SQL calls to be preprocessed and translated into JDBC code by a translator. <br><br>
</li>
<li>
<strong>Integration of relational concepts into frameworks.</strong> Developers simply accept that this problem is solvable, but only with a change of perspective. Instead of relying on language or library designers to solve this problem, developers take a different view of "objects" that is more relational in nature, building domain frameworks that are more directly built around relational constructs. For example, instead of creating a Person class that holds its instance data directly in fields inside the object, developers create a Person class that holds its instance data in a RowSet (Java) or DataSet (C#) instance, which can be assembled with other RowSets/DataSets into an easy-to-ship block of data for update against the database, or unpacked from the database into the individual objects. </li>
</ol></blockquote>
<p>Ted quickly posted a <a href="http://blogs.tedneward.com/post/thoughts-on-vietnam-commentary/">followup entry</a> which addressed common criticisms of his original post. If you have an itchy left mouse finger poised over the "comment" link right now, you may want to read that first.</p>
<p>Personally, I think <strong>the only workable solution to the ORM problem is to pick one or the other</strong>: either abandon relational databases, or abandon objects. If you take the O or the R out of the equation, <em>you no longer have a mapping problem</em>.</p>
<p>It may seem crazy to abandon the traditional Customer object  or to abandon the traditional Customer table  but picking one or the other is a totally sane alternative to the complex quagmire of classes, objects, code generation, SQL, and stored procedures that an ORM "solution" typically leaves us with.</p>
<p>Both approaches are certainly valid. I tend to err on the side of the database-as-model camp, because I think <a href="https://blog.codinghorror.com/why-objects-suck/">objects are overrated</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/object-relational-mapping-is-the-vietnam-of-computer-science/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Secretly, We're All Geeks ]]></title>
<link>https://blog.codinghorror.com/secretly-were-all-geeks/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Scott Hanselman was kind enough to <a href="http://www.hanselman.com/blog/RerediscoveringJeffAtwood.aspx">sing the praises of my blog</a> a few months ago, completely unprompted. I finally met Scott in person at TechEd this year, and I can assure you that if you suck, Scott will be the first person to <i>tell you</i> that you suck.* That's how he rolls, ese. So getting a thumbs up from Mr. Hanselman is hard-earned praise indeed, and I do appreciate it.
</p>
<p>
In the fine tradition of <a href="http://www.imdb.com/title/tt0223897/">paying it forward</a>, I want to pass on similar kudos to one of my favorite blogs-- <a href="http://secretgeek.net/">Leon Bambrick's secretGeek</a>.
</p>
<p>
<a href="http://secretgeek.net/"><img alt="image placeholder" >
</p>
<p>
Sure, there may be other blogs out there by authors who are <a href="http://steve-yegge.blogspot.com/">better writers</a>, or who have <a href="http://wesnerm.blogs.com/">killer technical chops</a>, but Leon is all that stuff, and he's <i>consistently funny</i>, too. And not in an uncomfortable, soul-baring, More Than I Needed To Know <a href="http://www.neopoleon.com/blog/">Rory Blythe</a> kind of way, or in the highly unfortunate I Can't Believe This Passes For Humor way of <a href="http://www.userfriendly.org/">User Friendly</a>.
</p>
<p>
Secretly, we may all be geeks-- but very few geeks are as talented at walking the fine line of technical comedy as Mr. Leon Bambrick. It's all funny because it's all true. Take a few minutes to read through his archives and you'll <a href="http://secretgeek.net/Ruby_On_Rails_face.asp">see what I mean</a>.
</p>
<p>
* But in an amusing way, so you'll laugh at how much you suck, too. ;)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/secretly-were-all-geeks/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Mysterious Cone of Uncertainty ]]></title>
<link>https://blog.codinghorror.com/the-mysterious-cone-of-uncertainty/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of the central themes in McConnell's <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art</a> is the ominously named <b>Cone of Uncertainty</b>. The cone defines statistically predictible levels of project estimate uncertainty at each stage of the project.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The cone has several ramifications, the most important of which is that <b>early project estimates will always be wildly inaccurate</b>:
</p>
<p>
</p>
<blockquote>
As you can see from the graph, estimates created very early in the project are subject to a high degree of error. Estimates created at initial concept time can be inaccurate by a factor of 4x on the high side, or 4x on the low side.
</blockquote>
<p>
That means the total estimate range is a staggering 16x at the time of initial concept! And believe it or not, that's a <i>best case</i> scenario:
</p>
<p>
</p>
<p>
</p>
<blockquote>
An important-- and difficult-- concept is that The Cone of Uncertainty represents the best-case accuracy that is possible to have in software estimates at different points in a project. <b>It is easily possible to do worse.</b> It isn't possible to be more accurate; it's only possible to be more lucky.
</blockquote>
<p>
Furthermore, the cone doesn't narrow itself. If you don't actively work to reduce the variability of your project*, the cone of uncertainty quickly becomes a cloud of uncertainty. When will the software be done? <a href="http://en.wikipedia.org/wiki/Duke_Nukem_Forever#Development_timeline">Who knows</a>. That's one reason for the <a href="http://www.codinghorror.com/blog/archives/000588.html">long, dismal history of software project failure</a>.
</p>
<p>
You may also be familiar with this software proverb:
</p>
<p>
</p>
<blockquote>
The first ninety percent of the task takes ninety percent of the time, and the last ten percent takes the other ninety percent.
</blockquote>
<p>
Getting trapped in the Cone of Uncertainty is a classic software project mistake. You think you're <a href="http://www.codinghorror.com/blog/archives/000889.html">99 percent done for months</a>. It's a cruel failure of perspective that's endemic to the profession of software development.
</p>
<p>
It reminds me of the popular <a href="http://en.wikipedia.org/wiki/Mystery_Spot">Mystery Spot</a> tourist attraction in nearby Santa Cruz.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I've been there. The Mystery Spot is a tacky tourist attraction, sure, but it's fun. And even if you're a complete skeptic and card-carrying Mensa member, the <a href="http://en.wikipedia.org/wiki/Ames_Room">Ames Room</a> illusion is incredibly convincing when you, and everyone around you, is standing in it.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Are you really 99 percent done? Or is your entire project stuck in the early, distorted part of the Cone of Uncertainty where you only <i>look</i> 99 percent done? Sometimes it's awfully difficult to tell the difference.
</p>
<p>
* This is something the <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">book </a> goes into great detail on, naturally.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-mysterious-cone-of-uncertainty/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ ASUS W3J Laptop Review ]]></title>
<link>https://blog.codinghorror.com/asus-w3j-laptop-review/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
So my <a href="http://www.codinghorror.com/blog/archives/000613.html">much-anticipated Asus W3J laptop</a> arrived a few days ago. To recap, my requirements for a laptop were:
</p>
<p>
</p>
<ul>
<li>Core Duo
</li>
<li>5 pounds maximum weight
</li>
<li>Dedicated video hardware
</li>
<li>Removable optical drive
</li>
</ul>
<p>
<a href="http://www.engadget.com/2005/06/04/laptops-outsell-desktops-for-the-first-time-again/">Laptops have outsold desktops since 2003</a>, depending on whose data you believe. And today's laptops are definitely converging with desktops (and vice-versa, in terms of noise and size). Laptops involve far fewer compromises than in years past. But I still consider laptops a necessary evil when I'm travelling. All other things being equal, I'd rather be sitting in front of a less expensive and more flexible desktop machine.
</p>
<p>
So, in no particular order, some thoughts about the W3J.
</p>
<p>
</p>
<ul>
<li>
<b>I love the glossy LCD display.</b> I was a little apprehensive about glare, but after using a glossy LCD for a few days, I am a total believer. I wish all of my LCDs, including the ones I use on my desktops, were glossy. The increase in contrast and brightness is truly remarkable. Matte LCD screens? They're dead to me.
<p>
</p>
</li>
<li>
<b>The Radeon Mobility X1600 is a great video card.</b> After installing the latest ATI mobility drivers-- you can only do this if you <a href="http://www.ati.com/online/mobilecatalyst/">download the full package and skip the tedious validation executable</a>-- I get a 3dMark05 score of ~4200. That's in the same ballpark as a desktop GeForce 6800GT, which is mightily impressive for a laptop.
<p>
I was able to play <a href="http://www.ea.com/official/battlefield/battlefield2/us/home.jsp">Battlefield 2</a> on relatively high settings at 1280x768 (use the -szx, and -szy startup params to get widescreen resolutions) and my framerate never dipped below 40 frames per second through an entire botmatch. After that, Vista's hardware accelerated Aero Glass interface should be a walk in the park.
</p>
<p>
The usual ATI caveat applies, of course. Avoid installing the Catalyst Center software at all costs. It's <a href="http://www.codinghorror.com/blog/archives/000487.html">bloated and slow</a>. Stick with the core driver and use <a href="http://www.guru3d.com/article/atitraytools/189/">ATI Tray Tools</a> if you need to tweak advanced settings.
</p>
<p>
</p>
</li>
<li>
<b>The metal cover is a nice touch.</b> The rest of the laptop is plastic, of course, but I'm hoping the metal cover is more functional than cosmetic. Every laptop I've owned, the LCD screen eventually gets scratched by the keyboard. Maybe the stiffer metal cover will prevent this from happening with the W3J. Until I know for sure, I'm not taking any chances-- I'll be putting a <a href="http://www.radtech.us/Products/NotebookScreensavRz.aspx">small piece of fabric on the keyboard</a> before closing the laptop.
<p>
I also like the way there's <b>no latch on the screen</b>. Simply flip down to close; flip up to open. The hinge is a little overly resistant right now, so it takes a bit more force than I'd like, but I assume it will loosen up over time as it's used.
</p>
<p>
</p>
</li>
<li>
<b>Unfortunately, the touchpad has a dedicated vertical scroll area</b>. This is nearly a deal breaker for me. There's no tactile feedback of any kind when you move your finger from the normal touchpad area into the dedicated scroll area. I'm suffering through it for now, because it's the only substantive complaint I have about the W3J. But how I wish there was a way to turn off that damn dedicated vertical scrolling area. You can scroll just fine without a dedicated area; the driver detects when your finger is near the edge and it switches dynamically.
<p>
</p>
</li>
<li>
<b>It's very easy to upgrade</b>. There's a large panel on the bottom which, when removed, allows easy access to the hard drive, memory, CPU, and   (what I think is) the video card. The CPU appears to be socketed, so it's theoretically replaceable. The hard drive and memory are obvious and easy upgrade candidates. In fact, I have another 1 gigabyte SO-DIMM on the way.
<p>
</p>
</li>
<li>
<b>The two gigabyte laptop memory limit is alive and well.</b> Although you can get laptops that theoretically allow you to use 4 gigabytes of memory, I doubt any of them have more than two SO-DIMM slots. So that means 2x2gb-- but have you <i>priced</i> a 2 gigabyte SO-DIMM? Consider <a href="http://configure.us.dell.com/dellstore/config.aspx?c=us&amp;cs=19&amp;l=en&amp;oc=M1710B2&amp;s=dhs">Dell's XPS M1710</a>; the 4gb memory upgrade option is currently $1,800 for DDR-533. That's as much as I paid for the entire laptop! And it's a whopping $3,000 if you want DDR-667.
<p>
I can get a 1 gigabyte SO-DIMM for under $90. Given current (and forseeable future) prices, I'm more than OK with a 2 gigabyte memory limit on this laptop. 2 gigabytes of memory should be workable for the next 3 years. Or at least until 4 gigabytes of laptop memory costs less than an entire laptop.
</p>
<p>
</p>
</li>
<li>
<b>Without optical drive, the machine is right at 5 pounds.</b> After unpacking the laptop, I snapped the DVD-R drive out and snapped in the lightweight plastic "traveller's bay" to reduce the overall weight. It's a bit back-heavy due to the weight of the battery, and it's no match for the flyweight three pound Dell 300M I used to cary, but it's quite portable considering the massive, uncompromising leap in performance.
<p>
I use a <a href="http://www.timbuk2.com/tb2/retail/catalog.htm?sizeId=2&amp;skusetId=85&amp;categoryId=6">small Timbuk2 messenger bag</a> to carry my laptop and other stuff. It's a little tight, but I'd rather pack light when possible. Unfortunately, it doesn't have a dedicated laptop compartment, so I use a <a href="http://www.sfbags.com/products/sleevecases/sleevecases.htm">waterfield SleeveCase</a> to cushion the laptop before storing it in the bag. If you're into laptop sleeves, I can recommend the SleeveCase highly. It comes in sizes to fit any laptop perfectly (the W3J uses a 26-19), and they're made in nearby San Francisco.
</p>
<p>
</p>
</li>
<li>
<b>The integrated intel "HD" audio is impressive</b>. I may not think integrated video makes sense, but I definitely think integrated audio does. Intel's <a href="http://www.digit-life.com/articles2/intel-hdaudio/intel-hdaudio.html">improved "HD" audio standard</a> is a welcome improvement to the creaky, ancient AC97 audio standard. It's a standard feature on the W3J's <a href="http://www.intel.com/products/chipsets/945pm/index.htm">Intel 945PM chipset</a>. When I slapped my headphones on and plugged them into the W3J, I was pleasantly surprised how much crisper this sounded than the generic AC97 in my old Dell 300m. It far exceeded my modest expectations for integrated audio.
</li>
</ul>
<p>
One other minor niggle with the W3J is the extremely bright blue LEDs on the bottom left. I don't mind a blue LED on the power switch, since it's on the right side of the hinge, and not directly in my line of sight. But we really need to disabuse manufacturers of the idea that consumers want <a href="http://www.codinghorror.com/blog/archives/000337.html">super-bright blue LEDs directly in our faces</a>.
</p>
<p>
But aside from the minor touchpad and LED issues, the W3J is a fine machine, and very enjoyable to use.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/asus-w3j-laptop-review/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Good an Estimator Are You? ]]></title>
<link>https://blog.codinghorror.com/how-good-an-estimator-are-you/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Chapter 2 of <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art</a> opens with a quiz designed to test your estimation abilities. It's an interesting exercise, so I thought everyone might like to give it a shot.</p>
<ul>
<li>For each question, <strong>fill in the upper and lower bounds so that you have a 90 percent chance of including the correct value.</strong> </li>
<li>Don't make your ranges too narrow or too wide, but be sure they're wide enough to give you a 90 percent chance of hitting the correct value. </li>
<li>Don't research the answers on the internet. </li>
<li>You must provide an estimate range for each question. </li>
<li>Spend no more than 10 minutes on this quiz. </li>
</ul>
<p>So, how good an estimator are you?</p>
<table width="700">
<tbody>
<tr>
<td><strong>Question</strong></td>
<td><strong>Low Estimate</strong></td>
<td><strong>High Estimate</strong></td>
</tr>
<tr>
<td>Surface temperature of the sun</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Latitude of Shanghai</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Area of the Asian continent</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>The year of Alexander the Great's birth</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Total value of U.S. currency in circulation in 2004</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Total volume of the Great Lakes</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Worldwide box office receipts for the movie <em>Titanic</em>
</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Total length of the coastline of the Pacific Ocean</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Number of book titles published in the U.S. since 1776</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
<tr>
<td>Heaviest blue whale ever recorded</td>
<td style="border:1px solid silver"></td>
<td style="border:1px solid silver"></td>
</tr>
</tbody>
</table>
<p>Remember, the purpose of the quiz isn't to determine whether or not you're the next <a href="http://www.ken-jennings.com/blog/">Ken Jennings</a>. It's about estimation, not trivia.</p>
<p>Tomorrow, I'll print <a href="http://blog.codinghorror.com/how-good-an-estimator-are-you-part-ii/">the answers along with a deeper explanation of this exercise</a>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-06-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-good-an-estimator-are-you/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Good an Estimator Are You? Part II ]]></title>
<link>https://blog.codinghorror.com/how-good-an-estimator-are-you-part-ii/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Here are the answers to the quiz presented in <a href="http://blog.codinghorror.com/how-good-an-estimator-are-you/">How Good an Estimator Are You?</a></p>
<p>If you're concerned that a quiz like this has nothing to do with software development, consider:</p>
<blockquote>In software, you aren't often asked to estimate the volume of the Great Lakes or the surface temperature of the sun. Is it reasonable to expect you to be able to estimate the amount of U.S. currency in circulation or the number of books published in the U.S., especially if you're not in the U.S.?
<p>Software developers are often asked to estimate projects in unfamiliar business areas, projects that will be implemented in new technologies, the impacts of new programming tools on productivity, the productivity of unidentified personnel, and so on. Estimating in the face of uncertainty is business as usual for software estimators. The rest of [the book <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art</a>] explains how to succeed in such circumstances.</p>
</blockquote>
<p>If you haven't read the entry with the quiz questions, please <a href="http://blog.codinghorror.com/how-good-an-estimator-are-you/">read it now</a> before reading any further, so you'll have an opportunity to try it before seeing the answers.</p>
<table width="700">
<tbody>
<tr>
<td><strong>Question</strong></td>
<td><strong>Answer</strong></td>
</tr>
<tr>
<td>Surface temperature of the sun</td>
<td style="border:1px solid silver">10,000F / 6,000C</td>
</tr>
<tr>
<td>Latitude of Shanghai</td>
<td style="border:1px solid silver">31 degrees North</td>
</tr>
<tr>
<td valign="top">Area of the Asian continent</td>
<td style="border:1px solid silver">17,139,000 square miles<br>44,390,000 square kilometers</td>
</tr>
<tr>
<td>The year of Alexander the Great's birth</td>
<td style="border:1px solid silver">356 BC</td>
</tr>
<tr>
<td>Total value of U.S. currency in circulation in 2004</td>
<td style="border:1px solid silver">$719.9 billion</td>
</tr>
<tr>
<td valign="top">Total volume of the Great Lakes</td>
<td style="border:1px solid silver">5,500 cubic miles<br>23,000 cubic kilometers<br>2.4 x 10^22 cubic feet<br>6.8 x 10^20 cubic meters<br>1.8 x 10^23 U.S. gallons<br>6.8 x 10^23 liters</td>
</tr>
<tr>
<td>Worldwide box office receipts for the movie <em>Titanic</em>
</td>
<td style="border:1px solid silver">$1.835 billion</td>
</tr>
<tr>
<td>Total length of the coastline of the Pacific Ocean</td>
<td style="border:1px solid silver">84,300 miles<br>135,663 kilometers</td>
</tr>
<tr>
<td>Number of book titles published in the U.S. since 1776</td>
<td style="border:1px solid silver">22 million</td>
</tr>
<tr>
<td valign="top">Heaviest blue whale ever recorded</td>
<td style="border:1px solid silver">380,000 pounds<br>190 English tons<br>170,000 kilograms<br>170 metric tons</td>
</tr>
</tbody>
</table>
<p>The specific goal of the exercise was to <strong>estimate at the 90 percent confidence level</strong>. There are 10 questions in the quiz, so if you were truly estimating at a 90 percent confidence level, you would have gotten about 9 answers correct.</p>
<p>McConnell gives this quiz to every participant in his estimation course. The results are pictured in the chart below.</p>
<p><img alt="image placeholder" >
<p>He offers this analysis of the data:</p>
<blockquote>For the test takers whose results are shown in the figure, the average number of correct answers is 2.8. Only 2 percent of quiz takers score 8 or more correct answers. No one has ever gotten 10 correct. <strong>I've concluded that most people's intuitive sense of "90% confident" is really comparable to something closer to "30% confident."</strong> Other studies have confirmed this basic finding (Zultner 1999, Jrgensen 2002).</blockquote>
<p>Additionally, the few people who manage to get close to the goal of ~9 correct answers typically feel they did something wrong:</p>
<blockquote>When I find the rare person who gets 7 or 8 answers correct, I ask "How did you get that many correct?" The typical response? "I made my ranges too wide."
<p>My response is, "No, you didn't! You didn't make your ranges wide enough!" If you get only 7 or 8 correct, your ranges were still too narrow to include the correct answer as often as you should have.</p>
<p><strong>We are conditioned to believe that estimates expressed as narrow ranges are more accurate than estimates expressed as wider ranges. We believe that wide ranges make us appear ignorant or incompetent.</strong> The opposite is usually the case.</p>
</blockquote>
<p>So, what have we learned from this exercise?</p>
<ul>
<li>When you ask someone for a range that provides 90% confidence, expect 30% confidence on average. </li>
<li>People are naturally hesitant to provide wide ranges  even when the confidence level requires a wide range to be accurate  because they feel that narrow estimates are a sign of a better estimate. </li>
</ul>
<p>Narrow estimates are self-defeating, but unfortunately they are human nature. Unless you have specific data that supports your narrow estimate, your estimate probably should be wider than you made it.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-good-an-estimator-are-you-part-ii/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Monopoly Interview ]]></title>
<link>https://blog.codinghorror.com/the-monopoly-interview/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Reginald Braithwaite's <a href="http://weblog.raganwald.com/2006/06/my-favourite-interview-question.html">favorite interview question</a> is an offbeat one: <b>sketch out a software design to referee the game Monopoly</b>.*
</p>
<p>
I think it's a valid design exercise which neatly skirts the <a href="http://www.techinterview.org/">puzzle question trap</a>. But more importantly, <b>it's fun</b>.
</p>
<p>
Interviews are a terror for the interviewee. And they're stressful for the interviewer, too. A design excercise centered around a salt-of-the-earth game like Monopoly is a great way to put both parties at ease. Lots of people have played Monopoly at some point, so you have a nice, common base of familiarity to work with.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Anything is better than the <a href="http://www.codinghorror.com/blog/archives/000592.html">"how would you write a routine to copy a file" interview question</a>, but any company that asks an entertaining and useful interview question like this is already a winner in my book.
</p>
<p>
But what I love most about the Monopoly question is how it sucks me in. Maybe it's because I'm a gamer at heart, but my mind immediately starts racing through all the different possibilities. It's a little embarrassing to admit, but I'd love nothing more than to sit in a room with another programmer and hash this problem out.
</p>
<p>
Because it's <i>fun</i>.
</p>
<p>
And isn't programming <a href="http://www.codinghorror.com/blog/archives/000030.html">supposed to be fun?</a>
</p>
<p>
* Monopoly is in the process of <a href="http://money.cnn.com/2006/04/24/news/funny/monopoly/index.htm">permanently updating their game board</a>. Was anyone <i>really</i> complaining that Monopoly wasn't grounded in modern locations and current property valuations? I hope this doesn't devolve into another <a href="http://en.wikipedia.org/wiki/New_Coke">"New Coke" fiasco</a>. At least the classic edition of the game will still be available.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-monopoly-interview/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How Good an Estimator are You? Part III ]]></title>
<link>https://blog.codinghorror.com/how-good-an-estimator-are-you-part-iii/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
For the final installment in the <a href="http://www.codinghorror.com/blog/archives/000625.html">How Good an Estimator Are You</a> series, I'd like to start with an anecdote from chapter 7 of <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art </a>:
</p>
<p>
</p>
<blockquote>
Suppose you're at a reception for the world's best software estimators. The room is packed, and you're seated in the middle of the room at a table with three other estimators. All you can see as you scan the room are wall-to-wall estimators. Suddenly, the emcee steps up to the microphone and say "We need to know exactly how many people are in the room so we can order dessert. Who can give the most accurate estimate for the number of people in the room?"
<p>
Bill, the estimator to your right, says "I make a hobby of estimating crowds. Based on my experience, it looks to me like we've got about 335 people in the room."
</p>
<p>
The estimator sitting across the table from you, Karl, says, "This room has 11 tables across and 7 tables deep. One of my friends is a banquet planner, and she told me that they plan for 5 people per table. It looks to me like most of the tables do actually have about 5 people at them. If we multiply 11 times 7 times 5, we get 385 people. I think we should use that as our estimate."
</p>
<p>
The estimator on your left, Lucy, says, "I noticed on the way into the room that there was an occupancy limit sign that says this room can hold 485 people. This room is pretty full. I'd say 70 to 80 percent full. If we multiply those percentages by the room limit, we get 340 to 388 people. How about if we use the average of 364 people, or maybe just simplify it to 365?"
</p>
<p>
Bill says, "We have estimates of 335, 365, and 385. It seems like the right answer must be in there somewhere. I'm comfortable with 365."
</p>
<p>
Everyone looks at you. You say, "I need to check something. Would you excuse me for a minute?"
</p>
<p>
You return a few minutes later. "Remember how we had to have our tickets scanned before we entered the room? I noticed on my way into the room that the handheld ticket scanner had a counter. So I went back and talked to the ticket taker at the front door. She said that, according to her scanner, she has scanned 407 tickets. She also said no one has left the room so far. I think we should use 407 as our estimate. What do you say?"
</p>
</blockquote>
<p>
The moral of this story, of course, is that <b>you should avoid estimating what you can count.</b> And if you can't get a count, you should at least try to <b>compute the estimate from a related count</b>, like Karl did in the anecdote above. The absolute worst estimates you can produce are judgmental-- estimates that are not derived from an actual count of any kind.
</p>
<p>
The real art of software estimation, then, is the frantic search for data points to hang your estimates on. Hopefully you're fortunate enough to work for an organization that captures historical data for your projects.
</p>
<p>
What kind of stuff can you count on a software project? Lots of stuff, actually:
</p>
<p>
</p>
<ul>
<li>Marketing requirements
</li>
<li>Features
</li>
<li>Use cases
</li>
<li>Stories
</li>
<li>Engineering requirements
</li>
<li>Function points
</li>
<li>Change requests
</li>
<li>Web pages
</li>
<li>Reports
</li>
<li>Dialog boxes
</li>
<li>Database tables (or procs, views, etc)
</li>
<li>Classes
</li>
<li>Defects found
</li>
<li>Configuration settings
</li>
<li>Lines of code
</li>
<li>Test cases
</li>
<li>Code churn
</li>
</ul>
<p>
One reason I'm working so closesly with <a href="http://msdn.microsoft.com/vstudio/teamsystem/">Team System</a> these days is that it makes capturing some of these metrics (almost) effortless.
</p>
<p>
The art of building an estimate from known reference points isn't a new topic in computer science. One of my favorite chapters in <a href="http://www.amazon.com/exec/obidos/ASIN/0201657880/codihorr-20">Programming Pearls</a> is about how essential <a href="http://www.cs.bell-labs.com/cm/cs/pearls/bote.html">back of the envelope calculations</a> are to software development:
</p>
<p>
</p>
<blockquote>
It was in the middle of a fascinating conversation on software engineering that Bob Martin asked me, "How much water flows out of the Mississippi River in a day?" Because I had found his comments up to that point deeply insightful, I politely stifled my true response and said, "Pardon me?" When he asked again I realized that I had no choice but to humor the poor fellow, who had obviously cracked under the pressures of running a large software shop.
<p>
My response went something like this. I figured that near its mouth the river was about a mile wide and maybe twenty feet deep (or about one two-hundred-and-fiftieth of a mile). I guessed that the rate of flow was five miles an hour, or a hundred and twenty miles per day. Multiplying
</p>
<p>
1 mile x 1/250 mile x 120 miles/day ~ 1/2 mile3/day
</p>
<p>
showed that the river discharged about half a cubic mile of water per day, to within an order of magnitude. But so what?
</p>
<p>
At that point Martin picked up from his desk a proposal for the communication system that his organization was building for the Summer Olympic games, and went through a similar sequence of calculations. He estimated one key parameter as we spoke by measuring the time required to send himself a one-character piece of mail. The rest of his numbers were straight from the proposal and therefore quite precise. His calculations were just as simple as those about the Mississippi River and much more revealing. They showed that, under generous assumptions, the proposed system could work only if there were at least a hundred and twenty seconds in each minute. He had sent the design back to the drawing board the previous day. (The conversation took place about a year before the event, and the final system was used during the Olympics without a hitch.)
</p>
<p>
That was Bob Martin's wonderful (if eccentric) way of introducing the engineering technique of "back-of-the-envelope" calculations. The idea is standard fare in engineering schools and is bread and butter for most practicing engineers. Unfortunately, it is too often neglected in computing.
</p>
</blockquote>
<p>
Steve Bush, in a recent comment, pointed out that physicist <a href="http://en.wikipedia.org/wiki/Enrico_Fermi">Enrico Fermi</a> was famed for these kinds of calculations, and apparently Fermi coined <a href="http://en.wikipedia.org/wiki/Back-of-the-envelope_calculation">the phrase "back-of-the-envelope calculation"</a>.
</p>
<p>
These calculations are typically represented in the form of <a href="http://mathforum.org/workshops/sum96/interdisc/sheila1.html">Fermi Questions</a>; the canonical Fermi Question is <a href="http://www.grc.nasa.gov/WWW/K-12/Numbers/Math/Mathematical_Thinking/fermis_piano_tuner.htm">How many piano tuners are there in Chicago?</a>
</p>
<p>
</p>
<ul>
<li>From the almanac, we know that Chicago has a population of about 3 million people.
</li>
<li>Assume that an average family contains four members. The number of families in Chicago is about 750,000.
</li>
<li>If one in five families owns a piano, there will be 150,000 pianos in Chicago.
</li>
<li>If the average piano tuner serviced four pianos every day of the week for five days, rested on weekends, and had a two week vacation during the summer,  then in one year (52 weeks) he would service 1,000 pianos.
</li>
<li>150,000 / (4 x 5 x 50) = 150
</li>
<li>there are ~150 piano tuners in Chicago
</li>
</ul>
<p>
Fermi questions are interesting, because the actual answer to the question is secondary to the process of how you arrived at the answer. <b>Did you guess? Or did you <i>estimate?</i></b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-good-an-estimator-are-you-part-iii/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Comparison of JPEG Compression Levels and Recompression ]]></title>
<link>https://blog.codinghorror.com/a-comparison-of-jpeg-compression-levels-and-recompression/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Over the years, I've standardized on a <b>JPEG compression factor of 15</b>; I find that generally provides the best compromise between image quality and file size for most photographic images.
</p>
<p>
Although I've done some ad-hoc testing that pointed to compression factor 15 as the sweet spot before, I've never done a formal test. So I performed a JPEG compression series using the <a href="http://www-ece.rice.edu/~wakin/images/">Lena reference image</a>*. Note that I resized the image slightly (from 512x512 to 384x384) to keep the file sizes relatively small. The original, uncompressed image size is <font color="red">433 kilobytes</font>.
</p>
<p>
</p>
<table>
<tr>
<td>
<b>compression factor 10</b> (39 kb)
</td>
<td>
<b>compression factor 15</b> (30 kb)
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td>
<b>compression factor 20</b> (26 KB)
</td>
<td>
<b>compression factor 30</b> (16 KB)
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td>
<b>compression factor 40</b> (11 KB)
</td>
<td>
<b>compression factor 50</b> (9 KB)
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
Beyond 50 percent compression factor, quality falls off a cliff, so I won't bother displaying anything higher. Here's a more complete breakdown of JPEG compression factor and file size for the 384x384 Lena image:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I was also curious what the image quality and file size penalty was for <b>recompressing a JPEG image</b>. That is, opening a JPEG and re-saving it as a JPEG, including all the artifacts from the original compressed image in the recompression. I've been forced to do this when I couldn't find an uncompressed or high quality version of the image I needed, and I always wondered how much worse it made the image when I recompressed it.
</p>
<p>
For the recompression test, I started with the uncompressed, resized 384x384 Lena reference image. For each new generation, I opened and saved the previous generation with my standard JPEG compression factor of 15.
</p>
<p>
</p>
<table>
<tr>
<td>Generation 1 (30kb)
</td>
<td>Generation 2 (30kb)
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td>Generation 3 (30kb)
</td>
<td>Generation 4 (30kb)
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td>Generation 5 (30kb)
</td>
<td>Generation 10 (30kb)
</td>
</tr>
<tr>
<td>
<img alt="image placeholder" >
</td>
<td>
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
I was quite surprised to find that there's <b>very little visual penalty for recompressing a JPEG once, twice, or even three times.</b> By generation five, you can see a few artifacts emerge in the image, and by generation ten, you're definitely in trouble. There's virtually no effect at all on file size, which stays constant at 30-31 kilobytes even through generation 15.
</p>
<p>
* An entire set of classic reference images is available from the <a href="http://sipi.usc.edu/database/database.cgi?volume=misc">USC-SIPI image database</a>. I distinctly remember that <a href="http://sipi.usc.edu/database/database.cgi?volume=misc&amp;image=11#top">Mandrill image</a> from my Amiga days.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-comparison-of-jpeg-compression-levels-and-recompression/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ In Defense of the "Smackdown" Learning Model ]]></title>
<link>https://blog.codinghorror.com/in-defense-of-the-smackdown-learning-model/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I've occasionally been told that I have a <strong>confrontational style of communication</strong>. But that's not necessarily a bad thing   as Kathy Sierra points out, <a href="http://headrush.typepad.com/creating_passionate_users/2005/08/the_smackdown_l.html">the smackdown learning model</a> can be surprisingly effective:</p>
<blockquote>
<p>What happens to your brain when you're forced to choose between two different  and potentially conficting  points of view? Learning. That's what makes the <a href="http://www.wwe.com/shows/smackdown/">smackdown model</a> such an effective approach to teaching, training, and most other forms of communication.</p>
<img alt="image placeholder" >
<p>Whether you're writing user instructions, teaching a class, writing a non-fiction book, or giving a conference presentation, consider including at least some aspect of the smackdown model. It's one of the most engaging ways to cause people's brains to both feel and think    the two elements you need for attention, understanding, retention, and recall.</p>
<p>By presenting different perspectives or views of the topic, the learner's brain is forced into making a decision about which one they most agree with. And as long as the learner is paying attention, you won't even have to ask. In other words, it doesn't have to be a formal exercise where the learner must physically make a choice between multiple things; simply by giving their brain the conflicting message, their brain has no choice. Brains cannot simply leave the conflicts out there without at least trying to make an evaluation.</p>
</blockquote>
<p>I think this is also why presentations with <i>two</i> presenters are unusually effective. They're more engaging because you get two viewpoints. There's more back and forth; not one person droning on, but a sort of conversation on the stage.</p>
<p>Although I can recommend the smackdown communication style, it's extremely important that everyone retain their sense of humor. Like "real" wrestling, always remember that <strong>you're only fighting for the entertainment value.</strong></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/in-defense-of-the-smackdown-learning-model/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Brute Force Key Attacks Are for Dummies ]]></title>
<link>https://blog.codinghorror.com/brute-force-key-attacks-are-for-dummies/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Cory Doctorow recently <a href="http://www.boingboing.net/2006/07/10/analogy_explains_str.html">linked</a> to this <a href="http://www.interesting-people.org/archives/interesting-people/200607/msg00058.html">fascinating email</a> from <a href="http://www.merrymeet.com/jon/">Jon Callas</a>, the <a href="http://www.pgp.com/library/ctocorner/index.html">CTO of PGP corporation</a>. In it, Jon describes <b>the impossibility of brute force attacks on modern cryptography</b>:
</p>
<p>
</p>
<blockquote>
Modern cryptographic systems are essentially unbreakable, particularly if an adversary is restricted to intercepts. We have argued for, designed, and built systems with 128 bits of security precisely because they are essentially unbreakable. It is very easy to underestimate the power of exponentials. 2^128 is a very big number. Burt Kaliski first came up with this characterization, and if he had a nickel for every time I tell it, he could buy a latte or three.
<p>
Imagine a computer that is the size of a grain of sand that can test keys against some encrypted data. Also imagine that it can test a key in the amount of time it takes light to cross it. <b>Then consider a cluster of these computers, so many that if you covered the earth with them, they would cover the whole planet to the height of 1 meter. The cluster of computers would crack a 128-bit key on average in 1,000 years.</b>
</p>
<p>
If you want to brute-force a key, it literally takes a planet-ful of computers. And of course, there are always 256-bit keys, if you worry about the possibility that government has a spare planet that they want to devote to key-cracking.
</p>
</blockquote>
<p>
Each additonal bit doubles the number of keys you have to test in a brute force attack, so by the time you get to 128 or 256 bits, you have a staggeringly large number of potential keys to test. The classic illustration of this <a href="http://en.wikipedia.org/wiki/Exponential_growth#Rice_on_a_chessboard">exponential growth</a> is the fable of the mathematician, the king, and the chess board:
</p>
<p>
</p>
<blockquote>
There is an old Persian legend about a clever courtier who presented a beautiful
chessboard to his king and requested that the king give him in return 1 grain of rice for the first square on the board, 2 grains of rice for the second square, 4 grains for the third, and so forth. The king readily agreed and ordered rice to be brought from his stores. By the fortieth square a million million rice grains had to be brought from the storerooms. The king's entire rice supply was exhausted long before he reached the sixty-fourth square. Exponential increase is deceptive because it generates immense numbers very quickly.
</blockquote>
<p>
By the time you get to that 32nd chessboard square, you're facing a very large number indeed.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
However, 2^32 isn't necessarily a very large set of keys when you're performing a brute force attack with a <b>worldwide distributed network of computers</b>. Such as the <a href="http://www.distributed.net/rc5/">RC5 distributed computing project</a>. Here's what they've done so far:
</p>
<ul>
<li>a <b>56-bit</b> key was <a href="http://stats.distributed.net/projects.php?project_id=3">cracked in 250 days</a>.
</li>
<li>a <b>64-bit</b> key was <a href="http://stats.distributed.net/projects.php?project_id=5">cracked in 1,757 days</a>.
</li>
<li>a <b>72-bit</b> key is still being cracked; 1,316 days so far with 379,906 days remaining.
</li>
</ul>
<p>
The earliest 56-bit challenge, which ended in 1997, tested keys at a rate of 1.6 million per second. The ongoing 72-bit challenge is currently testing keys at the rate of 139.2 million per second. We're testing keys 88 times faster than we were 10 years ago, through natural increases in computing power and additional computers added to the distributed computing network.
</p>
<p>
And yet the RC5-72 project <b>still has 1,040 years to go before they test the entire keyspace</b>. Remember, that's for a lousy 72-bit key! If we want to double the amount of time the brute force attack will take, all we need to do is tack on one teeny, tiny little bit to our key. 73-bit key? 2,080 years. 74-bit key? 4,160 years.
</p>
<p>
It's painfully clear that a brute force attack on even a 128 bit key is a fool's errand. Even if you're using a planet covered with computers that crack keys at the speed of light.
</p>
<p>
If you're a smart attacker, <b>you already know that brute force key attacks are strictly for dummies</b> with no grasp of math or time. There are so many other vulnerabilities that are much, much easier to attack:
</p>
<p>
</p>
<ul>
<li>Rootkits
</li>
<li>Social engineering
</li>
<li>Keyloggers
</li>
<li>Obtain the private key file and attack the password on it
</li>
</ul>
<p>
Of course, beyond ruling out brute force attacks, I'm barely scratching the surface here. Jon Callas' Black Hat conference presentation <a href="http://www.blackhat.com/presentations/bh-europe-05/bh-eu-05-callas-up.pdf">Hacking PGP</a> (pdf) goes into much more detail, if you're interested.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/brute-force-key-attacks-are-for-dummies/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Power, Surge Protection, PCs, and You ]]></title>
<link>https://blog.codinghorror.com/power-surge-protection-pcs-and-you/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>A question recently came up on the internal Vertigo mailing list about <strong>surge protection for home equipment and computers</strong>:</p>
<ul>
<li>Do you know if the cheap outlet strips work? I'm not sure if they are a good deal (work as good as more expensive strips) or a waste of money. </li>
<li>Do UPS provide better surge protection, or are you just paying more for the battery backup? </li>
<li>Do you know of any studies that show how well different devices work? </li>
</ul>
<p>The best source of information on this is Dan of the eponymously named <a href="http://www.dansdata.com">Dan's Data</a>. Let's start with his essential article on <a href="http://www.dansdata.com/sbs9.htm">power conditioning</a>:</p>
<blockquote>Mains irregularities come in four flavours - surges, sags, spikes and outages.
<p>A <strong>surge</strong> is a lengthy (2.5 second or longer) increase in the supply voltage. A <strong>sag</strong> is a similarly lengthy decrease. By and large, computer power supplies deal with both of these quite well, though it of course depends on the severity of the irregularity, not to mention the quality of the power supply, and how much of its capacity is being used by the computer. The closer to maximum capacity a power supply is, the less likely it is to handle a given surge or sag. For this reason, a computer with a 300 watt (W) Power Supply Unit (PSU) is likely to deal better with line irregularities than one with a 235W PSU, although it may not ever need more than 200W of the PSU's possible output.</p>
<p><strong>Outages</strong> are plain old blackouts, which are the Russian roulette of computing - you'll probably get away with no damage or only minor system corruption if the power drops out, but if you're writing to the only copy of an important file at the magic moment, you can kiss it goodbye.</p>
<p><strong>Spikes</strong> are the real nasties. A spike is a brief increase in the supply voltage - less than 2.5 seconds, often a lot less. For a fraction of a second, a spike can easily subject your equipment to several hundred volts. If this doesn't blow something up outright, it can progressively damage power supply and other components. So, after a few (or a few hundred) more spikes and surges, your PC dies, for no obvious reason. You may lose a power supply or modem; you may lose your motherboard; you may even lose your hard drive and everything on it.</p>
<p>If lightning directly strikes the power lines near your house, you will have a very exciting time and probably lose some gear, unless everything is unplugged. Fortunately, direct strikes to power lines are rare, because, by definition, a power line is well isolated from earth, and the lightning is looking for an earth. Buried power and telephone lines are a different story, though; lightning strikes a long way away can result in large induced spikes on these sorts of cables.</p>
</blockquote>
<p>Dan goes on to describe the risks of garden variety cheap, generic surge protectors:</p>
<blockquote>The plain surge/spike filter powerboards you can buy at various electronics, electrical and hardware stores are, arguably, worse than nothing. This is because they give you the impression you're protected, when you probably aren't - well, not for long, anyway.
<p>The chief surge-clamping component in a basic filter-board is a <strong>Metal-Oxide Varistor (MOV)</strong>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
MOVs pass current only when the voltage across them is above a set value, and they react very quickly (in a matter of microseconds, against the tens of milliseconds a circuit breaker takes). That's the good news. The bad news is that MOVs wear out - they're only good for a few uses, and the bigger the spike, the more damage is done.</p>
<p>Cheap power filters seldom give you any indication whether your MOV is alive or not. If the powerboard has an illuminated power switch, the switch light often goes off when the MOV has died. The switch lights generally last for decades, so no light almost definitely means no MOV - but since the light only shows the status of a fuse, and the fuse won't blow if the MOV has been killed by lots of smaller surges, the light can keep glowing merrily when the MOV has long since kicked the bucket.</p>
</blockquote>
<p>The key thing to take away from this article is that <strong>surge protectors wear out</strong>. They aren't good forever.</p>
<p>Personally, I recommend the <a href="http://www.amazon.com/dp/B0000513US/?tag=codihorr-20">Tripp Lite ISOBAR Ultra</a> series of surge protectors. And yes, it has to be the Ultra, because of the little green <strong>"protection present" LED</strong> the Ultra adds. It lets you know that the MOV inside your power strip is still functioning.</p>
<p>
<a href="http://www.amazon.com/dp/B0000513US/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>The 6-outlet ISOBAR ultra is <a href="http://www.amazon.com/dp/B0000513US/?tag=codihorr-20">about $50 online</a>, so they skew to the expensive side of the surge protection spectrum. But at least you won't get a false sense of security from a cheap power strip with a MOV that blew out three years ago. The <a href="http://computer.howstuffworks.com/surge-protector7.htm">howstuffworks article on surge protectors</a> mentions that you should look for power strips with a <strong>UL 1449 certification</strong>, but I think it's more important to look for one with that "protection present" LED.</p>
<p>If you're really serious about protecting that bit of equipment, you won't bother with a surge protector. A surge protector can only protect you from spikes and surges, after all. What about sags and outages? <strong>To get full protection from the entire gamut of power problems, you need an Uninterruptible Power Supply.</strong></p>
<p>And that's why, although I own and use many Tripp Lite Ultra power strips, <strong>all my home PCs are plugged into UPSes</strong>.
</p>
<p>
<a href="http://www.amazon.com/dp/B000FN8G0S/?tag=codihorr-20"><img alt="image placeholder" >
</p>
<p>I don't have enough experience to recommend a specific <em>brand</em> of UPS, other than a <a href="http://www.amazon.com/gp/search?ie=UTF8&amp;keywords=tripp%20lite%20ups&amp;tag=codihorr-20">general trust of Tripp Lite</a>, but this excellent <a href="http://www.computerpoweruser.com/editorial/article.asp?article=articles/archive/c0305/07c05/07c05.asp">Computer Power User article</a> (may be behind paywall after first visit) has a few general recommendations for us:
</p>
<ul>
<li>
<strong>Pick a UPS with USB support.</strong> Once the UPS is plugged into your PC's USB port, it'll enable those built-in Windows OS power functions you usually see on laptop computers, related to batteries and battery life. It also enables your computer to do a controlled shutdown when power runs out, exactly like a laptop. Note that you do <em>not</em> need to install the software that comes with the device to achieve this basic level of functionality!<br><br>
</li>
<li>
<strong>Think about battery runtime.</strong> You'll want to scale the size of the battery to how much runtime you need, and the power draw of what you're plugging into it. For a typical 2003 vintage desktop PC, ~800VA watts provided at least 10 minutes of runtime under fully-loaded conditions. That should be more than enough for a brief power outage.<br><br>
</li>
<li>
<strong>Is it a UPS or a SPS?</strong> If the device is a true UPS, the inverter is running all the time, translating the wall power into clean output. If it's a SPS (standby power supply), the inverter only kicks in when the power is actually out or unstable; at all other times, it's passing the "OK" power signal directly through, as-is. If you get a true UPS, look for "sine wave output". This is the ideal, pure form of power; cheaper devices use "square wave" or "modified square wave" which are harsher on sensitive equipment over time. On a SPS, it doesn't matter so much since the inverter will only be running when the power is actually out.<br><br>
</li>
<li>
<strong>Consider form factor and weight.</strong> The more battery power you have, the larger and heavier the unit will be. I have a 1200VA unit at home I inherited through a garage sale, and I can barely lift the thing. Given the choice, I'd opt for something with less power/runtime that is easier to move and less bulky. My home theater PC, for example, is on a modest UPS that's <a href="http://www.amazon.com/dp/B000B8MFI6/?tag=codihorr-20">more analogous to a giant power strip</a>. </li>
</ul>
<p>
Once you hook your device up to a true UPS, you've basically removed it from the power grid and hooked it into a custom electricity provider. The only use the UPS has for wall power is to charge its batteries. And be sure <i>not</i> to plug your UPS into any surge protection strip! Plug it directly into the wall. I've seen some truly bizarre PC behavior resulting from daisy-chaining UPSes or surge protection strips.
</p>
<p>So, in summary: <strong>if it's something you <em>really</em> care about, put it on a decent UPS. If it's something you want to protect, put it behind a decent surge protector with a "protection OK" indicator</strong>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/power-surge-protection-pcs-and-you/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Visual Studio IDE and Regular Expressions ]]></title>
<link>https://blog.codinghorror.com/the-visual-studio-ide-and-regular-expressions/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The Visual Studio IDE supports <b>searching and replacing with regular expressions</b>, right? Sure it does. It's right there in grey and black in the find and replace dialog. Just tick the "use Regular expressions" checkbox and we're off to the races.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
However, you're in for an unpleasant surprise when you attempt to actually <i>use</i> regular expressions to find anything in Visual Studio. Apparently <a href="http://msdn2.microsoft.com/en-us/library/2k3te2cs(d=ide).aspx">the Visual Studio IDE has its own bastardized regular expression syntax.</a> Why? Who knows. Probably for arcane backwards compatibility reasons, although I have no idea why you'd want to perpetually carry forward insanity. Evidently it <a href="http://www.codinghorror.com/blog/archives/000363.html">makes people billionaires</a>, so who am I to judge.
</p>
<p>
God forbid we all learn one standard* regular expression dialect.
</p>
<p>
At any rate, some of the Visual Studio IDE regular expressions look awfully similar to standard regex:
</p>
<p>
</p>
<table width="600">
<tr>
<td></td>
<td align="center">
<strong>
Visual Studio IDE</strong>
</td>
<td align="center">
<strong>Standard</strong>
</td>
</tr>
<tr>
<td align="right">
Any single character</td>
<td align="center">
.</td>
<td align="center">
.</td>
</tr>
<tr>
<td align="right">
Zero or more</td>
<td align="center">
*</td>
<td align="center">
*</td>
</tr>
<tr>
<td align="right">
One or more</td>
<td align="center">
+</td>
<td align="center">
+</td>
</tr>
<tr>
<td align="right">
Beginning of line</td>
<td align="center">
^</td>
<td align="center">
^</td>
</tr>
<tr>
<td align="right">
End of line</td>
<td align="center">
$</td>
<td align="center">
$</td>
</tr>
<tr>
<td align="right">
Beginning of word</td>
<td align="center">
&lt;</td>
<td align="center">
(no equivalent)</td>
</tr>
<tr>
<td align="right">
End of word</td>
<td align="center">
&gt;</td>
<td align="center">
(no equivalent)</td>
</tr>
<tr>
<td align="right">
Line break</td>
<td align="center">
n</td>
<td align="center">
n</td>
</tr>
<tr>
<td align="right">
Any character in set</td>
<td align="center">
[ ]</td>
<td align="center">
[ ]</td>
</tr>
<tr>
<td align="right">
Any character not in set</td>
<td align="center">
[^ ]</td>
<td align="center">
[^ ]</td>
</tr>
<tr>
<td align="right">
Or</td>
<td align="center">
|</td>
<td align="center">
|</td>
</tr>
<tr>
<td align="right">
Escape special char</td>
<td align="center">
</td>
<td align="center">
</td>
</tr>
<tr>
<td align="right">
Tag expression</td>
<td align="center">
{ }</td>
<td align="center">
( )</td>
</tr>
<tr>
<td align="right">
C/C++ identifier</td>
<td align="center">
:i</td>
<td align="center">
([a-zA-Z_$][a-zA-Z0-9_$]*)</td>
</tr>
<tr>
<td align="right">
Quoted string</td>
<td align="center">
:q</td>
<td align="center">
(("[^"]*")|('[^']*'))</td>
</tr>
<tr>
<td align="right">
Space or Tab</td>
<td align="center">
:b</td>
<td align="center">
[ |t]</td>
</tr>
<tr>
<td align="right">
Integer</td>
<td align="center">
:z</td>
<td align="center">
[0-9]+</td>
</tr>
</table>
<p>
But they certainly don't <i>act</i> related when you try to use them. For example, try something simple, like finding "[A-Za-z]+". That's all occurrences of more than one letter in a row. When I try this via the Visual Studio find dialog with the regex option checked, I get positively <i>bizarre</i> results. It finds a word made up of all letters, true, but as I click "Find Next", it then finds each subsequent letter in the word. Again. What planet are these so-called "regular expressions" from?
</p>
<p>
The semi-abandoned Microsoft VSEditor blog has a three part tutorial (<a href="http://blogs.msdn.com/vseditor/archive/2004/06/16/157276.aspx">part one</a>, <a href="http://blogs.msdn.com/vseditor/archive/2004/06/18/159515.aspx">part two</a>, <a href="http://blogs.msdn.com/vseditor/archive/2004/07/12/181078.aspx">part three</a>) on using the crazy Visual Studio dialect of Regex. There's a lot of emphasis on the strange &lt; and &gt; begin/end word match characters, which have no equivalent that I know of in the .NET and Perl dialect of regular expressions.
</p>
<p>
You might say that <b>searching with regular expressions is such an extreme edge condition for most developers</b> that it's not worth the Visual Studio development team's time. I won't disagree with you. It is rare, but it's hardly esoteric. Every developer should be able to grok the value of searching with the basic regular expressions that are a staple of their toolkit these days. Heck, some developers are so hard core they <a href="http://steve-yegge.blogspot.com/2006/06/shiny-and-new-emacs-22.html">search through their code with Lisp expressions</a>. Basic regex search functionality is awfully mild compared to that.
</p>
<p>
To be honest, searching with regular expressions isn't a common task for me either. But I'd be a lot more likely to use it if I didn't have to perform a lot of mental translation gymnastics on the occasions that I needed it. <a href="http://www.codinghorror.com/blog/archives/000377.html">Don't make me think</a>, man. But there is hope. There's a free <a href="http://www.codeproject.com/csharp/SearcherAddIn.asp">add-in available </a> which offers real regular expression searching in Visual Studio.
</p>
<p>
* well, <i>mostly</i> standard, anyway. Certainly <a href="http://www.cuneytyilmaz.com/prog/jrx/">JavaScript regex syntax</a> could be considered standard these days.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-visual-studio-ide-and-regular-expressions/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I Heart Strings ]]></title>
<link>https://blog.codinghorror.com/i-heart-strings/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://blogs.msdn.com/BradA/">Brad Abrams</a> was a founding member of the .NET common language runtime team way back in 1998. He's also the co-author of <a href="http://www.amazon.com/exec/obidos/search-handle-url/field-keywords=brad%20abrams">many essential books on .NET</a>, including <a href="http://www.amazon.com/exec/obidos/ASIN/0321154894/codihorr-20">both</a> <a href="http://www.amazon.com/exec/obidos/ASIN/0321194454/codihorr-20">volumes</a> of the .NET Framework Standard Library Annotated Reference. I was at a presentation Brad gave to the Triangle .NET User's Group early in 2005. During the Q&amp;A period, an audience member (and a friend of mine) asked Brad this question:
</p>
<p>
<i>What's your favorite class in the .NET 1.1 common langauge runtime?</i>
</p>
<p>
His answer? <b>String.</b>
</p>
<p>
And that's from a guy who will forget more about the .NET runtime than I will ever know about it. I still have my <a href="http://www.amazon.com/exec/obidos/ASIN/0321288661/codihorr-20">.NET class library reference poster</a>, autographed by Brad right next to the String class.
</p>
<p>
I've always felt that <b>string is the most noble of datatypes</b>. Computers run on ones and zeros, sure, but people don't. They use words, sentences, and paragraphs to communicate. People communicate with strings. The meteoric rise of HTTP, HTML, REST, serialization, and other heavily string-oriented, human-readable techniques vindicates -- at least in my mind -- my lifelong preference for the humble string.
</p>
<p>
Or, you could argue that we now have so much computing power and bandwidth available that passing friendly strings around in lieu of opaque binary data is actually practical. But don't be a killjoy.
</p>
<p>
Guess what my favorite new .NET 2.0 feature is. Go ahead. Guess! Generics? Nope. Partial classes? Nope again. It's the String.Contains method. And I'm awfully fond of String.IsNullOrEmpty, too.
</p>
<p>
What I love most about strings is that they have a million and one uses. They're the swiss army knife of data types. <a href="http://www.codinghorror.com/blog/archives/000245.html">Regular expressions</a>, for example, are themselves strings, as is SQL.*
</p>
<p>
</p>
<pre>
Regex.IsMatch(s, "&lt;[a-z]|&lt;!|&amp;#|Won[a-z]*s*=|(scripts*:)|expression(")
</pre>
<p>
One of the classic uses for strings, going <a href="http://www.phim.unibe.ch/comp_doc/c_manual/C/FUNCTIONS/format.html">way back to the C days</a>, is to specify output formats. Here's an example of basic string formatting in .NET.
</p>
<p>
</p>
<pre>
"Date is " + DateTime.Now.ToString("MM/dd hh:mm:ss");
</pre>
<p>
You can explicitly use the String.Format method to format, well, almost anything, including our date:
</p>
<p>
</p>
<pre>
String.Format("Date is {0:MM/dd hh:mm:ss}", DateTime.Now);
</pre>
<p>
As <a href="http://codebetter.com/blogs/karlseguin/archive/2006/04/10/142602.aspx">Karl Seguin</a> points out, String.Format is a superior alternative to naive string concatenation:
</p>
<p>
</p>
<blockquote>
Surely, I can't be the only one that has a hard time writing and maintaining code like:
<p>
</p>
<pre>
d.SelectSingleNode("/graph/data[name='" + name + "']");
</pre>
<p>
When I do write code like the above, I almost always forget my closing quote or square bracket! And as things get more complicated, it becomes a flat out nightmare.
</p>
<p>
The solution is to make heavy use of string.Format. You'll never EVER see me use plus to concatenate something to a string, and there's no reason you should either. To write the above code better, try:
</p>
<p>
</p>
<pre>
d.SelectSingleNode(string.Format("/graph/data[name='{0}']", name));
</pre>
</blockquote>
<p>
It's a win-win scenario: you get more power and more protection. For a complete rundown of the zillion possible String.Format specifiers, try these links:
</p>
<p>
</p>
<ul>
<li>SteveX Compiled - <a href="http://blog.stevex.net/index.php/string-formatting-in-csharp/">String Formatting in C#</a>
</li>
<li>Kathy Kam - <a href="http://blogs.msdn.com/kathykam/archive/2006/03/29/564426.aspx">.NET Format String 101</a>
</li>
<li>Kit George - <a href="http://msdn.microsoft.com/netframework/programming/bcl/faq/StringFormattingFAQ.aspx">String Formatting FAQ</a>
</li>
<li>MSDN - <a href="http://msdn.microsoft.com/library/default.asp?url=/library/en-us/cpguide/html/cpconFormattingTypes.asp">Formatting Types</a>
</li>
</ul>
<p>
String class, <i>you complete me</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/i-heart-strings/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Separating Programming Sheep from Non-Programming Goats ]]></title>
<link>https://blog.codinghorror.com/separating-programming-sheep-from-non-programming-goats/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><blockquote>
<p> Please note, this paper was ultimately <a href="http://www.eis.mdx.ac.uk/staffpages/r_bornat/papers/camel_hump_retraction.pdf">retracted by its author</a> (pdf) in 2014:</p>
<blockquote>
<p>In 2006 I wrote an intemperate description of the results of an experiment carried out by Saeed Dehnadi. Many of the extravagant claims I made were insupportable, and I retract them. I continue to believe, however, that Dehnadi had uncovered the first evidence of an important phenomenon in programming learners. Later research seems to confirm that belief.</p>
</blockquote>
</blockquote>
<p>A bunch of people have linked to this <a href="https://web.archive.org/web/20090401003425/http://www.cs.mdx.ac.uk/research/PhDArea/saeed/">academic paper</a>, which proposes <strong>a way to separate programming sheep from non-programming goats in computer science classes</strong>  long before the students have ever touched a program or a programming language:</p>
<blockquote>
<p>All teachers of programming find that their results display a 'double hump'. <strong>It is as if there are two populations: those who can [program], and those who cannot [program], each with its own independent bell curve.</strong> Almost all research into programming teaching and learning have concentrated on teaching: change the language, change the application area, use an IDE and work on motivation. None of it works, and the double hump persists. We have a test which picks out the population that can program, before the course begins. We can pick apart the double hump. You probably don't believe this, but you will after you hear the talk. We don't know exactly how/why it works, but we have some good theories.</p>
</blockquote>
<p>I wasn't aware that the dichotomy between programmers and non-programmers was so pronounced at this early stage. Dan Bricklin touched on this topic in his essay, <a href="http://www.bricklin.com/wontprogram.htm">Why Johnny Can't Program</a>. But evidently it's common knowledge amongst those who teach computer science:</p>

<blockquote>
<p>Despite the enormous changes which have taken place since electronic computing was invented in the 1950s, some things remain stubbornly the same. <strong>In particular, most people can't learn to program: between 30% and 60% of every university computer science department's intake fail the first programming course.</strong> Experienced teachers are weary but never oblivious of this fact; brighteyed beginners who believe that the old ones must have been doing it wrong learn the truth from bitter experience; and so it has been for almost two generations, ever since the subject began in the 1960s.</p>
</blockquote>
<p>You may think the test they're proposing to determine programming aptitude is complex, but it's not. Here's question one, verbatim:</p>
<blockquote>
<p>Read the following statements and tick the box next to the correct answer.</p>
<blockquote></blockquote>
<pre><code>int a = 10;
int b = 20;
a = b;
</code></pre>
<p>The new values of a and b are:<br>
[ ] <code>a = 20  b = 0</code><br>
[ ] <code>a = 20  b = 20</code><br>
[ ] <code>a = 0   b = 10</code><br>
[ ] <code>a = 10  b = 10</code><br>
[ ] <code>a = 30  b = 20</code><br>
[ ] <code>a = 30  b = 0</code><br>
[ ] <code>a = 10  b = 30</code><br>
[ ] <code>a = 0   b = 30</code><br>
[ ] <code>a = 10  b = 20</code><br>
[ ] <code>a = 20  b = 10</code></p>
</blockquote>
<p>This test seems trivial to professional programmers, but remember, it's intended for students who have never looked at a line of code in their lives. The other 12 questions are all variations on the same assignment theme.<br>
The authors of the paper posit that the primary hurdles in computer science are..</p>
<ul>
<li>assignment and sequence</li>
<li>recursion / iteration</li>
<li>concurrency*</li>
</ul>
<p>.. in that order. Thus, we start by testing the very first hurdle novice programmers will encounter: assignment. The test results divided the students cleanly into three groups:</p>
<ol>
<li>44% of students formed a consistent mental model of how assignment works (even if incorrect!)</li>
<li>39% students never formed a consistent model of how assignment works.</li>
<li>8% of students didn't give a damn and left the answers blank.</li>
</ol>
<p>The test was administered twice; once at the beginning, before any instruction at all, and again after three weeks of class. The striking thing is that there was virtually no movement at all between the groups from the first to second test. Either you had a consistent model in your mind immediately upon first exposure to assignment, the first hurdle in programming  <em>or else you never developed one!</em></p>
<p>The authors found an extremely high level of correlation between success at programming and forming a consistent mental model:</p>
<blockquote>
<p>Clearly, Dehnahdi's test is not a perfect divider of programming sheep from non-programming goats. <strong>Nevertheless, if it were used as an admissions barrier, and only those who scored consistently were admitted, the pass/fail statistics would be transformed. In the total population 32 out of 61 (52%) failed; in the first-test consistent group only 6 out of 27 (22%).</strong> We believe that we can claim that we have a predictive test which can be taken prior to the course to determine, with a very high degree of accuracy, which students will be successful. This is, so far as we are aware, the first test to be able to claim any degree of predictive success.</p>
</blockquote>
<p>
I highly recommend reading through <a href="https://web.archive.org/web/20070318023700/http://www.cs.mdx.ac.uk/research/PhDArea/saeed/paper1.pdf">the draft paper</a> (pdf), which was remarkably entertaining for what I thought was going to be a dry, academic paper. Instead, it reads like a blog entry. It's filled with interesting insights like this one:
</p>
<blockquote>
<p>It has taken us some time to dare to believe in our own results. It now seems to us, although we are aware that at this point we do not have sufficient data, and so it must remain a speculation, that what distinguishes the three groups in the first test is their different attitudes to meaninglessness.</p>
<p>Formal logical proofs, and therefore programs  formal logical proofs that particular computations are possible, expressed in a formal system called a programming language  are utterly meaningless. <strong>To write a computer program you have to come to terms with this, to accept that whatever you might want the program to mean, the machine will blindly follow its meaningless rules and come to some meaningless conclusion.</strong> In the test the consistent group showed a pre-acceptance of this fact: they are capable of seeing mathematical calculation problems in terms of rules, and can follow those rules wheresoever they may lead. The inconsistent group, on the other hand, looks for meaning where it is not. The blank group knows that it is looking at meaninglessness, and refuses to deal with it.</p>
</blockquote>
<p>Everyone should know how to use a computer, but <a href="https://blog.codinghorror.com/please-dont-learn-to-code/">not everyone needs to be a programmer</a>. It's still a little disturbing that <strong>the act of programming seems literally unteachable to a sizable subset of incoming computer science students</strong>. Evidently not everyone is as fascinated by meaningless rules and meaningless conclusions as we are; I can't imagine why not.</p>
<p>* which I hope to master <a href="http://www.codinghorror.com/blog/archives/000169.html">sometime between now and my death</a></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/separating-programming-sheep-from-non-programming-goats/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Own a Coding Horror ]]></title>
<link>https://blog.codinghorror.com/own-a-coding-horror/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>A few people recently pointed out that <a href="http://www.codinghorror.com/blog/archives/000515.html">my personal branding</a> isn't everything that it could be. Joseph Cooney even <a href="http://jcooney.net/archive/2005/04/21/512.aspx">took matters into his own hands</a>.</p>
<p>Well, I contacted the big man himself, <a href="http://www.stevemcconnell.com/">Steve McConnell</a>, and he graciously provided me a high resolution vector file of the original Coding Horror logo used in <a href="http://www.amazon.com/exec/obidos/ASIN/0735619670/codihorr-20">Code Complete</a> (see it <a href="http://blog.codinghorror.com/content/images/uploads/2004/02/6a0120a85dcdae970b0120a85dd8ee970b-pi.png">on the page</a>),  along with permission to sell items based on that design.</p>
<table width="100%">
<tr>
<td align="center">
<a href="http://www.cafepress.com/codinghorror/"><img alt="image placeholder" >
</td>
<td align="center">
<a href="http://www.cafepress.com/codinghorror/"><img alt="image placeholder" >
</td>
</tr>
<table cellspacing="8" cellpadding="8" width="100%">
<tr>
<td align="center" valign="top">
<strong>United States / Canada</strong><br> <a href="http://www.cafepress.com/codinghorror/"><img alt="image placeholder" >
</td>
<td align="center" valign="top">
<strong>International</strong><br> <a href="http://www.spreadshirt.net/shop.php?sid=159108"><img alt="image placeholder" >
</td>
</tr>
</table>
<p>I also have custom, two color die-cut vinyl stickers based on the same high resolution vector art.</p>
<img alt="image placeholder" >
<p>To give you an idea of scale, the coin in the picture is a nickel. The dimensions of the sticker are 3.55" h  3" w.</p>
<table cellspacing="8" cellpadding="8" width="100%">
<tr>
<td align="center">
<strong>United States</strong><br>$4 for 4 stickers</td>
<td align="center">
<strong>International</strong><br>$4 for 3 stickers</td>
</tr>
<tr>
<td align="center"><form action="https://www.paypal.com/cgi-bin/webscr" method="post"> <input name="cmd" type="hidden" value="_xclick"> <input name="business" type="hidden" value="jatwood@codinghorror.com"> <input name="undefined_quantity" type="hidden" value="1"> <input name="item_name" type="hidden" value="4 Coding Horror Stickers - shipped to US"> <input name="amount" type="hidden" value="4.00"> <input name="shipping" type="hidden" value="0.00"> <input name="no_shipping" type="hidden" value="2"> <input name="return" type="hidden" value="http://www.codinghorror.com/blog/"> <input name="cancel_return" type="hidden" value="http://www.codinghorror.com/blog/"> <input name="no_note" type="hidden" value="1"> <input name="currency_code" type="hidden" value="USD"> <input name="tax" type="hidden" value="0.00"> <input name="lc" type="hidden" value="US"> <input name="bn" type="hidden" value="PP-BuyNowBF"> <input alt="PayPal - The safer, easier way to pay online!" name="submit" src="https://www.paypal.com/en_US/i/btn/btn_buynowCC_LG.gif" type="image"> </form></td>
<td align="center"><form action="https://www.paypal.com/cgi-bin/webscr" method="post"> <input name="cmd" type="hidden" value="_xclick"> <input name="business" type="hidden" value="jatwood@codinghorror.com"> <input name="undefined_quantity" type="hidden" value="1"> <input name="item_name" type="hidden" value="3 Coding Horror Stickers - shipped Internationally"> <input name="amount" type="hidden" value="4.00"> <input name="shipping" type="hidden" value="0.00"> <input name="no_shipping" type="hidden" value="2"> <input name="return" type="hidden" value="http://www.codinghorror.com/blog/"> <input name="cancel_return" type="hidden" value="http://www.codinghorror.com/blog/"> <input name="no_note" type="hidden" value="1"> <input name="currency_code" type="hidden" value="USD"> <input name="tax" type="hidden" value="0.00"> <input name="lc" type="hidden" value="US"> <input name="bn" type="hidden" value="PP-BuyNowBF"> <input alt="PayPal - The safer, easier way to pay online!" name="submit" src="https://www.paypal.com/en_US/i/btn/btn_buynowCC_LG.gif" type="image"> </form></td>
</tr>
</table>
<p>In case anyone was wondering, the actual Coding Horror font is <a href="http://www.myfonts.com/fonts/linotype/frutiger/75-black/">Frutiger 75 Black</a>, as I figured out today.</p>
<!--kg-card-end: markdown-->
            

            <aside class="read-next">
                    <div class="left">
                      <div class="read-next-label">Next</div>                    
                      <h3 class="read-next-title"><a href="/diseconomies-of-scale-and-lines-of-code/">Diseconomies of Scale and Lines of Code</a></h3>
                    </div>
                    <div class="right">
                      <div class="read-next-label">Previous</div>                                            
                      <h3 class="read-next-title"><a href="/separating-programming-sheep-from-non-programming-goats/">Separating Programming Sheep from Non-Programming Goats</a></h3>
                    </div>
            </aside>

            <footer class="post-footer">

                <section class="author">
                    <h4>Written by Jeff Atwood</h4>
                    <p>Indoor enthusiast. Co-founder of Stack Overflow and Discourse. Disclaimer: I have no idea what I'm talking about. Find me here:  <a href="http://twitter.com/codinghorror">http://twitter.com/codinghorror</a></p>
                </section>

            </footer>


    

    <div id="discourse-comments"></div>

    <script type="text/javascript">
      var discourseUrl = "https://discourse.codinghorror.com/",
          discourseEmbedUrl = 'https://blog.codinghorror.com/own-a-coding-horror/';

      (function() {
        var d = document.createElement('script'); d.type = 'text/javascript'; d.async = true;
          d.src = discourseUrl + 'javascripts/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(d);
      })();
    </script>



<aside class="sidebar">
    <!-- <h3>&larr; Older</h3> <a href="https://blog.codinghorror.com">Read more posts</a> -->
    <!-- 
<div id="welovecodinghorror-block">
    <span> 
        <span class="block-wrap">
            <a href="https://buddy.works/?utm_source=blog&utm_campaign=coding_hororr_bz" class="block-img" target="_blank"><img alt="image placeholder" > 
            <a href="https://buddy.works/?utm_source=blog&utm_campaign=coding_hororr_bz" class="block-text" target="_blank">Get the fastest deployments in UI/UX that blows developers away</a>
        </span>
    </span>
</div>
-->

<script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CKYIK23L&amp;placement=blogcodinghorrorcom" id="_carbonads_js"></script>

<div id="hireme" class="hireme codinghorror" style="min-height: 220px; margin-bottom: 15px;"></div>
<script>
    setTimeout(function () {
        var a = document.createElement("script");
        var b = document.getElementsByTagName('script')[0];
        a.src = "//clc.stackoverflow.com/j/p?d=hireme";
        a.async = true; 
        a.type = "text/javascript"; 
        b.parentNode.insertBefore(a, b);
    }, 5);
</script>

<!--
<div class="welovecodinghorror" style="margin-bottom:15px"> 
[ad] Enjoy the blog? Read <b><a href="https://www.amazon.com/dp/B008HUMTO0/?tag=codihorr-20">Effective Programming: More than Writing Code</a></b> and <b><a href="https://www.amazon.com/dp/B00BU3KPQU/?tag=codihorr-20">How to Stop Sucking and Be Awesome Instead</a></b>  on your Kindle, iPad, Nook, or as a PDF.
</div>
-->

<h3>Resources</h3>

<ul>
    <li><a href="/about-me/">About Me</a></li>    
    <li><a href="https://www.discourse.org/">discourse.org</a></li>
    <li><a href="https://stackexchange.com/">stackexchange.com</a></li>
    <li><a href="https://commonmark.org/help/">Learn Markdown</a></li>    
    <li><a href="/recommended-reading-for-developers/">Recommended Reading</a></li>
</ul>

<ul>
    <li><a href="https://blog.codinghorror.com/rss/" class="icon-feed">Subscribe in a reader</a></li>
    <li><a href="https://follow.it/codinghorror?action=followPub" class="icon-email">Subscribe via email</a></li>
</ul>

<p>Coding Horror has been continuously published since 2004</p>

<footer class="site-footer">
    <section class="copyright">Copyright <a rel="author" href="https://en.wikipedia.org/wiki/Jeff_Atwood">Jeff Atwood</a>  2021<br>
        Logo image  1993 Steven C. McConnell <br>
    Proudly published with <a class="icon-ghost" href="https://ghost.org">Ghost</a></section>
</footer></aside>

    

    
       
    <!-- Begin comScore Tag -->
    <script>
        document.write(unescape("%3Cscript src='https://sb.scorecardresearch.com/beacon.js'%3E%3C/script%3E"));
    </script>
    <script>
        COMSCORE.beacon({
        c1: 2,
        c2: "6035669",
        c3: "",
        c4: "http://www.codinghorror.com/blog/",
        c5: "",
        c6: "",
        c15: ""
        });
    </script>
    <noscript>
      <img alt="image placeholder" >
    </noscript>
    <!-- end comScore Tag -->
</table> ]]></content>
<pubDate>2006-07-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/own-a-coding-horror/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Diseconomies of Scale and Lines of Code ]]></title>
<link>https://blog.codinghorror.com/diseconomies-of-scale-and-lines-of-code/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Steve McConnell on <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">diseconomies of scale in software development</a>:
</p>
<p>
</p>
<blockquote>
<b>Project size is easily the most significant determinant of effort, cost and schedule [for a software project].</b>*
<p>
People naturally assume that a system that is 10 times as large as another system will require something like 10 times as much effort to build. But the effort for a 1,000,000 LOC system is <i>more</i> than 10 times as large as the effort for a 100,000 LOC system.
</p>
<p>
[Using software industry productivity averages], the 10,000 LOC system would require 13.5 staff months. If effort increased linearly, a 100,000 LOC system would require 135 staff months. But it actually requires 170 staff months.
</p>
</blockquote>
<p>
Here's the single most important decision you can make on your software project if you want it to be successful: <i>keep it small.</i> Small may not accomplish much, but the odds of outright failure-- a <a href="http://www.codinghorror.com/blog/archives/000588.html">disturbingly common outcome for most software projects</a>-- is low.
</p>
<p>
I don't think the inverted, non-linear relationship between size and productivity on software projects will come as a shock to anyone; the guys at 37signals have been <a href="http://37signals.com/svn/archives2/when_big_groups_really_want_to_get_things_done_they_make_the_group_smaller.php">banging</a> <a href="http://37signals.com/svn/archives2/edward_hall_the_perfect_group_size_812.php">their</a> <a href="http://37signals.com/svn/archives2/the_disease_of_giants.php">drum</a> on the virtues of small for over a year now. Isn't <a href="http://sethgodin.typepad.com/seths_blog/2005/06/small_is_the_ne.html">small the new big</a> already?
</p>
<p>
But what I really want to focus on here is <b>how you measure a project's size</b>. What's big? What's small? McConnell is using lines of code (LOC) as his go-to measurement. Here's a table that illustrates the relationship between project size and productivity:
</p>
<p>
</p>
<table width="600">
<tr>
<td>Project Size</td>
<td>Lines of code (per year)</td>
<td>COCOMO average
</td>
</tr>
<tr>
<td>10,000 LOC</td>
<td>2,000 - 25,000</td>
<td>3,200
</td>
</tr>
<tr>
<td>100,000 LOC</td>
<td>1,000 - 20,000</td>
<td>2,600
</td>
</tr>
<tr>
<td>1,000,000 LOC</td>
<td>700 - 10,000</td>
<td>2,000
</td>
</tr>
<tr>
<td>10,000,000 LOC</td>
<td>300 - 5,000</td>
<td>1,600
</td>
</tr>
</table>
<p>
Lines of code is a reasonable metric to determine project size, but it also has some problems, which are well-documented in the <a href="http://en.wikipedia.org/wiki/Source_lines_of_code">wikipedia entry on lines of code</a>:
</p>
<p>
</p>
<pre>
/* How many lines of code is this? */
for (i=0; i&lt;100; ++i) printf("hello");
</pre>
<p>
For one thing, different languages vary widely in the number of lines of code they produce. 100 lines of Perl will probably accomplish a lot more than 100 lines of C. So you have to be careful that you're really comparing apples to apples.  Furthermore, skilled developers know that the less code you write, the fewer bugs you've created-- so they naturally distrust any productivity metric that weights absolute lines of code. And does code generation count?
</p>
<p>
Even with all its problems, the LOC metric is still where you should start, according to McConnell:
</p>
<p>
</p>
<blockquote>
My personal conclusion about using lines of code for software estimation is similar to Winston Churchill's conclusion about democracy: <b>The LOC measure is a terrible way to measure software size, except that all the other ways to measure size are worse.</b> For most organizations, despite its problems, the LOC measure is the workhorse technique for measuring size of past projects and for creating early-in-the-project estimates of new projects. The LOC measure is the <i>lingua franca</i> of software estimation, and it is normally a good place to start, as long as you keep its limitations in mind.
<p>
Your environment might be different enough from the common programming environments that lines of code are not highly correlated with project size. If that's true, find something that is more proportional to effort, count that, and base your size estimates on that instead. Try to find something that's easy to count, highly correlated with effort, and meaningful for use across multiple projects.
</p>
</blockquote>
<p>
The <a href="http://en.wikipedia.org/wiki/Source_lines_of_code">wikipedia article</a> features this chart of Windows operating system size, in lines of code, over time:
</p>
<p>
</p>
<table width="600">
<tr>
<td>1993</td>
<td>Windows NT 3.1</td>
<td>6 million
</td>
</tr>
<tr>
<td>1994</td>
<td>Windows NT 3.5</td>
<td>10 million
</td>
</tr>
<tr>
<td>1996</td>
<td>Windows NT 4.0</td>
<td>16 million
</td>
</tr>
<tr>
<td>2000</td>
<td>Windows 2000</td>
<td>29 million
</td>
</tr>
<tr>
<td>2002</td>
<td>Windows XP</td>
<td>40 million
</td>
</tr>
<tr>
<td>2007</td>
<td>Windows Vista</td>
<td>~50 million
</td>
</tr>
</table>
<p>
If you're wondering how much code the average programmer produces per day, I think you might be <a href="http://blogs.msdn.com/philipsu/archive/2006/06/14/631438.aspx">asking the wrong question</a>. Lines of code is certainly a key metric for determining project size, but it's also easily manipulated and misinterpreted. It should never be the only data point used to make decisions; it's just one of many signposts on the road that helps you orient your project.
</p>
<p>
* what are the other most significant determinants? Number two is the type of software you're developing, and personnel factors is a very close third.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/diseconomies-of-scale-and-lines-of-code/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Can't Database Tables Index Themselves? ]]></title>
<link>https://blog.codinghorror.com/why-cant-database-tables-index-themselves/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Here's a thought question for today: <b>why can't database tables index themselves?</b>
</p>
<p>
Obviously, indexes are a central concept to databases and database performance. But horror tales still abound of naive developers who "forget" to index their tables, and encounter massive performance and scalability problems down the road as their tables grow. I've run into it personally, and I've read plenty of other sad tales of woe from other developers who have, too. I've also forgotten to build indexes myself on non primary key columns many times. Why aren't databases smart enough to automatically protect themselves from this?
</p>
<p>
It always struck me as absurd that I had to go in and manually mark fields in a table to be indexed. Perhaps in the bad old file-based days of FoxPro, DBase, and Access, that might have been a necessary evil. But in a modern client-server database, the server should be aware of all the queries flowing through the system, and how much each of those queries cost. <b>Who better to decide what needs to be indexed than the database itself?</b>
</p>
<p>
Why can't you enable an automatic indexing mode on your database server that follows some basic rules, such as..
</p>
<p>
</p>
<ol>
<li>Does this query result in a table scan?
</li>
<li>If so, determine which field(s) could be indexed, for that particular query, to remove the need for a table scan.
</li>
<li>Store the potential index in a list. If the potential index already exists in the list, bump its priority.
</li>
<li>After (some configurable threshold), build the most commonly needed potential index on the target table.
</li>
</ol>
<p>
Of course, for database gurus who are uncomfortable with this, the feature could be disabled. And you could certainly add more rules to make it more robust. But for most database users, it should be enabled by default; <b>an auto-indexing feature would make most database installations almost completely self-tuning</b> with no work at all on their part.
</p>
<p>
I did some cursory web searches and I didn't see any features like this for any commercial database server. What am I missing here? Why does this seem so obvious, and yet it's not out there?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-cant-database-tables-index-themselves/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Creating Smaller Virtual Machines ]]></title>
<link>https://blog.codinghorror.com/creating-smaller-virtual-machines/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Now that <a href="http://www.microsoft.com/windows/virtualpc/default.mspx">Virtual PC is finally free</a>, I've become obsessed with producing <b>the smallest possible Windows XP Virtual PC image</b>. It's quite a challenge, because a default XP install can eat up well over a gigabyte. Once you factor in the swapfile and other overhead, you're generally talking about around 2-4 gigabytes for relatively simple configurations.
</p>
<p>
My best result so far, however, is a <b>641 megabyte</b> virtual machine image of a clean, <i>fully patched</i> Windows XP install. Not bad. And here's how I did it.
</p>
<p>
First, start with the obvious stuff:
</p>
<p>
</p>
<ol>
<li>Install Windows XP SP2. Take all default options.
</li>
<li>Connect to Windows update; install all critical updates.
</li>
<li>Install VM additions.
</li>
<li>Turn off system restore.
<ul>
<li>Right click My Computer; select properties
</li>
<li>Click the System Restore tab
</li>
<li>Click the "Turn off System Restore" checkbox
</li>
<li>OK all the way back out
</li>
</ul>
</li>
<li>Set Visual Effects to minimum.
<ul>
<li>Right click My Computer; select Properties
</li>
<li>Click the Advanced tab
</li>
<li>Click the Performance Settings button
</li>
<li>Click the "Adjust for best performance" checkbox
</li>
<li>OK all the way back out.
</li>
</ul>
</li>
<li>Shut down.
</li>
</ol>
<p>
<i>Don't install anything else yet!</i> Remember, we're trying to get to a minimal baseline install of Windows XP first. A nice, flat platform to build on.
</p>
<p>
It's critical to <b>turn off system restore</b>, because that eats up hundreds of megabytes of disk space. In a virtual machine environment, having a rollback path doesn't make sense anyway. And if the Windows software environment wasn't so pathological, we wouldn't need complex rollback support embedded in the OS, either, but I digress.
</p>
<p>
Now let's put together our toolkit of virtual machine optimization:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.litepc.com/xplite.html">XPlite</a> ($)
</li>
<li>
<a href="http://www.ccleaner.com/">Crap Cleaner</a>
</li>
<li>
<a href="http://www.microsoft.com/windowsxp/downloads/powertoys/xppowertoys.mspx">TweakUI</a>
</li>
<li>
<a href="http://www.whitneyfamily.org/Hacks/?item=Defrag">Whitney Defragger</a>
</li>
<li>
<a href="http://www.invirtus.com/">Invirtus VM Optimizer</a> ($, optional)
</li>
</ul>
<p>
Thes utilities are mostly free. And, except for Crap Cleaner, they don't even require installers. Just plop all the files for each one into a folder; I call mine VM-utils. Copy this folder to the target VM.
</p>
<p>
</p>
<ol>
<li>Use TweakUI to <a href="http://www.codinghorror.com/blog/archives/000565.html">turn on automatic login</a>. Otherwise you have to distribute <b>login credentials</b> with your VM, and who wants to do that?
<p>
</p>
</li>
<li>Now, use <a href="http://www.litepc.com/xplite.html">XPlite</a> to tear out all the <b>annoying, unnecessary bits of Windows XP</b>:
<p>
<img alt="image placeholder" >
</p>
<p>
XPlite is easily the best utility of its type; it removes scads of useless things built into XP that have no explicit uninstall mechanism. Unfortunately, XPlite is payware. There is a free version, but it's crippled; it can only remove a fraction of the items the full version can. See the full list of items it can remove along the right-hand side of the <a href="http://www.litepc.com/xplite.html">product page</a>.
</p>
<p>
By default, XPlite generally shows things that are safe to remove.  Note that the "Advanced Components" item is shown in that screenshot, which is definitely stuff that's <i>not</i> safe to remove unless you really know what you're doing. Anyway, here's what I consider totally safe to remove in XPlite's standard list:
</p>
<p>
</p>
<ul>
<li>Accessibility Options
</li>
<li>Communication and Messaging
</li>
<li>Server Components
</li>
<li>Games
</li>
<li>System Services
</li>
</ul>
</li>
<p>
The others require a bit of judicious selection.
</p>
<p>
</p>
</ol>
<ul>
<li>Accessories - you probably want Notepad, Calc, and the other essential applets. A world without Notepad is a world I don't want to live in.
</li>
<li>Internet Utilities - if you want to keep the default IE6 inside XP, I'd leave this alone. With the notable exception of MSN Explorer, which is always safe to drop.
</li>
<li>Multimedia - if you have sound enabled, selectively keep some of this, otherwise dump it all. It's highly unlikely you would ever want to watch videos or listen to music inside your VM, right? Right?
</li>
<li>Operating System Options - you may want to keep the core fonts if you're planning to browse the web within the VM. Also, beware of removing the service pack update files. Most of this is safe to dump, though. However, you will need the VB6 runtimes for Crap Cleaner to run!
</li>
<li>System Tools &amp; Utilities - I'd leave Dr. Watson, and possibly PerfMon, WSH and Zip folder support.
</li>
</ul>
<p>
Once you've made your selections, let XPlite do its thing. It's worth the effort, because you'll have an unbelievably squeaky clean Start menu when it's done. Who knew Windows XP could be this.. <i>simple?</i>
</p>
<p>
</p>
<li>Install and run <a href="http://www.ccleaner.com/">Crap Cleaner</a>. Perform the default analysis, then do a <b>cleanup</b>. This step is really optional; it only cleans up a couple megabytes of log files and miscellaneous junk. Be sure to uninstall Crap Cleaner when you're done, too.
<p>
</p>
</li>
<li>Now that we've cleaned everything up, we need to <b>defragment the disk</b>.
<p>
<img alt="image placeholder" >
</p>
<p>
You can use any defragmenter you like, of course, but this one is free and works quite well.
</p>
<p>
</p>
<ol>
<li>Navigate to the folder where you put your VM utilities, including the <a href="http://www.whitneyfamily.org/Hacks/?item=Defrag">Whitney Defragger</a>.
</li>
<li>Open a command prompt
</li>
<li>Copy the defragmenting program to our windows system folder:
<p>
</p>
<pre>
copy bootdfrg.exe c:windowssystem32
</pre>
<p>
</p>
</li>
<li>Install the defragmenting service:
<p>
</p>
<pre>
defrag -i
</pre>
<p>
</p>
</li>
<li>Schedule a defragmentation of the c: drive for the next boot:
<p>
</p>
<pre>
defrag -d c: -B
</pre>
<p>
</p>
</li>
<li>Restart the virtual machine.
</li>
<li>The defragmenter will run before Windows loads. Let it run to completion. It may take a little while, but it provides lots of textual feedback on what it's doing.
<p>
</p>
</li>
</ol>
</li>
<li>Now we have to <b>zero the free space on the drive</b>. You have your choice of the free Microsoft Virtual PC Pre-Compactor, or the inexpensive <a href="http://www.invirtus.com/">Invirtus VM Optimizer</a>. Both do the same thing, but the Invirtus tool results in an image that's about 15 percent smaller (641 megabytes vs. 758 megabytes, in my test) than the Microsoft tool.
<p>
Either way, you're mounting an ISO. The Microsoft Pre-Compactor is in a folder named "Virtual Machine Additions" under your Virtual PC install folder. Once mounted, the precompactor will autorun. Let it prep the drive; this doesn't take long.
</p>
<p>
Cleanly shut down the virtual machine.
</p>
<p>
</p>
</li>
<li>Finally, <b>shrink the virtual machine hard drive</b> using the disk wizard available from the Virtual PC UI:
<p>
</p>
<ol>
<li>Click the File | Virtual Disk Wizard drop-down menu
</li>
<li>Edit an existing virtual disk
</li>
<li>Select the correct disk image
</li>
<li>Select "Compact it"
</li>
<li>Select "replacing the original file"
</li>
</ol>
</li>
<p>
.. and prepare to marvel at the tiny size* of the resulting hard drive image!
</p>
<p>
It's really quite amazing how snappy and compact Windows XP can be, <b>once you remove all the useless cruft from it</b>.
</p>
<p>
* that's what <a href="http://en.wikiquote.org/wiki/The_Office_(US)">she said</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/creating-smaller-virtual-machines/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I Pity The Fool Who Doesn't Write Unit Tests ]]></title>
<link>https://blog.codinghorror.com/i-pity-the-fool-who-doesnt-write-unit-tests/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
J. Timothy King has a nice piece on <a href="http://www.jtse.com/blog/2006/07/11/twelve-benefits-of-writing-unit-tests-first">the twelve benefits of writing unit tests first</a>. Unfortunately, he seriously undermines his message by ending with this:
</p>
<p>
</p>
<blockquote>
However, if you are one of the [coders who won't give up code-first], one of those curmudgeon coders who would rather be right than to design good software Well, you truly have my pity.
</blockquote>
<p>
Extending your pity to anyone who doesn't agree with you isn't exactly the most effective way to get your message across.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Consider Mr. T. He's been pitying fools since the early 80's, and the world is still awash in foolishness.
</p>
<p>
It's too bad, because the message is an important one. The general adoption of unit testing is one of the most fundamental advances in software development in the last 5 to 7 years.
</p>
<p>
</p>
<blockquote>
How do you solve a software problem? How do they teach you to handle it in school? What's the first thing you do? You think about how to solve it. You ask, "What code will I write to generate a solution?" But that's backward. The first thing you should be doing --  In fact, this is what they say in school, too, though in my experience it's paid more lip-service than actual service --  The first thing you ask is not "What code will I write?" The first thing you ask is "How will I know that I've solved the problem?"
<p>
We're taught to assume we already know how to tell whether our solution works. It's a non-question. Like indecency, we'll know it when we see it. We believe we don't actually need to think, before we write our code, about what it needs to do. This belief is so deeply ingrained, it's difficult for most of us to change.
</p>
</blockquote>
<p>
King presents a list of <a href="http://www.jtse.com/blog/2006/07/11/twelve-benefits-of-writing-unit-tests-first">12 specific ways</a> adopting a test-first mentality has helped him write better code:
</p>
<p>
</p>
<ol>
<li>Unit tests prove that your code actually works
</li>
<li>You get a low-level regression-test suite
</li>
<li>You can improve the design without breaking it
</li>
<li>It's more fun to code with them than without
</li>
<li>They demonstrate concrete progress
</li>
<li>Unit tests are a form of sample code
</li>
<li>It forces you to plan before you code
</li>
<li>It reduces the cost of bugs
</li>
<li>It's even better than code inspections
</li>
<li>It virtually eliminates coder's block
</li>
<li>Unit tests make better designs
</li>
<li>It's faster than writing code without tests
</li>
</ol>
<p>
Even if you only agree with a quarter of the items on that list-- and I'd say at least half of them are true in my experience-- that is a huge step forward for software developers. You'll get no argument from me on the overall <a href="http://www.codinghorror.com/blog/archives/000265.html">importance of unit tests</a>. I've increasingly come to believe that <b>unit tests are so important that they should be a first-class language construct</b>.
</p>
<p>
However, I think the test-first dogmatists tend to be a little too religious for their own good. <b>Asking developers to fundamentally change the way they approach writing software overnight is asking a lot.</b> Particularly if those developers have yet to write their first unit test. I don't think any software development shop is ready for test-first development until they've adopted unit testing as a standard methodology on every software project they undertake. <a href="http://codebetter.com/blogs/jeffrey.palermo/archive/2006/03/28/141920.aspx">Excessive religious fervor</a> could sour them on the entire concept of unit testing.
</p>
<p>
And that's a shame, because <b>any tests are better than zero tests.</b> And isn't unit testing just a barely more formal way of doing the ad-hoc testing we've been doing all along? I think <a href="http://emw.inf.tu-dresden.de/de/pdai/Forschung/refactoring/refactoring_html/node7.html">Fowler</a> said it best:
</p>
<p>
</p>
<blockquote>
Whenever you are tempted to type something into a print statement or a debugger expression, write it as a test instead.
</blockquote>
<p>
I encourage developers to see the value of unit testing; I urge them to get into the habit of writing structured tests alongside their code. That small change in mindset could eventually lead to bigger shifts like test-first development-- but you have to crawl before you can <i>sprint</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/i-pity-the-fool-who-doesnt-write-unit-tests/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The problem with &quot;Low Priority&quot; ]]></title>
<link>https://blog.codinghorror.com/the-problem-with-low-priority/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've always thought it was ironic that <b>low priority emails are the ones I see first in my inbox</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Marking something with a low priority makes it stand out from all the others. Doesn't that make it implicitly <i>high</i> priority?
</p>
<p>
<a href="http://odetocode.com/Blogs/scott/archive/2006/06/27/4690.aspx">One man's urgent</a> is another man's low priority, and vice-versa. I think it's better to <a href="http://www.codinghorror.com/blog/archives/000455.html">leave the metadata to the machines</a> and avoid marking emails with a priority of any kind, high or low.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-problem-with-low-priority/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What is "Modern Software Development" ]]></title>
<link>https://blog.codinghorror.com/what-is-modern-software-development/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Joel Spolsky came up with a <a href="http://www.joelonsoftware.com/articles/fog0000000043.html">twelve-item checklist</a> in August, 2000 that provides a rough measure of  in his words  "how good a software team is":</p>
<p>
</p>
<ol>
<li>Do you use source control?</li>
<li>
Can you make a build in one step?</li>
<li>
Do you make daily builds?</li>
<li>Do you have a bug database?</li>
<li>Do you fix bugs before writing new code?</li>
<li>Do you have an up-to-date schedule?</li>
<li>Do you have a spec?</li>
</ol>
Steve McConnell enumerated <a href="http://www.stevemcconnell.com/bp08.htm">Software's Ten Essentials</a> in 1997, ten things that every software project should have:<p></p>
<ol>
<li>A product specification</li>
<li>A detailed user interface prototype</li>
<li>A realistic schedule</li>
<li>Explicit priorities</li>
<li>Active risk management</li>
<li>A quality assurance plan</li>
<li>Detailed activity lists</li>
<li>Software configuration management</li>
<li>Software architecture</li>
<li>An integration plan</li>
</ol>
<p>
These are great lists. <b>But Spolsky's list is 6 years old; McConnell's is almost 10 years old!</b> Does <i>your</i> software project meet all these criteria?
</p>
<p>
The lists are still highly relevant and definitely worth revisiting today. But I wonder if the field of software development has advanced far enough that we can take any of the items on this list for granted. I also wonder if any new practices have emerged in the last 6 years that aren't accounted for on either list.
</p>
<p>
So here's my question to you: <b>what core set of practices constitutes modern software development in 2006?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/what-is-modern-software-development/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Information Density and Dr. Bronner ]]></title>
<link>https://blog.codinghorror.com/information-density-and-dr-bronner/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Edward Tufte, in his new book, <a href="http://www.amazon.com/exec/obidos/ASIN/0961392177/codihorr-20">Beautiful Evidence</a>, continues on his crusade for <b>information density</b>. Here's a <a href="http://www.kuro5hin.org/story/2001/9/7/234449/3992">representative recap of a Tufte seminar from 2001</a>:
</p>
<p>
</p>
<blockquote>
Tufte spent most of his talk walking around the room while talking on a wireless mike. He had two projectors set up, but for the most part he only displayed pages or pictures from his books, instructing the audience to follow along in their own copies (which had been provided to every attendee). He occasionally carried around some other props, in particular a few 400-year old books from his personal library. This style not only entertained and engaged the audience, it also emphasized one of his main points, which is that <b>progress is often measured in data density - how many bits per unit of area can be accomodated by a hard drive or a display</b>.
<p>
In terms of text display, a page in a phone book can hold 36K of information, while the best display can only show about 5K. If you look at something like a topographical map, the resolution available on paper is a factor of ten, at least, beyond what can be shown on a screen.
</p>
<p>
Tufte feels that the same mantra about data density should be applied to web sites, and in fact to the entire contents of the computer display that the user sees when navigating a web site. Thus, he dislikes task bars, menu bars, status bars, and other GUI screen overhead, since they constrict how much of the display can be used for content. Once you get to the actual site, he has similar disdain for banner ads, navigation bars, graphical frills, and the like.
</p>
<p>
Tufte feels that the main measure of a web site (or any computer interface) should be <b>the percentage of the screen that is actually devoted to the task at hand</b>. He wants web pages to use words instead of icons, because <a href="http://www.codinghorror.com/blog/archives/000523.html">[words] can display information more compactly</a>. He does not like navigation bars, but instead wants as many choices as possible on the main page.
</p>
</blockquote>
<p>
You'll find the same theme repeated in all of Tufte's books: progress is measured in information density.
</p>
<p>
Although I definitely understand the desire for maximizing content and minimizing UI clutter, I have a hard time squaring the desire for maximum information density with the current Web 2.0 drive for minimalist <i>content</i>.
</p>
<p>
These days, you rarely see screens packed densely with content and hundreds of links, but that's what Tufte seems to be asking for. We even <a href="http://www.codinghorror.com/blog/archives/000529.html">make fun of the Yahoo home page because it has become so dense over time</a>. Are we wrong, and Tufte is right? Average display resolutions haven't increased that much between 1996 and 2006; we went from 800x600 to 1280x1024 or thereabouts. And we have the RGB magic of <a href="http://www.microsoft.com/typography/ClearTypeInfo.mspx">ClearType</a> which increases effective horizontal resolution by about 3x.
</p>
<p>
Maybe the <a href="http://www.codinghorror.com/blog/archives/000529.html">Yahoo home page design</a> overreaches because it's now being designed as if it was a printed page. We have higher resolutions, sure, but computer displays are still nowhere near the resolution of a printed page. Perhaps the current trend of design minimalism is simply eliminating wishful thinking: mating the very low resolution of a computer screen (as compared to a printed page) with a corresponding reduction in content.
</p>
<p>
But Tufte isn't the only design guru to worship at the altar of information density.  Jef Raskin, in <a href="http://www.amazon.com/exec/obidos/ASIN/0201379376/codihorr-20">The Humane Interface</a>, talks about this at some length. He even references Tufte directly:
</p>
<p>
</p>
<blockquote>
We seem to have a real fear of displaying data in our interfaces. We know that people can quickly find one among a few items much more quickly than they can find one among dozens: there is less to look through. But it does not follow, as some seem to think, that it is therefore better to have fewer items on each screen. If you have hundreds of items and split them up among dozens of screens, you lose more in navigation time than you gain in searching for the individual item, even if the one you seek is swimming in a sea of similar-looking items.
<p>
Visual designer Edward Tufte's first three principles for displaying information are:
</p>
<p>
</p>
<ul>
<li>Above all else, show the data.
</li>
<li>Maximize the data-ink ratio.
</li>
<li>Erase nondata ink.
</li>
</ul>
<p>
All we need to do is substitute <i>pixels</i> for <i>ink</i> for his advice to apply to display-based devices. A serious, professional user wants screens packed with useful stuff. Screens should be well labeled, with methods to make finding things easier <b>and dense with the information that represents the real value of each screen.</b>
</p>
</blockquote>
<p>
One of the most remarkable examples of information density, at least in a commercial product, is <a href="http://www.drbronner.com/index.html">Dr. Bronner's soaps</a>:
</p>
<p>
<a href="http://img66.imageshack.us/img66/1853/drbronnerpeppermintsoapsz0.png"><img alt="image placeholder" >
</p>
<p>
Click the image to see a larger version. You can also obtain PDF versions of the labels <a href="http://www.drbronner.com/story.html">directly from the company website</a> (scroll to the bottom).
</p>
<p>
I remember the first time I saw a Dr. Bronner product; the incredible density of the tiny text on the label drew me to it. Yes, they're filled with <a href="http://www.straightdope.com/classics/a3_386.html">half-crazy religious ravings</a>. Not so fun in person, but if someone is this jazzed about a bar of soap, it's somehow endearing. You can see a small video clip of Bronner ranting in person via the <a href="http://www.magicsoapbox.com/">Dr. Bronner's Magic Soapbox</a> documentary trailer.
</p>
<p>
<b>You'd think a label filled with reams of tiny, indecipherable text would be the kiss of death for any commercial product.</b> Not so for eccentric Dr. Bronner and his soaps. Is it a victory for information density? Maybe. I think <a href="http://www.craigslist.org">Craigslist</a> is conceptually pretty close to what Dr. Bronner was doing.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/information-density-and-dr-bronner/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Compiler, It Hurts When I Do This ]]></title>
<link>https://blog.codinghorror.com/compiler-it-hurts-when-i-do-this/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Here's a question that recently came up on an internal mailing list: <b>how do I create an enum with a name that happens to be a c# keyword?</b>
</p>
<p>
I immediately knew the answer for VB.net; you use brackets to delimit the word.
</p>
<p>
</p>
<pre language="vb.net">
Public Enum test
[Public]
[Private]
End Enum
Sub Main()
Dim e As test = test.Private
End Sub
</pre>
<p>
A little internet searching revealed that such things are called <b>escaped identifiers</b>, and the equivalent in c# is the @ character.
</p>
<p>
</p>
<pre language="c#">
public enum test
{
@public,
@private
}
static void main()
{
test e = test.@private;
}
</pre>
<p>
They do work the same, but they don't look the same. In c#, you have to type the unwanted escaped identifier every time you use the enum, and the enum even shows up with the @ prefix in intellisense. However, if you echo back the enum value, it will be "private", and not "@private", as expected.
</p>
<p>
However, after spending 30 minutes researching the answer and playing with the results, I began to wonder if the real answer to this question should be another question: <b>why do you need to do this?</b> At some point it all becomes a little ridiculous. What's next-- an enum named "enum"? A variable named "variable"?
</p>
<p>
Stop me if you've heard this one before:
</p>
<p>
</p>
<blockquote>
A man goes to a doctor's office. He says, "Doctor, it hurts when I raise my arm over my head."
<p>
The doctor replies, "Then don't raise your arm over your head."
</p>
</blockquote>
<p>
If the compiler is telling you it hurts when you do something, maybe you should stop doing it. Just something to consider before merrily swimming your way upstream.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/compiler-it-hurts-when-i-do-this/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Windows XP, Our New Favorite Legacy Operating System ]]></title>
<link>https://blog.codinghorror.com/windows-xp-our-new-favorite-legacy-operating-system/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
John Gruber gloats that <a href="http://daringfireball.net/2006/04/windows_the_new_classic">Windows XP does not fare well in a comparison against OS X</a>:
</p>
<p>
</p>
<blockquote>
But everything about <a href="http://www.apple.com/macosx/bootcamp/">Boot Camp</a> is calibrated to position Windows-on-Mac as the next Classic-style ghetto  --  a compatibility layer that you might need but that you wish you didn't.
<p>
Even the Boot Camp logo:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
reinforces this. It's a bastardized variant of Microsoft's Windows logo, sans color, and with the whitespace between the four panels forming a hidden "X",  la the <a href="http://www.thesneeze.com/mt-archives/000273.php">hidden arrow in the FedEx logo</a>.
</p>
<p>
[Microsoft is] stuck with the fact that in a fair shoot-out, Mac OS X is better. It looks better, it's better designed, it's more exciting, more intriguing, more satisfying. Cf. <a href="http://minimsft.blogspot.com/2006/03/vista-2007-fire-leadership-now.html#c114302448628930798">this joke from an anonymous poster</a> in the comments at Mini-Microsoft's weblog:
</p>
<blockquote>
What's the difference between OS X and Vista?
<p>
Microsoft employees are excited about OS X
</p>
</blockquote>
</blockquote>
<p>
What's conspicuously missing from this comparison is any mention of the fact that Windows XP was originally released in <i>October 2001</i>.
</p>
<p>
In the intervening five years, Apple's OS X has seen <a href="http://en.wikipedia.org/wiki/Mac_OS_X#Timeline_of_Apple_Macintosh_operating_systems">five major releases</a>. If you squint your eyes, tilt your head, and look at it from a distance, perhaps you could consider <a href="http://www.microsoft.com/windowsxp/sp2/default.mspx">Service Pack 2</a> a point release. But any way you slice it, <b>Windows XP is going on five years old now</b>. That's ancient. It's also the longest time Microsoft has ever gone between <a href="http://en.wikipedia.org/wiki/History_of_Microsoft_Windows#Timeline">major releases of Windows</a>.
</p>
<p>
Consider the minimum <a href="http://www.microsoft.com/windowsxp/pro/upgrading/sysreqs.mspx">system requirements</a> for Windows XP:
</p>
<p>
</p>
<ul>
<li>233 MHz processor
</li>
<li>64 MB of RAM (128 MB recommended)
</li>
<li>Super VGA (800 x 600) display
</li>
<li>CD-ROM or DVD drive
</li>
<li>Keyboard and mouse
</li>
</ul>
<p>
The cost of a license to Windows XP is-- quite literally-- more expensive than purchasing a PC that meets these minimum specs today.
</p>
<p>
What Gruber doesn't realize is that <a href="http://daringfireball.net/2006/04/windows_the_new_classic">relegating Windows XP to "Classic" status</a> isn't an insult. It's simply acknowledging what every Windows user already knows: <b>Windows XP is a legacy operating system.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
And there's no shame in it.
</p>
<p>
Look at the age of UNIX, which OS X is based on. In the same way that OS X is a modern remodelling of its BSD and Mach kernel origins, Windows Vista will be a much-needed modern renovation of the XP core.
</p>
<p>
But in the meantime, as the guys at Engadget <a href="http://www.engadget.com/2006/07/28/microsoft-exec-avoids-confirming-vista-release/">recently said</a>:
</p>
<p>
</p>
<blockquote>
At this point we don't really know what to expect anymore, and since <b>our current XP-powered setup already does everything we need it to</b>, we're getting pretty close to not caring if Vista is ever released at all.
</blockquote>
<p>
I'm perfectly content to use Windows XP "classic", as long as Windows Vista is on the horizon for 2007.
</p>
<p>
And there are other benefits to Windows XP's advanced age, too.
</p>
<p>
Since XP's minimum system requirements are absurdly low by today's standards, you'll have no problem running Windows XP-- even <i>multiple instances</i> of Windows XP-- in a virtual machine on a modern development PC. My <a href="http://www.codinghorror.com/blog/archives/000639.html">optimized, fully-patched Windows XP SP2 Virtual Machine image</a> is down to <b>587 megabytes</b>. That's a mere 139 megabytes as a self-extracting RAR file.
</p>
<p>
Most apps run fine in Windows XP with 128 megabytes or 160 megabytes of memory. For example, here's a screenshot of IE 7, Beta 3. It's running in an <a href="http://www.codinghorror.com/blog/archives/000639.html">optimized Windows XP virtual machine</a> with <b>only 128 megabytes of memory:</b>
</p>
<p>
<a href="http://www.codinghorror.com/blog/images/winxp-vm-ie7.png"><img alt="image placeholder" >
</p>
<p>
That's with four tabs open to ESPN, eBay, Yahoo news, and MSN. Even with all that going on, I have more than 20 megabytes of free memory. And my commit charge total is well under the physical memory total. There's still room for more stuff!
</p>
<p>
Clearly, <b>if all you need to do is test IE7 beta 3 in a virtual machine, a humble developer machine with 512 megs of memory will work fine.</b>* Of course, you still need to be careful if you don't have a gigabyte or more of system memory. There are <a href="http://blogs.msdn.com/virtual_pc_guy/archive/2005/09/22/473045.aspx">more detailed guidelines</a> at the Virtual PC guy blog.
</p>
<p>
Here's the complete Task Manager process list for this VM, if you're curious.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I see a few services that could be disabled to free up even more memory.
</p>
<p>
* however, if you're working at a job where developers are expected to work on machines with less than 1 gigabyte of memory, it's definitely time to start looking for a new job.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/windows-xp-our-new-favorite-legacy-operating-system/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Are You an XML Bozo? ]]></title>
<link>https://blog.codinghorror.com/are-you-an-xml-bozo/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Here's a helpful article that <a href="http://hsivonen.iki.fi/producing-xml/">documents some common pitfalls to avoid when composing XML documents</a>. Nobody wants to be <a href="http://www.tbray.org/ongoing/When/200x/2004/01/11/PostelPilgrim">called an XML Bozo</a> by Tim Bray, the co-editor of the XML specification, right?
</p>
<blockquote>
<p>
<img alt="image placeholder" >
<ol>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#nottext">Don't think of XML as a text format</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#notexttemplates">Don't use text-based templates</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#dontprint">Don't <code>print</code></a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#serializer">Use an isolated serializer</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#stack">Use a tree or a stack (or an XML parser)</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#namespace">Don't try to manage namespace declarations manually</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#strings">Use unescaped Unicode strings in memory</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#utf">Use UTF-8 (or UTF-16) for output</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#nfc">Use NFC</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#comments">Don't expect software to look inside comments</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#entities">Don't rely on external entities on the Web</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#cdata">Don't bother with CDATA sections</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#noescaping">Don't bother with escaping non-ASCII</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#prettyprinting">Avoid adding pretty-printing white space in character data</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#textxml">Don't use <code>text/xml</code></a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#xml10">Use XML 1.0</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#astral">Test with astral characters</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#controlchar">Test with forbidden control characters</a>
</li>
<li>
<a href="http://hsivonen.iki.fi/producing-xml/#brokenutf">Test with broken UTF-*</a>
</li>
</ol>
</blockquote>
<p>
I'm a little ambivalent about XML, largely due to what <a href="http://www.iunknown.com">John Lam</a> calls "The Angle Bracket Tax". I think <a href="http://www.codinghorror.com/blog/archives/000333.html">XSLT is utterly insane</a> for anything except the most trivial of tasks, but I <a href="http://www.codinghorror.com/blog/archives/000158.html">do like XPath</a>-- it's sort of like SQL with automatic, joinless parent-child relationships.
</p>
<p>
But XML is generally the least of all available evils, and if you're going to use it, you might as well follow the rules.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/are-you-an-xml-bozo/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Linus Torvalds, Visual Basic Fan ]]></title>
<link>https://blog.codinghorror.com/linus-torvalds-visual-basic-fan/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Stiff recently asked a few programmers a <a href="http://www.dodgycoder.net/2012/09/q-with-nine-great-programmers.html">series of open-ended questions</a>:
</p>
<ul>
<li>How did you learn programming? Were schools of any use?
</li>
<li>What's the most important skill every programmer should have?
</li>
<li>Are math and physics important skills for a programmer?
</li>
<li>What will be the next big thing in computer programming?
</li>
<li>If you had three months to learn one relatively new technology, which one would you choose?
</li>
<li>What are your favorite tools and why?
</li>
<li>What's your favorite programming book?
</li>
<li>What's your favorite non-programming book?
</li>
<li>What music do you listen to?
</li>
</ul>
<p>
The participants are all quite notable:
</p>
<ul>
<li>Linus Torvalds (Linux)
</li>
<li>Dave Thomas (Pragmatic Programmer)
</li>
<li>David Heinemeier Hansson (Ruby/Rails)
</li>
<li>Steve Yegge (Google/Amazon)
</li>
<li>Peter Norvig (Google Research Director)
</li>
<li>Guido Van Rossum (Python)
</li>
<li>James Gosling (Java)
</li>
<li>Tim Bray (XML)
</li>
</ul>
<p>
The interesting thing about open-ended questions is that <strong>the answers often reveal more about the person answering the question than they do about the question.</strong> Guido Van Rossum, for example, comes across as kind of a jerk. But the questions generally provoked some <a href="http://www.dodgycoder.net/2012/09/q-with-nine-great-programmers.html">very thoughtful responses</a>.
</p>
<p>
The most surprising response, however, was from Linus Torvalds. When asked what the "next big thing" would be in computer programming, here's part of his reply:
</p>
<blockquote>
For example, <strong>I personally believe that Visual Basic did more for programming than Object-Oriented Languages did.</strong> Yet people laugh at VB and say it's a bad language, and they've been talking about OO languages for decades.
<p>
And no, Visual Basic wasn't a great language, but I think the easy database interfaces in VB were fundamentally more important than object orientation is, for example.</p>
</blockquote>
<p>
Evidently we have another inductee into the <a href="http://www.codinghorror.com/blog/archives/000087.html">he-man object hater's club</a>.
</p>
<p>
Maybe the moral of this story is that we should value practical aspects of a language far more heavily than relatively meaningless technical merits. Or maybe I just get a kick out of hearing <strong>Linus Torvalds, the king of hard-core C geeks, compliment Visual Basic</strong>.
</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-07-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/linus-torvalds-visual-basic-fan/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Open Source: Free as in "Free" ]]></title>
<link>https://blog.codinghorror.com/open-source-free-as-in-free/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Here's <a href="http://www.hanselman.com/blog/SandcastleMicrosoftCTPOfAHelpCHMFileGeneratorOnTheTailsOfTheDeathOfNDoc.aspx">Scott Hanselman</a> on <a href="http://www.charliedigital.com/PermaLink,guid,95b2ab68-ba92-413a-b758-2783cde5df9c.aspx">the death of nDoc</a>:</p>
<blockquote>
<p>We are blessed. This Open Source stuff is free. But it's free like a puppy. It takes years of care and feeding. You don't get to criticize a free puppy that you bring in to your home.</p>
</blockquote>
<p>Free like a puppy is certainly more poignant than <a href="http://en.wikipedia.org/wiki/Libre">free as in beer</a>. But it's an equally terrible metaphor. Nobody has to crate train NUnit. Nobody has to take NCover for regular walks. Nobody has to clean up NDoc's poop. <b>If open source software required as much effort as raising a puppy, your local pound would be even more full than it already is of unwanted dogs.</b></p>
<img alt="image placeholder" >
<p>The whole <em>point</em> of open source  the reason any open source project exists  is to save us time. To keep us from rewriting the same software over and over. Puppies are cute and fuzzy and sweet, but they're also giant timesinks. To imply that an open source project is as labor intensive as a puppy is reinforcing the very worst stereotypes of open source: <b>software that's only free if your time is worthless.</b></p>
<p>Open source software is at its best when you aren't obligated to do anything at all.</p>
<p>You definitely shouldn't have to pay for it. Scott <a href="http://www.hanselman.com/blog/SandcastleMicrosoftCTPOfAHelpCHMFileGeneratorOnTheTailsOfTheDeathOfNDoc.aspx">didn't</a>:</p>
<blockquote>
<p>For "base of the pyramid" fundamental stuff like Build, Test, Coverage, Docs, will we pay for them? We should. Should we have given the NDoc project $5? Did NDoc help me personally and my company? Totally. Did I donate? No, and that was a mistake.</p>
</blockquote>
<p>How is that a mistake? It's exactly what open source is about: <em>maximum benefit, minimum effort</em>. To suggest that we are morally obligated to make monetary contributions to every open source project we benefit from shows a profound misunderstanding of the economics of open source.</p>
<blockquote>
<p>Personally, as an Open Source project co-leader, I'd much rather folks who use DasBlog pick a bug and send me a patch (unified diff format) than give money.  I suspect that Kevin would have been happy with a dozen engineers taking on tasks and taking on bugs in their spare time.</p>
</blockquote>
<p>Contributing code to an open source project is a far greater extravagance than any monetary contribution could ever be. It's also infeasible for 99 percent of the audience  the rare few who have both the time and the ability  which makes it an even more extravagant demand.</p>
<p>If contributing money is foolish and contributing code is an extravagance, what's a poor user to do? Nothing. Nothing at all, that is, other than use the software.</p>
<p><strong>The highest compliment you can pay any piece of open source software is to simply <em>use it</em>, because it's <em>worth</em> using.</strong> The more you use it, the more that open source project becomes a part of the fabric of your life, your organization, and ultimately the world.</p>
<p>Isn't that the greatest contribution of all?</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/open-source-free-as-in-free/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Shortening Long File Paths ]]></title>
<link>https://blog.codinghorror.com/shortening-long-file-paths/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We're working on a little shell utility that displays paths in a menu. Some of these paths can get rather long, so I cooked up this little regular expression to shorten them. It's a replacement, so you call it like this:
</p>
<p>
</p>
<p><font face="Monospace" size="-1">
<font color="Black"></font><font color="Navy">static</font><font color="Black"> </font><font color="Navy">string</font><font color="Black"> </font><font color="Maroon">PathShortener</font><font color="Black">(</font><font color="Navy">string</font><font color="Black"> </font><font color="Maroon">path</font><font color="Black">)<br>
{<br>
</font><font color="Navy">const</font><font color="Black"> </font><font color="Navy">string</font><font color="Black"> </font><font color="Maroon">pattern</font><font color="Black"> = @"^(w+:|)([^]+[^]+).*([^]+[^]+)$";<br>
</font><font color="Navy">const</font><font color="Black"> </font><font color="Navy">string</font><font color="Black"> </font><font color="Maroon">replacement</font><font color="Black"> = "$1$2...$3";<br>
</font><font color="Navy">if</font><font color="Black"> (</font><font color="Olive">Regex</font><font color="Black">.</font><font color="Maroon">IsMatch</font><font color="Black">(</font><font color="Maroon">path</font><font color="Black">, </font><font color="Maroon">pattern</font><font color="Black">))<br>
{<br>
</font><font color="Navy">return</font><font color="Black"> </font><font color="Olive">Regex</font><font color="Black">.</font><font color="Maroon">Replace</font><font color="Black">(</font><font color="Maroon">path</font><font color="Black">, </font><font color="Maroon">pattern</font><font color="Black">, </font><font color="Maroon">replacement</font><font color="Black">);<br>
}<br>
</font><font color="Navy">else<br>
</font><font color="Black">{<br>
</font><font color="Navy">return</font><font color="Black"> </font><font color="Maroon">path</font><font color="Black">;<br>
}<br>
}</font>
</font></p>
<p>
So, for these paths:
</p>
<p>
</p>
<pre>
C:Documents and SettingsjatwoodMy DocumentsVisual Studio 2005SimpleEncryptionUnitTestsUnitTests.vb
wumpuspublicHilo DeliverablesHilo FinalIntroductionCodeIntroApp_Themescellphonephoto-small.jpg
</pre>
<p>
The result is:
</p>
<p>
</p>
<pre>
C:Documents and Settingsjatwood...UnitTestsUnitTests.vb
wumpuspublic...cellphonephoto-small.jpg
</pre>
<p>
The general strategy is to <b>keep the first two folders at the beginning, replace the middle with an ellipsis, and leave the final folder and filename on the end.</b>
</p>
<p>
After spending an hour dinking around with this and testing it on a bunch of paths, a colleague pointed me to the Windows API call <a href="http://www.pinvoke.net/default.aspx/shlwapi/PathCompactPathEx.html">PathCompactPathEx</a>, which (almost) does the same thing. Doh!
</p>
<p>
</p>
<p><font face="Monospace" size="-1">
[<font color="Olive">DllImport</font><font color="Black">("shlwapi.dll", </font><font color="Maroon">CharSet</font><font color="Black"> = </font><font color="Olive">CharSet</font><font color="Black">.</font><font color="Maroon">Auto</font><font color="Black">)]<br>
</font><font color="Navy">static</font><font color="Black"> </font><font color="Navy">extern</font><font color="Black"> </font><font color="Navy">bool</font><font color="Black"> </font><font color="Maroon">PathCompactPathEx</font><font color="Black">([</font><font color="Olive">Out</font><font color="Black">] </font><font color="Olive">StringBuilder</font><font color="Black"> </font><font color="Maroon">pszOut</font><font color="Black">, </font><font color="Navy">string</font><font color="Black"> </font><font color="Maroon">szPath</font><font color="Black">, </font><font color="Navy">int</font><font color="Black"> </font><font color="Maroon">cchMax</font><font color="Black">, </font><font color="Navy">int</font><font color="Black"> </font><font color="Maroon">dwFlags</font><font color="Black">);<br>
<br>
</font><font color="Navy">static</font><font color="Black"> </font><font color="Navy">string</font><font color="Black"> </font><font color="Maroon">PathShortener</font><font color="Black">(</font><font color="Navy">string</font><font color="Black"> </font><font color="Maroon">path</font><font color="Black">, </font><font color="Navy">int</font><font color="Black"> </font><font color="Maroon">length</font><font color="Black">)<br>
{<br>
</font><font color="Olive">StringBuilder</font><font color="Black"> </font><font color="Maroon">sb</font><font color="Black"> = </font><font color="Navy">new</font><font color="Black"> </font><font color="Olive">StringBuilder</font><font color="Black">();<br>
</font><font color="Maroon">PathCompactPathEx</font><font color="Black">(</font><font color="Maroon">sb</font><font color="Black">, </font><font color="Maroon">path</font><font color="Black">, </font><font color="Maroon">length</font><font color="Black">, 0);<br>
</font><font color="Navy">return</font><font color="Black"> </font><font color="Maroon">sb</font><font color="Black">.</font><font color="Maroon">ToString</font><font color="Black">();<br>
}<br>
</font>
</font></p>
<p>
As you can see from <a href="http://msdn.microsoft.com/library/default.asp?url=/library/en-us/shellcc/platform/shell/reference/shlwapi/path/pathcompactpathex.asp">the API definition for PathCompactPathEx</a>, this works a little differently. It lets you set an absolute length for the path, and displays as many characters as it can with a "best fit" placement of the ellipsis. Here's the output for our two paths:
</p>
<p>
</p>
<pre>
C:Documents and Settingsjatwood...UnitTests.vb
wumpuspublicHilo Deliverab...photo-small.jpg
</pre>
<p>
So, which to choose? <b>CompactPathEx guarantees that the paths will always be exactly (x) characters while displaying as much as it can, but it may not be able to split cleanly.</b> My regex always splits cleanly, but makes no guarantees on length.
</p>
<p>
And obviously, if you're not running Windows, or if you don't care for p/invoke, the API call is clearly out.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/shortening-long-file-paths/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ My Love/Hate relationship with ClearType ]]></title>
<link>https://blog.codinghorror.com/my-lovehate-relationship-with-cleartype/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've been vacillating a bit on <a href="http://www.microsoft.com/typography/ClearTypeInfo.mspx">ClearType</a> recently. I love ClearType in theory. A threefold improvement in horizontal resolution on LCDs is an incredible step forward for computer displays. Internet Explorer 7 forces the issue a bit by always defaulting to ClearType for web content, even if you haven't enabled ClearType in Windows XP.
</p>
<p>
To sweeten the pot even further, <a href="http://www.microsoft.com/downloads/details.aspx?familyid=22e69ae4-7e40-4807-8a86-b3d36fab68d3&amp;displaylang=en">Consolas</a>, one of the best (if not the best) <a href="http://www.codinghorror.com/blog/archives/000157.html">fixed-width fonts I've ever seen</a>, is <a href="http://www.codinghorror.com/blog/archives/000356.html">only usable with ClearType enabled</a>.
</p>
<p>
But in practice, <b>I keep running into problems with ClearType enabled that drive me absolutely bonkers.</b> Check out this shot of Hex Workshop, using the <a href="http://www.microsoft.com/downloads/details.aspx?familyid=22e69ae4-7e40-4807-8a86-b3d36fab68d3&amp;displaylang=en">Consolas font</a>, with ClearType enabled:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
What's up with the hideous halation effects around the selected characters? It's unbearable! The obvious RGB noise around the characters is not helping readability at all.
</p>
<p>
Fortunately, the <a href="http://www.microsoft.com/typography/ClearTypePowerToy.mspx">ClearType Tuner PowerToy</a> lets us tweak this for the better. Switch to the advanced tab so you can use the ClearType Contrast Setting slider. The slider has a range of 1.0 to 2.2, and the changes take effect in real time.
</p>
<p>
Here's a shot of the same window with 2.2 contrast, the lightest possible.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The effect is exacerbated by reducing the contrast, so <b>clearly we have a contrast problem</b>. Let's try turning it all the way up.
</p>
<p>
Here's a shot of the same window with 1.0 contrast, the darkest possible.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Maximum contrast looks good, but it has an unwanted side effect as well-- now <b>bold</b> text looks terrible! Compare for yourself. Minimum contrast at the top, standard in the middle, and maximum at the bottom.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Bold text looks best with contrast set to <i>minimum</i>. I just can't win.
</p>
<p>
I'm currently compromising by sliding the contrast slider over a few notches toward the darker side-- a setting of 1.4 versus the default of 1.6. But no matter how I tweak the slider, there are always places where the text is less legible with ClearType on. Sometimes pathologically so.
</p>
<p>
I guess it's back to standard greyscale font smoothing for me. It's too bad, because I love Consolas, and I think ClearType is genius-- if they could get it to look good in <i>all</i> situations, and not just for black text on a white background.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/my-lovehate-relationship-with-cleartype/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Spec-tacular Failure ]]></title>
<link>https://blog.codinghorror.com/a-spec-tacular-failure/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've written before about <a href="http://www.codinghorror.com/blog/archives/000448.html">the dubious value of functional specifications</a>. If you want to experience the dubious value of specifications first hand, try writing a tool to read and write <a href="http://www.id3.org/">ID3 tags</a>.
</p>
<p>
ID3 tags describe the metadata for an MP3 file, such as Artist, Album, Track, and so forth. ID3 tags certainly don't <i>look</i> all that complicated. Newer versions appear at the beginning of the MP3 file, and are nearly human readable even in a hex editor:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
There's a set of <a href="http://www.id3.org/develop.html">comprehensive ID3 specifications</a> to help us out. <b>Unfortunately the ID3 specs are, in a word, <i>bad</i></b>.
</p>
<p>
Even with a bad spec, you can write code to parse ID3 tags. There are a number of <a href="http://www.codeproject.com/info/search.asp?searchkw=id3">CodeProject articles that read and write ID3 tags</a> with varying levels of success. There's also a mature .NET ID3 library available, <a href="http://home.fuse.net/honnert/hundred/?UltraID3Lib">UltraID3Lib</a>, but unfortunately it's closed source. It also suffers a little from <a href="http://www.codinghorror.com/blog/archives/000380.html">explosion at the pattern factory</a> design.
</p>
<p>
One of the first big warning signs is <a href="http://home.fuse.net/honnert/hundred/?UltraID3Lib">this list of ID3 "offenders"</a> on the UltraID3Lib site. It reads like a who's who of music applications: iTunes, WinAmp, Windows Media Player. <b>If the applications that ship with the operating system can't get ID3 tags right, clearly something is wrong.</b>
</p>
<p>
And that something is <a href="http://www.id3.org/develop.html">the ID3 spec</a>. How does it suck? Let me count the ways:
</p>
<p>
</p>
<ul>
<li>
<b>The spec shows how but rarely explains why.</b> For example, frame sizes are stored as 4-byte "syncsafe integers" where the 8th bit of every byte is zeroed. Why would you store size in such an annoying, unintuitive format? Who knows; the spec doesn't explain. You just grit your teeth and do it.
<p>
</p>
</li>
<li>
<b>The vast majority of the things described in the spec do not appear in any MP3 files that I can find or create.</b> There are 70+ possible frame types, but I've only seen a dozen or so in practice. And what about encryption? Compression? CRC checks? Footers? Extended headers? Never seen 'em. And I probably never will. But I still have to parse through pages and pages of detailed text about these extremely rare features.
<p>
</p>
</li>
<li>
<b>The spec has ridiculous enumerations.</b> Check out <a href="http://lame.sourceforge.net/doc/html/id3.html">the 147 possible values of the music genre byte</a>. The existing 147 categories seem to be chosen completely at random. For example, "Negerpunk" (133), "Christian Rap" (61), and "Native US" (64). And evidently "Primus" (108) isn't just a band, they're a valid music genre, too. iTunes thankfully puts a stop to this madness by only displaying a fraction of these genres in its genre drop-down. And it isn't just the genre tag; one of the possible picture types for the attached picture tag  "APIC" is-- and I swear I'm not making this up-- "A bright coloured fish" ($11). At some point you feel like you're wasting your time by enumerating insanity.
<p>
</p>
</li>
<li>
<b>No examples are provided</b>. Consider the comment frame. This is a relatively complex frame; it supports multiple languages and different encodings. It also supports multiple comments per frame with descriptive labels for each one. And yet it only merits a paragraph in the <a href="http://www.id3.org/id3v2.4.0-frames.txt">frames specification</a>, with no examples of usage whatsoever. Would it kill them to provide a couple examples of how a comment should actually look?
<p>
</p>
</li>
<li>
<b>Related items are not together.</b> The comment frame has two lookups in its header: language and text encoding. There is absolutely no reference at all to these lookup tables in the comment frame description. You have to "just know" that the main ID3 spec defines all languages with three character ISO-639-2 language codes, and that there are four possible text encodings from 00 to 03, with different rules for null termination. It'd be awfully difficult to write a comment tag reader without this information, yet it's nowhere to be found in the description of the comment tag.
</li>
</ul>
<p>
The ID3 spec is doubly frustrating because it makes a simple topic difficult. <b>ID3 tags are just not that complicated</b>. The spec makes me feel like an idiot for not being able to get this stuff right. <i>What's the matter? Can't you read the spec?</i>
</p>
<p>
No. I can't. And evidently, neither could the developers of WinAmp, iTunes, or Windows Media Player.
</p>
<p>
Since the ID3 spec is so deficient, <b>I've been using the behavior of popular applications as a de-facto spec</b>. In other words, I test to see how WinAmp behaves when editing ID3 tags:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
WinAmp isn't a model ID3 tag citizen. It ignores all comments except for the first one, and it adds garbage text as the language string for comments.
</p>
<p>
I also test to see how iTunes behaves when editing ID3 tags:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Although iTunes reads all versions of ID3 tags, it <a href="http://the.taoofmac.com/space/blog/2003-09-02">still writes ancient v2.2 ID3 tags to MP3 files</a>, even in the latest version. So it's an especially poor role model for tagging.
</p>
<p>
Warts and all, <b>the practical implementations of ID3 tags in popular applications like WinAmp and iTunes trump anything that's written in the formal ID3 spec.</b> I finally understand what <a href="http://kerneltrap.org/node/5725">Linus Torvalds was complaining about</a>:
</p>
<p>
</p>
<blockquote>
A "spec" is close to useless. I have never seen a spec that was both big enough to be useful and accurate. And I have seen lots of total crap work that was based on specs. It's the single worst way to write software, because it by definition means that the software was written to match theory, not reality.
</blockquote>
<p>
Specs, if they're well-written, can be useful. But they probably won't be. <b>The best functional spec you'll ever have is the behavior of real applications.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-spec-tacular-failure/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Filesystem Metadata Doesn't Scale ]]></title>
<link>https://blog.codinghorror.com/filesystem-metadata-doesnt-scale/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although I always use <a href="http://en.wikipedia.org/wiki/CDDB">CDDB metadata</a> in my self-ripped MP3 files, <b>the quality of the <a href="http://en.wikipedia.org/wiki/ID3">ID3 tags</a> in my MP3 files lags far behind the quality of the file and folder names</b>.
</p>
<p>
File and folder naming is immediately visible and easy to change.
</p>
<p>
</p>
<pre>
C:MusicBeatlesThe White AlbumDisc 11 - Back in the USSR.mp3
</pre>
<p>
Metadata tucked away inside a binary file.. isn't.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But Windows Media Player doesn't care a whit about my painstakingly constructed file names and folder trees. It ignores them completely in favor of the metadata <i>inside</i> the MP3 file to categorize music in its "media library". I've never used iTunes, but from what I've read, I understand it works the same way. To ignore obvious, simple external filesystem metadata in favor of complex internal ID3 metadata is doing a disservice to the user. But that's exactly how most media applications work!
</p>
<p>
It's also a case study in <b>the difference between text and binary files</b>. In the Googleland of web pages, everything is text, and therefore it's possible for everything to be self-describing and self-indexing. That's why <a href="http://www.codinghorror.com/blog/archives/000455.html">Google ignores metadata on the web</a>. Text files don't need metadata. Or even a filename. The words inside the text file describe it better than any human generally will. Human metadata is highly suspect; people <a href="http://www.well.com/~doctorow/metacrap.htm">aren't capable of creating objective metadata for their own content</a>. Plus, there's money to be made, and a dozen other reasons <a href="http://www.codinghorror.com/blog/archives/000455.html">the &lt;meta&gt; tag is all but irrelevant these days</a>.
</p>
<p>
In the world of binary data-- music, pictures, and video-- there's no text inside the file to work with. <b>For binary files, metadata isn't an optional nice to have. It's <i>required</i>.</b> For example, when you <a href="http://images.google.com/images?q=wozniak">perform a Google image search on "Wozniak"</a>, you're really searching the image <i>metadata</i>. If you get results, it's because..
</p>
<p>
</p>
<ul>
<li>Some text near the image contains the word "wozniak"
</li>
<li>The alt tag for the image contains "wozniak"
</li>
<li>The filename for the image contains "wozniak"
</li>
</ul>
<p>
Given how little metadata the image search has to work with, it's amazing that it works as well as it does..
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
.. but it still doesn't work very well. <b>You just can't search binary content properly without structured metadata.</b>
</p>
<p>
And <i>that's</i> why iTunes and Windows Media Player are so insistent about using the ID3 tags inside the MP3 files. Folders and filenames get awkward quickly. Everyone has a different organization method. One folder per Genre? Folders A-Z? One folder per Artist? Dashes, underscores, or semicolons for delimiters? Should filenames contain the information, or just the folders? Should the artist or the album come first? <b>The larger your music library grows, the more unwieldy it is to organize using folders and filenames.</b>
</p>
<p>
ID3 tags are more work, but they're far more effective. If you have proper ID3 tags, you can synthesize any file and folder structure you want. And searching your music collection is easy and fast, too.
</p>
<p>
That's why I've decided to buckle down and standardize all the ID3 tags in my MP3 collection. It's giant-- currently 10,970 songs and 733 albums in 48.9 gigabytes. I'm maniacal about <a href="http://www.codinghorror.com/blog/archives/000470.html">ripping my own MP3 files with VBR encoding</a> using Audiograbber and LAME. Proper ID3 tagging and album art also means my library will (finally) show up nicely in the music browser for my always-on, low-power optimized <a href="http://www.codinghorror.com/blog/archives/000221.html">home theater PC</a> running Windows Media Center.
</p>
<p>
<a href="http://www.microsoft.com/windowsxp/mediacenter/default.mspx"><img alt="image placeholder" >
</p>
<p>
<a href="http://www.newegg.com/Product/ProductList.asp?N=2010150014+103530113&amp;Submit=ENE&amp;SubCategory=14">Large hard drives</a> have come down a lot in price, so it's now feasible to consolidate all my media storage on the HTPC with a single quiet 500gb data drive.
</p>
<p>
With this many songs to organize, going into a properties dialog for each file is clearly out of the question. The two ID3 tag organizing utilities I saw recommended most were <a href="http://www.softpointer.com/tr.htm">Tag &amp; Rename</a> and <a href="http://www.mediamonkey.com/product.htm">MediaMonkey</a>. I didn't get around to trying Tag &amp; Rename, because I was blown away by <b>how amazingly great MediaMonkey is.</b> I can't recommend it strongly enough. The free version includes all the essential ID3 tag maintenance functions you'd ever need:
</p>
<p>
</p>
<ul>
<li>An easy way to grab all album information from Amazon, including cover art, track details, year, and artist information.
</li>
<li>Flexible translation back and forth between filesystem metadata and ID3 metadata, with a real time "as you type" preview of what will happen. This is a killer feature!
</li>
<li>Visualize your library by folder or metadata to quickly find errors, typos, and miscategorizations. Then drag and drop to fix them.
</li>
<li>Built-in tools to fix common stuff like Title/Artist reversal (depressingly common), casing problems, duplicate content, etcetera.
</li>
<li>Designed for large music libraries. It's super fast at writing tags. It also queues updates intelligently; I did complete updates of 10,000+ tags several times.
</li>
</ul>
<p>
It's an incredibly well-written app. It does <i>everything</i> right, including little stuff like automatic population of autocomplete drop-downs for every ID3 field based on your existing library. However, I do recommend switching to ASCII tags; it defaults to Unicode by default, which most people won't need, and this doubles the size of the tags.
</p>
<p>
Even with a great tool, fixing this much metadata was an incredibly tedious and thankless task. I don't even want to think about how much time I've spent on this. There's <a href="http://www.jonathansblog.net/gracenote_cddb">a lot of human error enshrined in the CDDB data</a>:
</p>
<ul>
<li>Track and Title reversed
</li>
<li>Spelling errors
</li>
<li>Grammar errors
</li>
<li>Casing problems; all lower case is common
</li>
<li>Missing important tags
</li>
</ul>
<p>
Very few things in CDDB are totally wrong, however. If Wikipedia can work, so can CDDB (or <a href="http://en.wikipedia.org/wiki/CDDB#Alternatives">something like it</a>). It's a question of making the editing process as easy and obvious as possible, so these minor mistakes get fixed over time.
</p>
<p>
Beyond minor mistakes, <b>metadata is a vast, grey wasteland of indeterminisms.</b> Which of these is correct?
</p>
<p>
</p>
<ul>
<li>"Eno, Brian" or "Brian Eno"?
</li>
<li>"Cardigans" or "The Cardigans"?
</li>
<li>"Earth Wind &amp; Fire", or "Earth, Wind &amp; File", or "Earth, Wind and Fire"?
</li>
<li>"Rock" or "Pop"?
</li>
<li>Does the Year field mean year of original song release or year of album release?
</li>
</ul>
<p>
The correct answer is "all of the above". And then some.
</p>
<p>
Although I've been generally happy with the results of the ID3 tagging, there is one notable piece of ID3 metadata missing. I own lots of multi-disc sets. Unfortunately, <b>there's no ID3 tag for disc number</b>, eg, "Disc 3 of 12". I can't find any ID3 tag (at least, none that are visible in MediaMonkey) that looks appropriate. So I end up tacking the disc number on to the album title, which seems a little hokey. *
</p>
<p>
I suppose the true lesson here is that <b>I should have been more diligent about editing metadata at the time I ripped the albums instead of deferring all the work until now.</b> Trying to infer metadata through the filesystem seems like a workable solution, but it isn't. Filesystem metadata just doesn't scale.
</p>
<p>
* Update: this is the TPOS tag, and it's exposed in the UI for iTunes and Tag &amp; Rename. It does not appear anywhere in MediaMonkey, which is an odd oversight.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/filesystem-metadata-doesnt-scale/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Properties vs. Public Variables ]]></title>
<link>https://blog.codinghorror.com/properties-vs-public-variables/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I occasionally see code with properties like this:
</p>
<p>
</p>
<p><font face="Monospace" size="-1">
<font color="Navy">private</font><font color="Black"> </font><font color="Navy">int</font><font color="Black"> </font><font color="Maroon">name</font><font color="Black">;<br>
<br>
</font><font color="Navy">public</font><font color="Black"> </font><font color="Navy">int</font><font color="Black"> </font><font color="Maroon">Name<br>
</font><font color="Black">{<br>
</font><font color="Navy">get</font><font color="Black"> { </font><font color="Navy">return</font><font color="Black"> </font><font color="Maroon">name</font><font color="Black">; }<br>
</font><font color="Navy">set</font><font color="Black"> { </font><font color="Maroon">name</font><font color="Black"> = </font><font color="Navy">value</font><font color="Black">; }<br>
}</font>
</font></p>
<p>
As I see it, there are three things to consider here.
</p>
<p>
</p>
<ol>
<li>
<b>When is a property not a property? When it's a glorified public variable.</b>
<p>
Why waste everyone's time with a bunch of meaningless just-in-case wrapper code? Start with the simplest thing that works-- a public variable. You can always <a href="http://c2.com/xp/YouArentGonnaNeedIt.html">refactor this later into a property</a> if it turns out additional work needs to be done when the name value is set. If you truly <i>need</i> a property, then use a property. Otherwise, <a href="http://en.wikipedia.org/wiki/KISS_Principle">KISS</a>!
</p>
<p>
<font color="red">Update:</font> As many commenters have pointed out, there are valid reasons to make a trivial property, exactly as depicted above:
</p>
<ul>
<li>Reflection works differently on variables vs. properties, so if you rely on reflection, it's easier to use all properties.
</li>
<li>You can't databind against a variable.
</li>
<li>Changing a variable to a property is <a href="http://blogs.msdn.com/abhinaba/archive/2006/04/11/572694.aspx">a breaking change</a>.
</li>
</ul>
</li>
<p>
It's a shame there's so much meaningless friction between variables and properties; most of the time they do the exact same thing. <a href="http://weblogs.asp.net/kdente/">Kevin Dente</a> proposed a bit of new syntax that would give us the best of both worlds:
</p>
<p>
</p>
<pre>
public property int Name;
</pre>
<p>
However, if the distinction between variable and property is such an ongoing problem, I wonder if a more radical solution is in order. <b>Couldn't we ditch variables entirely in favor of properties?</b> Don't properties do exactly the same thing as variables, but with better granular control over visibility?
</p>
<p>
</p>
<li>
<b>Distinguishing public and private using only case is an accident waiting to happen.</b>
<p>
The difference between name and Name is subtle at best. I don't want to <a href="http://www.codinghorror.com/blog/archives/000458.html">reopen the whole case sensitivity debate</a>, but using case to distinguish between variables is borderline irresponsible programming. Use a distinction that looks and reads different: m_name, _name. Or maybe eschew prefixes altogether and use fully qualified references: this.name. I don't really care. But please, for the love of all that's holy, don't abuse us with even more meaningless case sensitivity.
</p>
<p>
</p>
</li>
<li>
<b>Is it a property or a method?</b>
<p>
In this case, we barely have a property. But if you are executing code in a property, make sure you've written a property and not a method. A property should do less work-- a <i>lot</i> less work-- than a method. Properties should be lightweight. If your property incurs significant effort, it should be refactored into an explicit method. Otherwise it's going to feel like an annoying side-effect of setting a property. And if there's any chance at all that code could spawn an hourglass, it <i>definitely</i> should be a method. Conversely, if you have a lot of simple, lightweight methods, maybe they ought to be expressed as properties. Just something to think about.
</p>
<p>
</p>
</li>
</ol>
<p>
The really important thing to take away here is to <b>avoid writing code that doesn't matter</b>. And property wrappers around public variables are the very essence of meaningless code.
</p>
<p>
As for the rest, I've learned to take a "live and let live" approach to code formatting, at least for cosmetic stuff like variable names. When in doubt, try to follow the <a href="http://blogs.msdn.com/brada/articles/361363.aspx">Microsoft internal coding guidelines</a> unless you have a compelling reason not to.
</p>
<p>
But a few things still get under my skin. I've even seen .NET constants expressed in the old school all-caps way:
</p>
<p>
</p>
<p><font face="Monospace" size="-1">
<font color="Navy">static</font><font color="Black"> </font><font color="Navy">const</font><font color="Black"> </font><font color="Navy">int</font><font color="Black"> </font><font color="Maroon">TRIGGER_COUNT</font><font color="Black"> = 100;</font>
</font></p>
<p>
All style guidelines aside, <i>you know that ain't right</i>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/properties-vs-public-variables/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Quad Core Desktops and Diminishing Returns ]]></title>
<link>https://blog.codinghorror.com/quad-core-desktops-and-diminishing-returns/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Dual core CPUs were <a href="http://www.codinghorror.com/blog/archives/000285.html">a desktop novelty in the first half of 2005</a>. Now, with the introduction of the <a href="http://www.apple.com/macpro/">Mac Pro</a> (see one <a href="http://www.powermax.com/articles_reviews/article.php?id=33">unboxed</a>), <b>dual core is officially pass</b>. Quad core-- at least in the form of two dual-core CPUs-- is where it's at for desktop systems.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
And sometime early next year, the <a href="http://news.com.com/Intel+shows+off+its+quad+core/2100-1006_3-6038148.html">first true quad core CPUs will hit the market</a>.
</p>
<p>
I think there are clear multitasking benefits in a dual-core configuration for typical computer users. All you need to do is run two applications at once, and who doesn't do that these days?
</p>
<p>
However, <b>the benefits from moving to quad-core and beyond are less clear</b>. Effectively utilizing 4 or 8 CPU cores requires extremely aggressive multithreading support within applications. How aggressive? <i>Rewrite your entire application in a new language</i> aggressive. That's a <a href="http://www.codinghorror.com/blog/archives/000169.html">much more difficult problem</a>. It's also not a common optimization, except within very specific application niches.
</p>
<p>
Dual CPU desktop systems weren't twice as fast as single CPU desktop systems. But they were a substantial, worthwhile speed bump. <b>With quad CPU systems, we've hit the point of diminishing returns.</b>
</p>
<p>
Current benchmark data definitely bears this out. I distilled results from these <a href="http://www.gamepc.com/labs/view_content.asp?id=opteron275&amp;page=8">GamePC</a> and <a href="http://techreport.com/reviews/2005q2/opteron-x75/index.x?pg=6%0A">TechReport</a> reviews of the Opteron 275 (dual core 2.2 GHz), which also included the Opteron 247 (single core 2.2 GHz). <b>It's an apples-to-apples comparison between Dual and Quad configurations of an Athlon 64 running at the same speed-- 2.2 GHz.</b>
</p>
<p>
</p>
<table width="600">
<tr>
<td>
</td>
<td>
<strong>Dual CPU</strong>
</td>
<td>
<strong>Quad CPU</strong>
</td>
<td>
</td>
</tr>
<tr>
<td>
3D Studio Max 7.0 Radiosity Render</td>
<td>
239</td>
<td>
144</td>
<td>
<font color="red">1.7 x</font>
</td>
</tr>
<tr>
<td>
POV-Ray chess2.pov</td>
<td>
144</td>
<td>
87</td>
<td>
<font color="red">1.6 x</font>
</td>
</tr>
<tr>
<td>
Cinebench 2003 Rendering</td>
<td>
571</td>
<td>
1021</td>
<td>
<font color="red">1.8 x</font>
</td>
</tr>
<tr>
<td>
Alias Maya 6.0 Zoo Render</td>
<td>
49</td>
<td>
43</td>
<td>
1.1 x</td>
</tr>
<tr>
<td>
Photoshop CS Filter Benchmark</td>
<td>
146</td>
<td>
131</td>
<td>
1.1 x</td>
</tr>
<tr>
<td>
Flash MX 2004 MPEG import</td>
<td>
37</td>
<td>
35</td>
<td>
1.1 x</td>
</tr>
<tr>
<td>
Windows Media Encoder 9.0 MPEG to WMV</td>
<td>
125</td>
<td>
119</td>
<td>
1.1 x</td>
</tr>
<tr>
<td>
Xmpeg/DivX encoding</td>
<td>
71</td>
<td>
75</td>
<td>
1.1 x</td>
</tr>
<tr>
<td>
LAME 3.97 WAV to MP3</td>
<td>
69</td>
<td>
67</td>
<td>
none</td>
</tr>
<tr>
<td>
Apache 2.0 10k user stress test</td>
<td>
1397</td>
<td>
1478</td>
<td>
1.1 x</td>
</tr>
<tr>
<td>
Apache 2.0 50k user stress test</td>
<td>
1346</td>
<td>
1875</td>
<td>
1.4 x</td>
</tr>
<tr>
<td>
Sysmark 2004</td>
<td>
226</td>
<td>
242</td>
<td>
1.1 x</td>
</tr>
<tr>
<td>
Half-Life 2: Airboat chase</td>
<td>
95</td>
<td>
96</td>
<td>
none</td>
</tr>
<tr>
<td>
Doom 3: Site 3 timedemo</td>
<td>
164</td>
<td>
166</td>
<td>
none</td>
</tr>
<tr>
<td>
3DMark05</td>
<td>
5244</td>
<td>
5244</td>
<td>
none</td>
</tr>
</table>
<p>
I eliminated most of the synthetic benchmarks; I tried to focus on real desktop applications that people actually use. The <a href="http://www.bapco.com/products/sysmark2004/">Sysmark 2004</a> results are particularly telling.
</p>
<p>
However, the results I did find are so poor that <b>I wonder if any quad CPU system is good for much more than bragging rights</b>. Of the desktop apps, only three truly benefit from a quad CPU configuration: 3D Studio Max, POV-Ray, and Cinebench 2003. Notice a pattern? Rendering and encoding tend to parallelize well.
</p>
<p>
Unless you're often running a specific application that is optimized for multithreading, there's no compelling reason to run out and buy a quad-CPU desktop system today. And I don't see that advice changing over the next few years. At least, not until the state of software development changes quite radically to embrace multithreading across the board.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/quad-core-desktops-and-diminishing-returns/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Fitts' Law and Infinite Width ]]></title>
<link>https://blog.codinghorror.com/fitts-law-and-infinite-width/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a class="blines3" href="http://en.wikipedia.org/wiki/Fitts%27_law" target="_blank" title="Link outside of this blog">Fitts' Law</a> is arguably the most important formula in the field of human-computer interaction. It's..
</p>
<p>
Time = a + b log<sub>2</sub> ( D / S + 1 )
</p>
<p>
.. where D is the distance from the starting point of the cursor, and S is the width of the target. This is all considered on a 2D plane relative to the axis of movement.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Years of experimental results have <a class="blines3" href="http://en.wikipedia.org/wiki/Fitts%27_law#Success_and_implications_of_Fitts.27_law" target="_blank" title="Link outside of this blog">proven Fitts' law time and time again</a>:
</p>
<p>
</p>
<blockquote>
Fitts' law has been shown to apply under a variety of conditions, with many different limbs (hands, feet, head-mounted sights, eye gaze), manipulanda (input devices), physical environments (including underwater!), and user populations (young, old, mentally retarded, and drugged participants). Note that the constants a and b have different values under each of these conditions.
</blockquote>
<p>
It's not exactly rocket science, as <a class="blines3" href="http://www.asktog.com/basics/firstPrinciples.html#fittsLaw" target="_blank" title="Link outside of this blog">Bruce Tognazzini points out</a>:
</p>
<p>
</p>
<blockquote>
<b>The time to acquire a target is a function of the distance to and size of the target. </b>
<p>
While at first glance, this law might seem patently obvious, it is one of the most ignored principles in design. Fitts' law (properly, but rarely, spelled "Fitts' Law") dictates the Macintosh pull-down menu acquisition should be approximately five times faster than Windows menu acquisition, and this is proven out.
</p>
</blockquote>
<p>
So, to make navigation easier, you either put clickable items closer together, or you make the clickable area bigger. Or both. I know what you're thinking: <i>no duh</i>. But bear with me.
</p>
<p>
Here's one thing that puzzled me. I hate Windows as much as the next disestablishmentarianist, but how can the menu argument be valid? Are Macintosh pull-down menus really that much larger than Windows pull-down menus?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
They aren't significantly larger. <b>But Macintosh menus aren't attached to the application window-- they're always at the top of the screen.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Since the cursor stops at the edge of the screen, <b>for the purposes of Fitts' law calculation, Macintosh menus are infinitely tall!</b> Thus, Macintosh menus <i>are</i> faster to navigate.
</p>
<p>
Although placing the menus at the top of the display does leverage Fitts' law nicely, it also presents its own set of problems.
</p>
<ul>
<li>Where does the menu go in a multiple monitor scenario? <a class="blines2" href="http://www.codinghorror.com/blog/archives/000217.html" target="_blank" title="Link to another page in this blog">I use three monitors</a> on both my home and work PCs. If I move an application to the rightmost monitor, do the application menus still appear on the center or left monitor?
</li>
<li>Detaching applications from their UI in this manner seems to violate the rule of proximity-- related things should be together. On a single monitor system, the distance between the application and its menu could be quite large unless the application window is maximized.
</li>
<li>In a broader sense, <a class="blines2" href="http://www.codinghorror.com/blog/archives/000397.html" target="_blank" title="Link to another page in this blog">I think the days of the main menu are numbered as a keystone GUI metaphor.</a> As far back as I can remember, the Macintosh has always used this "menu at the top of the display" metaphor, so it's written in stone for users at this point. Change could be painful. But then again, Apple has a habit of reinventing themselves periodically, so who knows.
</li>
</ul>
<p>
Fitts' law isn't just about making things larger and easier to click on. It's about <a class="blines3" href="http://www.asktog.com/basics/firstPrinciples.html#fittsLaw" target="_blank" title="Link outside of this blog">maximizing the utility of the natural borders on the edges of your screen</a>:
</p>
<p>
</p>
<blockquote>
Fitts' law indicates that the most quickly accessed targets on any computer display are the four corners of the screen, because of their pinning action, and yet, for years, they seemed to be avoided at all costs by designers.
<p>
Use the pinning actions of the sides, bottom, top, and corners of your display: A single-row toolbar with tool icons that "bleed" into the edges of the display will be many times faster than a double row of icons with a carefully-applied one-pixel non-clickable edge between the tools and the side of the display.
</p>
</blockquote>
<p>
I've definitely felt the pain of Fitts' law violations.
</p>
<p>
I love multiple monitors. In my opinion, life begins with two displays, the largest you can afford. And you should really upsize to three if you want maximum benefit. But <b>one unfortunate side-effect of multiple monitors is the removal of some natural edges between adjoining monitors.</b> The cursor now flows freely between monitors; it's painful to stop the cursor on the left and right edges of the app on the center monitor.
</p>
<p>
And Fitts' law violations can also extend to hardware. Consider touchpad designs that have dedicated scrolling areas on the left or bottom.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This seems like a good idea on paper, but in practice, it destroys the usability of the touchpad. <b>On a touchpad with dedicated scrolling areas, you have no way to know when you've passed from touchpad area into the no-man's-land of scrolling area.</b> The natural edges of the touchpad are ruined; we've given them an arbitrarily different, hard-coded set of functionality. Dedicated hardware isn't even necessary to achieve scrolling effects on a touchpad. We can easily leverage Fitts' Law in the touchpad driver software instead. Just slide your finger until you hit an edge, then slide it along the edge.
</p>
<p>
<b>The edges could be your most valuable real estate.</b> Use them responsibly. Fitts' law is powerful stuff.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/fitts-law-and-infinite-width/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Last Configuration Section Handler.. Revisited ]]></title>
<link>https://blog.codinghorror.com/the-last-configuration-section-handler-revisited/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>If you need to store a little bit of state-- in your configuration file, or on disk-- nothing is faster than some quick and dirty <a href="http://en.wikipedia.org/wiki/Serialization">serialization</a>. Or as I like to call it, stringization.</p>
<p>In late 2004, I wrote about <a href="http://www.codinghorror.com/blog/archives/000161.html">The Last Configuration Section Handler</a>, which does exactly this for *.config files. It's based on earlier work by <a href="http://www.pluralsight.com/wiki/default.aspx/Craig/XmlSerializerSectionHandler.html">Craig Andera of Pluralsight</a>. Let's bring that code up to date for Visual Studio 2005, and furthermore, we'll do it in C# and <em>The Language of the Gods</em>, VB.NET.</p>
<p>The first thing to do is <strong>set up a little class that represents the data you want to serialize.</strong> Include whatever types you need, but make everything public so it'll be visible to the serializer.</p>
<p style="margin-left: 20px;"><span style="font-family: monospace;"> <span style="color: navy;">namespace</span><span style="color: black;"> </span><span style="color: maroon;">SomeNamespace<br> </span><span style="color: black;">{<br> </span><span style="color: navy;">public</span><span style="color: black;"> </span><span style="color: navy;">class</span><span style="color: black;"> </span><span style="color: maroon;">MyStuff<br> </span><span style="color: black;">{<br> </span><span style="color: navy;">public</span><span style="color: black;"> </span><span style="color: navy;">int</span><span style="color: black;"> </span><span style="color: maroon;">i</span><span style="color: black;">;<br> </span><span style="color: navy;">public</span><span style="color: black;"> </span><span style="color: navy;">string</span><span style="color: black;"> </span><span style="color: maroon;">s</span><span style="color: black;">;<br> } <br> }</span> </span></p>
<p>Now use this routine to serialize it:</p>
<p style="margin-left: 20px;"><span style="font-family: monospace;"> <span style="color: navy;">static</span><span style="color: black;"> </span><span style="color: navy;">string</span><span style="color: black;"> </span><span style="color: maroon;">SerializeObject</span><span style="color: black;">(</span><span style="color: navy;">object</span><span style="color: black;"> </span><span style="color: maroon;">o</span><span style="color: black;">)<br> {<br> </span><span style="color: maroon;">StringBuilder</span><span style="color: black;"> </span><span style="color: maroon;">sb</span><span style="color: black;"> = </span><span style="color: navy;">new</span><span style="color: black;"> </span><span style="color: maroon;">StringBuilder</span><span style="color: black;">();<br> </span><span style="color: maroon;">StringWriter</span><span style="color: black;"> </span><span style="color: maroon;">sw</span><span style="color: black;"> = </span><span style="color: navy;">new</span><span style="color: black;"> </span><span style="color: maroon;">StringWriter</span><span style="color: black;">(</span><span style="color: maroon;">sb</span><span style="color: black;">);<br> </span><span style="color: maroon;">XmlTextWriter</span><span style="color: black;"> </span><span style="color: maroon;">xtw</span><span style="color: black;"> = </span><span style="color: navy;">new</span><span style="color: black;"> </span><span style="color: maroon;">XmlTextWriter</span><span style="color: black;">(</span><span style="color: maroon;">sw</span><span style="color: black;">);<br> </span><span style="color: maroon;">xtw</span><span style="color: black;">.</span><span style="color: maroon;">Formatting</span><span style="color: black;"> = </span><span style="color: maroon;">Formatting</span><span style="color: black;">.</span><span style="color: maroon;">Indented</span><span style="color: black;">;<br> </span><span style="color: maroon;">xtw</span><span style="color: black;">.</span><span style="color: maroon;">WriteRaw</span><span style="color: black;">(</span><span style="color: navy;">null</span><span style="color: black;">);<br> <br> </span><span style="color: maroon;">XmlSerializerNamespaces</span><span style="color: black;"> </span><span style="color: maroon;">xsn</span><span style="color: black;"> = </span><span style="color: navy;">new</span><span style="color: black;"> </span><span style="color: maroon;">XmlSerializerNamespaces</span><span style="color: black;">();<br> </span><span style="color: maroon;">xsn</span><span style="color: black;">.</span><span style="color: maroon;">Add</span><span style="color: black;">("", "");<br> <br> </span><span style="color: maroon;">XmlSerializer</span><span style="color: black;"> </span><span style="color: maroon;">xs</span><span style="color: black;"> = </span><span style="color: navy;">new</span><span style="color: black;"> </span><span style="color: maroon;">XmlSerializer</span><span style="color: black;">(</span><span style="color: maroon;">o</span><span style="color: black;">.</span><span style="color: maroon;">GetType</span><span style="color: black;">());<br> </span><span style="color: maroon;">xs</span><span style="color: black;">.</span><span style="color: maroon;">Serialize</span><span style="color: black;">(</span><span style="color: maroon;">xtw</span><span style="color: black;">, </span><span style="color: maroon;">o</span><span style="color: black;">, </span><span style="color: maroon;">xsn</span><span style="color: black;">);<br> </span><span style="color: navy;">string</span><span style="color: black;"> </span><span style="color: maroon;">s</span><span style="color: black;"> = </span><span style="color: maroon;">sb</span><span style="color: black;">.</span><span style="color: maroon;">ToString</span><span style="color: black;">();<br> <br> </span><span style="color: green;">// &lt;Foo&gt; becomes &lt;Foo type="MyClass.Foo"&gt;<br> </span><span style="color: black;"></span><span style="color: maroon;">s</span><span style="color: black;"> = </span><span style="color: maroon;">Regex</span><span style="color: black;">.</span><span style="color: maroon;">Replace</span><span style="color: black;">(</span><span style="color: maroon;">s</span><span style="color: black;">, "(&lt;" + </span><span style="color: maroon;">o</span><span style="color: black;">.</span><span style="color: maroon;">GetType</span><span style="color: black;">().</span><span style="color: maroon;">Name</span><span style="color: black;"> + ")(&gt;)", "$1 type="" + </span><span style="color: maroon;">o</span><span style="color: black;">.</span><span style="color: maroon;">GetType</span><span style="color: black;">().</span><span style="color: maroon;">FullName</span><span style="color: black;"> + ""$2");<br> </span><span style="color: navy;">return</span><span style="color: black;"> </span><span style="color: maroon;">s</span><span style="color: black;">;<br> }</span> </span></p>
<p>The output is your class, serialized as a nice human-readable string.</p>
<p style="margin-left: 20px;"><span style="font-family: monospace;"> <span style="color: blue;">&lt;</span><span style="color: maroon;">MyStuff</span><span style="color: blue;"> </span><span style="color: red;">type</span><span style="color: blue;">=</span><span style="color: black;">"</span><span style="color: blue;">SomeNamespace.MyStuff</span><span style="color: black;">"</span><span style="color: blue;">&gt;<br> &lt;</span><span style="color: maroon;">i</span><span style="color: blue;">&gt;</span><span style="color: black;">1234</span><span style="color: blue;">&lt;/</span><span style="color: maroon;">i</span><span style="color: blue;">&gt;<br> &lt;</span><span style="color: maroon;">s</span><span style="color: blue;">&gt;</span><span style="color: black;">A bunch of information</span><span style="color: blue;">&lt;/</span><span style="color: maroon;">s</span><span style="color: blue;">&gt;<br> &lt;/</span><span style="color: maroon;">MyStuff</span><span style="color: blue;">&gt;</span> </span></p>
<p>It's just so darn.. straightforward. <a href="http://www.codinghorror.com/blog/archives/000634.html">As if I needed another reason to love strings</a>. Anyway, take that string and paste it into your web.config file.</p>
<p>To read it in, you'll need a custom config section. Paste this into your config file to define one:</p>
<p style="margin-left: 20px;"><span style="font-family: monospace;"> <span style="color: blue;">&lt;</span><span style="color: maroon;">configSections</span><span style="color: blue;">&gt;<br> &lt;</span><span style="color: maroon;">section</span><span style="color: blue;"> </span><span style="color: red;">name</span><span style="color: blue;">=</span><span style="color: black;">"</span><span style="color: blue;">MyStuff</span><span style="color: black;">"</span><span style="color: blue;"> </span><span style="color: red;">type</span><span style="color: blue;">=</span><span style="color: black;">"</span><span style="color: blue;">XmlSerializerSectionHandler, CSSerializerSection</span><span style="color: black;">"</span><span style="color: blue;"> /&gt;<br> &lt;/</span><span style="color: maroon;">configSections</span><span style="color: blue;">&gt;</span> </span></p>
<p>The actual XmlSerializerSectionHandler is a bit too much code to paste into a blog post, but it's still relatively simple:</p>
<ol>
<li>Extract the type from the XML Type attribute </li>
<li>Make sure the type is valid </li>
<li>Deserialize the XML into a new object of that type </li>
</ol>
<p>The XmlSerializerSectionHandler is too verbose to reprint here mainly because I added a bunch of error trapping. If something goes wrong, you get a nice explanatory exception instead of a cryptic error. It's good stuff.</p>
<ul>
<li>
<a href="http://www.codinghorror.com/files/csserializersection.zip">Download the Visual Studio 2005 CSSerializerSection solution</a> (5k) </li>
<li>
<a href="http://www.codinghorror.com/files/vbserializersection.zip">Download the Visual Studio 2005 VBSerializerSection Solution</a> (10k) </li>
</ul>
<p>There's almost no difference at all between the two languages, except that VB for some reason requires an additional namespace; instead of "SomeNamespace.MyStuff", it's "VBSerializerSection.SomeNamespace.MyStuff".</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-last-configuration-section-handler-revisited/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Sometimes It's a Hardware Problem ]]></title>
<link>https://blog.codinghorror.com/sometimes-its-a-hardware-problem/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One of our best servers at work was inherited from a previous engagement for x64 testing: it's a dual Opteron 250 with 8 gigabytes of RAM. Even after a year of service, those are still decent specs. And it has a nice upgrade path, too: the <a href="http://www.gamepc.com/labs/view_content.asp?id=thunderk8w&amp;page=1">Tyan Thunder K8W</a> motherboard it's based on supports up to 16 gigabytes of memory, and <a href="http://www.tyan.com/support/html/cpu_athlon_duron_opteron.html">the latest dual core Opterons</a>.
</p>
<p>
Anyway, we have it set up for <a href="http://www.microsoft.com/windowsserversystem/virtualserver/default.mspx">Virtual Server 2005 R2 duties</a>, running Windows Server 2003 x64. However, there was some anomalous behavior:
</p>
<p>
</p>
<ul>
<li>Virtual Server reported weird error messages: "Some nodes of this machine do not have local memory. This can cause virtual machines to run with degraded performance".
</li>
<li>The machine spontaneously rebooted during the day and overnight.
</li>
</ul>
<p>
We've used this server for over a year and never experienced anything problematic with it. The weirdness only started with the server's new role.
</p>
<p>
The first thing we did was <b>update the BIOS to the latest version, and make sure we had all the latest x64 chipset and platform drivers installed.</b> This is always a good first troubleshooting step-- it's the hardware equivalent of taking two asprins and calling in the morning. This resolved the "some nodes of this machine do not have local memory" error. However, the machine still spontaneously rebooted overnight, even with the latest BIOS and drivers.
</p>
<p>
At this point I began to suspect a hardware problem. Troubleshooting hardware stability can be difficult. But <b>you can troubleshoot hardware stability quite effectively with the right software: <a href="http://www.memtest.org/">Memtest86+</a> and <a href="http://www.mersenne.org/freesoft.htm">Prime95</a></b>.
</p>
<p>
</p>
<ol>
<li>
<b>Testing memory stability with <a href="http://www.memtest.org/">Memtest86+</a></b>
<p>
We started with Memtest86+ because we already suspected the memory. Memtest86+ isn't the only memory testing diagnostic out there, but it's probably the most well-known. Microsoft also offers their <a href="http://oca.microsoft.com/en/windiag.asp">Windows Memory Diagnostic</a> utility, which works exactly the same way. Memtest86+ is <a href="http://www.memtest.org/#downiso">available in several forms from the Memtest86+ web site</a>. We chose the ISO image, which we burned to CD. Boot from the Memtest86 CD, and it'll kick off the test run.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It took about 30-45 minutes to test 4 gigabytes of memory. The progress bar at the top right gives you an indication of how long the test has to run; there are 8 total tests in the standard test run. Beware, because it'll start repeating at test #1 after the first pass!
</p>
<p>
</p>
</li>
<li>
<b>Testing CPU stability with <a href="http://www.mersenne.org/freesoft.htm">Prime95</a></b>
<p>
Prime95 is my single favorite PC stability testing tool. If your PC can't pass an overight Prime95 run, it absolutely, positively has a hardware problem.* Although Prime95 is primarily a CPU test, it can also be a pretty good memory test, too. After downloading it, go to the Options menu and select Torture Test.
</p>
<ol>
<li>If you want to test CPU stability exclusively, choose "Small FFTs".
</li>
<li>If you want to test for CPU stability and memory stability, choose "Blend".
</li>
</ol>
</li>
</ol>
<p>
If you have a Dual (or Quad) CPU machine, you must run multiple instances of Prime95 to load each CPU. The easiest way to do this is to copy the Prime95 folder and run multiple executables, each one from a unique folder. You may want to set CPU affinity on the executables with Task Manager, but the scheduler will take care of loading all the CPUs just fine by itself.
</p>
<p>
A bit of warning, though: when Prime95 says "lots of RAM tested", they <i>mean </i> it. We tried running two instances of "Blend" with only 4 gigabytes of memory installed on the server and we nearly crushed the pagefile; both instances allocated nearly 6 gigabytes!
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In my experience, Prime95 will error out almost immediately if your CPUs or memory are unstable. This is great for troubleshooting because you know quickly if there's a problem or not. If you can run Prime95 "small FFTs" for an hour, it's highly likely that the CPU isn't your problem. And if you can run the same test overnight, CPU problems can be definitively ruled out.
</p>
<p>
In the case of our wayward server, Memtest86+ showed us rare, intermittent memory problems. But Prime95 consistently failed almost immediately when running the "blend" test. When we switched Prime95 to "small FFTs", it ran two instances for an hour just fine. Clearly a memory issue! Using a combination of Memtest86+ and Prime95, we found that <b>our server was totally stable with 4 gigabytes of memory installed</b>; the minute we put in all 8 gigabytes, we couldn't pass one or both tests.
</p>
<p>
Since 8 gigabytes of memory is essential for a VM server, removing memory wasn't an option. On a hunch, I switched the memory speed from 200 MHz to 166 MHz in the BIOS. Now both Prime95 blend and Memtest86+ pass without incident.
</p>
<p>
Although software is notoriously unreliable, we can't always blame the software. <b>Sometimes you really do have a hardware problem</b>.
</p>
<p>
* CPUs are almost never defective; it's usually a heat or power supply related failure.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/sometimes-its-a-hardware-problem/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Magical Number Seven Plus or Minus Two ]]></title>
<link>https://blog.codinghorror.com/the-magical-number-seven-plus-or-minus-two/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The seminal 1956 George Miller paper <a href="http://psychclassics.yorku.ca/Miller/">The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information</a> is a true classic. In it, Miller observed that the results of a number of 1950's era experiments in short-term memory had something in common: <b>most people could only retain 5 to 9 items in their short-term memory</b>.
</p>
<p>
This study is commonly cited as the reason why Bell chose to make telephone numbers exactly 7 digits long. I can't find any formal citations to support this, but the timing is right: by 1957 or thereabouts, most telephone numbers in the US were standardized to the 7-digit format.
</p>
<p>
<font size="6">5551212</font>
</p>
<p>
Are human beings only capable of holding between 5 and 9 pieces of information in their heads at once? <b>That's only 2.5 bits of information.</b> If you read the text of the paper, you'll quickly find that even Miller himself found <a href="http://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two">the magic number seven</a> a bit serendipitous:
</p>
<p>
</p>
<blockquote>
And finally, what about the magical number seven? What about the seven wonders of the world, the seven seas, the seven deadly sins, the seven daughters of Atlas in the Pleiades, the seven ages of man, the seven levels of hell, the seven primary colors, the seven notes of the musical scale, and the seven days of the week? What about the seven-point rating scale, the seven categories for absolute judgment, the seven objects in the span of attention, and the seven digits in the span of immediate memory? For the present I propose to withhold judgment. Perhaps there is something deep and profound behind all these sevens, something just calling out for us to discover it. But I suspect that it is only a pernicious, Pythagorean coincidence.
</blockquote>
<p>
The 7 digit figure might be a little optimistic. <a href="http://www.bbsonline.org/Preprints/OldArchive/bbs.cowan.html">Other research has shown the number to be closer to 4</a>. Even telephone numbers aren't commonly expressed as seven digits. They're expressed as a group of three digits and four digits, with a dash to separate them:
</p>
<p>
<font size="6">555-1212</font>
</p>
<p>
And the area code is separated, too:
</p>
<p>
<font size="6">434-555-1212</font>
</p>
<p>
So which is it? Can people remember 7 digits at once? Or are they really remembering chunks of 3 digits, 3 digits, and 4 digits?
</p>
<p>
I think <b>magical numbers are a red herring</b>. There are some interesting coincidences, however, such as Edward Hall's conclusion that <a href="http://37signals.com/svn/archives2/edward_hall_the_perfect_group_size_812.php">the perfect group size is 8-12 people</a>:
</p>
<p>
</p>
<blockquote>
Fortunately, something is known both empirically and scientifically about the influence exerted by size on groups and the effect of size on how the groups perform. Research with business groups, athletic teams, and even armies around the world has revealed there is an ideal size for a working group. This ideal size is between eight and twelve individuals. This is natural, because man evolved as a primate while living in small groupsEight to 12 persons can know each other well enough to maximize their talents. In groups beyond this size, the possible combinations of communication between individuals get too complex to handle; people are lumped into categories and begin the process of ceasing to exist as individuals. Tasks than can't be handled by a group of eight to 12 are probably too complex and should be broken down further. Participation and commitment fall off in larger groups  --  mobility suffers; leadership doesn't develop naturally but is manipulative and political.
</blockquote>
<p>
The value of this magical number lies in knowing the point of diminishing returns. Every group should strive to be as small as possible. Once the group size exceeds 8-12 people, break into another group.
</p>
<p>
Similar advice applies to software design. <b>Ideally users shouldn't have to remember anything</b>. Once they have to remember <i>more</i> than 7 items, it's definitely time to redesign.
</p>
<p>
</p>
<ul>
<li>In a well-designed system, you should never need to fall back on your faulty, unreliable short-term memory.
</li>
<li>The fewer bits of information users have to remember, the better.
</li>
<li>Use chunking and grouping aggressively to reduce the amount of information to remember.
</li>
</ul>
<p>
Magical numbers are fun. But the ideal group size is always one, and the ideal number of things I should need to keep in my short-term memory is zero.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-magical-number-seven-plus-or-minus-two/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Coding Horror Stickers ]]></title>
<link>https://blog.codinghorror.com/coding-horror-stickers/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>As I alluded to in the <a href="http://www.codinghorror.com/blog/archives/000636.html">T-Shirt post</a>, Coding Horror stickers have arrived:</p>
<img alt="image placeholder" >
<p>These are custom, two color die-cut vinyl stickers based on the high resolution vector art so graciously provided by our kind benefactor, <a href="http://www.stevemcconnell.com/">Steve McConnell</a>. To give you an idea of scale, the coin in the picture is a nickel. The dimensions of the sticker are 3.55" h  3" w.</p>
<p><s>As a thank you to my readers, <b>anyone who emails me from now until midnight PDT Wednesday, August 16th gets a free Coding Horror sticker.</b> Please make the title of the email "free sticker", and don't forget to provide your full postal address. You must live in the US or Canada.*</s></p>
<p><font color="red">Update: we've reached 350 stickers; the free sticker offer is now closed.</font> I totally <a href="http://www.larkware.com/dg6/TheDailyGrind948.aspx">blame Mike Gunderloy</a>. I'll try to get all the stickers out by Monday. I think you'll really like them!</p>
<table cellpadding="8" cellspacing="8" width="100%">
<tr>
<td align="center">
<b>United States</b><br>$4 for 4 stickers
</td>
<td align="center">
<b>International</b><br>$4 for 3 stickers
</td>
</tr>
<tr>
<td align="center">
<form action="https://www.paypal.com/cgi-bin/webscr" method="post">
<input name="cmd" type="hidden" value="_xclick">
<input name="business" type="hidden" value="jatwood@codinghorror.com">
<input name="undefined_quantity" type="hidden" value="1">
<input name="item_name" type="hidden" value="4 Coding Horror Stickers - shipped to US">
<input name="amount" type="hidden" value="4.00">
<input name="shipping" type="hidden" value="0.00">
<input name="no_shipping" type="hidden" value="2">
<input name="return" type="hidden" value="http://www.codinghorror.com/blog/">
<input name="cancel_return" type="hidden" value="http://www.codinghorror.com/blog/">
<input name="no_note" type="hidden" value="1">
<input name="currency_code" type="hidden" value="USD">
<input name="tax" type="hidden" value="0.00">
<input name="lc" type="hidden" value="US">
<input name="bn" type="hidden" value="PP-BuyNowBF">
<input alt="PayPal - The safer, easier way to pay online!" border="0" name="submit" src="https://www.paypal.com/en_US/i/btn/btn_buynowCC_LG.gif" type="image">
</form>
</td>
<td align="center">
<form action="https://www.paypal.com/cgi-bin/webscr" method="post">
<input name="cmd" type="hidden" value="_xclick">
<input name="business" type="hidden" value="jatwood@codinghorror.com">
<input name="undefined_quantity" type="hidden" value="1">
<input name="item_name" type="hidden" value="3 Coding Horror Stickers - shipped Internationally">
<input name="amount" type="hidden" value="4.00">
<input name="shipping" type="hidden" value="0.00">
<input name="no_shipping" type="hidden" value="2">
<input name="return" type="hidden" value="http://www.codinghorror.com/blog/">
<input name="cancel_return" type="hidden" value="http://www.codinghorror.com/blog/">
<input name="no_note" type="hidden" value="1">
<input name="currency_code" type="hidden" value="USD">
<input name="tax" type="hidden" value="0.00">
<input name="lc" type="hidden" value="US">
<input name="bn" type="hidden" value="PP-BuyNowBF">
<input alt="PayPal - The safer, easier way to pay online!" border="0" name="submit" src="https://www.paypal.com/en_US/i/btn/btn_buynowCC_LG.gif" type="image">
</form>
</td>
</tr>
</table>
<p>* Sorry, international readers. Dealing with postage rate scales makes my tiny American brain hurt.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/coding-horror-stickers/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Source Control: Anything But SourceSafe ]]></title>
<link>https://blog.codinghorror.com/source-control-anything-but-sourcesafe/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Everyone agrees that <a href="http://www.codinghorror.com/blog/archives/000643.html">source control is fundamental to the practice of modern software development</a>. However, there are dozens of source control options to choose from. VSoft, the makers of <a href="http://www.vsoft-tech.com.au/finalbuilder.aspx">FinalBuilder</a>, just published the results of their annual customer survey. One of the questions it asked was <a href="http://www.vsoft-tech.com.au/Default.aspx?tabid=77&amp;EntryID=190">which version control systems do you currently use, or plan to use, in the next 12 months?</a>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The top 9 responses are reprinted here. I'm disheartened to see that <a href="http://msdn.microsoft.com/vstudio/products/vssafe/default.aspx">Visual SourceSafe</a> is still at the top of the list. <b>If you are serious about the practice of software development, you should not be using SourceSafe.</b> This isn't a new idea; plenty of other developers have been warning us away from SourceSafe for years:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.highprogrammer.com/alan/windev/sourcesafe.html">Visual SourceSafe: Microsoft's Source Destruction System</a>
</li>
<li>
<a href="http://www.developsense.com/testing/VSSDefects.html">Visual SourceSafe Version Control: Unsafe at any Speed?</a>
</li>
</ul>
<p>
There's simply no reason to use SourceSafe when there are so many inexpensive (and even free) alternatives that are vastly superior. The more customers I visit, and the more developers I talk to, the more I believe that <b>SourceSafe poisons the minds of software developers.</b> Note that I include our own shop, Vertigo Software, in this list.
</p>
<p>
</p>
<ul>
<li>SourceSafe gives you the <i>illusion</i> of safety and control, while exposing your project to risk.
</li>
<li>SourceSafe teaches developers bad habits: avoid branching, exclusive locks, easy permanent deletions.
</li>
</ul>
<p>
SourceSafe was a perfectly adequate source control system in the late 90's. Unfortunately, SourceSafe was never updated architecturally to reflect modern source control practices. Even the latest version, SourceSafe 2005, absolutely <i>reeks</i> of 1999. And, to be fair, <b>some of the same criticisms apply to CVS</b>. CVS is no longer a modern source control system, either; it doesn't even support the concept of atomic checkins.
</p>
<p>
<b>One of my biggest hurdles has been unlearning all the bad things SourceSafe taught me about source control.</b> Source control is the absolute bedrock of software engineering. It's as fundamental as it gets. If my knowledge in this area isn't deep, wide, and fundamentally sound, can I really call myself a software engineer?
</p>
<p>
So, how do we learn modern source control?
</p>
<ol>
<li>Start with <a href="http://www.ericsink.com/scm/source_control.html">Eric Sink's Source Control HOWTO</a>. Eric is self-admittedly biased because his company created <a href="http://www.sourcegear.com/vault/">SourceGear Vault</a>, but he's up front about this. He has truly lived and breathed the topic of source control, and it shines through in his excellent writing.
</li>
<li>The online Subversion manual is well worth your time. The first few introductory chapters, starting with <a href="http://svnbook.red-bean.com/nightly/en/svn.basic.html">Chapter 2: Basic Concepts</a>, are wonderful primers.
</li>
<li>Chris Birmele's <a href="http://blogs.msdn.com/chrisbirmele/archive/2006/05/31/611179.aspx">paper on Branching and Merging</a> is the best introduction I've found to this essential source control task. There are dozens of ways to branch, and no one correct way to do it. Get familar with your options so you know what the tradeoffs are with each one.
</li>
</ol>
<p>
Visual SourceSafe was most Microsoft developers' first introduction to any kind of source control at all. That's great. But holding on to SourceSafe's archaic source control conventions is doing more damage than good these days. Make the switch to <a href="http://msdn.microsoft.com/vstudio/teamsystem/default.aspx">Team System</a>, <a href="http://subversion.tigris.org/">Subversion</a>, or any other modern source control system of your choice.
</p>
<p>
But whatever you do, <b>please don't use Visual SourceSafe.</b> Think of the children.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/source-control-anything-but-sourcesafe/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Power of "View Source" ]]></title>
<link>https://blog.codinghorror.com/the-power-of-view-source/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The 1996 JavaWorld article
<a href="http://www.javaworld.com/javaworld/jw-08-1996/jw-08-js-analysis.html">Is JavaScript here to stay?</a> is almost amusing in retrospect. John Lam recently <a href="http://www.iunknown.com/articles/2006/08/14/some-more-photos-from-lang-net">observed </a> that
</p>
<blockquote>
JavaScript is the world's most ubiquitous computing runtime.
</blockquote>
<p>
I think the answer is an emphatic <i>yes</i>.
</p>
<p>
JavaScript is currently undergoing a renaissance through AJAX. Sure, the AJAX-ified clones of <a href="http://www.writely.com">Word</a> and <a href="http://numsum.com/">Excel</a> are still pretty lame, but they're the first baby steps on <b>the long road to rewriting every client application in the world in JavaScript.</b> The line between client executable and web page gets blurrier every day.
</p>
<p>
The meteoric rise in popularity of Ruby has also renewed interest in dynamic languages. And <a href="http://schf.uc.org/articles/2006/08/13/javascript-the-underappreciated-dynamic-language">JavaScript may be the most underappreciated dynamic language of all.</a> Unfortunately, it's difficult to separate JavaScript from all its browser environment baggage and consider it <a href="http://www.crockford.com/javascript/survey.html">purely as a language</a>.
</p>
<p>
But these are both relatively recent developments. They're important milestones, but they're not the full story of JavaScript's success. Not by a long shot. I attribute most of JavaScript's enormous success to one long-standing menu item on every browser:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<b>The view source menu is the ultimate form of open source.</b> It's impossible to obfuscate or hide JavaScript running in a browser. The code that powers any AJAX application is right there in plain sight, for everyone to see, copy, and use. A complete set of JavaScript source code for the latest AJAX apps is never more than one HTTP download away. They're literally <i>giving away</i> the source code for their application to <i>every user</i>.
</p>
<p>
Some people might see that as a huge business risk. I say if your business model is that dependent on clever, obfuscated source code tricks, it isn't much of a business model.
</p>
<p>
I've read several <a href="http://www.codinghorror.com/blog/archives/000291.html">complaints that .NET code is too easy to decompile</a>. Nonsense. It should be even <i>easier</i> to decompile. The real stroke of genius in JavaScript wasn't closures, or XmlHttpRequest; it was <b>forcing people to share their source code with the community.</b> How do you think anyone found out about XmlHttpRequest in the first place? Through reading the documentation?
</p>
<p>
The entire JavaScript development community is predicated on instant, ubiquitous access to source code. This leads to what I call <b>"Code Darwinism"</b>: good techniques are seen immediately and reproduce promiscuously. Bad techniques never reproduce and die out.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
That's why I'm not afraid to bust out a copy of <a href="http://www.aisto.com/roeder/dotnet/">Reflector</a> and perform a little ad-hoc "View Source". It's common practice to decompile binary .NET assemblies, for a whole host of entirely valid reasons:
</p>
<ul>
<li>You've encountered a possible bug in the code
</li>
<li>You don't understand the code's behavior
</li>
<li>You need to do something similar in your own code
</li>
</ul>
<p>
Having the source code gives you the ability to fix your own problems-- or even someone else's problems. If you can see the source code, the binary is alive-- it can <i>evolve</i>.
</p>
<p>
And you can still license your software and make money, even if you're handing out the source code at the same time. <a href="http://www.devx.com/opinion/Article/20513">According to DesaWare</a>, one of the most compelling software sales pitches is the phrase "source code included":
</p>
<p>
</p>
<blockquote>
Providing source code is the only answer -- it's a way to say to the customer that if worst comes to worst, they can be their own alternate source. Even Microsoft has demonstrated this by providing Windows Source to certain customers, like large governments, who have the leverage to demand it. And, yes, escrow services should be sufficient for this purpose, but for some reason most customers don't like that approach. Perhaps it's lack of confidence in the long-term viability of the escrow services themselves? Or perhaps lack of faith in their own institutional memory to recall that such escrow arrangements had been made.
<p>
There are some nice side benefits of having source code available: the ability to learn from someone else's code, and the possibility of customizing components to suit specific needs, but those are smaller issues. Security is always a concern, but it is only applicable to software that has the potential to elevate the privilege of a user -- something that applies to a relatively small number of software components.
</p>
<p>
So what about the great closed source vs. open source debate? I'm never one to shy away from controversy, but that's for another time and place. What we did by releasing our software was not open source by any stretch of the imagination. Our source code is licensed to individual developers for their own use -- not for distribution. Does a true open source model make sense for the component world? I don't know. What I do know is that source code availability provides a level of peace of mind for some developers that probably cannot be matched any other way.
</p>
</blockquote>
<p>
We should do away with the pretense of hiding code. Let's not only acknowledge that decompiling .NET code is trivial, <b>let's <i>embrace</i> the power of "view source" by shipping source code along with our binaries.</b>
</p>
<p>
<!--kg-card-end: markdown-->
            </p> ]]></content>
<pubDate>2006-08-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-power-of-view-source/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Video Card Power Consumption ]]></title>
<link>https://blog.codinghorror.com/video-card-power-consumption/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
With the release of Intel's Core Duo and Core Duo 2 chips, it's finally happened-- <b>mainstream video card GPUs are about to overtake CPUs as the largest consumers of power inside your PC.</b>
</p>
<p>
Witness this chart, derived from <a href="http://www.xbitlabs.com/articles/video/display/power-noise.html">XBit labs' latest roundup</a>, of <b>video card power consumption in watts</b>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Now compare it to this chart of <b>maximum CPU power consumption in watts</b>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Notice a trend here?
</p>
<p>
The idea that your video card consumes more power than your CPU is old hat to PC gaming enthusiasts, who have always lived at the top of that video card power consumption chart. But it's about to trickle down to the mainstream; <b>you'll need a moderately fast gaming video card to get the best-looking 3D effects in Windows Vista.</b>
</p>
<p>
Perhaps the trick is to select an video card that offers <b>the best bang for the watt</b>. Here's a graph, derived from the  <a href="http://www.digit-life.com/articles2/digest3d/index.html">June 2006 Digit-Life video card roundup</a>, which divides the 3DMark2006 score* of the video card by its peak 3D power consumption.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
No surprise that the latest and greatest video cards end up on top; they probably use the newest manufacturing technology. The <b>GeForce 7600 GT</b> does astonishingly well here; it provides the 12th best 3DMark06 score of all the video cards listed, while only consuming a miserly 36 watts of power under full load. The <b>GeForce 7900 GT</b> is even better, consuming only 33% more power to produce a 42% higher 3DMark06 score.
</p>
<p>
I like the 7600 GT quite a lot, and I'd pick it for a well-balanced PC any day. It's fast, inexpensive, and efficient. It's even available in silent passively cooled versions. Here's <a href="http://www.newegg.com/Product/Product.asp?Item=N82E16814125025">one such model from Gigabyte</a>:
</p>
<p>
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16814125025"><img alt="image placeholder" >
</p>
<p>
<b>Video cards tend to have small, whiny fans that can spin up to deafening levels under load.</b> That's why passive cooling solutions are a nice option. But you need to be extra careful when choosing a passive solution. My work PC has a <a href="http://www.newegg.com/Product/Product.asp?Item=N82E16814150114">passively cooled GeForce 6600</a>, which only dissipates 28 watts under load. But it still overheated and caused faults when running 3D screen savers. I had to retrofit a slow-moving fan on it to keep it stable. Make sure you have good case airflow if you're going the passive route!
</p>
<p>
* <a href="http://www.ixbt.com/video/itogi-video/0706/itogi-video-m61-wxp-aaa-1280-pcie.html">3dMark2006 score for shader 2.0, at 1280x1024, with 4xAA and 16xAF</a>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/video-card-power-consumption/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ DirectX Version Number Abuse ]]></title>
<link>https://blog.codinghorror.com/directx-version-number-abuse/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Has anyone noticed that Microsoft defines "version" a little loosely when it comes to DirectX 9.0c? Here's a screenshot of the <a href="http://www.filehippo.com/download_directx/">DirectX 9.0c download page on FileHippo</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
DirectX 9.0c was originally released in August 2004, according to <a href="http://en.wikipedia.org/wiki/DirectX">the DirectX Wikipedia entry</a>. But Microsoft has surreptitiously been updating DirectX 9.0c since August 2005 <i>without incrementing the version number.</i>
</p>
<p>
</p>
<blockquote>
It is not known why Microsoft has not used new version numbers for the updates to DX9.0c  --  including the December 2005 update versioning could now be at DX9.0j, although this is nowhere reflected in the internal code.
</blockquote>
<p>
So do you want version 9.0c, 9.0c, 9.0c, or perhaps.. 9.0c?
</p>
<p>
The versions are all fully backwards compatible, of course, but <b>why is Microsoft abusing version numbers this way?</b>
</p>
<p>
It's impossible to tell what version of DirectX 9.0 you're actually running. I've installed several games over the past year which inexplicably demanded to re-install DirectX 9.0c; now I know why.
</p>
<p>
At least Vista stops the madness by <a href="http://www.theinquirer.net/default.aspx?article=26220">finally changing the version number to DirectX 9.0L</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/directx-version-number-abuse/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Total Users Does Not Equal Total Usage ]]></title>
<link>https://blog.codinghorror.com/total-users-does-not-equal-total-usage/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As of August 9th, 2006, <a href="http://internet.seekingalpha.com/article/15237">MySpace has 100 million members</a>. For reference, the population of California is approximately 36 million, and the population of the United States is approximately 300 million.
</p>
<p>
<img alt="image placeholder" >
<img alt="image placeholder" >
<img alt="image placeholder" >
</p>
<p>
I have a hard time believing that <b>1 in 3 Americans could conceivably be <a href="http://en.wikipedia.org/wiki/MySpace">MySpace</a> users.</b>
</p>
<p>
I'm not the only person to be skeptical of these inflated "member" numbers. Robert Scoble recently <a href="http://scobleizer.wordpress.com/2006/08/20/is-microsoft-really-the-largest-blog-vendor/">took issue with the claim that Windows Live Spaces is the largest blogging service on the planet</a>. He did <a href="https://scobleizer.wordpress.com/2006/08/20/wheres-the-blog-in-windows-live-spaces">a little ad-hoc investigation of Windows Live Spaces</a>. Most of the member pages he visited were virtual ghost towns.
</p>
<p>
<a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=2b53b317-ef09-449e-b6d9-1d184177c4df">Dare Obasanjo</a> addresses this criticism head-on:
</p>
<p>
</p>
<blockquote>
The number of spaces on Windows Live Spaces isn't a particularly interesting metric to me nor is it to anyone I know who works on the product. <b>We are more interested in the number of people who actually use our service</b> and get value added to their lives by being able to share, discuss and communicate with their friends, families and total strangers.
</blockquote>
<p>
Kudos to Dare for cutting to the heart of this debate. Who cares how many users signed up for your free service? <b>How many users actually <i>use</i> it?</b>
</p>
<p>
To illustrate the absurdity of user counts as a metric, Dare cited the <a href="http://www.livejournal.com/stats.bml">LiveJournal stats page</a>. According to that page, LiveJournal has approximately 11 million accounts. However:
</p>
<p>
</p>
<ul>
<li>
<b>1 in 3</b> accounts are <i>never</i> used.
</li>
<li>
<b>1 in 5</b> accounts are "active in some way".
</li>
<li>
<b>1 in 10</b> accounts updated in the last 30 days.
</li>
</ul>
<p>
If the LiveJournal statistics are representative of other social networking websites, then we should immediately divide the total number of "users", "spaces", or "accounts", by five. Maybe even by ten! That's a realistic estimate of how many people are actually using the service.
</p>
<p>
Total number of LiveJournal accounts:
</p>
<p>
<font size="5">11 million</font>
</p>
<p>
Total number of <i>active</i> LiveJournal accounts:
</p>
<p>
<font size="5">1.5 million</font>
</p>
<p>
And that's still an optimistic estimate, because it doesn't factor in multiple accounts established by the same person.
</p>
<p>
Now if only MySpace and Windows Live Spaces would be as forthcoming about the actual <i>usage</i> of their service, instead of bandying around meaningless user counts.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/total-users-does-not-equal-total-usage/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Building a Quiet PC ]]></title>
<link>https://blog.codinghorror.com/building-a-quiet-pc/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
When the first version of <a href="http://www.microsoft.com/windowsxp/mediacenter/default.mspx">Windows Media Center</a> was released in summer 2003, I decided it was time to build my first home theater PC. After I placed it in the living room, I realized I had made a terrible mistake: I had to turn the volume up to 11 just to drown out the noise of the HTPC! I couldn't believe how loud it was! For the next few months, I immersed myself in the world of <a href="http://www.silentpcreview.com">silent PC enthusiasts</a>. I must have reconfigured that system a dozen times to reduce the noise.
</p>
<p>
Now every PC I build is optimized for performance <i>and</i> low noise from the very beginning.
</p>
<p>
Anyone can build a high-powered rig that sounds like a jet taking off. Building a high-powered rig that's so quiet your wife can't tell when it's turned on or off-- now <i>that's</i> an accomplishment! It's a bona-fide engineering challenge.
</p>
<p>
In the process, I've learned quite a few things about building quiet PCs. I'd like to share them with you, so you can avoid making the mistakes I did.
</p>
<p>
</p>
<ol>
<li>
<b>The easiest way to build a quiet PC is to start with components that run cool.</b> It's as fundamental as the first law of thermodynamics: heat has to be exhausted from the system; more heat equals more noise. If you truly want a quiet system, start with cool running components. The three components that generate the most heat in your system are..
<p>
</p>
<ol>
<li>CPU
</li>
<li>video card
</li>
<li>power supply
</li>
</ol>
</li>
</ol>
<p>
.. in that order. Select these items very carefully, because they will account for 90 percent of the heat and noise generated inside your computer. Research how many watts of power each will draw when idle; when normally loaded; and when fully loaded.
</p>
<p>
And don't underestimate <a href="http://www.silentpcreview.com/article28-page6.html">the importance of the power supply</a>; it's the heart of your system, and it can be the source of serious stability, noise, and heat woes if you pick a clunker. The very <i>best</i> power supplies are only about 85% efficient, which means they're still dumping 15% of the total power draw back into your case as waste heat.
</p>
<p>
</p>
<li>
<b>Minimize the number of fans in your system</b>. Every fan is a source of noise. Remove fans unless they're absolutely necessary. If a fan is necessary, use the largest possible model. All other things being equal, large fans are quieter than small fans. That's why 120mm fans are now commonplace in PC cases.
<p>
One of the most useful noise diagnostics is to stop every fan in the system, one by one, using your Mark I finger. Repeat this a few times, listening closely to hear the difference with each fan stopped. Then try to eliminate or slow down the noisiest fan. Don't forget to test your video cards and motherboard fans while you're at it; these tend to be particularly noisy due to their small size. And remember, kids, always stop fans by touching them in the center, not in those whirling blades!
</p>
<p>
</p>
</li>
<li>
<b>Control the speed of your fans</b>. Fans running at full speed are almost never quiet. Some modern motherboards allow you to control the speed of the fans connected via the 3-pin motherboard headers, either in the BIOS or in software. Set an absolute speed, or even better, use dynamic fan speeds based on a temperature sensor; spin faster when it gets hot, and slow down when things cool off. There are also devices like the <a href="http://www.endpcnoise.com/cgi-bin/e/std/sku=fanmate2">Zalman Fanmate</a> that allow you to retrofit a fan speed control on any 3-pin fan.
<p>
<img alt="image placeholder" >
</p>
<p>
The <a href="http://www.sharkacomputers.com/56oh3pinres.html">Zalman 56 Ohm resistor</a> is a less expensive option if you don't need precise speed control.
</p>
<p>
</p>
</li>
<li>
<b>Consider aftermarket cooling solutions.</b> Aftermarket coolers for CPUs and video cards are typically <i>far</i> more efficient than the stock models manufacturers include. You might be able to get away with inefficient stock coolers for basic systems, but if you want high-end performance, a super-efficient cooler can literally be the difference between a quiet system and a loud system.
<p>
</p>
<ul>
<li>The current top dogs for CPU cooling efficiency are tall heatpipe stack designs such as the <a href="http://www.silentpcreview.com/article646-page1.html">Thermalright Ultra-120</a> and the <a href="http://www.silentpcreview.com/article251-page1.html">Scythe Ninja</a>.
</li>
<li>The current top dogs for VGA cooling efficiency are copper heatpipe designs, such as the Arctic Cooling <a href="http://www.techgage.com/article/arctic_cooling_accelero_x1">Accelero X1</a> and the Zalman <a href="http://www.silentpcreview.com/article612-page5.html">VF900-CU</a>.
</li>
<li>Consider replacing any small fan and heatsink combinations -- such as <a href="http://forums.tweakguides.com/showthread.php?t=1408&amp;page=2">the ones commonly found on motherboards</a> -- with larger, passive coolers. Two great options are the <a href="http://www.endpcnoise.com/cgi-bin/e/std/sku=nb47j">Zalman NB47J</a> and the newer, flower style <a href="http://www.endpcnoise.com/cgi-bin/e/std/sku=nbf47.html">Zalman NBF47</a>.
</li>
</ul>
</li>
<p>
<img alt="image placeholder" >
<img alt="image placeholder" >
<img alt="image placeholder" >
</p>
<p>
Note that aftermarket coolers tend to be quite a bit larger than stock coolers; measure to make sure they'll fit in your system before buying.
</p>
<p>
</p>
<li>
<b>Dampen your hard drive</b>. Hard drive manufacturers have made huge strides in noise reduction in the last few years. You still need to be a bit careful in <a href="http://www.endpcnoise.com/cgi-bin/e/std/category=Quiet_Hard_Drives.html">selecting a drive</a>, but most new hard drives are relatively quiet. That's the good news. The bad news is that hard drives are still giant hunks of metal spinning at 7,200 or 10,000 RPM.
<p>
As such, the first order of business here is to dampen the drives -- make absolutely sure there is a soft material of some kind between the hard drive and your PC's case. Some people improvise <a href="http://www.polpo.org/gallery/suspension">bungee suspension slings</a>, some people use foam or <a href="http://scientificsonline.com/product.asp?pn=3037000&amp;bhcd2=1156401254">sorbothane</a>, some people <a href="http://www.silentpcreview.com/article245-page1.html">put them in dampening enclosures</a>. Whatever you do, always avoid metal-to-metal contact between a hard drive and the case.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The truly hardcore use 2.5" laptop hard drives, which are even quieter, but they also have significant performance and price penalties over standard 3.5" desktop drives.
</p>
<p>
</p>
</li>
<li>
<b>Use noise-reduction materials</b>. If you've ever worked in a recording studio where the walls are covered with noise-reduction materials, you've probably heard first-hand how effective they can be. However, noise reduction materials are <i>strictly</i> a second line of defense. They treat the symptom and not the source; ideally you want to quiet the thing that is making noise-- not hide it behind a layer of dampening material.
<p>
That said, noise reduction materials can help take the edge off the last remaining bit of noise in a system.  For PC builds, I like <a href="http://froogle.google.com/froogle?q=pax.mate">pax.mate</a> and <a href="http://search.ebay.com/search/search.dll?satitle=eggcrate+foam">generic eggcrate foam</a>. You can see pictures of both materials in action in <a href="http://www.silentpcreview.com/forums/viewtopic.php?p=123107">this SilentPCReview thread documenting a LAN party system I built in summer 2004</a>. But they should always be a final, finishing step.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I'm ashamed to admit that I have something of an eggcrate foam fetish. In addition to wedging it inside my systems wherever it'll fit, I regularly put cardboard-mounted panels of the eggcrate foam behind my PCs to reduce the reflected noise from the rear exhaust fans. If your PC is under a desk, fitting eggcrate foam along the undersides of the desk can be surprisingly effective, too.
</p>
<p>
</p>
</li>
<li>
<b>Passive cooling isn't worth it</b>. If you really get bitten by the silence bug, you'll invariably be drawn to that holy grail of silent computing: completely passive cooling. Passive cooling is totally silent by definition, but also it's the equivalent of scaling the Himalayas-- not something you undertake lightly and certainly not without a few years of experience under your belt.
<p>
Although there are exotic pre-built passive solutions like Zalman's <a href="http://www.silentpcreview.com/article161-page1.html">TNN-500A</a> and <a href="http://www.silentpcreview.com/article302-page1.html">TNN-300</a> cases, they're solidly in the "if you have to ask how much it costs, <a href="http://svcompucycle.stores.yahoo.net/zm-ttn500a.html">you can't afford it</a>" category.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Passive cooling setups are an order of magnitude more difficult to cool: they require a tricky balance of careful construction, natural convective airflow, and setup tweaking. You can achieve 90 percent of the results you'd get with completely passive cooling using a few nearly-silent, slow-moving fans-- at a fraction of the effort and risk!
</p>
</li>
<p>
I can't emphasize enough that <b>the best way to quiet your PC is to begin with the right parts.</b> If you're really serious about silence, ensure that you have..
</p>
<p>
</p>
<ul>
<li>CPUs and video cards that run cool
</li>
<li>a quiet, efficient power supply
</li>
<li>hard drives that run relatively quiet as shipped
</li>
</ul>
<p>
Always try to deal with the <i>source</i> of the noise first. Beyond that, following the few tips I outlined above will eventually get you to near-complete silence-- or at least to below-ambient noise level, which is pretty much the same thing.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-quiet-pc/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Coding Horror Sightings ]]></title>
<link>https://blog.codinghorror.com/coding-horror-sightings/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The free stickers were all mailed Monday. Here's a quick statistical breakdown, courtesy of my wife:
</p>
<p>
</p>
<table width="250">
<tr>
<td>United States</td>
<td>320
</td>
</tr>
<tr>
<td>Canada</td>
<td>49
</td>
</tr>
</table>
<p>
38 of the 50 states were represented. The states with zero sticker requests were: HI, KS, LA, MS, MT, ND, NM, RI, SD, VT, WV and WY. Here are the top 10 states:
</p>
<p>
</p>
<table width="200">
<tr>
<td>CA</td>
<td>32
</td>
</tr>
<tr>
<td>TX</td>
<td>26
</td>
</tr>
<tr>
<td>WA</td>
<td>16
</td>
</tr>
<tr>
<td>FL</td>
<td>16
</td>
</tr>
<tr>
<td>PA</td>
<td>13
</td>
</tr>
<tr>
<td>MA</td>
<td>13
</td>
</tr>
<tr>
<td>CO</td>
<td>13
</td>
</tr>
<tr>
<td>IL</td>
<td>13
</td>
</tr>
<tr>
<td>OH</td>
<td>12
</td>
</tr>
<tr>
<td>MN</td>
<td>12
</td>
</tr>
</table>
<p>
And here's a similar breakdown for Canadian provinces:
</p>
<p>
</p>
<table width="200">
<tr>
<td>Ontario</td>
<td>15
</td>
</tr>
<tr>
<td>Alberta</td>
<td>11
</td>
</tr>
<tr>
<td>Quebec</td>
<td>10
</td>
</tr>
<tr>
<td>British Columbia</td>
<td>9
</td>
</tr>
<tr>
<td>New Brunswick</td>
<td>1
</td>
</tr>
<tr>
<td>Manitoba</td>
<td>1
</td>
</tr>
<tr>
<td>Nova Scotia</td>
<td>1
</td>
</tr>
<tr>
<td>Saskatchewan</td>
<td>1
</td>
</tr>
</table>
<p>
Contrary to popular belief, I am fully aware that the United States isn't the only country in the world. Here's a breakdown of the international orders to date:
</p>
<p>
</p>
<table width="200">
<tr>
<td>United Kingdom</td>
<td>7
</td>
</tr>
<tr>
<td>Australia</td>
<td>3
</td>
</tr>
<tr>
<td>Germany</td>
<td>2
</td>
</tr>
<tr>
<td>Finland</td>
<td>1
</td>
</tr>
<tr>
<td>Brazil</td>
<td>1
</td>
</tr>
<tr>
<td>Switzerland</td>
<td>1
</td>
</tr>
<tr>
<td>Sweden</td>
<td>2
</td>
</tr>
<tr>
<td>Belgium</td>
<td>1
</td>
</tr>
<tr>
<td>Denmark</td>
<td>1
</td>
</tr>
<tr>
<td>New Zealand</td>
<td>1
</td>
</tr>
<tr>
<td>Latvia</td>
<td>1
</td>
</tr>
</table>
<p>
Although the free sticker offer is over, you can still <a href="http://www.codinghorror.com/blog/archives/000636.html">buy a set of 4 stickers for $3</a>. They're usually mailed the same day.
</p>
<p>
</p>
<table cellpadding="5" width="750">
<tr>
<td valign="bottom">
Will Sullivan's is appropriately positioned next to a real coding horror.
</td>
<td valign="bottom">
Bryan Likes created the <a href="http://www.infinitecat.com/infinite/cat-html/1301-1400/1301.html">infinite cat project</a> recursive version.
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="bottom">
Here's one from my fellow developers at Vertigo. If you work with me, I'll give you a sticker. But only grudgingly.
</td>
<td valign="bottom">
Sam Livingston-Gray put his to good use covering up that hideous Apple logo. Bonus points for real-life simulation!
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="bottom">
Matt Blodgett evidently <i>doesn't</i> own a digital camera. But he <i>does</i> have mad MS Paint skills.
</td>
<td valign="bottom">
My old friend Geoff Dalgas created this animated version of the sticker.
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="bottom">
Brian Stephens works on <a href="http://titanquestgame.com/">Titan Quest</a>, which doesn't <i>play</i> like a Coding Horror.
</td>
<td valign="bottom">
Bryan Kramer sighted his at a Jacksonville, Florida Code Camp during a marathon not-for-profit coding session.
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="bottom">
David Howell gave his sticker a place of honor in his cube.
</td>
<td valign="bottom">
Nathan Birkes used his sticker to pimp out his Grand Prix. Stylin'!
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
<tr>
<td valign="bottom">
<a href="http://www.furrygoat.com/">Steve Makofsky</a> works at Microsoft. Guess what part of Vista he worked on?
</td>
<td valign="bottom">
Martin Marconcini is going for sticker symmetry on his Ford Focus.
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
<b>If you have any Coding Horror sticker or T-shirt "action shots", email them to me, and I'll post them here. </b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/coding-horror-sightings/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Programmer's Bill of Rights ]]></title>
<link>https://blog.codinghorror.com/the-programmers-bill-of-rights/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>It's unbelievable to me that a company would pay a developer $60$100k in salary, yet cripple them with terrible working conditions and crusty hand-me-down hardware. This makes no business sense whatsoever. And yet I see it all the time. It's shocking how many companies still don't provide software developers with the essential things they need to succeed.</p>
<p>I propose we adopt a <strong>Programmer's Bill of Rights</strong>, protecting the rights of programmers by preventing companies from denying them the fundamentals they need to be successful.</p>
<img alt="image placeholder" >
<ul>
<li>
<p><strong>Every programmer shall have <a href="https://blog.codinghorror.com/multiple-monitors-and-productivity/">two monitors</a></strong></p>
<p>With the crashing prices of LCDs and the ubiquity of dual-output video cards, you'd be crazy to limit your developers to a single screen. The productivity benefits of doubling your desktop are <a href="https://developers.slashdot.org/story/03/10/09/137232/multiple-monitors-increase-productivity">well documented by now</a>. If you want to maximize developer productivity, make sure each developer has two monitors. <a href="https://blog.codinghorror.com/three-monitors-for-every-user/">Or three</a>.</p>
</li>
<li>
<p><strong>Every programmer shall have <a href="https://blog.codinghorror.com/building-a-pc-part-viii-iterating/">a fast PC</a></strong></p>
<p>Developers are required to run a lot of software to get their jobs done: development environments, database engines, web servers, virtual machines, and so forth. Running all this software requires a fast PC with lots of memory. The faster a developer's PC is, the faster they can cycle through debug and compile cycles. You'd be foolish to pay the extortionist prices for the extreme top of the current performance heap  but always make sure you're buying <em>near</em> the top end. Outfit your developers with fast PCs that have lots of memory. Time spent staring at a progress bar is <em>wasted time</em>.</p>
</li>
<li>
<p><strong>Every programmer shall have their choice of <a href="https://blog.codinghorror.com/my-mouse-fetish/">mouse</a> and <a href="https://blog.codinghorror.com/the-code-keyboard/">keyboard</a></strong></p>
<p>In college, I <a href="https://blog.codinghorror.com/are-you-following-the-instructions-on-the-paint-can/">ran a painting business</a>. Every painter I hired had to buy their own brushes. This was one of the first things I learned. Throwing a standard brush at new painters didn't work. The "company" brushes were quickly neglected and degenerated into a state of disrepair. But painters who bought their own brushes took care of them. Painters who bought their own brushes learned to appreciate the difference between the professional $20 brush they owned and cheap disposable dollar store brushes. Having their own brush engendered a sense of enduring responsibility and craftsmanship. Programmers should have the same relationship with their mouse and keyboard  they are the essential, workaday tools we use to practice our craft and should be treated as such.</p>
</li>
<li>
<p><strong>Every programmer shall have <a href="https://blog.codinghorror.com/investing-in-a-quality-programming-chair/">a comfortable chair</a></strong></p>
<p>Let's face it. We make our livings largely by sitting on our butts for 8 hours a day. Why not spend that 8 hours in a comfortable, well-designed chair? Give developers chairs that make sitting for 8 hours not just tolerable, but enjoyable. Sure, you hire developers primarily for their giant brains, but don't forget your developers' <em>other</em> assets.</p>
</li>
<li>
<p><strong>Every programmer shall have a fast internet connection</strong></p>
<p>Good programmers <a href="https://blog.codinghorror.com/never-design-what-you-can-steal/">never write what they can steal</a>. And the internet is the best conduit for stolen material ever invented. I'm <a href="https://blog.codinghorror.com/recommended-reading-for-developers/">all for books</a>, but it's hard to imagine getting any work done without fast, responsive internet searches at my fingertips.</p>
</li>
<li>
<p><strong>Every programmer shall have <a href="https://blog.codinghorror.com/this-is-your-anti-productivity-pod/">quiet working conditions</a></strong></p>
<p>Programming requires focused mental concentration. Programmers cannot work effectively in an interrupt-driven environment. Make sure your working environment protects your programmers' <a href="http://en.wikipedia.org/wiki/Flow_(psychology)">flow state</a>, otherwise they'll waste most of their time bouncing back and forth between distractions.</p>
</li>
</ul>
<p>The few basic rights we're asking for are easy. They aren't extravagant demands. They're fundamental to the quality of work life for a software developer. If the company you work for isn't getting it right, making it right is neither expensive nor difficult. <strong>Demand your rights as a programmer!</strong> And remember: you can either change your company, or you can <em>change your company</em>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-programmers-bill-of-rights/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How to Write Technical Documentation ]]></title>
<link>https://blog.codinghorror.com/how-to-write-technical-documentation/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I was browsing around the <a href="http://www.couchdb.com/CouchDB/CouchDBWeb.nsf/direct/Introduction">CouchDb</a>   <a href="http://couchdb.infogami.com/">wiki</a> yesterday when I saw Damien Katz' hilarious <a href="http://couchdb.infogami.com/alpha1">description</a> of <b>how technical documentation really gets written.</b> You know, in the real world:
</p>
<p>
</p>
<blockquote>
<p>Welcome to the world of technical documentation!</p>
<p>The situation you are in is no different from any other tech writer. The technical writing process:</p>
<ol>
<li>Ask engineer how the damn thing works.</li>
<li>Deafing silence.</li>
<li>Crickets.</li>
<li>Tumbleweed.</li>
<li>Just start writing something. Anything.</li>
<li>Give this something to the engineer.</li>
<li>Watch engineer become quite upset at how badly you've missed the point of everything.</li>
<li>As the engineer berates you, in between insults he will also throw off nuggets of technical information.</li>
<li>Collect these nuggets, as they are the only reliable technical information you will receive.</li>
<li>Try like hell to weave together this information into something enlightening and technically accurate.</li>
<li>Go to step 6.</li>
</ol>
<p>Ok, you're not the doc writing type. That's okay, neither am I. However, people are already working to make this better, and I will continue to do so.</p>
</blockquote>
<p>
I think I've been on both ends of this exchange at some point in my career. It's funny because it's true. I'm sure I've read <a href="http://www.mikepope.com/blog/DisplayBlog.aspx?permalink=1114">descriptions exactly like this on Mike Pope's blog</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-to-write-technical-documentation/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Sporkfe ]]></title>
<link>https://blog.codinghorror.com/the-sporkfe/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Why does the <a href="http://lightmyfireusa.com/spork.html">sporkfe</a> fascinate me so?
</p>
<p>
<a href="http://lightmyfireusa.com/spork.html"><img alt="image placeholder" >
</p>
<p>
It's a spoon. It's a fork. It's a knife. Some call it a <a href="http://www.everything2.com/index.pl?node_id=1463951">splade</a>-- sold commercially in Australia for the last 50 years under the <a href="http://www.splayds.com/">Splayds</a> brand name-- but I prefer <i>sporkfe</i>. Really, when was the last time you ate your food with a <i>blade?</i>
</p>
<p>
I have no idea why I <a href="http://www.x-tremegeek.com/templates/searchdetail.asp?productID=12213">bought these</a>. But at least I saved myself from the indignity of owning <a href="http://blogs.vertigosoftware.com/jatwood/archive/2006/08/24/The_Mother_of_All_Swiss_Army_Knives.aspx">the Mother of All Swiss Army Knives</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-sporkfe/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Thread Priorities are Evil ]]></title>
<link>https://blog.codinghorror.com/thread-priorities-are-evil/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Programmers* love to futz around with thread priorities. As if <a href="http://www.codinghorror.com/blog/archives/000169.html">programming with threads wasn't already dangerous enough</a>, we've got to get in there and tweak thread priorities to make things run.. er.. "better".
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Let's <a href="http://www.codinghorror.com/blog/archives/000393.html">fire up Task Manager</a> and take a quick survey of process priorities. Out of <b>38</b> processes running on my computer right now, I have <b>0</b> at low priority, <b>36</b> at normal priority, and <b>2</b> essential system processes (csrss and winlogon) running at high priority.
</p>
<p>
I bet <b>almost every process on your machine is running at a base priority of "Normal"</b>, too. And there's a very good reason for this.
</p>
<p>
Witness K. Scott Allen's <a href="http://odetocode.com/Blogs/scott/archive/2006/08/27/6053.aspx">strange threading experiment</a>:
</p>
<p>
</p>
<blockquote>
This <a href="http://odetocode.com/Blogs/scott/archive/2006/08/27/6053.aspx">program </a> behaves badly on a single processor machine, and pegs the CPU at 100% for over two minutes. On a multi processor machine, the program finishes all the threading work in the blink of an eye - only a brief CPU spike.
<p>
Strangely, if I remove a single line of code:
</p>
<p>
</p>
<pre>t.Priority = ThreadPriority.BelowNormal;</pre>
<p>
 then the program performs just as well on a single processor machine (only a brief spike - comparable to the multi processor scenario).
</p>
</blockquote>
<p>
This little threading demo highlights <b>one of the reasons a dual-core computer is so desirable -- it protects you from poorly written programs.</b> If a program goes haywire and consumes 100% of CPU time, you still have a "spare" CPU waiting to pick up the slack. Whereas a single processor machine becomes totally unresponsive. That's why <b>Task Manager itself runs at High priority</b>-- so you can pre-empt these kind of runaway apps.**
</p>
<p>
Hardware fixes to software problems <a href="http://www.codinghorror.com/blog/archives/000364.html">are never pretty</a>. What's really going on here? Joe Duffy is something of an expert on the topic of threading and concurrency-- he works for Microsoft on CPU-based parallelism in the .NET Common Language Runtime-- and he has <a href="http://www.bluebytesoftware.com/blog/PermaLink,guid,1c013d42-c983-4102-9233-ca54b8f3d1a1.aspx">this to say</a>:
</p>
<p>
</p>
<blockquote>
<b>Messing with [thread] priorities is actually a very dangerous practice, and this is only one illustration of what can go wrong.</b> (Other illustrations are topics for another day.) In summary, plenty of people do it and so reusable libraries need to be somewhat resilient to it; otherwise, we get bugs from customers who have some valid scenario for swapping around priorities, and then we as library developers end up fixing them in service packs. It's less costly to write the right code in the first place.
<p>
Here's the problem. If somebody begins the work that will make 'cond' true on a lower priority thread (the producer), and then the timing of the program is such that the higher priority thread that issues this spinning (the consumer) gets scheduled, the consumer will starve the producer completely. This is a classic race. And even though there's an explicit Sleep in there, issuing it doesn't allow the producer to be scheduled because it's at a lower priority. The consumer will just spin forever and unless a free CPU opens up, the producer will never produce. Oops!
</p>
<p>
The moral of the story? <b>[Thread] priorities are evil, don't mess with them.</b>
</p>
</blockquote>
<p>
Although there are some edge conditions where micromanaging thread priorities can make sense, it's generally a bad idea. <b>Set up your threads at normal priority and let the operating system deal with scheduling them.</b> No matter how brilliant a programmer you may be, I can practically guarantee you won't be able to outsmart the programmers who wrote the scheduler in your operating system.
</p>
<p>
* and users who think they're programmers<br>
** assuming the runaway app itself isn't running at High priority, in which case you're in a world of hurt.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/thread-priorities-are-evil/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Game Player, Game Programmer ]]></title>
<link>https://blog.codinghorror.com/game-player-game-programmer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Greg Costikyan's essay <a href="http://www.manifestogames.com/node/1425">Welcome Comrade!</a> is a call to arms for hobbyist game programmers:
</p>
<p>
</p>
<blockquote>
<img alt="image placeholder" >
Back in the day, it took a couple of man days to create a Doom level. Creating a Doom III level took multiple man-weeks. Thus budgets spiral every upward; as late as 1992, a typical computer game had a budget of $200,000. Today, 10 million dollars is your bare buy-in for a next generation title.
<p>
As budgets soar, publishers are increasingly conservative about what they will fund, because nobody wants to lose 10 million dollars. So they look for ways to reduce their risk. Today, they have become so risk-averse that anything other than a franchise title, a game based on a movie license, or a game that slots easily into a category they know how to sell is unthinkable.
</p>
<p>
Today, Myst, Civilization, or Sim City would never get funded.
</p>
<p>
We're condemned to more of the same-old same-old from now for all eternity--unless we figure out a way to break this iron grip--what Raph Koster calls "<a href="http://www.raphkoster.com/gaming/moore.shtml">Moore's Wall</a>."
</p>
<p>
We think it's possible-- by building for the game industry what the independent film and independent music movements do for their own industry. <b>Creating a viable "independent games" movement, where people can experiment, at lower budgets and with less risk, on quirky, offbeat, innovative games</b>-- and find an audience that prizes gameplay over glitz, innovation over graphical trickery, playfulness over polygons.
</p>
</blockquote>
<p>
Greg's <a href="http://www.manifestogames.com/">Manifesto Games</a> website aims to make this a reality, by creating an audience and supporting hobbyist developers.
</p>
<p>
James Hague's <a href="http://www.loonygames.com/content/1.19/feat/">Rise and Fall of the Hobbyist Game Programmer</a> documents just how profoundly the world has changed for would-be game programmers in the last 30 years:
</p>
<p>
</p>
<blockquote>
For a small percentage of enthusiasts, <b>there's always been the calling to jump from just playing games to creating them</b>. It's crazy, of course, because the rush of playing a great game doesn't carry over to spending twenty straight hours in the basement trying to figure out why a level initialization routine fails ten percent of the time. But those that persisted, they drove the industry in its early days.
<p>
I remember reading about Mark Turmell-- and others whose names I've forgotten-- who were somehow inspired to design their own games, and then sit down and figure out exactly how to turn them into something their friends could actually come over and play. Those were fantastic feats that started the chatter about computer games becoming a new art form. One person, one vision, and six months later a finished product that was snapped up by a publisher--pure creation. A new alternative for would-be novelists.
</p>
<p>
The dream is still alive in these days of 32-bit processors and 3D accelerators, but over the years the reality behind it has quietly slipped away and few have stopped to notice.
</p>
<p>
In 1981, personal computers were in the thick of their 8-bit heyday. Not only are we talking about an 8-bit 6502--a processor with one primary register and no multiply instruction--running at less than 2 megahertz, but it was still acceptable, though just barely, to write games in BASIC. Now don't get me wrong, BASIC was the downtrodden interpreted language that it still is, but it shipped with every Apple II and Atari 800, and was the obvious choice for budding programmers.
</p>
</blockquote>
<p>
Perhaps this is another reason why <a href="http://arstechnica.com/journals/microsoft.ars/2006/8/10/4953">the Visual Studio Express IDE should ship with Vista</a>. Or maybe doing it as-is with the .NET 2.0 command-line compiler and Notepad is more authentic. For more perspective on how the game programming world has changed since those early days, I can highly recommend James Hague's essential 1997 e-book <a href="http://www.dadgum.com/halcyon/">Halcyon Days: Interviews with Classic Computer and Video Game Programmers</a>.
</p>
<p>
Perhaps it's a little easier to imagine transitioning from gamer to programmer in the world of mobile devices. <a href="http://www.lightworksgames.com/blog/">Lightworks games</a> is doing just that-- two guys pursuing their dream by building a game company from the ground up on the PocketPC. They started with <a href="http://www.lightworksgames.com/blog/entry.aspx?entryid=ebad63ce-a1b5-4043-84e0-a23d50d9163f">Cavemen</a>, a charming little <a href="http://www.lightworksgames.com/blog/cavemen.aspx">Lemmings clone</a>.
</p>
<p>
There's also Microsoft's intriguing <a href="http://msdn.microsoft.com/directx/xna/gamestudio/">XNA Game Studio</a>, which is <a href="http://www.microsoft.com/downloads/details.aspx?familyid=21e979e3-b8ae-4ea6-8e65-393ea7684d6c&amp;displaylang=en">now available in beta</a>. It's a way for hobbyist developers to write non-commercial games that run on the Xbox 360. There have been rumblings about the best of these non-commercial games eventually making their way to the Xbox Live marketplace-- which could potentially convert those hobbyist game programmers into small business owners. It's an exciting prospect, given the huge installed base of most consoles, and the ease of getting everything running on a standard console platform.
</p>
<p>
<b>Is the dream of jumping from game player to game programmer still alive?</b> It's certainly how I got my start in programming.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/game-player-game-programmer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Computer Languages aren't Human Languages ]]></title>
<link>https://blog.codinghorror.com/computer-languages-arent-human-languages/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Though I've become agnostic about <a href="http://www.codinghorror.com/blog/archives/000519.html">the utterly meaningless non-choice between VB.NET and C#</a>, the inherited syntax of C leaves a lot to be desired, in my opinion. And not just in <a href="http://www.codinghorror.com/blog/archives/000458.html">the case sensitivity department</a>. Daniel Appleman, in his excellent e-book, <a href="http://www.amazon.com/Visual-Basic-Which-Choose/dp/B0006AB0N0">VB.NET or C#, Which to Choose?</a>, concurs:
</p>
<p>
</p>
<blockquote>
Here I risk stepping on some toes, because language syntax is very much a religious issue with many programmers. Certainly we all tend to prefer the language syntax we are familiar with, and C++ and Java programmers will certainly find a great deal that is familiar in C#.
<p>
It should also be clear from this section that the differences between the two languages in this area really are minor. Both have virtually the same functionality.
</p>
<p>
Nevertheless, on the subject of object syntax, I must give the win to VB.NET. Just look at the inheritance declarations:
</p>
<p>
</p>
<pre>
public class BClass: AClass, Iint
Public Class BClass
Inherits AClass
Implements Iint
</pre>
<p>
Look at the words used to control inheritance:
</p>
<p>
</p>
<pre>
abstract, sealed, virtual
MustInherit, NotInheritable, Overridable, Overrides, Shadows
</pre>
<p>
When it comes to looking at code and understanding what it does -- especially later on when the original developer has left and some young programmer right out of college has to figure out what it does quickly to solve some obscure bug or add a new feature, which one is going to be easier to understand? Visual Basic .NET.
</p>
</blockquote>
<p>
Although I do agree with Appleman on this point-- <i>void</i> is for sci-fi geeks; <i>nothing</i> is for human beings-- in the big scheme of things, it's barely relevant. If the success or failure of your project hinges on the minor syntax differences between two virtually identical .NET languages, you have much deeper problems than choice of language.
</p>
<p>
Although <a href="http://www.codinghorror.com/blog/archives/000396.html">the tradeoff between verbosity and succinctness</a> is worth considering, there are other risks here. <b>Computer languages, however verbose you make them, shouldn't try to become proxy versions of spoken languages.</b> I've never worked with <a href="http://en.wikipedia.org/wiki/AppleScript">AppleScript</a> before, but it fell into this trap in a big way. Here's a sample bit of AppleScript code to illustrate:
</p>
<p>
</p>
<pre>
tell application "Mori"
tell front document
set a to first item of selection
set b to second item of selection
set a's note to (a reference to a's) note &amp; (a reference to b's note)
end tell
end tell
</pre>
<p>
Looks almost like a paragraph, doesn't it? John Gruber <a href="http://daringfireball.net/2005/09/englishlikeness_monster">calls AppleScript the English-Likeness Monster</a>:
</p>
<p>
</p>
<blockquote>
The idea was, and I suppose still is, that AppleScript's English-like facade frees you from worrying about computer-science-y jargon like classes and objects and properties and commands, and allows you to just say what you mean and have it just work.
<p>
But saying what you mean, in English, almost never "just works" and compiles successfully as AppleScript, and so to be productive you still have to understand all of the ways that AppleScript actually works. But this is difficult, because <b>the language syntax is optimized for English-likeness, rather than being optimized for making it clear just what the f**k is actually going on.</b>
</p>
<p>
This is why Python and JavaScript, two other scripting language of roughly the same vintage as AppleScript, are not only better languages than AppleScript, but are easier than AppleScript, even though neither is very English-like at all. Python and JavaScript's syntaxes are much more abstract than AppleScript's, but they are also more obvious. (Python, in particular, celebrates obviousness.)
</p>
</blockquote>
<p>
AppleScript's <b>natural language metaphor</b> turns out to be more of a curse than a blessing.
</p>
<p>
Some languages are arguably more readable than others, of course, but keeping the goal of clarity front and center is far more important than bickering about relatively meaningless language choices. <a href="http://www.codinghorror.com/blog/archives/000272.html">You can write FORTRAN in any language</a>, so choose whatever language you're most comfortable with and <i>optimize for making it clear what the f**k is going on.</i>
</p>
<p>
(I thought about letting the f-bomb drop in this post for emphasis, but my fireball isn't quite as daring as John Gruber's.)
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-08-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/computer-languages-arent-human-languages/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ External Hard Drives ]]></title>
<link>https://blog.codinghorror.com/external-hard-drives/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Now that Vista Release Candidate 1 is available, it's <a href="http://vertigoblogs/ericc/archive/2006/09/03/Visual_Walkthrough_of_Vista_RC1_Setup.aspx">time to start playing with it</a>. I'm tired of using my current <a href="http://www.codinghorror.com/blog/archives/000646.html">legacy operating system</a>. Testing Vista probably means I'll probably be booting from an <b>external hard drive</b>.
</p>
<p>
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16817155223"><img alt="image placeholder" >
</p>
<p>
External drives have been available in Firewire and USB flavors for years. An even better option is to route your internal SATA connectors to the back of your PC and <b>plug in the external hard drive using its native SATA interface</b> for maximum performance.
</p>
<p>
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16813997002"><img alt="image placeholder" >
</p>
<p>
The performance difference between USB, Firewire, and SATA can be dramatic. Compare <a href="http://www.anandtech.com/mb/showdoc.aspx?i=2358&amp;p=17">these throughput numbers</a>:
</p>
<p>
</p>
<table width="400">
<tr>
<td>SATA II</td>
<td>55 MB/sec
</td>
</tr>
<tr>
<td>SATA</td>
<td>54 MB/sec
</td>
</tr>
<tr>
<td>IDE</td>
<td>54 MB/sec
</td>
</tr>
<tr>
<td>Firewire 800</td>
<td>41 MB/sec
</td>
</tr>
<tr>
<td>USB 2.0</td>
<td>35 MB/sec
</td>
</tr>
<tr>
<td>Firewire 400</td>
<td>29 MB/sec
</td>
</tr>
</table>
<p>
It's also possible to use plain old internal SATA connectors to connect external drives, but most external brackets convert the internal SATA connectors to External SATA connectors or "eSATA". These are basically just <a href="http://www.bjorn3d.com/read.php?cID=912">more robust, better shielded versions of regular SATA connectors</a>. Do be careful which connector you get, because they have different shapes and aren't interchangeable.
</p>
<p>
eSATA connections are great for desktops, but most PC laptops typically only have USB connectors. Fortunately, there are enclosures that offer the best of both worlds-- <b>USB 2.0 and SATA connections</b> for <a href="http://www.newegg.com/Product/Product.asp?Item=N82E16817145392">2.5" notebook hard drives</a>, as well as <a href="http://www.newegg.com/Product/Product.asp?Item=N82E16817173022">3.5" desktop hard drives</a>. Just buy the enclosure and add a hard drive of your choice.
</p>
<p>
If you want maximum performance from your external drive, I recommend choosing something from the 10,000 RPM <a href="http://www.storagereview.com/articles/200601/WD1500ADFD_1.html">Western Digital Raptor series</a>. I've switched to Raptors as my system drive on both my work and home PC, and the difference is quite noticeable. They're also much quieter and cooler than I expected for such fast drives. The Raptors aren't cheap, but you'll see the value of these drives <a href="http://www.anandtech.com/storage/showdoc.aspx?i=2480&amp;p=7">the first time you boot up</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/external-hard-drives/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Transfer Mode Downgraded ]]></title>
<link>https://blog.codinghorror.com/transfer-mode-downgraded/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I noticed when I was burning the Vista RC1 DVD that ..
</p>
<p>
</p>
<ol>
<li>It took <i>forever</i>, eg, nearly an hour
</li>
<li>My PC was very sluggish during the burn
</li>
</ol>
<p>
I began to suspect something was awry with the IDE controller that the DVD-R drive is connected to. I navigated to <b>Device Manager</b>, expanded the <b>IDE ATA/ATAPI controllers</b> tree node, right-clicked the <b>Parallel ATA Controller</b> node and selected properties.
</p>
<p>
And what do I find on the Secondary Channel tab? Sure enough, <b>Transfer mode downgraded</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This behavior is, of course, <i>by design</i>. <a href="http://www.microsoft.com/whdc/device/storage/IDE-DMA.mspx">Microsoft automatically downgrades the transfer mode on a Parallel or Serial ATA channel after receiving more than six CRC errors on that channel.</a> At least you can see when this has happened-- Microsoft provides the little yellow alert pictured above, along with some alerts in the system Event Log.
</p>
<p>
CRC errors are <i>very</i> dangerous for a hard drive-- that means you've got some serious hardware problems. <b>But for a DVD or CD drive, it probably just means you tried to read a scratched disc.</b> You can <a href="http://www.neowin.net/forum/lofiversion/index.php/t19007.html">override this obnoxious behavior in the registry</a>.
</p>
<p>
I flipped the switch back to "Let BIOS select transfer mode", rebooted, and I was on my way:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
However, depending on what Windows XP has decided to do here, you may need to uninstall the channel (just right-click it in Device Manager to do this). Don't worry, uninstalling won't cause any problems. Just reboot and the channel will be redetected with default settings.
</p>
<p>
To illustrate how important proper PATA/SATA transfer mode settings are, here's how long it took to burn a Vista RC1 DVD on my PC before and after:
</p>
<p>
in PIO mode: <font color="red"><b>56 minutes</b></font>.<br>
in Ultra DMA 2 mode: <b>4 minutes</b>.
</p>
<p>
Friends don't let friends use Programmed I/O Mode.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/transfer-mode-downgraded/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Unnecessary Dialogs: Stopping the Proceedings with Idiocy ]]></title>
<link>https://blog.codinghorror.com/unnecessary-dialogs-stopping-the-proceedings-with-idiocy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although I like <a href="http://www.flos-freeware.ch/notepad2.html">Notepad2</a>, it has some pathological alert dialog behavior, particularly when it comes to searching. Here's an alert dialog I almost always get when searching a document:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Thanks for the update, Notepad2. I really wanted a whole modal alert dialog to tell me this important fact. And if my search text is not found?
</p>
<p>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Because I couldn't <i>possibly</i> tell if the text was not found without a giant.. alert.. dialog.
</p>
<p>
These are both unnecessary alert dialogs that, collectively, destroy the flow of my search task. It's the GUI equivalent of that annoying little kid from <a href="http://www.imdb.com/title/tt0116695/">Jerry Maguire</a> telling me that:
</p>
<p>
<img alt="image placeholder" >

<img alt="image placeholder" >

<img alt="image placeholder" >
</p>
<p>
Meanwhile, I'm trying to get some freaking work done.
</p>
<p>
Alan Cooper, in his book <a href="http://www.amazon.com/exec/obidos/ASIN/0764526413/codihorr-20">About Face 2.0</a>, calls this <b>stopping the proceedings with idiocy</b>. And that's exactly what it is.
</p>
<p>
</p>
<blockquote>
There is a particular form of excise that is so prevalent it deserves special attention. In Chapter 9, we introduced the concept of flow, where the user enters a highly productive mental state by working in harmony with his tools. Flow is a natural state, and people will enter it without much prodding. It takes some effort to break into flow after someone has achieved it. Interruptions like a ringing telephone will do it, as will an error message box. Most interruptions are avoidable; a few aren't. <b>But interrupting a user's flow for no good reason is <i>stopping the proceedings with idiocy</i> and is one of the most disruptive forms of excise.</b>
<p>
Poorly designed software will make assertions that no self-respecting individual would ever make. It states unequivocally, for example, that a file doesn't exist merely because it is too stupid to look for it in the right place, and then implicitly blames <i>you</i> for losing it. A program will cheerfully execute an impossible query that hangs up your system until you decide to reboot. Users view such software behavior as idiocy, and with just cause.
</p>
</blockquote>
<p>
The canonical example of unnecessary dialogs, the delete confirmation dialog, lives on in Windows Vista:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The real irony here is that moving files to the recycle bin is a completely recoverable action. It doesn't matter what I click in this dialog. If I mistakenly "delete" files this way, I can simply <i>recover them from the recycle bin</i>. This alert dialog is utterly superfluous. It's just another button I have to click through to get my work done. Sure, I can disable it (and I have), but the fact that the delete confirmation dialog exists at all is a giant sock in the nose for usability professionals everywhere.
</p>
<p>
Here's how strongly I feel about this: <b>every time you send your users to an alert dialog, you have failed them.</b> In a perfect world, we should never see a single alert dialog. Ever.
</p>
<p>
Heck, I'm <a href="http://www.codinghorror.com/blog/archives/000019.html">not even sure the dialog box itself was ever a good idea</a>. There's a lot of evidence that <a href="http://www.codinghorror.com/blog/archives/000114.html">users never read dialogs</a> and quickly train themselves to mindlessly click through them. Consider Mike's latest <a href="http://www.mikepope.com/blog/DisplayBlog.aspx?permalink=1592">experience</a>:
</p>
<p>
</p>
<blockquote>
Over the weekend I was at a meeting of parents where many laptops were open and we were all looking at a spreadsheet. One parent opened the spreadsheet in Excel and was confronted by that big dialog boxes that warns you about macros.
<p>
It was classic. She just stopped and said "What am I supposed to do!? What does this mean!?" <b>She did not read one single word of the dialog box text.</b> Being me and all, I said "What does it say?" and more-or-less made her read the text, mostly on principle. Not that it probably helped much, because even when she'd read that "macros can be harmful" or whatever it says, she asked me "But it's ok to open this spreadsheet"? Yes, it was. Who knows what she would have done if she'd been on her own. I'm not sure she knows what a macro actually is.
</p>
</blockquote>
<p>
The web has been a dialog-free world for years, and nobody seems to miss them very much. Maybe this is why. I dream of the day when we can produce a dialog-free GUI.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/unnecessary-dialogs-stopping-the-proceedings-with-idiocy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software: It's a Gas ]]></title>
<link>https://blog.codinghorror.com/software-its-a-gas/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://en.wikipedia.org/wiki/Nathan_Myhrvold">Nathan Myhrvold</a>, the former CTO of Microsoft, is also a bona-fide physicist. He holds physics degress from UCAL and Princeton. He even had a postdoctoral fellowship under the famous Stephen Hawking. Thus, as you might expect, his 1997 ACM keynote presentation, <a href="http://www.research.microsoft.com/acm97/nm/sld001.htm">The Next Fifty Years of Software</a> is full of physics and science metaphors.
</p>
<p>
It starts with Nathan's four Laws of Software:
</p>
<p>
</p>
<ol>
<li>
<b>Software is a gas</b><br>
Software always expands to fit whatever container it is stored in.
<p>
</p>
</li>
<li>
<b>Software grows until it becomes limited by Moore's Law</b><br>
The initial growth of software is rapid, like gas expanding, but is inevitably limited by the rate of increase in hardware speed.
<p>
</p>
</li>
<li>
<b>Software growth makes Moore's Law possible</b><br>
People buy new hardware because the software requires it.
<p>
</p>
</li>
<li>
<b>Software is only limited by human ambition and expectation</b><br>
We'll always find new algorithms, new applications, and new users.
</li>
</ol>
<p>
Myhrvold goes on to describe software development as a state of <b>Perpetual Crisis</b>. The size and complexity of software is constantly rising, with no limit in sight. As we develop more advanced software-- and as we develop solutions to manage the ever-increasing complexity of this software-- the benefits of the new software are absorbed by the rising tide of customer expectations. Software development will never be easy; new software always has to push against the current complexity boundary if it wants to be commercially successful.
</p>
<p>
This was all written in 1997. Nearly ten years later, are his points still valid? Software is certainly still a gas. Now that we're <a href="http://software.ericsink.com/entries/LarryO.html">entering the multi-core era</a>, there is one crucial difference. Historically hardware has gotten more complex because of limitations in the ability of software to scale; now the software needs to get more complex because of limitations in the ability of hardware to scale. <b>The burden of scaling now falls on the software.</b>
</p>
<p>
Myhrvold then makes an interesting point about the amount of storage required to capture human diversity. If..
</p>
<p>
</p>
<ul>
<li>the human Genome is approximately 1 gigabyte of data;
</li>
<li>the individual difference between any two humans is 0.25% of their Genome;
</li>
<li>we assume a lossless compression rate of 2:1;
</li>
</ul>
<p>
The individually unique part of the human Genome can be stored in ~1.2 megabytes. Thus, <b>you fit on a 3.5" floppy disk.</b>
</p>
<p>
In fact, the entirety of human genetic diversity for every living human being could be stored in a 3.7 terabyte drive array. And the entire genetic diversity of <i>every living thing on earth</i> could be stored in roughly the size of the internet circa 2001.
</p>
<p>
I'm not sure what that means, exactly, but I love the idea that I can fit myself on a 3.5" floppy disk.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-its-a-gas/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Have You Ever Been Windows Experienced? ]]></title>
<link>https://blog.codinghorror.com/have-you-ever-been-windows-experienced/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Now that <a href="http://download.windowsvista.com/preview/rc1/en/download.htm">Windows Vista Release Candidate 1</a> is sorta-kinda available to everyone, let's see what it takes to run it. Here's a comparison of the Vista hardware requirements with the hardware requirements of Windows XP:
</p>
<p>
</p>
<table>
<tr>
<td width="80"></td>
<td width="250">
<b>Windows XP</b> (2001)</td>
<td width="250">
<b>Windows Vista</b> (2007)
</td>
</tr>
<tr>
<td valign="top">CPU</td>
<td valign="top">233 MHz</td>
<td valign="top">800 MHz<br>(1 GHz recommended)
</td>
</tr>
<tr>
<td valign="top">RAM</td>
<td valign="top">64 MB<br valign="top">(128 MB recommended)</td>
<td>512 MB<br>(1 GB recommended)
</td>
</tr>
<tr>
<td valign="top">Video</td>
<td valign="top">Super VGA (800 x 600) display</td>
<td valign="top">DirectX9 video card<br>
(128 MB video RAM recommended)
</td>
</tr>
<tr>
<td valign="top">HDD</td>
<td valign="top">1.5 GB</td>
<td valign="top">15 GB
</td>
</tr>
</table>
<p>
<b>Vista requires 10x the drive space, 8x the memory, and 4x the CPU power.</b> It also substantially raises the bar for video; most integrated video solutions are no longer acceptable. The increase in minimum spec is not unreasonable, considering it's been <i>6 long years</i> since the last release of a mainstream desktop operating from Microsoft.
</p>
<p>
Still, Vista-capable PCs can be had on the cheap. Even <a href="http://www.emachines.com/products/products.html?prod=T6534">a basic $449 eMachines box</a> exceeds these requirements. Granted, you might need to spend a bit of extra money to upgrade the memory from the default 512 megabytes, but even then you could buy a cheap 512 megabyte USB key and <a href="http://blogs.msdn.com/tomarcher/archive/2006/06/02/615199.aspx">use it as ReadyBoost cache</a>.
</p>
<p>
To deal with Vista's increased system requirements, <b>Microsoft baked in a system benchmarking tool known as the Windows Experience Index.</b> At first boot, your system is profiled, and features are enabled or disabled based on your machine's Windows Experience Index score. Here's what my home PC scored:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Unlike some of the <a href="http://en.wikipedia.org/wiki/Features_new_to_Windows_Vista">new Microsoft Vista features</a>, this one is remarkably well thought out. For one thing, it expresses the total score as the lowest subscore. This is an incredibly intuitive way to highlight that <b>your PC's performance is only as good as the slowest subsystem</b>. You know immediately which part of your system will give you the most bang for the buck when upgrading.*
</p>
<p>
Clicking the <b>View and Print Details</b> button results in a great detailed system summary as well. Here's the Windows Experience Index summary page for my <a href="http://www.codinghorror.com/blog/archives/000624.html">Asus W3J laptop</a>:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's a nice, balanced set of results, exactly what I was shooting for with this laptop. I also planned to upgrade the laptop's hard drive later in its life to boost its performance, so this confirms that choice as well. But what exactly is being measured here?
</p>
<p>
If you browse to <b>c:windowsperformancewinsat</b> and look in the datastore folder, you'll find an XML file that describes the test results in detail. Here's the relevant Metrics section:
</p>
<p>
</p>
<p><font face="Monospace" size="-1">
<font color="Blue">&lt;</font><font color="Maroon">Metrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">CPUMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">CompressionMetric</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">MB/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">43.83377</font><font color="Blue">&lt;/</font><font color="Maroon">CompressionMetric</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">EncryptionMetric</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">MB/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">23.30456</font><font color="Blue">&lt;/</font><font color="Maroon">EncryptionMetric</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">Compression2Metric</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">MB/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">138.22060</font><font color="Blue">&lt;/</font><font color="Maroon">Compression2Metric</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">Encryption2Metric</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">MB/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">178.69444</font><font color="Blue">&lt;/</font><font color="Maroon">Encryption2Metric</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">DshowEncodeTime</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">19.18101</font><font color="Blue">&lt;/</font><font color="Maroon">DshowEncodeTime</font><font color="Blue">&gt;<br>
&lt;/</font><font color="Maroon">CPUMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">MemoryMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">Bandwidth</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">MB/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">3316.58691</font><font color="Blue">&lt;/</font><font color="Maroon">Bandwidth</font><font color="Blue">&gt;<br>
&lt;/</font><font color="Maroon">MemoryMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">GamingMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">AlphaFps</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">F/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">49.85000</font><font color="Blue">&lt;/</font><font color="Maroon">AlphaFps</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">ALUFps</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">F/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">40.82000</font><font color="Blue">&lt;/</font><font color="Maroon">ALUFps</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">TexFps</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">F/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">45.64000</font><font color="Blue">&lt;/</font><font color="Maroon">TexFps</font><font color="Blue">&gt;<br>
&lt;/</font><font color="Maroon">GamingMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">GraphicsMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">DWMFps</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">F/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">88.73640</font><font color="Blue">&lt;/</font><font color="Maroon">DWMFps</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">VideoMemBandwidth</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">MB/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">4695.65000</font><font color="Blue">&lt;/</font><font color="Maroon">VideoMemBandwidth</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">MFVideoDecodeDur</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">2.93202</font><font color="Blue">&lt;/</font><font color="Maroon">MFVideoDecodeDur</font><font color="Blue">&gt;<br>
&lt;/</font><font color="Maroon">GraphicsMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">DiskMetrics</font><font color="Blue">&gt;<br>
&lt;</font><font color="Maroon">AvgThroughput</font><font color="Blue"> </font><font color="Red">units</font><font color="Blue">=</font><font color="Black">"</font><font color="Blue">MB/s</font><font color="Black">"</font><font color="Blue">&gt;</font><font color="Black">31.75583</font><font color="Blue">&lt;/</font><font color="Maroon">AvgThroughput</font><font color="Blue">&gt;<br>
&lt;/</font><font color="Maroon">DiskMetrics</font><font color="Blue">&gt;<br>
&lt;/</font><font color="Maroon">Metrics</font><font color="Blue">&gt;</font>
</font></p>
<p>
I can see the <b>Windows Experience Index base score</b> becoming a standard tool for bragging rights amongst OEM PC builders. And because Microsoft used a balanced set of benchmarks with a logical scoring mechanism based on the weakest link in the system, the WEI score is more meaningful than a third party synthetic benchmark: when these scores improve, <i>users win</i>.
</p>
<p>
Just kidding. My WEI is bigger than yours.
</p>
<p>
* There is one caveat here: gaming. A low-ish ~2 video card rating will be plenty for Aero and WPF apps. A higher video rating will only really matter for users that play games, so it might be unfair to reduce the entire system's score to the video card score.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/have-you-ever-been-windows-experienced/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Technological Racism ]]></title>
<link>https://blog.codinghorror.com/technological-racism/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
</p>
<p>
Brian Kuhn recently <a href="http://blog.oppositionallydefiant.com/CommentView,guid,ac62e225-9975-42b4-972d-885cd17cde24.aspx">described the real risk</a> of <b>technocentrism</b>.
</p>
<p>
</p>
<blockquote>
[..] people use (or have rejected) particular operating systems, tools, and software that has in turn shaped their perceptions when it comes to making judgments on the various merits of particular technologies. People tend to categorize or identify themselves with particular "technological cultures"; some of the most common being type of operating system they use, development platform, and programming language. <b>Participation and identification with these cultures brings with it a tendency to look at the world primarily from the perspective of one's own technological culture, or technocentrism.</b>
<p>
If you do not make an effort to be aware of being technocentric, it is easy to become a zealot of the the technology you identify most with. I find myself guilty of this at times, and see the results of technocentrism most often in the back and forth arguments of many blog comment posts. You can find this sort of rabid fanaticism and heated arguments all over the Internet, and in my opinion it is to the detriment of all participants.
</p>
<p>
<a href="http://www.ibiblio.org/Dave/ar00164.htm"><img alt="image placeholder" >
</p>
<p>
[We can all] co-exist without all of us ending up resorting to some sort of technology jihad.
</p>
</blockquote>
<p>
</p>
<p>
Developers are <a href="http://www.codinghorror.com/blog/archives/000247.html">no strangers to technology jihads</a>; it's an occupational hazard. But creating a website that intentionally and maliciously makes content look <i>worse</i> in Internet Explorer 6, well, that's crossing the line from technocentrism into the disturbing realm of <b>technological racism</b>.
</p>
<p>
</p>
<blockquote>
If you happen to be using a non-Internet Explorer browser, let me quickly explain the insanity that is unfolding. It seems some people have intentionally modified their blogs/web sites so that they render differently based on the browser you are using. Usually browser detection is used to ensure that a web site renders properly for a variety of platforms, but now we see that this ability can be used for the reverse. <b>If you are using a version of Internet Explorer you get the web site in black and white coloring and it tends to be very, very ugly. If you are using another browser such as FireFox, it renders in color and the font is actually readable.</b> Internet Explorer users also get a message like "Why pay for black and white when you can get full color for free?" at the top of the page.
</blockquote>
<p>
Although I fully realize that <a href="http://www.codinghorror.com/blog/archives/000242.html">IE6 is the new Netscape 4.7x</a>, such heavy-handed methods are more likely to hurt the cause than advance it. But perhaps Brian's criticism was ultimately taken to heart; the site in question changed to <a href="http://www.roseability.com/">an alert at the top of the page</a> (visible only in IE) instead of actively making the page content painful to read.
</p>
<p>
<a href="http://www.stuffandnonsense.co.uk/">All That Malarkey</a>, a popular CSS design website, does the same thing, but with a decidedly more tongue-in-cheek bent. Here's a side-by-side shot of the same All That Malarkey <a href="http://www.stuffandnonsense.co.uk/archives/3d_css_zen_garden.html">page</a> in IE6 and IE7:
</p>
<p>
<a href="http://www.stuffandnonsense.co.uk/archives/3d_css_zen_garden.html"><img alt="image placeholder" >

<a href="http://www.stuffandnonsense.co.uk/archives/3d_css_zen_garden.html"><img alt="image placeholder" >
</p>
<p>
It's a funny nod to the black-and-white fashion style of <a href="http://en.wikipedia.org/wiki/2_Tone">2 Tone musical artists</a>. If you scroll to the bottom, the joke is revealed:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's clever, but the use of color to discriminate between browsers in both cases is unfortunate; it evokes comparisons with our cultural history of <a href="http://en.wikipedia.org/wiki/Racism">racism</a> and <a href="http://en.wikipedia.org/wiki/Racial_segregation">segregation</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I empathize with the pain that IE6 causes. I really do. But keep the goal in mind: getting people to switch away from a browser that's nearly six years old. <b>The zealotry and vitriol of technological racism is not a particularly effective way to realize change.</b> The best way to get rid of IE6 is through gentle evangelism. Don't waste your time attacking the status quo. Instead, spend your time making the alternatives more attractive by supporting and encouraging them.
</p>
<p>
You'll always get more flies with honey than vinegar.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/technological-racism/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Has Joel Spolsky Jumped the Shark? ]]></title>
<link>https://blog.codinghorror.com/has-joel-spolsky-jumped-the-shark/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
When you're starting out as a technical blogger, you'll inevitably stumble across <a href="http://www.joelonsoftware.com/">Joel on Software</a>. He's been blogging since the year 2000, when computers were hand-carved of wood and the internet transmitted data via carrier pigeon. He has his own <a href="http://www.fogcreek.com/">software development company</a>, a few <a href="http://www.amazon.com/exec/obidos/ASIN/1893115941/codihorr-20%0A">books</a> under his belt, and he's an outstanding and entertaining writer by any measure. In many ways, Joel is a legend.
</p>
<p>
Although Joel's blog entries are generally pure gold, he has generated his fair share of controversy in the last six years. For example, he <a href="http://www.joelonsoftware.com/items/2003/10/13.html">doesn't like programming using exceptions</a>, despite the fact that they are <a href="http://www.nedbatchelder.com/text/exceptions-vs-status.html">the bread and butter</a> of modern programming languages. He also said that <a href="http://www.joelonsoftware.com/articles/ThePerilsofJavaSchools.html">teaching new programmers only Java is liable to poison their minds</a>, although I think Java is <a href="http://www.nedbatchelder.com/blog/20060101T073856.html">the least</a> of any budding new programmer's problems. But a few of Joel's recent posts go far, far beyond these minor gaffes.
</p>
<p>
For instance, two weeks ago we found out that Joel's company wrote their flagship product, FogBugz, in <a href="http://www.joelonsoftware.com/items/2006/09/01.html">a proprietary language they created themselves</a>.
</p>
<p>
</p>
<blockquote>
FogBugz is written in Wasabi, a very advanced, functional-programming dialect of Basic with closures and lambdas and Rails-like active records that can be compiled down to VBScript, JavaScript, PHP4 or PHP5. <b>Wasabi is a private, in-house language written by one of our best developers that is optimized specifically for developing FogBugz</b>; the Wasabi compiler itself is written in C#.
</blockquote>
<p>
You couldn't possibly have heard it, but that was the sound of fifty thousand programmers' heads simultaneously exploding.
</p>
<p>
Writing your own language is absolutely beyond the pale. It's a toxic decision that is so completely at odds with Joel's previous excellent and sane advice on software development that people <i>literally thought he was joking</i>. He had to write <a href="http://www.joelonsoftware.com/items/2006/09/01b.html">an entire follow-up post</a> to explain that, no, he <i>wasn't</i> kidding.
</p>
<p>
Read his <a href="http://www.joelonsoftware.com/items/2006/09/01b.html">defense of Wasabi</a>. If anything, it <i>amplifies</i> the insanity. Because, you know, installing a PHP/NET/Java runtime at a customer site is totally unsupportable, even though it's the business model of 99.9% of the rest of the world. And with Wasabi, they can add any language features they want! Just like Lisp, right? And eventually they'll plug in a .NET CLR back-end to Wasabi and generate bytecode! Never mind the fact that your company's flagship application is still written in a freaky custom language based on <i>VBScript</i> that only three people in the world know how to program.
</p>
<p>
But wait! It gets worse!
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Now Joel says that a dynamically typed language like Ruby <a href="http://www.joelonsoftware.com/items/2006/09/12.html">can't possibly be fast enough to run FogBugz</a>:
</p>
<p>
</p>
<blockquote>
I understand the philosophy that developer cycles are more important than cpu cycles, but frankly that's just a bumper-sticker slogan and not fair to the people who are complaining about performance. Even though our product, FogBugz, seems like something that should be perfect for Ruby on Rails, we have several parts of code where performance is extremely important. In FogBugz 6 there's one place where we need to do literally millions of calculations to display a single chart on a single web page. We have gotten it down to 3 seconds or so in our current development environment with a lot of optimization, but frankly with a duck-typed function call I really don't think we could do it before the web browser gave up and timed out and the sun cooled down a couple of degrees.
</blockquote>
<p>
Let me get this straight. Let me make sure I'm understanding this. Because I think I've gone crosseyed.
</p>
<p>
</p>
<ol>
<li>I don't see how Wasabi-- a language that, per Joel, <i>compiles down to VBScript on Windows</i>-- could actually be faster than Ruby. VBScript certainly isn't compiled, and it isn't exactly known for its blazing speed. Speed improvement is one of the many bullet points used to justify the switch from ASP to ASP.NET.
<p>
</p>
</li>
<li>If performance is so critically important in this section of the code, why wouldn't Joel simply build that section of the code in a compiled language and <i>call it</i> from the other language? Am I missing something here? Is there some law that states all code for a web application must be in the same exact language?
<p>
</p>
</li>
<li>Justifying any language choice based on one tiny section of the code makes no sense whatsoever. It's a complete reversal of the well-known 90/10 rule. If we followed Joel's logic, we should reject all dynamically typed languages. Even in a world filled with 3 gigahertz $200 dual-core CPUs that get cheaper every nanosecond. Because, y'know, there's this one part here that's kinda slow.
</li>
</ol>
<p>
All of this makes me wonder: <b>has Joel Spolsky jumped the shark?</b>
</p>
<p>
I reject this new, highly illogical Joel Spolsky. I demand the immediate return of the sage, sane, wise Joel Spolsky of years past. But maybe it's like wishing for a long-running television show to return to its previous glories.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/has-joel-spolsky-jumped-the-shark/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Vista and the Rise of the Flash Drives ]]></title>
<link>https://blog.codinghorror.com/vista-and-the-rise-of-the-flash-drives/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In my recent <a href="http://www.codinghorror.com/blog/archives/000678.html">Windows Vista performance investigation</a>, I discovered the new <a href="http://www.microsoft.com/windowsvista/features/foreveryone/performance.mspx">ReadyBoost</a> feature. ReadyBoost allows you to <b>augment your PC's performance using a USB flash memory drive.</b> It's very easy to use; just plug in a USB flash drive that's 256 megabytes or larger, then navigate to the ReadyBoost tab on the properties dialog for the drive:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The drive has to meet certain minimum performance characteristics (defined in the <a href="http://blogs.msdn.com/tomarcher/archive/2006/06/02/615199.aspx">ReadyBoost FAQ</a>) to be usable for ReadyBoost. Vista performs a one-time performance benchmark on the drive after it's inserted to determine if the drive is suitable.
</p>
<p>
But what is ReadyBoost actually <i>doing</i> to improve performance? It's leveraging the <b>unique advantages of flash memory</b>..
</p>
<p>
</p>
<ol>
<li>decent read and write speeds
</li>
<li>extremely fast random access times
</li>
<li>very low power consumption
</li>
</ol>
<p>
.. by caching the system pagefile on that USB flash drive.* Subsequent accesses hit the cached, compressed pagefile on the flash drive and bypass the hard drive entirely.
</p>
<p>
If we've gone this far, you might wonder why we just don't go all the way and <a href="http://www.reghardware.co.uk/2006/03/21/samsung_unveils_ssd/">use a giant 32-gigabyte flash drive</a> as our primary hard drive. I can think of three reasons why you wouldn't want to do that:
</p>
<p>
</p>
<ol>
<li>Speed. Flash memory is fast, but it's not nearly as fast a modern hard drive. And it's not even remotely in the same league as system memory.
</li>
<li>Cost. Although flash memory pricing has been in freefall for a while, it's still rather expensive on a cost-per-megabyte basis. This will definitely change over time, however.
</li>
<li>Durability. Flash memory literally wears out after a fixed number of writes, usually 100,000 or so. Hard drives last many orders of magnitude longer.
</li>
</ol>
<p>
Also, the performance benefits of a solid state hard drive-- even one based on ultra-fast battery-backed DDR memory-- <a href="http://www.codinghorror.com/blog/archives/000349.html">aren't as amazing as you might think</a>.
</p>
<p>
That's why the best solution might be a combination of traditional mechanical hard drives <i>and</i> flash memory-- <b>so-called "hybrid" hard drives with embedded flash cache</b>. For example, the <a href="http://www.seagate.com/cda/newsinfo/newsroom/releases/article/0,,3199,00.html">Seagate Momentus 5400 PSD</a> includes 256 megabytes of flash RAM. This feature is called <a href="http://www.microsoft.com/whdc/system/sysperf/accelerator.mspx">ReadyDrive</a>, and it's even better than ReadyBoost. Unlike a USB flash drive, the flash RAM on a hard drive can be read <i>before the system is booted</i>, and thus can be used to speed up boot and resume times, too.
</p>
<p>
It's looking more and more like flash memory is the future. But be careful, because <b>not all flash memory is created equal</b>. I researched USB flash drive performance recently and I found benchmark roundups at <a href="http://www.hardwaresecrets.com/article/321/4">hardware secret</a>,
<a href="http://www.anandtech.com/memory/showdoc.aspx?i=2549&amp;p=1">AnandTech</a>, and
<a href="http://arstechnica.com/reviews/hardware/flash2005.ars/1">Ars Technica</a>. In my research, I found that there are at least three distinct tiers of flash drive performance today: mediocre, good, and best. The price difference between the best performers and the worst performers isn't much, so you might as well buy the fast ones.  The flash drives that performed the best in the above three benchmarks were the <b>Kingston Data Traveller Elite</b> and the <b>Lexar JumpDrive Lightning</b>.
</p>
<p>
Cheap flash drives are cheap for a reason-- they skimp on performance. Here's performance comparison of three USB thumb drives I had on hand: a 1 gigabyte Iomega Micro Mini, a 1 gigabyte Kingston Data Traveler Elite, and a generic no-name 128 megabyte model I got at a trade show.
</p>
<p>
I ran <a href="http://www.sisoftware.net/">SiSoft Sandra's</a> flash memory test on these three drives. The results are summarized below. Note that the bars are stacked, so the total transfer rate is only as high as the largest sub-color in the bar.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
There's a big disparity between read and write performance on flash drives. And small files are disproportionately painful to transfer through these devices. The cheaper the flash drive, the worse these characteristics will be. When you go for an inexpensive USB flash drive, that's the tradeoff you're making.
</p>
<p>
I also ran the <a href="http://www.benchmarkhq.ru/english.html?/be_hdd.html">command line chddspeed utility</a> on these three drives. Here are the results for the random access read test.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Flash memory is exceptionally strong at random access; my fast WD Raptor drive can't touch these scores.
</p>
<p>
Here are the <a href="http://www.benchmarkhq.ru/english.html?/be_hdd.html">chddspeed</a> results for sequential access.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Up to 12 Mb/sec is nothing to sneeze at, but it's nearly 6 times slower than the 68 Mb/sec the Raptor achieves. If you need fast sequential read (or write) speeds, you want a hard drive.
</p>
<p>
After all this analysis, it's clear to me that traditional hard drives and flash memory are quite complimentary; they're strong in different areas. But <b>flash drives are the future</b>. They will definitely replace hard drives in almost all low end and low power devices-- and future high performance hard drives will need to have a substantial chunk of flash memory on board to stay competitive.
</p>
<p>
* Yes, it's encrypted, and yes, it is optimized for the limited duty cycle of flash drives. It's even compressed, so that 1 GB flash drive is effectively 2 GB of cache. This is all covered in the excellent <a href="http://blogs.msdn.com/tomarcher/archive/2006/06/02/615199.aspx">ReadyBoost FAQ</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/vista-and-the-rise-of-the-flash-drives/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ A Visit from the Metrics Maid ]]></title>
<link>https://blog.codinghorror.com/a-visit-from-the-metrics-maid/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
For the last few days, I've been surveying a software project. Landing on a planet populated entirely by an alien ecosystem of source code can be overwhelming. That's why the first first thing I do is bust out my <b>software tricorder</b> -- <a href="http://www.codinghorror.com/blog/archives/000381.html">static code analysis tools</a>.
</p>
<p>
The two most essential static code analysis tools, for .NET projects, are <a href="http://www.ndepend.com/">nDepend</a> and <a href="http://www.gotdotnet.com/team/FxCop/">FxCop</a>. Like real software tricorders, they produce reams and reams of data -- lots of <b>raw metrics on the source code</b>.
</p>
<p>
Even basic metrics can identify potential trouble spots and/or areas of interest in the code, such as..
</p>
<p>
</p>
<ul>
<li>Methods that are too large or too small.
</li>
<li>Classes that are too large or too small.
</li>
<li>Methods that are too complex (as measured by <a href="http://en.wikipedia.org/wiki/Cyclomatic_complexity">cyclomatic complexity</a>).
</li>
<li>Methods with too many parameters (more than <a href="http://www.codinghorror.com/blog/archives/000658.html">7 plus or minus 2</a>).
</li>
<li>Methods with too many local variables.
</li>
<li>Classes with an excessively deep inheritance structure.
</li>
<li>Types that are excessively large.
</li>
</ul>
<p>
These simple metrics are already quite valuable. You can imagine how valuable more advanced software metrics could be, such as <a href="http://software.ericsink.com/articles/Code_Coverage.html">code coverage</a>. Or how quickly you're finding and fixing bugs. And more advanced static analysis tools can offer literally <a href="http://msdn2.microsoft.com/en-us/library/ee1hzekz.aspx">hundreds of recommendations</a>, ranging from mundane to mission-critical.
</p>
<p>
Having more data about your software development project can never be bad. The real trick, of course, lies in interpreting all that data, and deciding how to act on it. There's <b>a huge temptation to become a metermaid-- to use the metrics as a reward or punishment system</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
If Joe wrote a method with a cyclomatic complexity of 52, then he better get slapped with a complexity ticket, right? No excess complexity in the simplicity zone, you idiot!
</p>
<p>
Not necessarily. <b>Responsible use of the metrics is just as important as collecting them in the first place.</b> <a href="http://www.eaipatterns.com/ramblings/41_metrics.html">Gregor Hohpe elaborates</a>:
</p>
<p>
</p>
<blockquote>
Some of the most hated people in San Francisco must be the meter maids, the DPT people who drive around in golf carts and hand out tickets to anyone who overslept street cleaning or did not have enough quarters for the meter. On some projects, the most hated people are the metric maids, the people who go around and try to sum up a developer's hard work and intellectual genius in a number between 1 and 10.
<p>
Many managers love metrics: "You can't manage it if you can't measure it". I am actually a big proponent of extracting and visualizing information from large code bases or running systems (see <a href="http://www.eaipatterns.com/ramblings/11_dependencies.html">Visualizing Dependencies</a>). But when one tries to boil the spectrum between good and evil down to a single number we have to be careful as to what this number actually expresses.
</p>
</blockquote>
<p>
Martin Woodward calls this <a href="http://www.woodwardweb.com/vsts/000284.html">the measurement dilemma</a>.
</p>
<p>
</p>
<blockquote>
The reporting aspects of <a href="http://msdn.microsoft.com/vstudio/teamsystem/team/default.aspx?pull=/library/en-us/dnvs05/html/teamfoundatwrk.asp">Team Foundation Server</a> are a new, more accurate instrument to take measurements inside your software development process. But you need to be wary about the things you measure.  The metrics need to mean something useful rather than just be interesting.  The effect of taking the metric should be carefully considered before taking it.  This is not a new problem. But because <a href="http://msdn.microsoft.com/vstudio/teamsystem/team/default.aspx?pull=/library/en-us/dnvs05/html/teamfoundatwrk.asp">Team Foundation Server</a> makes it so easy to get data out of the system, the temptations are greater.
</blockquote>
<p>
Martin also references the <a href="http://en.wikipedia.org/wiki/Uncertainty_principle">Heisenberg Uncertainty Principle</a>, which states that you can't measure something without changing it. I believe this is true for software development metrics <b>only if you are using that metric to reward or punish.</b>
</p>
<p>
Recording metrics on your project can be beneficial <i>even if you don't explicitly act on them</i>. Having a public "wall of metrics" might be a better idea. It can be a focal point for discussion about what the metrics mean to the team. This gives everyone on the project an opportunity to discuss and reflect, and act on the metrics as they deem appropriate. Maybe the team will even remove a few metrics that are of no value.
</p>
<p>
What metrics do you find helpful on <i>your</i> software projects? What metrics do you find not so helpful? And if you have no project metrics to talk about, well, what are you waiting for?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/a-visit-from-the-metrics-maid/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is Your IDE Hot or Not? ]]></title>
<link>https://blog.codinghorror.com/is-your-ide-hot-or-not/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Scott Hanselman recently brought up the topic of <a href="http://www.hanselman.com/blog/CommentView.aspx?guid=038f7325-ba8e-46d1-a1ad-ecc186167de8">IDE font and color schemes</a> again. I've been in search of the <a href="http://www.codinghorror.com/blog/archives/000157.html">ideal programming font</a> and the <a href="http://www.codinghorror.com/blog/archives/000417.html">ideal syntax colorization scheme</a> for a while now. Here's my current take on it.</p>
<p><img alt="image placeholder" >
<p>As you can see, I've finally <a href="http://www.codinghorror.com/blog/archives/000651.html">given in to the inevitability of ClearType</a>. Someone pointed out the <a href="http://www.vim.org/scripts/script.php?script_id=415">zenburn vim color scheme</a> in the comments. I think it's a nice dark background yin to my light background yang. So I set it up as an alternative for the dark background enthusiasts.</p>
<p><img alt="image placeholder" >
<p>Try these IDE color schemes yourself. Download the exported Visual Studio 2005 Fonts and Colors settings files:</p>
<ul>
<li>
<a href="https://github.com/coding-horror/ide-hot-or-not/raw/master/exported-font-and-colors-for-jeff-atwood-sept-19.zip">Download Jeff's scheme</a> (2kb)
</li>
<li>
<a href="https://github.com/coding-horror/ide-hot-or-not/raw/master/exported-font-and-colors-zenburn.zip">Download "Zenburn" scheme</a> (2kb) (now with HTML, XML, and CSS properties by Geraldo Medrano)
</li>
<li>Download more schemes, and contribute your own, at the <a href="https://studiostyl.es/">Studio Styles</a> site.
</li>
</ul>
<p>To import, use the <strong>Tools | Import and Export Settings</strong> menu in Visual Studio 2005. But be sure you have the necessary fonts installed first  <a href="http://www.microsoft.com/downloads/details.aspx?familyid=22e69ae4-7e40-4807-8a86-b3d36fab68d3">Consolas</a> for the main font and <a href="http://www.donationcoder.com/Software/Jibz/Dina/">Dina</a> for the output console font.</p>
<p>Here's how to export your own IDE font and color settings:</p>
<ul>
<li>Tools | Import and Export Settings...
</li>
<li>Select Export
</li>
<li>Click the All Settings node to unselect everything in the tree
</li>
<li>Expand the tree to "All Settings, Options , Environment"
</li>
<li>Click the "Fonts and Colors" node
</li>
<li>Click next, name the file appropriately, and Finish.
</li>
</ul>
<p>What we really need is for <strong>some enterprising coder to create a "Hot or Not" site for IDE color schemes</strong>, where we can post screenshots and downloadable *.settings files for our preferred IDE color and font schemes. <span style="color: red;">Update:</span> Someone set up <a href="https://studiostyl.es/">Studio Styles</a>.</p>
<p>If we're posting comparative screenshots, it might be a good idea to use the same code sample in each one. Here's the code sample I used in the above screenshot, which highlights some potential programming-specific font legibility issues (O vs. 0, I vs. l, etcetera).</p>
<pre>
#region codinghorror.com
class Program : Object
{
  static int _I = 1;
  /// &lt;summary&gt;
  /// The quick brown fox jumps over the lazy dog
  /// THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG
  /// &lt;/summary&gt;
  static void Main(string[] args)
  {
    Uri Illegal1Uri = new Uri("http://packmyboxwith/jugs.html?q=five-dozen&amp;t=liquor");
    Regex OperatorRegex = new Regex(@"S#$", RegexOptions.IgnorePatternWhitespace);
    for (int O = 0; O &lt; 123456789; O++)
    {
      _I += (O % 3) * ((O / 1) ^ 2) - 5;
      if (!OperatorRegex.IsMatch(Illegal1Uri.ToString()))
      {
        Console.WriteLine(Illegal1Uri);
      }
    }
  }
}
#endregion
</pre>
<p>If you're formulating your own ideal font and color scheme, the only specific advice I have for you is to <a href="http://www.codinghorror.com/blog/archives/000340.html">avoid too much contrast</a>  don't use pure white on pure black, or vice versa. That's why my background is a light grey and not white.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-your-ide-hot-or-not/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ On Unnecessary Namespacing ]]></title>
<link>https://blog.codinghorror.com/on-unnecessary-namespacing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Is it really necessary to qualify everything in Windows Vista with the "Windows" namespace?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Hey, guess what operating system this is!
</p>
<p>
At least the Vista start menu lets me do a containing search, so if I start typing 'fax', the menu dynamically filters itself to show only items <i>containing</i> what I typed. The revamped Start menu is one of my favorite Vista features; it directly addresses <a href="http://www.codinghorror.com/blog/archives/000273.html">XP's abysmal start menu user experience</a>.
</p>
<p>
But still-- <b>what's with all the Windows noise</b>? Wouldn't that list be so much easier to navigate if we deleted the words "Microsoft" and "Windows" from each entry?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I'm sure the very suggestion of dropping those key <i>branding</i> words will drive the marketing weasels apoplectic. But who's more important? The users, or your marketing weasels?* Repeated words, if they're repeated often enough, are just babbling noise.
</p>
<p>
I have a similar problem with the add reference dialog in Visual Studio.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Unfortunately this dialog does not support containing search-- only "starts with" search-- so it's a royal pain to find what I need. This is a concrete example of how <a href="http://www.codinghorror.com/blog/archives/000188.html">unnecessary namespacing hurts usability</a>. Thank goodness the System namespace is actually named <b>System</b> and not "Microsoft.Windows.dotNet.System".
</p>
<p>
* a rhetorical question.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/on-unnecessary-namespacing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ When Understanding means Rewriting ]]></title>
<link>https://blog.codinghorror.com/when-understanding-means-rewriting/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you <i>ask</i> a software developer what they spend their time doing, they'll tell you that they spend most of their time writing code.
</p>
<p>
However, if you actually <i>observe</i> what software developers spend their time doing, you'll find that they spend most of their time <i>trying to understand</i> code:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Peter Hallam <a href="http://blogs.msdn.com/peterhal/archive/2006/01/04/509302.aspx">explains</a>:
</p>
<p>
</p>
<blockquote>
Why is 5x more time spent modifying code than writing new code? New code becomes old code almost instantly. Write some new code. Go for coffee. All of sudden you've got old code. Brand spanking new code reflects at most only the initial design however most design doesn't happen up front. Most development projects use the iterative development methodology. Design, code, test, repeat. Repeat a lot. Only the coding in the first iteration qualifies as all new code. After the first iteration coding quickly shifts to be more and more modifying rather than new coding. Also, almost all code changes made while bug fixing falls into the modifying code category. Look at [the Visual Studio development team]; our stabilization (aka bug fixing) milestones are as long as our new feature milestones. Modifying code consumes much more of a professional developer's time than writing new code.
<p>
Why is 3x more time spend understanding code than modifying code? Before modifying code, you must first understand what it does. This is true of any refactoring of existing code - you must understand the behavior of the code so that you can guarantee that the refactoring didn't change anything unintended. When debugging, much more time is spent understanding the problem than actually fixing it. Once you've fixed the problem, you need to understand the new code to ensure that the fix was valid. Even when writing new code, you never start from scratch. You'll be calling existing code to do most of your work. Either user written code or a library supplied by Microsoft, or a third party for which no source is available. Before calling this existing code you must understand it in precise detail. When writing my first XML enabled app, I spent much more time figuring out the details of the XML class libraries than I did actually writing code. When adding new features you must understand the existing features so that you can reuse where appropriate. <b>Understanding code is by far the activity at which professional developers spend most of their time.</b>
</p>
</blockquote>
<p>
<b>I think the way most developers "understand" code is to rewrite it</b>. <a href="http://www.joelonsoftware.com/articles/fog0000000069.html">Joel thinks rewriting code is always a bad idea</a>. I'm not so sure it's that cut and dried. According to <a href="http://www.amazon.com/exec/obidos/ASIN/055380202X/codihorr-20">The Universe in a Nutshell</a>, here's what was written on <a href="http://en.wikiquote.org/wiki/Richard_Feynman">Richard Feynman's</a> blackboard at the time of his death:
</p>
<p>
</p>
<blockquote>
What I cannot create, I do not understand.
</blockquote>
<p>
It's not that developers <i>want</i> to rewrite everything; it's that very few developers are smart enough to understand code <i>without</i> rewriting it. And as much as I believe in the virtue of reading code, I'm convinced that <a href="http://www.codinghorror.com/blog/archives/000552.html">the only way to get better at writing code is to write code</a>. Lots of it. Good, bad, and everything in between. Nobody wants developers to reinvent the wheel (again), but reading about how a wheel works is a poor substitute for the experience of driving around on a few wheels of your own creation.
</p>
<p>
Understanding someone else's code-- really comprehending how it all fits together-- takes a herculean amount of mental effort. And, even then, <b>is source code truly the best way to understand an application?</b> After reading Nate Comb's <a href="http://terranova.blogs.com/terra_nova/2006/08/heat.html">thought provoking blog entry</a>, I wonder:
</p>
<p>
</p>
<blockquote>
Would Martians wishing to understand the rules of the World of Warcraft (WoW) be better off trying to read its source code or watching video of millions of hours of screen capture?
<p>
The challenge of <a href="http://www.codinghorror.com/blog/archives/000628.html">Reginald's interview question</a> is this: "If someone were to read the source code, do you think they could learn how to play [Monopoly]?"
</p>
<p>
In some ways this challenge hints of the reward of "downhill synthesis" over an "uphill analysis":  who really knows what the rules of WoW are except by grace of the analysis of a million fan websites and trial and error.  Do the developers <b>really know</b>?
</p>
</blockquote>
<p>
I've worked on plenty of applications where, even with the crutch of source code <i>I wrote myself</i>, I had trouble explaining exactly how the application works. Imagine how difficult that explanation becomes with three, five, or twenty developers involved.
</p>
<p>
Does the source code really tell the story of the application? I'm not so sure. Maybe the best way to understand an application is, paradoxically, to ignore the source code altogether. If you want to know how the application really works, observe carefully how users use it. Then go write your own version.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/when-understanding-means-rewriting/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ How big is your Lap, Anyway? ]]></title>
<link>https://blog.codinghorror.com/how-big-is-your-lap-anyway/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Laptop magazine's <a href="http://laptopmag.com/Features/Attack-of-the-20-inch-Notebook.htm">Attack of the 20-inch Notebook</a> is a tongue-in-cheek look at using the <a href="http://www.dell.com/content/products/productdetails.aspx/xpsnb_m2010?c=us&amp;l=en&amp;s=dhs&amp;cs=19">Dell XPS M2010</a> as a portable system in a few different locations.
</p>
<p>
<a href="http://laptopmag.com/Features/Attack-of-the-20-inch-Notebook.htm"><img alt="image placeholder" >
</p>
<p>
Hilarity ensued. For context, here are the relevant specs of this semi-portable concept system:
</p>
<p>
</p>
<ul>
<li>20" LCD
</li>
<li>full-size bluetooth keyboard (with numeric pad)
</li>
<li>16.75" h x 19.25" w x 3" d
</li>
<li>20.3 pounds with AC adapter
</li>
</ul>
<p>
Shades of the original 28 pound <a href="http://www.old-computers.com/MUSEUM/computer.asp?st=1&amp;c=547">Compaq Portable</a>, although the 9" text-mode monochrome monitor and 4.77MHz 8088 aren't nearly as impressive.
</p>
<p>
Although the XPS M2010 is an extreme case, I never quite understood the fascination of those giant 10+ pound desktop replacement laptops. You can even buy batteryless laptops that must be plugged in -- <a href="http://arstechnica.com/news.ars/post/20020715-1987.html">so-called "Mobile PCs"</a>. Isn't <i>portability</i> the whole point of a notebook computer?
</p>
<p>
I adored my three pound Dell Inspiron 300; travelling with it was effortless. I compromised a bit for maximum Vista performance with <a href="http://www.codinghorror.com/blog/archives/000624.html">my 5.5 pound Asus W3J</a>, which is a great machine, but at nearly double the weight it's also a more noticeable burden. That's absolutely as large as I'm willing to go for a laptop. I'd much rather be using an ultraportable like the <a href="http://reviews.cnet.com/Fujitsu_LifeBook_Q2010/4505-3121_7-31959337.html#more">2.2 pound Samsung Q2010</a> or the <a href="http://www.dell.com/content/products/features.aspx/latit_d420?c=us&amp;cs=04&amp;l=en&amp;s=bsd">3 pound Dell D420</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/how-big-is-your-lap-anyway/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Fifty Years of Software Development ]]></title>
<link>https://blog.codinghorror.com/fifty-years-of-software-development/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
O'Reilly's <a href="http://www.oreilly.com/pub/a/oreilly/news/languageposter_0504.html%0A">History of Programming Languages poster</a> is fascinating reading.
</p>
<p>
<a href="http://www.oreilly.com/pub/a/oreilly/news/languageposter_0504.html%0A"><img alt="image placeholder" >
</p>
<p>
If you trace programming languages back to their origins, you'll find that <b>we've been at this programming stuff a long, long time.</b> </p>
<p>
</p>
<ul>
<li>
<a href="http://en.wikipedia.org/wiki/Fortran">Fortran</a> (1954)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/COBOL">Cobol</a> (1959)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Lisp_programming_language">Lisp</a> (1958)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/BASIC_programming_language">Basic</a> (1964)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Forth_programming_language">Forth</a> (1970)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Pascal_programming_language">Pascal</a> (1970)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Smalltalk">SmallTalk</a> (1971)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/C_programming_language">C</a> (1971)
</li>
</ul>
<p>
C is roughly as old as I am; FORTRAN is as old as my parents. But what about the new kids on the block? the TIOBE software <a href="http://www.tiobe.com/tpci.htm%0A">TCPI metrics</a> page provides some data on language popularity going back to the year 2001. Consider the tender age of many of the newest, hippest programming languages:
</p>
<p>
</p>
<ul>
<li>
<a href="http://en.wikipedia.org/wiki/Perl">Perl</a> (1987)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Python_programming_language">Python</a> (1991)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Erlang_programming_language">Erlang</a> (1991)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Ruby_programming_language">Ruby</a> (1993)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/Java_programming_language">Java</a> (1995)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/JavaScript">JavaScript</a> (1995)
</li>
<li>
<a href="http://en.wikipedia.org/wiki/PHP">PHP</a> (1995)
</li>
</ul>
<p>
Ruby is barely a teenager. JavaScript hasn't even hit its teens yet.
</p>
<p>
Now correlate the ages of those modern languages with the publication dates of a few books that represent current thinking in <a href="http://www.codinghorror.com/blog/archives/000643.html">modern software development</a>:
</p>
<p>
</p>
<table>
<tr>
<td>1994</td>
<td>
<a href="http://www.amazon.com/exec/obidos/ASIN/0805353402/codihorr-20">Object-Oriented Design</a> (Booch)
</td>
</tr>
<tr>
<td>1995</td>
<td>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201633612/codihorr-20">Design Patterns</a> (GoF)
</td>
</tr>
<tr>
<td>1997</td>
<td>
<a href="http://www.amazon.com/exec/obidos/ASIN/0321193687/codihorr-20">UML Distilled</a> (Fowler)
</td>
</tr>
<tr>
<td>1999</td>
<td>
<a href="http://www.amazon.com/exec/obidos/ASIN/0321278658/codihorr-20">Extreme Programming Explained</a> (Beck)
</td>
</tr>
<tr>
<td>1999</td>
<td>
<a href="http://www.amazon.com/exec/obidos/ASIN/0201485672/codihorr-20">Refactoring</a> (Fowler)
</td>
</tr>
<tr>
<td>2001</td>
<td>
<a href="http://www.agilealliance.org/">Agile Alliance</a> is formed
</td>
</tr>
</table>
<p>
Modern software development is a recent development. Even though we collectively have over fifty years of experience under our belt, <b>the profession of software development is still very much in its infancy.</b>
</p>
<p>
Consider source control as an example. Source control is the absolute bedrock of software engineering. <b>I believe that source control was not widely prevalent until 1999</b>. Here's why:
</p>
<ol>
<li>Although <a href="http://en.wikipedia.org/wiki/Concurrent_Versions_System">CVS</a> has been around since the late eighties, it was widely popularized through <a href="http://www.sourceforge.org/">SourceForge</a>, which didn't exist until the year 2000.
</li>
<li>Microsoft's SourceSafe was available starting in the mid-90's but didn't hit mainstream acceptance until it was bundled as a part of Visual Studio 6.0 Enterprise in 1998.
</li>
</ol>
<p>
Clearly, source control existed before the year 1999. Why did it take so long for this essential tool of software engineering to filter down to the mainstream? The answer lies in the <a href="http://www.cs.cmu.edu/~Compose/ftp/shaw-fin-etaps.pdf">Redwine-Riddle maturation model</a> (pdf):
</p>
<p>
</p>
<blockquote>
Redwine and Riddle reviewed a number of software technologies to see how they develop and propagate. <b>They found that it typically takes 15-20 years for a technology to evolve from concept formulation to the point where it's ready for popularization.</b>
<p>
They identify six typical phases:
</p>
<ul>
<li>Basic research. Investigate basic ideas and concepts, put initial structure on
the problem, frame critical research questions.
</li>
<li>Concept formulation. Circulate ideas informally, develop a research community, converge on a compatible set of ideas, publish solutions to specific subproblems.
</li>
<li>Development and extension. Make preliminary use of the technology, clarify
underlying ideas, generalize the approach.
</li>
<li>Internal enhancement and exploration. Extend approach to another domain,
use technology for real problems, stabilize technology, develop training materials, show value in results.
</li>
<li>External enhancement and exploration. Similar to internal, but involving a
broader community of people who weren't developers, show substantial evidence
of value and applicability.
</li>
<li>Popularization. Develop production-quality, supported versions of the technology, commercialize and market technology, expand user community.
</li>
</ul>
Redwine and Riddle presented timelines for several software technologies as they progressed through these phases up until the mid-1980s. I presented a similar analysis for the maturation of software architecture in the 1990s.
</blockquote>
<p>
CVS was <a href="http://groups.google.com/groups?:mod.sources.*&amp;ie=UTF-8&amp;c2coff=1&amp;safe=off&amp;selm=122%40mirror.UUCP&amp;rnum=2">released in 1986</a>. It took another fifteen years for CVS usage to become mainstream, <i>exactly as predicted by Redwine-Riddle</i>.
</p>
<p>
The model Redwine-Riddle proposed in 1980 is very much alive today. Mark Dominus, in <a href="http://newbabe.pobox.com/~mjd/blog/prog/design-patterns.html">Design Patterns of 1972</a>, reaches back nearly thirty-five years to illustrate <b>how we're still struggling to evolve our programming languages today</b>:
</p>
<p>
</p>
<blockquote>
Had the "Design Patterns" movement been popular in 1960, its goal would have been to train programmers to recognize situations in which the "subroutine" pattern was applicable, and to implement it habitually when necessary. While this would have been a great improvement over not using subroutines at all, it would have been vastly inferior to what really happened, which was that the "subroutine" pattern was codified and embedded into subsequent languages.
Identification of patterns is an important driver of progress in programming languages. As in all programming, the idea is to notice when the same solution is appearing repeatedly in different contexts and to understand the commonalities. This is admirable and valuable. The problem with the "Design Patterns" movement is the use to which the patterns are put afterward: programmers are trained to identify and apply the patterns when possible. Instead, the patterns should be used as signposts to the failures of the programming language. As in all programming, the identification of commonalities should be followed by an abstraction step in which the common parts are merged into a single solution.
<p>
Multiple implementations of the same idea are almost always a mistake in programming. The correct place to implement a common solution to a recurring design problem is in the programming language, if that is possible.
</p>
<p>
The stance of the "Design Patterns" movement seems to be that it is somehow inevitable that programmers will need to implement Visitors, Abstract Factories, Decorators, and Faades. But these are no more inevitable than the need to implement Subroutine Calls or Object-Oriented Classes in the source language. These patterns should be seen as defects or missing features in Java and C++. <b>The best response to identification of these patterns is to ask what defects in those languages cause the patterns to be necessary, and how the languages might provide better support for solving these kinds of problems.</b>
</p>
</blockquote>
<p>
I do think the pace of change in software development is quickening, thanks to exponential increases in communication over the last fifty years-- television, satellites, cellular phones, and of course the internet. As software developers, we've grown accustomed to computer hardware doubling in speed every 18 months. What we haven't been able to cope with so well is <b>how long it takes for the human beings to catch up with the hardware</b>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/fifty-years-of-software-development/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Company of Heroes ]]></title>
<link>https://blog.codinghorror.com/company-of-heroes/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
My latest gaming obsession is the new <a href="http://en.wikipedia.org/wiki/Real-time_strategy">real-time strategy</a> game, <a href="http://www.companyofheroesgame.com/">Company of Heroes</a>. It's easily one of the best games of the year for the PC. And it's quite possibly one of the best real-time strategy games ever made. To give you an idea of what I'm talking about, the game currently has <a href="http://www.gamerankings.com/htmlpages2/927618.asp">a 95% review average on GameRankings</a> with 13 reviews, which puts it squarely on track to be one of the top 10 best reviewed PC games <i>of all time</i>.
</p>
<p>
It's so good, in fact, that I was compelled to complete <a href="http://www.codinghorror.com/blog/images/company-of-heroes-all-campaign-medals.jpg">every optional objective</a> in the campaign missions.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The <a href="http://www.gamespot.com/promos/2006/companyofheroes-demo/index.html">Company of Heroes demo</a> is a whopping 1.8 gigabytes in size, but it offers a significant chunk of the game: unlimited, unlocked skirmish mode against the CPU and two single player maps.
</p>
<p>
Sure, the World War II genre has been done to death. But this is a real-time strategy game with incredible graphical detail, dynamic, destructible levels, and unparalleled unit intelligence and tactics. It elevates the entire real-time strategy genre to the next level.
</p>
<p>
Company of Heroes is the first new game I installed after installing Vista RC1. Coincidentally, it's also one of the first games with <a href="http://www.xploder.net/news/2297/Microsofts-Games-for-Windows-Plans.htm">Microsoft's "Games for Windows" certification</a>, which means (among other things) that it <a href="http://blogs.vertigosoftware.com/ericc/archive/2006/09/18/3700.aspx">integrates automatically into Vista's Games menu</a>.
</p>
<p>
Needless to say, highly recommended. If you've ever played and enjoyed an RTS game of any type, buy this game immediately. For everyone else, <a href="http://www.gamespot.com/promos/2006/companyofheroes-demo/index.html">get the demo</a> and try it yourself. I think you'll be impressed.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/company-of-heroes/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Why Does Vista Use All My Memory? ]]></title>
<link>https://blog.codinghorror.com/why-does-vista-use-all-my-memory/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Windows Vista has a <b>radically different approach to memory management</b>. Check out the "Physical Memory, Free" column in my Task Manager:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
At the time this screenshot was taken, this machine had a few instances of IE7 running, plus one remote desktop. I'm hardly doing anything at all, yet <i>I only have 6 megabytes of free physical memory</i>.
</p>
<p>
Now compare with this screenshot of Windows XP's Task Manager under similar low-load conditions:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Under "Physical Memory, Available" I have approximately 1.5 gigabytes of free physical memory, as you'd expect.
</p>
<p>
So what's going on here? Why is Vista using so much memory when I'm doing so very little?
</p>
<p>
To answer that question, you have to consider what your computer's physical memory (RAM) is <i>for</i>. Just as a hypothetical, let's say you wanted to create a new text file:
</p>
<p>
</p>
<ol>
<li>You double-click on the notepad icon.
</li>
<li>The Notepad executable loads from disk into memory.
</li>
<li>Notepad executes.
</li>
<li>Notepad allocates free memory to store your text document.
</li>
</ol>
<p>
So Notepad clearly needs a little memory for itself: enough to execute, and to store the contents of the text document it's displaying. But that's maybe a couple megabytes, at most. If even that. What about the other 2,046 megabytes of system memory?
</p>
<p>
You have to stop thinking of system memory as a resource and start thinking of it as a a cache. Just like the <a href="http://en.wikipedia.org/wiki/CPU_cache">level 1 and level 2 cache on your CPU</a>, system memory is yet another type of high-speed cache that sits between your computer and the disk drive.
</p>
<p>
And the most important rule of cache design is that <b>empty cache memory is wasted cache memory.</b> Empty cache isn't doing you any good. It's expensive, high-speed memory sucking down power for zero benefit. The primary mission in the life of every cache is to populate itself as quickly as possible with the data that's most likely to be needed-- and to consistently deliver a high "hit rate" of needed data retrieved from the cache. Otherwise you're going straight to the hard drive, mister, and <b>if you have to ask how much going to the hard drive will cost you in performance, you can't afford it</b>.
</p>
<p>
Diomidis Spinellis <a href="http://www.spinellis.gr/pubs/trade/2006-login-memhier/html/memhier.html">published</a> an excellent breakdown of the cache performance ratios in a typical PC circa January 2006:
</p>
<p>
</p>
<table border="1">
<tr>
<td></td>
<td align="right">Nominal	</td>
<td align="right">Worst case	</td>
<td align="right">Sustained	</td>
<td align="right"></td>
<td align="center" colspan="2">Productivity </td>
</tr>
<tr>
<td>Component	</td>
<td align="right">size		</td>
<td align="right">latency	</td>
<td align="right">throughput 	</td>
<td align="right">$1 buys	</td>
<td align="center" colspan="2">(Bytes read / s / $) </td>
</tr>
<tr>
<td></td>
<td align="right"></td>
<td align="right"></td>
<td align="right">(MB/s)	</td>
<td align="right"></td>
<td>Worst case		</td>
<td>Best case </td>
</tr>
<tr>
<td>L1 D cache	</td>
<td align="right">64 KB	</td>
<td align="right">1.4ns		</td>
<td align="right">19022		</td>
<td align="right">10.7 KB	</td>
<td>7.9110<sup>12</sup>	</td>
<td>2.1910<sup>14</sup> </td>
</tr>
<tr>
<td>L2 cache	</td>
<td align="right">512 KB	</td>
<td align="right">9.7ns		</td>
<td align="right">5519		</td>
<td align="right">12.8 KB	</td>
<td>1.3510<sup>12</sup>	</td>
<td>7.6110<sup>13</sup> </td>
</tr>
<tr>
<td>DDR RAM	</td>
<td align="right">256 MB	</td>
<td align="right">28.5ns	</td>
<td align="right">2541		</td>
<td align="right">9.48 MB	</td>
<td>3.4810<sup>14</sup>	</td>
<td>2.6510<sup>16</sup> </td>
</tr>
<tr>
<td>Hard drive	</td>
<td align="right">250 GB	</td>
<td align="right">25.6ms	</td>
<td align="right">67		</td>
<td align="right">2.91 GB	</td>
<td>1.2210<sup>11</sup>	</td>
<td>2.1710<sup>17</sup> </td>
</tr>
</table>
<p>
In summary, here's how much faster each cache memory type in your computer is than the hard drive:
</p>
<p>
</p>
<table width="400px">
<tr>
<td>System memory</td>
<td>37x faster
</td>
</tr>
<tr>
<td>CPU Level 2 cache</td>
<td>82x faster
</td>
</tr>
<tr>
<td>CPU Level 1 cache</td>
<td>283x faster
</td>
</tr>
</table>
<p>
Those figures explain why I only have 6 megabytes of "free" memory in Windows Vista. <b>Vista is trying its darndest to pre-emptively populate every byte of system memory with what it thinks I might need next.</b> It's running a low-priority background task that harvests previously accessed data from the disk and plops it into unused system memory. They even have a fancy marketing name for it-- <a href="http://www.microsoft.com/windowsvista/features/foreveryone/performance.mspx">SuperFetch</a>:
</p>
<p>
</p>
<blockquote>
In previous versions of Windows, system responsiveness could be uneven. You may have experienced sluggish behavior after booting your machine, after performing a fast user switch, or even after lunch. Although too many carbohydrates might slow you down after lunch, your computer slows down for different reasons. When you're not actively using your computer, background tasks --  including automatic backup and antivirus software scans --  take this opportunity to run when they will least disturb you. These background tasks can take space in system memory that your applications were using. After you start to use your PC again, it can take some time to reload your data into memory, slowing down performance.
<p>
SuperFetch understands which applications you use most, and preloads these applications into memory, so your system is more responsive. SuperFetch uses an intelligent prioritization scheme that understands which applications you use most often, and can even differentiate which applications you are likely to use at different times (for example, on the weekend versus during the week), so that your computer is ready to do what you want it to do. Windows Vista can also prioritize your applications over background tasks, so that when you return to your machine after leaving it idle, it's still responsive.
</p>
</blockquote>
<p>
This isn't a new concept, of course. But <b>Vista treats system memory like a cache much more aggressively and effectively than any other version of Windows</b>. As alluded to in the above lunch anecdote-- and as you can see from the Task Manager screenshot above-- Windows XP has no qualms whatsoever about leaving upwards of a gigabyte of system memory empty. From a caching perspective, this is unfathomable. Vista tries its damndest to fill that empty system memory cache as soon as it can.
</p>
<p>
Although I am a total believer in the system-memory-as-cache religion, SuperFetch can still have some undesirable side effects. I first noticed that something was up when I fired up Battlefield 2 under Vista and joined a multiplayer game. Battlefield 2 is something of a memory hog; the game regularly uses a gigabyte of memory on large 64-player multiplayer maps. During the first few minutes of gameplay, I noticed that the system was a little sluggish, and the drive was running constantly. This was very unusual and totally unlike the behavior under Windows XP. Once the map is loaded and you join the game, the entire game is in memory. What could possibly be loading from disk at that point? Well, SuperFetch saw a ton of memory freed to make room for the game, and dutifully went about filling the leftover free memory on a low-priority background disk thread. Normally, this would be no big deal, but even a low-priority background disk thread is pretty noticeable when you're playing a twitch shooter online with 63 other people at a resolution of 1600x1200.
</p>
<p>
I'm perfectly fine letting SuperFetch have its way with my system memory. <b>The question shouldn't be "Why does Vista use all my memory?", but "Why the heck did previous versions of Windows use my memory so ineffectively?"</b> I don't know. Maybe the rules were different before 2 gigabytes was a mainstream memory configuration.
</p>
<p>
The less free memory I have, the better; every byte of memory should be actively working on my behalf at all times. However, I do wish there was a way to tell SuperFetch to ixnay on the oadinglay when I'm gaming.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/why-does-vista-use-all-my-memory/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Changing Your Organization (for Peons) ]]></title>
<link>https://blog.codinghorror.com/changing-your-organization-for-peons/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
James Shore's <a href="http://www.jamesshore.com/Change-Diary/">nineteen-week change diary</a> is fascinating reading:
</p>
<p>
</p>
<blockquote>
<img alt="image placeholder" >
It was 2002. The .com bust was in full slump and work was hard to find. I had started my own small business as an independent consultant at the worst possible time: the end of 2000, right as the bubble popped. I had some noteworthy successes doing what I loved: coaching agile Extreme Programming (XP) teams in doing great work for a valuable purpose. And then the work dried up.
<p>
Eventually I admitted that I was going to have to find some "real" work to fill the gap. I took a contract job as a programmer on a team customizing some web software for a large institutional customer. This team was the opposite of agile. I was bored and frustrated. It didn't take me long to remember Martin Fowler's advice. As a peon, could I make the kinds of changes I made as a (damned good!) XP coach? Or would they kick me out, causing me to change organizations a little more abruptly?
</p>
</blockquote>
<p>
James' story is an interesting one because he was <b>attempting to effect organizational change with no formal power</b>. He was, after all, merely a developer on the project. It's a bittersweet story of success and failure, but it does show that one developer <i>can</i> make a difference.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/changing-your-organization-for-peons/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Making Developers Cry Since 1995 ]]></title>
<link>https://blog.codinghorror.com/making-developers-cry-since-1995/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p><a href="http://blogs.msdn.com/micahel/">Michael Hunter's blog</a> byline is unapologetically over-the-top: <em>making developers cry since 1995</em>.</p>
<p><img alt="image placeholder" >
<p>That's probably why he's such an awesome tester. Well, that, and the braids. Never before in the history of testing professionals have the top and bottom halves of a man's head been so mismatched.*</p>
<p>The absolute worst testers you can possibly have are developers. They're better than nothing. But <em>barely</em>. Even a mediocre tester will make your application better, and by proxy, encourage you to become a better developer. The very best testers will drag you, kicking and screaming if necessary, across the bug-bar threshold. <strong>Professional testers force you to become a better developer.</strong> Sometimes it's painful. But in a good way, like a heavy workout.</p>
<p>To get an idea of how gnarly the work of a test professional actually is, take a look at Michael's <a href="http://blogs.msdn.com/micahel/articles/175571.aspx">Did I Remember To (test)</a> list. I can barely read the first page without wincing in sympathetic pain. And the list goes on, and on, and <em>on</em>.</p>
<p>Michael recently expanded that list into an entire series of blog entries for DDJ titled "You are not done yet", which are now captured in handy PDF form -- <b><a href="http://www.thebraidytester.com/downloads/YouAreNotDoneYet.pdf">Michael Hunter's You Are Not Done Yet Checklist</a>.</b>
</p>
<p>
</p>
<blockquote>
Pick something. Anything. A feature in your favorite software application, your favorite toy, your favorite piece of furniture. Now start brainstorming things you could do to test it. Think of as many different things to do to that object as you can. Come back and continue reading when youre done.
<p>
Whats that? Youre back already? There are test cases you havent thought of, I guarantee it. How do I know? Because for even the tiniest bit of something  the Find dialog box in your web browser, say, there are billions of possible test cases. Some of them are likely to find interesting issues and some of them arent. Some of them we execute because we want to confirm that certain functionality works correctly. These latter cases are the basis of my You Are Not Done Yet list.
</p>
<p>
This list is large and can be overwhelming at first. Fear not. You have probably already covered many of these cases. Others wont be applicable to your situation. Some may be applicable yet you will decide to pass on them for some reason or other. Verifying you have executed each of these test cases is not the point of the list. The point is to get you thinking about all of the testing you have and have not done and
point out areas you meant to cover which you havent yet.
</p>
<p>
So dont quail at the thought of all this testing you havent done yet. Instead, customize this list to your context. Scratch off items which do not apply. Use the list as a launch point for finding items not on it which do apply. Use it to organize your testing before you start. Use it as a last-minute checklist before you finish. How you use it is not nearly as important as that you use it in the first place.
</p>
</blockquote>
<p>
</p>
<p>Brrr. It's enough to make you hang up <a href="http://www.jonathancoulton.com/2006/04/14/thing-a-week-29-code-monkey/">your Tab and Fritos</a> to become a console developer. But if you can pass that testing gauntlet, <strong>you've definitely earned your stripes as a seasoned software developer</strong>.</p>
<p>* I kid! I kid because I love! <span style="font-size: xx-small;">please don't test my app</span></p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/making-developers-cry-since-1995/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Multitasking Myth ]]></title>
<link>https://blog.codinghorror.com/the-multi-tasking-myth/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In <a href="http://www.amazon.com/exec/obidos/ASIN/0932633226/codihorr-20">Quality Software Management: Systems Thinking</a>, Gerald Weinberg proposed a rule of thumb to calculate the waste caused by project switching:</p>
<img alt="image placeholder" >
<p>Even adding a single project to your workload is profoundly debilitating by Weinberg's calculation. You lose 20% of your time. By the time you add a third project to the mix, nearly half your time is wasted in task switching.<br>
This can be a problem even if you're only working on a single project at any time. The impact of simply letting your email, phone, and instant messaging interrupt what you're doing can be profound, as documented in this <a href="http://news.bbc.co.uk/1/hi/uk/4471607.stm">BBC study</a>:</p>
<blockquote>
<p>The study, carried out at the Institute of Psychiatry, found excessive use of technology reduced workers' intelligence. <strong>Those distracted by incoming email and phone calls saw a 10-point fall in their IQ - more than twice that found in studies of the impact of smoking marijuana</strong>, said researchers.</p>
</blockquote>
<p>Kathy Sierra wrote a great <a href="http://headrush.typepad.com/creating_passionate_users/2005/03/your_brain_on_m.html">post comparing multi-tasking and serial tasks</a> and followed it up a year later with a typically insightful post proposing that <a href="http://headrush.typepad.com/creating_passionate_users/2006/03/multitasking_ma.html">multi-tasking makes us stupid</a>:</p>
<blockquote>
<p>Perhaps the biggest problem of all, though, is that the majority of people doing the most media multitasking have a big-ass blind spot on just how much they suck at it.</p>
<p>We <em>believe</em> we can e-mail and talk on the phone at the same time, with little or no degradation of either communication.</p>
<p>We <em>believe</em> we can do homework while watching a movie.</p>
<p>We <em>believe</em> we can surf the web while talking to our kids/spouse/lover/co-worker.</p>
</blockquote>
<blockquote>
<p><strong>But we can't!</strong> Not without a hit on every level  time, quality, and the ability to think deeply.</p>
</blockquote>
<p>Joel Spolsky <a href="http://www.joelonsoftware.com/articles/fog0000000022.html">compares the task switching penalty for computers and computer programmers</a>:</p>
<blockquote>
<p>The trick here is that when you manage programmers, specifically, task switches take a really, really, really long time. That's because programming is the kind of task where you have to keep a lot of things in your head at once. The more things you remember at once, the more productive you are at programming. A programmer coding at full throttle is keeping zillions of things in their head at once: everything from names of variables, data structures, important APIs, the names of utility functions that they wrote and call a lot, even the name of the subdirectory where they store their source code. If you send that programmer to Crete for a three week vacation, they will forget it all. The human brain seems to move it out of short-term RAM and swaps it out onto a backup tape where it takes forever to retrieve.</p>
</blockquote>
<p>I've often pushed back on demands to work on multiple projects at the same time. It can be <a href="http://blog.codinghorror.com/just-say-no/">difficult to say no</a>, because software developers are notoriously prone to the <a href="http://blog.codinghorror.com/defeating-optimism/">occupational hazard of optimism</a>.</p>
<p>We typically <a href="http://blog.codinghorror.com/how-good-an-estimator-are-you/">overestimate how much we'll actually get done</a>, and multi-tasking exaggerates our own internal biases even more. Whenever possible, avoid interruptions and avoid working on more than one project at the same time.  If it's unavoidable, <strong>be brutally honest with yourself  and your stakeholders  about how much you can actually get done under multi-tasking conditions.</strong> It's probably less than you think.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-multi-tasking-myth/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Hard Drives -- breaking the Terabyte Barrier ]]></title>
<link>https://blog.codinghorror.com/hard-drives-breaking-the-terabyte-barrier/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I recently upgraded my home system with one of the 750 gigabyte Seagate <a href="http://www.hitachigst.com/hdd/research/recording_head/pr/PerpendicularAnimation.html">perpendicular drives</a> in order to consolidate a number of hard drives I had on my server. 750 gigabytes is a tremendous amount of storage space in a single drive-- but it doesn't quite get us across the magical terabyte threshold. It's looking more and more like <b>the first terabyte desktop hard drive</b> will arrive <a href="http://arstechnica.com/news.ars/post/20060815-7509.html">sometime in 2007</a>.
</p>
<p>
Let's take a look back at the other magical thresholds we broke through on the way -- when were 1 gigabyte, 10 gigabyte, and 100 gigabyte drives released?
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The data points are derived from <a href="http://www.alts.net/ns1625/winchest.html">this chart</a>; the scale of the graph is logarithmic. The pace of capacity increase has dampened a bit since 2001, but <a href="http://www.hitachigst.com/hdd/research/recording_head/pr/PerpendicularAnimation.html">perpendicular technology</a> has gotten us (mostly) back on track.
</p>
<p>
I remember how excited I was to get my first gigabyte, 10 gigabyte, and 100 gigabyte hard drives back in the day. I've long since stopped worrying about room for applications and even games. It's all media and virtual PC storage these days. Of course, <i>finding</i> things on such a large drive is another matter.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-28T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/hard-drives-breaking-the-terabyte-barrier/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ I Rock at BASIC ]]></title>
<link>https://blog.codinghorror.com/i-rock-at-basic/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>How in the world wide web did I not know about the <a href="http://glarkware.com/adult/i-rock-at-basic">"I Rock at BASIC" t-shirt</a>?</p>
<p><a href="http://glarkware.com/adult/i-rock-at-basic"><img alt="image placeholder" >
</a></p>
<p>We've all written this program at some point in our careers. But only those of us who truly rock at BASIC.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-09-29T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/i-rock-at-basic/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Anything But Waterfall ]]></title>
<link>https://blog.codinghorror.com/anything-but-waterfall/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Steve Yegge's <a href="http://steve-yegge.blogspot.com/2006/09/good-agile-bad-agile_27.html">scathing criticism of agile methodologies</a> takes a page from <a href="http://www.codinghorror.com/blog/archives/000679.html">Joel Spolsky's book</a>. It's not merely an indictment of <a href="http://www.agilealliance.com">Agile</a>, it's <i>also</i> a celebration of how his company does business. Just substitute "Google" for "Fog Creek Software" and you'll get the idea.
</p>
<p>
It's a long post, so I'll save you the effort of reading it: <b>if you're practicing Agile and you don't work at Google, you're probably doing it wrong.</b> Here's how Google does it:
</p>
<p>
</p>
<blockquote>
<ul>
<li>There are managers, sort of, but most of them code at least half-time, making them more like tech leads.
<p>
</p>
</li>
<li>Developers can switch teams and/or projects any time they want, no questions asked; just say the word and the movers will show up the next day to put you in your new office with your new team.
<p>
</p>
</li>
<li>Google has a philosophy of not ever telling developers what to work on, and they take it pretty seriously.
<p>
</p>
</li>
<li>Developers are strongly encouraged to spend 20% of their time (and I mean their M-F, 8-5 time, not weekends or personal time) working on whatever they want, as long as it's not their main project.
<p>
</p>
</li>
<li>There aren't very many meetings. I'd say an average developer attends perhaps 3 meetings a week, including their 1:1 with their lead.
<p>
</p>
</li>
<li>It's quiet. Engineers are quietly focused on their work, as individuals or sometimes in little groups or 2 to 5.
<p>
</p>
</li>
<li>There aren't Gantt charts or date-task-owner spreadsheets or any other visible project-management artifacts in evidence, not that I've ever seen.
<p>
</p>
</li>
<li>Even during the relatively rare crunch periods, people still go get lunch and dinner, which are (famously) always free and tasty, and they don't work insane hours unless they want to.
<p>
</p>
</li>
<li>Google drives behavior through incentives. Engineers working on important projects are, on average, rewarded more than those on less-important projects. The rewards and incentives are too numerous to talk about here, but the financial incentives range from gift certificates and massage coupons up through giant bonuses and stock grants.
<p>
</p>
</li>
<li>Google is a peer-review oriented culture, and earning the respect of your peers means a lot there. More than it does at other places, I think. [..] your actual performance review is almost entirely based on your peer reviews, so it has an indirect financial impact on you.
<p>
</p>
</li>
<li>[Google] has a long all-hands in which they show every single project that launched to everyone, and put up the names and faces of the teams (always small) who launched each one, and everyone applauds.
</li>
</ul>
</blockquote>
<p>
If nothing else, it's an interesting window into Google's software development process.
</p>
<p>
The whole FogCreek/Google-Is-So-Totally-Awesome thing is an annoyance. But I have a deeper problem with this post. I think Steve's criticisms of agile are hysterical and misplaced; <b>attacking Agile is a waste of time because most developers <i>haven't even gotten there yet!</i></b> The real enemy isn't Agile, it's <a href="http://en.wikipedia.org/wiki/Waterfall_model">Waterfall</a> and <a href="http://en.wikipedia.org/wiki/Big_Design_Up_Front">Big Design Up Front</a>. Even "bad" Agile is a huge quality of life improvement for developers stuck in the dark ages of BDUF. I know because I've been there.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Rather than wasting time and effort on discriminating between "good" and "bad" Agile, we should be <b>banding together in the name of Anything But Waterfall.</b> The fact that some maladjusted developer or project manager could use Steve's well-written, reasonable sounding rant as a justification to keep their project in the dark ages of Waterfall and BDUF absolutely <i>kills</i> me. Who is the real enemy here?
</p>
<p>
I'm not the only person with criticisms of Steve's rant. Dare Obasanjo <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=2f33ca2b-56ae-4328-936b-22d0913f8d5c">notes</a> that the talent meritocracy at Google sounds disturbingly similar to the one outlined in Malcolm Gladwell's <a href="http://www.gladwell.com/2002/2002_07_22_a_talent.htm">The Talent Myth</a>:
</p>
<p>
</p>
<blockquote>
This "talent mind-set" is the new orthodoxy of American management. It is the intellectual justification for why such a high premium is placed on degrees from first-tier business schools, and why the compensation packages for top executives have become so lavish. In the modern corporation, the system is considered only as strong as its stars, and, in the past few years, this message has been preached by consultants and management gurus all over the world. None, however, have spread the word quite so ardently as McKinsey, and, of all its clients, one firm took the talent mind-set closest to heart. It was a company where McKinsey conducted twenty separate projects, where McKinsey's billings topped ten million dollars a year, where a McKinsey director regularly attended board meetings, and where the C.E.O. himself was a former McKinsey partner. <b>The company, of course, was Enron.</b>
</blockquote>
<p>
Read <a href="http://www.gladwell.com/2002/2002_07_22_a_talent.htm">the rest of the article</a>; the similarities are truly startling. <b>It's not very reassuring to think that the only difference between Enron and Google is their "Don't be evil" motto.</b> We now have laws in place to protect us from Enron, eg, <a href="http://en.wikipedia.org/wiki/Sarbanes-Oxley_Act">Sarbanes-Oxley</a>. I'm not aware of any pending motto enforcement acts. Yet.
</p>
<p>
Wes Felter <a href="http://wmf.editthispage.com/2006/09/28">
calls it "a great rant"</a>, but also cleverly juxtaposes two of Steve's sentences to illustrate a point:
</p>
<p>
</p>
<blockquote>
This nickel-a-line-of-code gig is lame. You know where the real money is at? <b>You start your own religion.</b> [...] There is nothing like it on the face of this earth. I could talk for hours, days about how amazing it is to work at Google, and I wouldn't be done. And they're not done either. Every week it seems like there's a new perk, a new benefit, a new improvement, a new survey asking us all if there's any possible way in which life at Google could be better.
</blockquote>
<p>
One wonders if the "good" agile at Google isn't just as much of a religion as the "bad" Agile.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/anything-but-waterfall/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is Software Development Like Manufacturing? ]]></title>
<link>https://blog.codinghorror.com/is-software-development-like-manufacturing/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We've adopted <a href="http://en.wikipedia.org/wiki/Scrum_(management)">Scrum</a> for all of our software development at Vertigo. Although I'm totally in favor of <a href="http://www.codinghorror.com/blog/archives/000694.html">Anything But Waterfall</a>, Scrum is an unfortunate name:
</p>
<ol>
<li>It's two additional characters away from <a href="http://en.wikipedia.org/wiki/Scrotum">a term for male genitalia</a>.
</li>
<li>The term is derived from <a href="http://en.wikipedia.org/wiki/Rugby_football">rugby</a>, an extraordinarily violent sport. During my first year at college, a guy on our hall participated in Rugby. His ongoing injuries, both small and large, became a running joke in the dorm. Eventually even he started to re-evaluate the merits of the sport. As Steve <a href="http://steve-yegge.blogspot.com/2006/09/good-agile-bad-agile_27.html">pointed out</a>, Wikipedia defines scrum as <i>".. the most dangerous phase in rugby, since a collapse or inproper engage can lead to a front row player damaging or even breaking his neck."</i> My indirect experience with rugby leads me to agree. The most dangerous phase of a violent sport is not exactly the sort of thing you <i>want</i> to add to your project.
</li>
<li>When you tell customers your software developers use the Scrum process, they have absolutely no idea what you're talking about.
</li>
</ol>
<p>
We usually say "agile" to avoid all the weird connotations of the word Scrum.
</p>
<p>
To promote understanding of Scrum, and Agile software development in general, everyone at Vertigo got a copy of Mary and Tom Poppendieck's book, <a href="http://www.amazon.com/exec/obidos/ASIN/0321150783/codihorr-20">Lean Software Development: An Agile Toolkit</a>. I was inclined to like the book, because I'm a big fan of Mary Poppendieck's article <a href="http://www.poppendieck.com/pdfs/Compensation.pdf">Team Compensation</a> (pdf).*
</p>
<p>
Although the book is great, the Poppendiecks <b>spend a lot of their time drawing parallels between software development and manufacturing</b>. Every few pages, you'll find some example from a classic manufacturing company: Ford, L.L. Bean, GM, Dell, Toyota, etcetera. Although the examples do extend beyond the manufacturing sector, they're definitely dominated by it.
</p>
<p>
Perhaps this makes sense if you consider that <b>Scrum originated in manufacturing</b>:
</p>
<p>
</p>
<blockquote>
Scrum was named as a project management style in auto and consumer product manufacturing companies by Takeuchi and Nonaka in "The New New Product Development Game" (Harvard Business Review, Jan-Feb 1986). Jeff Sutherland, John Scumniotales, and Jeff McKenna documented, conceived and implemented Scrum as it is described below at Easel Corporation in 1993, incorporating team managment styles noted by Takeuchi and Nonaka. In 1995, Ken Schwaber formalized the definition of Scrum and helped deploy it worldwide in software development.
</blockquote>
<p>
The manufacturing examples presented in the book don't resonate with me at all. <b>I'm not convinced that manufacturing industries and software development have much, if anything, in common.</b> Fortunately, the Poppendiecks address this criticism early in the book:
</p>
<p>
</p>
<blockquote>
The origins of lean thinking lie in production, but lean <i>principles</i> are broadly applicable to other disciplines. However, lean production <i>practices</i> -- specific guidelines on what to do -- cannot be transplanted directly from a manufacturing plant to software development. Many attempts to apply lean production practices to software development have been unsuccessful because generating good software is not a production process; it is a development process.
<p>
Development is quite different than production. Think of development as creating a recipe and production as following the recipe. Thse are very different activities, and they should be carried out with different approaches. Developing a recipe is a learning process involving trial and error. You would not expect an expert chef's first attempt at a new dish to be the last attempt. In fact, the whole idea of developing a recipe is to try many variations on a theme and discover the best dish.
</p>
<p>
Once a chef has developed a recipe, preparing the dish means following the recipe. This is equivalent to manufacturing, where the objective is to faithfully and repeatedly reproduce a "recipe" with a minimum of variation.
</p>
</blockquote>
<p>
In many ways, software development is the antithesis of manufacturing:
</p>
<p>
</p>
<ul>
<li>
<b>Variability is the enemy in manufacturing</b>; in software, it's the reason we get up in the morning. Every worthwhile software development project is a custom one-off job for a unique problem.
</li>
<li>
<b>Requirements are the bread and butter of manufacturing</b>; in software, we rarely have meaningful requirements. Even if we do, the only measure of success that matters is whether our solution solves the customer's shifting idea of what their problem is.
</li>
</ul>
<p>
I suppose the proof is in the pudding; if Scrum works for manufacturers and software development shops alike, then maybe the parallels between the two industries are valid. Still, I think <a href="http://www.amazon.com/exec/obidos/ASIN/0321150783/codihorr-20">Lean Software Development: An Agile Toolkit</a> would be a much stronger book if it relied more on examples from actual software development efforts and less on examples from the movie <a href="http://www.imdb.com/title/tt0091159/">Gung Ho</a>.
</p>
<p>
* which I discovered through Joel Spolsky's <a href="http://www.amazon.com/exec/obidos/ASIN/1590595009/codihorr-20">The Best Software Writing I</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-software-development-like-manufacturing/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ On Frameworkitis ]]></title>
<link>https://blog.codinghorror.com/on-frameworkitis/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Alex Gorbatchev, after a long hiatus, is <a href="http://www.dreamprojections.com/">blogging again</a>. What was keeping him away? <a href="http://www.codinghorror.com/blog/archives/000450.html">Frameworkitis</a>.
</p>
<p>
</p>
<blockquote>
This is the longest break in posting I've had in the last 2.5 years of blogging. Community Server is really bringing me down I just don't like it.
<p>
So, I started working on my own blog engine for like the 6th time. This time it's different. It's actually moving ahead. Not so long ago I read an article about how to stay productive on a project. One thing that I took away from it, was the most crippling problem in all my previous projects - <b>procrastinating via developing frameworks. Every time I have started working on my own blog, I delved deep into creating frameworks and [needless] to say, none of my previous 5 attempts went even as far as being able to post a new entry.</b>
</p>
<p>
It really is very hard trying to stay away from creating libraries, thinking about future uses and what extra things I can put in that might used in the future. <b>Simply creating code that works and only does what I need it to really helps to move things ahead.</b>
</p>
</blockquote>
<p>
Indeed.
</p>
<p>
Can you guess what the number one sin in <a href="http://blogs.msdn.com/ericgu/archive/2006/08/03/687962.aspx">Eric Gunnerson's Seven Deadly Sins of Programming</a> is? I bet you can.
</p>
<p>
Although I'll admit I've been sorely tempted myself, I wonder if <a href="http://performancing.com/node/64">writing your own blog software</a> isn't a form of procrastination in and of itself.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/on-frameworkitis/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Building and Overclocking a Core 2 Duo System ]]></title>
<link>https://blog.codinghorror.com/building-and-overclocking-a-core-2-duo-system/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's been over a year since I built my last PC, and all those killer Core 2 Duo benchmark and overclocking results were making me anxious. I just pulled the trigger on the following Core 2 Duo upgrade:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16813131045">ASUS P5B Deluxe</a> motherboard, $195
</li>
<li>
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16820211061">A-DATA 2GB DDR2 667</a> memory, $199
</li>
<li>
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16819115003">Core 2 Duo E6600</a> CPU, $318
</li>
<li>
<a href="http://www.newegg.com/Product/Product.asp?Item=N82E16835185027">Scythe Infinity</a> heatsink, $58
</li>
</ul>
<p>
I'm not replacing my video card, hard drive, power supply, or case. This is a straight "drop in" replacement for my existing Athlon X2 4800+.
</p>
<p>
First, a few words on why I chose these specific parts. Computer hardware is one of my few indulgences, but I do a freakishly obsessive amount of research before buying anything. Allow me to share my freakish obsession with you, dear reader. After all, that's what the internet is for.
</p>
<p>
</p>
<ol>
<li>
<b>Motherboard.</b> The 965 Express was <a href="http://techreport.com/reviews/2006q3/core2-chipsets/">an editors' choice at Tech Report</a>. It's the most modern chipset for the Core 2 Duo, too. ASUS is a well respected brand name, and I really like the fact that it has a silent heatpipe on the northbridge instead of a fan. Modern northbridges run very hot, and cooling them quietly can be a PITA because of their proximity to the CPU and video cards.
<p>
</p>
</li>
<li>
<b>Memory.</b> Fast DDR2 memory ain't cheap. And I won't go below 2 gigabytes, which is what I consider a mainstream memory configuration these days. Have you <a href="http://www.newegg.com/Product/ProductList.asp?N=2010170147+1052420643&amp;Submit=ENE&amp;SubCategory=147">priced 2 gigabytes of DDR2-1066 lately?</a> Personally, I think buying <i>extremely</i> fast memory is overrated; by the time the system has to reach beyond the L1 and L2 cache into main memory, the performance penalty is <a href="http://www.codinghorror.com/blog/archives/000688.html">already so severe</a> that a few additional nanoseconds isn't going to matter in the big scheme of things. That's why I went with a nice midrange DDR2-667, specifically the AData Vitesta memory which <a href="http://www.anandtech.com/mb/showdoc.aspx?i=2797&amp;p=19">did quite well in a recent AnandTech value memory roundup</a>. Even if you push the front side bus up to 400 MHz-- what I consider an <i>extreme</i> overclock-- that's still only (400 x 2) or DDR2-800 officially. And all the value DDR2-533 memory <a href="http://www.anandtech.com/mb/showdoc.aspx?i=2797&amp;p=17">AnandTech tested</a> ran fine at 800 speeds, as long as you bumped up the voltage a bit.
<p>
</p>
</li>
<li>
<b>CPU.</b> Core 2 Duo is clearly the benchmark champ at the moment. I've been a <a href="http://www.codinghorror.com/blog/archives/000029.html">long</a> <a href="http://www.codinghorror.com/blog/archives/000352.html">time</a> AMD enthusiast, but Intel finally abandoned the problematic Pentium 4 architecture and built a better mousetrap this time. The E6600 is the cheapest Core 2 Duo with 4 megabytes of level 2 cache. I'm a big believer in cache, so I'm not willing to drop down to the E6300 or E6400 which only have 2 megabytes of L2. This might be a little irrational if you actually compare the performance of both cache sizes on an apples-to-apples clock rate basis, but so be it. I loves me some L2 cache.
<p>
</p>
</li>
<li>
<b>Heatsink.</b> If you <a href="http://www.codinghorror.com/blog/archives/000665.html">want a quiet PC</a>, buy the best CPU heatsink you can afford. That said, the <a href="http://www.scythe-usa.com/product/cpu/024/scinf1000.html">Scythe Infinity</a> is definitely overkill for a Core 2 Duo system, even an overclocked and overvolted one. But it's such beautiful, magnificent, glorious overkill. It barely fit in my case. That just made me love it all the more. This monster <i>barely</i> gets warm under dual Prime95 load. Running it completely passive is a no-brainer, but make sure you have proper case airflow.
</li>
</ol>
<p>
My general strategery with computer upgrades is to <b>buy upper midrange and overclock myself into high-end territory for extra value</b>. The Core 2 Duo CPU makes this easy, because they're all <i>incredible</i> overclockers. I overclocked my $319 2.4 GHz E6600 chip beyond <a href="http://www.newegg.com/Product/Product.asp?Item=N82E16819115001">$999 Core 2 "extreme" X6800</a> territory with a few quick modifications in the BIOS:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As a responsible overclocker, I also ensure the system is actually stable at these settings through hours and hours of <a href="http://www.codinghorror.com/blog/archives/000657.html">Prime 95 torture testing</a>. I still have those two instances of Prime95 running in the background as I'm writing this post.
</p>
<p>
So how did I turn my 90-pound weakling of a $320 CPU into a fire-breathing $999 monster CPU? It's quite easy. Read on.
</p>
<p>
</p>
<ol>
<li>
<b>Install the latest BIOS on the motherboard.</b> This is standard operating practice whenever I build a new system. On the P5B, the flash utility is built into the BIOS and <i>it even supports USB flash drives!</i> Finally! I downloaded the latest P5B Deluxe BIOS from ASUS' web site, copied it on a flash drive, plugged it in. I then booted, pressed ALT+F2 during startup to access the flash utility, and it autodetected the new BIOS file. All I had to do was hit enter to start the BIOS update, and I was done.
<p>
</p>
</li>
<li>
<b>Slowly increase the FSB speed in the BIOS.</b> I have an E6600, which is a 2.4 GHz chip with a 9x multiplier. That means the FSB speed is 2400 / 9 or 266 MHz. As I increase the FSB speed, the CPU speed also increases. I first tried 333 MHz, which results in 333 * 9 or 3.0 GHz. As you can see in the screenshot, I've currently gone a bit further for 3.15 GHz. Remember, <font color="red">make small changes and test as you go</font>. Don't immediately go for the highest possible overclock. Be conservative initially; you can adjust upward more later after you develop confidence.
<p>
</p>
</li>
<li>
<b>Increase voltage to the CPU, and memory in the BIOS.</b> To goose that extra bit of performance out of your system, increase voltages in the BIOS across the board. Don't worry, I'm not talking about massive increases here-- just slight boosts. I'm using 1.425 volts for the CPU (up from 1.35v), and 2.1 volts (up from 1.8v) for the memory. If what you want to do doesn't work with these modest voltage boosts, it probably won't work at all.
<p>
</p>
</li>
<li>
<b>Boot and see what happens.</b>
<ul>
<li>
<b>My computer won't boot.</b> Don't worry. No harm, no foul. Unplug your system, find the clear CMOS jumper on your motherboard, and use it to clear the CMOS. You can also pop out the CMOS battery if you're impatient. Make sure you do this with the system unplugged, and give the system a full minute to clear the CMOS.
</li>
<li>
<b>I can't boot into my operating system.</b> Your overclocking settings are too aggressive. We already increased voltage, so you need to back down your overclocking settings in the BIOS.
</li>
<li>
<b>It works!</b> Maybe it does, maybe it doesn't. Don't get cocky. See next step.
</li>
</ul>
</li>
<p>
</p>
<li>
<b>Burn your new settings in with Prime95.</b> Assuming you booted and logged into your operating system without crashing, hanging, or <a href="http://www.codinghorror.com/blog/archives/000452.html">bluescreening</a>*, your next job is to run torture tests to see if things are <i>really</i> working. <a href="http://www.codinghorror.com/blog/archives/000657.html">Prime95 is your new best friend</a>. You'll run one instance for every core in your CPU-- create a copy of the Prime95 folder for each core, and run the executables from those folders. Use Options, Torture Test, "In place large FFTs" to start. If you can run Prime95 this way for an hour, it's very likely your system is stable. If you can run Prime95 this way overnight, your system is <i>guaranteed</i> stable.
</li>
</ol>
<p>
Now that I've gotten my Core 2 Duo system stable at 3+ GHz, I can bask in the glory of a system that's <b>50% faster than my old Athlon X2 4800+</b> -- at least <a href="http://www.anandtech.com/cpuchipsets/showdoc.aspx?i=2795&amp;p=8">according to SYSmark 2004</a>. Not bad for under 800 bucks.
</p>
<p>
* Sounds traumatic, but if you want to make an omelette, you have to break some eggs. <a href="http://www.codinghorror.com/blog/archives/000123.html">Don't be afraid to break stuff.</a>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-05T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-and-overclocking-a-core-2-duo-system/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ DEFCON: Shall We Play a Game? ]]></title>
<link>https://blog.codinghorror.com/defcon-shall-we-play-a-game/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Earlier this year I wrote about <a href="http://www.codinghorror.com/blog/archives/000520.html">how much I loved</a> Introversion Software's indie PC game Darwinia. Introversion just released their newest game, <a href="http://everybody-dies.com/">DEFCON</a>.
</p>
<p>
</p>
<p>
DEFCON channels <a href="http://www.imdb.com/title/tt0086567/">WarGames</a> and <a href="http://en.wikipedia.org/wiki/Balance_of_Power_(computer_game)">Balance of Power</a>..
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
.. but Defcon begins where <a href="http://en.wikipedia.org/wiki/Balance_of_Power_(computer_game)">Balance of Power</a> ended:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's positively <a href="http://www.imdb.com/title/tt0057012/">strangelovian</a>.
</p>
<p>
The developers nail the mood of cold war paranoia, as explained in <a href="http://www.eurogamer.net/article.php?article_id=62477">this Eurogamer interview</a>:
</p>
<p>
</p>
<blockquote>
[Defcon] simulates Global Thermonuclear War.
<p>
Points are scored by successfully nuking the enemy civilian population into oblivion. This is an extremely difficult task because launching an attack on the enemy makes you very vulnerable - Ground Silos and Subs and Bombers all give away their positions the moment they launch nuclear weapons.
</p>
<p>
We're playing this game every day and people keep coming up with new strategies - but the bottom line is it's very difficult to win convincingly. Games often end with both sides obliterated. It's a fascinating and nervous game to play.
</p>
<p>
We've gone for a very minimal atmosphere, with some wonderful ambient music playing (written by Alistair Lindsay and Michael Maidment - the same guys that did the awesome Darwinia audio). There's very little in-game sound except deep rumbles when nukes hit. It's like you're ten miles underground in a bunker, bringing the world to an end one city at a time, completely detached from the millions of deaths you are causing.
</p>
</blockquote>
<p>
DEFCON uses OpenGL, which is quite problematic in Vista at the moment. It works great under XP, of course.
</p>
<p>
The game is unusually multitasking friendly; it doesn't capture the mouse pointer, so you can run it on a secondary monitor and treat it just like any other window on your screen. It also continues to run in the background when you minimize it. Running in the background is essential for those inevitable office matches:
</p>
<p>
</p>
<blockquote>
Yeah, we're very excited by Office Mode. The basic idea is that a group of work-mates can start the game up in the morning in Office Mode, playing over their local area network. The game takes place entirely in real-time (you can quite easily end the world with nuclear conflict in eight hours) and each player controls one territory, e.g. North America or Russia. You can hit the Panic key (press escape twice) which immediately removes the game from the screen and places a discreet icon in your system tray. That icon changes when important things happen - for example if you detect some nuclear launches the icon will flash as a Nuke for a few seconds. Because everything is taking place in real-time you've got at least 30 minutes before those nukes land, so you've got plenty of time to respond without interfering with your real work too much.
</blockquote>
<p>
Although DEFCON offers four speeds from real-time to 20x, even on 20x it's still a relatively slow paced real time strategy game, with plenty of "think time".  Battleships and bombers don't turn on a dime, and rapid clicking won't win games.
</p>
<p>
Unlike Darwinia, <b>DEFCON is primarily a multiplayer experience</b>. Although you can play against the computer AI-- <a href="http://features.engadget.com/2004/10/23/movie-gadget-friday-the-w-o-p-r-from-wargames/">our good friend the W.O.P.R.</a>-- there's not much of a single player narrative to the game. The best way to conduct Global Thermonuclear War is with a couple of your closest friends. Download the <a href="http://everybody-dies.com/downloads/index.html">demo version</a>, which has functional LAN and internet multiplayer, and nuke your coworkers into the stone age.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/defcon-shall-we-play-a-game/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Software Development: It's a Religion ]]></title>
<link>https://blog.codinghorror.com/software-development-its-a-religion/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
It's Monday, and <a href="http://steve-yegge.blogspot.com/2006/10/egomania-itself.html">Steve Yegge still hates Agile software development</a>. How much does he hate it? Approximately 11,000 words' worth. I think I could start a cottage industry producing Cliff's Notes versions of Steve Yegge posts. Here's my condensed version of Steve's latest:
</p>
<p>
</p>
<ul>
<li>Steve didn't intend to <a href="http://steve-yegge.blogspot.com/2006/09/good-agile-bad-agile_27.html">promote</a> Google's software development process as the One True Method of software development. It's just an example of one <i>possible</i> alternative to Agile.
</li>
<li>Agile software development methodologies only work because <i>any</i> software development methodology works if you have reasonably talented engineers trying hard enough.
</li>
<li>There's no empirical, scientific way to prove that Agile is any better than any other software development methodology. Thus, the promotion of Agile is a superstition.
</li>
</ul>
<p>
The repeated use of the word "superstition" is a key point. In his previous post, he referred to <a href="http://steve-yegge.blogspot.com/2006/09/good-agile-bad-agile_27.html">Agile as a religion</a>:
</p>
<p>
</p>
<blockquote>
So the consultants, now having lost their primary customer, were at a bar one day, and one of them (named L. Ron Hubbard) said: "This nickel-a-line-of-code gig is lame. You know where the real money is at? You start your own religion." And that's how both Extreme Programming and Scientology were born.
</blockquote>
<p>
Steve says "religion" like that's a bad thing.
</p>
<p>
<a href="http://www.barcodeart.com/art/portrait/bar_code_jesus_01_01.html"><img alt="image placeholder" >
</a>
</p>
<p>
But <b>software development is, and has always been, a religion.</b> We band together into groups of people who believe the same things, with very little basis for proving <i>any</i> of those beliefs. Java versus .NET. Microsoft versus Google. Static languages versus Dynamic languages. We may kid ourselves into believing we're "computer scientists", but when was the last time you used a hypothesis and a control to prove anything? We're too busy solving customer problems in the chosen tool, unbeliever!
</p>
<p>
</p>
<blockquote>
The fundamental cultural problem with superstition arises when people don't know how to differentiate between reliable and unreliable data-verification sources, so they treat non-science as science. If they don't recognize or admit that they're being superstitious, then they'll feel no qualms at all about trying to propagate their beliefs to YOU.
</blockquote>
<p>
Did Steve Yegge <i>prove</i> that Google's software development methodology is any better than big-a Agile? No, but he strongly believes it to be so in his heart of hearts. You might even say he's religious about it. And so what? <b>There's nothing wrong with a religion that preaches solid engineering.</b> If you're a true believer in the church of Google methodology, you'll become a better developer. When Steve evangelizes the glory of Google's methodology so eloquently, it gets <i>other</i> developers excited about what they're doing and makes <i>them</i> better developers, too. Before you know it, the whole team is juiced because everything is coming together on this totally awesome plan that they all believe in-- whether it's big-a Agile, Google, Scrum, or <i>whatever</i>.
</p>
<p>
In order for programmers to be effective, they have to believe in what they're doing.  Whether that belief is scientifically and empirically provable is completely irrelevant. It's <a href="http://www.codinghorror.com/blog/archives/000601.html">Peopleware 101</a>. Steve is so hell-bent on proving his own <b>methodology athiesm</b> that he undermines his own point.  It's <a href="http://www.acmqueue.com/modules.php?name=Content&amp;pa=showpage&amp;pid=98">all religion</a>, as Jef Raskin points out:
</p>
<p>
</p>
<blockquote>
Computer systems exhibit all the behaviors best suited to create superstitious responses. You will try something, it won't work, so you try it again -- the exact same way -- and this time it works, or not. That's random reinforcement. The effectiveness of many programming and management practices thus are not measurable. Most of the principles of "extreme programming," for example, seem reasonable to me, and I was using many of them long before they had acquired their present absurd name. The people who promulgate the idea, however, are also those who created the paradigm. Most reported results aren't even single-blind, much less double-blind. We rarely understand, in any detail, the processes going on behind the tasks we do with computers. We're using megabytes of code written by others, code that is indifferently documented and inadequately tested, and which is being used in ways and in combinations unforeseen by its creators.
</blockquote>
<p>
Software methodology religion, in and of itself, isn't dangerous. There's always <a href="http://damienkatz.net/2005/02/emo-philips-on-religion.html">the risk of religious persecution</a>, but the only truly dangerous people are <b>the religious nuts who don't realize they are religious nuts.</b> I don't like resorting to name-calling, but I just can't see how Steve could otherwise be so glib:
</p>
<p>
</p>
<blockquote>But rather than enumerating all the non-Agile teams and companies as special cases, let's get straight to the rule: Most great software developers around the world don't use Agile. They just work hard, <b>they stay lightweight</b>, and they ship great stuff. Most developers still have no idea what Agile even is. Think of that!</blockquote>
<p>
</p>
<ol>
<li>How exactly is "staying lightweight" different from Agile? Isn't Agile the Church of Lightweight? Steve may disagree with specific tenets of the church, (pair programming, etc), and that's fine. Nobody prays exactly the same way, and not everyone is a zealot. But you always have a set of shared, core beliefs. And lightweight development is clearly a core Agile belief.
<p>
</p>
</li>
<li>It's true that most developers don't use agile software development. But it's not by choice. They weren't <i>given</i> a choice. They're usually stuck in organizations that don't allow them the luxury of "staying lightweight". They're <a href="http://www.codinghorror.com/blog/archives/000689.html">peons trapped in a sausage factory</a>.
<p>
</p>
</li>
<li>Steve talks about "staying lightweight" as if it's the easiest thing in the world, like it's some natural state of grace that developers and organizations are born into. Telling developers to stay lightweight is like telling depressed people to cheer up.
</li>
</ol>
<p>
I'm not sure why Steve is so uncomfortable with the idea of software development as a religion, as a set of shared beliefs with very little "basis [in] scientific experiment or pure deductive reasoning." Because he's surely one of the best evangelists I've ever read.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/software-development-its-a-religion/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Blog Advertising: Yea or Nay ]]></title>
<link>https://blog.codinghorror.com/blog-advertising-yea-or-nay/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I've recently been approached by several different people to inquire about <b>advertising on my blog</b>.
</p>
<p>
It doesn't cost me anything to run this blog. I used to host it myself on my cable modem, and my employer, <a href="http://www.vertigo.com/">Vertigo Software</a>, generously donated hosting when I outgrew the limited upstream bandwidth of a cable modem.
</p>
<p>
I do have a bit of advertising on the blog already, through my Amazon affiliate links. That seemed like a natural fit for my <a href="http://www.codinghorror.com/blog/archives/000020.html">recommended reading list</a> when I originally put it together. But there's <b>never a visible advertisement</b>. The affiliate links are indistinguishable from a normal link to a book on Amazon, which is usually quite useful.
</p>
<p>
I can understand wanting to recoup hosting costs-- if I had any-- but Scott Hanselman asks: <a href="http://www.hanselman.com/blog/default.aspx">what about the cost of your time writing all those blog entries?</a>
</p>
<p>
<a href="http://www.youtube.com/results?search_query=this+note%27s+for+you"><img alt="image placeholder" >
</p>
<p>
I'm not opposed to advertising. I won't pretend that I don't like money, particularly here in the United States where money is synonymous with freedom.
</p>
<p>
But advertising <i>responsibly</i> is difficult.
</p>
<p>
</p>
<ul>
<li>
<b>Stand behind the products you're indirectly selling.</b> They should be products or services you yourself recommend. Some of the more selective blogs join targeted ad networks with products they hand-pick, such as <a href="http://coudal.com/deck/">the deck</a>.
<p>
</p>
</li>
<li>
<b>Limit the number of ads you take</b>. Using the Ronco spray-on monetization plan and filling your page with as many types of advertising and affiliate programs as possible smacks of desperation. Even worse, it makes your website look like a tacky Nascar joke.
<p>
<img alt="image placeholder" >
</p>
<p>
</p>
</li>
<li>
<b>Realize that advertising changes the nature of your blog.</b> The first ads you take convert your blog from a non-profit to a commercial venture. It's no longer a hobby; you're being paid to blog. It's work. And unless you're only accepting only random ads, there are also new avenues for conflicts of interest.
</li>
</ul>
<p>
At least for my blog, I don't think the benefits of advertising outweigh the negatives. I like the idea that every time I write an entry, I did so purely for my own reasons, whatever they are, and not because I needed to drive ad revenue.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/blog-advertising-yea-or-nay/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Chess: Computer v. Human ]]></title>
<link>https://blog.codinghorror.com/chess-computer-v-human/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I recently visited the <a href="http://www.computerhistory.org/">Computer History Museum</a> in nearby San Jose, which has a new exhibit on <a href="http://www.computerhistory.org/chess/">the history of computer chess</a>. Despite my total lack of interest in chess as a game, <a href="http://en.wikipedia.org/wiki/Computer_chess">computer chess</a> has a special significance in the field of computer science. <strong>Chess remains the most visible and public benchmark of the relentless increase in computer speed over the last 50 years.</strong></p>
<p><img alt="image placeholder" >
<p>There are two general strategies available to computer chess programs:</p>
<ol>
<li>
<strong>Brute force search</strong> or Type A. All possible positions are examined. </li>
<li>
<strong>Strategic AI</strong> or Type B. Only good positions are examined. </li>
</ol>
<p>As it turns out, computers have a hard time with the concept of "good". That's why the history of computer chess is dominated by Type A programs. The most famous Type A chess computer is probably IBM's Deep Blue, which went through a number of incarnations before it defeated a reigning world chess champion in 1997.</p>
<p>I recently <a href="http://www.codinghorror.com/blog/archives/000697.html">built myself a new PC</a> based on the latest Intel Core 2 Duo chip. According to the <a href="http://www.chess.com/download/view/fritz-12-benchmark">Fritz Chess Benchmark</a>, my current home PC is capable of evaluating approximately <strong>4.45 million chess positions per second</strong>. The figure is actually expressed as 4452 kilonodes per second (kN/s), a common unit of measurement for chess engines.</p>
<p>4.45 million chess positions per second <em>sounds</em> impressive, until you compare that with <a href="http://www.research.ibm.com/deepblue/meet/html/d.3.1.shtml">the Deep Blue timeline</a>:</p>
<table width="425">
<tbody>
<tr>
<td>Year</td>
<td>Positions/sec</td>
</tr>
<tr>
<td>1985</td>
<td>50k</td>
</tr>
<tr>
<td>1987</td>
<td>500k</td>
</tr>
<tr>
<td>1988</td>
<td>720k</td>
</tr>
<tr>
<td>1989</td>
<td>2 million</td>
</tr>
<tr>
<td>1991</td>
<td>7 million</td>
</tr>
<tr>
<td>1996</td>
<td>100 million</td>
</tr>
<tr>
<td>1997</td>
<td>200 million</td>
</tr>
</tbody>
</table>
<p><strong>The fastest desktop PCs are more than 15 years behind Deep Blue in computer chess</strong>. Of course, Deep Blue was built using large arrays of custom hardware designed for the sole purpose of playing chess, so it's a little unfair to directly compare it to a general-purpose, commodity CPU.</p>
<p>Chess is an inherently parallelizable problem. The dual and quad-core CPUs <a href="http://www.tomshardware.com/charts/desktop-cpu-charts-2010/Logic-Fritz-Chess,2419.html">on the Fritz Chess benchmark results page</a> almost exactly double the results of single-core CPUs of the same speed. You could certainly string together a bunch of these fast commodity desktops and build your way up to Deep Blue numbers. This <a href="http://www.extremetech.com/article2/0,1697,1915528,00.asp">fascinating ExtremeTech article on building desktop chess computers</a> indicates it would take 24 dual, dual-core 2.2 GHz Opteron machines to match Deep Blue. Or at least it would have in January 2006 when that article was written. But something more significant than commodity hardware scaling is going on here --Type B chess programs are finally emerging:</p>
<blockquote>
<strong>Despite its vastly inferior brute force, the Deep Blitz machine could already be a match for Deep Blue because of improvements in chess software.</strong> Deep Fritz is able to evaluate lines of play to a similar depth because it successfully narrows its search only to the strongest lines of play.
<p>The data suggest that Deep Blue spent a lot of time evaluating bad moves but overcame this weakness through brute force. In a match between Deep Blue and the Deep Blitz machine running Deep Fritz or Deep Shredder, it seems unclear which machine would win. Obviously, Kasparov did not evaluate 200 million chess positions per second when he defeated Deep Blue in game 1 of the 1997 match, thus the 200 million positions per second number is not a requirement to play chess at the word championship level. It seems likely that Deep Fritz, which is more efficient at filtering out weak moves, is a far more 'intelligent' chess program compared with Deep Blue's software.</p>
</blockquote>
<p>The latest <a href="http://computerchess.org.uk/ccrl/">computer chess ratings</a> are determined solely by computer vs. computer play. Bram Cohen thinks the derived ratings from computer play are <a href="http://bramcohen.livejournal.com/29624.html">enough to crown the computer chess programs champs over human grandmasters, too</a>:</p>
<blockquote>What's the best tournament chess game of all time? If by 'best' one means 'best played' then I'm afraid the answer is Zappa vs. Fruit. In this most recent world computer tournament, Zappa scored an astounding 10.5 out of 11, a better performance than any human has ever had in a human world championship, and against a stronger field than any human world champion has ever faced. Fruit came in a clear second, so this is the only tournament game we have between the two strongest chess players ever created. Of course, you'll soon be able to buy the commercial version of Zappa and have it play against itself, resulting in a string of games most of which are better than any game ever played between two humans. Welcome to chess in the 21st century.
<p>Some humorous notes: Zappa and Fruit were both written by lone grad students in under two years. Dark horses obliterating the field is a common thing in AI. Zappa's lone draw was ironically against the program which lost every other game in the entire tournament.</p>
<p>Now that <strong>computers are clearly better than humans at chess</strong>, the question arises, can computers attempt to guess the strength of a game's play based on the moves in that game? And can we use that method to evaluate 'classic' games? Do we really want to?</p>
</blockquote>
<p>I think this is a dubious claim, particularly since it's not based on any actual data from computer versus human games. Although Deep Blue did beat Kasparov in 1997, there's ample evidence that Kasparov was the better player and he psyched himself out during the match. <a href="http://www.chessbase.com/newsdetail.asp?newsid=1229">All subsequent rematches between human world champions and computer chess programs have resulted in ties</a>-- including two with Kasparov himself in 2003. Statistician Jeff Sonas <a href="http://www.chessbase.com/newsdetail.asp?newsid=1244">believes computers will never consistently defeat the best human players</a>:</p>
<blockquote>Computers are becoming more and more dominant against everyone but the top 200 players in the world. That is leading to an overall performance rating for computers that is getting higher and higher. However, the players in the top-200 are holding their ground even against the latest and greatest computers. Perhaps that group will soon shrink down to only the top-100, or the top-50, but not inevitably, and not irreversibly. As you can see from my previous graphics, there is no sign that the top-200 players are losing ground at all against the top computers.
<p>The top 20 humans (the 2700+ crowd) are managing a long string of drawn matches against computers, and the rest of the top-200 is averaging the same 35% to 40% score that they did a few years ago. So, amazing as it may seem, I don't see any evidence that the top computers are suddenly going to take over the chess world. Of course the top computers are improving, mostly through hardware and software upgrades, but somehow the top humans are improving just as fast, in other ways.</p>
<p>We are at a unique point in chess history, an unprecedented state of dynamic balance. <strong>The top computers have caught up with the top grandmasters, and right now I'm not convinced that the computers will zoom past the grandmasters.</strong> Everything depends on whether computers or grandmasters can improve faster, starting today. It may even be that the top humans can figure out how to improve their own anti-computer play, to the point that they will pull ahead again. Perhaps Garry Kasparov can lead the way once more.</p>
</blockquote>
<p>I tend to agree. We may have reached an inflection point. The problem space of chess is so astonishingly large that incremental increases in hardware speed and algorithms are unlikely to result in meaningful gains from here on out.</p>
<p>Computer chess programs may have long ago crushed the rest of us in their inevitable Moore's Law march, but the best 200 chess players in the world are still holding their ground.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/chess-computer-v-human/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Field of Dreams Strategy ]]></title>
<link>https://blog.codinghorror.com/the-field-of-dreams-strategy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
We have a tendency to <b>fetishize audience metrics</b> in the IT industry. Presenters stress out about about their feedback ratings and measure themselves by how many attendees they can attract for a presentation. Bloggers obsessively track their backlinks, pagerank, and traffic numbers. I see it a lot, and <a href="http://swigartconsulting.blogs.com/tech_blender/2006/10/welcome_reader_.html">it's strange to me</a>. I don't chase those numbers. I couldn't even tell you how many readers I have, or what my presentation ratings were. I don't mean to sound glib, but I don't care. Audience metrics aren't the reason I write, and they aren't the reason I present. They're incidental.
</p>
<p>
Conan O'Brien made an interesting observation <a href="http://www.avclub.com/content/node/51876">in a recent interview</a> when asked about his audience:
</p>
<p>
</p>
<blockquote>
There's a temptation to overthink the whole thing. I've had a <a href="http://www.imdb.com/title/tt0097351/">Field Of Dreams</a> philosophy to this: If you build it, they will come. I still have no idea.
<p>
<img alt="image placeholder" >
</p>
<p>
<b>I don't look at research. I don't look at who's watching, or when they're watching. I've never been interested in any of that. I'm interested in doing what I think is funny.</b> For the last 13 years, that seems to have worked for me. If I go to 11:30 and do what I think is funny, and someone comes and tells me it isn't getting enough people in the tent, I'd say, "Well, that's all I can do." If I'm looking at spreadsheets and time-lapse studies of viewing patterns, I think I'm wasting my time. What I should be worried about the first night I host The Tonight Show is, "How can I make this a funny show?" The second night, "All right, let's make another funny show doing some different stuff." You do it one show at a time. And if you're lucky, eight years later, you've alienated a nation.
</p>
</blockquote>
<p>
Similarly, Rob Caron once <a href="http://www.mikepope.com/blog/AddComment.aspx?blogid=1135">commented</a>:
</p>
<p>
</p>
<blockquote>The day I care about keeping my blog readers happy is the day I'll stop blogging. Who needs the added stress?
</blockquote>
<p>
There's certainly value in audience metrics. But it's easy to overanalyze, too. Instead of obsessing over who does and doesn't link to you, concentrate on writing a blog entry <i>you'd </i>like to read. Instead of worrying about audience feedback, focus on delivering a presentation <i>you'd</i> like to attend.
</p>
<p>
<b>You should trust your gut more than any metrics.</b> Build it, and they will come.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-field-of-dreams-strategy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Opting Out of Linked In ]]></title>
<link>https://blog.codinghorror.com/opting-out-of-linked-in/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>From the <a href="http://en.wikipedia.org/wiki/LinkedIn">Wikipedia entry on Linked In</a>:</p>
<blockquote>It is not possible to remove yourself from LinkedIn. Instead, you have to file a customer support ticket.</blockquote>
<p>This blurb neatly summarizes everything that's wrong with the Linked In service.</p>
<p>I've been a member of Linked In for almost two years now. I dutifully entered my credentials and kept them up to date. The only other interaction I've had with the service since then has been <strong>a continual stream of link requests</strong>. I'm selective about who I approve, limiting it to people I've only met in real life. And the net benefit of this selectivity? As far as I can tell, zilch. Nada. Nothing. I did get a cold call from a headhunter once based on my Linked In profile, but I don't consider that a benefit.</p>
<p>Has this service ever been useful to anyone? I'm telling you, <strong>Linked In is the digital equivalent of a chain letter.</strong> If you really want to contact a friend of a friend (of a friend), just pick up the phone or send an email. If the only way you can reach someone is through this nutty online social pyramid scheme, you don't <em>deserve</em> to be taken seriously. And I can guarantee that you won't be.</p>
<p><img alt="image placeholder" >
<p>Consider carefully: <strong>who really benefits from your participation in Linked In?</strong> I'll tell you who benefits: Linked In.</p>
<p>If you can't immediately point to a few direct benefits <em>you</em> personally get from participating in Linked In, then why do it? Why build Linked In's marketing database with <em>your</em> valuable time and information?</p>
<p>From this point on, I'm opting out of linked in. Like Russell Beattie, I've found that <a href="http://www.russellbeattie.com/notebook/1008411.html">there really is no there there</a>. If you're a member of Linked In and you're not seeing direct personal benefits, I urge you to <a href="http://www.linkedin.com/feedback?displayContactCustomerServiceFeedback=">close your Linked In account</a> as well. It's high time we put an end to this glorified chain letter of a service.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/opting-out-of-linked-in/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Chickens, Pigs, and Really Inappropriate Terminology ]]></title>
<link>https://blog.codinghorror.com/chickens-pigs-and-really-inappropriate-terminology/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Here's a <a href="http://www.mountaingoatsoftware.com/scrum/dailymeeting.php">description of the daily Scrum meeting</a> in the <a href="http://en.wikipedia.org/wiki/Scrum_%28development%29">Scrum process</a>:
</p>
<p>
</p>
<blockquote>
During the month-long sprints, the team holds daily meetings-- the daily Scrum. Meetings are typically held in the same location and at the same time each day. Ideally the daily Scrums are held in the morning, as they help set the context for the coming day's work. <b>Each participant in the Daily Scrum is known as either a chicken or a pig, depending on his involvement in the project.</b>
</blockquote>
<p>
Scrum has some serious naming problems, <a href="http://www.codinghorror.com/blog/archives/000695.html">starting with Scrum itself</a>. Here's another one. Chickens? Pigs? The whole thing is completely lost on me. Evidently it's based on a joke from Schwaber and Beedle's <a href="http://www.amazon.com/exec/obidos/ASIN/0130676349/codihorr-20">Agile Software Development with Scrum</a>:
</p>
<p>
</p>
<blockquote>
Chicken: <br>
Let's start a restaurant!
<p>
Pig:<br>
What would we call it?
</p>
<p>
Chicken:<br>
Ham n' Eggs!
</p>
<p>
Pig:
No thanks. I'd be committed, but you'd only be involved!
</p>
</blockquote>
<p>
In other words, pigs sacrifice their lives for the project, whereas chickens only have to give up their eggs. It's amusing, I suppose, but just try explaining it to the people coming to your Daily Scrum meetings.
</p>
<p>
<a href="http://www.girlvspig.com/archives/her17.html"><img alt="image placeholder" >
</p>
<p>
I agree that <a href="http://www.codinghorror.com/blog/archives/000219.html">everyone participating in the project should have "skin in the game"</a>. But not literally. Pride in your project is one thing, but implying that you'd give your very life to see the project succeed is just <a href="http://www.codinghorror.com/blog/archives/000143.html">a little too macho for my tastes</a>. And it gets worse. Jeff Sutherland, one of the co-creators of Scrum, explains that <a href="http://wiki.scrums.org/index.cgi?PigsAndChickens">the chicken term is <i>meant</i> to be derogatory</a>:
</p>
<p>
</p>
<blockquote>
The real issue is who is committed to the project and accountable for deliverables. They get to talk at the daily meeting. They are the pigs and their butts are on the line. We could call them contributors if we don't like pigs.
<p>
<b>People who are not committed to the project and are not accountable for deliverables at the meeting do not get to talk [at the daily meeting]</b>. They are excess overhead for the meeting. They might be called eavesdroppers if you don't like chickens. Whatever we call them it should have a negative connotation because they tend to sap productivity. They are really suckers or parasites that live off the work of others. Sorry to be politically incorrect but others should come up with a euphemism that conveys the right balance between being "nice" and communicating clearly that eavesdroppers must minimize their impact on the productivity of the team.
</p>
<p>
If you look at most corporate meetings you will see 50-80% excess overhead. These are the meetings that Scrum eliminates on day 1 if done properly.
</p>
<p>
Most of excess overhead will claim they need to know what is going on because it impacts their work in some way. They don't need to know what is going on in the Scrum. They need to be able to see a visual representation off the backlog that is updated daily, preferably automatically on the web. At the end of the Sprint, they get to go to a demo where they can see exactly what went on, can provide their input, and can influence the next Sprint. This is where they can provide a real contribution.
</p>
</blockquote>
<p>
I see where Jeff is coming from here. I really do. I have a deep respect for project managers* who nobly throw themselves on meeting grenades so the team can actually get work done. The number one goal of any competent PM is to shield their team from as much of this organizational overhead as possible. But <b>the use of derogatory in-joke terminology harms the cause by making it harder for outsiders to take Scrum seriously</b>. And I wonder: how do you diplomatically break the news to a chicken that thinks it's a pig?
</p>
<p>
Luckily, the <a href="http://wiki.scrums.org/index.cgi?PigsAndChickens">very same wiki page</a> provides some alternative terminology that better communicates what's going on in the daily Scrum meeting:
</p>
<p>
</p>
<ul>
<li>Players, Spectators
</li>
<li>Contributors, Observers
</li>
<li>Committed, Interested
</li>
<li>Forwards, Backs (continuing with the rugby theme)
</li>
<li>Active, Passive
</li>
</ul>
<p>
Although I don't agree with all of it, there are some solid software development principles in <a href="http://en.wikipedia.org/wiki/Scrum_%28development%29">Scrum</a>. It's a shame that stupid stuff like chickens and pigs get in the way.
</p>
<p>
* or, in the spectacularly bad parlance of Scrum, ScrumMasters.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/chickens-pigs-and-really-inappropriate-terminology/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Last Responsible Moment ]]></title>
<link>https://blog.codinghorror.com/the-last-responsible-moment/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In <a href="http://www.amazon.com/exec/obidos/ASIN/0321150783/codihorr-20">Lean Software Development: An Agile Toolkit</a>, Mary and Tom Poppendieck describe a counter-intuitive technique for making better decisions:</p>
<blockquote><p>Concurrent software development means starting development when only partial requirements are known and developing in short iterations that provide the feedback that causes the system to emerge. Concurrent development makes it possible to <strong>delay commitment until the last responsible moment, that is, the moment at which failing to make a decision eliminates an important alternative.</strong> If commitments are delayed beyond the last responsible moment, then decisions are made by default, which is generally not a good approach to making decisions.</p></blockquote>
<p>Paradoxically, it's possible to make better decisions by <em>not deciding</em>. I'm a world class procrastinator, so what's to stop me from reading this as carte blanche? Why do today what I can put off until tomorrow?</p>
<p>Making decisions at the Last Responsible Moment isn't procrastination; it's <a href="http://www.codinghorror.com/blog/archives/000237.html">inspired laziness</a>. It's a solid, fundamental risk avoidance strategy. <strong>Decisions made too early in a project are hugely risky.</strong> Early decisions often result in work that has to be thrown away. Even worse, those early decisions can have crippling and unavoidable consequences for the entire future of the project.</p>
<p>Early in a project, you should make as few binding decisions as you can get away with. This doesn't mean you stop working, of course  you adapt to the highly variable nature of software development. Often, <a href="http://www.codinghorror.com/blog/archives/000373.html">having the guts to say "I don't know"</a> is your best decision. Immediately followed by " but we're working on it."</p>
<p>Jeremy Miller participated in a TDD panel with Mary Poppendieck last year, and he logically <a href="http://codebetter.com/blogs/jeremy.miller/archive/2006/01/18/136648.aspx">connects the dots</a> between the Last Responsible Moment and <a href="http://www.codinghorror.com/blog/archives/000111.html">YAGNI</a>:</p>
<blockquote><p><strong>The key is to make decisions as late as you can responsibly wait because that is the point at which you have the most information on which to base the decision.</strong> In software design it means you forgo creating generalized solutions or class structures until you know that they're justified or necessary.</p></blockquote>
<p>I think there's a natural human tendency to build or buy things in anticipation of future needs, however unlikely. Isn't that the <a href="http://www.scouting.org/">Boy Scout</a> motto  <a href="http://www.scouting.org/factsheets/02-503a.html">Be Prepared?</a></p>
<p><img alt="image placeholder" >
<p>As a former Scout myself, I think we should resist our natural tendency to prepare too far in advance. My workshop is chock full of unused tools I thought I <em>might</em> need. Why do I have this air compressor? When was the last time I used my wet/dry vac? Have I <em>ever</em> used that metric socket set? It's a complete waste of money and garage space. Plus all the time I spent agonizing over the selection of these tools I don't use. I've adopted the Last Responsible Moment approach for my workshop. I force myself to only buy tools that I've used before, or tools that I have a very specific need for on a project I'm about to start.</p>
<p>Be prepared. But for tomorrow, not next year. Deciding too late is dangerous, but deciding too early in the rapidly changing world of software development is arguably even <em>more</em> dangerous. Let the principle of Last Responsible Moment be your guide.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-last-responsible-moment/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Buy the Community, Not the Product ]]></title>
<link>https://blog.codinghorror.com/buy-the-community-not-the-product/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Now that Internet Explorer 7.0 <a href="http://www.microsoft.com/windows/ie/default.mspx">is final</a>, the browser wars can begin again in earnest. It's clear that users should upgrade, because <a href="http://www.codinghorror.com/blog/archives/000242.html">IE6 is so ancient</a>. Security concerns alone compel an upgrade. But should IE6 users upgrade to IE7, or should they choose an alternative?
</p>
<p>
This comment in a web forum recently summed up my feelings nicely:
</p>
<p>
</p>
<blockquote>
I have no idea why anyone cares that much about their browser, or why they feel it needs to be some sort of contest. <b>I visit websites, which I consider more important than what I use to view said websites.</b>
</blockquote>
<p>
I've used IE7 at work and Firefox at home for the last six months or so. They're both modern web browsers. I don't see a big difference between the two. But there are dozens of killer add-ins for Firefox that extend the browser in useful ways. The lack of a viable <a href="https://addons.mozilla.org/firefox/433/">FlashBlock</a> for IE7 is enough to make me switch.
</p>
<p>
It's not that Firefox is inherently a better product than IE7. It isn't. But Firefox has a stronger, more vibrant user community, and <i>that</i> ultimately makes it a better product than IE7. Which makes me wonder: <b>is the community around a product more important than the product itself?</b>
</p>
<p>
Community doesn't happen accidentally. And <a href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;articleId=9004205&amp;pageNumber=6">Microsoft hasn't done much to cultivate community around Internet Explorer 7</a>:
</p>
<p>
</p>
<blockquote>
Another area where IE7 has serious shortcomings is with add-ons that give extra features to the browser. Firefox has an incredibly rich community of developers creating extensions, and IE has nothing that comes remotely close to it.
<p>
Don't expect much to happen in the way of add-ons for IE7, at least for the foreseeable future. There are several reasons for this. A big one has to do with how add-ons are written. To write an add-on for Internet Explorer, you need to be a C programmer. To write an extension for Firefox, you only need to be able to write a script -- and there are far more people in the world capable of writing scripts than are capable of writing C code.
</p>
<p>
Microsoft is aware of the problem and says that it hopes to ultimately make it possible to author add-ons via scripting. But there's no timetable for this.
</p>
<p>
Beyond that is a cultural issue. There is a sizable community of people that believes in open-source as a movement and philosophy, but outside the confines of Microsoft, you won't find a similar community devoted to Microsoft. So you don't have people with the same fervor devoted to writing IE add-ons as you have writing Firefox extensions.
</p>
<p>
Microsoft doesn't seem to be doing anything to foster an add-on movement, either. The Firefox extension site, for example, is run by the Mozilla Foundation, which plays an integral role in the open-source movement. Microsoft's add-on site, meanwhile, isn't even completely run by Microsoft itself; it's a co-branded download library powered by CNET's Download.com.
</p>
</blockquote>
<p>
It's clear that <b>community support can make or break a product</b>. But popularity can be a curse, too. Dare Obasanjo asks, <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=cc51fa1f-2737-4a23-9288-13f56ce9cc29">what happens when your community turns on you?</a>
</p>
<p>
</p>
<blockquote>
A number of times while he was speaking, Tim O'Reilly gave the impression that extensions like Greasemonkey are examples of Firefox's superiority as a browser platform. I completely disagree with this notion, and not only because Internet Explorer has Greasemonkey clones like Trixie and Turnabout. The proof is in the fact that the average piece of Windows spyware actually consists of most of the core functionality of Greasemonkey. <b>The big difference is that Firefox has a community of web developers and hobbyists who build cool applications for it while most of the folks extending Internet Explorer in the Windows world are writing spyware and other kinds of malware.</b>
</blockquote>
<p>
It'll be interesting to see if the Firefox community can avoid this pitfall as Firefox gains in popularity. But the benefits of a strong community are worth the risk; it's enough to make the choice between IE7 and Firefox a meaningful one.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/buy-the-community-not-the-product/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ My Giant Heatsink Fetish ]]></title>
<link>https://blog.codinghorror.com/my-giant-heatsink-fetish/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
One side effect of <a href="http://www.codinghorror.com/blog/archives/000665.html">building quiet PCs</a> is that you tend to develop a <b>giant heatsink fetish</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
From left to right:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.arctic-cooling.com/vga2.php?idx=91">Arctic Cooling Accelero X1</a> on the ATI 1900XTX video card
</li>
<li>
<a href="http://www.thermalright.com/a_page/main_product_hr05.htm">Thermalright HR-05</a> on the Intel 965 northbridge chipset
</li>
<li>
<a href="http://www.scythe-usa.com/product/cpu/024/scinf1000.html">Scythe Infinity</a> on the Core 2 Duo CPU
</li>
</ul>
<p>
It pains me to replace the northbridge cooling on the <a href="http://www.asus.com/products4.aspx?modelmenu=1&amp;model=1179&amp;l1=3&amp;l2=11&amp;l3=307">Asus P5B Deluxe</a>, which already includes a luxe heatpipe and radiator arrangement. But it wasn't working for me-- I had <a href="http://www.silentpcreview.com/forums/viewtopic.php?t=34826">serious overheating problems</a> very specific to the northbridge.
</p>
<p>
I guess that's not too surprising if you consider that <a href="http://www.silentpcreview.com/forums/viewtopic.php?t=35078">modern Intel northbridges dissipate almost 20 watts under load</a>.* For comparison, Intel CPUs didn't dissipate more than 20 watts under load <a href="http://en.wikipedia.org/wiki/CPU_power_dissipation">until the introduction of the Pentium II 450</a> in 1998.
</p>
<p>
* more like 30+ watts if you're using the craptacular integrated graphics on some motherboards.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/my-giant-heatsink-fetish/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Iron Stool ]]></title>
<link>https://blog.codinghorror.com/the-iron-stool/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://office.microsoft.com/en-us/assistance/HA010211801033.aspx">classic project management parlance</a> , every project is a combination of <b>money, scope and time</b>.
</p>
<p>
</p>
<ol>
<li>Here's what we're going to do
</li>
<li>Here's how much time we have to do it
</li>
<li>Here's how much money we can spend doing it.
</li>
</ol>
<p>
These three factors are all related. If you pull on one "edge" of the triangle, the other sides have to give. If we cut the budget in half, we can't do as much, so scope has to give. That's why it's often called <b>the iron triangle</b>.
</p>
<p>
In software development, the terms are a little different, but the underlying meaning is the same. We use <b>Time, Resources, and Functionality</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Sometimes all three dimensions of the triangle are locked. If you're given three people, four months, and a non-negotiable budget of $300k to build software, then that's what you do. But how is this possible? Something still has to give. <b>There's an unstated fourth ingredient in the iron triangle: quality.</b>
</p>
<p>
Once you add the fourth ingredient, the triangle metaphor breaks down. Sam Guckenheimer <a href="http://www.awprofessional.com/articles/article.asp?p=468589&amp;seqNum=3&amp;rl=1">calls it a tetrahedon</a>. But <a href="http://blogs.vertigosoftware.com/swarren/">my co-worker Susan</a> has an even better analogy: it's a stool.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
At least for software development there's still some debate as to <a href="http://www.awprofessional.com/articles/article.asp?p=468589&amp;seqNum=3&amp;rl=1">whether or not the stool really is made of iron</a>:
</p>
<p>
</p>
<blockquote>
Although widely practiced, [the iron triangle] paradigm does not work well. Just as Newtonian physics is now known to be a special case, the iron triangle is a special case that assumes the process is flowing smoothly to begin with. It assumes that resource productivity is uniformly distributed, that there is little variance in the effectiveness of task completion, and that no spare capacity exists throughout the system. These conditions exist sometimes, notably on low-risk projects. Unfortunately, for the types of software projects usually undertaken, they are often untrue.
<p>
Many users of agile methods have <a href="http://alistair.cockburn.us/index.php/Process:_the_fourth_dimension">demonstrated experiences that pleasantly contradict this viewpoint</a>. If you improve qualities of service, such as reliability, you can shorten time. Significant improvements in flow are possible within the existing resources and time
</p>
</blockquote>
<p>
It's definitely a good idea to keep the "classic" stool resources in mind. But the highly variable nature of software development means that, if you're careful, you may be able to build your stool out of a more malleable material than iron.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-iron-stool/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Windows Live Writer: making the Internet a better place ]]></title>
<link>https://blog.codinghorror.com/windows-live-writer-making-the-internet-a-better-place/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Does this look familiar?
</p>
<p>
</p>
<blockquote>
Temporary Post Used For Style Detection (14debf21-5e75-4077-9bf0-88d425739dc7)
<p>
This is a temporary post that was not deleted. Please delete this manually. (f19173c9-9b1f-4430-8823-bae7c95236a0)
</p>
</blockquote>
<p>
<b>Seriously. Enough with this already.</b> I'm gonna hurt somebody.
</p>
<p>
If you're not in on the joke, it's an artifact of Microsoft's <a href="http://windowslivewriter.spaces.live.com/blog/cns!D85741BB5E0BE8AA!174.entry">Windows Live Writer</a> blogging tool. It generates "hidden" skeleton blog posts to detect CSS styles in its editor, but these posts somehow keep showing up in my aggregator. And <i>that's annoying</i>.
</p>
<p>
There are also <a href="http://www.google.com/search?q=%22temporary+post+used+for+style+detection%22">19,500 google results for the phrase "temporary post used for style detection"</a>. Gee, thanks, Windows Live Writer. That's exactly 19,499 too many. <a href="http://labnol.blogspot.com/2006/08/microsoft-wysiwyg-blog-editor-how-do-i.html">This post is actually useful</a>, since it describes the problem in more detail.
</p>
<p>
On the plus side, I did get the chance to bring two new GUIDs into the world. And <a href="http://www.codinghorror.com/blog/archives/000399.html">you know how I love GUIDs</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/windows-live-writer-making-the-internet-a-better-place/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Does Writing Code Matter? ]]></title>
<link>https://blog.codinghorror.com/does-writing-code-matter/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Ian Landsman's <a href="https://web.archive.org/web/20070306071950/http://www.userscape.com/blog/index.php/site/comments/10_tips_for_moving_from_programmer_to_entrepreneur/">10 tips for moving from programmer to entrepreneur</a> is excellent advice. Even if you have no intention of becoming an entrepreneur.</p>
<blockquote>
<p>One of the biggest issues I see is developers getting caught up in the code. Spending countless hours making a function perfect or building features which show off the latest technology. Now you have to write code to be in the software business. It has to be high quality code that isn't filled with bugs or is insecure. However, <b>the best code in the world is meaningless if nobody knows about your product</b>. Code is meaningless if the IRS comes and throws you in jail because you didn't do your taxes. Code is meaningless if you get sued because you didn't bother having a software license created by a lawyer.</p>
</blockquote>
<p><a href="https://blog.codinghorror.com/can-your-team-pass-the-elevator-test/">Software developers love code</a>. But we're biased. And we write less of it than we think we do. <a href="https://blog.codinghorror.com/when-understanding-means-rewriting/">We spend far more time understanding code than writing it</a>.</p>
<p>Anyway, as Ian points out, <b>the importance of the code we do write is absolutely dwarfed by everything else that goes on around it.</b> Raise your hand if you've ever poured your heart and soul into an application that never shipped. I know I have. And that's just the tip of the iceberg; there are hundreds of reasons the code you write may have zero impact on the world. If nobody knows about your code, if nobody can understand your code, if for whatever reason <em>your code doesn't even ship</em>  then <b>have you really accomplished anything by writing that code?</b></p>
<p>Maybe the best way to succeed as a programmer is to cut out the low value activities entirely and <a href="http://steve-yegge.blogspot.com/2006/07/get-famous-by-not-programming.html">stop writing code altogether</a>. Steve Yegge explains:</p>
<blockquote>
<p>Do you have any programming heroes? I do! Oddly enough, though, I've never really seen much of their code. <b>Most of the famous-ish programmers I respect have actually made their impact on me through writing, and it's usually just prose, with maybe a little code interspersed.</b></p>
<p>There are programmers I admire who've built things that I use a lot. But when I try to come up with a list of programmers I admire (and I specifically mean people I don't know personally), I find they almost always fall into one (or both) of just two categories:</p>
<ul>
<li>People who wrote a useful programming language, an operating system, or an especially important framework.</li>
<li>People who wrote a really neat book about programming.</li>
</ul>
<p>When someone builds a framework    any environment that we live in and actually enjoy programming in    and there's one person who's chiefly identifiable as the primary author of that framework, then I think we tend to admire that person, and unlike other programmers, the person starts to become famous.</p>
<p>Even if they're a crappy programmer.</p>
<p>Not that we'd really know, because how often do we go look at the source code for the frameworks we use? How much time have you spent examining the source code of your favorite programming language's compiler, interpreter or VM? And by the time such systems reach sufficient size and usefulness, how much of that code was actually penned by the original author?</p>
</blockquote>
<p>Am I really telling developers to stop writing code? No, not really. Developers are already good at writing code. It's why they became software developers in the first place. Writing reams of code just digs you deeper into an already deeply specialized skill. What I <em>am</em> proposing is that we spend less time coding and more time developing skills in other areas that <em>complement</em> our coding skills. <a href="https://blog.codinghorror.com/is-writing-more-important-than-programming/">Become a better writer</a>. <a href="https://discourse.codinghorror.com/t/presentation-zen/895">Become a better speaker</a>. <a href="https://blog.codinghorror.com/being-technologically-savvy-isnt-enough/">Improve your personal skills</a>. <a href="https://blog.codinghorror.com/buy-the-community-not-the-product/">Participate in the community</a>. <b>Try to spend some time talking to people instead of the compiler.</b> That's how you distinguish yourself from your peers. And that's ultimately how you become a better software developer, too.</p>
<p>Of course, this isn't a zero-sum game. You can have it both ways. <b>Ideally, you'd write code, and then write or talk about the code in a way that inspires and illuminates other people.</b> But we don't have an infinite amount of time, either. If you have to choose between writing code and writing <em>about</em> code, remember which side of the equation is more important  and balance accordingly.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/does-writing-code-matter/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Swiss Army Knife or Generalizing Specialist ]]></title>
<link>https://blog.codinghorror.com/swiss-army-knife-or-generalizing-specialist/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/000710.html">Does Writing Code Matter?</a>, I proposed that developers spend less time on the technical stuff, which they're already quite good at, and more time cultivating other non-technical skills that developers tend to lack. One commenter took issue with this approach:
</p>
<p>
</p>
<blockquote>
I don't agree with the premise of improvement of weaknesses. I like the premise of enhancing talent and being aware of weaknesses. "Know yourself" doesn't mean go learn everything and become a Swiss Army Knife.
</blockquote>
<p>
It's easy to take my modest proposal to an absurd extreme: either you write code all day, or you become completely non-technical and never touch a compiler again. Or maybe you spend so much time pursuing related interests that you become a jack-of-all-trades, master of none. In other words, a Swiss Army Knife.
</p>
<p>
<a href="http://www.outdoorlife.com/outdoor/photogallery/gallery/0,20036,1304110,00.html"><img alt="image placeholder" >
</p>
<p>
First, a clarification. <b>Cultivating non-technical skills is, first and foremost, about becoming a better software developer.</b> If you wanted to be rich, famous, and get girls, then you picked the wrong profession. I'm sorry I had to be the one to break this to you.
</p>
<p>
Instead of a Swiss Army Knife, you should strive to be a <a href="http://www.agilemodeling.com/essays/generalizingSpecialists.htm">generalizing specialist</a>.
</p>
<p>
</p>
<blockquote>
<b>A generalizing specialist is someone with one or more technical specialties who actively seeks to gain new skills in both their existing specialties as well as in other areas, including both technical and domain areas.</b> When you get your first job as an IT professional it is often in the role of a junior programmer or junior DBA.  You will initially focus on becoming good at that role, and if you're lucky your organization will send you on training courses to pick up advanced skills in your specialty.  Once you're adept at that specialty, or even when you've just reached the point of being comfortable at it, it is time to expand your horizons and learn new skills in different aspects of the software lifecycle and in your relevant business domain.  When you do this you evolve from being a specialist to being a generalizing specialist.  Generalizing specialists are often referred to as craftspeople, multi-disciplinary developers, cross-functional developers, polymaths, or even "renaissance developers".
<p>
A generalizing specialist is more than just a generalist.  A generalist is a jack-of-all-trades but a master of none, whereas a generalizing specialist is a jack-of-all-trades and master of a few.  Big difference.
</p>
</blockquote>
<p>
Too much specialization is a pitfall of its own. Have you ever worked on projects where you had "the database guy", "the testing guy", "the web guy", and so forth? Wayne Allen refers to this as a process smell-- <a href="http://weblogs.asp.net/wallen/archive/2005/09/30/426299.aspx">waiting on specialists</a>.
</p>
<p>
</p>
<blockquote>
A common process smell in new agile teams is more and more stories/backlog items incomplete at the end of the iteration. There are a couple of different reasons this might happen, but the one I'm interested in today can be detected by the claim "I finished my tasks". The clear implication is that "I got my stuff done, but someone else didn't".
<p>
A little additional research usually shows that people are waiting for other people with some kind of specialization such as database, QA, UI, or any other skill that isn't widely distributed among the team. As an agile team this is where specialization gets in the way. In a more traditional project the measure of delivery is the task, however, in agile projects the measure of delivery is working features. Specialists typically don't deliver working features, thus the problem. Note I am not saying that specializations aren't needed, but they do need to be balanced with other needs that help deliver features.
</p>
</blockquote>
<p>
How do you know if you're on the road to becoming a generalizing specialist? Well, as in any good exercise regimen, you should be regularly exceeding your comfort zone. <a href="http://www.agileadvice.com/archives/2005/08/generalizing_sp.html">Sometimes you have to stretch a little</a>:
</p>
<p>
</p>
<blockquote>
<b>The generalizing specialist is willing and able to learn new skills - to stretch as the needs of the team change.</b> And since change is natural, this is an essential attitude for team members. However, we are usually trained, and strongly encouraged to have a deep specialty. This approach to education and training is a natural consequence to the typical organizational model for work and society. Therefore, if a team is converting to agile work methods, people need to be coached to stretch themselves and learn new things.
</blockquote>
<p>
I see too many software developers burrowing themselves deeper and deeper into the same skillsets and specialties. It's all too easy to fall into that rut. There's an entire universe of software engineering skills outside the narrow realm of coding. <b>To be a better software developer, grow from a specialist to a generalizing specialist.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/swiss-army-knife-or-generalizing-specialist/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ CAPTCHA Effectiveness ]]></title>
<link>https://blog.codinghorror.com/captcha-effectiveness/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>If you've used the internet at all in the last few years, I'm sure you've seen your share of <a href="http://en.wikipedia.org/wiki/Captcha">CAPTCHAs</a>:</p>
<p><img alt="image placeholder" >
<p>Of course, nobody <em>wants</em> to use CAPTCHAs. They're a necessary evil, just like the locks on the doors to your home and your car.</p>
<p>CAPTCHAs are designed to discriminate between computer scripts from spammers and real human beings. There's a <a href="http://weblogs.asp.net/rhoward/archive/2006/07/19/Why-no-CAPTCHA_3F00_.aspx">popular misconception</a> in technical circles that <a href="http://en.wikipedia.org/wiki/Captcha">CAPTCHA</a> has been "broken":</p>
<blockquote>CAPTCHA, which stands for (C)ompletely (A)utomated (P)ublic (T)uring test to tell (C)omputers and (H)umans (A)part, works well for small sites but larger 'community' sites where there are multiple SPAM targets CAPTCHA only provides a false sense of security - it can be broken fairly easily and serious spammers are getting more sophisticated all the time.</blockquote>
<p>Some people actually believe that spammers can now "fairly easily" write scripts which use advanced <a href="http://en.wikipedia.org/wiki/Optical_character_recognition">optical character recognition</a> to automatically defeat any online CAPTCHA form.</p>
<p>Although there have been a number of <a href="http://en.wikipedia.org/wiki/Captcha#Computer_character_recognition">CAPTCHA-defeating proof of concepts</a> published, there is no practical evidence that these exploits are actually working in the real world. And <strong>if CAPTCHA is so thoroughly defeated, why is it still in use on virtually every major website on the internet?</strong> Google, Yahoo, Hotmail, you name it, if the site is even remotely popular, their new account forms are protected by CAPTCHAs.</p>
<p>The comment form of my blog is protected by what I refer to as "naive CAPTCHA", where <em>the CAPTCHA term is the same every single time</em>. This has to be the most ineffective CAPTCHA of all time, and yet it stops 99.9% of comment spam. I can count on two hands the number of manually entered comment spams I've gotten since I implemented it. Granted, Yahoo is more popular than my blog by many orders of magnitude. But it's still strong evidence that moving the difficulty bar up even one tiny notch can be quite effective in reducing spam. I went from cleaning up comment spam every day to cleaning one per month. Big difference.</p>
<p>I've been experimenting with improving the rendering algorithms in my <a href="http://www.codeproject.com/aspnet/CaptchaControl.asp">CAPTCHA server control</a>, and it's interesting how fragile typical computer OCR really is. SimpleOCR has <a href="http://www.simpleocr.com/Demo/">an online form that allows you to upload and OCR small greyscale TIF images</a>. Here are the results of submitting a few standard 180x50 CAPTCHAs from my reworked rendering algorithm. Note that these CAPTCHAs all use the same font, Courier New.</p>
<table width="600">
<tbody>
<tr>
<td><strong>OCR result</strong></td>
<td></td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Standard</td>
<td>CQXKN</td>
<td>5/5</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Low perturbation</td>
<td>KxT*2</td>
<td>3/5</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Medium perturbation</td>
<td>acNx4</td>
<td>2/5</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>High perturbation</td>
<td>Kc</td>
<td>0/5</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Extreme perturbation</td>
<td>(blank)</td>
<td>0/5</td>
</tr>
<tr>
<td><img alt="image placeholder" >
<td>Standard, low noise</td>
<td>(blank)</td>
<td>0/5</td>
</tr>
</tbody>
</table>
<p>I didn't expect it to do well, but I was frankly surprised how poorly the SimpleOCR engine actually performed. <strong>Adding a tiny bit of noise or perturbation to the CAPTCHA text was all it took to break the OCR</strong>. I'm sure there are more advanced OCR engines out there that might be able to do somewhat better than the free SimpleOCR engine. Still, it's unlikely that any OCR engine could beat high perturbation  where the characters are <em>physically overlapping each other</em>  plus a little background noise. And that level of CAPTCHA security is absolute overkill unless you happen to run one of the top 100 most popular sites on the internet. Furthermore, none of these are particularly difficult CAPTCHAs. The most extreme perturbation sample shown above is eminently "human solvable", at least in my opinion.</p>
<p>The default settings for my new and improved CAPTCHA server control, a combination of </p>
<ul>
<li>high contrast for human readability </li>
<li>medium, per-character perturbation </li>
<li>random fonts per character </li>
<li>low background noise </li>
</ul>
<p> should be <em>far</em> more protection than most websites need.</p>
<p>
<img alt="image placeholder" >
</p>
<p>Remember, I use "naive CAPTCHA" with 99.9% effectiveness. The "low" settings will be even easier to read than the defaults and may be more appropriate for your user base.</p>
<p>Of course, OCR isn't the only way to attack CAPTCHA. But the other scenarios for spammers "beating" CAPTCHA are even more far-fetched. The <a href="http://petmail.lothar.com/design.html#auto34">Petmail documentation</a> explains:</p>
<h3>1. The Turing Farm</h3>
<blockquote>Let's say spammers set up a sweatshop to employ people to look at computer screens and answer CAPTCHA challenges. They get to send one message for each challenge passed. Assuming 10 seconds per challenge, and paying roughly $5 per hour, that represents $14 per thousand messages. A typical spam run of 1 million messages per day would cost $14,000 per day and require 116 people working 24/7.
<p>This would break the economic model used by most current spammers. A recent Wired article showed one spammer earning $10 for each successful sale. At that rate, the cost of $14,000 for 1,000,000 spam emails requires a 1 in 1000 success rate just to break even, whereas current spammers are managing a 1 in 100,000 or even 1 in 1,000,000 sucess rate.</p>
</blockquote>
<h3>2. The Turing Porn Farm</h3>
<blockquote>A <a href="http://yro.slashdot.org/yro/04/01/28/1344207.shtml">recent slashdot article</a> described a trick in which spammers run a porn site that is gated by CAPTCHA challenges, which are actually ripped directly from Yahoo's new account creation page. The humans unwittingly solve the challenge on behalf of the spammers, who can therefore automate a process that was meant to be rate-limited to humans. This attack is simply another way of paying the workers of a Turing Farm. The economics may be infeasible because porn hosting costs money too.</blockquote>
<p>If you're not using CAPTCHAs because you think they're compromised, then you're too gullible for your own good. There's absolutely no concrete data supporting any of these attack scenarios happening outside laboratory (read: infinite money and time) conditions. Just <a href="http://online.wsj.com/public/article/SB114903737427467003-BFXQeLeq3RdZ5Icuyb8gkda47DA_20070530.html">ask Google</a>:</p>
<blockquote>Some captchas have been solved with more than 90% accuracy by scientists specializing in computer vision research at the University of California, Berkeley, and elsewhere. Hobbyists also regularly write code to solve captchas on commercial sites with a high degree of accuracy.
<p>But several Internet companies say their captchas appeared to be highly effective at thwarting spammers. "Researchers are really good, and the attackers really are not," says Mr. Jeske of Google, based in Mountain View, Calif. "Having these methods in place we find extremely effective against automated malicious attackers."</p>
</blockquote>
<p>The real secret to CAPTCHA is that it hits spammers where they are most vulnerable: <strong>in the pocketbook</strong>. The minute you put up a computational barrier, the entire economic model of spam comes crashing down.</p>
<p>Now if you'd prefer not to use CAPTCHA because it's <em>an inconvenience for the user</em>, I can respect that. <strong>CAPTCHA isn't the only way to block spammers.</strong> But give CAPTCHA its due: it was <a href="http://www2.parc.com/istl/projects/captcha/history.htm">one of the original spam blocking measures used way back in 1997 by AltaVista</a>. And, even more impressively, it's still one of the most effective ways to block spam at its source <em>today</em>.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-25T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/captcha-effectiveness/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Build Server: Your Project's Heart Monitor ]]></title>
<link>https://blog.codinghorror.com/the-build-server-your-projects-heart-monitor/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Although I've been <a href="http://www.codinghorror.com/blog/archives/000149.html">dismissive of build servers</a> in the past, I've increasingly come to believe that <b>the build server is critical-- it's the heart monitor of your software project</b>. It can tell you when your project is healthy, and it can give you advance warning when your project is about to flatline.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
You should start out with a simple pulse-- <b>whether or not your project builds, and how often you're building it</b>. The build server can be so much more, though. The Zutubi article <a href="http://zutubi.com/products/pulse/articles/buildenlightenment/">The Path to Build Enlightenment</a> provides a great overview of what a build server can do for your project:
</p>
<p>
</p>
<ul>
<li>
<b>Machine independence</b><p>
Let's get past "It runs on my machine" first. The build server retrieves everything from source control, and builds on a machine untainted by developer dependencies. It forces an integration point for all the developers working on the project, in a neutral, indifferent way. You can hate your co-workers, but it's irrational to hate the build server.
</p>
<p>
</p>
</li>
<li>
<b>Scripted Builds</b><p>
Your build process is now clearly defined by a script and under source control. You might say it's almost.. self-documenting. Isn't that the way it should be?
</p>
<p>
</p>
</li>
<li>
<b>Scripted tests</b><p>
Sure, maybe all the code compiles. But does the software actually <i>work</i>? The build server is a logical place to integrate some basic tests to see if your product is doing what it's supposed to do. Mere compilation is not enough. The more tests you accrete into the build over time, the better the feedback is from the build, and the more valuable it will be to your project. It's a positive reinforcement cycle.
</p>
<p>
</p>
</li>
<li>
<b>Daily and Weekly builds</b><p>
Once you have the build server set up, you'll establish a rhythm for your project, where you're building regularly. When something breaks, you'll know, and quickly. A solid heartbeat from the build server leads to a confident development team.
</p>
<p>
</p>
</li>
<li>
<b>Continuous Integration</b><p>
This is the holy grail of build server integration-- doing a complete build every time something is checked into source control. Once you've gotten your feet wet with weekly and daily builds, it's the next logical step. It also forces you to keep your test and build times reasonable so things can proceed quickly.
</p>
<p>
</p>
</li>
<li>
<b>Automated releases</b><p>
The build server automates all the drudge work associated with releasing software. It..
</p>
<p>
</p>
<ol>
<li>labels the source code with the build number
</li>
<li>creates a uniquely named drop folder for that particular build
</li>
<li>tags the binaries with the build number in the file metadata
</li>
<li>creates installation packages and installers
</li>
<li>publishes the installs to websites, FTP sites, or file paths
</li>
</ol>
</li>
<p>
A well-designed, fully-automated build process makes it trivially easy for anyone to get a particular release, or to go back in time to a previous release. And it's less work for you when the build machine does it.
</p>
<p>
</p>
<li>
<b>Building in multiple environments</b><p>
For advanced projects only. If you have to test your code against 10 different languages, or different variants of an operating system, consider integrating those tests into the build process. It's painful, but so is that much ad-hoc testing.
</p>
<p>
</p>
</li>
<li>
<b>Static and Dynamic Analysis</b><p>
There's an entire universe of analysis tools that you can run on your code during the build to produce the <a href="http://www.codinghorror.com/blog/archives/000681.html">wall of metrics</a>. FxCop, nDepends, LibCheck, and so forth. There are lots of metrics, and only you and your team can decide what's important to you. But some of these metrics are really clutch. At the very least, <a href="http://research.microsoft.com/research/pubs/view.aspx?type=Publication&amp;id=1359">you'll want to know how much code churn</a> you have for each build.
</p>
<p>
</p>
</li>
</ul>
<p>
If you don't have a build server on your project, what are you waiting for?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-26T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-build-server-your-projects-heart-monitor/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Single Most Important Virtual Machine Performance Tip ]]></title>
<link>https://blog.codinghorror.com/the-single-most-important-virtual-machine-performance-tip/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If you use virtual machines at all, you should have the single most important virtual machine performance tip committed to heart by now: <b>always run your virtual machines from a separate physical hard drive</b>:
</p>
<p>
</p>
<blockquote>
[the] biggest performance win is to put the virtual hard disks on separate disk spindles from the operating system.  The biggest performance hit in virtual machines is disk I/O. Making the VM fight with your OS and swap disk makes this issue much, much worse.  Additionally, today's USB 2.0 and firewire external hard drives run on a fast interface bus, have large buffers and spin at 7,200 rpm, as opposed to 4,200 rpm for most laptop hard drives.
</blockquote>
<p>
I've talked about <a href="http://www.codinghorror.com/blog/archives/000207.html">virtualization performance penalties</a> before, but this bears repeating. I originally read this tip at <a href="http://www.hanselman.com/blog/CommentView.aspx?guid=097ce75a-838a-4511-a858-d6de8e8e78a9">Scott's blog</a>, and I've heard it echoed in emails directly from the <a href="http://blogs.msdn.com/Virtual_PC_Guy/">Virtual PC Guy</a> himself.
</p>
<p>
It's true that most laptop drives are at 5,400 rpm these days, and a scant few even run at 7,200 rpm. But the tip is still as valid as ever. <b>The primary performance bottleneck in virtual machines, by a very wide margin, is the hard drive.</b> Although it's possible to <a href="http://www.codinghorror.com/blog/archives/000639.html">squeeze a complete install of Windows XP into a 641 megabyte VM hard drive image file</a>, most VM hard drive image files rapidly grow to multiple gigabytes. It's not unusual to see VMs end up 5 or 10 gigabytes in size. It shouldn't be too surprising that the disk subsystem has a disproportionately large impact on overall virtual machine performance.
</p>
<p>
That's one reason why all the desktop machines I build now have <b>two hard drives</b>:
</p>
<ol>
<li>A faster, smaller drive for the operating system and essential applications. You can't beat the 10,000 rpm Western Digital Raptor series for this role.
</li>
<li>A larger data drive for virtual machines and everything else.
</li>
</ol>
<p>
This way, whenever I boot up a VM, it's running from a different physical spindle than the operating system, and thus running at optimal speeds. It's also a good way to segregate your operating system and data in case you need to do a complete wipe of your operating system. And it's certainly a much safer and more practical two drive approach than <a href="http://www.codinghorror.com/blog/archives/000335.html">RAID-0 on the desktop</a>.
</p>
<p>
Unfortunately, we can't drop a second drive into our laptops. But there's another solution that works almost as well: <b>external SATA and USB2 enclosures</b>. These enclosures offer the best of both worlds: high-speed USB 2.0 interfaces for laptops, and full-speed eSATA connections for desktops.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The <a href="http://www.silentpcreview.com/article673-page1.html">Icy Dock</a>, pictured above, is one of the best of these new enclosures. It's a bit spendy, but it's remarkably well made from mostly aluminum, with a clever locking tray mechanism. It also includes all the extras you need to connect it to your PC, including a USB 2.0 cable, an eSATA bracket, and an eSATA cable. Just add the desktop SATA drive of your choice.
</p>
<p>
I've talked about <a href="http://www.codinghorror.com/blog/archives/000673.html">the difference between USB 2.0 and full-blown SATA performance</a> before. Here's a direct comparison between a modern 250 gigabyte 7,200 rpm SATA drive in the Icy Dock (connected via USB), and my laptop's internal 100 gigabyte 5,400 rpm hard drive:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The USB 2.0 interface is nothing to sneeze at. With a fast 7,200 rpm desktop drive mounted, it does a little better than the internal laptop drive overall, once you factor in random access times and the constant speed across the entire drive. But it's obviously limited by the interface. That's why the option to connect a drive via its native SATA interface is so desirable in an external enclosure. Some recent motherboards even include eSATA connectors on their back panel, such as the Asus P5B that I <a href="http://www.codinghorror.com/blog/archives/000697.html">recently built</a>. I presume it's only a matter of time before some enterprising laptop manufacturer releases a laptop with an eSATA connector.
</p>
<p>
It's not a slam-dunk performance victory over the internal laptop drive in absolute terms. But <b>the real-world performance improvement gained from running a VM on an external USB 2.0 drive is quite noticeable</b>. Recommended.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-single-most-important-virtual-machine-performance-tip/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Whitelist, Blacklist, Greylist ]]></title>
<link>https://blog.codinghorror.com/whitelist-blacklist-greylist/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I recently got into a spirited discussion about <a href="http://akismet.com/">Akismet</a>. What is Akismet?
</p>
<p>
</p>
<blockquote>
When a new comment, trackback, or pingback comes to your blog it is submitted to the Akismet web service which runs hundreds of tests on the comment and returns a thumbs up or thumbs down.
</blockquote>
<p>
Akismet is awfully coy about the "tests" they run to distinguish between spam and everything else. I believe Akismet is essentially the same as the old <a href="http://www.jayallen.org/projects/mt-blacklist/">mt-blacklist</a> plugin I use to block trackback spam. But instead of manually entering blacklist terms, Akismet <a href="http://akismet.com/faq/">harnesses the collective knowledge of the intarwebs</a>. As soon as one person blacklists something, it's blacklisted for the entire Akismet community. And it definitely works. It's so effective that <a href="http://www.hanselman.com/">some people</a> use it as their only protection against spam comments and trackbacks. I think this is very unwise.
</p>
<p>
First of all, blacklists aren't a panacea. They have their pros and cons. Just ask <a href="http://photomatt.net/">Matt Mullenweg</a>, the author of Akismet. He recently left <a href="http://elliottback.com/wp/archives/2006/09/23/akismet-hack/">this comment</a> on a blog post:
</p>
<p>
</p>
<blockquote>
Unfortunately, <b>the DNS realtime blacklists cause an unusually high false positive rate</b>, which is why we don't use them anymore.
</blockquote>
<p>
Interesting. And if you're going to keep a blacklist, you might as well keep a greylist and whitelist, too:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
These three lists have been around as long as spam itself:
</p>
<p>
Items on the <b>Blacklist</b> are <i>never allowed through</i>. They are either held in a moderation queue, or deleted.
</p>
<p>
Items on the <b>Whitelist</b> are <i>always allowed through</i>.
</p>
<p>
Items on the <b>Greylist</b> are <i>held for human moderation</i>.
</p>
<p>
Akismet also offers <a href="http://www.darcynorman.net/image/2006/06/akismet-spam-attack">a moderation queue</a>, so it has aspects of a greylist as well. Instead of spending time maintaining a blacklist, you spend time <a href="http://www.problogger.net/archives/2006/07/29/comment-spam-is-akismet-ok/">staring down a greylist moderation queue</a>. I'm not so sure that's an improvement. If you consider Akismet a success because you <i>ignore the moderation queue entirely</i>, have you really succeeded?
</p>
<p>
It's also quite possible to use <a href="http://www.iampariah.com/blog/2005/12/whitelist-spam-attacks-threaten-blogs-and-email/">whitelist attacks</a> on blacklists, where spammers use innocent and legitimate URLs in their spam. I've had a few of these myself. Even if you don't have a whitelist, attacks like this greatly reduce the effectiveness of a blacklist-- legitimate domains end up blacklisted through collateral damage.
</p>
<p>
But let's forget, for a moment, all the problems I just described with blacklists, whitelists, and greylists. <b>The core problem is relying on a single method of defense against spam.</b> Relying <i>only</i> on Akismet means:
</p>
<p>
</p>
<ol>
<li>You've added an external dependency to your website. <a href="http://www.codinghorror.com/blog/archives/000497.html">I hate dependencies</a>, and I always strive to keep the number of dependencies I accept to an absolute minimum.
</li>
<li>If Akismet goes down, you either get inundated by spam while the floodgates are open, or nobody can comment/trackback. Neither scenario is desirable.
</li>
<li>I get 75 spam trackbacks per <i>hour</i> on this blog. Multiply that the number of blogs on the internet, and you get an astronomically large number. Why should Akismet have to check every single one of those? Does Akismet have the capacity to scale that large? And is it reasonable to expect them to?
</li>
</ol>
<p>
I can understand making the choice to use Akismet exclusively for trackbacks, where <a href="http://underscorebleach.net/jotsheet/2005/08/track-back-ping-movable-type-wordpress-blog-blogging-blogger-weblog-spam-spammer-spamming">our options for combating spam are severely limited</a>. But for comments, <a href="http://www.codinghorror.com/blog/archives/000712.html">abandoning CAPTCHA</a> in favor of Akismet is unforgivable. <a href="http://engtech.wordpress.com/">Engtech</a> explains some of the problems with this approach in a recent comment:
</p>
<p>
</p>
<blockquote>
[Akismet] has been pretty effective, but there's been a few interesting cases:
<p>
</p>
<ul>
<li>compliment spam ("great post!" with website field linking to their p-rn/adsense splog site)
</li>
<li>only attacking blogs that appear to still have the default post as the first post -- less likely to monitor spam.
</li>
<li>one p-rn spammer who finds political/pop culture keywords in a post and inserts human crafted messages. Like: "Some people say Matt Damon isn't that good of an actor, I really liked him in Talented Mr. Ripley" whenever it finds a post with "Matt Damon"
</li>
</ul>
<p>
The one thing it has absolutely sucked at is spammers-to-be. People who are just testing out spam generation algorithms that have no payload. So you'll get random gibberish from an IP address and it will take a few days for Akismet to learn.
</p>
</blockquote>
<p>
Hearing this pains me greatly. All the of the above could have been completely eliminated by using <i>both</i> methods: <b>CAPTCHA to validate that it's a human, then Akismet to validate that it's not human-entered spam.</b>
</p>
<p>
Akismet is a fine addition to our anti-spamming toolkit. But that doesn't mean it's a good idea to outsource your entire anti-spam effort to a single website, either. Anti-spam security starts at home. For best results, use <a href="http://en.wikipedia.org/wiki/Defence_in_depth">defense in depth</a> and <b>combine local anti-spam measures, such as CAPTCHA, with Akismet as a backup.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/whitelist-blacklist-greylist/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ What did you write five years ago? ]]></title>
<link>https://blog.codinghorror.com/what-did-you-write-five-years-ago/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Here's an excellent bit of halloween advice from <a href="http://www.larkware.com/dg7/TheDailyGrind1003.aspx">Mike Gunderloy</a>: <b>go read some source code you wrote five years ago for a real scare.</b>
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's a good idea to go occasionally back to the well and get a sense of your progress as a so-called professional software developer. My goal is to <a href="http://www.codinghorror.com/blog/archives/000530.html">suck slightly less every year</a>. What were you writing in October, 2001?
</p>
<p>
I was writing a lot of VBScript code at that time, in the form of Windows Script Host scripts and classic ASP pages. One of the few nice things about WSH was its modern (for the time) regex support, so I first discovered <a href="http://www.codinghorror.com/blog/archives/000245.html">the joy of regular expressionism</a> around this time. I was also beginning to develop a healthy dislike of XML, which has matured into a lifelong ennui. Not that plain text is any better, but angle brackets aren't a silver bullet, either.
</p>
<p>
Reading through some of my five year old code, <b>it's difficult to tell my personal WTFs apart from the WTFs inherited due to limitations in the WSH languages and Classic ASP coding environments</b>. It's only been five years, true, but I think the clean-room elegance of the .NET framework, and the vastly improved development environment offered by Visual Studio 200x, far outstrip my meager improvements as a developer in the same time frame. Did I make mistakes? Absolutely. But when the only tools you have to choose from are <code>Response.Write</code> and <code>Server.CreateObject</code>, it's hard to imagine what you could have done differently. It's like <a href="http://weblogs.asp.net/alex_papadimoulis/archive/2005/05/25/408925.aspx">trying to choose between using an old shoe or a glass bottle</a> to hammer nails. I'm just lucky I still have the use of both of my hands.
</p>
<p>
Perhaps, in hindsight, this is an argument in support of <a href="http://www.infoq.com/articles/Netter-on-Rails">learning alternative development environments</a>. In 2001, I knew I was wearing blinders-- and I also knew .NET was right around the corner. But what's around the <i>next</i> corner? How will I look back on <i>today's</i> code five years from now?
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-10-31T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/what-did-you-write-five-years-ago/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The High Score Table ]]></title>
<link>https://blog.codinghorror.com/the-high-score-table/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The <a href="http://www.emuunlim.com/doteaters/play2sta2.htm">first video game to introduce a high score table was Asteroids</a>, and after that they were a key fixture in virtually every arcade game from the 80's and 90's. One of my favorite high score tables was in <a href="http://en.wikipedia.org/wiki/Gaplus">Gaplus</a>, the little known sequel to the mega-popular <a href="http://en.wikipedia.org/wiki/Galaga">Galaga</a>, which was itself the sequel to <a href="http://en.wikipedia.org/wiki/Galaxian">Galaxian</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I thought <b>the inclusion of blood type in the high score table for Gaplus was a clever commentary on the meaninglessness of high score tables</b> by the game's developers. As it turns out, <a href="http://groups.google.com/group/rec.games.video.arcade.collecting/msg/e208666c62f099ea?dmode=source">it's just a Japanese eccentricity</a>:
</p>
<p>
</p>
<blockquote>
If this is a Japanese game, this would make some sense. In Japan, blood type is matched with personality, much like horoscopes here in the US. It's not uncommon to see blood type given for different characters in a game or comic, along with sex, age, etc. It's an important vital statistic that gives more insight to a person!
</blockquote>
<p>
We may not play arcade games any more, but <b>we still have our high score tables</b>.
</p>
<p>
Technorati maintains a ranking of the top 100 blogs based on their <a href="http://www.technorati.com/help/faq.html#ranking">Technorati Rank</a>:
</p>
<p>
<a href="http://www.technorati.com/pop/blogs/"><img alt="image placeholder" >
</p>
<p>
We also have traffic metrics, which is <a href="http://www.alexa.com/site/help/traffic_learn_more">what Alexa's top 100 websites is based on</a>:
</p>
<p>
<a href="http://www.alexa.com/site/ds/top_sites?ts_mode=lang&amp;lang=en"><img alt="image placeholder" >
</a>
</p>
<p>
And of course, there's the most wizardly of all high scores, Google's <a href="http://www.google.com/corporate/tech.html">PageRank</a>:
</p>
<p>
<a href="http://www.phplivesupport.com/google_pagerank.php"><img alt="image placeholder" >
</a>
</p>
<p>
<i>What's your high score?</i> And more importantly, <b>what's your blood type?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-high-score-table/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Growing up with the Microcomputer ]]></title>
<link>https://blog.codinghorror.com/growing-up-with-the-microcomputer/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I read Robert X Cringley's book <a href="http://www.amazon.com/exec/obidos/ASIN/0887308554/codihorr-20">Accidental Empires</a> shortly after it was published in 1992. It's a gripping worm's eye view of Silicon Valley's formative years. It's also <a href="http://www.searls.com/overdriv2.html">Doc Searls' favorite book about the computer industry</a>. Highly recommended.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0887308554/codihorr-20"><img alt="image placeholder" >
</p>
<p>
I didn't realize that the book was later expanded and made into a <a href="http://www.pbs.org/nerds/">three-hour PBS documentary</a> in 1995, <a href="http://www.amazon.com/exec/obidos/ASIN/1162826436/codihorr-20">Triumph of the Nerds</a>. I rented the movie on Netflix and it's a fantastic companion to the book. The time capsule interviews alone make it worth watching: Steve Jobs, Steve Ballmer, Bill Gates, Larry Ellison, and many other key luminaries.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/1162826436/codihorr-20"><img alt="image placeholder" >
</a>
</p>
<p>
Watching the documentary brought on waves of nostalgia. I've always felt like <b>the home computer and I grew up together</b>. I was born in 1970. In 1971, Bill Gates and Paul Allen formed Traf-O-Data, and Steve Jobs and Steve Wozniak started selling <a href="http://en.wikipedia.org/wiki/Blue_box">blue boxes</a> in southern California. In 1975, the first "personal" computer, the <a href="http://en.wikipedia.org/wiki/Altair_8800">Altair 8800</a>, was introduced.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's difficult to get excited about a machine with no display and a row of dip-switches for input. Only <i>two years later</i>, in 1977, the first <i>modern</i> personal computer was introduced: the <a href="http://en.wikipedia.org/wiki/Apple_II">Apple II</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The Altair is barely recognizable as a personal computer, even though it is technically the first one. And yet the Apple II, a mere two years later, is the <b>archetypal personal computer</b>. Every modern home computer released after 1977 followed the template that Apple established for the industry: molded plastic case, expansion slots, CRT display, integrated keyboard, and floppy disk drive. Apple, along with the first killer app for the personal computer, <a href="http://en.wikipedia.org/wiki/VisiCalc">VisiCalc</a>, dominated the home computer industry until 1981. That's when the IBM PC hit the market-- and the clones followed.
</p>
<p>
Although I had access to Apple II computers in middle school, we couldn't afford an Apple until 1984, when we brought home the Apple //c. I never quite made the transition to the Macintosh, which was even more expensive. Still, many of my formative programming experiences were in AppleBASIC.
</p>
<p>
Have personal computers grown up since the early seventies? Sure. They've been around for more than 30 years now. But reading <a href="http://www.amazon.com/exec/obidos/ASIN/0887308554/codihorr-20">Accidental Empires</a> and watching <a href="http://www.amazon.com/exec/obidos/ASIN/1162826436/codihorr-20">Triumph of the Nerds</a>, I realized that <b>computers still have a long way to go before they're fully grown up. And so do I.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-02T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/growing-up-with-the-microcomputer/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Customization: The Software Tar-Baby ]]></title>
<link>https://blog.codinghorror.com/customization-the-software-tar-baby/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Vendors often pitch <a href="http://www.edocmagazine.com/vault_articles.asp?ID=25530&amp;header=e_features_header.gif">customization as a feature of their software</a>:
</p>
<p>
</p>
<blockquote>
In the end, customizations and enhancements to a software solution are nearly always needed. This allows the software to be tailored to your needs, allowing for greater success, either with users or in business processes. They shouldn't be considered "necessary evils," but rather a "project variable." As long as they are justified, understood, and developed by the right resources, a product's modification can close the gap between a good product, and one that fits your organization perfectly.
</blockquote>
<p>
In my experience, software customization is as much a danger as a benefit. I am reminded of <a href="http://www.otmfan.com/html/brertar.htm">the Tar-Baby parable</a>:
</p>
<p>
</p>
<blockquote>
"How are you feeling this morning?" says Brer Rabbit, says he.
<p>
The Tar-Baby didn't say a thing.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
"What is the matter with you then? Are you deaf?" says Brer Rabbit, says he. "Cause if you are, I can holler louder," says he.
</p>
<p>
The Tar-Baby stayed still.
</p>
<p>
"You're stuck-up, that's what's wrong with you. You think you're too good to talk to me," says Brer Rabbit, says he. "And I'm going to cure you, that's what I'm going to do," says he.
</p>
<p>
Tar-Baby didn't say a word.
</p>
<p>
"I'm going to teach you how to talk to respectable folks if it's my last act," says Brer Rabbit, says he. "If you don't take off that hat and say howdy, I'm going to bust you wide open," says he.
</p>
<p>
Tar-Baby stayed still.
</p>
<p>
Brer Rabbit kept on asking her why she wouldn't talk and the Tar-Baby kept on saying nothing until Brer Rabbit finally drew back his fist, he did, and blip--he hit the Tar-Baby on the jaw. But his fist stuck and he couldn't pull it loose. The tar held him. But Tar-Baby, she stayed still.
</p>
<p>
"If you don't let me loose, I'm going to hit you again," says Brer Rabbit, says he, and with that he drew back his other fist and blap--he hit the Tar-Baby with the other hand and that one stuck fast too.
</p>
<p>
Tar-Baby she stayed still.
</p>
<p>
"Turn me loose, before I kick the natural stuffing out of you," says Brer Rabbit, says he, but the Tar-Baby just sat there.
</p>
<p>
She just held on and then Brer Rabbit jumped her with both his feet. Then Brer Rabbit yelled out that if that Tar-Baby didn't turn him loose, he was going to butt her crank-sided. Then he butted her and his head got stuck.
</p>
<p>
Brer Fox walked out from behind the bushes and strolled over to Brer Rabbit, looking as innocent as a mockingbird. "Well, I expect I got you this time, Brer Rabbit," says he. "Maybe I don't, but I expect I do. You've been around here sassing after me a mighty long time, but now it's the end. And then you're always getting into something that's none of your business," says Brer Fox, says he. <b>"Who asked you to come and strike up a conversation with this Tar-Baby? And who stuck you up the way you are? Nobody in the round world. You just jammed yourself into that Tar-Baby without waiting for an invitation,"</b> says Brer Fox, says he.
</p>
</blockquote>
<p>
It's tempting to view customization as the solution to any software limitations you encounter. If the software isn't doing exactly what you want, roll up your sleeves and mold the software into a better solution. This is usually done with the vendor's blessing; it's designed to be "extensible", after all. <b>But like the tar-baby, extensive software customizations can trap you.</b>
</p>
<p>
Where do you draw the line between customization, extensibility, and full-bore programming environment? I've participated in several projects where extensive customization of a third-party software package precluded us from upgrading to newer versions, or even switching to a competitor. Extracting yourself from a particular software choice is difficult even in the best of circumstances. But once you've performed extensive software customizations, extracting yourself from that software becomes <i>nearly impossible</i>.
</p>
<p>
And that's why, the next time a vendor sells you on customizations, you should consider the parable of the Tar-Baby <i>before</i> you're stuck in it.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/customization-the-software-tar-baby/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ KeyTraino for Visual Studio 2005 ]]></title>
<link>https://blog.codinghorror.com/keytraino-for-visual-studio-2005/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Leon Bambrick is <a href="http://www.codinghorror.com/blog/archives/000622.html">full of good ideas</a>. Like <a href="http://secretgeek.net/KeyTraino.asp">KeyTraino</a>, for instance:
</p>
<p>
</p>
<blockquote>
When you use the toolbar, the menus or the context-menus of an application, KeyTraino shows the alternative keystroke you could've used.
</blockquote>
<p>
Evidently someone at SlickEdit is wearing a tinfoil hat that transmits at the same frequency as Leon's, because they just released a <a href="http://www.slickedit.com/content/view/441">free set of Visual Studio 2005 add-ins</a> that includes the KeyTraino feature:
</p>
<p>
</p>
<blockquote>
The Command Spy monitors command execution and allows you to see exactly what commands you've run, how many times you've run them and what key bindings are used to invoke those commands. The main purpose of this tool is to allow you to learn what commands are bound to which keystrokes, so that you can work faster within the IDE.
</blockquote>
<p>
And it works, too:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This <a href="http://www.slickedit.com/content/view/441">very same add-in</a> has a bunch of other features, too. It allows you to place <a href="http://en.wikipedia.org/wiki/Dancing_Banana">the dancing banana</a> (or any other graphic of your choice) in the editor pane of your IDE. No, I'm not kidding.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Now <i>that's</i> productivity.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-06T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/keytraino-for-visual-studio-2005/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Screencasting for Windows ]]></title>
<link>https://blog.codinghorror.com/screencasting-for-windows/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
If a picture is worth a thousand words, <b>is a single screencast equal to a thousand word blog post?</b>
</p>
<p>
There's a lot to be said for lightweight, embedded screencasts. I'm particularly fond of animated GIF screencasts for small demonstrations. You can see examples in these posts: <a href="http://www.codinghorror.com/blog/archives/000432.html">one</a>, <a href="http://www.codinghorror.com/blog/archives/000419.html">two</a>, <a href="http://www.codinghorror.com/blog/archives/000583.html">three</a>.
</p>
<p>
Here's a compendium of all the screencasting tools I could find, but it's far from comprehensive:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.techsmith.com/products/studio/default.asp">Camtasia Studio</a> ($300)
</li>
<li>
<a href="http://www.bbsoftware.co.uk/BBFlashBack.aspx">BB FlashBack</a> ($40-300)
</li>
<li>
<a href="http://www.adobe.com/products/captivate/">Adobe Captivate 2</a> ($500)
</li>
<li>
<a href="http://www.free-screen-capture.com/screen-recorder/">Super Screen Recorder</a> ($40)
</li>
<li>
<a href="http://www.ejoystudio.com/oripa-screen-recorder/index.htm">oRipa Screen Recorder</a> (free)
</li>
<li>
<a href="http://sourceforge.net/projects/camstudio/">CamStudio Desktop Screen Recorder</a> (free)
</li>
<li>
<a href="http://weblogs.asp.net/jgalloway/archive/2006/11/07/Animated-GIF-Plugin-for-Cropper-_2B00_-some-.NET-Animated-GIF-code.aspx">Animated GIF plugin for Cropper</a> (free)
</li>
<li>
<a href="http://www.peda.com/ggg/">GifgIfgiF</a> ($28)
</li>
<li>
<a href="http://www.debugmode.com/wink/">Wink</a> (free)
</li>
<li>
<a href="http://www.yessoftware.com/products/product_detail.php?product_id=19">DemoCharge</a> ($50-$200)
</li>
</ul>
<p>
You're also probably wondering <b>which of these tools I recommend</b>. What do I look like, Scott Hanselman? I've only used three of these, not all of them. Check out <a href="http://www.donationcoder.com/Reviews/Archive/ScreenCasting/">Donation Coder's screencasting roundup</a> for a blow by blow comparison.
</p>
<p>
Personally, I use <b>GifgIfgiF for quick and dirty animated GIF screencasts</b>, and <b>Camtasia studio</b> for more advanced screencasts where I may need to do editing or render to output formats such as Flash, Quicktime, or Windows Media. One of the biggest challenges in screencasting is choosing an appropriate codec. Video codecs are optimized for movie content, <i>definitely</i> not for GUIs. Screencast results can be quite poor if you choose a typical movie codec. Did you know Windows Media Player has an outstanding <a href="http://www.microsoft.com/technet/prodtechnol/windowsmedia/evaluate/scrcodec.mspx">screen codec</a> that's <a href="http://www.microsoft.com/windows/windowsmedia/forpros/codecs/video.aspx#WindowsMediaVideo9Screen">optimized for GUIs</a>?
</p>
<p>
I recommend picking up one of the free screencasting tools to start with. Add it to your toolkit. Get comfortable with how it works so you can whip out a screen capture session any time the situation calls for it. However, if you find yourself doing a lot of screencasting, I'd definitely invest in one of the more expensive tools that offers more editing options and more choices in output rendering.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/screencasting-for-windows/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Speed Still Matters ]]></title>
<link>https://blog.codinghorror.com/speed-still-matters/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I remember switching my homepage from AltaVista to Google back in 2000 for one simple reason: <b>it was blazingly fast</b>. It's the same reason I don't use <a href="http://www.google.com/ig">personalized Google</a>, or <a href="http://www.google.com/webhp?complete=1&amp;hl=en">Google suggest</a> as my homepage: they're simply too slow.
</p>
<p>
Dare Obasanjo* wonders if <a href="http://www.25hoursaday.com/weblog/PermaLink.aspx?guid=c19f8a74-c0c9-46c6-b85e-cf7ff125e4c0">AJAX apps are rolling page load speeds back six years</a>:
</p>
<p>
</p>
<blockquote>
One big problem with the AJAX craze that has hit the Web is how much slower websites have become now that using Flash and DHTML to add "richness" to Web applications is becoming more commonplace. <b>My mind now boggles at the fact that I now see loading pages that last several seconds when visiting Web sites more and more these days. </b>
</blockquote>
<p>
Dare uses Yahoo! Mail as an example, but I've experienced similarly long load times for the new Hotmail beta, too. The load times can be so long that a combination disclaimer/escape hatch appears below the loading animation:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Maybe I'm just impatient. However, there's a lot of concrete data to support the theory that <b>unless you make it load fast, nobody will stick around long enough to find out what you have to offer</b>. For instance, <a href="http://www.akamai.com/html/about/press/releases/2006/press_110606.html">a recent study</a> found that most shoppers will only wait four seconds for a page to load before abandoning the site entirely.
</p>
<p>
Dare also cited this <a href="http://glinden.blogspot.com/2006/11/marissa-mayer-at-web-20.html">post by Greg Linden</a> which provides more quantitative data on page load times from Google and Amazon:
</p>
<p>
</p>
<blockquote>
Google VP Marissa Mayer just spoke at the Web 2.0 Conference and offered tidbits on what Google has learned about speed, the user experience, and user satisfaction.
<p>
Marissa started with a story about a user test they did. They asked a group of Google searchers how many search results they wanted to see. Users asked for more, more than the ten results Google normally shows. More is more, they said. So Marissa ran an experiment where Google increased the number of search results to thirty. Traffic and revenue from Google searchers in the experimental group dropped by 20%.
</p>
<p>
Ouch. Why? Why, when users had asked for this, did they seem to hate it?
</p>
<p>
After a bit of looking, Marissa explained that they found an uncontrolled variable. The page with 10 results took .4 seconds to generate. The page with 30 results took .9 seconds. <b>Half a second delay caused a 20% drop in traffic. Half a second delay killed user satisfaction.</b>
</p>
<p>
This conclusion may be surprising -- people notice a half second delay? -- but we had a similar experience at Amazon.com. In A/B tests, <b>we tried delaying the page in increments of 100 milliseconds and found that even very small delays would result in substantial and costly drops in revenue.</b>
</p>
</blockquote>
<p>
And let's not forget the classic reference on application responsiveness: <i>Response Time in Man-Computer Conversation Transactions</i>, written way back in 1968 by R.B. Miller. I know it primarily through Jakob Neilsen's <a href="http://www.useit.com/papers/responsetime.html">Response Times: The Three Important Limits</a>.
</p>
<p>
</p>
<blockquote>
<ul>
<li>
<b>0.1 second</b> is about the limit for having the user feel that the system is reacting instantaneously, meaning that no special feedback is necessary except to display the result. <p>
</p>
</li>
<li>
<b>1.0 second</b> is about the limit for the user's flow of thought to stay uninterrupted, even though the user will notice the delay. Normally, no special feedback is necessary during delays of more than 0.1 but less than 1.0 second, but the user does lose the feeling of operating directly on the data.  <p>
</p>
</li>
<li>
<b>10 seconds</b> is about the limit for keeping the user's attention focused on the dialogue. For longer delays, users will want to perform other tasks while waiting for the computer to finish, so they should be given feedback indicating when the computer expects to be done. Feedback during the delay is especially important if the response time is likely to be highly variable, since users will then not know what to expect.
</li>
</ul>
</blockquote>
<p>
The 10 second number seems too high for today's world of ubiquitous broadband and quad-core CPUs. That level of delay should be increasingly rare. I'd argue the user attention threshold is now more like 5 seconds. If your application is going to spend more than 5 seconds doing something, you owe your users an estimate of when you'll be done, and real-time feedback on your progress. A basic hourglass doesn't cut it.
</p>
<p>
What's more important? Getting flash after 5 seconds, or functional no-frills layouts in less than a second? Let's get our priorities straight. <b>Speed still matters.</b> And remember, the <i>perception</i> of speed is just as important as <i>actual</i> speed. If you can't be fast, be clever. Exploit <a href="http://www.codinghorror.com/blog/archives/000444.html">progressive rendering</a> and <a href="http://www.codinghorror.com/blog/archives/000059.html">HTTP compression</a>.
</p>
<p>
* It's ironic, then, that <a href="http://www.25hoursaday.com/weblog/">Dare's blog</a> is so incredibly slow to load every time I've directly visited it. One benefit of RSS aggregators, I suppose, is that I rarely need to.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/speed-still-matters/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Office 2007 -- not so WIMPy ]]></title>
<link>https://blog.codinghorror.com/office-2007-not-so-wimpy/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In my opinion, the new <a href="http://office.microsoft.com/en-us/products/FX100487411033.aspx">Office 2007</a> user interface is <b>one of the most innovative things to come out of Redmond in years</b>. It's nothing less than <a href="http://www.codinghorror.com/blog/archives/000397.html">the death of the main menu as a keystone GUI metaphor</a>. This is a big deal. Historically, where Office goes, everyone else follows. It's already starting to trickle down: IE7 does not show its main menu by default, and neither does Vista. You have to press Alt to expose the menu. The main menu has been demoted to a sort of configuration panel for advanced users; for everyone else, there's the Ribbon and toolbar buttons.
</p>
<p>
GUIs are characterized by their <a href="http://en.wikipedia.org/wiki/WIMP_(computing)">WIMP</a> characteristics: <b>W</b>indows, <b>I</b>cons, <b>M</b>enus, <b>P</b>ointing device. Office 2007's <a href="http://office.microsoft.com/en-us/products/HA101679411033.aspx">Ribbon</a> is a compelling argument in favor of abandoning the creaky old main menu GUI metaphor. I'd also argue that Office, in every new version, has further de-emphasized the <a href="http://www.codinghorror.com/blog/archives/000262.html">highly problematic MDI windowing standard</a>. Even without the vagaries of MDI, I spend far more time wrangling windows than I should. That's why I work with maximized windows 99% of the time (albeit across <a href="http://www.codinghorror.com/blog/archives/000217.html">multiple monitors</a>). So I'm inclined to think that windows themselves aren't all that useful as a GUI construct either, either. So, if Office 2007 drops the W and M from WIMP, what are we left with?
</p>
<p>
IP. Icons and Pointing Devices.
</p>
<p>
It's a radical change, right? Perhaps, until you consider the world's most popular GUI environment, the web browser, has no Menus or Windows. It's nothing but Icons and Pointing Devices. And yet people seem to adapt to the web much more readily than traditional WIMP apps. If anything, Office 2007's UI overhaul brings it in line with the rest of world that lives in your web browser.
</p>
<p>
Still, <b>it's impressive that Microsoft was willing to make such a large change to their flagship application</b>. Vista, in comparison, makes almost no changes to the core Windows GUI. <a href="http://blogs.msdn.com/jensenh/">Jensen Harris' blog</a> documents <a href="http://blogs.msdn.com/jensenh/archive/2006/11/10/the-office-2007-ui-bible.aspx">exactly how Microsoft arrived here</a>:
</p>
<p>
</p>
<ul>
<li><a href="http://blogs.msdn.com/jensenh/archive/2006/03/28/563007.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/03/28/563007.aspx">The Why of the New UI (Part 1)</a></li>
<li><a href="http://blogs.msdn.com/jensenh/archive/2006/03/29/563938.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/03/29/563938.aspx">Ye Olde Museum Of Office Past (Why the UI, Part 2)</a></li>
<li><a href="http://blogs.msdn.com/jensenh/archive/2006/03/31/565877.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/03/31/565877.aspx">Combating the Perception of Bloat (Why the UI, Part 3)</a></li>
<li>
<a href="http://blogs.msdn.com/jensenh/archive/2006/04/03/567261.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/04/03/567261.aspx">New Rectangles to the Rescue? (Why the UI, Part 4)</a>
</li>
<li><a href="http://blogs.msdn.com/jensenh/archive/2006/04/04/568249.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/04/04/568249.aspx">Tipping the Scale (Why the UI, Part 5)</a></li>
<li><a href="http://blogs.msdn.com/jensenh/archive/2006/04/05/568947.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/04/05/568947.aspx">Inside Deep Thought (Why the UI, Part 6)</a></li>
<li><a href="http://blogs.msdn.com/jensenh/archive/2006/04/07/570798.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/04/07/570798.aspx">No Distaste for Paste (Why the UI, Part 7)</a></li>
<li><a href="http://blogs.msdn.com/jensenh/archive/2006/04/11/573348.aspx" mce_href="http://blogs.msdn.com/jensenh/archive/2006/04/11/573348.aspx">Grading On the Curve (Why the UI, Part 8)</a></li>
</ul>
<p>
There are dozens of related articles in Jensen's <a href="http://blogs.msdn.com/jensenh/archive/2006/11/10/the-office-2007-ui-bible.aspx">Office 2007 UI bible</a>, but these background articles are essential.
</p>
<p>
Kudos to Microsoft on the UI changes in Office 2007. It's the first version of Office <i>worth</i> upgrading to.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-09T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/office-2007-not-so-wimpy/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ It's a Malformed World ]]></title>
<link>https://blog.codinghorror.com/its-a-malformed-world/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
<a href="http://www.dehora.net/journal/">Bill de hra</a> recently highlighted <a href="http://lists.w3.org/Archives/Public/www-tag/2006Aug/0048.html">a little experiment Ian Hickson ran</a> in August:
</p>
<p>
</p>
<blockquote>
I did a short study recently checking only for <i>syntax</i> errors in HTML documents, and the results were that of the 667416 files tested, 626575 had syntax errors. <b>Over 93%</b>. That's only syntax errors in the HTML, not checking the CSS, the content types, the semantic errors (e.g. duplicate IDs -- 86461 of those files had duplicated IDs), or any other errors.
<p>
<img alt="image placeholder" >
</p>
<p>
If you included those kinds of errors, you'd probably find that almost all
pages had errors that would trigger this warning. Thus any sort of visible
UI would be basically always saying "this page is broken". That would not
be good UI for the majority of users, who don't care.
</p>
</blockquote>
<p>
Even <a href="http://en.wikipedia.org/wiki/Tim_Berners-Lee">Tim-Berners Lee</a>, the godfather of the Web, acknowledges that <a href="http://dig.csail.mit.edu/breadcrumbs/node/166">the move to enforce well-formedness on the web with XHTML has failed</a>:
</p>
<p>
</p>
<blockquote>
Some things are clearer with hindsight of several years. It is necessary to evolve HTML incrementally. The attempt to get the world to switch to XML, including quotes around attribute values and slashes in empty tags and namespaces all at once didn't work. <b>The large HTML-generating public did not move, largely because the browsers didn't complain.</b> Some large communities did shift and are enjoying the fruits of well-formed systems, but not all. It is important to maintain HTML incrementally, as well as continuing a transition to well-formed world, and developing more power in that world.
</blockquote>
<p>
Perhaps this is why there's <a href="http://validator.w3.org/check?uri=http%3A%2F%2Fwww.google.com">63 HTML validation errors on Google's homepage</a> right now. <b>Like it or not, we live in a world of malformed HTML.</b> Browsers aren't compilers. They don't fail spectacularly when they encounter invalid markup. And nor should they. HTML is, and always has been, tolerant by design. We'll always be awash in a sea of <a href="http://essaysfromexodus.scripting.com/whatIsTagSoup">tag soup</a>.
</p>
<p>
Your browser doesn't care if your HTML is well-formed. Your users don't care if your HTML is well-formed. So <i>why should you?</i>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/its-a-malformed-world/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Microsoft Project and the Gantt Waterfall ]]></title>
<link>https://blog.codinghorror.com/microsoft-project-and-the-gantt-waterfall/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I've been using <a href="http://office.microsoft.com/en-us/project/default.aspx">Microsoft Project</a> quite a bit recently with a certain customer of ours. They bleed Gantt. I hadn't used Project in years, and after being exposed to it again, it really struck me how deeply <a href="http://en.wikipedia.org/wiki/Waterfall_model">the waterfall model</a> is ingrained into the product. Take a look. What do you see?</p>
<p><img alt="image placeholder" >
<p>Every Microsoft Project file I open is a giant waterfall, inexorably flowing across the page from left to right like <a href="http://en.wikipedia.org/wiki/Life_on_the_Mississippi">Twain's mighty Mississippi river</a>.</p>
<p>But like Twain's fictional Mississippi, project management with Microsoft Project is <a href="http://angryaussie.wordpress.com/2006/11/08/the-myth-of-project-management/">largely built on tall tales</a>:</p>
<blockquote>When you work in IT, you deal with the consensual hallucination of Project Management. <strong>There is an almost universal belief that it is possible to predict ahead of time how long a project will take, how much it will cost and what will happen along the way.</strong> In the broadest sense, this is possible. If you have enough experience you can come up with ballpark figures; last time we did something similar it took this long and cost this much.
<p>But some people believe Project Management should tell you these things down to the day and the dollar. A project plan should tell you every task that needs to be completed. A project plan should be flawless and leave nothing to chance. And a project plan should be completed before ANY work is done on the project.</p>
<p>Despite the fact this is clearly insanity, it is a terrifyingly common mindset in management ranks. Project planning and goals are obviously important at some level (otherwise how the hell would you know what you are doing?) but how did we move from "let's have a clearly defined set of project goals and a strategy for how we'll get there," to "this is 100% accurate, carved in stone and will never change"?</p>
</blockquote>
<p>What are the alternatives? Well, <a href="http://www.codinghorror.com/blog/archives/000694.html">anything but waterfall</a>. And a dose of McConnell's <a href="http://www.amazon.com/exec/obidos/ASIN/0735605351/codihorr-20">Software Estimation: Demystifying the Black Art</a>, which manages to cover the difficult topic of software estimation without a <em>single</em> mention of Microsoft Project.</p>
<p>Amazing.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/microsoft-project-and-the-gantt-waterfall/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Simplicity as a Force ]]></title>
<link>https://blog.codinghorror.com/simplicity-as-a-force/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Simplicity isn't easy to achieve, and John Maeda's short book, <a href="http://www.amazon.com/exec/obidos/ASIN/0262134721/codihorr-20">The Laws of Simplicity</a>, provokes a lot of thought on the topic.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0262134721/codihorr-20"><img alt="image placeholder" >
</p>
<p>
Programmers swim in a sea of unending complexity. We get so used to complexity as an ambient norm that we begin, consciously or unconsciously, projecting it into our work. Simplicity is tough in any field, but in ours, we exacerbate the problem. <b>Impossibly complex applications are the <a href="http://www.codinghorror.com/blog/archives/000113.html">default deliverable</a> for new programmers.</b> Only seasoned software development veterans are capable of producing applications that are easy to understand and troubleshoot. <a href="http://www.codinghorror.com/blog/archives/000190.html">Simplicity isn't achievable as a passive goal; it's a force that must be actively applied</a>.
</p>
<p>
You can read most of the book online via <a href="http://weblogs.media.mit.edu/SIMPLICITY/">John's excellent blog</a>, including <a href="http://lawsofsimplicity.com/category/laws?order=ASC">abbreviated versions of the ten laws of simplicity</a>. One of my favorite sections is about <a href="http://weblogs.media.mit.edu/SIMPLICITY/archives/000113.html">the evolution of the iPod's controls</a>.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/KISS_principle">Keep it Simple, Stupid</a>. If only it was that easy. It feels more like back-breaking work to keep things from inevitably devolving into complexity.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/simplicity-as-a-force/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ It's Never Been Built Before ]]></title>
<link>https://blog.codinghorror.com/its-never-been-built-before/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
In <a href="http://www.codinghorror.com/blog/archives/000725.html">Microsoft Project and the Gantt Waterfall</a>, many commenters wondered <b>why software projects can't be treated like any other construction or engineering project</b>:
</p>
<p>
</p>
<blockquote>
I am not sure why it is so difficult to estimate software development? Is it a mystery, magic, is there a man behind the curtain that every project depends on?
<p>
I mean it's simple, come on! It's like a designer and general contractor coming over and estimating how long it will take to remodel your kitchen.
</p>
</blockquote>
<p>
But software projects truly aren't like other engineering projects. I don't say this out of a sense of entitlement, or out of some misguided attempt to obtain special treatment for software developers. I say it because <b>the only kind of software we ever build is unproven, experimental software.</b> Sam Guckenheimer <a href="http://www.awprofessional.com/articles/article.asp?p=468589&amp;rl=1">explains</a>:
</p>
<p>
</p>
<blockquote>
To overcome the gap, you must recognize that <b>software engineering is not like other engineering.</b> When you build a bridge, road, or house, for example, you can safely study hundreds of very similar examples. Indeed, most of the time, economics dictate that you build the current one almost exactly like the last to take the risk out of the project.
<p>
With software, if someone has built a system just like you need, or close to what you need, then chances are you can license it commercially (or even find it as freeware). No sane business is going to spend money on building software that it can buy more economically. With thousands of software products available for commercial license, it is almost always cheaper to buy. Because the decision to build software must be based on sound return on investment and risk analysis, the software projects that get built will almost invariably be those that are not available commercially.
</p>
<p>
This business context has a profound effect on the nature of software projects. It means that software projects that are easy and low risk, because they've been done before, don't get funded. <b>The only new software development projects undertaken are those that haven't been done before or those whose predecessors are not publicly available. This business reality, more than any other factor, is what makes software development so hard and risky, which makes attention to process so important.</b>
</p>
</blockquote>
<p>
One kitchen remodelling project is much like another, and the next airplane you build will be nearly identical to the last five airplanes you built. Sure, there are some variables, some tweaks to the process over time, but it's a glorified <a href="http://www.codinghorror.com/blog/archives/000695.html">factory assembly line</a>. In software development, if you're repeating the same project over and over, you won't have a job for very long. At least not on this continent. If all you need is a stock airplane, <i>you buy one</i>. <b>We're paid to build high-risk, experimental airplanes.</b>
</p>
<p>
<a href="http://www.sprucegoose.org/aircraft_artifacts/exhibits.html"><img alt="image placeholder" >
</p>
<p>
The appropriately named happy-go-lucky left this comment on <a href="http://www.codinghorror.com/blog/archives/000725.html#comments">the same post</a> which explains the distinction quite succinctly:
</p>
<p>
</p>
<blockquote>
The problem originates in the fact that "Software Project" shares the word "project" with "engineering project" or "construction project."
<p>
"Ah-ha!" our hapless software managers cry, as they roll-out the money for a copy of MS Project. And the software developers cry all the way 'til the end of the "project."
</p>
<p>
Software invention is just that. It has more in common with Mr. Edison's Menlo Park laboratory than the local hi-rise construction site.
</p>
<p>
Of course, there are far fewer variables on a work site than in software invention. Gravity remains the same, elements don't change and concrete has known properties. Things aren't that stable when operating systems, hardware, software and business processes come together in "the perfect speculation."
</p>
</blockquote>
<p>
In software engineering projects, you aren't subject to God's rules. <a href="http://www.codinghorror.com/blog/archives/000298.html">You get to play God: define, build, and control an entire universe in a box</a>. It's a process of invention and evolution, not an assembly line. Can software development be managed? Sure. But it's a mistake to try managing it the same way you'd manage a kitchen remodel.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/its-never-been-built-before/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Computers are Lousy Random Number Generators ]]></title>
<link>https://blog.codinghorror.com/computers-are-lousy-random-number-generators/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
The .NET framework provides two random number generators. The first is <a href="http://msdn2.microsoft.com/en-US/library/system.random.aspx">System.Random</a>. But is it really <i>random?</i>
</p>
<p>
</p>
<blockquote>
Pseudo-random numbers are chosen with equal probability from a finite set of numbers. <b>The chosen numbers are not completely random because a definite mathematical algorithm is used to select them, but they are sufficiently random for practical purposes</b>. The current implementation of the Random class is based on Donald E. Knuth's subtractive random number generator algorithm, from <a href="http://www.amazon.com/exec/obidos/ASIN/0201896842/codihorr-20">The Art of Computer Programming, volume 2: Seminumerical Algorithms</a>.
</blockquote>
<p>
These cannot be random numbers because they're produced by a computer algorithm; computers are physically incapable of randomness. But perhaps <i>sufficiently random for practical purposes</i> is enough.
</p>
<p>
The second method is <a href="http://msdn2.microsoft.com/en-US/library/system.security.cryptography.randomnumbergenerator.aspx">System.Security.Cryptography.RandomNumberGenerator</a>. It's more than an algorithm. It also incorporates <a href="http://en.wikipedia.org/wiki/CryptGenRandom">the following environmental factors</a> in its calculations:
</p>
<p>
</p>
<ul>
<li>The current process ID
</li>
<li>The current thread ID
</li>
<li>The tick count since boot time
</li>
<li>The current time
</li>
<li>Various high precision CPU performance counters
</li>
<li>An MD4 hash of the user's environment (username, computer name, search path, etc)
</li>
</ul>
<p>
<a href="http://www.seifried.org/security/cryptography/20000126-random-numbers.html">Good cryptography requires high quality random data</a>. In fact, <b>a perfect set of encrypted data is indistinguishable from random data</b>.
</p>
<p>
I wondered what randomness looks like. So I wrote the following program, which compares the two random number methods available in the .NET framework. In blue, <code>System.Random</code>, and in red, <code>System.Cryptography.RandomNumberGenerator</code>.
</p>
<p>
</p>
<pre language="c#">
const int maxlen = 3000;
Random r = new Random();
RandomNumberGenerator rng = RandomNumberGenerator.Create();
Byte[] b = new Byte[4];
using (StreamWriter sw = new StreamWriter("random.csv"))
{
for (int i = 0; i &lt; maxlen; i++)
{
sw.Write(r.Next());
sw.Write(",");
rng.GetBytes(b);
sw.WriteLine(Math.Abs(BitConverter.ToInt32(b, 0)));
}
}
</pre>
<p>
3,000 random numbers<br>
<a href="http://www.codinghorror.com/blog/images/3000-random-numbers.png"><img alt="image placeholder" >
</p>
<p>
10,000 random numbers<br>
<a href="http://www.codinghorror.com/blog/images/10000-random-numbers.png"><img alt="image placeholder" >
</p>
<p>
30,000 random numbers<br>
<a href="http://www.codinghorror.com/blog/images/30000-random-numbers.png"><img alt="image placeholder" >
</p>
<p>
I have no idea how to test for true randomness. <a href="http://www.fourmilab.ch/hotbits/statistical_testing/stattest.html">The math is far beyond me</a>. But I don't <i>see</i> any obvious patterns in the resulting data. It's utterly random noise to my eye. Although both of these methods produce reasonable randomness, they're ultimately still <a href="http://en.wikipedia.org/wiki/Pseudo-random_number_generator">pseudo-random number generators</a>. Computers are great number crunchers, but they're lousy random number generators.
</p>
<p>
<b>To have any hope of producing <i>truly</i> random data, you must reach outside the computer and sample the analog world</b>. For example, <a href="http://waste.sourceforge.net/">WASTE</a> samples user mouse movements to generate randomness:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
But even something as seemingly random as user input <a href="http://www.random.org/essay.html">can be predictable</a>; not all environmental sources are suitably random:
</p>
<p>
</p>
<blockquote>
True random numbers are typically generated by sampling and processing a source of entropy outside the computer. A source of entropy can be very simple, like the little variations in somebody's mouse movements or in the amount of time between keystrokes. In practice, however, it can be tricky to use user input as a source of entropy. Keystrokes, for example, are often buffered by the computer's operating system, meaning that several keystrokes are collected before they are sent to the program waiting for them. To the program, it will seem as though the keys were pressed almost simultaneously.
<p>
A better source of entropy is a radioactive source. The points in time at which a radioactive source decays are completely unpredictable, and can be sampled and fed into a computer, avoiding any buffering mechanisms in the operating system. In fact, this is what the <a href="http://www.fourmilab.ch/hotbits/">HotBits</a> people at Fourmilab in Switzerland are doing. Another source of entropy could be atmospheric noise from a radio, like that used here at <a href="http://www.random.org">random.org</a>, or even just background noise from an office or laboratory. The <a href="http://www.lavarnd.org/">lavarand</a> people at Silicon Graphics have been clever enough to use lava lamps to generate random numbers, so their entropy source not only gives them entropy, it also looks good! The latest random number generator to come online is <a href="http://random.hd.org/index.html">EntropyPool</a> which gathers random bits from a variety of sources including HotBits and random.org, but also from web page hits received by the EntropyPool's web server.
</p>
</blockquote>
<p>
Carl Ellision has an excellent <a href="http://theworld.com/~cme/P1363/ranno.html">summary of many popular environmental sources of randomness</a> and their strengths and weaknesses. But environmental sources have their limits, too-- unlike pseudo-random algorithms, they have to be harvested over time. Not all environmental sources can provide enough random data for a server under heavy load, for example. And some encryption methods require more random data than others; one particularly secure algorithm requires one bit of random data for each bit of encrypted data.
</p>
<p>
Computers may be lousy random number generators, but <a href="http://www.wired.com/wired/archive/11.08/random_pr.html">we've still come a long way</a>:
</p>
<p>
</p>
<blockquote>
As recently as 100 years ago, people who needed random numbers for scientific work still tossed coins, rolled dice, dealt cards, picked numbers out of hats, or browsed census records for lists of digits. In 1927, statistician L.H.C. Tippett published a table of 41,600 random numbers obtained by taking the middle digits from area measurements of English churches. In 1955, the Rand Corporation published A Million Random Numbers With 100,000 Normal Deviates, a massive tome filled with tables of random numbers. To remove slight biases discovered in the course of testing, the million digits were further randomized by adding all pairs and retaining only the last digit. The Rand book became a standard reference, still used today in low-level applications such as picking precincts to poll.
</blockquote>
<p>
The world is random. Computers aren't. <b>Randomness is really, really hard for computers</b>. It's important to understand the ramifications of this big divide between the analog and digital world, otherwise you're likely to make the <a href="http://www.ddj.com/184409807">same rookie mistakes Netscape did</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/computers-are-lousy-random-number-generators/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Filesystem Paths: How Long is Too Long? ]]></title>
<link>https://blog.codinghorror.com/filesystem-paths-how-long-is-too-long/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>I recently imported some source code for a customer that <b>exceeded the maximum path limit of 256 characters</b>. The paths in question weren't particularly meaningful, just <i>pathologically</i>* long, with redundant subfolders. To complete the migration, I renamed some of the parent folders to single character values.</p>
<p>This made me wonder: <b>is 256 characters a reasonable limit for a path?</b> And what's the longest path in my filesystem, anyway? I whipped up this little C# console app to loop through all the paths on my drive and report the longest one.</p>
<pre><code>static string _MaxPath = "";
static void Main(string[] args)
{
  RecursePath(@"c:\");
  Console.WriteLine("Maximum path length is " + _MaxPath.Length);
  Console.WriteLine(_MaxPath);
  Console.ReadLine();
}

static void RecursePath(string p)
{
  foreach (string d in Directory.GetDirectories(p))
  {
    if (IsValidPath(d))
    {
      foreach (string f in Directory.GetFiles(d))
      {
        if (f.Length &gt; _MaxPath.Length)
        {
          _MaxPath = f;
        }
      }
      RecursePath(d);
    }
  }
}
static bool IsValidPath(string p)
{
  if ((File.GetAttributes(p) &amp; FileAttributes.ReparsePoint) == FileAttributes.ReparsePoint)
  {
    Console.WriteLine("'" + p + "' is a reparse point. Skipped");
    return false;
  }
  if (!IsReadable(p))
  {
    Console.WriteLine("'" + p + "' *ACCESS DENIED*. Skipped");
    return false;
  }
  return true;
}
static bool IsReadable(string p)
{
  try
  {
    string[] s = Directory.GetDirectories(p);
  }
  catch (UnauthorizedAccessException ex)
  {
    return false;
  }
  return true;
}
</code></pre>
<p>It works, but it's a bit more complicated than I wanted it to be, because</p>
<ol>
<li>There are a few folders we don't have permission to access.</li>
<li>Vista makes heavy use of <a href="http://en.wikipedia.org/wiki/NTFS#Features">reparse points</a> to <a href="http://www.hanselman.com/blog/MoreOnVistaReparsePoints.aspx">remap old XP folder locations as symbolic links</a>.</li>
</ol>
<p><b>The longest path on a clean install of Windows XP is 152 characters.</b></p>
<pre><code>c:\Documents and Settings\All Users\Application Data\Microsoft\Crypto\RSAS-1-5-18d42cc0c3858a58db2db37658219e6400_89e7e133-abee-4041-a1a7-406d7effde91
</code></pre>
<p>This is followed closely by a bunch of stuff in <code>c:\WINDOWS\assembly\GAC_MSIL</code>, which is a side-effect of .NET 2.0 being installed.</p>
<p><b>The longest path on a semi-clean install of Windows 8.1 is 273 characters:</b></p>
<pre><code>c:\Users\wumpus-home\AppData\Local\Packages\WinStore_cw5n1h2txyewy\AC\Microsoft\Windows Store\Cache\0\0-Namespace-https???services.apps.microsoft.com?browse?6.2.9200-1?615?en-US?c?US?Namespace?pc?00000000-0000-0000-0000-000000000000?00000000-0000-0000-0000-000000000000.
</code></pre>
<p>The longest path <i>Microsoft</i> created in Windows 8.1 is 273 characters. But what's the longest path I can create in Windows Explorer?</p>
<img alt="image placeholder" >
<p>The best I could do is 239 characters for folders, and 11 characters for the filename. Add in 3 characters for the inevitable "c:", plus 6 slashes. <b>That's a grand total of 259 characters</b>. Anything longer and I got a "destination path too long" error.</p>
<img alt="image placeholder" >
<p>The 259 character path limit I ran into jibes with the <a href="http://shellrevealed.com/blogs/shellblog/archive/2006/09/28/Common-Questions-Concerning-the-SHFileOperation-API_3A00_-Part-2.aspx">documented MAX_PATH limitation of the Windows shell</a>:</p>
<blockquote>
<p>The maximum length path (in characters) that can be used by the [Windows] shell is <code>MAX_PATH</code> (defined as 260).  Therefore, you should create buffers that you will pass to SHFILEOPSTRUCT to be of length <code>MAX_PATH</code> + 1 to account for these NULLs.</p>
</blockquote>
<p>If 259 characters plus a null seems like an unusually restrictive path limit for a modern filesystem like NTFS, you're right. <b>The NTFS filesystem supports paths of 32,000 characters</b>, but it's largely irrelevant because the majority of Windows APIs you'd use to <i>get</i> to those paths only accept paths of <code>MAX_PATH</code> or smaller. There is a <a href="http://msdn.microsoft.com/en-us/library/aa365247.aspx">wonky Unicode workaround to the MAX_PATH limitation</a>, according to MSDN:</p>
<blockquote>
<p>In the Windows API (with some exceptions discussed in the following paragraphs), the maximum length for a path is <code>MAX_PATH</code>, which is defined as 260 characters. A local path is structured in the following order: drive letter, colon, backslash, name components separated by backslashes, and a terminating null character. For example, the maximum path on drive D is "D:\some 256-character path string&lt;NUL&gt;" where "&lt;NUL&gt;" represents the invisible terminating null character for the current system codepage. (The characters &lt; &gt; are used here for visual clarity and cannot be part of a valid path string.)</p>
<p>The Windows API has many functions that also have Unicode versions to permit an extended-length path for a maximum total path length of 32,767 characters. This type of path is composed of components separated by backslashes, each up to the value returned in the lpMaximumComponentLength parameter of the GetVolumeInformation function (this value is commonly 255 characters). To specify an extended-length path, use the "\?" prefix. For example, "\?\D:\very long path".</p>
<p>The "\?" prefix can also be used with paths constructed according to the universal naming convention (UNC). To specify such a path using UNC, use the "\?\UNC" prefix. For example, "\?\UNC\server\share", where "server" is the name of the computer and "share" is the name of the shared folder. These prefixes are not used as part of the path itself. They indicate that the path should be passed to the system with minimal modification, which means that you cannot use forward slashes to represent path separators, or a period to represent the current directory, or double dots to represent the parent directory. Because you cannot use the "\?" prefix with a relative path, relative paths are always limited to a total of <code>MAX_PATH</code> characters.</p>
<p>The shell and the file system may have different requirements. It is possible to create a path with the API that the shell UI cannot handle.</p>
</blockquote>
<p>Still, I wonder if the world really needs 32,000 character paths. Is a 260 character path really that much of a limitation? <b>Do we need hierarchies that deep?</b> Martin Hardee has <a href="https://web.archive.org/web/20070205200717/http://blogs.sun.com/MartinHardee/date/20040624">an amusing anecdote on this topic</a>:</p>
<blockquote>
<p>We were very proud of our user interface and the fact that we had a way to browse 16,000 (!!) pages of documentation on a CD-ROM.  But browsing the hierarchy felt a little complicated to us. So we asked <a href="http://www.edwardtufte.com/">Tufte</a> to come in and have a look, and were hoping perhaps for a pat on the head or some free advice.</p>
<p>He played with our AnswerBook for about 90 seconds, turned around, and pronounced his review:</p>
<p>"Dr Spock's Baby Care is a best-selling owner's manual for the most complicated 'product' imaginable  and it only has two levels of headings.  You people have 8 levels of hierarchy and I haven't even stopped counting yet.  No wonder you think it's complicated."</p>
</blockquote>
<p><b>I think 260 characters of path is more than enough rope to hang ourselves with.</b> If you're running into path length limitations, the real problem isn't the operating system, or even the computers. The problem is the <a href="http://www.codinghorror.com/blog/archives/000246.html">deep, dark pit of hierarchies</a> the human beings have dug themselves into.</p>
<p>* ouch</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-20T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/filesystem-paths-how-long-is-too-long/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ iPod Alternatives ]]></title>
<link>https://blog.codinghorror.com/ipod-alternatives/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I have a great deal of respect for <a href="http://daringfireball.net/2006/03/ipod_juggernaut">Apple's iPod juggernaut</a>. They've almost single-handedly legitimized the market for downloadable music. The kind you pay for. The kind that, at least <i>in theory</i>, supports the artists who produce the music instead of ripping them off.
</p>
<p>
That said, I have some problems with the iPod.
</p>
<p>
</p>
<ol>
<li>
<b>The iPod is boring</b>. How can I properly <a href="http://en.wikipedia.org/wiki/Rage_Against_the_Machine">rage against the machine</a> with the same standard, factory issue music players that everyone else has? I don't want this to devolve into <a href="http://www.anythingbutipod.com/">a knee-jerk rejection of all iThings</a>, but let's be honest here: when every soccer Mom carries an iPod, it's no longer a cool technical accessory. It's completely mainstream. I'd be lying if I said this didn't matter to me.
<p>
</p>
</li>
<li>
<b>The iPod has no support for subscription services</b>. I'm a member of <a href="http://music.yahoo.com/ymu/default.asp?">Yahoo Music Unlimited</a>, which gives me unlimited access to a massive library of music for 6 bucks a month. I can stream any of this music to multiple PCs, or I can download it to my hard drive or mobile audio players. And it's in a very respectable 192kbps 2-pass CBR format, too. For that same six bucks a month, I could buy a whopping <i>six</i> tracks from the iTunes store. While I can certainly understand the desire to own music, <i>why not give us a choice?</i> Apple's insistence on purchase-only models is a huge mistake.
<p>
</p>
</li>
<li>
<b>The iPod does not support WMA</b>. Although Jobs grudgingly made the iPod Windows compatible two years after its introduction, he still gets his jabs in. The conspicuous lack of WMA support is a not-so-subtle f*ck you to the Windows community. And what of OGG? Or FLAC? Clearly, the hardware is capable, but the political forces inside Apple won't allow it. You'd figure a company that had the guts to make a stunning, wholesale switch to x86 processors could deign to support a few alternative audio formats on their music players. But no.
<p>
</p>
</li>
<li>
<b>The iPod lacks features.</b> I'll never understand why the iPod chooses to deliberately ignore FM radio and its rich history in the music industry. Heck, you might even want to <i>record</i> FM radio. That's just crazy talk! And the list goes on: there's no voice recording, no EQ settings, no gapless playback, etcetera.
<p>
</p>
</li>
<li>
<b>The iPod requires custom software to work.</b> Every music player on the market should have this down to a science by now:
<p>
</p>
<ul>
<li>plug in the USB cable
</li>
<li>drag and drop your music on the device
</li>
<li>disconnect the cable and ROCK
</li>
</ul>
</li>
<p>
The iPod fails miserably on this count: it <i>requires</i> iTunes installed (or another <a href="http://www.redchairsoftware.com/anapod/">custom application</a>) to transfer any music to the device. You can't even use it as an external hard drive without setting up a separate, special partition on the device first. Of course, use iTunes if you want, but you shouldn't be forced to use iTunes because the hardware is a brick if you don't. How did Apple get this so very, very wrong?
</p>
</ol>
<p>
Now, your goals may not be my goals. But when my wife wanted a new music player to replace her aging <a href="http://www.amazon.com/gp/redirect.html?ie=UTF8&amp;location=http%3A%2F%2Fwww.amazon.com%2FRio-Carbon-GB-MP3-Player%2Fdp%2FB0002UB2P0&amp;tag=codihorr-20&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">Rio Carbon</a> (RIP-- a <a href="http://dapreview.net/e107_plugins/content/content.php?content.121">great little player for its time</a>), these are the criteria I used to evaluate them.
</p>
<p>
Unfortunately, music devices that can be used seamlessly and interchangeably as a generic external USB hard drive and digital music player are quite rare. The sole exception, at least for hard-disk devices, is the <a href="http://reviews.cnet.com/Cowon_iAudio_X5L_30GB/4505-6490_7-31383685.html">Cowon X5L</a>. The Cowon is a decent player, but it suffers from Soviet Russia-era design aesthetics. Due to lack of choices, I was forced to compromise on devices that support Microsoft's <a href="http://en.wikipedia.org/wiki/Media_Transfer_Protocol">Media Transfer Protocol</a>. When connected to a Windows XP or Windows Vista machine, MTP support allows you to drag and drop music directly on to the device-- <b>without installing any software</b>. It's not ideal, since it's tied to Microsoft, but it's the best I can do.
</p>
<p>
The <a href="http://dapreview.net/">Digital Audio Players Review</a> website had the most helpful advice. Their <a href="http://dapreview.net/e107_plugins/content/content.php?content.259">top pick</a> was the <a href="http://www.amazon.com/gp/redirect.html?ie=UTF8&amp;location=http%3A%2F%2Fwww.amazon.com%2Fgp%2Fproduct%2FB000CS7UTY&amp;tag=codihorr-20&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">
Creative Zen Vision:M</a>. I agreed, so I went with the pink one. You know, for the ladies.
</p>
<p>
<a href="http://www.amazon.com/gp/redirect.html?ie=UTF8&amp;location=http%3A%2F%2Fwww.amazon.com%2Fgp%2Fproduct%2FB000CS7UTY&amp;tag=codihorr-20&amp;linkCode=ur2&amp;camp=1789&amp;creative=9325">
<img alt="image placeholder" >
</p>
<p>
It's a great little device, and as promised, we just dragged and dropped our music on it-- which happens to be a mix of MP3 and WMA files. And it worked with our <a href="http://music.yahoo.com/ymu/default.asp">Yahoo Music Unlimited</a> subscription as well.
</p>
<p>
To complement the 30gb hard drive player, I also picked up a flash device-- the new, larger <a href="http://www.iriveramerica.com/prod/ultra/clix/clix-4GB.aspx">4gb iRiver Clix</a>.
</p>
<p>
<a href="http://www.iriveramerica.com/prod/ultra/clix/clix-4GB.aspx"><img alt="image placeholder" >
</p>
<p>
I've owned a few iRiver products in the past and they've always been excellent. <a href="http://dapreview.net/e107_plugins/content/content.php?content.283">dapreview gave the Clix high marks</a>, and so has <a href="http://www.engadget.com/2006/05/24/iriver-clix-review-roundup/">everyone else who has reviewed it</a>. The feature set is great. It meets every one of my criteria, throws in video support, and even goes a little beyond with support for <a href="http://en.wikipedia.org/wiki/Adobe_Flash_Lite">Flash Lite</a> <a href="http://www.smashingcontent.com/games/iriver/">games</a>.
</p>
<p>
I respect the way the pioneering iPod has collectively led the industry out of the <a href="http://en.wikipedia.org/wiki/Napster">dark Napster ages</a>. And I like the iPod design. But until Apple at least supports subscription services and the WMA/FLAC/OGG file formats, I can't justify purchasing any iPod hardware.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-21T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/ipod-alternatives/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Exploring Vista's Advanced Search ]]></title>
<link>https://blog.codinghorror.com/exploring-vistas-advanced-search/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I used the file search function in Windows XP a lot, particularly to find groups of files. But the XP search syntax doesn't work in Vista. Vista uses the <a href="http://www.microsoft.com/windows/desktopsearch/addresources/advanced.mspx">Windows Desktop Search query syntax</a>. Which means
</p>
<p>
"*.vbproj;*.csproj"
</p>
<p>
becomes
</p>
<p>
"ext:(*.vbproj OR *.csproj)"
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Note that the boolean operator <i>must</i> be in all-caps to work. That was painful to figure out.
</p>
<p>
I highly recommend reading through the <a href="http://www.microsoft.com/windows/desktopsearch/addresources/advanced.mspx">Windows Desktop Search advanced query reference</a>. First of all, it's completely different than searching in XP, so you'll need to retrain your brain. But it's also a far richer search paradigm than we ever had in XP. And you can <b>use the same CTRL+E search keyboard shortcut</b> that works in your browser to harness its power in Windows Explorer.
</p>
<p>
When you perform a search, note that the Search Tools menu is available; that's our main interface for all the new search options.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
From here, you can bring up the Search Pane, which lets you filter your searches to particular file types, and includes an expandable Advanced Search pane.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
As you fill in values in the Advanced Search pane and click Search, the equivalent query terms will be populated in the CTRL+E search box. It's a good way to learn basic search syntax. Once you've learned <a href="http://www.microsoft.com/windows/desktopsearch/addresources/advanced.mspx">the new Vista search syntax</a>, you won't need the Search Pane training wheels any more; you can press CTRL+E and type in what you want. It's Google-icious.
</p>
<p>
There's also an important distinction between indexed search locations and non-indexed search locations. To see the difference, choose "Search Options" from the Search Tools menu.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Most notably, <b>your search terms will only extend to file contents in indexed locations</b>. I'm also very glad to see search now ignores compressed files by default. This was a real pain in XP, which insisted on digging through 600 megabyte ZIP files as a part of any search.
</p>
<p>
To view indexed locations, or add your own, select Modify Index Locations from the Search Tools menu. On a default Vista install, there are only three indexed locations:
</p>
<p>
</p>
<ul>
<li>Offline Files
</li>
<li>c:Program DataMicrosoftWindowsStart Menu
</li>
<li>c:Users
</li>
</ul>
<p>
There is one big caveat here: <b>the full-text indexer only indexes file extensions that it understands</b>. To view or modify the list of file extensions the indexer understands, click the Advanced Options button on the Modify Index Locations dialog, then select the File Types tab.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Perhaps the coolest new search feature is that <b>you can enter searches directly from the Windows start menu</b>. Try it. Hit the Windows key and just start typing search queries. There's nothing to install, nothing to configure, searching <i>just works</i> in Vista. It's about time.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-22T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/exploring-vistas-advanced-search/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ CPU vs. GPU ]]></title>
<link>https://blog.codinghorror.com/cpu-vs-gpu/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Intel's latest quad-core CPU, the <a href="http://www.anandtech.com/cpuchipsets/showdoc.aspx?i=2866">Core 2 Extreme QX6700</a>, consists of <b>582 million transistors</b>. That's a lot. But it pales in comparison to the <b>680 million transistors</b> of nVidia's latest video card, the <a href="http://www.anandtech.com/video/showdoc.aspx?i=2870&amp;p=1">8800 GTX</a>. Here's a small chart of transistor counts for recent <a href="http://en.wikipedia.org/wiki/Central_processing_unit">CPUs</a> and <a href="http://en.wikipedia.org/wiki/Graphics_processing_unit">GPUs</a>:
</p>
<p>
</p>
<table width="400">
<tr>
<td>AMD Athlon 64 X2</td>
<td>CPU</td>
<td>154 m
</td>
</tr>
<tr>
<td>Intel Core 2 Duo</td>
<td>CPU</td>
<td>291 m
</td>
</tr>
<tr>
<td>Intel Pentium D 900</td>
<td>CPU</td>
<td>376 m
</td>
</tr>
<tr>
<td>ATI X1950 XTX</td>
<td><font color="red">GPU</font></td>
<td>384 m
</td>
</tr>
<tr>
<td>Intel Core 2 Quad</td>
<td>CPU</td>
<td>582 m
</td>
</tr>
<tr>
<td>NVIDIA G8800 GTX</td>
<td><font color="red">GPU</font></td>
<td>680 m
</td>
</tr>
</table>
<p>
ATI won't release a new video card until next year. But their current <a href="http://www.anandtech.com/video/showdoc.aspx?i=2821">X1950 XTX</a> isn't exactly chopped liver: 384 million transistors is more than any current dual-core CPU.
</p>
<p>
Of course, comparing GPUs to CPUs isn't an apples-to-apples comparison. The clock rates are lower, the architectures are radically different, and the problems they're trying to solve are almost completely unrelated. But <b>GPUs now exceed the complexity of modern CPUs in terms of absolute transistor count.</b> And like CPUs, they're becoming programmable-- it's possible to harness all that graphics power to do something other than graphics.
</p>
<p>
There's a nice <a href="http://techreport.com/etc/2006q4/gpu-folding/index.x?pg=1">overview on AnandTech</a> which provides some background on this architectural sea change in video cards:
</p>
<p>
</p>
<blockquote>
So far, the only types of programs that have effectively tapped GPU power-- other than the obvious applications and games requiring 3D rendering-- have also been video related: video decoders, encoders, video effect processors, and so forth. But there are many non-video tasks that are floating-point intensive, and these programs have been unable to harness the power of the GPU.
<p>
Meanwhile, the academic world has designed and utilized custom-built floating-point research hardware for years. These devices are known as <b>stream processors</b>. Stream processors are extremely powerful floating-point processors able to process whole blocks of data at once, whereas CPUs carry out only a handful of numerical operations at a time. We've seen CPUs implement some stream processing with instruction sets like SSE and 3DNow!, but these efforts pale in comparison to what custom hardware has been able to do.
</p>
<p>
3D rendering is also a streaming task. Modern GPUs have evolved into stream processors, sharing much in common with the customized hardware of researchers. GPU designers have cut corners where they don't need certain functionality for 3D rendering, but they have ultimately developed extremely fast and flexible stream processors. Modern GPUs are just as fast as custom hardware, but due to economies of scale are many, many times cheaper than custom hardware.
</p>
</blockquote>
<p>
<b>Dedicated, task-specific hardware is orders of magnitude faster than what you can achieve with a general purpose CPU.</b> If you need proof of this, just look at the <a href="http://www.codinghorror.com/blog/archives/000701.html">chess benchmarks</a>. <a href="http://en.wikipedia.org/wiki/Deep_Blue">IBM's Deep Blue</a> was capable of evaluating 200 million chess moves per second in 1997. Ten years later, the fastest quad-core desktop system can only evaluate <a href="http://www.chessbase.com/newsdetail.asp?newsid=3504">8 million chess moves per second</a>. Ten year old custom hardware is still 25 times faster than the best general purpose CPUs. Amazing.
</p>
<p>
The most high profile application for all this GPU power at the moment is Stanford's <a href="http://folding.stanford.edu/">Folding@Home</a>. There's no shortage of <a href="http://ir.ati.com/phoenix.zhtml?c=105421&amp;p=irol-newsArticle&amp;ID=910520&amp;highlight=">exciting PR</a> on this topic:
</p>
<p>
</p>
<blockquote>
The processing power of just 5,000 ATI processors is also enough to rival that of the existing 200,000 computers currently involved in the Folding@home project; and it is estimated that if a mere 10,000 computers were to each use an ATI processor to conduct folding research, that the Folding@home program would effectively perform faster than the fastest supercomputer in existence today, surpassing the 1 petaFLOP level.
</blockquote>
<p>
Stanford recently introduced a <a href="http://folding.stanford.edu/FAQ-highperformance.html">high performance folding client</a> which runs on ATI's X1800 and X1900 series video cards. TechReport <a href="http://techreport.com/etc/2006q4/gpu-folding/index.x?pg=1">tested the new high performance folding client</a> and came away a little disappointed:
</p>
<p>
</p>
<blockquote>
Over five days, our Radeon X1900 XTX crunched eight work units for a total or 2,640 points. During the same period, our single Opteron 180 core chewed its way through six smaller work units for a score of 899 -- just about one third the point production of the Radeon. However, had we been running the CPU client on both of our system's cores, the point output should have been closer to 1800, putting the Radeon ahead by less than 50%.
</blockquote>
<p>
The GPU may be doing 20 to 40 times more work, but the scores are calibrated to a baseline system, not the absolute amount of work that's done. It's a little anticlimactic.
</p>
<p>
Stanford's advanced folding client exploits the <a href="http://graphics.stanford.edu/projects/brookgpu/lang.html">Brook Language</a>, an extension to ANSI C that allows them to compile C-like code that runs on the GPU. It leverages <a href="http://techreport.com/etc/2006q4/stream-computing/index.x?pg=1">ATI's Stream</a> API to communicate with the GPU. NVIDIA offers something similar to Brook in their <a href="http://developer.nvidia.com/object/cuda.html">CUDA technology</a>:
</p>
<p>
</p>
<blockquote>
GPU computing with CUDA technology is an innovative combination of computing features in next generation NVIDIA GPUs that are accessed through a standard C language.  Where previous generation GPUs were based on "streaming shader programs", CUDA programmers use C to create programs called threads that are similar to multi-threading programs on traditional CPUs.  In contrast to multi-core CPUs, where only a few threads execute at the same time, NVIDIA GPUs featuring CUDA technology process thousands of threads simultaneously enabling a higher capacity of information flow.
</blockquote>
<p>
Of course, CUDA only works on the latest G80 series of cards, just like the ATI's Stream technology is really only useful on their latest X1900 series. All this potential programmability is a very recent development.
</p>
<p>
I expect the relationship between CPU and GPU to largely be a symbiotic one: they're good at different things. <b>But I also expect quite a few computing problems to make the jump from CPU to GPU in the next 5 years</b>. The potential order-of-magnitude performance improvements are just too large to ignore.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-23T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/cpu-vs-gpu/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Discussions: Flat or Threaded? ]]></title>
<link>https://blog.codinghorror.com/discussions-flat-or-threaded/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Clay Shirky's <a href="http://www.codinghorror.com/blog/archives/000295.html">classic articles on social software</a> should be required reading for all software developers working on web applications. As near as I can tell, that's pretty much every developer these days.
</p>
<p>
But I somehow missed Joel Spolsky's related 2003 article on social software, <a href="http://www.joelonsoftware.com/articles/BuildingCommunitieswithSo.html">Building Communities With Software</a>.* It's an excellent, albeit somewhat long-winded, explanation of the way Joel runs his <a href="http://discuss.joelonsoftware.com/?joel">community forums</a>. Although I recently <a href="http://www.codinghorror.com/blog/archives/000679.html">accused Joel of jumping the shark</a>, his scathing criticism of Usenet, Slashdot, and IRC is right on the money. All three are deeply flawed social software models, incapable of sustaining civilized discussion.
</p>
<p>
Joel advocates policies on his discussion boards that seem unworkable, even borderline <i>anarchic</i>:
</p>
<p>
</p>
<ul>
<li>No registration
</li>
<li>No user moderation
</li>
<li>No email notifications for new posts
</li>
<li>No posted rules
</li>
<li>No support for quoting or reply shortcuts
</li>
<li>No unread post shortcuts
</li>
<li>Arbitrary deletion of off-topic posts
</li>
</ul>
<p>
Reads like a recipe for disaster, doesn't it? But with one minor exception**, I'm in complete agreement. <b>When it comes to writing social software, Joel's curmudgeonly advice may very well be the right approach.</b> Read <a href="http://www.joelonsoftware.com/articles/BuildingCommunitieswithSo.html">the rest of Joel's post</a> to understand why.
</p>
<p>
In particular, I share Joel's intense dislike of threaded conversations:
</p>
<p>
</p>
<blockquote>
<i>Q. OK, but can't you at least have branching? If someone gets off on a tangent, that should be its own branch which you can follow or go back to the main branch.</i>
<p>
A. Branching is very logical to a programmer's mind but it doesn't correspond to the way conversations take place in the real world. Branched discussions are disjointed to follow and distracting. [..] Branching makes discussions get off track, and reading a thread that is branched is discombobulating and unnatural. Better to force people to start a new topic if they want to get off topic.
</p>
</blockquote>
<p>
</p>
<table>
<tr>
<td>Threaded</td>
<td></td>
<td>Flat
</td>
</tr>
<tr>
<td valign="top">
<img alt="image placeholder" >
</td>
<td>
</td>
<td valign="top">
<img alt="image placeholder" >
</td>
</tr>
</table>
<p>
Two of the oldest and most popular discussion boards on the web, <a href="http://www.phpbb.com/">phpBB</a> and <a href="http://www.vbulletin.com/">vBulletin</a>, avoid threaded views. The phpBB developers <a href="http://www.phpbb.com/phpBB/viewtopic.php?t=256707">won't add threading</a>. vBulletin offers threaded views, but they are off by default-- and often disabled completely by administrators.
</p>
<p>
Personally, <b>I have yet find any threaded discussion format I like</b>. Aside from the philosophical objections Joel raises, threaded discussions are painful to use. You're forced to click through to see the responses, and once you do, there's far too much pogo-ing up and down the hierarchy of the threaded discussions. It's all so.. <i>unnecessary</i>.
</p>
<p>
Flat discussion views have their limitations, too. But they're minor compared to the trainwreck that is threaded discussions. Until we can come up with a new discussion model that <i>doesn't</i> add a slew of new problems, let's take Joel's advice and <b>stick with simple, flat discussion views</b>.
</p>
<p>
* Thanks to <a href="http://haacked.com">Phil</a> for pointing this article out to me.
</p>
<p>
** Quoted snippets are helpful if used in moderation. Unlike Joel, I don't have total recall of the last five posts I just read; judicious use of a few contextual quotes helps me keep the rest of the conversation in my brain.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-24T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/discussions-flat-or-threaded/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ This Is What Happens When You Let Developers Create UI ]]></title>
<link>https://blog.codinghorror.com/this-is-what-happens-when-you-let-developers-create-ui/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Deep down inside every software developer, <b>there's a budding graphic designer waiting to get out.</b> And if you let that happen, you're in trouble. Or at least your users will be, anyway:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Joseph Cooney calls this <a href="http://jcooney.net/archive/2006/10/30/36235.aspx">The Dialog</a>:
</p>
<p>
</p>
<blockquote>
A developer needed a screen for something, one or two text boxes and not much more, so they created "the dialog", maybe just to "try something out" and always with the intention of removing it before the product ships. They discovered they needed a few more parameters, so a couple more controls were added in a fairly haphazard fassion. "The dialog" exposes "the feature", something cool or quite useful. Admittedly "the feature" is more tailored towards power users, but it's still pretty cool. The developer thinks of new parameters that would make "the feature" even more powerful and so adds them to the dialog. Maybe a few other developers or power users see "the dialog" and also like "the feature". But why doesn't it expose <i>this</i> parameter? New controls are added. Pretty soon the technical team are so used to seeing "the dialog" the way it is that they become blind to its strange appearance. Ship time approaches and the product goes through more thorough testing, and "the dialog" is discovered, but it is too late to be heavily re-worked. Instead it is given a cursory spruce-up.
</blockquote>
<p>
If you let your developers create your UI, hilarity ensues, as in <a href="http://www.ok-cancel.com/comic/4.html">this classic OK/Cancel strip</a>. But when <a href="http://weblogs.asp.net/alex_papadimoulis/archive/2004/06/02/146784.aspx">The FileMatrix</a> is unleashed upon unsuspecting users, it's more like a horror movie. I still get chills. And like a bad horror movie franchise, <a href="http://www.gardenerofthoughts.org/ideas/filematrix/screenshots.htm">the FileMatrix is still alive and kicking</a>, folks.
</p>
<p>
<b>Friends don't let friends produce Developer UI.</b>
</p>
<p>
Part of being a good software developer is knowing your limits. Either <a href="http://www.codinghorror.com/blog/archives/000152.html">copy something that's already well designed</a>, or have the good sense to stick to coding and leave the graphic design to the experts.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-27T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/this-is-what-happens-when-you-let-developers-create-ui/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ The Project Postmortem ]]></title>
<link>https://blog.codinghorror.com/the-project-postmortem/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
You may think you've completed a software project, but you aren't truly finished until you've conducted a <b>project postmortem</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Mike Gunderloy calls the postmortem an <a href="http://www.developer.com/design/article.php/3637441">essential tool for the savvy developer</a>:
</p>
<p>
</p>
<blockquote>
The difference between average programmers and excellent developers is not a matter of knowing the latest language or buzzword-laden technique. Rather, it can boil down to something as simple as not making the same mistakes over and over again. Fortunately, there's a powerful tool that any developer can use to help learn from the past: the project postmortem.
</blockquote>
<p>
There's no shortage of checklists out there offering <a href="http://www.michaelgreer.com/postmortem.htm">guidance on conducting your project postmortem</a>. My advice is a bit more sanguine: <b>I don't think it matters how you conduct the postmortem, as long as you do it.</b> Most shops are far too busy rushing ahead to the next project to spend any time thinking about how they could improve and refine their software development process. And then they wonder why their new project suffers from all the same problems as their previous project.
</p>
<p>
Steve Pavlina offers <a href="http://www.gamedev.net/reference/articles/article977.asp">a game developer's perspective on postmortems</a>:
</p>
<p>
</p>
<blockquote>
The goal of a postmortem is to draw meaningful conclusions to help you learn from your past successes and failures. Despite its grim-sounding name, a postmortem can be an extremely productive method of improving your development practices.
</blockquote>
<p>
Game development is <a href="http://www.codinghorror.com/blog/archives/000129.html">some of the most difficult software development on the planet</a>. It's a veritable pressure cooker, which also makes it a gold mine of project postmortem knowledge. I've mentioned my fascination wth the <a href="http://www.codinghorror.com/blog/archives/000456.html">Gamasutra postmortems</a> before, but I didn't realize that all the Gamasutra postmortems had been consolidated into a book: <a href="http://www.amazon.com/exec/obidos/ASIN/1578202140/codihorr-20">Postmortems from Game Developer: Insights from the Developers of Unreal Tournament, Black and White, Age of Empires, and Other Top-Selling Games (Paperback) </a>. Ordered. Also, if you're too lazy for all that pesky reading, Noel Llopis <a href="http://www.gamesfromwithin.com/articles/0404/000019.html">condensed all the commonalities from the Game Developer magazine postmortems</a>.
</p>
<p>
Geoff Keighley's <a href="http://www.gamespot.com/features/btg/">Behind the Games</a> series, while not quite postmortems, are in the same vein. The early entries in the series are amazing pieces of investigative reporting on some of the most notorious software development projects in the game industry. Here are a few of my favorites:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.gamespot.com/features/btg-tri/">Haunted Glory: The Rise and Fall of Trilobyte</a>
</li>
<li>
<a href="http://www.gamespot.com/features/halflife_final/index.html">The Final Hours of Half-Life</a>
</li>
<li>
<a href="http://www.gamespot.com/features/btg-daikatana/">Knee Deep in a Dream: The Story of Daikatana</a>
</li>
<li>
<a href="http://gamespot.com/gamespot/features/pc/btg_bw/index.html">The Final Hours of Black &amp; White</a>
</li>
</ul>
<p>
Most of the marquee games highlighted here suffered massive schedule slips and development delays. It's testament to the difficulty of writing A-list games. I can't wait to read <b>The Final Hours of <a href="http://en.wikipedia.org/wiki/Duke_Nukem_Forever">Duke Nukem Forever</a></b>, which has been in development for almost ten years now. Its vaporware status is <i>legendary</i>-- here's <a href="http://duke.a-13.net/">a list of notable world events that have occurred since DNF began development</a>. "When it's done", indeed.
</p>
<p>
Don't make the mistake of omitting the project postmortem from your project. If you <i>don't</i> conduct project postmortems, then how can you possibly know what you're doing right-- and more importantly, how to <a href="http://www.codinghorror.com/blog/archives/000017.html">avoid making the same exact mistakes on your next project?</a>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-11-30T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/the-project-postmortem/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Today is &quot;Support Your Favorite Small Software Vendor Day&quot; ]]></title>
<link>https://blog.codinghorror.com/today-is-support-your-favorite-small-software-vendor-day/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I'm a Windows user, and I'm out to <a href="http://www.drunkenblog.com/drunkenblog-archives/000581.html">prove Wil Shipley wrong</a>:
</p>
<p>
</p>
<blockquote>
Mac users love their machines; Windows users put up with their machines because they don't believe there's anything really better.
<p>
I love the Mac user base because they tend to be people who are into trying out new software and recommending it to each other and giving the little guy a chance. <b>Windows users have demonstrated, ipso facto, that they do not believe in the little guy.</b>
</p>
</blockquote>
<p>
Wil's student talk from WWDC 2005 <a href="http://wilshipley.com/blog/2005/06/student-talk-from-wwdc-2005.html">piles on even more criticism</a> of stereotypical Windows users:
</p>
<p>
</p>
<ul>
<li>Windows users like going with the market leader, the "safe" choice.
</li>
<li>Windows users don't want to spend more for quality, so they buy crapware knockoffs of your idea instead.
</li>
<li>Windows users never upgrade.
</li>
<li>Windows users only use three apps: Word, IE, and ITunes.
</li>
<li>Windows users are afraid to install new software due to the massive amount of craplets and malware saturating the market.
</li>
</ul>
<p>
Them's fightin' words, Wil Shipley. Well, except for the last part, which is true. 90% of Windows software is absolute unfettered crap which should never be installed on any computer running any operating system. Ever. But I'd also say <a href="http://en.wikipedia.org/wiki/Sturgeon's_law">Sturgeon's Revelation</a> applies to all media, not just Windows software. But our 90% is larger than your 90%. Despite what all the Elise-drivin', iPod wearin', Mac-lovin' pundits would have you believe, it's not <i>all</i> craplets and malware in the Windows world.
</p>
<p>
As Windows users, we should do our part to fix this. Let's band together and support those small software vendors writing Windows apps that not only don't suck, they ROCK. Let's support the little guy who still gives a damn about creating small, beautiful, useful apps on an operating system that gets no respect.
</p>
<p>
That is why I declare today, Friday, December 1st, 2006, <b>Support Your Favorite Small Software Vendor Day</b>.
</p>
<p>
I've used <a href="http://www.mediamonkey.com/">Media Monkey</a> several times to help <a href="http://www.codinghorror.com/blog/archives/000653.html">catalog my self-ripped music collection</a>, and I was blown away by the speed, the ease of use, and the <a href="http://www.mediamonkey.com/product.htm">cool features</a> for mass-tagging my music. And, I'm ashamed to admit, I never paid the twenty bucks to register it. Even after using it quite extensively. I'm rectifying that situation right now: even as I type this post, I'm <a href="http://www.mediamonkey.com/register.htm?l=en">registering Media Monkey</a>.
</p>
<p>
<a href="http://www.mediamonkey.com/"><img alt="image placeholder" >
</p>
<p>
Check your hard drive, and I'm sure you, too, will find some bit of software written by a small software development shop, maybe even a single developer. Something you find incredibly useful. Something you rely on every day. Something you recommend without reservation to friends and peers. Something that makes using the computer that much more enjoyable. Or at least less painful.
</p>
<p>
<b>Stop reading this post <i>right now</i> and buy that software.</b> If it's not commercial software, don't let that stop you. Share the love by sending money to the person/shop/organization that created it.
</p>
<p>
This month it's MediaMonkey. Next month it might be <a href="http://bluemars.org/clipx/">ClipX</a>, or <a href="http://www.scootersoftware.com/">Beyond Compare</a>, or <a href="http://www.regexbuddy.com/cgi-bin/affref.pl?aff=jatwood">RegexBuddy</a>, or <a href="http://timesnapper.com/">TimeSnapper</a>. It's time to stop floating by on the "free" version and give something back. If I can't come up with the scratch to spend <b>a measly $20 a month supporting the very best work of my fellow independent software developers</b>, can I really call myself a <i>professional</i> software developer? Can you?
</p>
<p>
As a Windows user, I work extra hard to avoid reinforcing all these negative stereotypes. <b>I believe in the little guy writing cool Windows software.</b> And by "believe in", I mean "pay". And so should you. Whatever operating system you choose to run, try to support the little guys writing the apps <i>you</i> use. We owe it to them. And, more importantly, we owe it to ourselves.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-01T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/today-is-support-your-favorite-small-software-vendor-day/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Cool Gifts for Geeks: 2006 Edition ]]></title>
<link>https://blog.codinghorror.com/cool-gifts-for-geeks-2006-edition/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
As a technology enthusiast with a bad impulse purchase habit, I'm unrepentantly difficult to buy gifts for. The way I figure it, the only reason to grow up is so you can afford to buy yourself all the crap your parents wouldn't buy you when you were a kid.
</p>
<p>
That said, here are some of <b>my favorite lists of cool, quirky, offbeat geek gifts for 2006</b>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.kk.org/cooltools/archives/001473.php">Cool Tools High-End gifts, Part I</a>
</li>
<li>
<a href="http://www.kk.org/cooltools/archives/001479.php">Cool Tools High-End gifts, Part II</a>
</li>
<li>
<a href="http://scientificamerican.com/article.cfm?articleID=F800CBE7-E7F2-99DF-34D20E586BBF26E3&amp;pageNumber=1&amp;catID=4">Scientific American's 20 Gadgets We Love</a>
</li>
<li>
<a href="http://www.core77.com/ultimategiftguide/index.html">Core77's 77 design gifts under $77</a>
</li>
<li>
<a href="http://www.thinkgeek.com/holiday2006.shtml">ThinkGeek 2006 OMG! The most awesomest gifts EVAR ftw!!!11!one!</a>
</li>
<li>Engadget: <a href="http://www.engadget.com/2006/11/24/engadgets-holiday-gift-guide-for-him/">for him</a>, <a href="http://www.engadget.com/2006/11/24/engadgets-holiday-gift-guide-for-her/">for her</a>, <a href="http://www.engadget.com/2006/12/06/engadgets-holiday-gift-guide-for-son/">for son</a>
</li>
<li>
<a href="http://reviews.cnet.com/4520-12827_7-6659138.html?tag=ltst">CNET holiday gift guide</a>
</li>
<li>BBspot's <a href="http://www.bbspot.com/News/2006/12/top-11-best-geek-gifts.html">Top 11 best Geek Gifts</a> (parody)
</li>
<li>StreetTech gift guide: <a href="http://www.streettech.com/modules.php?op=modload&amp;name=Reviews&amp;file=index&amp;req=showcontent&amp;id=64">part one</a>, <a href="http://www.streettech.com/modules.php?op=modload&amp;name=Reviews&amp;file=index&amp;req=showcontent&amp;id=65">part two</a>
</li>
</ul>
<p>
This year, I preemptively treated myself to a the new <a href="http://www.iriveramerica.com/prod/ultra/clix/clix-4GB.aspx">4 gigabyte iRiver Clix</a> ($199), and after living with this stellar little flash music player for a week, I can heartily recommend it to anyone.
</p>
<p>
<a href="http://www.iriveramerica.com/prod/ultra/clix/clix-4GB.aspx"><img alt="image placeholder" >
</p>
<p>
It does <a href="http://www.codinghorror.com/blog/archives/000730.html">everything the iPod refuses to do</a>: subscription services, wma/ogg support, FM Radio (w/recording!), <a href="http://www.adobe.com/products/flashlite/">Flash Lite</a> games, video playback, and voice recording. It has a speedy, intuitive UI that can be switched between landscape or portrait mode at will. And best of all, no software installs are required*: just plug it in, drag and drop your music on it, then play. But don't take my word for it: read the glowing critical acclaim at <a href="http://www.pcmag.com/article2/0,1895,1961584,00.asp">PC Magazine</a>, <a href="http://www.anythingbutipod.com/archives/2006/05/iriver-clix-review.php">ABiP</a>, and <a href="http://reviews.cnet.com/iRiver_Clix_2GB/4505-6490_7-31861628-2.html?tag=nav">Cnet</a>.
</p>
<p>
I've provided one specific gift recommendation, and my favorite geek gift suggestion lists so far. But I'm sure I've missed plenty. <b>Are there any cool geek gift lists I've missed?</b>
</p>
<p>
* caveat: assuming you have an OS that supports <a href="http://en.wikipedia.org/wiki/Media_Transfer_Protocol">MTP</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-03T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/cool-gifts-for-geeks-2006-edition/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Are You an Evangelist Too? ]]></title>
<link>https://blog.codinghorror.com/are-you-an-evangelist-too/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Anil Dash and I have the same job title: <b>evangelist</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
I share <a href="http://www.dashes.com/anil/2006/11/29/what_i_do_for_a">Anil's reservations about his job title</a>, too:
</p>
<p>
</p>
<blockquote>
You see, these days my business cards describe me as "Chief Evangelist". On the plus side, it's the first time in the history of the company that I've basically only had one job (though I still help out with as much stuff as I can), but on the downside, the title is f**king ridiculous. I hate the word "evangelist" as a description for people who advocate technology not merely because of its religious connotations, but also because it implies a degree of proselytization that I'd like to think I don't participate in. Most of the time, my job is really just simple education.
</blockquote>
<p>
However, unlike Anil, I believe <b>the religious connotations of the evangelist title are perfectly suited to the field of software development</b>. <a href="http://www.codinghorror.com/blog/archives/000699.html">Software development is a religion</a>, and any programmer worth his or her salt is <a href="http://www.codinghorror.com/blog/archives/000247.html">the scarred veteran of a thousand religious wars</a>. That doesn't mean we need to be humorless jerks about it, of course. But to completely disavow the connection between religion and software development is dishonest. I say we embrace it. We're all disciples of <a href="http://en.wikipedia.org/wiki/John_von_Neumann">the church of Von Neumann</a>. Praise the lord and pass the ones and zeroes!
</p>
<p>
The title is a little ridiculous. My wife tells me that everyone laughs when she explains that her husband is a <i>technical evangelist</i>. Am I offended? Heck no. I think that's great. Laughing is the only sane, rational response to any kind of evangelism -- it means you have a sense of humor. <b>Entertainment is a crucial part of being an evangelist.</b> Without it, you're a sanctimonious bore. Good evangelism is always equal parts education and entertainment. <i>Edutainment</i>, if you will.
</p>
<p>
Of course, you'll only be effective as an evangelist if you can <b>clearly communicate your ideas to other people</b>. This is a critical skill, whether you have any desire to be an "evangelist" or not. As Joel Spolsky famously <a href="http://www.joelonsoftware.com/articles/CollegeAdvice.html">said</a>:
</p>
<p>
</p>
<blockquote>
The difference between a tolerable programmer and a great programmer is not how many programming languages they know, and it's not whether they prefer Python or Java. It's whether they can communicate their ideas.
</blockquote>
<p>
It's <a href="http://www.codinghorror.com/blog/archives/000710.html">questionable how effective you can be by writing code alone</a>. You have to convince us how awesome your code is. You have to make us <i>believe</i> in the glory of that code. In short, you evangelize. And that means constantly cultivating those essential communication skills.
</p>
<p>
With apologies to Jeff Foxworthy, if you frequently find yourself entertaining people to effectively communicate with them, <a href="http://www.fortogden.com/foredneck.html">you may be.. an Evangelist</a>. Take <a href="http://radar.oreilly.com/archives/2006/12/engineering_man.html">Marc Hedlund's experiences</a>, for example:
</p>
<p>
</p>
<blockquote>
I was recently asked how I run our development team. I said, "Well, basically I blog about something I think we should do, and if the blog post convinces the developers, they do it. If not, I lobby for it, and if that fails too, the idea falls on the floor. They need my approval to launch something, but that's it. That's as much 'running things' as I do, and most of the ideas come from other people at this point, not from me and my blog posts. I've argued against some of our most successful ideas, so it's a good thing I don't try to exert more control." I'm exaggerating somewhat; of course I haven't blogged about all of our ideas yet. But I do think of myself as Lobbyist-in-Chief, and I have lots of good examples of cases where I failed to talk people into an idea and it didn't happen as a result. One person I said this to asked, "So who holds the product vision, then?" and I replied, "Well, I guess I do," but really that's not right. We all do. The product is the result of the ideas that together we've agreed to pursue. I recruit people based on their interest in and enthusiasm about the ideas behind Wesabe, and then set them loose, and we all talk and listen constantly. That's how it works -- and believe it or not, it does work.
</blockquote>
<p>
Like Marc, you may already be an evangelist and not even know it. And it really <i>does</i> work.
</p>
<p>
Evangelism is simply <b>sharing your excitement and enthusiasm with other people in an effective way</b>. If that makes you more entertaining and a better communicator, well, those are side effects you can probably live with.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-04T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/are-you-an-evangelist-too/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Reading with Edward Tufte ]]></title>
<link>https://blog.codinghorror.com/reading-with-edward-tufte/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Today, a group of thirteen <a href="http://www.vertigo.com">Vertigo</a> folks, including myself, attended Edware Tufte's <a href="https://www.edwardtufte.com/tufte/courses">one-day course on Presenting Data and Information</a> in San Francisco. The course is $360 for the day, but that includes all four of Tufte's books, which are currently going for about $141 new on Amazon. We had a group of more than ten, so we received the 25% group discount. The net cost is about $130 for a day with Tufte.
</p>
<p>
Once you start Tufte's course, you'll immediately realize why all four books are included in the course cost.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
It's not due to any particular generosity on Tufte's part-- <b>he uses the books as high-resolution handouts</b>. Tufte only uses projectors and computers for a handful of images and movies. Everything else begins with a scholarly "please turn to page (n) of your books".
</p>
<p>
And they are truly wonderful books. <a href="http://www.codinghorror.com/blog/archives/000270.html">I've been a Tufte fan for years</a>, so I already owned a set, but it's worth attending his course just to get the books.
</p>
<p>
<a href="http://www.amazon.com/exec/obidos/ASIN/0961392142/codihorr-20"><img alt="image placeholder" >

<a href="http://www.amazon.com/exec/obidos/ASIN/0961392118/codihorr-20"><img alt="image placeholder" >

<a href="http://www.amazon.com/exec/obidos/ASIN/0961392126/codihorr-20"><img alt="image placeholder" >

<a href="http://www.amazon.com/exec/obidos/ASIN/0961392177/codihorr-20"><img alt="image placeholder" >
</p>
<p>
His writing is fantastic, but it can be dry at times. I was surprised to find that <b>Edward Tufte is a funny, animated speaker</b>. We spent all morning reading through about a half-dozen sections in his last three books. Although I've read them all before, it was illuminating to have Tufte guide us through the reading selections and provide running commentary. It complemented the text nicely. He brought out a lot of nuances in the text that I completely glossed over in my initial read. The latter half of the day was split between <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&amp;topic_id=1&amp;topic=">sparklines</a> and <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001yB&amp;topic_id=1">avoiding the pitfalls of PowerPoint</a>. As usual, everything was presented directly from the books.
</p>
<p>
Should you attend a <a href="https://www.edwardtufte.com/tufte/courses">Tufte course</a>? If you can swing it, and <a href="https://www.edwardtufte.com/tufte/course-choose">if there's one in your area</a>, <b>I definitely recommend it</b>. There's nothing in the course you couldn't get directly from the books yourself, but the material is always more effective when it's presented by a good teacher.
</p>
<p>
As you enter the course, you're provided a folded four-page handout. One of the highlights in this handout is a section titled "An Education for Analytical Design". It's a cheat sheet of sorts, and <a href="http://www.codinghorror.com/blog/archives/000481.html">you know how I love cheatsheets</a>. I'll reprint it here exactly as Tufte entered it, adding hyperlinks for easier browsing:
</p>
<p>
</p>
<blockquote>
<b>An Education for Analytical Design</b>
<p>
<b>Fundamentals</b>Josef Albers, <a href="http://www.amazon.com/exec/obidos/ASIN/0300115954/codihorr-20"><i>Interaction of Color</i></a>Robert Bringhurst, <a href="http://www.amazon.com/exec/obidos/ASIN/0881792063/codihorr-20"><i>The Elements of Typographic Style</i></a>Joseph Lowman, <a href="http://www.amazon.com/exec/obidos/ASIN/078795568X/codihorr-20"><i>Mastering the Techniques of Teaching</i></a>Scott McCloud, <a href="http://www.amazon.com/exec/obidos/ASIN/06097625X/codihorr-20"><i>Understanding Comics</i></a>Marcel Minnaert, <a href="http://www.amazon.com/exec/obidos/ASIN/0387979352/codihorr-20"><i>Light and Color in the Outdoors </i></a>Donald Norman, <a href="http://www.amazon.com/exec/obidos/ASIN/0465067107/codihorr-20"><i>The Design of Everyday Things</i></a>Strunk and White, <a href="http://www.amazon.com/exec/obidos/ASIN/020530902X/codihorr-20"><i>The Elements of Style</i></a>, the last chapter on style (read once a year)Norman J.W.Thrower, <a href="http://www.amazon.com/exec/obidos/ASIN/0226799735/codihorr-20"><i>Maps and Civilization</i></a>Edward Tufte, <a href="http://www.amazon.com/exec/obidos/ASIN/0961392142/codihorr-20"><i>The Visual Display of Quantitative Information</i></a>Edward Tufte, <a href="http://www.amazon.com/exec/obidos/ASIN/0961392118/codihorr-20"><i>Envisioning Information</i></a>Edward Tufte, <a href="http://www.amazon.com/exec/obidos/ASIN/0961392126/codihorr-20"><i>Visual Explanations</i></a>Edward Tufte, <a href="http://www.amazon.com/exec/obidos/ASIN/0961392177/codihorr-20"><i>Beautiful Evidence</i></a>
</p>
<p>
<b>Advanced Readings</b>Rudolf Arnheim, <a href="http://www.amazon.com/exec/obidos/ASIN/0520242262/codihorr-20"><i>Visual Thinking</i></a>William Cleveland, <a href="http://www.amazon.com/exec/obidos/ASIN/0963488414/codihorr-20"><i>The Elements of Graphing Data</i></a> and his <a href="http://www.amazon.com/exec/obidos/ASIN/0963488406/codihorr-20"><i>Visualizing Data</i></a>Eduard Imhoff, <a href="http://www.amazon.com/exec/obidos/ASIN/3110067110/codihorr-20"><i>Cartographic Relief Presentation</i></a>Stewart Brand, <a href="http://www.amazon.com/exec/obidos/ASIN/0753810123/codihorr-20"><i>The Clock of the Long Now: Time and Responsibility</i></a>Alan Cooper, <a href="http://www.amazon.com/exec/obidos/ASIN/0764526413/codihorr-20"><i>About Face</i></a>Ben Shneiderman, <a href="http://www.amazon.com/exec/obidos/ASIN/0321197860/codihorr-20"><i>Designing the User Inteface</i></a>Philip Greenspun, <a href="http://www.amazon.com/exec/obidos/ASIN/1558605347/codihorr-20"><i>Philip and Alex's Guide to Web Publishing</i></a>
</p>
<p>
<b>Videos</b>Video and book: <a href="http://www.amazon.com/exec/obidos/ASIN/6305943877/codihorr-20"><i>Powers of Ten</i></a> (<a href="http://www.metacafe.com/watch/54240/powers_of_ten/">watch video</a>) by Philip Morrison and Phylis Morrison and The Office of Charles and Ray Eames; <a href="http://www.css.washington.edu/emc/titles.php?abstracts=1&amp;mid=6486"><i>Sorting out Sorting</i></a> (<a href="http://youtube.com/watch?v=AUn7-36oluU">watch video</a>) by Ronald Baecker; <a href="http://www.projectmathematics.com/"><i>Project MATHEMATICS!</i></a> (<a href="http://www.projectmathematics.com/storypi.htm">watch videos</a>) by Tom M. Apostol and James F. Blinn
</p>
<p>
<b>Internet</b> <a href="http://www.google.com">www.google.com</a> <i>(also searches images!)</i> <a href="http://www.aldaily.com">www.aldaily.com</a> <a href="http://www.bookfinder.com">www.bookfinder.com</a> <a href="http://www.asktog.com">www.asktog.com</a> <a href="http://www.amazon.com">www.amazon.com</a> <a href="http://setiathome.ssl.berkeley.edu">setiathome.ssl.berkeley.edu</a> <a href="http://www.junkbusters.com">www.junkbusters.com</a> <a href="http://www.photo.net">www.photo.net</a> <a href="http://www.science.nasa.gov">www.science.nasa.gov</a> <a href="http://www.musanim.com">www.musanim.com</a> <i>(to order the Music Animation Machine videotape)</i>
</p>
<p>
<b>Computer Programs</b>For serious data analysis, use a high-end statistics package such as <a href="http://www.originlab.com/">Origin 6.0</a>, <a href="http://www.systat.com/">SYSTAT 8.0</a>, <a href="http://www.datadesk.com/">Datadesk</a>, <a href="http://www.stata.com/">STATA</a>, <a href="http://www.sas.com/">SAS</a>, <a href="http://www.spss.com/">SPSS</a>, <a href="http://www.systat.com/products/sigmaplot/">SigmaPlot</a>, <a href="http://www.insightful.com/products/splus/">S-PLUS</a>. See <a href="https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&amp;topic_id=1">sparklines essay on Ask ET forum</a> for more on production issues.
</p>
<p>
<b>Courses</b>Writing, general science, statistics (data analysis, research design), applied mathematics, cartography, medical illustration, architecture, publishing, typography, color, book design, film-making, computers, scientific visualization
</p>
<p>
<b>Personal Favorites</b>Christopher Alexander, Sara Ishikawa, <i>et al.</i>, <a href="http://www.amazon.com/exec/obidos/ASIN/0195019199/codihorr-20"><i>A Pattern Language</i></a>; Robert Merton, <a href="http://www.amazon.com/exec/obidos/ASIN/0226520862/codihorr-20"><i>On the Shoulders of Giants</i></a>; Evelyn Waugh, <a href="http://www.amazon.com/exec/obidos/ASIN/0316926108/codihorr-20"><i>Scoop</i></a>; Italo Calvino <a href="http://www.amazon.com/s/ref=nb_ss_b/103-9777711-6401439?url=search-alias%3Dstripbooks&amp;field-keywords=author%3Aitalo+calvino">novels</a>; Gore Vidal <a href="http://www.amazon.com/s/ref=nb_ss_b/103-9777711-6401439?url=search-alias%3Dstripbooks&amp;field-keywords=gore+vidal+essays">literary essays</a>; <i>The Paris Review</i> <a href="http://www.amazon.com/exec/obidos/ASIN/0312361750/codihorr-20">Interviews</a>; <i>Writers at Work</i> (<a href="http://www.amazon.com/s/ref=nb_ss_b/103-9777711-6401439?url=search-alias%3Dstripbooks&amp;field-keywords=writers+at+work+paris+review">15 volumes</a>); Paul Klee, <i>Notebooks</i>; Richard P. Feynman, <a href="http://www.amazon.com/exec/obidos/ASIN/0393316041/codihorr-20"><i>"Surely You Are Joking, Mr. Feynman,"</i></a> and <a href="http://www.amazon.com/exec/obidos/ASIN/0393320928/codihorr-20"><i>"What Do You Care What Other People Think"</i></a>
</p>
</blockquote>
<p>
</p>
<p>
</p>
<blockquote>
<b>Some 20th Century Classics of Information Architecture</b>
<p>
<a href="http://en.wikipedia.org/wiki/Hertzsprung-Russell_diagram">Hertzsprung-Russell Diagram</a>, 1912. Relating the brightness of stars to their spectrum and temperature, this diagram showed the unexpected, brought together many dimensions of information into a coherent pattern, and has remained relevant for understanding the evolution of stars for nearly a century now. The diagram also accommodates the modern intensifying of information: the first plot contained 300 stars; recent diagrams show data from 93,000 stars.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Tube_map">Harry Beck, The London Underground Map</a>, 1933. Beck's diagram of the seven lines of the London Underground, though geographically inaccurate, provides a coherent overview of a complex system. With excellent color printing, classic British railroad typography, and, in the modern style, only horizontal, vertical, and 45 degree lines, the map became a beautiful organizing image of London. Despite 65 years of revisions due to the extensions of the Underground and bureaucratic tinkering with the design, the map nicely survives to this day. European and American knock-offs did not succeed.
</p>
<p>
<a href="http://www.houghtonmifflinbooks.com/peterson/bird.cfm">Roger Tory Peterson, <i>A Field Guide to The Birds</i></a>, 1934. This book exemplifies the modern field guide, visually demonstrating to every reader the richness of biological diversity by means of "diagnostic marks" (pointers indicating small but telltale differences among birds). With some 5.5 million copies in print, the book got tens of millions of people outdoors looking at birds -- and also thinking about how to preserve the diversity and complexity of nature.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Penguin_Books">Jan Tschichold and Penguin Books</a>, 1947-1949. These inexpensive paperbacks brought the classics -- and a good many current books as well -- to the mass market. Tschichold set a consistent design for the Penguin books, with clear, elegant, timeless typography that endlessly serves the content.
</p>
<p>
<a href="http://www.swisstopo.admin.ch/internet/swisstopo/en/home.html">Swiss Mountain Maps, Bundesamt Fur Landestopographie</a>. Beautiful layering and separation, excellent three-dimensional effects (shading, contour lines, labels), superb resolution. The best national maps (of course, the Swiss have good content to work with!).
</p>
<p>
<a href="http://en.wikipedia.org/wiki/DNA">James D. Watson and Francis Crick, Molecular Structure for DNA</a>, 1953. The double helix of DNA, a distinctly high resolution design, is Nature's information architecture for all life forms. Since the two strands of the helix are complimentary, the very architecture suggests how DNA replicates itself and how genetic information is communicated from generation to generation.
</p>
<p>
<a href="http://data.giss.nasa.gov/gistemp/">NASA, Global Temperature Maps</a>, 1960. For nearly 40 years, satellites have continuously measured the temperature of the Earth's surface and atmosphere. High resolution visual displays provide the only way to comprehend these multidimensional data files of trillions of numbers that help to assess the longrun history of global temperature change.
</p>
<p>
<a href="http://www2.oag.com/tt/catalog/traveler.html">The OAG Pocket Flight Guide</a>. A thousand pages of tiny type published each month on thin paper, this nice pocket book shows approximately 200,000 flight schedules. The guide gives control of the information -- and therefore greater choice -- to individual travellers, protecting them from the biases of travel agents and airlines. Used at the airport, this high resolution classic of information display also assists recovery from delayed or cancelled flights. Requires reading-glasses for those of a certain age.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Graphical_user_interface">Douglas Engelbart and Xerox Parc, The Graphical User Interface</a>, 1965-1981. Until 10-15 years ago, the main way that humans interacted with computers was by <i>remembering and typing</i>. Now we <i>look and point</i> -- at words and images, links, icons, menus, windows. The graphical user interface has given the computer to everyone (with enough money) and, combined with the laser printer, has led to more printed paper per capita than ever in human history! The quality of interface design may have peaked around 1990; too many computer screens today are overrun with operating system imperalism, featuritis, marketeering banners, and overproduced gimmicks.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Vietnam_Veterans_Memorial">Maya Lin, the Vietnam Veterans Memorial</a>, 1985. From a distance the 58,000 dead soldiers arrayed on the black granite yield a visual measure of what 58,000 means, as the letters of each name blur into a gray shape. When the viewer approaches, these shapes resolve into individuals. The focus is on the tragic information; absent are the marble paraphernalia of other official monuments -- big porticoes, steps and stairs, and the kitschy hyper-realistic generic soldiers.
</p>
<p>
<a href="http://en.wikipedia.org/wiki/Internet">The Internet and Email</a>, 1990-. The greatest dispersion and intensification of information since the printing of books with moveable type in Korea and China around 650. Weaknesses: recency bias, short attention span, low credibility of many documents, low resolution in space and time.
</p>
<p>
</p>
</blockquote>
That should be enough to keep us busy for a while. And be sure to check out the hilarious <a href="http://www.tc.cornell.edu/About/Pages/outreach.htm">Viz-o-Matic</a> video that E.T. showed during the class, too!
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-07T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/reading-with-edward-tufte/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Joining The Prestigious Three Monitor Club ]]></title>
<link>https://blog.codinghorror.com/joining-the-prestigious-three-monitor-club/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I have something in common with Bill Gates and Larry Page:
</p>
<p>
</p>
<blockquote>
<a href="http://www.sfgate.com/cgi-bin/article.cgi?file=/chronicle/archive/2000/12/31/BU178263.DTL">Larry Page</a>: I have a weird setup in my office. I have one computer with three monitors: one flat-screen monitor and two regular ones. I have my browser on one screen, my schedule on another and my e-mail on another. I can drag things to different screens. I also have a projector. So if I'm talking with everyone in my office, I can move stuff onto a big screen.
<p>
<a href="http://money.cnn.com/2006/03/30/news/newsmakers/gates_howiwork_fortune/">Bill Gates</a>: If you look at this office, there isn't much paper in it. On my desk I have three screens, synchronized to form a single desktop. I can drag items from one screen to the next. Once you have that large display area, you'll never go back, because it has a direct impact on productivity.
</p>
</blockquote>
<p>
We're all members of the <b>three monitor club</b>.
</p>
<p>
If you're only using one monitor, you are <a href="http://www.codinghorror.com/blog/archives/000012.html">cheating yourself out of potential productivity</a>. Two monitors is a no-brainer. It's so fundamental that I included it as a part of the <a href="http://www.codinghorror.com/blog/archives/000666.html">Programmer's Bill of Rights</a>.
</p>
<p>
But you can do better.
</p>
<p>
As good as two monitors is, <b>three monitors is <a href="http://www.codinghorror.com/blog/archives/000217.html">even better</a></b>. With three monitors, there's a "center" to focus on. And 50% more display area. While there's certainly a <a href="http://blogs.vertigosoftware.com/jatwood/archive/2005/08/28/Multiple_Monitor_Madness.aspx">point of diminishing returns for additional monitors</a>, I think three is the sweet spot. Even Edward Tufte, in <a href="http://www.codinghorror.com/blog/archives/000739.html">the class I recently attended</a>, explicitly mentioned multiple monitors. I don't care how large a single display can be; you can <i>never</i> have enough desktop space.
</p>
<p>
Normally, to achieve three monitors, you have to either:
</p>
<ol>
<li>Buy an exotic video card that has more than 2 monitor connections.
</li>
<li>Install a second video card.
</li>
</ol>
<p>
The first option is difficult because video cards with 3+ monitor connections are quite rare and usually expensive to boot. The second option, adding an additional video card, is easier, but not without some compatibility pitfalls of its own. But there's a third way that may be easiest of all. The Matrox <a href="http://www.matrox.com/graphics/en/gxm/products/th2go/home.php">TripleHead2Go</a> is a neat little external device that provides three display support from a single video output. And it's now available in analog VGA and <a href="http://www.matrox.com/graphics/en/gxm/products/th2go/digital/home.php">digital DVI editions</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
There is one big caveat, however. In a modern three monitor config, the operating system sees each monitor as an independently controllable desktop. You can set resolution, size, and position of the monitors independently, and windows can intelligently size themselves to each desktop on each monitor.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
With the matrox Triplehead2Go, <b>you're stuck with one mongo giant desktop that spans all your monitors</b>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
This is a very old-school way of implementing multiple monitors. Before Windows was properly aware of multiple displays (think NT 4.0 era), the "giant desktop" was the only way you could get more than one display to work at all. And "giant desktop" has a <i>lot</i> of downsides:
</p>
<p>
</p>
<ol>
<li>Maximizing a window becomes an exercise in futility.
</li>
<li>You may not want your start menu on the leftmost monitor.
</li>
<li>With two monitors, "centered" dialogs split the middle.
</li>
</ol>
<p>
To avoid the many problems of "giant desktop" fakery, you really need the OS to know that you're using two or three physical monitors, along with their resolutions, positions, and so forth.
</p>
<p>
But the Triplehead2Go has its charms. You don't have to open your computer to install it, for one thing. And it works with computers that <i>can't</i> be opened, such as laptops. The Triplehead2Go abstracts away the multiple monitors at a hardware level and presents itself to the operating system as a giant ultra widescreen monitor.
</p>
<p>
The Triplehead2Go also has one unexpected strength: <b>video games</b>. 3D acceleration across multiple video cards is tricky at best. And there's no good way to tell a game to use multiple monitors unless it's explicitly coded to do so. The Triplehead2Go device neatly sidesteps both of these limitations by externally simulating one ultra-ultra-wide monitor.
</p>
<p>
PCFormat UK experimented with the Triplehead2Go in a couple recent and upcoming game titles, such as <a href="http://blog.pcformat.co.uk/page/pcformat?entry=armed_assault_holy_trinity">Armed Assault</a>:
</p>
<p>
<a href="http://blog.pcformat.co.uk/resources/pcformat/windetriptych3.jpg"><img alt="image placeholder" >
</p>
<p>
Armed Assault also takes advantage of an optional <a href="http://www.naturalpoint.com/trackir/">TrackIR head-tracking device</a>. The combination of a three-monitor setup with head tracking is incredibly immersive, and has to be seen to be believed. <a href="http://blog.pcformat.co.uk/resources/pcformat/trinity.wmv">Watch the video and be amazed</a>.
</p>
<p>
Three-monitor setups are particularly strong in "simulator" type games where peripheral vision is crucial to gameplay. PC Format UK tried it with the recently released <a href="http://blog.pcformat.co.uk/page/pcformat/20060503">GTR2 racing game</a>, and the results are impressive.
</p>
<p>
<a href="http://blog.pcformat.co.uk/resources/pcformat/monzacrashw.jpg"><img alt="image placeholder" >
</p>
<p>
There are lots more screenshots of various games running in triple-head mode at <a href="http://www.tomshardware.com/2006/05/04/can_matroxs_triplehead2go_span_fun_across_three_displays/page8.html">Tom's Hardware</a> and <a href="http://www.neoseeker.com/Articles/Hardware/Reviews/triplehead2go/5.html">Neoseeker</a>.
</p>
<p>
<b>The traditional "add another video card" method is still the preferred way to gain entry into the prestigious three monitor club.</b> But for laptop users and gamers, the Matrox Triplehead2Go is also a nice option with <a href="http://www.matrox.com/graphics/en/gxm/products/th2go/faq.php">a few caveats</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-08T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/joining-the-prestigious-three-monitor-club/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Moore's Law in Practical Terms ]]></title>
<link>https://blog.codinghorror.com/moores-law-in-practical-terms/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
There are two popular <a href="http://en.wikipedia.org/wiki/Moore's_law#Formulations_of_Moore.27s_Law">formulations of Moore's Law</a>:
</p>
<p>
</p>
<blockquote>
The most popular formulation [of Moore's Law] is <b>the doubling of the number of transistors on integrated circuits every 18 months</b>. At the end of the 1970s, Moore's Law became known as the limit for the number of transistors on the most complex chips. However, it is also common to cite Moore's Law to refer to the rapidly continuing advance in computing power per unit cost, because transistor count is also a rough measure of computer processing power.
</blockquote>
<p>
The number of transistors on a CPU hasn't actually been doubling every 18 months; it's been doubling every 24 months. Here's a graph of <a href="http://en.wikipedia.org/wiki/Transistor_count">the transistor count of each major Intel x86 chip family release</a> from 1971 to 2006:
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
The dotted line is the predicted transistor count if you doubled the 2,300 transistors from the Intel 4004 chip every two years since 1971.
</p>
<p>
That's why I prefer the second, looser definition of Moore's law: dramatic increases in computing power per unit cost. If you're a stickler for detail, there's an <a href="http://arstechnica.com/articles/paedia/cpu/moore.ars">extensive investigation of Moore's law at Ars Technica</a> you can refer to.
</p>
<p>
But how do we correlate Moore's Law-- the inexorable upward spiral of raw transistor counts-- with performance in practical terms? Personally, I like to look at benchmarks that use "typical" PC applications, such as <a href="http://www.bapco.com/products/sysmark2004/">SysMark 2004</a>. According to page 14 of <a href="http://www.bapco.com/techdocs/SYSmark2004WhitePaper.pdf">this PDF</a>, SysMark 2004 scores are calibrated to a reference system: a Pentium 4 2.0 GHz. The reference system scores 100. <b>Thus, a system which scores 200 in SysMark 2004 will be twice as fast as the reference system.</b>
</p>
<p>
So, what was the first new CPU to <i>double</i> the performance of the SysMark 2004 reference system with a perfect 200? The Pentium 4 "Extreme Edition" 3.2 GHz scores 197 on the SysMark 2004 office benchmark in this <a href="http://www.tomshardware.com/2004/03/18/spring_speed_leap/page25.html">set of Tom's Hardware benchmarks</a>. Let's compare the release dates of these two CPUs:
</p>
<p>
</p>
<table width="300">
<tr>
<td>Pentium 4 2.0 GHz</td>
<td>August 27th, 2001
</td>
</tr>
<tr>
<td>Pentium 4EE 3.2 GHz</td>
<td>November 3rd, 2003
</td>
</tr>
</table>
<p>
It took <b>26 months to double real world performance in SysMark 2004</b>. That tracks almost exactly with the doubling of transistor counts every 24 months.
</p>
<p>
This isn't a perfect comparison, since other parts of the PC get faster at different rates. But it's certainly a good indication that <b>CPU transistor count is fairly reliable indicator of overall performance.</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-10T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/moores-law-in-practical-terms/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Printer and Screen Resolution ]]></title>
<link>https://blog.codinghorror.com/printer-and-screen-resolution/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>A recurring theme in <a href="http://www.codinghorror.com/blog/archives/000739.html">Edward Tufte's books</a> is <strong>the massive difference in resolution between the printed page and computer displays</strong>. Printed pages lend themselves to <a href="http://www.codinghorror.com/blog/archives/000644.html">vastly greater information density</a>.</p>
<p><a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&amp;topic_id=1">Sparklines</a> are one particular technique of Tufte's designed to exploit the greater resolution of the printed page. I was curious just how profound the difference in resolution is between a computer screen and a book, so I scanned in a sparkline from <a href="http://www.amazon.com/exec/obidos/ASIN/0961392177/codihorr-20">Beautiful Evidence</a> with my aging <a href="http://www.epson.com/cgi-bin/Store/support/supDetail.jsp?BV_UseBVCookie=yes&amp;oid=14568&amp;infoType=Overview">Epson 1200U</a> scanner.</p>
<p>
<img alt="image placeholder" >
<p>This is what the sparkline looks like on the page, roughly. It's quite small. The actual size will depend on the resolution of the display you're using to view this, of course, but it's in the ballpark at 1280x1024 and 1600x1200.</p>
<p>Here's the very same sparkline at the maximum resolution of my scanner, 1200 DPI:</p>
<p><img alt="image placeholder" >
<p><img alt="image placeholder" >
<p>Of course, <a href="http://www.amazon.com/exec/obidos/ASIN/0961392177/codihorr-20">Beautiful Evidence</a> was commercially printed, which is typically very high resolution-- on the order of 2400 DPI. Let's try something a little less sophisticated. Here's a bit of text in 8 point Gill Sans MT that I printed on our decrepit old <a href="http://printers.necam.com/main.cfm?thePage=http://printers.necsam.com/public/printers/splash_page/870.htm&amp;SP=367">NEC 870</a> printer and scanned back in at 1200 DPI:</p>
<p><img alt="image placeholder" >
<p>This is output from a 600 DPI printer that was originally released more than 7 years ago.</p>
<p>For comparison, <a href="http://www.dansdata.com/gz029.htm">a typical computer display is between 72 and 100 DPI</a>. But that doesn't stop us from trying:</p>
<p><a href="http://www.bonavistasystems.com/"><img alt="image placeholder" >
<p>As Tufte promised, the difference in resolution between the most expensive computer display you can buy and a cheap off-brand printer <strong>really is astronomical</strong>. We have a long, long way to go before computer displays can get anywhere near printer resolutions.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-11T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/printer-and-screen-resolution/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Is Your Database Under Version Control? ]]></title>
<link>https://blog.codinghorror.com/is-your-database-under-version-control/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
When I ask development teams whether their database is under version control, I usually get blank stares.
</p>
<p>
The database is a critical part of your application. If you deploy version 2.0 of your application against version 1.0 of your database, what do you get? A broken application. And that's why <b>your database should always be under source control right next to your application code</b>. You deploy the app, and you deploy the database. Like peanut butter and chocolate, they are two great tastes that taste great together.
</p>
<p>
At Vertigo, we rolled our own tool to reverse engineer the database into a set of files, which we then check into source control. I've visited other customers that did the same thing. But why write what you can buy? Leon Bambrick lists <a href="http://secretgeek.net/dbcontrol.asp">a number of great tools</a> you can purchase to help you in get your database under version control where it belongs. Unfortunately, he omitted one of the best tools: Microsoft's new <a href="http://msdn2.microsoft.com/en-us/teamsystem/aa718807.aspx">Team Edition for Database Professionals</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
<a href="http://msdn2.microsoft.com/en-us/teamsystem/aa718807.aspx">Team Edition for Database Professionals</a> goes far beyond mere reverse engineering of the database into files. You get an industrial-strength database project that you can add to your solution, along with a few other goodies:
</p>
<p>
</p>
<ul>
<li>
<b>Create test data.</b> A blank database schema isn't particularly useful to develop against. Now you can distribute your database schema along with one-click synthetic data generation plans. With flexible synthetic data generators, you can avoid dumping production data to developers, or, God forbid, letting developers fend for themselves by creating their own test data. And you can generate 1,000 rows or 100,000 rows. I wish I had a dollar every time an application I've worked on began to have performance problems because none of the developers had the foresight to test the app with more than a few rows of crappy, manually entered test data. Data generation is a <i>huge</i> increase in development quality.
</li>
<li>
<b>Schema comparison</b>. If we can compare two files in source control, why can't we compare two tables? A robust schema comparison tool is essential. Not sure why staging is different than production? Run a quick schema compare on 'em. Did I mention it also creates a real-time update script every time you do a comparison.. which it can execute with one additional click?
</li>
<li>
<b>Data comparison</b>. If your testers are complaining because they entered test data that causes your application to crash, run the data compare tool to determine exactly how their data differs from yours.
</li>
<li>
<b>Database unit testing</b>. If you make a change to the database schema, how do you know if you've broken any applications that rely on that database? You know because you've written unit tests that validate the database. Right? <i>Right?</i>
</li>
<li>
<b>Refactoring</b>. You can rename entities in the database (columns, tables, procs, etc) and have the rename automatically cascade throughout the database.
</li>
<li>
<b>Integrated T-SQL editor</b>. T-SQL is now a first class language construct in the IDE, just like C# and VB.NET. Run queries and view execution plans and stats, all without leaving the cozy confines of good old Visual Studio.
</li>
</ul>
<p>
It's a great tool.. if you're a Microsoft shop, and you're using SQL Server. I highly recommend <a href="http://www.microsoft.com/downloads/details.aspx?familyid=7de00386-893d-4142-a778-992b69d482ad&amp;displaylang=en">downloading the trial edition</a>. But the specifics of the tool aren't important; <b>get your database under version control by any means necessary</b>. Making your database a first-class citizen in source control seems totally obvious in retrospect. Now if only we could convince more developers to actually do it.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-12T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/is-your-database-under-version-control/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ LCD Progress ]]></title>
<link>https://blog.codinghorror.com/lcd-progress/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
After revisiting my <a href="http://www.codinghorror.com/blog/archives/000740.html">
ongoing three monitor obsession</a> recently, I was compelled to upgrade my current
mongrel mix of varying LCD monitor brands and sizes. I settled on three 20" <a href="http://review.zdnet.com/Samsung_SyncMaster_204B/4505-3174_16-31676719.html">
Samsung 204B</a> panels.</p>
<p>
Standardizing on a single type of monitor in a multiple monitor configuration has obvious
advantages in color consistency and uniform sizing. But LCD technology has also
advanced quite a bit since my last LCD purchase. Here's a small chart outlining the relevant
specs of every LCD panel I've ever owned:</p>
<p>
</p>
<table border="0" width="600">
<tr>
<td></td>
<td>
<strong>Samsung 191T</strong>
</td>
<td>
<strong>
Rosewill R910J</strong>
</td>
<td>
<strong>
Samsung 213T</strong>
</td>
<td>
<strong>
Samsung 204B</strong>
</td>
</tr>
<tr>
<td bgcolor="LightGrey">Vintage</td>
<td>
Mid 2003
</td>
<td>
Early 2005</td>
<td>
Early 2005</td>
<td>
Late 2006</td>
</tr>
<tr>
<td bgcolor="LightGrey">Size</td>
<td>19"
</td>
<td>
19"</td>
<td>
21.3"</td>
<td>
20"</td>
</tr>
<tr>
<td bgcolor="lightgrey">
Price Paid</td>
<td>
$660</td>
<td>
$320</td>
<td>
$840</td>
<td>
$350</td>
</tr>
<tr>
<td bgcolor="LightGrey">Resolution</td>
<td>1280x1024
</td>
<td>
1280x1024</td>
<td>
1600x1200</td>
<td>
1600x1200</td>
</tr>
<tr>
<td bgcolor="LightGrey">
Brightness</td>
<td>250 cd/m<sup>2</sup>
</td>
<td>
250 cd/m<sup>2</sup>
</td>
<td>
250 cd/m<sup>2</sup>
</td>
<td>
300 cd/m<sup>2</sup>
</td>
</tr>
<tr>
<td bgcolor="LightGrey">Contrast</td>
<td>500:1
</td>
<td>
600:1</td>
<td>
500:1</td>
<td>
800:1</td>
</tr>
<tr>
<td bgcolor="LightGrey">Viewing Angle</td>
<td>170
</td>
<td>
170</td>
<td>
170</td>
<td>
160</td>
</tr>
<tr>
<td bgcolor="LightGrey">Response time</td>
<td>25 ms
</td>
<td>
25ms</td>
<td>
25ms</td>
<td>
<span style="color: red">
5ms</span>
</td>
</tr>
</table>

<p>
Yes, there are minor brightness and contrast bumps. But more importantly, there's
been <strong>a huge improvement in
response time</strong>. This addresses one of the <a href="http://techreport.com/reviews/2002q4/lcds/index.x?pg=1">
key criticisms of LCD monitors</a>:
</p>
<p></p>
<blockquote>
The liquid crystals in an LCD have to change their
molecular structure to manipulate light, and that's not a speedy process. As a result,
LCD pixels respond much slower than what you may be used to on a CRT monitor, and
that can cause ghosting and streaking, especially at high frame rates.
The pixel response time of LCDs has improved dramatically over the years, but CRTs
still have the edge. What's most worrying about pixel response times, however, is
that LCDs with similar pixel response time specs don't always show the same performance
in the real world. It's really something you have to check for yourself.
</blockquote>
<p>
That was written in 2002. LCDs are larger and cheaper now, and getting
larger and cheaper every day. The improvement in response time makes watching video and gaming
on LCDs nearly equivalent to a CRT. Worries about dead pixels are generally a thing of the past, too. It's
fair to say that LCDs have won the hearts, minds, and wallets of the public in 2006. It's difficult to find places that even <em>sell</em> CRTs these days.</p>
<p>
I'm glad the era of the CRT is finally over. Not just because LCDs are more svelte
and power efficient, but also because LCD monitors are much less finicky than CRT
monitors. <strong>Getting great image quality with an LCD is dead simple.</strong>
You only need to do two things:</p>
<p>
</p>
<ol>
<li>
<strong>Always use the DVI port to connect your LCD.</strong>
<p>
<img alt="image placeholder" >
</p>
<p>
The DVI port is digital, so you get a perfect connection to the LCD every time. Using a VGA port with an LCD is downright pathological-- it means you're converting
the digital bits inside your video card to an analog video signal, then converting
the analog video signal <em>back</em>
to digital bits inside the LCD. You open yourself
up to a whole host of nasty analog conversion issues along the way. Don't do this!
Use the DVI port! If you own a video card
that doesn't have two DVI ports, it's time for a new video card.</p>
</li>
<li>
<p>
<strong>Set your monitor's refresh rate to 60 Hertz.</strong></p>
<p><img alt="image placeholder" >
<p>
<a href="http://en.wikipedia.org/wiki/Refresh_rate">Refresh rate has no real meaning
to a LCD</a>, but it can still cause problems if it's set to anything higher
than 60 hertz. This ought to be set automatically when you connect a LCD panel,
but it never is in my experience. So go in and lock the refresh rate down to 60
hertz.</p>
</li>
<li>
<b>Set the display to the maximum native resolution.</b>
<p>
LCDs work best at their native resolution-- when there is one pixel on the LCD for every pixel on the screen. If you run a 1600x1200 LCD panel with a 1280x1024 desktop, you'll get a blurry, upsized image instead of the perfect digital clarity LCDs are capable of. The maximum native resolution is usually the maximum resolution available in the display dialog, but double check your monitor's manual if you're unsure. LCDs should look <i>perfect</i>. If it looks blurry at all, either you're using an anlaog VGA input, or you're using the wrong resolution.
</p>
</li>
</ol>
<p>
The digital connection between PC and LCD is about as good as it gets, right out
of the box. Contrast this with the experience of hooking up a new CRT: to get the
best image quality, you had to tweak the refresh rate, the image sizing, the pincushion
adjustment, and a half-dozen other tedious, fiddly little analog settings.
</p>
<p>
But even with the refresh rate issue largely addressed, LCDs do have <a href="http://techreport.com/reviews/2002q4/lcds/index.x?pg=1">a few
other display peculiarities</a> that linger on:</p>
<blockquote>
<b>Viewing angle. </b>When viewed from the side, above, or below, images on LCD
monitors become noticeably darker, and colors start to get washed out. CRTs, on
the other hand, can be viewed from extreme angles with little loss in actual picture
quality. Admittedly, there are few areas where viewing angle makes a big difference
for end users, but the limitation is worth noting. If, for example, you want to
watch a DVD on your LCD with a group of friends, everyone is going to have to get
real cozy with each other on the couch to see things properly. Limited viewing angles
might not be a bad excuse to get a little closer to your date, but your buddy that's
just over to watch Office Space may object to you rubbing up against his leg like
that.
<p>
</p>
<b>Color reproduction. </b>Although LCD screens claim support for 32-bit color,
the displays themselves often aren't capable of accurately reproducing <i>all</i>
16.7 million colors common 32-bit graphics modes. With a properly calibrated LCD,
a casual user probably won't notice the difference, but the limitation will probably
give graphics designers fits.
<p>
</p>
<b>Contrast ratio. </b>LCDs are back-lit whenever they're on, which means that
TFT panels have to orient the liquid crystals to block light if they want to display
black. Some light inevitably manages to seep through the cracks, which limits a
screen's ability to display a true black.
</blockquote>
<p>
Some of these peculiarities are only of interest to hardcore graphic designers.
I'm assuming that most modern LCDs are capable of displaying the full 32-bit range
of color by now. Regardless, color calibration remains <a href="http://reviews.cnet.com/4520-6501_7-5143365-1.html?tag=promo2">
as much an art as a science</a>, and adjusting colors is difficult on LCDs.
I've also noticed backlight problems on every LCD I've owned, including the new
models that just arrived. Blacks are never quite as deep as they would be on a CRT.
And the backlighting is never perfectly uniform. I tend to see gradations in color
and brightness on LCDs where there shouldn't be any. As for viewing angle, this
is more of a problem for LCD televisions than monitors.
In computing scenarios,
we tend to sit much closer to the monitors, and in a fixed location. If you're a
hardcore graphic designer, you can buy <a href="http://www.lacie.com/products/range.htm?id=10016">
extremely high end, extremely expensive LCD monitors</a> which attempt to resolve
the color and uniformity problems endemic to most LCDs. But these specialty monitors
do nothing for viewing angle, and they tend to sacrifice response time, making the ghosting and streaking problems even worse.</p>
<p>
<strong>Is it possible to calibrate a LCD?</strong> You can get some ideas of what
you might want to calibrate in <a href="http://reviews.cnet.com/Labs/4520-6603_7-5098394-1.html?tag=txt">
CNET's description of their LCD monitor testing methodology</a>. Software like
<a href="http://www.displaymate.com/enduser.html">Displaymate</a> or <a href="http://www.passmark.com/products/monitortest.htm">
MonitorTest</a> can even walk you through the process. But the earlier good
news-- that LCD displays generally don't need to be adjusted to produce good image
quality -- is also the bad news here. There's not much you <em>can</em> adjust on
a digitally connected LCD, other than the brightness and color temperatures. But
that's generally enough to <a href="http://www.normankoren.com/makingfineprints1A.html">
calibrate the essentials: brightness and gamma</a>.</p>
<p>
After you're done calibrating, it's time to clean all that dust off your LCD. I've
been wary of cleaning my LCD panels, because I'm afraid of damaging the anti-glare
or glossy (laptop) coatings. Soap and water leaves massive streaks, and caustic
window cleaners are clearly out. I was recently turned on to the <a href="http://www.amazon.com/exec/obidos/ASIN/B000068P8W/codihorr-20">Monster ScreenClean display cleaning kit</a>,
which works wonderfully. It cleans almost effortlessly without streaks, and it's
a screen-friendly non-alcohol formulation. It's almost like screen lube.</p>
<p>
LCDs still have a way to go before they're <em>perfect</em> substitutes for CRTs.
With the recent industry advances in refresh rate, at least LCDs no longer have
any glaring weaknesses. Here's hoping that improvements continue to keep pace in in viewing angle and backlighting.</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-13T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/lcd-progress/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Percentage of Chart Which Resembles Ms. Pac-Man ]]></title>
<link>https://blog.codinghorror.com/percentage-of-chart-which-resembles-ms-pac-man/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I couldn't <a href="http://themot.org/gallery/d/58721-1/pacmanchart.png">resist</a>.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
In the innocent era of 8-bit arcades, you made characters female by adding a cute little pixelated red bow. Just like in <a href="http://www.somethingawful.com/index.php?a=2305&amp;p=20">Ms. Sawhorse Detective</a>.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-14T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/percentage-of-chart-which-resembles-ms-pac-man/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ High-Definition Video on the PC ]]></title>
<link>https://blog.codinghorror.com/high-definition-video-on-the-pc/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>Now that HD-DVD and Blu-Ray are starting to enter the market in earnest, I thought I'd revisit HD video playback on the PC. I'm seriously considering buying one of the $199 <a href="http://www.pcper.com/article.php?aid=325">Xbox 360 HD-DVD kits</a> and <a href="http://www.hackaday.com/2006/11/13/xbox-hd-dvd-rom-on-mac-and-pc/">retrofitting it into my Home Theater PC</a>.</p>
<p>I'll start by comparing three clips from the <a href="http://www.microsoft.com/windows/windowsmedia/musicandvideo/hdvideo/contentshowcase.aspx">Microsoft Windows Media High Definition Showcase</a> page. It's a tad out of date now  most of these sample high-definition clips were mastered in late 2003 or early 2004, long before HD-DVD or Blu-Ray. But the bitrates and sizes are still representative.</p>
<p>Most of the clips had similar performance characteristics, so I chose one clip from each category.</p>
<table width="700">
<tr>
<td>
</td>
<td>
<a href="http://download.microsoft.com/download/1/5/0/15092c6c-5af1-4208-b5e2-54af6f1009a4/T2_720.exe">T2 Promo</a><br>
<b>720p</b>
</td>
<td>
<a href="http://download.microsoft.com/download/1/5/0/15092c6c-5af1-4208-b5e2-54af6f1009a4/T2_1080.exe">T2 Promo</a><br>
<b>1080p</b>
</td>
<td>
<a href="http://download.microsoft.com/download/e/a/d/eadb9b42-728b-42b0-bfdf-b472fa2a2464/Step_into_Liquid_1080.exe">Step Into Liquid Promo</a><a><br>
<b>1080p</b></a>
</td>
</tr>
<tr>
<td>
Resolution</td>
<td>
1280 x 720</td>
<td>
1440 x 1080</td>
<td>
1440 x 1080</td>
</tr>
<tr>
<td>
Bitrate</td>
<td>
6.93 Mbps</td>
<td>
8.44 Mbps</td>
<td>
8.44 Mbps</td>
</tr>
<tr>
<td>
Audio Codec</td>
<td>
WMA 9 Pro<br>
5.1 channel<br>
384 Kbps</td>
<td>
WMA 9 Pro<br>
5.1 channel<br>
384 Kbps</td>
<td>
WMA 9 Pro<br>
2 channel<br>
384 Kbps</td>
</tr>
<tr>
<td>
Video Codec</td>
<td>
WMA 9 Pro</td>
<td>
WMA 9 Pro</td>
<td>
WMA 9 Pro</td>
</tr>
</table>
<p>Note that I included the <a href="http://www.amazon.com/exec/obidos/ASIN/B0001FGBUC/codihorr-20">Step Into Liquid</a> promo because it's the <em>only</em> clip on the <a href="http://www.microsoft.com/windows/windowsmedia/musicandvideo/hdvideo/contentshowcase.aspx">WMV HD Showcase page</a> that requires an abnormally large amount of CPU power to decode. I'm still not sure exactly why. The resolution is the same, and the bitrate looks comparable. You'll also note that Microsoft has an odd definition of 1080p. The official television resolutions break down as follows:</p>
<table width="450">
<tr>
<td>
</td>
<td>
</td>
<td>
</td>
<td align="right">
Pixels per frame</td>
</tr>
<tr>
<td>
<strong>
480i</strong>
</td>
<td>
704 x 480 </td>
<td>
interlaced</td>
<td style="text-align: right">
168,960</td>
</tr>
<tr>
<td>
<strong>
480p</strong>
</td>
<td>
704 x 480 </td>
<td>
progressive</td>
<td style="text-align: right">
337,920</td>
</tr>
<tr>
<td>
<strong><b>720p</b></strong>
</td>
<td>
1280 x 720</td>
<td>
progressive</td>
<td style="text-align: right">
921,600</td>
</tr>
<tr>
<td>
<strong>
1080i</strong>
</td>
<td>
1920 x 1080 </td>
<td>
interlaced</td>
<td style="text-align: right">
1,036,800</td>
</tr>
<tr>
<td>
<strong>1080p</strong>
</td>
<td>
1920 x 1080 </td>
<td>
progressive</td>
<td style="text-align: right">
2,073,600</td>
</tr>
</table>
<p>The official definition of <strong>1080p is 1920x1080</strong>, so I'm not sure what Microsoft was thinking there. Interlaced means resolution is effectively halved vertically in time; frames alternate between odd and even lines each cycle.</p>
<p><img alt="image placeholder" >
<p><a href="http://en.wikipedia.org/wiki/Interlace">Interlaced video modes</a> are generally considered inferior to progressive video modes, and should only be used if you have no way to enable progressive modes. Interlacing has a lot of problems and should be avoided whenever possible.</p>
<p>I compared CPU usage in Task Manager during full-screen playback of each clip in <a href="http://www.microsoft.com/windows/windowsmedia/player/11/">Windows Media Player 11</a> on a few systems I have around the house. Note that <a href="http://en.wikipedia.org/wiki/DXVA">DirectX Video Acceleration</a> was enabled in each case.</p>
<table width="800">
<tr>
<td></td>
<td>
<strong>Pentium-M 1.75 GHz</strong>
</td>
<td>
<strong>Athlon 64 1.8 GHz</strong>
</td>
<td>
<strong>Core Duo 2.0 GHz</strong>
</td>
</tr>
<tr>
<td>
<a href="http://download.microsoft.com/download/1/5/0/15092c6c-5af1-4208-b5e2-54af6f1009a4/T2_720.exe">
T2 Promo<br>
</a>720p</td>
<td>
<img alt="image placeholder" >
75% CPU, perfect</td>
<td>
<img alt="image placeholder" >
50% CPU, perfect</td>
<td>
<img alt="image placeholder" >
25% CPU, perfect</td>
</tr>
<tr>
<td>
<a href="http://download.microsoft.com/download/1/5/0/15092c6c-5af1-4208-b5e2-54af6f1009a4/T2_1080.exe">
T2 Promo<br>
</a>1080p</td>
<td>
<img alt="image placeholder" >
85% CPU, perfect</td>
<td>
<img alt="image placeholder" >
75% CPU, perfect</td>
<td>
<img alt="image placeholder" >
33% CPU, perfect</td>
</tr>
<tr>
<td>
<a href="http://download.microsoft.com/download/e/a/d/eadb9b42-728b-42b0-bfdf-b472fa2a2464/Step_into_Liquid_1080.exe">
Step Into Liquid Promo</a><br>1080p</td>
<td>
<img alt="image placeholder" >
100% CPU, unwatchably choppy</td>
<td>
<img alt="image placeholder" >
95% CPU, very choppy</td>
<td>
<img alt="image placeholder" >
40% CPU, perfect</td>
</tr>
</table>
<p>I have a sneaking suspicion the reason Microsoft redefined "1080p" as 1440x1080 had to do with performance. I doubt any PC system could play a true 1080p clip at the time these clips were mastered. <strong>It clearly requires a lot of CPU horespower to render high definition video.</strong> Driving 1920x1080 requires a lot of grunt  both in terms of pixel-pushing video bandwidth, and also in terms of CPU power for the advanced encoding used to keep the file size down on these massive resolutions. Dual core does this especially well, although it appears to do so by brute force load sharing rather than any special multiprocessor optimizations in the decoder. <strong>The mainstream PC is only now catching up to the performance required to watch high definition video</strong>.</p>
<p>All the video samples I cited are in Windows Media format. Windows Media, by all accounts, offers a <a href="http://www.drunkenblog.com/drunkenblog-archives/000312.html">very good next generation encoder</a>, but it isn't the only encoder on the block. Both <a href="http://www.engadget.com/2005/09/19/blu-ray-vs-hd-dvd-state-of-the-s-union-s-division/">Blu-Ray and HD-DVD</a> allow three different encoders:</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/H.264">H.264 / MPEG-4 AVC</a></li>
<li>
<a href="http://en.wikipedia.org/wiki/VC-1">Microsoft Video Codec 1</a> (aka VC1,
WMV HD)</li>
<li><a href="http://en.wikipedia.org/wiki/MPEG-2">MPEG-2</a></li>
</ul>
<p>Woe to the poor consumer who <a href="http://www.highdefdigest.com/feature_blurayvshddvd_roundtwo.html">buys a HD-DVD or Blu-Ray disc encoded with the ancient MPEG-2 encoder</a>. It'll look awful and take up a lot more room than it should. H.264 and MVC-1, however, are truly next generation encoders. They look better in less space, but they also require a<em> lot</em> more CPU power to decode. At least we have a few legitimate uses left for the ridiculous amounts of CPU power we've inherited over the years.</p>
<p>If you own a relatively new video card, <strong>it is possible to offload some of the video decoding chores from your CPU to your video card's GPU</strong>. But the configuration, drivers, and software necessary to achieve this acceleration is <a href="http://forums.nvidia.com/index.php?showtopic=12150&amp;st=560">daunting</a>. Anandtech found that, when properly configured, the latest video cards can significantly reduce the H.264 decoding burden on the CPU; <a href="http://www.anandtech.com/video/showdoc.aspx?i=2645&amp;p=2"> ATI reduced it by half</a>, and <a href="http://www.anandtech.com/video/showdoc.aspx?i=2798&amp;p=3">Nvidia reduced it by a fifth</a>. But good luck getting everything set up in Windows XP. Here's hoping Windows Vista and <a href="http://en.wikipedia.org/wiki/DXVA">DirectX Video Acceleration 2.0</a> enables hardware accelerated video decoding out of the box.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-15T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/high-definition-video-on-the-pc/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Next-Gen DVD: Are Those Additional Pixels Worth Your Money? ]]></title>
<link>https://blog.codinghorror.com/next-gen-dvd-are-those-additional-pixels-worth-your-money/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
Next generation DVD formats promise a huge jump in resolution, from the <b>720 x 480</b> of standard DVD to the <b>1920 x 1080</b> of HD-DVD and Blu-Ray.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Additional resolution is always welcome, of course. But it's not free. You'll have to purchase a HD-DVD or Blu-Ray player, and a television set capable of displaying the new high definition formats. Then you'll need to either rent or buy features on the new optical media formats, as they become available.
</p>
<p>
But <i>are those additional pixels worth your money?</i>
</p>
<p>
Decide for yourself. Consider <a href="http://www.cornbread.org/FOTRCompare/index.html">this detailed comparison of Fellowship of the Ring</a> in both formats. Mouse over each image to see before and after; click the images to see the full-size versions.
</p>
<p>
Here's a closeup of one particular section to illustrate the difference in fine detail:
</p>
<p>
<img alt="image placeholder" >

<img alt="image placeholder" >
</p>
<p>
There is more detail, but I'm left wondering how much of that detail I would notice on a 42" display ten feet in front of my couch. Edward Tufte's arguments <a href="http://www.codinghorror.com/blog/archives/000644.html">in favor of information density</a> are for the printed page, which you read less than a foot from your eyes. I don't think the same rules apply to video ten feet or more away. And how, exactly, do we explain the runaway success of YouTube, where video quality is never less than appalling? Clearly, the rules are different for images in motion.
</p>
<p>
As screens grow in size, you do need more detail. I doubt a DVD would look very good projected on a movie screen in a typical movie theater. But I also think people tend to overestimate how much detail is needed for an image of a given size; witness <a href="http://pogue.blogs.nytimes.com/2006/11/21/21pogues-posts-2/">David Pogue's street experiment</a>:
</p>
<p>
</p>
<blockquote>
On the show, we did a test. <b>We blew up a photograph to 16 x 24 inches at a professional photo lab. One print had 13-megapixel resolution; one had 8; the third had 5. Same exact photo, down-rezzed twice, all three printed at the same poster size. I wanted to hang them all on a wall in Times Square and challenge passersby to see if they could tell the difference.</b>
<p>
Even the technician at the photo lab told me that I was crazy, that there'd be a huge difference between 5 megapixels and 13.
</p>
<p>
I'm prepared to give away the punch line of this segment, because hey -- the show doesn't air till February, and you'll have forgotten all about what you read here today, right?
</p>
<p>
Anyway, we ran the test for about 45 minutes. Dozens of people stopped to take the test; a little crowd gathered. About 95 percent of the volunteers gave up, announcing that there was no possible way to tell the difference, even when mashing their faces right up against the prints. A handful of them attempted guesses -- but were wrong. Only one person correctly ranked the prints in megapixel order, although (a) she was a photography professor, and (b) I believe she just got lucky.
</p>
<p>
I'm telling you, there was NO DIFFERENCE.
</p>
</blockquote>
<p>
So, by the same logic, are high definition DVD formats a waste of money?
</p>
<p>
Perhaps. <b>But I've noticed that typical DVD playback pales in comparison to high definition video clips, even when downscaled to the 800x480 of my 42" EDTV plasma.</b> It's a form of supersampling anti-aliasing; higher resolution sources scale better to larger <i>and smaller</i> screens. I don't think you necessarily need a giant screen, or even a particularly high resolution screen, to benefit from the additional source resolution.
</p>
<p>
Next-gen DVDs offer almost 5 times the resolution of standard DVDs. Despite the math, <b>the practical difference between DVD resolution and next-gen DVD resolution is highly subjective</b>. And it's arguably much less significant than the giant jump we took over the last 10 years to get from standard television resolution to DVD resolution. Have we already reached the point of diminishing returns? Is anyone actually arguing that DVDs don't look good enough? And is the market willing to pay more for higher resolutions?
</p>
<p>
To make matters worse, the road to next-gen DVD is currently fraught with risks: technological copy-protection pitfalls, additional costs, and an ongoing format war. PCFormat UK writes that <b>both formats <i>reek of exploitation</i></b>, and offers an <a href="http://blog.pcformat.co.uk/?entry=hd_dvd_and_blu_ray">apples to apples comparison</a> of DVD, HD-DVD and Blu-Ray stills from the movie <a href="http://www.imdb.com/title/tt0139654/">Training Day</a>.  Judge for yourself.
</p>
<p>
Although I'll always be a fan of increased resolution, I'm not sure these additional pixels have earned my money yet.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-16T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/next-gen-dvd-are-those-additional-pixels-worth-your-money/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Hard Drive Temperatures: Be Afraid ]]></title>
<link>https://blog.codinghorror.com/hard-drive-temperatures-be-afraid/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>
I recently had a noisy fan failure in my <a href="http://www.codinghorror.com/blog/archives/000218.html">ASUS Vento 3600 case</a>. The particular fan that failed was the 80mm fan in the front panel, which is responsible for circulating air by the hard drives in the front of the case. I disconnected it while I considered my options. There's not a lot of airflow by the hard drives in this case. <b>I've actually had a hard drive failure in this system</b>, which I strongly suspect was due to leaving the front fan disconnected.
</p>
<p>
The two hard drives are mounted with rubber grommets to <a href="http://www.codinghorror.com/blog/archives/000665.html">reduce conducted vibration noise</a>, a standard feature of many new PC cases.
</p>
<p>
<img alt="image placeholder" >
</p>
<p>
Avoiding direct metal-to-metal contact will always help quiet drives-- they are, after all, giant hunks of metal spinning at 7,200 or 10,000 RPM. But the lack of metal-to-metal contact <i>also</i> means the drives don't benefit from the significant auxiliary cooling effects of metal contact.
</p>
<p>
Of course, hard drives don't generate nearly as much heat as your CPU and video card do. They only consume <a href="http://www.digit-life.com/articles2/storage/hddpower.html">around 10 or 12 watts under load, and around 7 watts at idle</a>.  But unlike your CPU, they're generating a lot of mechanical movement, which means friction-- and heat disproportionate to the power input. They still need some airflow to stay at a reasonable temperature.
</p>
<p>
I often read about users obsessing over their CPU or GPU temperatures, while ignoring their hard drive temperatures entirely. That's a shame, because <b>the hard drive is the most temperature sensitive device inside your computer</b>. Most manufacturers <a href="http://users.erols.com/chare/elec.htm">rate CPUs up to 70C</a>, and GPUs commonly rate to 90C and beyond.
</p>
<p>
</p>
<blockquote>
Manufacturers measure off quite a modest range of operating temperatures for hard drives, from +5 to +55C as a rule, and occasionally to +60C. This operating range is much lower than processors, video cards, or chipsets. Moreover, hard drive reliability depends heavily on their operating temperatures. According to our research, <b>increasing HDD temperature by 5C has the same effect on reliability as switching from 10% to 100% HDD workload. Each one-degree drop of HDD temperature is equivalent to a 10% increase of HDD service life.</b>
</blockquote>
<p>
Hard drives are only rated to 55C in most cases. Although there's <a href="http://www.silentpcreview.com/forums/viewtopic.php?t=7677">still a lot of ongoing discussion</a> on what exactly a "safe" temperature is for a hard drive, the general consensus is that high temperatures are much more risky for the hard drive than any other component inside your computer.
</p>
<p>
When your CPU, video card, or motherboard fails, you buy a new one and replace it. Big deal. Life goes on. But when your hard drive fails, unless you have a rigorous backup regime, <i>you just lost all your data</i>. <b>Failure of a hard drive tends to have catastrophic consequences for your data</b>. That's why I'm always very careful with hard drive temperatures. When I disconnected the failing fan, I used <a href="http://private.peterlink.ru/tochinov/download.html">the excellent DTemp hard-drive temperature monitoring utility</a> to keep an eye on the temperatures.
</p>
<p>
<a href="http://private.peterlink.ru/tochinov/download.html"><img alt="image placeholder" >
</p>
<p>
Sure enough, with the front fan disconnected, both drives inched up to 46C in 15 minutes. And that was at idle. I can only imagine what the temperatures would look like after internal temperatures increased under load. I've already had one drive failure in this case with sustained temperatures around the same level. Some kind of replacement airflow is essential. I used foam tape to mount an 80mm fan on the front of the drives, blowing across the drives and back towards the case. As I write this, they're down to 33C -- a whopping 13 degree drop.
</p>
<p>
<b>Hard drive temperature is arguably the most important temperature to monitor in your computer.</b> If you regularly see temperatures of 45C or higher on your drive, consider improving airflow in your case. If you don't, you've substantially increased your risk of hard drive failure or data loss.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/hard-drive-temperatures-be-afraid/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
<item>
<title><![CDATA[ Code Tells You How, Comments Tell You Why ]]></title>
<link>https://blog.codinghorror.com/code-tells-you-how-comments-tell-you-why/</link>
<content><![CDATA[ 
                <!--kg-card-begin: markdown--><p>In an <a href="http://blog.codinghorror.com/when-good-comments-go-bad/">earlier post on the philosophy of code comments</a>, I noted that <b>the best kind of comments are the ones you don't need</b>. Allow me to clarify that point. You should first strive to make your code as simple as possible to understand without relying on comments as a crutch. Only at the point where the code <i>cannot</i> be made easier to understand should you begin to add comments.</p>
<p>It helps to keep your audience in mind when you're writing code. The classic book <a href="http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-7.html">Structure and Interpretation of Computer Programs</a>, originally published in 1985, gets right to the point in the preface:</p>
<blockquote>
<p>Programs must be written for people to read, and only incidentally for machines to execute.</p>
</blockquote>
<p>Knuth covers similar ground in his classic 1984 essay on <a href="http://www-cs-faculty.stanford.edu/~knuth/lp.html">Literate Programming</a> (<a href="http://www.literateprogramming.com/knuthweb.pdf">pdf</a>):</p>
<blockquote>
<p>Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.</p>
</blockquote>
<blockquote>
<p>The practitioner of <a href="http://en.wikipedia.org/wiki/Literate_programming">literate programming</a> can be regarded as an essayist, whose main concern is with exposition and excellence of style. Such an author, with thesaurus in hand, chooses the names of variables carefully and explains what each variable means. He or she strives for a program that is comprehensible because its concepts have been introduced in an order that is best for human understanding, using a mixture of formal and informal methods that reinforce each other.</p>
</blockquote>
<p>If you write your code to be consumed by other programmers first, and by the compiler second, you may find the need for additional comments to be greatly reduced. Here's an excellent example of <a href="http://www.jtse.com/blog/2006/12/15/does-bad-writing-reflect-poor-programming-skills">using comments as a crutch</a>:</p>
<blockquote>
<p>This is a snippet of code from a well funded, closed-source system that has been deployed in production for years.</p>
<pre><code>float _x = abs(x - deviceInfo-&gt;position.x) / scale;
</code></pre>
</blockquote>
<pre><code>int directionCode;
if (0 &lt; _x &amp; x != deviceInfo-&gt;position.x) {
    if (0 &gt; x - deviceInfo-&gt;position.x) {
        directionCode = 0x04 /*left*/;
    } else if (0 &lt; x - deviceInfo-&gt;position.x) {
        directionCode = 0x02 /*right*/;
    }
}
</code></pre>
<blockquote>
<p>This is equivalent to the following, more readable code, with a bugfix.</p>
<pre><code>static const int DIRECTIONCODE_RIGHT = 0x02;
static const int DIRECTIONCODE_LEFT = 0x04;
static const int DIRECTIONCODE_NONE = 0x00;

int oldX = deviceInfo-&gt;position.x;
int directionCode = (x &gt; oldX)? DIRECTIONCODE_RIGHT
                  : (x &lt; oldX)? DIRECTIONCODE_LEFT
                  : DIRECTIONCODE_NONE;
</code></pre>
<p>Note that more comments does not mean more readable code. It didn't in this example. <b>The comments in the snippet above  if you even noticed them  only clutter the code even more.</b> Sometimes <em>fewer</em> comments makes for more readable code. Especially if it forces you to use meaningful symbol names instead.</p>
</blockquote>
<p>Although there are almost infinite opportunities to refactor and simplify code to obviate the need for comments, explaining yourself exclusively in code has its limits.</p>
<p>No matter how simple, concise, and clear your code may end up being, it's impossible for code to be completely self-documenting. <b>Comments can never be replaced by code alone.</b> Just ask <a href="http://acmqueue.com/modules.php?name=Content&amp;pa=showpage&amp;pid=290&amp;page=2">Jef Raskin</a>:</p>
<blockquote>
<p>Code can't explain why the program is being written, and the rationale for choosing this or that method. Code cannot discuss the reasons certain alternative approaches were taken. For example:</p>
<pre><code>/* A binary search turned out to be slower than the Boyer-Moore algorithm for the data sets of interest, thus we have used the more complex, but faster method even though this problem does not at first seem amenable to a string search technique. */
</code></pre>
</blockquote>
<p>What is perfectly, transparently obvious to one developer may be utterly opaque to another developer who has no context. Consider <a href="http://everything2.com/index.pl?node_id=1709851&amp;displaytype=printable">this bit of commenting advice</a>:</p>
<blockquote>
<p>You may very well know that</p>
<p><code>$string = join('',reverse(split('',$string)));</code></p>
<p>reverses your string, but how hard is it to insert</p>
<p><code># Reverse the string</code></p>
<p>into your Perl file?</p>
</blockquote>
<p>Indeed. It's not hard at all. Code can only tell you <em>how</em> the program works; comments can tell you <em>why</em> it works.  Try not to shortchange your fellow developers in either area.</p>
<!--kg-card-end: markdown-->
             ]]></content>
<pubDate>2006-12-18T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/code-tells-you-how-comments-tell-you-why/</guid>
<author><![CDATA[ Jeff Atwood ]]></author>
</item>
</channel>
</rss>
